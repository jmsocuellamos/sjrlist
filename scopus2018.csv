"Authors","Author full names","Author(s) ID","Title","Year","Source title","Cited by","DOI","Link","Affiliations","Authors with affiliations","Abstract","Author Keywords","Index Keywords","Publisher","ISSN","ISBN","CODEN","PubMed ID","Document Type","Source","EID"
"Guo Y.; Budak Ü.; Şengür A.","Guo, Yanhui (55712447000); Budak, Ümit (57189511236); Şengür, Abdulkadir (12545159900)","55712447000; 57189511236; 12545159900","A novel retinal vessel detection approach based on multiple deep convolution neural networks","2018","Computer Methods and Programs in Biomedicine","45","10.1016/j.cmpb.2018.10.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055902158&doi=10.1016%2fj.cmpb.2018.10.021&partnerID=40&md5=ccbbfa081f9ba2140c17b3659bc606ed","Department of Computer Science, University of Illinois, Springfield, IL, United States; Department of Electrical-Electronics Engineering, Bitlis Eren University, Bitlis, Turkey; Electrical and Electronics Engineering Department, Firat University, Elazig, Turkey","Guo Y., Department of Computer Science, University of Illinois, Springfield, IL, United States; Budak Ü., Department of Electrical-Electronics Engineering, Bitlis Eren University, Bitlis, Turkey; Şengür A., Electrical and Electronics Engineering Department, Firat University, Elazig, Turkey","Background and objective: Computer aided detection (CAD) offers an efficient way to assist doctors to interpret fundus images. In a CAD system, retinal vessel (RV) detection is a crucial step to identify the retinal disease regions. However, RV detection is still a challenging problem due to variations in morphology of the vessels on noisy and low contrast fundus images. Methods: In this paper, we formulate the detection task as a classification problem and solve it using a multiple classifier framework based on deep convolutional neural networks. The multiple deep convolutional neural network (MDCNN) is constructed and trained on fundus images with limited image quantity. The MDCNN is trained using an incremental learning strategy to improve the networks’ performance. The final classification results are obtained from the voting procedure on the results of MDCNN. Results: The MDCNN achieves better performance and significantly outperforms the state-of-the-art for automatic retinal vessel segmentation on the DRIVE dataset with 95.97% and 96.13% accuracy and 0.9726 and 0.9737 AUC (area below the operator receiver character curve) score on training and testing sets, respectively. Another public dataset, STARE, is also used to evaluate the proposed network. The experimental results demonstrate that the proposed MDCNN network achieves 95.39% accuracy and 0.9539 AUC score in STARE dataset. We further compare our result with several state-of-the-art methods based on AUC values. The comparison is shown that our proposal yields the third best AUC value. Conclusions: Our method yields the better performance in the compared the state of the art methods. In addition, our proposal has no preprocessing stage, and the input color fundus images are fed into the CNN directly. © 2018 Elsevier B.V.","Image segmentation; Multiple deep convolution neural network; Retinal vessels segmentation","Algorithms; Computer Systems; Diagnosis, Computer-Assisted; Fundus Oculi; Humans; Machine Learning; Models, Statistical; Neural Networks (Computer); Reproducibility of Results; Retinal Diseases; Retinal Vessels; Sensitivity and Specificity; Computer aided diagnosis; Convolution; Eye protection; Image segmentation; Neural networks; Ophthalmology; Personnel training; Statistical tests; Classification results; Computer-aided detection; Convolution neural network; Deep convolutional neural networks; Retinal vessel detection; Retinal vessel segmentations; Retinal vessels segmentations; State-of-the-art methods; Article; artificial neural network; automation; classification; classifier; eye fundus; image segmentation; measurement accuracy; multiple deep convolution neural network; retina blood vessel; retina image; wavelet transformation; algorithm; computer assisted diagnosis; computer system; diagnostic imaging; human; machine learning; reproducibility; retina blood vessel; retina disease; sensitivity and specificity; statistical model; Deep neural networks","Elsevier Ireland Ltd","01692607","","CMPBE","30501859","Article","Scopus","2-s2.0-85055902158"
"Bjerrum E.J.; Sattarov B.","Bjerrum, Esben Jannik (7801393192); Sattarov, Boris (57204503832)","7801393192; 57204503832","Improving chemical autoencoder latent space and molecular de novo generation diversity with heteroencoders","2018","Biomolecules","103","10.3390/biom8040131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055784756&doi=10.3390%2fbiom8040131&partnerID=40&md5=92502990d1d6c28ccf509d21b1c085ad","Wildcard Pharmaceutical Consulting, Zeaborg Science Center, Frødings Allé 41, Søborg, 2860, Denmark; Science Data Software LLC, 14914 Bradwill Court, Rockville, 20850, MD, United States","Bjerrum E.J., Wildcard Pharmaceutical Consulting, Zeaborg Science Center, Frødings Allé 41, Søborg, 2860, Denmark; Sattarov B., Science Data Software LLC, 14914 Bradwill Court, Rockville, 20850, MD, United States","Chemical autoencoders are attractive models as they combine chemical space navigation with possibilities for de novo molecule generation in areas of interest. This enables them to produce focused chemical libraries around a single lead compound for employment early in a drug discovery project. Here, it is shown that the choice of chemical representation, such as strings from the simplified molecular-input line-entry system (SMILES), has a large influence on the properties of the latent space. It is further explored to what extent translating between different chemical representations influences the latent space similarity to the SMILES strings or circular fingerprints. By employing SMILES enumeration for either the encoder or decoder, it is found that the decoder has the largest influence on the properties of the latent space. Training a sequence to sequence heteroencoder based on recurrent neural networks (RNNs) with long short-term memory cells (LSTM) to predict different enumerated SMILES strings from the same canonical SMILES string gives the largest similarity between latent space distance and molecular similarity measured as circular fingerprints similarity. Using the output from the code layer in quantitative structure activity relationship (QSAR) of five molecular datasets shows that heteroencoder derived vectors markedly outperforms autoencoder derived vectors as well as models built using ECFP4 fingerprints, underlining the increased chemical relevance of the latent space. However, the use of enumeration during training of the decoder leads to a marked increase in the rate of decoding to different molecules than encoded, a tendency that can be counteracted with more complex network architectures. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","De novo molecule design; Deep learning; LSTM; Molecular autoencoders; Molecular data augmentation; Molecular heteroencoders; RNN","Algorithms; Models, Molecular; Neural Networks (Computer); Probability; Quantitative Structure-Activity Relationship; acoustic nerve fiber; algorithm; Article; artificial neural network; chemical database; decoder; finger dermatoglyphics; learning; machine learning; memory; nonhuman; pilot study; prediction; principal component analysis; probability; quantitative structure activity relation; short term memory; space and space related phenomena; training; algorithm; molecular model","MDPI AG","2218273X","","","30380783","Article","Scopus","2-s2.0-85055784756"
"Park H.S.; Lee S.M.; Kim H.P.; Seo J.K.; Chung Y.E.","Park, Hyoung Suk (55946430300); Lee, Sung Min (57192998770); Kim, Hwa Pyung (57195218952); Seo, Jin Keun (55917227100); Chung, Yong Eun (12773009200)","55946430300; 57192998770; 57195218952; 55917227100; 12773009200","CT sinogram-consistency learning for metal-induced beam hardening correction","2018","Medical Physics","80","10.1002/mp.13199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056186264&doi=10.1002%2fmp.13199&partnerID=40&md5=e0aa178abe508071f73ab7393619b3db","Division of Integrated Mathematics, National Institute for Mathematical Sciences, Daejeon, 34047, South Korea; Department of Computational Science and Engineering, Yonsei University, Seoul, 120-749, South Korea; Department of Radiology, Yonsei University College of Medicine, Seoul, 03722, South Korea","Park H.S., Division of Integrated Mathematics, National Institute for Mathematical Sciences, Daejeon, 34047, South Korea; Lee S.M., Department of Computational Science and Engineering, Yonsei University, Seoul, 120-749, South Korea; Kim H.P., Department of Computational Science and Engineering, Yonsei University, Seoul, 120-749, South Korea; Seo J.K., Department of Computational Science and Engineering, Yonsei University, Seoul, 120-749, South Korea; Chung Y.E., Department of Radiology, Yonsei University College of Medicine, Seoul, 03722, South Korea","Purpose: This paper proposes a sinogram-consistency learning method to deal with beam hardening-related artifacts in polychromatic computerized tomography (CT). The presence of highly attenuating materials in the scan field causes an inconsistent sinogram that does not match the range space of the Radon transform. When the mismatched data are entered into the range space during CT reconstruction, streaking and shading artifacts are generated owing to the inherent nature of the inverse Radon transform. Methods: The proposed learning method aims to repair inconsistent sinogram by removing the primary metal-induced beam hardening factors along the metal trace in the sinogram. Taking account of the fundamental difficulty in obtaining sufficient training data in a medical environment, the learning method is designed to use simulated training data and a patient’s implant type-specific learning model is used to simplify the learning process. Results: The feasibility of the proposed method is investigated using a dataset, consisting of real CT scans of pelvises containing simulated hip prostheses. The anatomical areas in training and test data are different, in order to demonstrate that the proposed method extracts the beam hardening features, selectively. The results show that our method successfully corrects sinogram inconsistency by extracting beam hardening sources by means of deep learning. Conclusion: This paper proposed a deep learning method of sinogram correction for beam hardening reduction in CT for the first time. Conventional methods for beam hardening reduction are based on regularizations, and have the fundamental drawback of being not easily able to use manifold CT images, while a deep learning approach has the potential to do so. © 2018 American Association of Physicists in Medicine","computerized tomography; deep learning; metal artifact reduction; tomographic image reconstruction","Artifacts; Humans; Image Processing, Computer-Assisted; Machine Learning; Metals; Pelvis; Tomography, X-Ray Computed; Deep learning; Hardening; Image reconstruction; Inverse problems; Mathematical transformations; Metals; Radon; Trace elements; metal; % reductions; Beam hardening; Deep learning; Learning methods; Metal artifact reduction; Range spaces; Sinogram consistency; Sinograms; Tomographic image reconstruction; Training data; Article; artifact; artifact reduction; computer assisted tomography; computer simulation; feature extraction; image reconstruction; learning algorithm; pelvis; space; artifact; diagnostic imaging; human; image processing; machine learning; procedures; x-ray computed tomography; Computerized tomography","John Wiley and Sons Ltd","00942405","","MPHYA","30238586","Article","Scopus","2-s2.0-85056186264"
"Fischer W.; Moudgalya S.S.; Cohn J.D.; Nguyen N.T.T.; Kenyon G.T.","Fischer, Will (15759657800); Moudgalya, Sanketh S. (57205176470); Cohn, Judith D. (12773828500); Nguyen, Nga T.T. (57209863315); Kenyon, Garrett T. (7102602432)","15759657800; 57205176470; 12773828500; 57209863315; 7102602432","Sparse coding of pathology slides compared to transfer learning with deep neural networks","2018","BMC Bioinformatics","11","10.1186/s12859-018-2504-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058922677&doi=10.1186%2fs12859-018-2504-8&partnerID=40&md5=ecb9bdaa6e0a231528e47ff17482c14c","Los Alamos National Laboratory, Los Alamos, NM, United States; Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, United States","Fischer W., Los Alamos National Laboratory, Los Alamos, NM, United States; Moudgalya S.S., Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, United States; Cohn J.D., Los Alamos National Laboratory, Los Alamos, NM, United States; Nguyen N.T.T., Los Alamos National Laboratory, Los Alamos, NM, United States; Kenyon G.T., Los Alamos National Laboratory, Los Alamos, NM, United States","Background: Histopathology images of tumor biopsies present unique challenges for applying machine learning to the diagnosis and treatment of cancer. The pathology slides are high resolution, often exceeding 1GB, have non-uniform dimensions, and often contain multiple tissue slices of varying sizes surrounded by large empty regions. The locations of abnormal or cancerous cells, which may constitute a small portion of any given tissue sample, are not annotated. Cancer image datasets are also extremely imbalanced, with most slides being associated with relatively common cancers. Since deep representations trained on natural photographs are unlikely to be optimal for classifying pathology slide images, which have different spectral ranges and spatial structure, we here describe an approach for learning features and inferring representations of cancer pathology slides based on sparse coding. Results: We show that conventional transfer learning using a state-of-the-art deep learning architecture pre-trained on ImageNet (RESNET) and fine tuned for a binary tumor/no-tumor classification task achieved between 85% and 86% accuracy. However, when all layers up to the last convolutional layer in RESNET are replaced with a single feature map inferred via a sparse coding using a dictionary optimized for sparse reconstruction of unlabeled pathology slides, classification performance improves to over 93%, corresponding to a 54% error reduction. Conclusions: We conclude that a feature dictionary optimized for biomedical imagery may in general support better classification performance than does conventional transfer learning using a dictionary pre-trained on natural images. © 2018 The Author(s).","Cancer pathology slides; Deep learning; Locally Competitive Algorithm; Sparse coding; TCGA; Transfer learning; Unsupervised learning","Deep Learning; Humans; Neoplasms; Neural Networks (Computer); Codes (symbols); Deep learning; Diagnosis; Diseases; Image coding; Network coding; Pathology; Tumors; Unsupervised learning; Cancer pathology slides; Competitive algorithms; Sparse coding; TCGA; Transfer learning; artificial neural network; human; neoplasm; pathology; trends; Deep neural networks","BioMed Central Ltd.","14712105","","BBMIC","30577746","Article","Scopus","2-s2.0-85058922677"
"Merk D.; Grisoni F.; Friedrich L.; Schneider G.","Merk, Daniel (53868203200); Grisoni, Francesca (56020972100); Friedrich, Lukas (57188921458); Schneider, Gisbert (7402466014)","53868203200; 56020972100; 57188921458; 7402466014","Tuning artificial intelligence on the de novo design of natural-product-inspired retinoid X receptor modulators","2018","Communications Chemistry","69","10.1038/s42004-018-0068-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061969204&doi=10.1038%2fs42004-018-0068-1&partnerID=40&md5=8c648f47fe5726742c7826aa26c34d33","Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland; Department of Earth and Environmental Sciences, University of Milano-Bicocca, P.za della Scienza, 1, Milan, IT-20126, Italy","Merk D., Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland; Grisoni F., Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland, Department of Earth and Environmental Sciences, University of Milano-Bicocca, P.za della Scienza, 1, Milan, IT-20126, Italy; Friedrich L., Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland; Schneider G., Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland","Instances of artificial intelligence equip medicinal chemistry with innovative tools for molecular design and lead discovery. Here we describe a deep recurrent neural network for de novo design of new chemical entities that are inspired by pharmacologically active natural products. Natural product characteristics are incorporated into a deep neural network that has been trained on synthetic low molecular weight compounds. This machine-learning model successfully generates readily synthesizable mimetics of the natural product templates. Synthesis and in vitro pharmacological characterization of four de novo designed mimetics of retinoid X receptor modulating natural products confirms isofunctional activity of two computer-generated molecules. These results positively advocate generative neural networks for natural-product-inspired drug discovery, reveal both opportunities and certain limitations of the current approach, and point to potential future developments. © 2018, The Author(s).","","","Springer Nature","23993669","","","","Article","Scopus","2-s2.0-85061969204"
"Arbabshirani M.R.; Fornwalt B.K.; Mongelluzzo G.J.; Suever J.D.; Geise B.D.; Patel A.A.; Moore G.J.","Arbabshirani, Mohammad R. (36135424000); Fornwalt, Brandon K. (15829119400); Mongelluzzo, Gino J. (57189689204); Suever, Jonathan D. (26022647000); Geise, Brandon D. (55481167500); Patel, Aalpen A. (57199234712); Moore, Gregory J. (7403282979)","36135424000; 15829119400; 57189689204; 26022647000; 55481167500; 57199234712; 7403282979","Advanced machine learning in action: identification of intracranial hemorrhage on computed tomography scans of the head with clinical workflow integration","2018","npj Digital Medicine","282","10.1038/s41746-017-0015-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135599973&doi=10.1038%2fs41746-017-0015-z&partnerID=40&md5=2c42311f5552798581453e3475f2574e","Geisinger, Department of Radiology, 100 N. Academy Avenue, Danville, 17822-2007, PA, United States; Geisinger, Department of Imaging Science and Innovation, 100 N. Academy Avenue, Danville, 17822-4400, PA, United States","Arbabshirani M.R., Geisinger, Department of Radiology, 100 N. Academy Avenue, Danville, 17822-2007, PA, United States; Fornwalt B.K., Geisinger, Department of Radiology, 100 N. Academy Avenue, Danville, 17822-2007, PA, United States, Geisinger, Department of Imaging Science and Innovation, 100 N. Academy Avenue, Danville, 17822-4400, PA, United States; Mongelluzzo G.J., Geisinger, Department of Radiology, 100 N. Academy Avenue, Danville, 17822-2007, PA, United States; Suever J.D., Geisinger, Department of Radiology, 100 N. Academy Avenue, Danville, 17822-2007, PA, United States, Geisinger, Department of Imaging Science and Innovation, 100 N. Academy Avenue, Danville, 17822-4400, PA, United States; Geise B.D., Geisinger, Department of Radiology, 100 N. Academy Avenue, Danville, 17822-2007, PA, United States; Patel A.A., Geisinger, Department of Radiology, 100 N. Academy Avenue, Danville, 17822-2007, PA, United States, Geisinger, Department of Imaging Science and Innovation, 100 N. Academy Avenue, Danville, 17822-4400, PA, United States; Moore G.J., Geisinger, Department of Radiology, 100 N. Academy Avenue, Danville, 17822-2007, PA, United States","Intracranial hemorrhage (ICH) requires prompt diagnosis to optimize patient outcomes. We hypothesized that machine learning algorithms could automatically analyze computed tomography (CT) of the head, prioritize radiology worklists and reduce time to diagnosis of ICH. 46,583 head CTs (~2 million images) acquired from 2007–2017 were collected from several facilities across Geisinger. A deep convolutional neural network was trained on 37,074 studies and subsequently evaluated on 9499 unseen studies. The predictive model was implemented prospectively for 3 months to re-prioritize “routine” head CT studies as “stat” on realtime radiology worklists if an ICH was detected. Time to diagnosis was compared between the re-prioritized “stat” and “routine” studies. A neuroradiologist blinded to the study reviewed false positive studies to determine whether the dictating radiologist overlooked ICH. The model achieved an area under the ROC curve of 0.846 (0.837–0.856). During implementation, 94 of 347 “routine” studies were re-prioritized to “stat”, and 60/94 had ICH identified by the radiologist. Five new cases of ICH were identified, and median time to diagnosis was significantly reduced (p < 0.0001) from 512 to 19 min. In particular, one outpatient with vague symptoms on anti-coagulation was found to have an ICH which was treated promptly with reversal of anticoagulation, resulting in a good clinical outcome. Of the 34 false positives, the blinded over-reader identified four probable ICH cases overlooked in original interpretation. In conclusion, an artificial intelligence algorithm can prioritize radiology worklists to reduce time to diagnosis of new outpatient ICH by 96% and may also identify subtle ICH overlooked by radiologists. This demonstrates the positive impact of advanced machine learning in radiology workflow optimization. © 2018, The Author(s).","","Computerized tomography; Deep neural networks; Learning algorithms; Radiation; Anti-coagulation; Clinical workflow; Computed tomography scan; Convolutional neural network; False positive; Intracranial hemorrhages; Machine learning algorithms; Machine-learning; Reduce time; Workflow integration; adult; Article; artificial neural network; brain hemorrhage; clinical outcome; computer assisted tomography; controlled study; deep convolutional neural network; false positive result; female; human; machine learning; major clinical study; male; middle aged; neuroradiologist; outpatient; priority journal; receiver operating characteristic; workflow; Radiology","Nature Publishing Group","23986352","","","","Article","Scopus","2-s2.0-85135599973"
"Halupka K.J.; Antony B.J.; Lee M.H.; Lucy K.A.; Rai R.S.; Ishikawa H.; Wollstein G.; Schuman J.S.; Garnavi R.","Halupka, Kerry J. (57189389433); Antony, Bhavna J. (24474399700); Lee, Matthew H. (57204920330); Lucy, Katie A. (57056025000); Rai, Ravneet S. (57204920787); Ishikawa, Hiroshi (55504416200); Wollstein, Gadi (6701388168); Schuman, Joel S. (7007053912); Garnavi, Rahil (15845331200)","57189389433; 24474399700; 57204920330; 57056025000; 57204920787; 55504416200; 6701388168; 7007053912; 15845331200","Retinal optical coherence tomography image enhancement via deep learning","2018","Biomedical Optics Express","79","10.1364/BOE.9.006205","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057793803&doi=10.1364%2fBOE.9.006205&partnerID=40&md5=d47b42cc5bb7a8382d24e4c5b6bc9327","IBM Research, Level 22/60 City Rd, Southbank, VIC, Australia; Department of Ophthalmology, NYU Langone Eye Center, New York University School of Medicine, New York, NY, United States","Halupka K.J., IBM Research, Level 22/60 City Rd, Southbank, VIC, Australia; Antony B.J., IBM Research, Level 22/60 City Rd, Southbank, VIC, Australia; Lee M.H., IBM Research, Level 22/60 City Rd, Southbank, VIC, Australia; Lucy K.A., Department of Ophthalmology, NYU Langone Eye Center, New York University School of Medicine, New York, NY, United States; Rai R.S., Department of Ophthalmology, NYU Langone Eye Center, New York University School of Medicine, New York, NY, United States; Ishikawa H., Department of Ophthalmology, NYU Langone Eye Center, New York University School of Medicine, New York, NY, United States; Wollstein G., Department of Ophthalmology, NYU Langone Eye Center, New York University School of Medicine, New York, NY, United States; Schuman J.S., Department of Ophthalmology, NYU Langone Eye Center, New York University School of Medicine, New York, NY, United States; Garnavi R., IBM Research, Level 22/60 City Rd, Southbank, VIC, Australia","Optical coherence tomography (OCT) images of the retina are a powerful tool for diagnosing and monitoring eye disease. However, they are plagued by speckle noise, which reduces image quality and reliability of assessment. This paper introduces a novel speckle reduction method inspired by the recent successes of deep learning in medical imaging. We present two versions of the network to reflect the needs and preferences of different end-users. Specifically, we train a convolution neural network to denoise cross-sections from OCT volumes of healthy eyes using either (1) mean-squared error, or (2) a generative adversarial network (GAN) with Wasserstein distance and perceptual similarity. We then interrogate the success of both methods with extensive quantitative and qualitative metrics on cross-sections from both healthy and glaucomatous eyes. The results show that the former approach provides state-of-the-art improvement in quantitative metrics such as PSNR and SSIM, and aids layer segmentation. However, the latter approach, which puts more weight on visual perception, outperformed for qualitative comparisons based on accuracy, clarity, and personal preference. Overall, our results demonstrate the effectiveness and efficiency of a deep learning approach to denoising OCT images, while maintaining subtle details in the images. © 2018 Optical Society of America.","","Deep learning; Diagnosis; Image denoising; Mean square error; Medical imaging; Optical tomography; Speckle; Adversarial networks; Convolution neural network; Effectiveness and efficiencies; Perceptual similarity; Personal preferences; Quantitative metrics; Retinal optical coherence tomography; Wasserstein distance; Article; clinical article; controlled study; deep learning; diagnostic accuracy; eye disease; generative adversarial network; glaucoma; human; human tissue; image enhancement; image processing; image quality; machine learning; mathematical parameters; mean square error; optical coherence tomography; retina; signal noise ratio; Image enhancement","OSA - The Optical Society","21567085","","","","Article","Scopus","2-s2.0-85057793803"
"Gu Y.; Lu X.; Yang L.; Zhang B.; Yu D.; Zhao Y.; Gao L.; Wu L.; Zhou T.","Gu, Yu (57199810470); Lu, Xiaoqi (14039286600); Yang, Lidong (25648734900); Zhang, Baohua (55721022500); Yu, Dahua (53864510100); Zhao, Ying (56374524900); Gao, Lixin (57204481407); Wu, Liang (57203604225); Zhou, Tao (57204478992)","57199810470; 14039286600; 25648734900; 55721022500; 53864510100; 56374524900; 57204481407; 57203604225; 57204478992","Automatic lung nodule detection using a 3D deep convolutional neural network combined with a multi-scale prediction strategy in chest CTs","2018","Computers in Biology and Medicine","156","10.1016/j.compbiomed.2018.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055751023&doi=10.1016%2fj.compbiomed.2018.10.011&partnerID=40&md5=32a91a4830697e728c0e2e520766feb0","School of Computer Engineering and Science, Shanghai University, Shanghai, 200444, China; Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China; School of Foreign Languages, Inner Mongolia University of Science and Technology, Baotou, 014010, China","Gu Y., School of Computer Engineering and Science, Shanghai University, Shanghai, 200444, China, Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China; Lu X., School of Computer Engineering and Science, Shanghai University, Shanghai, 200444, China, Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China; Yang L., Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China; Zhang B., Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China; Yu D., Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China; Zhao Y., Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China; Gao L., Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China, School of Foreign Languages, Inner Mongolia University of Science and Technology, Baotou, 014010, China; Wu L., Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China; Zhou T., Inner Mongolia Key Laboratory of Pattern Recognition and Intelligent Image Processing, School of Information Engineering, Inner Mongolia University of Science and Technology, Baotou, 014010, China","Objective: A novel computer-aided detection (CAD) scheme for lung nodule detection using a 3D deep convolutional neural network combined with a multi-scale prediction strategy is proposed to assist radiologists by providing a second opinion on accurate lung nodule detection, which is a crucial step in early diagnosis of lung cancer. Method: A 3D deep convolutional neural network (CNN) with multi-scale prediction was used to detect lung nodules after the lungs were segmented from chest CT scans, with a comprehensive method utilized. Compared with a 2D CNN, a 3D CNN can utilize richer spatial 3D contextual information and generate more discriminative features after being trained with 3D samples to fully represent lung nodules. Furthermore, a multi-scale lung nodule prediction strategy, including multi-scale cube prediction and cube clustering, is also proposed to detect extremely small nodules. Result: The proposed method was evaluated on 888 thin-slice scans with 1186 nodules in the LUNA16 database. All results were obtained via 10-fold cross-validation. Three options of the proposed scheme are provided for selection according to the actual needs. The sensitivity of the proposed scheme with the primary option reached 87.94% and 92.93% at one and four false positives per scan, respectively. Meanwhile, the competition performance metric (CPM) score is very satisfying (0.7967). Conclusion: The experimental results demonstrate the outstanding detection performance of the proposed nodule detection scheme. In addition, the proposed scheme can be extended to other medical image recognition fields. © 2018","3D convolutional neural network; Cube clustering; Deep learning; Lung nodule detection; Multi-scale cube prediction","Cluster Analysis; Humans; Imaging, Three-Dimensional; Lung; Lung Neoplasms; Neural Networks (Computer); Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Solitary Pulmonary Nodule; Tomography, X-Ray Computed; Biological organs; Computer aided diagnosis; Computerized tomography; Convolution; Deep learning; Forecasting; Geometry; Image recognition; Medical imaging; Neural networks; 10-fold cross-validation; Computer-aided detection; Convolutional neural network; Cube clustering; Deep convolutional neural networks; Discriminative features; Lung nodule detection; Multi-scale; Article; deep convolutional neural network; early cancer diagnosis; false positive result; human; image analysis; image segmentation; lung cancer; lung nodule; lung parenchyma; lung volume; machine learning; major clinical study; priority journal; support vector machine; trachea; tracheobronchial tree; x-ray computed tomography; artificial neural network; cluster analysis; computer assisted diagnosis; diagnostic imaging; lung; lung nodule; lung tumor; procedures; thorax radiography; three dimensional imaging; x-ray computed tomography; Deep neural networks","Elsevier Ltd","00104825","","CBMDA","30390571","Article","Scopus","2-s2.0-85055751023"
"Zeng N.; Qiu H.; Wang Z.; Liu W.; Zhang H.; Li Y.","Zeng, Nianyin (36703553900); Qiu, Hong (57204002577); Wang, Zidong (55810114200); Liu, Weibo (57001851000); Zhang, Hong (57163176600); Li, Yurong (7502076797)","36703553900; 57204002577; 55810114200; 57001851000; 57163176600; 7502076797","A new switching-delayed-PSO-based optimized SVM algorithm for diagnosis of Alzheimer's disease","2018","Neurocomputing","234","10.1016/j.neucom.2018.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054038562&doi=10.1016%2fj.neucom.2018.09.001&partnerID=40&md5=ca4234b83b5e046903dc05ef39e0caed","Department of Instrumental and Electrical Engineering, Xiamen University, Fujian, 361005, China; College of Electrical Engineering and Automation, Shandong University of Science and Technology, Qingdao, 266590, China; Department of Computer Science, Brunel University London, Middlesex, UB8 3PH, Uxbridge, United Kingdom; College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, 350002, China; Fujian Key Laboratory of Medical Instrumentation and Pharmaceutical Technology, Fuzhou, 350002, China","Zeng N., Department of Instrumental and Electrical Engineering, Xiamen University, Fujian, 361005, China; Qiu H., Department of Instrumental and Electrical Engineering, Xiamen University, Fujian, 361005, China; Wang Z., College of Electrical Engineering and Automation, Shandong University of Science and Technology, Qingdao, 266590, China, Department of Computer Science, Brunel University London, Middlesex, UB8 3PH, Uxbridge, United Kingdom; Liu W., Department of Computer Science, Brunel University London, Middlesex, UB8 3PH, Uxbridge, United Kingdom; Zhang H., Department of Instrumental and Electrical Engineering, Xiamen University, Fujian, 361005, China; Li Y., College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, 350002, China, Fujian Key Laboratory of Medical Instrumentation and Pharmaceutical Technology, Fuzhou, 350002, China","In healthcare sector, it is of crucial importance to accurately diagnose Alzheimer's disease (AD) and its prophase called mild cognitive impairment (MCI) so as to prevent degeneration and provide early treatment for AD patients. In this paper, a framework is proposed for the diagnosis of AD, which consists of MRI images preprocessing, feature extraction, principal component analysis, and the support vector machine (SVM) model. In particular, a new switching delayed particle swarm optimization (SDPSO) algorithm is proposed to optimize the SVM parameters. The developed framework based on the SDPSO-SVM model is successfully applied to the classification of AD and MCI using MRI scans from ADNI dataset. Our developed algorithm can achieve excellent classification accuracies for 6 typical cases. Furthermore, experiment results demonstrate that the proposed algorithm outperforms several SVM models and also two other state-of-art methods with deep learning embedded, thereby serving as an effective AD diagnosis method. © 2018 Elsevier B.V.","Alzheimer's disease; Classification; Principal component analysis; Support vector machine; Switching delayed particle swarm optimization","Classification (of information); Deep learning; Diagnosis; Magnetic resonance imaging; Neurodegenerative diseases; Particle swarm optimization (PSO); Patient treatment; Support vector machines; Alzheimer's disease; Classification accuracy; Diagnosis methods; Healthcare sectors; Mild cognitive impairments (MCI); MRI Image; State-of-art methods; SVM algorithm; algorithm; Alzheimer disease; Article; classification algorithm; image processing; learning algorithm; mild cognitive impairment; neuroimaging; nuclear magnetic resonance imaging; priority journal; process optimization; support vector machine; switching delayed particle swarm optimization algorithm; Principal component analysis","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85054038562"
"Ståhl N.; Falkman G.; Karlsson A.; Mathiason G.; Boström J.","Ståhl, Niclas (57202368687); Falkman, Göran (6603459313); Karlsson, Alexander (25655035500); Mathiason, Gunnar (24450494500); Boström, Jonas (56250748100)","57202368687; 6603459313; 25655035500; 24450494500; 56250748100","Deep Convolutional Neural Networks for the Prediction of Molecular Properties: Challenges and Opportunities Connected to the Data","2018","Journal of integrative bioinformatics","8","10.1515/jib-2018-0065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061622864&doi=10.1515%2fjib-2018-0065&partnerID=40&md5=f34f6338ae3e027368bb06cc6cae0fe8","School of Informatics, University of Skövde, SE 54145, Sweden; School of Informatics, University of Skövde, Sweden; Department of Medicinal Chemistry, CVMD iMED, AstraZeneca, Mölndal, Sweden","Ståhl N., School of Informatics, University of Skövde, SE 54145, Sweden; Falkman G., School of Informatics, University of Skövde, Sweden; Karlsson A., School of Informatics, University of Skövde, Sweden; Mathiason G., School of Informatics, University of Skövde, Sweden; Boström J., Department of Medicinal Chemistry, CVMD iMED, AstraZeneca, Mölndal, Sweden","We present a flexible deep convolutional neural network method for the analysis of arbitrary sized graph structures representing molecules. This method, which makes use of the Lipinski RDKit module, an open-source cheminformatics software, enables the incorporation of any global molecular (such as molecular charge and molecular weight) and local (such as atom hybridization and bond orders) information. In this paper, we show that this method significantly outperforms another recently proposed method based on deep convolutional neural networks on several datasets that are studied. Several best practices for training deep convolutional neural networks on chemical datasets are also highlighted within the article, such as how to select the information to be included in the model, how to prevent overfitting and how unbalanced classes in the data can be handled.","Deep learning; Molecular property prediction; Side effects prediction; Unbalanced data","Databases, Pharmaceutical; Drug Design; Humans; Machine Learning; Neural Networks (Computer); Pharmaceutical Preparations; Software; drug; artificial neural network; chemistry; classification; drug database; drug design; human; machine learning; software","NLM (Medline)","16134516","","","30517077","Article","Scopus","2-s2.0-85061622864"
"Kearney V.; Chan J.W.; Valdes G.; Solberg T.D.; Yom S.S.","Kearney, Vasant (56449200500); Chan, Jason W. (57189630606); Valdes, Gilmer (55875962300); Solberg, Timothy D. (57204614205); Yom, Sue S. (7004388914)","56449200500; 57189630606; 55875962300; 57204614205; 7004388914","The application of artificial intelligence in the IMRT planning process for head and neck cancer","2018","Oral Oncology","51","10.1016/j.oraloncology.2018.10.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055623109&doi=10.1016%2fj.oraloncology.2018.10.026&partnerID=40&md5=9b7e63732cac14d60237ab9fee0f83af","Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States","Kearney V., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States; Chan J.W., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States; Valdes G., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States; Solberg T.D., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States; Yom S.S., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States","Artificial intelligence (AI) is beginning to transform IMRT treatment planning for head and neck patients. However, the complexity and novelty of AI algorithms make them susceptible to misuse by researchers and clinicians. Understanding nuances of new technologies could serve to mitigate potential clinical implementation pitfalls. This article is intended to facilitate integration of AI into the radiotherapy clinic by providing an overview of AI algorithms, including support vector machines (SVMs), random forests (RF), gradient boosting (GB), and several variations of deep learning. This document describes current AI algorithms that have been applied to head and neck IMRT planning and identifies rapidly growing branches of AI in industry that have potential applications to head and neck cancer patients receiving IMRT. AI algorithms have great clinical potential if used correctly but can also cause harm if misused, so it is important to raise the level of AI competence within radiation oncology so that the benefits can be realized in a controlled and safe manner. © 2018 The Authors","Artificial intelligence; Automated treatment planning; Convolutional neural networks; Deep learning; Head and neck; Intensity modulated radiation therapy; Machine learning; Predictive medicine; Radiation oncology; Treatment planning","Clinical Competence; Clinical Decision-Making; Head and Neck Neoplasms; Humans; Machine Learning; Radiation Injuries; Radiation Oncologists; Radiotherapy Planning, Computer-Assisted; Radiotherapy, Intensity-Modulated; Article; artificial intelligence; cancer control; cancer patient; cancer radiotherapy; deep learning; gradient boosting; head and neck cancer; human; intensity modulated radiation therapy; learning algorithm; organs at risk; priority journal; quality control; radiation oncology; random forest; support vector machine; treatment planning; adverse device effect; adverse event; clinical competence; clinical decision making; head and neck tumor; intensity modulated radiation therapy; machine learning; procedures; radiation injury; radiation oncologist; radiotherapy planning system","Elsevier Ltd","13688375","","EJCCE","30527225","Article","Scopus","2-s2.0-85055623109"
"Li F.; Liu M.","Li, Fan (57208660432); Liu, Manhua (8611675100)","57208660432; 8611675100","Alzheimer's disease diagnosis based on multiple cluster dense convolutional networks","2018","Computerized Medical Imaging and Graphics","121","10.1016/j.compmedimag.2018.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054817381&doi=10.1016%2fj.compmedimag.2018.09.009&partnerID=40&md5=70366e1bf5da75de8df15710632350ab","Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China; Shanghai Engineering Research Center for Intelligent Diagnosis and Treatment Instrument, Shanghai Jiao Tong University, Shanghai, 200240, China","Li F., Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China; Liu M., Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China, Shanghai Engineering Research Center for Intelligent Diagnosis and Treatment Instrument, Shanghai Jiao Tong University, Shanghai, 200240, China","Alzheimer's disease (AD) is an irreversible neurodegenerative disorder with progressive impairment of memory and cognitive functions. Structural magnetic resonance images (MRI) play important role to evaluate the brain anatomical changes for AD Diagnosis. Machine learning technologies have been widely studied on MRI computation and analysis for quantitative evaluation and computer-aided-diagnosis of AD. Most existing methods extract the hand-craft features after image processing such as registration and segmentation, and then train a classifier to distinguish AD subjects from other groups. Motivated by the success of deep learning in image classification, this paper proposes a classification method based on multiple cluster dense convolutional neural networks (DenseNets) to learn the various local features of MR brain images, which are combined for AD classification. First, we partition the whole brain image into different local regions and extract a number of 3D patches from each region. Second, the patches from each region are grouped into different clusters with the K-Means clustering method. Third, we construct a DenseNet to learn the patch features for each cluster and the features learned from the discriminative clusters of each region are ensembled for classification. Finally, the classification results from different local regions are combined to enhance final image classification. The proposed method can gradually learn the MRI features from the local patches to global image level for the classification task. There are no rigid registration and segmentation required for preprocessing MRI images. Our method is evaluated using T1-weighted MRIs of 831 subjects including 199 AD patients, 403 mild cognitive impairment (MCI) and 229 normal control (NC) subjects from Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Experimental results show that the proposed method achieves an accuracy of 89.5% and an AUC (area under the ROC curve) of 92.4% for AD vs. NC classification, and an accuracy of 73.8% and an AUC of 77.5% for MCI vs. NC classification, demonstrating the promising classification performances. © 2018 Elsevier Ltd","Alzheimer's disease; Dense convolutional network; K-Means clustering; Patch features; Structural magnetic resonance image","Algorithms; Alzheimer Disease; Diagnosis, Computer-Assisted; Humans; Neural Networks (Computer); Aluminum compounds; Brain mapping; Cluster analysis; Clustering algorithms; Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Convolution; Deep learning; Disease control; Image enhancement; Image registration; Image segmentation; Magnetic resonance imaging; Neural networks; Neurodegenerative diseases; Alzheimer's disease; Convolutional networks; Convolutional neural network; K - means clustering; Magnetic resonance images (MRI); Mild cognitive impairments (MCI); Neurodegenerative disorders; Patch features; aged; Alzheimer disease; Article; classification algorithm; comparative study; computer assisted diagnosis; controlled study; dense convolutional network; diagnostic accuracy; diagnostic imaging; diagnostic test accuracy study; feature extraction; female; human; image analysis; image processing; image segmentation; machine learning; major clinical study; male; mild cognitive impairment; Mini Mental State Examination; neuroimaging; nuclear magnetic resonance imaging; priority journal; receiver operating characteristic; sensitivity and specificity; three dimensional imaging; algorithm; Alzheimer disease; artificial neural network; computer assisted diagnosis; diagnostic imaging; pathology; procedures; Image classification","Elsevier Ltd","08956111","","CMIGE","30340094","Article","Scopus","2-s2.0-85054817381"
"Wang Y.-B.; You Z.-H.; Li X.; Jiang T.-H.; Cheng L.; Chen Z.-H.","Wang, Yan-Bin (57194205411); You, Zhu-Hong (23062542900); Li, Xiao (56014830500); Jiang, Tong-Hai (35762809900); Cheng, Li (57197460610); Chen, Zhan-Heng (57200208992)","57194205411; 23062542900; 56014830500; 35762809900; 57197460610; 57200208992","Prediction of protein self-interactions using stacked long short-term memory from protein sequences information","2018","BMC Systems Biology","17","10.1186/s12918-018-0647-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058915731&doi=10.1186%2fs12918-018-0647-x&partnerID=40&md5=77cd47e12af1867ee2a05e2e53bdb27b","Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China; University of Chinese Academy of Sciences, Beijing, 100049, China","Wang Y.-B., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China, University of Chinese Academy of Sciences, Beijing, 100049, China; You Z.-H., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China; Li X., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China; Jiang T.-H., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China; Cheng L., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China; Chen Z.-H., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China, University of Chinese Academy of Sciences, Beijing, 100049, China","Background: Self-interacting Proteins (SIPs) plays a critical role in a series of life function in most living cells. Researches on SIPs are important part of molecular biology. Although numerous SIPs data be provided, traditional experimental methods are labor-intensive, time-consuming and costly and can only yield limited results in real-world needs. Hence,it's urgent to develop an efficient computational SIPs prediction method to fill the gap. Deep learning technologies have proven to produce subversive performance improvements in many areas, but the effectiveness of deep learning methods for SIPs prediction has not been verified. Results: We developed a deep learning model for predicting SIPs by constructing a Stacked Long Short-Term Memory (SLSTM) neural network that contains ""dropout"". We extracted features from protein sequences using a novel feature extraction scheme that combined Zernike Moments (ZMs) with Position Specific Weight Matrix (PSWM). The capability of the proposed approach was assessed on S.erevisiae and Human SIPs datasets. The result indicates that the approach based on deep learning can effectively resist data skew and achieve good accuracies of 95.69 and 97.88%, respectively. To demonstrate the progressiveness of deep learning, we compared the results of the SLSTM-based method and the celebrated Support Vector Machine (SVM) method and several other well-known methods on the same datasets. Conclusion: The results show that our method is overall superior to any of the other existing state-of-the-art techniques. As far as we know, this study first applies deep learning method to predict SIPs, and practical experimental results reveal its potential in SIPs identification. © 2018 The Author(s).","Deep learning; Dropout; Self-interacting proteins; Stacked long short-term memory","Computational Biology; Humans; Neural Networks (Computer); Protein Interaction Mapping; Saccharomyces cerevisiae; artificial neural network; biology; human; metabolism; procedures; protein analysis; Saccharomyces cerevisiae","BioMed Central Ltd.","17520509","","","30577794","Article","Scopus","2-s2.0-85058915731"
"Wang S.; Zhang R.; Deng Y.; Chen K.; Xiao D.; Peng P.; Jiang T.","Wang, Shuangkun (55431462200); Zhang, Rongguo (57744301400); Deng, Yufeng (58449708400); Chen, Kuan (57194444397); Xiao, Dan (57202903982); Peng, Peng (57202214327); Jiang, Tao (56680525600)","55431462200; 57744301400; 58449708400; 57194444397; 57202903982; 57202214327; 56680525600","Discrimination of smoking status by MRI based on deep learning method","2018","Quantitative Imaging in Medicine and Surgery","11","10.21037/qims.2018.12.04","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068555189&doi=10.21037%2fqims.2018.12.04&partnerID=40&md5=b25303ddc64620eedf317748d4b114f9","Department of Radiology, Beijing Chaoyang Hospital, Capital Medical University, Beijing, 10020, China; Infervision, Beijing, 10021, China; Tobacco Medicine and Tobacco Cessation Center, China-Japan Friendship Hospital, Beijing, 100029, China; WHO Collaborating Center for Tobacco Cessation and Respiratory Diseases Prevention, China-Japan Friendship Hospital, Beijing, 100029, China","Wang S., Department of Radiology, Beijing Chaoyang Hospital, Capital Medical University, Beijing, 10020, China; Zhang R., Infervision, Beijing, 10021, China; Deng Y., Infervision, Beijing, 10021, China; Chen K., Infervision, Beijing, 10021, China; Xiao D., Tobacco Medicine and Tobacco Cessation Center, China-Japan Friendship Hospital, Beijing, 100029, China, WHO Collaborating Center for Tobacco Cessation and Respiratory Diseases Prevention, China-Japan Friendship Hospital, Beijing, 100029, China; Peng P., Department of Radiology, Beijing Chaoyang Hospital, Capital Medical University, Beijing, 10020, China; Jiang T., Department of Radiology, Beijing Chaoyang Hospital, Capital Medical University, Beijing, 10020, China","Background: This study aimed to assess the feasibility of deep learning-based magnetic resonance imaging (MRI) in the prediction of smoking status. Methods: The head MRI 3D-T1WI images of 127 subjects (61 smokers and 66 non-smokers) were collected, and 176 image slices obtained for each subject. These subjects were 23-45 years old, and the smokers had at least 5 years of smoking experience. Approximate 25% of the subjects were randomly selected as the test set (15 smokers and 16 non-smokers), and the remaining subjects as the training set. Two deep learning models were developed: deep 3D convolutional neural network (Conv3D) and convolution neural network plus a recurrent neural network (RNN) with long short-term memory architecture (ConvLSTM). Results: In the prediction of smoking status, Conv3D model achieved an accuracy of 80.6% (25/31), a sensitivity of 80.0% and a specificity of 81.3%, and ConvLSTM model achieved an accuracy of 93.5% (29/31), a sensitivity of 93.33% and a specificity of 93.75%. The accuracy obtained by these methods was significantly higher than that (<70%) obtained with support vector machine (SVM) methods. Conclusions: The deep learning-based MRI can accurately predict smoking status. Studies with large sample size are needed to improve the accuracy and to predict the level of nicotine dependence. © Quantitative Imaging in Medicine and Surgery. All rights reserved.","Deep learning; Magnetic resonance imaging (MRI); Smoking status; Support vector machine (SVM)","","AME Publishing Company","22234292","","","","Article","Scopus","2-s2.0-85068555189"
"Dimitriou N.; Arandjelović O.; Harrison D.J.; Caie P.D.","Dimitriou, Neofytos (57212446568); Arandjelović, Ognjen (8557887000); Harrison, David J. (7403545350); Caie, Peter D. (36112828700)","57212446568; 8557887000; 7403545350; 36112828700","A principled machine learning framework improves accuracy of stage II colorectal cancer prognosis","2018","npj Digital Medicine","41","10.1038/s41746-018-0057-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108534486&doi=10.1038%2fs41746-018-0057-x&partnerID=40&md5=4e1154444be3a1f815b4e207ccd74d68","School of Computer Science, University of St Andrews, St Andrews, KY16 9SX, United Kingdom; School of Medicine, University of St Andrews, St Andrews, KY16 9TF, United Kingdom","Dimitriou N., School of Computer Science, University of St Andrews, St Andrews, KY16 9SX, United Kingdom; Arandjelović O., School of Computer Science, University of St Andrews, St Andrews, KY16 9SX, United Kingdom; Harrison D.J., School of Medicine, University of St Andrews, St Andrews, KY16 9TF, United Kingdom; Caie P.D., School of Medicine, University of St Andrews, St Andrews, KY16 9TF, United Kingdom","Accurate prognosis is fundamental in planning an appropriate therapy for cancer patients. Consequent to the heterogeneity of the disease, intra- and inter-pathologist variability, and the inherent limitations of current pathological reporting systems, patient outcome varies considerably within similarly staged patient cohorts. This is particularly true when classifying stage II colorectal cancer patients using the current TNM guidelines. The aim of the present work is to address this problem through the use of machine learning. In particular, we introduce a data driven framework which makes use of a large number of diverse types of features, readily collected from immunofluorescence imagery. Its outstanding performance in predicting mortality in stage II patients (AUROC = 0:94), exceeds that of current clinical guidelines such as pT stage (AUROC = 0:65), and is demonstrated on a cohort of 173 colorectal cancer patients. © 2018, The Author(s).","","Diagnosis; Disease control; Diseases; Patient treatment; 'current; Cancer patients; Cancer prognosis; Clinical guideline; Data driven; Inherent limitations; Learning frameworks; Machine-learning; Performance; Reporting systems; adult; aged; Article; cancer mortality; cancer patient; cancer prognosis; cancer surgery; cancer survival; classifier; cohort analysis; colorectal cancer; colorectal surgery; deep learning; feature extraction; female; high risk patient; human; human tissue; k nearest neighbor; low risk patient; major clinical study; male; practice guideline; priority journal; random forest; support vector machine; tumor differentiation; Machine learning","Nature Publishing Group","23986352","","","","Article","Scopus","2-s2.0-85108534486"
"Zhang L.; Yu G.; Guo M.; Wang J.","Zhang, Long (57201265835); Yu, Guoxian (35175184400); Guo, Maozu (7201564856); Wang, Jun (57191488821)","57201265835; 35175184400; 7201564856; 57191488821","Predicting protein-protein interactions using high-quality non-interacting pairs","2018","BMC Bioinformatics","21","10.1186/s12859-018-2525-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059256606&doi=10.1186%2fs12859-018-2525-3&partnerID=40&md5=710e5000179a7bf1352dcbf387d029b1","College of Computer and Information Sciences, Southwest University, Chongqing, China; School of Electrical and Information Engineering, Beijing University of Civil Engineering and Architecture, Beijing, China; Beijing Key Laboratory of Intelligent Processing for Building Big Data, Beijing, China","Zhang L., College of Computer and Information Sciences, Southwest University, Chongqing, China; Yu G., College of Computer and Information Sciences, Southwest University, Chongqing, China; Guo M., School of Electrical and Information Engineering, Beijing University of Civil Engineering and Architecture, Beijing, China, Beijing Key Laboratory of Intelligent Processing for Building Big Data, Beijing, China; Wang J., College of Computer and Information Sciences, Southwest University, Chongqing, China","Background: Identifying protein-protein interactions (PPIs) is of paramount importance for understanding cellular processes. Machine learning-based approaches have been developed to predict PPIs, but the effectiveness of these approaches is unsatisfactory. One major reason is that they randomly choose non-interacting protein pairs (negative samples) or heuristically select non-interacting pairs with low quality. Results: To boost the effectiveness of predicting PPIs, we propose two novel approaches (NIP-SS and NIP-RW) to generate high quality non-interacting pairs based on sequence similarity and random walk, respectively. Specifically, the known PPIs collected from public databases are used to generate the positive samples. NIP-SS then selects the top-m dissimilar protein pairs as negative examples and controls the degree distribution of selected proteins to construct the negative dataset. NIP-RW performs random walk on the PPI network to update the adjacency matrix of the network, and then selects protein pairs not connected in the updated network as negative samples. Next, we use auto covariance (AC) descriptor to encode the feature information of amino acid sequences. After that, we employ deep neural networks (DNNs) to predict PPIs based on extracted features, positive and negative examples. Extensive experiments show that NIP-SS and NIP-RW can generate negative samples with higher quality than existing strategies and thus enable more accurate prediction. Conclusions: The experimental results prove that negative datasets constructed by NIP-SS and NIP-RW can reduce the bias and have good generalization ability. NIP-SS and NIP-RW can be used as a plugin to boost the effectiveness of PPIs prediction. Codes and datasets are available at http://mlda.swu.edu.cn/codes.php?name=NIP. © 2018 The Author(s).","Deep neural networks; Non-interacting proteins; Protein-protein interactions; Random walk; Sequence similarity","Animals; Computational Biology; Humans; Mice; Neural Networks (Computer); Protein Interaction Mapping; Proteins; Saccharomyces cerevisiae; Sequence Analysis, Protein; Deep neural networks; Forecasting; Random processes; protein; Accurate prediction; Amino acid sequence; Degree distributions; Feature information; Generalization ability; Protein-protein interactions; Random Walk; Sequence similarity; amino acid sequence; article; covariance; prediction; protein protein interaction; animal; artificial neural network; biology; chemistry; human; metabolism; mouse; procedures; protein analysis; Saccharomyces cerevisiae; sequence analysis; Proteins","BioMed Central Ltd.","14712105","","BBMIC","30598096","Article","Scopus","2-s2.0-85059256606"
"Mandala S.K.; Gurrapu N.; Pulyala M.R.","Mandala, Suresh Kumar (56985808300); Gurrapu, Neelima (57207832587); Pulyala, Mahipal Reddy (57200247726)","56985808300; 57207832587; 57200247726","A study on the development of machine learning in health analysis","2018","Indian Journal of Public Health Research and Development","0","10.5958/0976-5506.2018.02094.6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062959685&doi=10.5958%2f0976-5506.2018.02094.6&partnerID=40&md5=aaf149e7e2c6a2434252c6c2e02b3e49","Vaagdevi College of Engineering, Warangal, India","Mandala S.K., Vaagdevi College of Engineering, Warangal, India; Gurrapu N., Vaagdevi College of Engineering, Warangal, India; Pulyala M.R., Vaagdevi College of Engineering, Warangal, India","Machine Learning (ML) provides methods, techniques, and tools that can help solving diagnostic and prognostic problems in a variety of medical domains. ML is being used for the analysis of the importance of clinical parameters and their combinations for prognosis, e.g. prediction of disease progression, extraction of medical knowledge for outcome research, therapy planning and support, and for the overall patient management. The Machine Learning field evolved by the extensive area of artificial-intelligence, which intends to mimic bright abilities of humans with machines. Machine Learning (ML) has evolved by the endeavour of computer enthusiasts harnessing the chance of computers learning how to play with matches, and also part of Math (Data) that infrequently believed computational processes, to a different research field which hasn’t merely given the essential base for statistical-computational fundamentals of learning procedures, but additionally has generated various calculations which are regularly employed for text translation, pattern recognition, and many other industrial purposes and it has caused a individual research interest in data mining to determine hidden regularities or irregularities from societal statistics that growing by instant. This paper concentrates on explaining the Style and development of Machine Learning, a number of the most popular Machine Learning calculations and Attempt to compare the Well-known algorithms based on a few fundamental concepts. © 2018, Indian Journal of Public Health Research and Development. All rights reserved.","Disease progression; Extraction; Machine learning; Medical diagnostic","Article; artificial intelligence; artificial neural network; automatic speech recognition; data mining; deep learning; facial recognition; learning algorithm; learning style; machine learning; neuroscience; reinforcement; signal processing; software; supervised machine learning; support vector machine","Institute of Medico-Legal Publications","09760245","","","","Article","Scopus","2-s2.0-85062959685"
"England J.R.; Gross J.S.; White E.A.; Patel D.B.; England J.T.; Cheng P.M.","England, Joseph R. (57202116779); Gross, Jordan S. (56157739700); White, Eric A. (13605358200); Patel, Dakshesh B. (7402238220); England, Jasmin T. (56442121100); Cheng, Phillip M. (8693313300)","57202116779; 56157739700; 13605358200; 7402238220; 56442121100; 8693313300","Detection of traumatic pediatric elbow joint effusion using a deep convolutional neural network","2018","American Journal of Roentgenology","33","10.2214/AJR.18.19974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056977536&doi=10.2214%2fAJR.18.19974&partnerID=40&md5=fe7d766892fdc715e3e40124d421074d","Department of Radiology, Keck School of Medicine of USC, 1441 Eastlake Ave, Ste 2315B, Los Angeles, 90033, CA, United States; Department of Emergency Medicine, Harbor-UCLA Medical Center, Torrance, CA, United States","England J.R., Department of Radiology, Keck School of Medicine of USC, 1441 Eastlake Ave, Ste 2315B, Los Angeles, 90033, CA, United States; Gross J.S., Department of Radiology, Keck School of Medicine of USC, 1441 Eastlake Ave, Ste 2315B, Los Angeles, 90033, CA, United States; White E.A., Department of Radiology, Keck School of Medicine of USC, 1441 Eastlake Ave, Ste 2315B, Los Angeles, 90033, CA, United States; Patel D.B., Department of Radiology, Keck School of Medicine of USC, 1441 Eastlake Ave, Ste 2315B, Los Angeles, 90033, CA, United States; England J.T., Department of Emergency Medicine, Harbor-UCLA Medical Center, Torrance, CA, United States; Cheng P.M., Department of Radiology, Keck School of Medicine of USC, 1441 Eastlake Ave, Ste 2315B, Los Angeles, 90033, CA, United States","OBJECTIVE. The purpose of this study is to determine whether a deep convolutional neural network (DCNN) trained on a dataset of limited size can accurately diagnose traumatic pediatric elbow effusion on lateral radiographs. MATERIALS AND METHODS. A total of 901 lateral elbow radiographs from 882 pediatric patients who presented to the emergency department with upper extremity trauma were divided into a training set (657 images), a validation set (115 images), and an independent test set (129 images). The training set was used to train DCNNs of varying depth, architecture, and parameter initialization, some trained from randomly initialized parameter weights and others trained using parameter weights derived from pretraining on an ImageNet dataset. Hyperparameters were optimized using the validation set, and the DCNN with the highest ROC AUC on the validation set was selected for further performance testing on the test set. RESULTS. The final trained DCNN model had an ROC AUC of 0.985 (95% CI, 0.966–1.000) on the validation set and 0.943 (95% CI, 0.884–1.000) on the test set. On the test set, sensitivity was 0.909 (95% CI, 0.788–1.000), specificity was 0.906 (95% CI, 0.844–0.958), and accuracy was 0.907 (95% CI, 0.843–0.951). CONCLUSION. Accurate diagnosis of traumatic pediatric elbow joint effusion can be achieved using a DCNN. © American Roentgen Ray Society.","Artificial intelligence; Deep convolutional neural network; Deep learning; Elbow effusion; Machine learning","Adolescent; Child; Child, Preschool; Diagnosis, Computer-Assisted; Elbow Joint; Female; Humans; Infant; Male; Neural Networks (Computer); Observer Variation; Radiography; Retrospective Studies; Sensitivity and Specificity; Young Adult; adolescent; adult; Article; artificial neural network; child; data analysis; diagnostic accuracy; elbow; emergency ward; female; human; joint effusion; joint radiography; limb injury; major clinical study; male; preschool child; priority journal; sensitivity and specificity; upper limb; validation process; computer assisted diagnosis; diagnostic imaging; elbow; infant; injuries; observer variation; radiography; retrospective study; young adult","American Roentgen Ray Society","0361803X","","AJROA","30300006","Article","Scopus","2-s2.0-85056977536"
"Philbrick K.A.; Yoshida K.; Inoue D.; Akkus Z.; Kline T.L.; Weston A.D.; Korfiatis P.; Takahashi N.; Erickson B.J.","Philbrick, Kenneth A. (25959278600); Yoshida, Kotaro (56647222500); Inoue, Dai (23485318900); Akkus, Zeynettin (41560908300); Kline, Timothy L. (26648884000); Weston, Alexander D. (57200394792); Korfiatis, Panagiotis (23397073600); Takahashi, Naoki (56697763700); Erickson, Bradley J. (7201472755)","25959278600; 56647222500; 23485318900; 41560908300; 26648884000; 57200394792; 23397073600; 56697763700; 7201472755","What does deep learning see? Insights from a classifier trained to predict contrast enhancement phase from CT images","2018","American Journal of Roentgenology","51","10.2214/AJR.18.20331","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056921390&doi=10.2214%2fAJR.18.20331&partnerID=40&md5=22f1164a175ed8e359ff1a9d11dab09c","Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States","Philbrick K.A., Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States; Yoshida K., Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States; Inoue D., Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States; Akkus Z., Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States; Kline T.L., Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States; Weston A.D., Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States; Korfiatis P., Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States; Takahashi N., Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States; Erickson B.J., Department of Radiology, Radiology Informatics Laboratory, Mayo Clinic, 3507 17th Ave NW, Rochester, 55901, MN, United States","OBJECTIVE. Deep learning has shown great promise for improving medical image classification tasks. However, knowing what aspects of an image the deep learning system uses or, in a manner of speaking, sees to make its prediction is difficult. MATERIALS AND METHODS. Within a radiologic imaging context, we investigated the utility of methods designed to identify features within images on which deep learning activates. In this study, we developed a classifier to identify contrast enhancement phase from whole-slice CT data. We then used this classifier as an easily interpretable system to explore the utility of class activation map (CAMs), gradient-weighted class activation maps (Grad-CAMs), saliency maps, guided backpropagation maps, and the saliency activation map, a novel map reported here, to identify image features the model used when performing prediction. RESULTS. All techniques identified voxels within imaging that the classifier used. SAMs had greater specificity than did guided backpropagation maps, CAMs, and Grad-CAMs at identifying voxels within imaging that the model used to perform prediction. At shallow network layers, SAMs had greater specificity than Grad-CAMs at identifying input voxels that the layers within the model used to perform prediction. CONCLUSION. As a whole, voxel-level visualizations and visualizations of the imaging features that activate shallow network layers are powerful techniques to identify features that deep learning models use when performing prediction. © American Roentgen Ray Society.","Class activation map (CAM); Computer-aided diagnosis; Contrast enhancement phase; Convolutional neural network (CNN); CT; Deep learning; Gradient-weighted class activation map (Grad-CAM); Guided backpropagation; Machine learning; Saliency activation map; Saliency map","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Sensitivity and Specificity; Tomography, X-Ray Computed; article; classifier; contrast enhancement; machine learning; prediction; algorithm; human; image processing; sensitivity and specificity; x-ray computed tomography","American Roentgen Ray Society","0361803X","","AJROA","30403527","Article","Scopus","2-s2.0-85056921390"
"Yang Z.-X.; Tang L.; Zhang K.; Wong P.K.","Yang, Zhi-Xin (55802371653); Tang, Lulu (57203748013); Zhang, Kun (57206640763); Wong, Pak Kin (57193640456)","55802371653; 57203748013; 57206640763; 57193640456","Multi-View CNN Feature Aggregation with ELM Auto-Encoder for 3D Shape Recognition","2018","Cognitive Computation","44","10.1007/s12559-018-9598-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055340181&doi=10.1007%2fs12559-018-9598-1&partnerID=40&md5=96fe2d466a695679ceeb1ae5b3c17f9c","Department of Electromechanical Engineering, Faculty of Science and Technology, University of Macau, Macau SAR, China","Yang Z.-X., Department of Electromechanical Engineering, Faculty of Science and Technology, University of Macau, Macau SAR, China; Tang L., Department of Electromechanical Engineering, Faculty of Science and Technology, University of Macau, Macau SAR, China; Zhang K., Department of Electromechanical Engineering, Faculty of Science and Technology, University of Macau, Macau SAR, China; Wong P.K., Department of Electromechanical Engineering, Faculty of Science and Technology, University of Macau, Macau SAR, China","Fast and accurate detection of 3D shapes is a fundamental task of robotic systems for intelligent tracking and automatic control. View-based 3D shape recognition has attracted increasing attention because human perceptions of 3D objects mainly rely on multiple 2D observations from different viewpoints. However, most existing multi-view-based cognitive computation methods use straightforward pairwise comparisons among the projected images then follow with weak aggregation mechanism, which results in heavy computation cost and low recognition accuracy. To address such problems, a novel network structure combining multi-view convolutional neural networks (M-CNNs), extreme learning machine auto-encoder (ELM-AE), and ELM classifer, named as MCEA, is proposed for comprehensive feature learning, effective feature aggregation, and efficient classification of 3D shapes. Such novel framework exploits the advantages of deep CNN architecture with the robust ELM-AE feature representation, as well as the fast ELM classifier for 3D model recognition. Compared with the existing set-to-set image comparison methods, the proposed shape-to-shape matching strategy could convert each high informative 3D model into a single compact feature descriptor via cognitive computation. Moreover, the proposed method runs much faster and obtains a good balance between classification accuracy and computational efficiency. Experimental results on the benchmarking Princeton ModelNet, ShapeNet Core 55, and PSB datasets show that the proposed framework achieves higher classification and retrieval accuracy in much shorter time than the state-of-the-art methods. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","3D shape recognition; Convolutional neural networks; ELM auto-encoder; Multi-view feature aggregation","Automation; Classification (of information); Computational efficiency; Convolution; Intelligent robots; Mesh generation; Neural networks; Signal encoding; 3D shape recognition; Auto encoders; Classification accuracy; Convolutional neural network; Extreme learning machine; Feature aggregation; Feature representation; State-of-the-art methods; Learning systems","Springer New York LLC","18669956","","","","Article","Scopus","2-s2.0-85055340181"
"Lyu C.; Wang L.; Zhang J.","Lyu, Chuqiao (57205251740); Wang, Lei (57203826056); Zhang, Juhua (8686735700)","57205251740; 57203826056; 8686735700","Deep learning for DNase i hypersensitive sites identification","2018","BMC Genomics","9","10.1186/s12864-018-5283-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059291987&doi=10.1186%2fs12864-018-5283-8&partnerID=40&md5=f576472871297f0be9b956af2743e567","School of Life Science, Beijing Institute of Technology, South Zhongguancun Street, Beijing, 100081, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, Ministry of Industry and Information Technology, Beijing Institute of Technology, Beijing, China","Lyu C., School of Life Science, Beijing Institute of Technology, South Zhongguancun Street, Beijing, 100081, China; Wang L., School of Life Science, Beijing Institute of Technology, South Zhongguancun Street, Beijing, 100081, China; Zhang J., School of Life Science, Beijing Institute of Technology, South Zhongguancun Street, Beijing, 100081, China, Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, Ministry of Industry and Information Technology, Beijing Institute of Technology, Beijing, China","Background: The DNase I hypersensitive sites (DHSs) are associated with the cis-regulatory DNA elements. An efficient method of identifying DHSs can enhance the understanding on the accessibility of chromatin. Despite a multitude of resources available on line including experimental datasets and computational tools, the complex language of DHSs remains incompletely understood. Methods: Here, we address this challenge using an approach based on a state-of-the-art machine learning method. We present a novel convolutional neural network (CNN) which combined Inception like networks with a gating mechanism for the response of multiple patterns and longterm association in DNA sequences to predict multi-scale DHSs in Arabidopsis, rice and Homo sapiens. Results: Our method obtains 0.961 area under curve (AUC) on Arabidopsis, 0.969 AUC on rice and 0.918 AUC on Homo sapiens. Conclusions: Our method provides an efficient and accurate way to identify multi-scale DHSs sequences by deep learning. © 2018 The Author(s).","Convolutional neural network; Deep learning; DNase I hypersensitive sites","Arabidopsis; Computational Biology; Deep Learning; Deoxyribonuclease I; Humans; Models, Biological; Oryza; Regulatory Sequences, Nucleic Acid; DNA fragment; deoxyribonuclease I; Arabidopsis; area under the curve; Article; artificial neural network; deep learning; DNA sequence; DNase I hypersensitive site; genome; human; machine learning; molecular genetic phenomena and functions; nonhuman; rice; sequence analysis; biological model; biology; enzymology; genetics; metabolism; Oryza; procedures; regulatory sequence","BioMed Central Ltd.","14712164","","BGMEE","30598079","Article","Scopus","2-s2.0-85059291987"
"Rawat R.R.; Ruderman D.; Macklin P.; Rimm D.L.; Agus D.B.","Rawat, Rishi R. (57204717718); Ruderman, Daniel (6602930579); Macklin, Paul (57203054046); Rimm, David L. (7006794489); Agus, David B. (26643549000)","57204717718; 6602930579; 57203054046; 7006794489; 26643549000","Correlating nuclear morphometric patterns with estrogen receptor status in breast cancer pathologic specimens","2018","npj Breast Cancer","22","10.1038/s41523-018-0084-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056874776&doi=10.1038%2fs41523-018-0084-4&partnerID=40&md5=fd3753b10f54edc106e7bd4c22adada4","Lawrence J. Ellison Institute for Transformative Medicine, University of Southern California, 2250 Alcazar Street, CSC 240, Los Angeles, 90089-9075, CA, United States; Intelligent Systems Engineering, Indiana University, 700N. Woodlawn Ave., Bloomington, 47408, IN, United States; Department of Pathology, BML 116, Yale University School of Medicine, 310 Cedar St, PO Box 208023, New Haven, 06520-8023, CT, United States","Rawat R.R., Lawrence J. Ellison Institute for Transformative Medicine, University of Southern California, 2250 Alcazar Street, CSC 240, Los Angeles, 90089-9075, CA, United States; Ruderman D., Lawrence J. Ellison Institute for Transformative Medicine, University of Southern California, 2250 Alcazar Street, CSC 240, Los Angeles, 90089-9075, CA, United States; Macklin P., Intelligent Systems Engineering, Indiana University, 700N. Woodlawn Ave., Bloomington, 47408, IN, United States; Rimm D.L., Department of Pathology, BML 116, Yale University School of Medicine, 310 Cedar St, PO Box 208023, New Haven, 06520-8023, CT, United States; Agus D.B., Lawrence J. Ellison Institute for Transformative Medicine, University of Southern California, 2250 Alcazar Street, CSC 240, Los Angeles, 90089-9075, CA, United States","In this pilot study, we introduce a machine learning framework to identify relationships between cancer tissue morphology and hormone receptor pathway activation in breast cancer pathology hematoxylin and eosin (H&E)-stained samples. As a proof-of-concept, we focus on predicting clinical estrogen receptor (ER) status—defined as greater than one percent of cells positive for estrogen receptor by immunohistochemistry staining—from spatial arrangement of nuclear features. Our learning pipeline segments nuclei from H&E images, extracts their position, shape and orientation descriptors, and then passes them to a deep neural network to predict ER status. After training on 57 tissue cores of invasive ductal carcinoma (IDC), our pipeline predicted ER status in an independent test set of patient samples (AUC ROC = 0.72, 95%CI = 0.55–0.89, n = 56). This proof of concept shows that machine-derived descriptors of morphologic histology patterns can be correlated to signaling pathway status. Unlike other deep learning approaches to pathology, our system uses deep neural networks to learn spatial relationships between pre-defined biological features, which improves the interpretability of the system and sheds light on the features the neural network uses to predict ER status. Future studies will correlate morphometry to quantitative measures of estrogen receptor status and, ultimately response to hormonal therapy. © 2018, The Author(s).","","eosin; estrogen receptor; hematoxylin; tamoxifen; Article; breast cancer; breast carcinoma; cancer prognosis; cancer tissue; controlled study; diagnostic test; estrogen receptor negative breast cancer; estrogen receptor positive breast cancer; histopathology; hormonal therapy; human; immunohistochemistry; machine learning; major clinical study; morphometry; nerve cell network; pilot study; priority journal; proof of concept; sensitivity and specificity; treatment response","Nature Publishing Group","23744677","","","","Article","Scopus","2-s2.0-85056874776"
"Teffahi H.; Yao H.","Teffahi, Hanane (57201193986); Yao, Hongxun (7401678052)","57201193986; 7401678052","D-SS Frame: deep spectral-spatial feature extraction and fusion for classification of panchromatic and multispectral images","2018","High Technology Letters","1","10.3772/j.issn.1006-6748.2018.04.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059628465&doi=10.3772%2fj.issn.1006-6748.2018.04.006&partnerID=40&md5=638fdb2b86368a8fcf53c87b813b1103","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Algerian Space Agency, Algiers, 16342, Algeria","Teffahi H., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China, Algerian Space Agency, Algiers, 16342, Algeria; Yao H., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China","Facing the very high-resolution (VHR) image classification problem, a feature extraction and fusion framework is presented for VHR panchromatic and multispectral image classification based on deep learning techniques. The proposed approach combines spectral and spatial information based on the fusion of features extracted from panchromatic (PAN) and multispectral (MS) images using sparse autoencoder and its deep version. There are three steps in the proposed method, the first one is to extract spatial information of PAN image, and the second one is to describe spectral information of MS image. Finally, in the third step, the features obtained from PAN and MS images are concatenated directly as a simple fusion feature. The classification is performed using the support vector machine (SVM) and the experiments carried out on two datasets with very high spatial resolution. MS and PAN images from WorldView-2 satellite indicate that the classifier provides an efficient solution and demonstrate that the fusion of the features extracted by deep learning techniques from PAN and MS images performs better than that when these techniques are used separately. In addition, this framework shows that deep learning models can extract and fuse spatial and spectral information greatly, and have huge potential to achieve higher accuracy for classification of multispectral and panchromatic images. Copyright © by HIGH TECHNOLOGY LETTERS PRESS.","Feature extraction(FE); Feature fusion; Image classification; Multispectral(MS) image; Panchromatic(PAN) image; Sparse autoencoder; Stacked sparse autoencoder; Support vector machine(SVM)","Deep learning; Extraction; Feature extraction; Image classification; Image fusion; Learning algorithms; Support vector machines; Auto encoders; Feature fusion; Multispectral image classification; Multispectral images; Panchromatic (Pan) image; Spectral information; Very high resolution (VHR) image; Very high spatial resolutions; Classification (of information)","Inst. of Scientific and Technical Information of China","10066748","","HTLEF","","Article","Scopus","2-s2.0-85059628465"
"Sanaullah A.; Yang C.; Alexeev Y.; Yoshii K.; Herbordt M.C.","Sanaullah, Ahmed (55924663100); Yang, Chen (7407027585); Alexeev, Yuri (6602740577); Yoshii, Kazutomo (13404801000); Herbordt, Martin C. (6603686731)","55924663100; 7407027585; 6602740577; 13404801000; 6603686731","Real-time data analysis for medical diagnosis using FPGA-accelerated neural networks","2018","BMC Bioinformatics","27","10.1186/s12859-018-2505-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056636234&doi=10.1186%2fs12859-018-2505-7&partnerID=40&md5=e0f6ca700e5cfa029a62290b8582c90a","Computer Architecture and Automated Design Lab, Boston University, Boston, MA, United States; Argonne Leadership Computing Facility, Argonne National Laboratory, Lemont, IL, United States; Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, United States","Sanaullah A., Computer Architecture and Automated Design Lab, Boston University, Boston, MA, United States; Yang C., Computer Architecture and Automated Design Lab, Boston University, Boston, MA, United States; Alexeev Y., Argonne Leadership Computing Facility, Argonne National Laboratory, Lemont, IL, United States; Yoshii K., Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, United States; Herbordt M.C., Computer Architecture and Automated Design Lab, Boston University, Boston, MA, United States","Background: Real-time analysis of patient data during medical procedures can provide vital diagnostic feedback that significantly improves chances of success. With sensors becoming increasingly fast, frameworks such as Deep Neural Networks are required to perform calculations within the strict timing constraints for real-time operation. However, traditional computing platforms responsible for running these algorithms incur a large overhead due to communication protocols, memory accesses, and static (often generic) architectures. In this work, we implement a low-latency Multi-Layer Perceptron (MLP) processor using Field Programmable Gate Arrays (FPGAs). Unlike CPUs and Graphics Processing Units (GPUs), our FPGA-based design can directly interface sensors, storage devices, display devices and even actuators, thus reducing the delays of data movement between ports and compute pipelines. Moreover, the compute pipelines themselves are tailored specifically to the application, improving resource utilization and reducing idle cycles. We demonstrate the effectiveness of our approach using mass-spectrometry data sets for real-time cancer detection. Results: We demonstrate that correct parameter sizing, based on the application, can reduce latency by 20% on average. Furthermore, we show that in an application with tightly coupled data-path and latency constraints, having a large amount of computing resources can actually reduce performance. Using mass-spectrometry benchmarks, we show that our proposed FPGA design outperforms both CPU and GPU implementations, with an average speedup of 144x and 21x, respectively. Conclusion: In our work, we demonstrate the importance of application-specific optimizations in order to minimize latency and maximize resource utilization for MLP inference. By directly interfacing and processing sensor data with ultra-low latency, FPGAs can perform real-time analysis during procedures and provide diagnostic feedback that can be critical to achieving higher percentages of successful patient outcomes. © 2018 The Author(s).","Cancer; FPGA; Inference; Machine learning; Mass-spectrometry; Multi-layer perceptrons; Real-time","Data Analysis; Humans; Machine Learning; Neoplasms; Neural Networks (Computer); Computer graphics; Data handling; Deep neural networks; Diagnosis; Diseases; Display devices; Feedback; Graphics processing unit; Hospital data processing; Integrated circuit design; Learning systems; Mass spectrometry; Network architecture; Pipeline processing systems; Pipelines; Program processors; Virtual storage; Application-specific optimizations; Cancer; Field programmable gate array (FPGAs); Inference; Mass spectrometry data; Multi-layer perceptrons; Real time; Real time data analysis; artificial neural network; data analysis; human; machine learning; neoplasm; pathology; trends; Field programmable gate arrays (FPGA)","BioMed Central Ltd.","14712105","","BBMIC","30577751","Article","Scopus","2-s2.0-85056636234"
"Fernando T.; Denman S.; Sridharan S.; Fookes C.","Fernando, Tharindu (57201854886); Denman, Simon (56238954000); Sridharan, Sridha (7102172665); Fookes, Clinton (7003338437)","57201854886; 56238954000; 7102172665; 7003338437","Soft + Hardwired attention: An LSTM framework for human trajectory prediction and abnormal event detection","2018","Neural Networks","232","10.1016/j.neunet.2018.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054597180&doi=10.1016%2fj.neunet.2018.09.002&partnerID=40&md5=ea5044f3e2e8e6e4ac05a240ea99d362","Image and Video Research Laboratory, SAIVT, Queensland University of Technology, Australia","Fernando T., Image and Video Research Laboratory, SAIVT, Queensland University of Technology, Australia; Denman S., Image and Video Research Laboratory, SAIVT, Queensland University of Technology, Australia; Sridharan S., Image and Video Research Laboratory, SAIVT, Queensland University of Technology, Australia; Fookes C., Image and Video Research Laboratory, SAIVT, Queensland University of Technology, Australia","As humans we possess an intuitive ability for navigation which we master through years of practice; however existing approaches to model this trait for diverse tasks including monitoring pedestrian flow and detecting abnormal events have been limited by using a variety of hand-crafted features. Recent research in the area of deep-learning has demonstrated the power of learning features directly from the data; and related research in recurrent neural networks has shown exemplary results in sequence-to-sequence problems such as neural machine translation and neural image caption generation. Motivated by these approaches, we propose a novel method to predict the future motion of a pedestrian given a short history of their, and their neighbours, past behaviour. The novelty of the proposed method is the combined attention model which utilises both “soft attention” as well as “hard-wired” attention in order to map the trajectory information from the local neighbourhood to the future positions of the pedestrian of interest. We illustrate how a simple approximation of attention weights (i.e. hard-wired) can be merged together with soft attention weights in order to make our model applicable for challenging real world scenarios with hundreds of neighbours. The navigational capability of the proposed method is tested on two challenging publicly available surveillance databases where our model outperforms the current-state-of-the-art methods. Additionally, we illustrate how the proposed architecture can be directly applied for the task of abnormal event detection without handcrafting the features. © 2018 Elsevier Ltd","Attention models; Deep feature learning; Human trajectory prediction; Social navigation","Attention; Databases, Factual; Deep Learning; Forecasting; Humans; Machine Learning; Motion; Neural Networks (Computer); Deep learning; Feature extraction; Forecasting; Navigation; Trajectories; Abnormal event detections; Attention model; Deep feature learning; Proposed architectures; Social navigation; State-of-the-art methods; Trajectory information; Trajectory prediction; article; attention; human; human experiment; learning; machine; monitoring; motion; neighborhood; pedestrian; prediction; artificial neural network; factual database; forecasting; machine learning; trends; Long short-term memory","Elsevier Ltd","08936080","","NNETE","30317132","Article","Scopus","2-s2.0-85054597180"
"Ueltzhöffer K.","Ueltzhöffer, Kai (36547176100)","36547176100","Deep active inference","2018","Biological Cybernetics","54","10.1007/s00422-018-0785-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056315905&doi=10.1007%2fs00422-018-0785-7&partnerID=40&md5=37945d83a4cbfe46f110e03025285feb","Heidelberg, Germany","Ueltzhöffer K., Heidelberg, Germany","This work combines the free energy principle and the ensuing active inference dynamics with recent advances in variational inference in deep generative models, and evolution strategies to introduce the “deep active inference” agent. This agent minimises a variational free energy bound on the average surprise of its sensations, which is motivated by a homeostatic argument. It does so by optimising the parameters of a generative latent variable model of its sensory inputs, together with a variational density approximating the posterior distribution over the latent variables, given its observations, and by acting on its environment to actively sample input that is likely under this generative model. The internal dynamics of the agent are implemented using deep and recurrent neural networks, as used in machine learning, making the deep active inference agent a scalable and very flexible class of active inference agent. Using the mountain car problem, we show how goal-directed behaviour can be implemented by defining appropriate priors on the latent states in the agent’s model. Furthermore, we show that the deep active inference agent can learn a generative model of the environment, which can be sampled from to understand the agent’s beliefs about the environment and its interaction therewith. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.","Action; Cognition; Deep learning; Generative models; Perception; Variational inference","Algorithms; Cognition; Environment; Goals; Humans; Models, Theoretical; Neural Networks (Computer); Nonlinear Dynamics; Perception; Equivalence classes; Free energy; Recurrent neural networks; Sensory perception; Action; Cognition; Evolution strategies; Generative model; Latent variable modeling; Posterior distributions; Variational free energy; Variational inference; algorithm; artificial neural network; cognition; environment; human; motivation; nonlinear system; perception; physiology; theoretical model; Deep learning","Springer Verlag","03401200","","BICYA","30350226","Article","Scopus","2-s2.0-85056315905"
"Madani A.; Arnaout R.; Mofrad M.; Arnaout R.","Madani, Ali (55980592600); Arnaout, Ramy (6603419002); Mofrad, Mohammad (10040081000); Arnaout, Rima (18036450400)","55980592600; 6603419002; 10040081000; 18036450400","Fast and accurate view classification of echocardiograms using deep learning","2018","npj Digital Medicine","325","10.1038/s41746-017-0013-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086330988&doi=10.1038%2fs41746-017-0013-1&partnerID=40&md5=235fdaa3f9dcd5978109db097ceeaaef","Molecular Biophysics and Integrated Bioimaging Division, Lawrence Berkeley National Lab, California Institute for Quantitative Biosciences (QB3), University of California at Berkeley, 208A Stanley Hall Room 1762, Berkeley, 94720, CA, United States; Beth Israel Deaconess Medical Center, Harvard Medical School, 330 Brookline Avenue Dana 615, Boston, 02215, MA, United States; Cardiovascular Research Institute, University of California, 555 Mission Bay Blvd South Rm 484, San Francisco, 94143, United States","Madani A., Molecular Biophysics and Integrated Bioimaging Division, Lawrence Berkeley National Lab, California Institute for Quantitative Biosciences (QB3), University of California at Berkeley, 208A Stanley Hall Room 1762, Berkeley, 94720, CA, United States; Arnaout R., Beth Israel Deaconess Medical Center, Harvard Medical School, 330 Brookline Avenue Dana 615, Boston, 02215, MA, United States; Mofrad M., Molecular Biophysics and Integrated Bioimaging Division, Lawrence Berkeley National Lab, California Institute for Quantitative Biosciences (QB3), University of California at Berkeley, 208A Stanley Hall Room 1762, Berkeley, 94720, CA, United States; Arnaout R., Cardiovascular Research Institute, University of California, 555 Mission Bay Blvd South Rm 484, San Francisco, 94143, United States","Echocardiography is essential to cardiology. However, the need for human interpretation has limited echocardiography’s full potential for precision medicine. Deep learning is an emerging tool for analyzing images but has not yet been widely applied to echocardiograms, partly due to their complex multi-view format. The essential first step toward comprehensive computer-assisted echocardiographic interpretation is determining whether computers can learn to recognize these views. We trained a convolutional neural network to simultaneously classify 15 standard views (12 video, 3 still), based on labeled still images and videos from 267 transthoracic echocardiograms that captured a range of real-world clinical variation. Our model classified among 12 video views with 97.8% overall test accuracy without overfitting. Even on single low-resolution images, accuracy among 15 views was 91.7% vs. 70.2–84.0% for board-certified echocardiographers. Data visualization experiments showed that the model recognizes similarities among related views and classifies using clinically relevant image features. Our results provide a foundation for artificial intelligence-assisted echocardiographic interpretation. © 2018, The Author(s).","","Computer aided analysis; Deep learning; Echocardiography; Neural networks; Classifieds; Computer assisted; Convolutional neural network; Emerging tools; Learn+; Multi-views; Overfitting; Real-world; Still-images; Test accuracy; adult; aged; Article; artificial intelligence; clinical feature; convolutional neural network; deep learning; echocardiography; female; human; machine learning; major clinical study; male; priority journal; transthoracic echocardiography; workflow; Data visualization","Nature Publishing Group","23986352","","","","Article","Scopus","2-s2.0-85086330988"
"Tranter A.D.; Slatyer H.J.; Hush M.R.; Leung A.C.; Everett J.L.; Paul K.V.; Vernaz-Gris P.; Lam P.K.; Buchler B.C.; Campbell G.T.","Tranter, A.D. (57202157150); Slatyer, H.J. (56367700400); Hush, M.R. (32167561900); Leung, A.C. (57202154642); Everett, J.L. (56224931400); Paul, K.V. (57202160073); Vernaz-Gris, P. (56156597400); Lam, P.K. (7202365902); Buchler, B.C. (6701608195); Campbell, G.T. (25822383000)","57202157150; 56367700400; 32167561900; 57202154642; 56224931400; 57202160073; 56156597400; 7202365902; 6701608195; 25822383000","Multiparameter optimisation of a magneto-optical trap using deep learning","2018","Nature Communications","57","10.1038/s41467-018-06847-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055079130&doi=10.1038%2fs41467-018-06847-1&partnerID=40&md5=e8b3b90d352bef4ffe47b003c7cc253a","Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia; School of Engineering and Information Technology, University of New South Wales, 2600, ACT, Australia","Tranter A.D., Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia; Slatyer H.J., Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia; Hush M.R., School of Engineering and Information Technology, University of New South Wales, 2600, ACT, Australia; Leung A.C., Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia; Everett J.L., Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia; Paul K.V., Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia; Vernaz-Gris P., Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia; Lam P.K., Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia; Buchler B.C., Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia; Campbell G.T., Centre for Quantum Computation and Communication Technologies, Department of Quantum Science, Research School of Physics and Engineering, The Australian National University, Acton, 2601, Australia","Machine learning based on artificial neural networks has emerged as an efficient means to develop empirical models of complex systems. Cold atomic ensembles have become commonplace in laboratories around the world, however, many-body interactions give rise to complex dynamics that preclude precise analytic optimisation of the cooling and trapping process. Here, we implement a deep artificial neural network to optimise the magneto-optic cooling and trapping of neutral atomic ensembles. The solution identified by machine learning is radically different to the smoothly varying adiabatic solutions currently used. Despite this, the solutions outperform best known solutions producing higher optical densities. © 2018, The Author(s).","","Algorithms; Deep Learning; Magnetics; Neural Networks (Computer); Optics and Photonics; adiabatic process; algorithm; artificial neural network; cooling; laboratory method; machine learning; numerical model; optical property; optimization; algorithm; Article; artificial neural network; compression; cooling; human; machine learning; molecular dynamics; optical density; optical depth; quantum mechanics; magnetism; optics","Nature Publishing Group","20411723","","","30341301","Article","Scopus","2-s2.0-85055079130"
"Zhao W.; Yang J.; Sun Y.; Li C.; Wu W.; Jin L.; Yang Z.; Ni B.; Gao P.; Wang P.; Hua Y.; Li M.","Zhao, Wei (58596853900); Yang, Jiancheng (57192458106); Sun, Yingli (57196275040); Li, Cheng (57195327997); Wu, Weilan (57205075464); Jin, Liang (57203350763); Yang, Zhiming (57194494912); Ni, Bingbing (57188713282); Gao, Pan (58712002300); Wang, Peijun (14027748800); Hua, Yanqing (8980222500); Li, Ming (56927069100)","58596853900; 57192458106; 57196275040; 57195327997; 57205075464; 57203350763; 57194494912; 57188713282; 58712002300; 14027748800; 8980222500; 56927069100","3D deep learning from CT scans predicts tumor invasiveness of subcentimeter pulmonary adenocarcinomas","2018","Cancer Research","150","10.1158/0008-5472.CAN-18-0696","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058441289&doi=10.1158%2f0008-5472.CAN-18-0696&partnerID=40&md5=49ee5dac051b52a776cfbad116e5e214","Diagnosis and Treatment Center of Small Lung Nodules of Huadong Hospital, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; SJTU-UCLA Joint Center for Machine Perception and Inference, Shanghai Jiao Tong University, Shanghai, China; Diannei Technology, Shanghai, China; Department of Radiology, Tongji Hospital, School of Medicine, Tongji University, Shanghai, China; Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China","Zhao W., Diagnosis and Treatment Center of Small Lung Nodules of Huadong Hospital, Shanghai, China, Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China; Yang J., Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China, SJTU-UCLA Joint Center for Machine Perception and Inference, Shanghai Jiao Tong University, Shanghai, China, Diannei Technology, Shanghai, China; Sun Y., Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China; Li C., Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China; Wu W., Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China; Jin L., Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China; Yang Z., Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China; Ni B., Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China, SJTU-UCLA Joint Center for Machine Perception and Inference, Shanghai Jiao Tong University, Shanghai, China; Gao P., Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China; Wang P., Department of Radiology, Tongji Hospital, School of Medicine, Tongji University, Shanghai, China; Hua Y., Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China; Li M., Diagnosis and Treatment Center of Small Lung Nodules of Huadong Hospital, Shanghai, China, Department of Radiology, Huadong Hospital Affiliated to Fudan University, Shanghai, 200040, China","Identification of early-stage pulmonary adenocarcinomas before surgery, especially in cases of subcentimeter cancers, would be clinically important and could provide guidance to clinical decision making. In this study, we developed a deep learning system based on 3D convolutional neural networks and multitask learning, which automatically predicts tumor invasiveness, together with 3D nodule segmentation masks. The system processes a 3D nodule-centered patch of preprocessed CT and learns a deep representation of a given nodule without the need for any additional information. A dataset of 651 nodules with manually segmented voxel-wise masks and pathological labels of atypical adenomatous hyperplasia (AAH), adenocarcinomas in situ (AIS), minimally invasive adenocarcinoma (MIA), and invasive pulmonary adenocarcinoma (IA) was used in this study. We trained and validated our deep learning system on 523 nodules and tested its performance on 128 nodules. An observer study with 2 groups of radiologists, 2 senior and 2 junior, was also investigated. We merged AAH and AIS into one single category AAH-AIS, comprising a 3-category classification in our study. The proposed deep learning system achieved better classification performance than the radiologists; in terms of 3-class weighted average F1 score, the model achieved 63.3% while the radiologists achieved 55.6%, 56.6%, 54.3%, and 51.0%, respectively. These results suggest that deep learning methods improve the yield of discriminative results and hold promise in the CADx application domain, which could help doctors work efficiently and facilitate the application of precision medicine. Significance: Machine learning tools are beginning to be implemented for clinical applications. This study represents an important milestone for this emerging technology, which could improve therapy selection for patients with lung cancer. © 2018 American Association for Cancer Research.","","Adenocarcinoma; Adolescent; Adult; Aged; Aged, 80 and over; Area Under Curve; Decision Making; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Lung Neoplasms; Male; Middle Aged; Mutation; Neoplasm Invasiveness; Neural Networks (Computer); Precision Medicine; Prognosis; Retrospective Studies; Tomography, X-Ray Computed; Young Adult; adenocarcinoma in situ; adolescent; adult; aged; Article; artificial neural network; cancer classification; deep learning algorithm; diagnostic radiologist; female; human; intermethod comparison; learning algorithm; lung adenocarcinoma; lung nodule; major clinical study; male; personalized medicine; priority journal; retrospective study; three dimensional imaging; tumor invasion; voxel based morphometry; x-ray computed tomography; adenocarcinoma; area under the curve; computer assisted diagnosis; decision making; diagnostic imaging; image processing; lung tumor; middle aged; mutation; procedures; prognosis; three dimensional imaging; tumor invasion; very elderly; young adult","American Association for Cancer Research Inc.","00085472","","CNREA","30279243","Article","Scopus","2-s2.0-85058441289"
"Gaiduk M.; Penzel T.; Ortega J.A.; Seepold R.","Gaiduk, Maksym (57194099003); Penzel, Thomas (57207902667); Ortega, Juan Antonio (33867735500); Seepold, Ralf (13807648300)","57194099003; 57207902667; 33867735500; 13807648300","Automatic sleep stages classification using respiratory, heart rate and movement signals","2018","Physiological Measurement","27","10.1088/1361-6579/aaf5d4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058913948&doi=10.1088%2f1361-6579%2faaf5d4&partnerID=40&md5=7f3da718b04e623249b809dfba9e1ba4","HTWG Konstanz, Konstanz, Germany; Interdisciplinary Center for Sleep Medicine, Charité Clinic, Berlin, Germany; University of Seville, Seville, Spain; Department of Information and Internet Technology, Sechenov University, Moscow, Russian Federation","Gaiduk M., HTWG Konstanz, Konstanz, Germany, University of Seville, Seville, Spain; Penzel T., Interdisciplinary Center for Sleep Medicine, Charité Clinic, Berlin, Germany; Ortega J.A., University of Seville, Seville, Spain; Seepold R., HTWG Konstanz, Konstanz, Germany, Department of Information and Internet Technology, Sechenov University, Moscow, Russian Federation","Objective: This paper presents an algorithm for non-invasive sleep stage identification using respiratory, heart rate and movement signals. The algorithm is part of a system suitable for long-term monitoring in a home environment, which should support experts analysing sleep. Approach: As there is a strong correlation between bio-vital signals and sleep stages, multinomial logistic regression was chosen for categorical distribution of sleep stages. Several derived parameters of three signals (respiratory, heart rate and movement) are input for the proposed method. Sleep recordings of five subjects were used for the training of a machine learning model and 30 overnight recordings collected from 30 individuals with about 27 000 epochs of 30 s intervals each were evaluated. Main results: The achieved rate of accuracy is 72% for Wake, NREM, REM (with Cohen's kappa value 0.67) and 58% for Wake, Light (N1 and N2), Deep (N3) and REM stages (Cohen's kappa is 0.50). Our approach has confirmed the potential of this method and disclosed several ways for its improvement. Significance: The results indicate that respiratory, heart rate and movement signals can be used for sleep studies with a reasonable level of accuracy. These inputs can be obtained in a non-invasive way applying it in a home environment. The proposed system introduces a convenient approach for a long-term monitoring system which could support sleep laboratories. The algorithm which was developed allows for an easy adjustment of input parameters that depend on available signals and for this reason could also be used with various hardware systems. © 2018 Institute of Physics and Engineering in Medicine.","body movement; heart rate; multinomial logistic regression; non-invasive sleep study; respiration; sleep stage classification; sleep study","Adult; Automation; Female; Healthy Volunteers; Heart Rate; Humans; Male; Movement; Polysomnography; Respiratory Rate; Signal Processing, Computer-Assisted; Sleep Stages; Software; Young Adult; Patient monitoring; Regression analysis; Sleep research; Wakes; Body movements; Heart-rate; Long term monitoring; Multinomial logistic regression; Non-invasive sleep study; Respiration; Sleep stage; Sleep stages classifications; Sleep studies; adult; automation; breathing rate; female; heart rate; human; male; movement (physiology); normal human; physiology; polysomnography; signal processing; sleep stage; software; young adult; Heart","IOP Publishing Ltd","09673334","","PMEAE","30524059","Article","Scopus","2-s2.0-85058913948"
"Desai A.D.; Peng C.; Fang L.; Mukherjee D.; Yeung A.; Jaffe S.J.; Griffin J.B.; Farsiu S.","Desai, Arjun D. (57210203201); Peng, Chunlei (56313611100); Fang, Leyuan (36739090900); Mukherjee, Dibyendu (57644359100); Yeung, Andrew (57204916176); Jaffe, Stephanie J. (57196017344); Griffin, Jennifer B. (56553289500); Farsiu, Sina (6603132896)","57210203201; 56313611100; 36739090900; 57644359100; 57204916176; 57196017344; 56553289500; 6603132896","Open-source, machine and deep learning-based automated algorithm for gestational age estimation through smartphone lens imaging","2018","Biomedical Optics Express","9","10.1364/BOE.9.006038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057855822&doi=10.1364%2fBOE.9.006038&partnerID=40&md5=31f31cbcec355fccc4b4a37d905089cf","Department of Biomedical Engineering, Duke University, Durham, 27708, United States; School of Cyber Engineering, Xidian University, Xi'an, 710071, China; Center for Global Health, RTI International, Research Triangle Park, 27709, United States; Department of Ophthalmology, Duke University Medical Center, Durham, 27710, United States; Department of Computer Science, Duke University, Durham, 27708, United States","Desai A.D., Department of Biomedical Engineering, Duke University, Durham, 27708, United States, Department of Computer Science, Duke University, Durham, 27708, United States; Peng C., Department of Biomedical Engineering, Duke University, Durham, 27708, United States, School of Cyber Engineering, Xidian University, Xi'an, 710071, China; Fang L., Department of Biomedical Engineering, Duke University, Durham, 27708, United States; Mukherjee D., Department of Biomedical Engineering, Duke University, Durham, 27708, United States; Yeung A., Department of Biomedical Engineering, Duke University, Durham, 27708, United States; Jaffe S.J., Department of Biomedical Engineering, Duke University, Durham, 27708, United States; Griffin J.B., Center for Global Health, RTI International, Research Triangle Park, 27709, United States; Farsiu S., Department of Biomedical Engineering, Duke University, Durham, 27708, United States, Department of Ophthalmology, Duke University Medical Center, Durham, 27710, United States, Department of Computer Science, Duke University, Durham, 27708, United States","Gestational age estimation at time of birth is critical for determining the degree of prematurity of the infant and for administering appropriate postnatal treatment. We present a fully automated algorithm for estimating gestational age of premature infants through smartphone lens imaging of the anterior lens capsule vasculature (ALCV). Our algorithm uses a fully convolutional network and blind image quality analyzers to segment usable anterior capsule regions. Then, it extracts ALCV features using a residual neural network architecture and trains on these features using a support vector machine-based classifier. The classification algorithm is validated using leave-one-out cross-validation on videos captured from 124 neonates. The algorithm is expected to be an influential tool for remote and point-of-care gestational age estimation of premature neonates in low-income countries. To this end, we have made the software open source. © 2018 Optical Society of America.","","Image segmentation; Network architecture; Open source software; Open systems; Smartphones; Statistical methods; Automated algorithms; Classification algorithm; Convolutional networks; Fully automated; Leave-one-out cross validations; Low income countries; Premature infants; Premature neonates; algorithm; anterior lens capsule; Article; artificial neural network; capillary density; classification algorithm; correlational study; deep learning; gestational age; human; image analysis; image processing; image quality; image segmentation; information processing; learning; machine learning; measurement accuracy; measurement precision; methodology; prematurity; remote sensing; sensitivity and specificity; support vector machine; training; validation process; vascularization; Deep learning","OSA - The Optical Society","21567085","","","","Article","Scopus","2-s2.0-85057855822"
"Lee S.H.","Lee, Scott H. (57209989458)","57209989458","Natural language generation for electronic health records","2018","npj Digital Medicine","44","10.1038/s41746-018-0070-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089606125&doi=10.1038%2fs41746-018-0070-0&partnerID=40&md5=1920fee165348795bb7a792e472d7eff","Centers for Disease Control and Prevention, Atlanta, GA, United States","Lee S.H., Centers for Disease Control and Prevention, Atlanta, GA, United States","One broad goal of biomedical informatics is to generate fully-synthetic, faithfully representative electronic health records (EHRs) to facilitate data sharing between healthcare providers and researchers and promote methodological research. A variety of methods existing for generating synthetic EHRs, but they are not capable of generating unstructured text, like emergency department (ED) chief complaints, history of present illness, or progress notes. Here, we use the encoder–decoder model, a deep learning algorithm that features in many contemporary machine translation systems, to generate synthetic chief complaints from discrete variables in EHRs, like age group, gender, and discharge diagnosis. After being trained end-to-end on authentic records, the model can generate realistic chief complaint text that appears to preserve the epidemiological information encoded in the original record-sentence pairs. As a side effect of the model’s optimization goal, these synthetic chief complaints are also free of relatively uncommon abbreviation and misspellings, and they include none of the personally identifiable information (PII) that was in the training data, suggesting that this model may be used to support the de-identification of text in EHRs. When combined with algorithms like generative adversarial networks (GANs), our model could be used to generate fully-synthetic EHRs, allowing healthcare providers to share faithful representations of multimodal medical data without compromising patient privacy. This is an important advance that we hope will facilitate the development of machine-learning methods for clinical decision support, disease surveillance, and other data-hungry applications in biomedical informatics. © 2018, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.","","Decision support systems; Deep learning; Diagnosis; Generative adversarial networks; Health care; Medical informatics; Natural language processing systems; Records management; Biomedical informatics; Data Sharing; Electronic health; Emergency departments; Encoder-decoder; Health care providers; Health records; Methodological research; Natural language generation; Unstructured texts; adult; age; aged; Article; electronic health record; female; human; language; learning algorithm; male; middle aged; predictive value; priority journal; validity; very elderly; young adult; Learning algorithms","Nature Publishing Group","23986352","","","","Article","Scopus","2-s2.0-85089606125"
"Xiao L.; Zhang Y.; Peng G.","Xiao, Liming (57204460323); Zhang, Yonghong (55995777500); Peng, Gongzhuang (55855293400)","57204460323; 55995777500; 55855293400","Landslide susceptibility assessment using integrated deep learning algorithm along the china-nepal highway","2018","Sensors (Switzerland)","90","10.3390/s18124436","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058619741&doi=10.3390%2fs18124436&partnerID=40&md5=3b51ab022ef6d78b480de8a1e5e03183","Department of Information and Communication, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Engineering Research Institute, University of Science and Technology Beijing, Beijing, 100083, China","Xiao L., Department of Information and Communication, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Zhang Y., Department of Information and Communication, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Peng G., Engineering Research Institute, University of Science and Technology Beijing, Beijing, 100083, China","The China-Nepal Highway is a vital land route in the Kush-Himalayan region. The occurrence of mountain hazards in this area is a matter of serious concern. Thus, it is of great importance to perform hazard assessments in a more accurate and real-time way. Based on temporal and spatial sensor data, this study tries to use data-driven algorithms to predict landslide susceptibility. Ten landslide instability factors were prepared, including elevation, slope angle, slope aspect, plan curvature, vegetation index, built-up index, stream power, lithology, precipitation intensity, and cumulative precipitation index. Four machine learning algorithms, namely decision tree (DT), support vector machines (SVM), Back Propagation neural network (BPNN), and Long Short Term Memory (LSTM) are implemented, and their final prediction accuracies are compared. The experimental results showed that the prediction accuracies of BPNN, SVM, DT, and LSTM in the test areas are 62.0%, 72.9%, 60.4%, and 81.2%, respectively. LSTM outperformed the other three models due to its capability to learn time series with long temporal dependencies. It indicates that the dynamic change course of geological and geographic parameters is an important indicator in reflecting landslide susceptibility. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","China-nepal highway; Landslide susceptibility; LSTM; Machine learning; Remote sensing images","Backpropagation algorithms; Data mining; Decision trees; Deep learning; Forecasting; Hazards; Landslides; Learning systems; Lithology; Long short-term memory; Remote sensing; Support vector machines; Back-propagation neural networks; China-nepal highway; Cumulative precipitation; Landslide susceptibility; Landslide susceptibility assessments; LSTM; Precipitation intensity; Remote sensing images; Learning algorithms","MDPI AG","14248220","","","30558225","Article","Scopus","2-s2.0-85058619741"
"Kearney V.; Chan J.W.; Haaf S.; Descovich M.; Solberg T.D.","Kearney, Vasant (56449200500); Chan, Jason W. (57189630606); Haaf, Samuel (57204482778); Descovich, Martina (6602469680); Solberg, Timothy D. (57204614205)","56449200500; 57189630606; 57204482778; 6602469680; 57204614205","DoseNet: A volumetric dose prediction algorithm using 3D fully-convolutional neural networks","2018","Physics in Medicine and Biology","137","10.1088/1361-6560/aaef74","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057754026&doi=10.1088%2f1361-6560%2faaef74&partnerID=40&md5=016cd0563edb5df9ce574a688a9b3fc9","Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States","Kearney V., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States; Chan J.W., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States; Haaf S., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States; Descovich M., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States; Solberg T.D., Department of Radiation Oncology, University of California, San Francisco, 94115, CA, United States","The goal of this study is to demonstrate the feasibility of a novel fully-convolutional volumetric dose prediction neural network (DoseNet) and test its performance on a cohort of prostate stereotactic body radiotherapy (SBRT) patients. DoseNet is suggested as a superior alternative to U-Net and fully connected distance map-based neural networks for non-coplanar SBRT prostate dose prediction. DoseNet utilizes 3D convolutional downsampling with corresponding 3D deconvolutional upsampling to preserve memory while simultaneously increasing the receptive field of the network. DoseNet was implemented on 2 Nvidia 1080 Ti graphics processing units and utilizes a 3 phase learning protocol to help achieve convergence and improve generalization. DoseNet was trained, validated, and tested with 151 patients following Kaggle completion rules. The dosimetric quality of DoseNet was evaluated by comparing the predicted dose distribution with the clinically approved delivered dose distribution in terms of conformity index, heterogeneity index, and various clinically relevant dosimetric parameters. The results indicate that the DoseNet algorithm is a superior alternative to U-Net and fully connected methods for prostate SBRT patients. DoseNet required ∼50.1 h to train, and ∼0.83 s to make a prediction on a 128 × 128 × 64 voxel image. In conclusion, DoseNet is capable of making accurate volumetric dose predictions for non-coplanar SBRT prostate patients, while simultaneously preserving computational efficiency. © 2018 Institute of Physics and Engineering in Medicine.","automated treatment planning; convolutional neural networks; deep learning; dose prediction; knowledge based planning; machine learning; radiation oncology","Algorithms; Humans; Neural Networks (Computer); Radiosurgery; Radiotherapy Dosage; Radiotherapy Planning, Computer-Assisted; Computational efficiency; Computer graphics; Convolution; Deep learning; Dosimetry; Graphics processing unit; Knowledge based systems; Learning systems; Neural networks; Oncology; Program processors; Radiotherapy; Signal sampling; Urology; Convolutional neural network; Dosimetric parameter; Heterogeneity index; Knowledge based planning; Prediction algorithms; Radiation oncology; Stereotactic body radiotherapy; Treatment planning; algorithm; artificial neural network; human; procedures; radiosurgery; radiotherapy dosage; radiotherapy planning system; Forecasting","Institute of Physics Publishing","00319155","","PHMBA","30511663","Article","Scopus","2-s2.0-85057754026"
"Asakura T.; Date Y.; Kikuchi J.","Asakura, Taiga (56191732100); Date, Yasuhiro (12243044000); Kikuchi, Jun (56423275500)","56191732100; 12243044000; 56423275500","Application of ensemble deep neural network to metabolomics studies","2018","Analytica Chimica Acta","39","10.1016/j.aca.2018.02.045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043379372&doi=10.1016%2fj.aca.2018.02.045&partnerID=40&md5=7d81c8e81175ca6e29ec3d64ca1c9ca6","RIKEN Center for Sustainable Resource Science, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Kanagawa, Japan; Graduate School of Medical Life Science, Yokohama City University, 1-7-29 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Kanagawa, Japan; Graduate School of Bioagricultural Sciences, Nagoya University, 1 Furo-cho, Chikusa-ku, Nagoya, 464-8601, Aichi, Japan","Asakura T., RIKEN Center for Sustainable Resource Science, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Kanagawa, Japan; Date Y., RIKEN Center for Sustainable Resource Science, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Kanagawa, Japan, Graduate School of Medical Life Science, Yokohama City University, 1-7-29 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Kanagawa, Japan; Kikuchi J., RIKEN Center for Sustainable Resource Science, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Kanagawa, Japan, Graduate School of Medical Life Science, Yokohama City University, 1-7-29 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Kanagawa, Japan, Graduate School of Bioagricultural Sciences, Nagoya University, 1 Furo-cho, Chikusa-ku, Nagoya, 464-8601, Aichi, Japan","Deep neural network (DNN) is a useful machine learning approach, although its applicability to metabolomics studies has rarely been explored. Here we describe the development of an ensemble DNN (EDNN) algorithm and its applicability to metabolomics studies. As a model case, the developed EDNN approach was applied to metabolomics data of various fish species collected from Japan coastal and estuarine environments for evaluation of a regression performance compared with conventional DNN, random forest, and support vector machine algorithms. This study also revealed that the metabolic profiles of fish muscles were correlated with fish size (growth) in a species-dependent manner. The performance of EDNN regression for fish size based on metabolic profiles was superior to that of DNN, random forest, and support vector machine algorithms. The EDNN approach, therefore, should be helpful for analyses of regression and concerns pertaining to classification in metabolomics studies. © 2018","Deep neural network; Ensemble learning; Machine learning; Metabolomics; Nuclear magnetic resonance","Deep Learning; Metabolomics; Artificial intelligence; Decision trees; Fish; Learning systems; Metabolism; Nuclear magnetic resonance; Regression analysis; Support vector machines; drug metabolite; Ensemble learning; Estuarine environments; Machine learning approaches; Metabolic profiles; Metabolomics; Metabolomics data; Random forests; Support vector machine algorithm; animal tissue; Article; artificial neural network; classification; coastal waters; controlled study; ensemble deep neural network; estuary; fish; growth; metabolomics; nonhuman; priority journal; random forest; species difference; support vector machine; metabolomics; procedures; Deep neural networks","Elsevier B.V.","00032670","","ACACA","30292297","Article","Scopus","2-s2.0-85043379372"
"Dey S.; Luo H.; Fokoue A.; Hu J.; Zhang P.","Dey, Sanjoy (57199712479); Luo, Heng (57213205899); Fokoue, Achille (15135570400); Hu, Jianying (55499375800); Zhang, Ping (55491528800)","57199712479; 57213205899; 15135570400; 55499375800; 55491528800","Predicting adverse drug reactions through interpretable deep learning framework","2018","BMC Bioinformatics","95","10.1186/s12859-018-2544-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059247997&doi=10.1186%2fs12859-018-2544-0&partnerID=40&md5=79de4b4a9245808dba19c3912e82561d","Center for Computational Health, IBM T.J. Watson Research Center, 1101 Kitchawan Road, Yorktown Heights, NY, United States; Cognitive Computing, IBM T.J. Watson Research Center, 1101 Kitchawan Road, Yorktown Heights, NY, United States","Dey S., Center for Computational Health, IBM T.J. Watson Research Center, 1101 Kitchawan Road, Yorktown Heights, NY, United States; Luo H., Center for Computational Health, IBM T.J. Watson Research Center, 1101 Kitchawan Road, Yorktown Heights, NY, United States; Fokoue A., Cognitive Computing, IBM T.J. Watson Research Center, 1101 Kitchawan Road, Yorktown Heights, NY, United States; Hu J., Center for Computational Health, IBM T.J. Watson Research Center, 1101 Kitchawan Road, Yorktown Heights, NY, United States; Zhang P., Center for Computational Health, IBM T.J. Watson Research Center, 1101 Kitchawan Road, Yorktown Heights, NY, United States","Background: Adverse drug reactions (ADRs) are unintended and harmful reactions caused by normal uses of drugs. Predicting and preventing ADRs in the early stage of the drug development pipeline can help to enhance drug safety and reduce financial costs. Methods: In this paper, we developed machine learning models including a deep learning framework which can simultaneously predict ADRs and identify the molecular substructures associated with those ADRs without defining the substructures a-priori. Results: We evaluated the performance of our model with ten different state-of-the-art fingerprint models and found that neural fingerprints from the deep learning model outperformed all other methods in predicting ADRs. Via feature analysis on drug structures, we identified important molecular substructures that are associated with specific ADRs and assessed their associations via statistical analysis. Conclusions: The deep learning model with feature analysis, substructure identification, and statistical assessment provides a promising solution for identifying risky components within molecular structures and can potentially help to improve drug safety evaluation. © 2018 The Author(s).","Adverse drug reaction; Chemical fingerprint; Deep learning","Area Under Curve; Back Pain; Deep Learning; Drug-Related Side Effects and Adverse Reactions; Humans; Models, Theoretical; Necrosis; Chemical analysis; Forecasting; Pharmacodynamics; Adverse drug reaction (ADRs); Adverse drug reactions; Chemical fingerprint; Drug development pipeline; Learning frameworks; Machine learning models; State of the art; Statistical assessment; adverse drug reaction; area under the curve; backache; human; necrosis; theoretical model; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","30591036","Article","Scopus","2-s2.0-85059247997"
"Gröhl J.; Kirchner T.; Adler T.; Maier-Hein L.","Gröhl, Janek (57191360550); Kirchner, Thomas (7102358573); Adler, Tim (57207918421); Maier-Hein, Lena (22634618600)","57191360550; 7102358573; 57207918421; 22634618600","Confidence estimation for machine learning-based quantitative photoacoustics","2018","Journal of Imaging","26","10.3390/jimaging4120147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063200239&doi=10.3390%2fjimaging4120147&partnerID=40&md5=4ea120e40d8934c366582ea6bead22a1","Division of Computer Assisted Medical Interventions (CAMI), German Cancer Research Center (DKFZ), Heidelberg, 69120, Germany; Medical Faculty, Heidelberg University, Heidelberg, 69120, Germany; Faculty of Physics and Astronomy, Heidelberg University, Heidelberg, 69120, Germany","Gröhl J., Division of Computer Assisted Medical Interventions (CAMI), German Cancer Research Center (DKFZ), Heidelberg, 69120, Germany, Medical Faculty, Heidelberg University, Heidelberg, 69120, Germany; Kirchner T., Division of Computer Assisted Medical Interventions (CAMI), German Cancer Research Center (DKFZ), Heidelberg, 69120, Germany, Faculty of Physics and Astronomy, Heidelberg University, Heidelberg, 69120, Germany; Adler T., Division of Computer Assisted Medical Interventions (CAMI), German Cancer Research Center (DKFZ), Heidelberg, 69120, Germany; Maier-Hein L., Division of Computer Assisted Medical Interventions (CAMI), German Cancer Research Center (DKFZ), Heidelberg, 69120, Germany, Medical Faculty, Heidelberg University, Heidelberg, 69120, Germany","In medical applications, the accuracy and robustness of imaging methods are of crucial importance to ensure optimal patient care. While photoacoustic imaging (PAI) is an emerging modality with promising clinical applicability, state-of-the-art approaches to quantitative photoacoustic imaging (qPAI), which aim to solve the ill-posed inverse problem of recovering optical absorption from the measurements obtained, currently cannot comply with these high standards. This can be attributed to the fact that existing methods often rely on several simplifying a priori assumptions of the underlying physical tissue properties or cannot deal with realistic noise levels. In this manuscript, we address this issue with a new method for estimating an indicator of the uncertainty of an estimated optical property. Specifically, our method uses a deep learning model to compute error estimates for optical parameter estimations of a qPAI algorithm. Functional tissue parameters, such as blood oxygen saturation, are usually derived by averaging over entire signal intensity-based regions of interest (ROIs). Therefore, we propose to reduce the systematic error of the ROI samples by additionally discarding those pixels for which our method estimates a high error and thus a low confidence. In silico experiments show an improvement in the accuracy of optical absorption quantification when applying our method to refine the ROI, and it might thus become a valuable tool for increasing the robustness of qPAI methods. © 2018 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license","Confidence learning; Deep learning; Error analysis; Quantitative photoacoustic imaging; Uncertainty estimation","Deep learning; Errors; Inverse problems; Medical imaging; Optical properties; Photoacoustic effect; Tissue; Uncertainty analysis; Confidence estimation; Confidence learning; Creative Commons; Deep learning; Machine-learning; Photo-acoustic imaging; Quantitative photoacoustic imaging; Region-of-interest; Regions of interest; Uncertainty estimation; Medical applications","MDPI","2313433X","","","","Article","Scopus","2-s2.0-85063200239"
"Zhang J.; Ding S.; Zhang N.","Zhang, Jian (56637434200); Ding, Shifei (24314525600); Zhang, Nan (56994194400)","56637434200; 24314525600; 56994194400","An overview on probability undirected graphs and their applications in image processing","2018","Neurocomputing","15","10.1016/j.neucom.2018.07.078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054051141&doi=10.1016%2fj.neucom.2018.07.078&partnerID=40&md5=80caffcbbf684e83f30e2b6e45f805f2","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China","Zhang J., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China; Ding S., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Zhang N., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China","This review aims to report recent developments about deep learning algorithms based on Restricted Boltzmann Machines (RBMs) and Conditional Random Fields (CRFs). Firstly, we give an overview of the general RBMs and CRFs, which are powerful methods for representing dependency of input data, and they can be treated as the basic blocks of deep neural nets as well. Secondly, this review introduces RBM variants and the deep learning models. Apart from the Deep Belief Networks (DBNs) and the Deep Boltzmann Machines (DBMs), the RBMs can be combined with the Convolutional Neural Nets (CNNs), which perform well in image recognition and image reconstruction. Thirdly, this review discusses CRFs and their applications in image annotation and scene recognition. Lastly, this review describes the developments and existing problems in neural nets and lists some experiments. © 2018","Classification; Conditional random field; Deep neural nets; Restricted Boltzmann machine","Classification (of information); Image recognition; Image reconstruction; Image segmentation; Learning algorithms; Neural networks; Random processes; Conditional random field; Conditional Random Fields(CRFs); Deep belief networks; Deep boltzmann machines; Deep neural nets; Existing problems; Restricted boltzmann machine; Scene recognition; article; image processing; image reconstruction; learning algorithm; machine; probability; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85054051141"
"Babu D.S.; Leelavathy N.; Rath R.; Varma M.V.S.","Babu, D. Satti (57525725900); Leelavathy, N. (57205747516); Rath, Ramakrushna (57223028596); Varma, M.V. Satish (58017426800)","57525725900; 57205747516; 57223028596; 58017426800","Recognition of object using improved features extracted from deep convolution network","2018","Indian Journal of Public Health Research and Development","2","10.5958/0976-5506.2018.02070.3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062940724&doi=10.5958%2f0976-5506.2018.02070.3&partnerID=40&md5=9371ee9c8cc874e044b0bc5a17122de1","Department of CSE, Godavari Institute of Engineering & Technology, Rajahmundry, A.P, India","Babu D.S., Department of CSE, Godavari Institute of Engineering & Technology, Rajahmundry, A.P, India; Leelavathy N., Department of CSE, Godavari Institute of Engineering & Technology, Rajahmundry, A.P, India; Rath R., Department of CSE, Godavari Institute of Engineering & Technology, Rajahmundry, A.P, India; Varma M.V.S., Department of CSE, Godavari Institute of Engineering & Technology, Rajahmundry, A.P, India","Object recognition will be a methodology uses a particular object done a picture. Object recognition calculations rely ahead matching learning is an example recognition calculations utilizing presence built alternately characteristic based strategies. Object recognition systems incorporate characteristic extraction Furthermore machine taking in models, profound taking in quest Likewise CNN. Profound taking in convolution neural system (CNN) need been demonstrated with be altogether compelling to characteristic extraction. CNN will be compacted for you quit offering on that one alternately All the more convolution layers et cetera emulated Eventually Tom’s perusing you quit offering on that one alternately that’s only the tip of the iceberg completelyjoined layers. To picture classification, the fill in with classifiers expects during exploring the greater part proper classifiers for large amount profound features. Those features concentrated starting with that picture assumes a paramount part in picture arrangement. Characteristic extraction will be the methodology for retrieving the imperative information from crude information. Characteristic extraction will be discovering those set of parameters that remember those item decisively Also particularly. Done characteristic extraction each character is spoken to toward a characteristic vector, which turns into its personality. Those real objective from claiming characteristic extraction is on extricate An situated about features, which expand those recognition rate.. In this work the features extracted from CNN applied as input to train machine learning classifiers and perform image classification. A systematic comparison between various classifiers is made for object recognition. © 2018, Indian Journal of Public Health Research and Development. All rights reserved.","Feature extraction; Machine learning; Neural networks; Object recognition","article; calculation; classifier; feature extraction; human; human experiment; iceberg; machine learning; personality; recognition","Institute of Medico-Legal Publications","09760245","","","","Article","Scopus","2-s2.0-85062940724"
"Zhang Z.; Chen L.; Humphries B.; Brien R.; Wicha M.S.; Luker K.E.; Luker G.D.; Chen Y.-C.; Yoon E.","Zhang, Zhixiong (56719046800); Chen, Lili (57140935300); Humphries, Brock (55758316500); Brien, Riley (57189376686); Wicha, Max S. (57203044772); Luker, Kathryn E. (7006008866); Luker, Gary D. (7004595443); Chen, Yu-Chih (52063090000); Yoon, Euisik (7102248055)","56719046800; 57140935300; 55758316500; 57189376686; 57203044772; 7006008866; 7004595443; 52063090000; 7102248055","Morphology-based prediction of cancer cell migration using an artificial neural network and a random decision forest","2018","Integrative Biology (United Kingdom)","28","10.1039/c8ib00106e","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058886945&doi=10.1039%2fc8ib00106e&partnerID=40&md5=88b2815f1d5711193ffb061ee4b2198e","Department of Electrical Engineering and Computer Science, University of Michigan, 1301 Beal Avenue, Ann Arbor, 48109-2122, MI, United States; Center for Molecular Imaging, Department of Radiology, University of Michigan, 109 Zina Pitcher Place, Ann Arbor, 48109-2200, MI, United States; Comprehensive Cancer Center, University of Michigan, 1500 E. Medical Center Drive, Ann Arbor, 48109, MI, United States; Forbes Institute for Cancer Discovery, University of Michigan, 2800 Plymouth Rd., Ann Arbor, 48109, MI, United States; Department of Microbiology and Immunology, University of Michigan, 109 Zina Pitcher Place, Ann Arbor, 48109-2200, MI, United States; Department of Biomedical Engineering, University of Michigan, 2200 Bonisteel, Blvd., Ann Arbor, 48109-2099, MI, United States","Zhang Z., Department of Electrical Engineering and Computer Science, University of Michigan, 1301 Beal Avenue, Ann Arbor, 48109-2122, MI, United States; Chen L., Department of Electrical Engineering and Computer Science, University of Michigan, 1301 Beal Avenue, Ann Arbor, 48109-2122, MI, United States; Humphries B., Center for Molecular Imaging, Department of Radiology, University of Michigan, 109 Zina Pitcher Place, Ann Arbor, 48109-2200, MI, United States; Brien R., Department of Electrical Engineering and Computer Science, University of Michigan, 1301 Beal Avenue, Ann Arbor, 48109-2122, MI, United States; Wicha M.S., Comprehensive Cancer Center, University of Michigan, 1500 E. Medical Center Drive, Ann Arbor, 48109, MI, United States, Forbes Institute for Cancer Discovery, University of Michigan, 2800 Plymouth Rd., Ann Arbor, 48109, MI, United States; Luker K.E., Center for Molecular Imaging, Department of Radiology, University of Michigan, 109 Zina Pitcher Place, Ann Arbor, 48109-2200, MI, United States; Luker G.D., Center for Molecular Imaging, Department of Radiology, University of Michigan, 109 Zina Pitcher Place, Ann Arbor, 48109-2200, MI, United States, Comprehensive Cancer Center, University of Michigan, 1500 E. Medical Center Drive, Ann Arbor, 48109, MI, United States, Department of Microbiology and Immunology, University of Michigan, 109 Zina Pitcher Place, Ann Arbor, 48109-2200, MI, United States, Department of Biomedical Engineering, University of Michigan, 2200 Bonisteel, Blvd., Ann Arbor, 48109-2099, MI, United States; Chen Y.-C., Department of Electrical Engineering and Computer Science, University of Michigan, 1301 Beal Avenue, Ann Arbor, 48109-2122, MI, United States, Comprehensive Cancer Center, University of Michigan, 1500 E. Medical Center Drive, Ann Arbor, 48109, MI, United States, Forbes Institute for Cancer Discovery, University of Michigan, 2800 Plymouth Rd., Ann Arbor, 48109, MI, United States; Yoon E., Department of Electrical Engineering and Computer Science, University of Michigan, 1301 Beal Avenue, Ann Arbor, 48109-2122, MI, United States, Department of Biomedical Engineering, University of Michigan, 2200 Bonisteel, Blvd., Ann Arbor, 48109-2099, MI, United States","Metastasis is the cause of death in most patients of breast cancer and other solid malignancies. Identification of cancer cells with highly migratory capability to metastasize relies on markers for epithelial-to-mesenchymal transition (EMT), a process increasing cell migration and metastasis. Marker-based approaches are limited by inconsistences among patients, types of cancer, and partial EMT states. Alternatively, we analyzed cancer cell migration behavior using computer vision. Using a microfluidic single-cell migration chip and high-content imaging, we extracted morphological features and recorded migratory direction and speed of breast cancer cells. By applying a Random Decision Forest (RDF) and an Artificial Neural Network (ANN), we achieved over 99% accuracy for cell movement direction prediction and 91% for speed prediction. Unprecedentedly, we identified highly motile cells and non-motile cells based on microscope images and a machine learning model, and pinpointed and validated morphological features determining cell migration, including not only known features related to cell polarization but also novel ones that can drive future mechanistic studies. Predicting cell movement by computer vision and machine learning establishes a ground-breaking approach to analyze cell migration and metastasis. © The Royal Society of Chemistry.","","Algorithms; Animals; Breast Neoplasms; Cell Line, Tumor; Cell Movement; Decision Support Techniques; Deep Learning; Epithelial-Mesenchymal Transition; Female; Humans; Lab-On-A-Chip Devices; Mice; Models, Biological; Neoplasm Metastasis; Neoplasms; Neural Networks (Computer); Reproducibility of Results; Single-Cell Analysis; algorithm; animal; artificial neural network; biological model; breast tumor; cell motion; decision support system; epithelial mesenchymal transition; female; human; lab on a chip; metastasis; mouse; neoplasm; pathology; reproducibility; single cell analysis; tumor cell line","Royal Society of Chemistry","17579694","","","30420987","Article","Scopus","2-s2.0-85058886945"
"Streefland M.B.","Streefland, Mariette Boerstoel (57204576973)","57204576973","Why Are We Still Creating Individual Case Safety Reports?","2018","Clinical Therapeutics","10","10.1016/j.clinthera.2018.10.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056243992&doi=10.1016%2fj.clinthera.2018.10.012&partnerID=40&md5=dc3261078e25fc59d53f01bc18816225","Alexion Pharmaceuticals, Inc., United States","Streefland M.B., Alexion Pharmaceuticals, Inc., United States","The history of drug safety monitoring, or pharmacovigilance, has been an interesting one. Despite many and ongoing changes, it has typically been characterized by a rather slow-moving and reactive progression. Pharmacovigilance has always lagged behind other fields and industries and has been slow to adapt to new approaches. The main aspect holding it back has been a focus on the administrative and adherence side of creating individual case safety reports (ICSRs) and distributing these reports to the various stakeholders per strict regulatory requirements. Now, in 2018, we are more behind the curve than ever, and the field seems to be at a breaking point, calling for urgent and drastic changes. The question at hand is whether in this era of an abundance of electronically available data and technological advancements, which allow the application of automation, this process still makes sense. Is there still a place for creating and redistributing ICSRs from marketed use in a current, state-of-the-art safety system? Artificial intelligence, deep machine learning, and related technologies are already in place in many other industries. Swift and rigorous change is necessary for the discipline of pharmacovigilance to keep up with what is happening in the world at large. © 2018 Elsevier Inc.","adverse event reporting; case processing; drug safety; drug safety profiles; individual case safety reports; information technology; pharmacovigilance","Adverse Drug Reaction Reporting Systems; Humans; Pharmacovigilance; Article; case report; drug safety; drug surveillance program; human; medical history","Excerpta Medica Inc.","01492918","","CLTHD","30420290","Article","Scopus","2-s2.0-85056243992"
"Hayashi Y.; Matsumoto J.; Kumagai S.; Morishita K.; Xiang L.; Kobori Y.; Hori S.; Suzuki M.; Kanamori T.; Hotta K.; Sumaru K.","Hayashi, Yohei (56584780900); Matsumoto, Junichi (57210640881); Kumagai, Shohei (55557786900); Morishita, Kana (55340444700); Xiang, Long (57014282000); Kobori, Yohei (57210641893); Hori, Seiji (57210646859); Suzuki, Masami (57210635231); Kanamori, Toshiyuki (55851670500); Hotta, Kazuhiro (8981361800); Sumaru, Kimio (6603955963)","56584780900; 57210640881; 55557786900; 55340444700; 57014282000; 57210641893; 57210646859; 57210635231; 55851670500; 8981361800; 6603955963","Automated adherent cell elimination by a high-speed laser mediated by a light-responsive polymer","2018","Communications Biology","6","10.1038/s42003-018-0222-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071157315&doi=10.1038%2fs42003-018-0222-4&partnerID=40&md5=c79cf8d4f438bd9a8d5335dc22b8ade9","iPS Cell Advanced Characterization and Development Team, RIKEN Bioresource Research Center, 3-1-1 Koyadai, Tsukuba, 305-0074, Ibaraki, Japan; Kataoka Corporation, 140 Tsukiyama-cho, Kuze, Minami-ku, 601-8203, Kyoto, Japan; Meijo University, 1-501 Shiogamaguchi, Tenpaku, 468-8502, Nagoya, Japan; Biotechnology Research Institute for Drug Discovery, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba Central 5th, 1-1-1 Higashi, Tsukuba, 305-8565, Ibaraki, Japan; iPS Portal, Inc., 448-5 Kajii-cho, Kamigyo-ku, 602-0841, Kyoto, Japan","Hayashi Y., iPS Cell Advanced Characterization and Development Team, RIKEN Bioresource Research Center, 3-1-1 Koyadai, Tsukuba, 305-0074, Ibaraki, Japan; Matsumoto J., Kataoka Corporation, 140 Tsukiyama-cho, Kuze, Minami-ku, 601-8203, Kyoto, Japan; Kumagai S., Meijo University, 1-501 Shiogamaguchi, Tenpaku, 468-8502, Nagoya, Japan; Morishita K., Biotechnology Research Institute for Drug Discovery, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba Central 5th, 1-1-1 Higashi, Tsukuba, 305-8565, Ibaraki, Japan; Xiang L., iPS Portal, Inc., 448-5 Kajii-cho, Kamigyo-ku, 602-0841, Kyoto, Japan; Kobori Y., iPS Portal, Inc., 448-5 Kajii-cho, Kamigyo-ku, 602-0841, Kyoto, Japan; Hori S., iPS Portal, Inc., 448-5 Kajii-cho, Kamigyo-ku, 602-0841, Kyoto, Japan; Suzuki M., Kataoka Corporation, 140 Tsukiyama-cho, Kuze, Minami-ku, 601-8203, Kyoto, Japan; Kanamori T., Biotechnology Research Institute for Drug Discovery, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba Central 5th, 1-1-1 Higashi, Tsukuba, 305-8565, Ibaraki, Japan; Hotta K., Meijo University, 1-501 Shiogamaguchi, Tenpaku, 468-8502, Nagoya, Japan; Sumaru K., Biotechnology Research Institute for Drug Discovery, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba Central 5th, 1-1-1 Higashi, Tsukuba, 305-8565, Ibaraki, Japan","Conventional cell handling and sorting methods require manual labor, which decreases both cell quality and quantity. To purify adherent cultured cells, cell purification technologies that are high throughput without dissociation and can be utilized in an on-demand manner are expected. Here, we developed a Laser-induced, Light-responsive-polymer-Activated, Cell Killing (LiLACK) system that enables high-speed and on-demand adherent cell sectioning and purification. This system employs a visible laser beam, which does not kill cells directly, but induces local heat production through the trans-cis-trans photo-isomerization of azobenzene moieties. Using this system in each passage for sectioning, human induced pluripotent stem cells (hiPSCs) maintained their pluripotency and self-renewal during long-term culture. Furthermore, combined with deep machine-learning analysis on fluorescent and phase contrast images, a label-free and automatic cell processing system has been developed by eliminating unwanted spontaneously differentiated cells in undifferentiated hiPSC culture conditions. © 2018, The Author(s).","","","Nature Research","23993642","","","","Article","Scopus","2-s2.0-85071157315"
"Wozniak J.M.; Jain R.; Balaprakash P.; Ozik J.; Collier N.T.; Bauer J.; Xia F.; Brettin T.; Stevens R.; Mohd-Yusof J.; Cardona C.G.; Essen B.V.; Baughman M.","Wozniak, Justin M. (8900976900); Jain, Rajeev (57198836726); Balaprakash, Prasanna (15073878200); Ozik, Jonathan (6506796192); Collier, Nicholson T. (16041252300); Bauer, John (57205178026); Xia, Fangfang (15761155800); Brettin, Thomas (34976299400); Stevens, Rick (57221587276); Mohd-Yusof, Jamaludin (6505851438); Cardona, Cristina Garcia (55200807700); Essen, Brian Van (18038810700); Baughman, Matthew (57202993030)","8900976900; 57198836726; 15073878200; 6506796192; 16041252300; 57205178026; 15761155800; 34976299400; 57221587276; 6505851438; 55200807700; 18038810700; 57202993030","CANDLE/Supervisor: A workflow framework for machine learning applied to cancer research","2018","BMC Bioinformatics","47","10.1186/s12859-018-2508-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058909711&doi=10.1186%2fs12859-018-2508-4&partnerID=40&md5=4fa9966d6ee78af5b3ad553e18f96d8f","Argonne National Laboratory, Argonne, IL, United States; Los Alamos National Laboratory, Los Alamos, NM, United States; Lawrence Livermore National Laboratory, Livermore, CA, United States; Minerva, San Francisco, CA, United States","Wozniak J.M., Argonne National Laboratory, Argonne, IL, United States; Jain R., Argonne National Laboratory, Argonne, IL, United States; Balaprakash P., Argonne National Laboratory, Argonne, IL, United States; Ozik J., Argonne National Laboratory, Argonne, IL, United States; Collier N.T., Argonne National Laboratory, Argonne, IL, United States; Bauer J., Argonne National Laboratory, Argonne, IL, United States; Xia F., Argonne National Laboratory, Argonne, IL, United States; Brettin T., Argonne National Laboratory, Argonne, IL, United States; Stevens R., Argonne National Laboratory, Argonne, IL, United States; Mohd-Yusof J., Los Alamos National Laboratory, Los Alamos, NM, United States; Cardona C.G., Los Alamos National Laboratory, Los Alamos, NM, United States; Essen B.V., Lawrence Livermore National Laboratory, Livermore, CA, United States; Baughman M., Minerva, San Francisco, CA, United States","Background: Current multi-petaflop supercomputers are powerful systems, but present challenges when faced with problems requiring large machine learning workflows. Complex algorithms running at system scale, often with different patterns that require disparate software packages and complex data flows cause difficulties in assembling and managing large experiments on these machines. Results: This paper presents a workflow system that makes progress on scaling machine learning ensembles, specifically in this first release, ensembles of deep neural networks that address problems in cancer research across the atomistic, molecular and population scales. The initial release of the application framework that we call CANDLE/Supervisor addresses the problem of hyper-parameter exploration of deep neural networks. Conclusions: Initial results demonstrating CANDLE on DOE systems at ORNL, ANL and NERSC (Titan, Theta and Cori, respectively) demonstrate both scaling and multi-platform execution. © 2018 The Author(s).","Article; Author; Sample","Early Detection of Cancer; Humans; Machine Learning; Neoplasms; Neural Networks (Computer); Workflow; Artificial intelligence; Complex networks; Data flow analysis; Diseases; Enterprise resource management; Sampling; Supercomputers; Application frameworks; Article; Author; Cancer research; Complex algorithms; Hyper-parameter; Powerful systems; Work-flow systems; article; cancer research; human; machine learning; workflow; artificial neural network; early cancer diagnosis; machine learning; neoplasm; pathology; procedures; trends; workflow; Deep neural networks","BioMed Central Ltd.","14712105","","BBMIC","30577736","Article","Scopus","2-s2.0-85058909711"
"Montesinos-López O.A.; Montesinos-López A.; Crossa J.; Gianola D.; Hernández-Suárez C.M.; Martín-Vallejo J.","Montesinos-López, Osval A. (16233976300); Montesinos-López, Abelardo (36104391100); Crossa, José (7003797730); Gianola, Daniel (7006290311); Hernández-Suárez, Carlos M. (6603175577); Martín-Vallejo, Javier (6507140476)","16233976300; 36104391100; 7003797730; 7006290311; 6603175577; 6507140476","Multi-trait, multi-environment deep learning modeling for genomic-enabled prediction of plant traits","2018","G3: Genes, Genomes, Genetics","90","10.1534/g3.118.200728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058157750&doi=10.1534%2fg3.118.200728&partnerID=40&md5=a46cf06050928d35421652bf669e0ce4","Facultad de Telemática, Universidad de Colima, Colima, Colima, 28040, Mexico; Departamento de Matemáticas, Centro Universitario de Ciencias Exactas e Ingenierías (CUCEI), Universidad de Guadalajara, Guadalajara, Jalisco, 44430, Mexico; Biometrics and Statistics Unit, Genetic Resources Program, International Maize and Wheat Improvement Center (CIMMYT), Apdo. Postal 6-641, Ciudad de México, 06600, Mexico; Departments of Animal Sciences, Dairy Science, and Biostatistics and Medical Informatics, University of Wisconsin-Madison, Madison, 53706, WI, United States; Facultad de Ciencias, Universidad de Colima, Colima, Colima, 28040, Mexico; Departamento de Estadística, Universidad de Salamanca, c/Espejo 2, Salamanca, 37007, Spain","Montesinos-López O.A., Facultad de Telemática, Universidad de Colima, Colima, Colima, 28040, Mexico; Montesinos-López A., Departamento de Matemáticas, Centro Universitario de Ciencias Exactas e Ingenierías (CUCEI), Universidad de Guadalajara, Guadalajara, Jalisco, 44430, Mexico; Crossa J., Biometrics and Statistics Unit, Genetic Resources Program, International Maize and Wheat Improvement Center (CIMMYT), Apdo. Postal 6-641, Ciudad de México, 06600, Mexico; Gianola D., Departments of Animal Sciences, Dairy Science, and Biostatistics and Medical Informatics, University of Wisconsin-Madison, Madison, 53706, WI, United States; Hernández-Suárez C.M., Facultad de Ciencias, Universidad de Colima, Colima, Colima, 28040, Mexico; Martín-Vallejo J., Departamento de Estadística, Universidad de Salamanca, c/Espejo 2, Salamanca, 37007, Spain","Multi-trait and multi-environment data are common in animal and plant breeding programs. However, what is lacking are more powerful statistical models that can exploit the correlation between traits to improve prediction accuracy in the context of genomic selection (GS). Multi-trait models are more complex than univariate models and usually require more computational resources, but they are preferred because they can exploit the correlation between traits, which many times helps improve prediction accuracy. For this reason, in this paper we explore the power of multi-trait deep learning (MTDL) models in terms of prediction accuracy. The prediction performance ofMTDL models was compared to the performance of the Bayesian multi-trait and multienvironment (BMTME) model proposed by Montesinos-López et al. (2016), which is a multi-trait version of the genomic best linear unbiased prediction (GBLUP) univariate model. Both models were evaluated with predictors with and without the genotype environment interaction term. The prediction performance of both models was evaluated in terms of Pearson's correlation using cross-validation. We found that the best predictions in two of the three data sets were found under the BMTME model, but in general the predictions of both models, BTMTE and MTDL, were similar. Among models without the genotype environment interaction, the MTDL model was the best, while among models with genotype environment interaction, the BMTME model was superior. These results indicate that the MTDL model is very competitive for performing predictions in the context of GS, with the important practical advantage that it requires less computational resources than the BMTME model. © 2018 Montesinos-López et al.","Bayesian modelling; deep learning multi-trait multienvironment genomic prediction plant breeding; GenPred; Resources; Shared Data","Gene-Environment Interaction; Genome, Plant; Machine Learning; Models, Genetic; Sequence Analysis, DNA; Triticum; Zea mays; article; genotype environment interaction; learning; plant breeding; prediction; validation process; biological model; DNA sequence; genetics; machine learning; maize; plant genome; procedures; wheat","Genetics Society of America","21601836","","","30291108","Article","Scopus","2-s2.0-85058157750"
"Abatemarco D.; Perera S.; Bao S.H.; Desai S.; Assuncao B.; Tetarenko N.; Danysz K.; Mockute R.; Widdowson M.; Fornarotto N.; Beauchamp S.; Cicirello S.; Mingle E.","Abatemarco, Danielle (57204478707); Perera, Sujan (55503585500); Bao, Sheng Hua (57204811158); Desai, Sameen (57204476848); Assuncao, Bruno (57204480527); Tetarenko, Niki (57204477462); Danysz, Karolina (57204479166); Mockute, Ruta (57204480983); Widdowson, Mark (57204476923); Fornarotto, Nicole (57204798189); Beauchamp, Sheryl (58450493100); Cicirello, Salvatore (57204481156); Mingle, Edward (57204479282)","57204478707; 55503585500; 57204811158; 57204476848; 57204480527; 57204477462; 57204479166; 57204480983; 57204476923; 57204798189; 58450493100; 57204481156; 57204479282","Training Augmented Intelligent Capabilities for Pharmacovigilance: Applying Deep-learning Approaches to Individual Case Safety Report Processing","2018","Pharmaceutical Medicine","15","10.1007/s40290-018-0251-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057277215&doi=10.1007%2fs40290-018-0251-9&partnerID=40&md5=96cbb41af3191509dbc3dea0352a7b53","Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; IBM Watson Health, 75 Binney Street, Cambridge, 02142, MA, United States","Abatemarco D., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Perera S., IBM Watson Health, 75 Binney Street, Cambridge, 02142, MA, United States; Bao S.H., IBM Watson Health, 75 Binney Street, Cambridge, 02142, MA, United States; Desai S., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Assuncao B., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Tetarenko N., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Danysz K., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Mockute R., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Widdowson M., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Fornarotto N., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Beauchamp S., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Cicirello S., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States; Mingle E., Celgene Corporation, 86 Morris Avenue, Summit, 07901, NJ, United States","Introduction: Regulations are increasing the scope of activities that fall under the remit of drug safety. Currently, individual case safety report (ICSR) collection and collation is done manually, requiring pharmacovigilance professionals to perform many transactional activities before data are available for assessment and aggregated analyses. For a biopharmaceutical company to meet its responsibilities to patients and regulatory bodies regarding the safe use and distribution of its products, improved business processes must be implemented to drive the industry forward in the best interest of patients globally. Augmented intelligent capabilities have already demonstrated success in capturing adverse events from diverse data sources. It has potential to provide a scalable solution for handling the ever-increasing ICSR volumes experienced within the industry by supporting pharmacovigilance professionals’ decision-making. Objective: The aim of this study was to train and evaluate a consortium of cognitive services to identify key characteristics of spontaneous ICSRs satisfying an acceptable level of accuracy determined by considering business requirements and effective use in a real-world setting. The results of this study will serve as supporting evidence for or against implementing augmented intelligence in case processing to increase operational efficiency and data quality consistency. Methods: A consortium of ten cognitive services to augment aspects of ICSR processing were identified and trained through deep-learning approaches. The input data for model training were 20,000 ICSRs received by Celgene drug safety over a 2-year period. The data were manually made machine-readable through the process of transcription, which converts images into text. The machine-readable documents were manually annotated for pharmacovigilance data elements to facilitate the training and testing of the cognitive services. Once trained by cognitive developers, the cognitive services’ output was reviewed by pharmacovigilance subject-matter experts against the accepted ground-truth for correctness and completeness. To be considered adequately trained and functional, each cognitive service was required to reach a threshold of F1 or accuracy score ≥ 75%. Results: All ten cognitive services under development have reached an evaluative score ≥ 75% for spontaneous ICSRs. Conclusion: All cognitive services under development have achieved the minimum evaluative threshold to be considered adequately trained, demonstrating how machine-learning and natural language processing techniques together provide accurate outputs that may augment pharmacovigilance professionals’ processing of spontaneous ICSRs quickly and accurately. The intention of augmented intelligence is not to replace the pharmacovigilance professional, but rather support them in their consistent decision-making so that they may better handle the overwhelming amount of data otherwise manually curated and monitored for ongoing drug surveillance requirements. Through this supported decision-making, pharmacovigilance professionals may have more time to apply their knowledge in assessing the case rather than spending it performing transactional tasks to simply capture the pertinent data within a safety database. By capturing data consistently and efficiently, we begin to build a corpus of data upon which analyses may be conducted and insights gleaned. Cognitive services may be key to an organization’s transformation to more proactive decision-making needed to meet regulatory requirements and enhance patient safety. © 2018, The Author(s).","","Article; causality; cognition; drug surveillance program; human; intelligence; intelligence quotient; learning algorithm; machine learning; medical decision making; natural language processing; patient safety; practice guideline; priority journal; standardization; task performance; training","Springer International Publishing","11782595","","","","Article","Scopus","2-s2.0-85057277215"
"Waldmann P.","Waldmann, Patrik (6603822225)","6603822225","Approximate Bayesian neural networks in genomic prediction","2018","Genetics Selection Evolution","36","10.1186/s12711-018-0439-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058915705&doi=10.1186%2fs12711-018-0439-1&partnerID=40&md5=1e5acf92cc5d2256e473018a8ef2d2ac","Department of Animal Breeding and Genetics, Swedish University of Agricultural Sciences (SLU), Box 7023, Uppsala, 750 07, Sweden","Waldmann P., Department of Animal Breeding and Genetics, Swedish University of Agricultural Sciences (SLU), Box 7023, Uppsala, 750 07, Sweden","Background: Genome-wide marker data are used both in phenotypic genome-wide association studies (GWAS) and genome-wide prediction (GWP). Typically, such studies include high-dimensional data with thousands to millions of single nucleotide polymorphisms (SNPs) recorded in hundreds to a few thousands individuals. Different machine-learning approaches have been used in GWAS and GWP effectively, but the use of neural networks (NN) and deep-learning is still scarce. This study presents a NN model for genomic SNP data. Results: We show, using both simulated and real pig data, that regularization is obtained using weight decay and dropout, and results in an approximate Bayesian (ABNN) model that can be used to obtain model averaged posterior predictions. The ABNN model is implemented in mxnet and shown to yield better prediction accuracy than genomic best linear unbiased prediction and Bayesian LASSO. The mean squared error was reduced by at least 6.5% in the simulated data and by at least 1% in the real data. Moreover, by comparing NN of different complexities, our results confirm that a shallow model with one layer, one neuron, one-hot encoding and a linear activation function performs better than more complex models. Conclusions: The ABNN model provides a computationally efficient approach with good prediction performance and in which the weight components can also provide information on the importance of the SNPs. Hence, ABNN is suitable for both GWP and GWAS. © 2018 The Author(s).","","Algorithms; Animals; Bayes Theorem; Computer Simulation; Genome; Genome-Wide Association Study; Genomics; Machine Learning; Models, Genetic; Neural Networks (Computer); Polymorphism, Single Nucleotide; Sequence Analysis, DNA; Swine; Suidae; accuracy assessment; artificial neural network; Bayesian analysis; genetic marker; genomics; machine learning; numerical model; performance assessment; prediction; algorithm; animal; artificial neural network; Bayes theorem; biological model; computer simulation; DNA sequence; genetics; genome; genome-wide association study; genomics; machine learning; pig; procedures; single nucleotide polymorphism","BioMed Central Ltd.","0999193X","","GSEVE","30577737","Article","Scopus","2-s2.0-85058915705"
"Kwon H.; Kim Y.; Yoon H.; Choi D.","Kwon, Hyun (57197769092); Kim, Yongchul (55699558400); Yoon, Hyunsoo (15061371300); Choi, Daeseon (8660876600)","57197769092; 55699558400; 15061371300; 8660876600","Random untargeted adversarial example on Deep neural network","2018","Symmetry","17","10.3390/sym10120738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059017272&doi=10.3390%2fsym10120738&partnerID=40&md5=a4f017262c7b0b191f7df75141f4506d","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Department of Electrical Engineering, Korea Military Academy, Seoul, 01805, South Korea; Department of Medical Information, Kongju National University, Gongju-si, 32588, South Korea; KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 305-701, South Korea","Kwon H., School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 305-701, South Korea; Kim Y., Department of Electrical Engineering, Korea Military Academy, Seoul, 01805, South Korea; Yoon H., School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Choi D., Department of Medical Information, Kongju National University, Gongju-si, 32588, South Korea","Deep neural networks (DNNs) have demonstrated remarkable performance in machine learning areas such as image recognition, speech recognition, intrusion detection, and pattern analysis. However, it has been revealed that DNNs have weaknesses in the face of adversarial examples, which are created by adding a little noise to an original sample to cause misclassification by the DNN. Such adversarial examples can lead to fatal accidents in applications such as autonomous vehicles and disease diagnostics. Thus, the generation of adversarial examples has attracted extensive research attention recently. An adversarial example is categorized as targeted or untargeted. In this paper, we focus on the untargeted adversarial example scenario because it has a faster learning time and less distortion compared with the targeted adversarial example. However, there is a pattern vulnerability with untargeted adversarial examples: Because of the similarity between the original class and certain specific classes, it may be possible for the defending system to determine the original class by analyzing the output classes of the untargeted adversarial examples. To overcome this problem, we propose a new method for generating untargeted adversarial examples, one that uses an arbitrary class in the generation process. Moreover, we show that our proposed scheme can be applied to steganography. Through experiments, we show that our proposed scheme can achieve a 100% attack success rate with minimum distortion (1.99 and 42.32 using the MNIST and CIFAR10 datasets, respectively) and without the pattern vulnerability. Using a steganography test, we show that our proposed scheme can be used to fool humans, as demonstrated by the probability of their detecting hidden classes being equal to that of random selection. © 2018 by the authors.","Adversarial example; Deep neural network; Random selection; Untargeted adversarial example","","MDPI AG","20738994","","","","Article","Scopus","2-s2.0-85059017272"
"Khan A.; Liu Q.; Wang K.","Khan, Atlas (57201734888); Liu, Qian (57195133713); Wang, Kai (55547129985)","57201734888; 57195133713; 55547129985","iMEGES: Integrated mental-disorder GEnome score by deep neural network for prioritizing the susceptibility genes for mental disorders in personal genomes","2018","BMC Bioinformatics","10","10.1186/s12859-018-2469-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059227013&doi=10.1186%2fs12859-018-2469-7&partnerID=40&md5=4453f02cc4d9c841ac22dcbaf836374f","Columbia University, Division of Nephrology, Department of Medicine, College of Physicians and Surgeons, New York, 10032, NY, United States; Children's Hospital of Philadelphia, Raymond G. Perelman Center for Cellular and Molecular Therapeutics, Philadelphia, 19104, PA, United States; University of Pennsylvania Perelman School of Medicine, Department of Pathology and Laboratory Medicine, Philadelphia, 19104, PA, United States","Khan A., Columbia University, Division of Nephrology, Department of Medicine, College of Physicians and Surgeons, New York, 10032, NY, United States; Liu Q., Children's Hospital of Philadelphia, Raymond G. Perelman Center for Cellular and Molecular Therapeutics, Philadelphia, 19104, PA, United States; Wang K., Children's Hospital of Philadelphia, Raymond G. Perelman Center for Cellular and Molecular Therapeutics, Philadelphia, 19104, PA, United States, University of Pennsylvania Perelman School of Medicine, Department of Pathology and Laboratory Medicine, Philadelphia, 19104, PA, United States","Background: A range of rare and common genetic variants have been discovered to be potentially associated with mental diseases, but many more have not been uncovered. Powerful integrative methods are needed to systematically prioritize both variants and genes that confer susceptibility to mental diseases in personal genomes of individual patients and to facilitate the development of personalized treatment or therapeutic approaches. Methods: Leveraging deep neural network on the TensorFlow framework, we developed a computational tool, integrated Mental-disorder GEnome Score (iMEGES), for analyzing whole genome/exome sequencing data on personal genomes. iMEGES takes as input genetic mutations and phenotypic information from a patient with mental disorders, and outputs the rank of whole genome susceptibility variants and the prioritized disease-specific genes for mental disorders by integrating contributions from coding and non-coding variants, structural variants (SVs), known brain expression quantitative trait loci (eQTLs), and epigenetic information from PsychENCODE. Results: iMEGES was evaluated on multiple datasets of mental disorders, and it achieved improved performance than competing approaches when large training dataset is available. Conclusion: iMEGES can be used in population studies to help the prioritization of novel genes or variants that might be associated with the susceptibility to mental disorders, and also on individual patients to help the identification of genes or variants related to mental diseases. © 2018 The Author(s).","Deep neural network; Machine learning; Mental disorders; Personal genome; Single nucleotide variants (SNVs); Structural variants (SVs)","Area Under Curve; Databases, Genetic; Deep Learning; Genetic Predisposition to Disease; Genome, Human; Humans; Mental Disorders; Neural Networks (Computer); Polymorphism, Single Nucleotide; Software; Gene expression; Gene therapy; Learning systems; Patient treatment; Computational tools; Mental disorders; Personal genomes; Population studies; Quantitative trait locus; Single nucleotides; Structural variants (SVs); Susceptibility genes; area under the curve; artificial neural network; genetic database; genetic predisposition; genetics; human; human genome; mental disease; single nucleotide polymorphism; software; Deep neural networks","BioMed Central Ltd.","14712105","","BBMIC","30591030","Article","Scopus","2-s2.0-85059227013"
"Couture H.D.; Williams L.A.; Geradts J.; Nyante S.J.; Butler E.N.; Marron J.S.; Perou C.M.; Troester M.A.; Niethammer M.","Couture, Heather D. (56495230100); Williams, Lindsay A. (56819601400); Geradts, Joseph (7005254839); Nyante, Sarah J. (23467471800); Butler, Ebonee N. (24512206500); Marron, J.S. (35411635500); Perou, Charles M. (7003834979); Troester, Melissa A. (57203104364); Niethammer, Marc (6701819640)","56495230100; 56819601400; 7005254839; 23467471800; 24512206500; 35411635500; 7003834979; 57203104364; 6701819640","Image analysis with deep learning to predict breast cancer grade, ER status, histologic subtype, and intrinsic subtype","2018","npj Breast Cancer","175","10.1038/s41523-018-0079-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056823491&doi=10.1038%2fs41523-018-0079-1&partnerID=40&md5=1c77f47465ac1a6e26409abca170ab9e","Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Department of Epidemiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Department of Pathology, Dana-Farber Cancer Institute, Boston, 02115, MA, United States; Department of Radiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Lineberger Comprehensive Cancer Center, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Department of Statistics and Operations Research, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Department of Genetics, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States","Couture H.D., Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Williams L.A., Department of Epidemiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Geradts J., Department of Pathology, Dana-Farber Cancer Institute, Boston, 02115, MA, United States; Nyante S.J., Department of Radiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Butler E.N., Department of Epidemiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Marron J.S., Lineberger Comprehensive Cancer Center, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States, Department of Statistics and Operations Research, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Perou C.M., Lineberger Comprehensive Cancer Center, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States, Department of Genetics, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Troester M.A., Department of Epidemiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States, Lineberger Comprehensive Cancer Center, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Niethammer M., Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States, Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States","RNA-based, multi-gene molecular assays are available and widely used for patients with ER-positive/HER2-negative breast cancers. However, RNA-based genomic tests can be costly and are not available in many countries. Methods for inferring molecular subtype from histologic images may identify patients most likely to benefit from further genomic testing. To identify patients who could benefit from molecular testing based on H&E stained histologic images, we developed an image analysis approach using deep learning. A training set of 571 breast tumors was used to create image-based classifiers for tumor grade, ER status, PAM50 intrinsic subtype, histologic subtype, and risk of recurrence score (ROR-PT). The resulting classifiers were applied to an independent test set (n = 288), and accuracy, sensitivity, and specificity of each was assessed on the test set. Histologic image analysis with deep learning distinguished low-intermediate vs. high tumor grade (82% accuracy), ER status (84% accuracy), Basal-like vs. non-Basal-like (77% accuracy), Ductal vs. Lobular (94% accuracy), and high vs. low-medium ROR-PT score (75% accuracy). Sampling considerations in the training set minimized bias in the test set. Incorrect classification of ER status was significantly more common for Luminal B tumors. These data provide proof of principle that molecular marker status, including a critical clinical biomarker (i.e., ER status), can be predicted with accuracy >75% based on H&E features. Image-based methods could be promising for identifying patients with a greater need for further genomic testing, or in place of classically scored variables typically accomplished using human-based scoring. © 2018, The Author(s).","","estrogen receptor; adult; aged; Article; breast cancer; cancer grading; cancer recurrence; cancer risk; controlled study; deep learning; diagnostic accuracy; female; human; image analysis; image processing; machine learning; major clinical study; prediction; priority journal; scoring system; sensitivity and specificity; support vector machine; tissue microarray","Nature Publishing Group","23744677","","","","Article","Scopus","2-s2.0-85056823491"
"Tong C.; Liang B.; Li J.; Zheng Z.","Tong, Chao (56669274500); Liang, Baoyu (57204539783); Li, Jun (57841251500); Zheng, Zhigao (57191615965)","56669274500; 57204539783; 57841251500; 57191615965","A Deep Automated Skeletal Bone Age Assessment Model with Heterogeneous Features Learning","2018","Journal of Medical Systems","33","10.1007/s10916-018-1091-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056064131&doi=10.1007%2fs10916-018-1091-6&partnerID=40&md5=d5313ad2531b43b2d397abb7bea71d8b","School of Computer Science and Engineering, Beihang, Beijing, 100191, China; National Engineering Laboratory for Internet Medical Systems and Applications, The First Affiliated Hospital of Zhengzhou University, Zhengzhou, 450052, Henan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China","Tong C., School of Computer Science and Engineering, Beihang, Beijing, 100191, China, National Engineering Laboratory for Internet Medical Systems and Applications, The First Affiliated Hospital of Zhengzhou University, Zhengzhou, 450052, Henan, China; Liang B., School of Computer Science and Engineering, Beihang, Beijing, 100191, China, National Engineering Laboratory for Internet Medical Systems and Applications, The First Affiliated Hospital of Zhengzhou University, Zhengzhou, 450052, Henan, China; Li J., School of Computer Science and Engineering, Beihang, Beijing, 100191, China, National Engineering Laboratory for Internet Medical Systems and Applications, The First Affiliated Hospital of Zhengzhou University, Zhengzhou, 450052, Henan, China; Zheng Z., School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China","Skeletal bone age assessment is a widely used standard procedure in both disease detection and growth prediction for children in endocrinology. Conventional manual assessment methods mainly rely on personal experience in observing X-ray images of left hand and wrist to calculate bone age, which show some intrinsic limitations from low efficiency to unstable accuracy. To address these problems, some automated methods based on image processing or machine learning have been proposed, while their performances are not satisfying enough yet in assessment accuracy. Motivated by the remarkable success of deep learning (DL) techniques in the fields of image classification and speech recognition, we develop a deep automated skeletal bone age assessment model based on convolutional neural networks (CNNs) and support vector regression (SVR) using multiple kernel learning (MKL) algorithm to process heterogeneous features in this paper. This deep framework has been constructed, not only exploring the X-ray images of hand and twist but also some other heterogeneous information like race and gender. The experiment results prove its better performance with higher bone age assessment accuracy on two different data sets compared with the state of the art, indicating that the fused heterogeneous features provide a better description of the degree of bones’ maturation. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Convolutional neural networks; Heterogeneous features; Skeletal bone age assessment model; Support vector regression","Adolescent; Age Determination by Skeleton; Age Factors; Algorithms; Child; Child, Preschool; Continental Population Groups; Female; Hand; Humans; Image Processing, Computer-Assisted; Infant; Infant, Newborn; Male; Neural Networks (Computer); Sex Factors; Support Vector Machine; Wrist; adolescent; adult; algorithm; Article; automatic speech recognition; automation; bone age; bone age determination; child; convolutional neural network; feature extraction; female; gender; hand radiography; human; image analysis; image processing; infant; intermethod comparison; machine learning; male; measurement accuracy; measurement error; multiple kernel learning; newborn; race; skeleton; support vector machine; age; algorithm; anatomy and histology; ancestry group; artificial neural network; bone age determination; hand; preschool child; procedures; sex factor; support vector machine; wrist","Springer New York LLC","01485598","","JMSYD","30390162","Article","Scopus","2-s2.0-85056064131"
"Ning L.; Pittman R.; Shen X.","Ning, Lin (57195062871); Pittman, Randall (57190231690); Shen, Xipeng (7402721676)","57195062871; 57190231690; 7402721676","LCD: A Fast Contrastive Divergence Based Algorithm for Restricted Boltzmann Machine","2018","Neural Networks","15","10.1016/j.neunet.2018.08.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054015590&doi=10.1016%2fj.neunet.2018.08.018&partnerID=40&md5=942a9f5bcc9569c5d2b98c29798273fe","North Carolina State University, Raleigh, NC, United States","Ning L., North Carolina State University, Raleigh, NC, United States; Pittman R., North Carolina State University, Raleigh, NC, United States; Shen X., North Carolina State University, Raleigh, NC, United States","Restricted Boltzmann Machine (RBM) is the building block of Deep Belief Nets and other deep learning tools. Fast learning and prediction are both essential for practical usage of RBM-based machine learning techniques. This paper proposes Lean Contrastive Divergence (LCD), a modified Contrastive Divergence (CD) algorithm, to accelerate RBM learning and prediction without changing the results. LCD avoids most of the required computations with two optimization techniques. The first is called bounds-based filtering, which, through triangle inequality, replaces expensive calculations of many vector dot products with fast bounds calculations. The second is delta product, which effectively detects and avoids many repeated calculations in the core operation of RBM, Gibbs Sampling. The optimizations are applicable to both the standard contrastive divergence learning algorithm and its variations. In addition, this paper presents how to implement these optimizations effectively on massively parallel processors. Results show that the optimizations can produce several-fold (up to 3X for training and 5.3X for prediction) speedups. © 2018 Elsevier Ltd","Acceleration; Contrastive Divergence; RBM","Algorithms; Databases, Factual; Deep Learning; Machine Learning; Neural Networks (Computer); Time Factors; Acceleration; Deep learning; Forecasting; Building blockes; Contrastive divergence; Deep belief nets; Machine learning techniques; Massively parallel processors; Optimization techniques; Restricted boltzmann machine; Triangle inequality; acceleration; article; calculation; filtration; learning algorithm; machine learning; prediction; sampling; algorithm; artificial neural network; factual database; machine learning; time factor; trends; Learning algorithms","Elsevier Ltd","08936080","","NNETE","30273844","Article","Scopus","2-s2.0-85054015590"
"Deniz E.; Şengür A.; Kadiroğlu Z.; Guo Y.; Bajaj V.; Budak Ü.","Deniz, Erkan (36782014900); Şengür, Abdulkadir (12545159900); Kadiroğlu, Zehra (57203169426); Guo, Yanhui (55712447000); Bajaj, Varun (57209289122); Budak, Ümit (57189511236)","36782014900; 12545159900; 57203169426; 55712447000; 57209289122; 57189511236","Transfer learning based histopathologic image classification for breast cancer detection","2018","Health Information Science and Systems","227","10.1007/s13755-018-0057-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103706931&doi=10.1007%2fs13755-018-0057-x&partnerID=40&md5=7c9ef50ce74a94dd1756adb346d46696","Technology Faculty, Electrical and Electronics Engineering Department, Firat University, Elazig, Turkey; Department of Computer Science, University of Illinois at Springfield, Springfield, IL, United States; Discipline of Electronics and Communication Engineering, PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, India; Electrical and Electronics Engineering Department, Engineering Faculty, Bitlis Eren University, Bitlis, Turkey","Deniz E., Technology Faculty, Electrical and Electronics Engineering Department, Firat University, Elazig, Turkey; Şengür A., Technology Faculty, Electrical and Electronics Engineering Department, Firat University, Elazig, Turkey; Kadiroğlu Z., Technology Faculty, Electrical and Electronics Engineering Department, Firat University, Elazig, Turkey; Guo Y., Department of Computer Science, University of Illinois at Springfield, Springfield, IL, United States; Bajaj V., Discipline of Electronics and Communication Engineering, PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, India; Budak Ü., Electrical and Electronics Engineering Department, Engineering Faculty, Bitlis Eren University, Bitlis, Turkey","Breast cancer is one of the leading cancer type among women in worldwide. Many breast cancer patients die every year due to the late diagnosis and treatment. Thus, in recent years, early breast cancer detection systems based on patient’s imagery are in demand. Deep learning attracts many researchers recently and many computer vision applications have come out in various environments. Convolutional neural network (CNN) which is known as deep learning architecture, has achieved impressive results in many applications. CNNs generally suffer from tuning a huge number of parameters which bring a great amount of complexity to the system. In addition, the initialization of the weights of the CNN is another handicap that needs to be handle carefully. In this paper, transfer learning and deep feature extraction methods are used which adapt a pre-trained CNN model to the problem at hand. AlexNet and Vgg16 models are considered in the presented work for feature extraction and AlexNet is used for further fine-tuning. The obtained features are then classified by support vector machines (SVM). Extensive experiments on a publicly available histopathologic breast cancer dataset are carried out and the accuracy scores are calculated for performance evaluation. The evaluation results show that the transfer learning produced better result than deep feature extraction and SVM classification. © 2018, Springer Nature Switzerland AG.","Breast cancer detection; Convolutional neural networks; Deep feature extraction; Histopathologic image; Transfer learning","Article; breast cancer; cancer classification; cancer diagnosis; diagnostic accuracy; histopathology; human; image analysis; priority journal; scoring system; support vector machine; transfer of learning","Springer International Publishing","20472501","","","","Article","Scopus","2-s2.0-85103706931"
"Jeong M.; Ko B.C.","Jeong, Mira (35094275600); Ko, Byoung Chul (7102833929)","35094275600; 7102833929","Driver’s facial expression recognition in real-time for safe driving","2018","Sensors (Switzerland)","107","10.3390/s18124270","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058421475&doi=10.3390%2fs18124270&partnerID=40&md5=21571d8802cd23a4da80ce54236c4479","Department of Computer Engineering, Keimyung University, Daegu, 42601, South Korea","Jeong M., Department of Computer Engineering, Keimyung University, Daegu, 42601, South Korea; Ko B.C., Department of Computer Engineering, Keimyung University, Daegu, 42601, South Korea","In recent years, researchers of deep neural networks (DNNs)-based facial expression recognition (FER) have reported results showing that these approaches overcome the limitations of conventional machine learning-based FER approaches. However, as DNN-based FER approaches require an excessive amount of memory and incur high processing costs, their application in various fields is very limited and depends on the hardware specifications. In this paper, we propose a fast FER algorithm for monitoring a driver’s emotions that is capable of operating in low specification devices installed in vehicles. For this purpose, a hierarchical weighted random forest (WRF) classifier that is trained based on the similarity of sample data, in order to improve its accuracy, is employed. In the first step, facial landmarks are detected from input images and geometric features are extracted, considering the spatial position between landmarks. These feature vectors are then implemented in the proposed hierarchical WRF classifier to classify facial expressions. Our method was evaluated experimentally using three databases, extended Cohn-Kanade database (CK+), MMI and the Keimyung University Facial Expression of Drivers (KMU-FED) database, and its performance was compared with that of state-of-the-art methods. The results show that our proposed method yields a performance similar to that of deep learning FER methods as 92.6% for CK+ and 76.7% for MMI, with a significantly reduced processing cost approximately 3731 times less than that of the DNN method. These results confirm that the proposed method is optimized for real-time embedded applications having limited computing resources. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","ADAS; Deep neural networks; Embedded application; Facial expression recognition; Weighted random forest","Automobile Driving; Databases, Factual; Deep Learning; Emotions; Face; Facial Expression; Humans; Machine Learning; Memory; Neural Networks (Computer); Database systems; Decision trees; Deep neural networks; Specifications; ADAS; Cohn-Kanade database; Conventional machines; Embedded application; Facial expression recognition; Hardware specifications; Random forests; State-of-the-art methods; artificial neural network; car driving; emotion; face; facial expression; factual database; human; machine learning; memory; physiology; psychology; Face recognition","MDPI AG","14248220","","","30518132","Article","Scopus","2-s2.0-85058421475"
"Jansen C.; Hodel S.; Penzel T.; Spott M.; Krefting D.","Jansen, Christoph (56286202100); Hodel, Stephan (57205180954); Penzel, Thomas (57207902667); Spott, Martin (6603328790); Krefting, Dagmar (23004694400)","56286202100; 57205180954; 57207902667; 6603328790; 23004694400","Feature relevance in physiological networks for classification of obstructive sleep apnea","2018","Physiological Measurement","7","10.1088/1361-6579/aaf0c9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058918531&doi=10.1088%2f1361-6579%2faaf0c9&partnerID=40&md5=74f5de08699f597b79b3cb387148f00e","Center of Biomedical Image and Information Processing, HTW Berlin, University of Applied Sciences Berlin, Berlin, Germany; Sleep Medicine Center, Charité - Universitatsmedizin Berlin, Berlin, Germany; International Clinical Research Center, St. Anne's University Hospital Brno, Brno, Czech Republic; HTW Berlin, University of Applied Sciences Berlin, Berlin, Germany","Jansen C., Center of Biomedical Image and Information Processing, HTW Berlin, University of Applied Sciences Berlin, Berlin, Germany, Sleep Medicine Center, Charité - Universitatsmedizin Berlin, Berlin, Germany; Hodel S., Center of Biomedical Image and Information Processing, HTW Berlin, University of Applied Sciences Berlin, Berlin, Germany; Penzel T., Sleep Medicine Center, Charité - Universitatsmedizin Berlin, Berlin, Germany, International Clinical Research Center, St. Anne's University Hospital Brno, Brno, Czech Republic; Spott M., HTW Berlin, University of Applied Sciences Berlin, Berlin, Germany; Krefting D., Center of Biomedical Image and Information Processing, HTW Berlin, University of Applied Sciences Berlin, Berlin, Germany","Objective: Physiological networks (PN) model couplings between organs in a high-dimensional parameter space. Machine learning methods, in particular artifical neural networks (ANNs), are powerful on high-dimensional classification tasks. However, lack of interpretability of the resulting models has been a drawback in research. We assess relevant PN topology changes in obstructive sleep apnea (OSA) by novel ANN interpretation techniques. Approach: ANNs are trained to classify OSA based on the PNs of 48 patients and 48 age and gender matched healthy controls. The PNs consisting of 2812 links are derived from overnight biosignal recordings. The interpretation technique DeepLift is applied to the resulting ANN models, enabling the determination of the relevant features for classification decisions on individual subjects. The mean relevance scores of the features are compared to other machine learning methods (decision tree and random forests) and statistical tests on group differences. Main results: The ANN interpretation results show good agreement with the compared methods and 87% of the samples could be correctly classified. OSA patients show a significantly higher coupling (p 0.001) in light sleep (N2) between breathing rate and EEG power in all electrode locations and to chin and leg muscular tone. In deep sleep (N3), OSA leads to significantly lower coupling (p 0.01) in lateral connections of EEG and power in central and frontal positions. Misclassified OSA patients had all mild/moderate AHIs and did not show PN topology changes. Both nights of these patients have been consistently misclassified as healthy. This may indicate, that the impact of respiratory events differs in subjects, thus forming different phenotypes. Significance: The proposed PN analysis provides a powerful and robust method to quantify a broad range of physiological interactions. Interpretability of the ANN make them a promising tool to identify new diagnostic markers in data-driven approaches. © 2018 Institute of Physics and Engineering in Medicine.","artificial neural networks; classification; DeepLift; feature relevance; interpretable ANNs; network physiology; sleep apnea","Case-Control Studies; Decision Trees; Female; Humans; Machine Learning; Male; Middle Aged; Models, Statistical; Neural Networks (Computer); Sleep Apnea, Obstructive; Classification (of information); Decision trees; Diagnosis; Machine learning; Physiological models; Physiology; Sleep research; Artifical neural networks; Deeplift; Feature relevance; High-dimensional; Higher-dimensional; Interpretable artifical neural network; Machine learning methods; Network physiology; Obstructive sleep apnea; Sleep apnea; artificial neural network; case control study; decision tree; female; human; machine learning; male; middle aged; pathophysiology; sleep disordered breathing; statistical model; Neural networks","IOP Publishing Ltd","09673334","","PMEAE","30524083","Article","Scopus","2-s2.0-85058918531"
"Taherkhani A.; Cosma G.; McGinnity T.M.","Taherkhani, Aboozar (24823233900); Cosma, Georgina (24334913600); McGinnity, T.M. (7003792410)","24823233900; 24334913600; 7003792410","Deep-FS: A feature selection algorithm for Deep Boltzmann Machines","2018","Neurocomputing","57","10.1016/j.neucom.2018.09.040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054196401&doi=10.1016%2fj.neucom.2018.09.040&partnerID=40&md5=2375d00b175d304eebcb8025f6fa2935","School of Science and Technology, Nottingham Trent University, Nottingham, United Kingdom; Intelligent Systems Research Centre, Ulster University, Northern Ireland, Derry, United Kingdom","Taherkhani A., School of Science and Technology, Nottingham Trent University, Nottingham, United Kingdom; Cosma G., School of Science and Technology, Nottingham Trent University, Nottingham, United Kingdom; McGinnity T.M., School of Science and Technology, Nottingham Trent University, Nottingham, United Kingdom, Intelligent Systems Research Centre, Ulster University, Northern Ireland, Derry, United Kingdom","A Deep Boltzmann Machine is a model of a Deep Neural Network formed from multiple layers of neurons with nonlinear activation functions. The structure of a Deep Boltzmann Machine enables it to learn very complex relationships between features and facilitates advanced performance in learning of high-level representation of features, compared to conventional Artificial Neural Networks. Feature selection at the input level of Deep Neural Networks has not been well studied, despite its importance in reducing the input features processed by the deep learning model, which facilitates understanding of the data. This paper proposes a novel algorithm, Deep Feature Selection (Deep-FS), which is capable of removing irrelevant features from large datasets in order to reduce the number of inputs which are modelled during the learning process. The proposed Deep-FS algorithm utilizes a Deep Boltzmann Machine, and uses knowledge which is acquired during training to remove features at the beginning of the learning process. Reducing inputs is important because it prevents the network from learning the associations between the irrelevant features which negatively impact on the acquired knowledge of the network about the overall distribution of the data. The Deep-FS method embeds feature selection in a Restricted Boltzmann Machine which is used for training a Deep Boltzmann Machine. The generative property of the Restricted Boltzmann Machine is used to reconstruct eliminated features and calculate reconstructed errors, in order to evaluate the impact of eliminating features. The performance of the proposed approach was evaluated with experiments conducted using the MNIST, MIR-Flickr, GISETTE, MADELON and PANCAN datasets. The results revealed that the proposed Deep-FS method enables improved feature selection without loss of accuracy on the MIR-Flickr dataset, where Deep-FS reduced the number of input features by removing 775 features without reduction in performance. With regards to the MNIST dataset, Deep-FS reduced the number of input features by more than 45%; it reduced the network error from 0.97% to 0.90%, and also reduced processing and classification time by more than 5.5%. Additionally, when compared to classical feature selection methods, Deep-FS returned higher accuracy. The experimental results on GISETTE, MADELON and PANCAN showed that Deep-FS reduced 81%, 57% and 77% of the number of input features, respectively. Moreover, the proposed feature selection method reduced the classifier training time by 82%, 70% and 85% on GISETTE, MADELON and PANCAN datasets, respectively. Experiments with various datasets, comprising a large number of features and samples, revealed that the proposed Deep-FS algorithm overcomes the main limitations of classical feature selection algorithms. More specifically, most classical methods require, as a prerequisite, a pre-specified number of features to retain, however in Deep-FS this number is identified automatically. Deep-FS performs the feature selection task faster than classical feature selection algorithms which makes it suitable for deep learning tasks. In addition, Deep-FS is suitable for finding features in large and big datasets which are normally stored in data batches for faster and more efficient processing. © 2018","Deep Boltzmann Machine; Deep learning; Deep Neural Networks; Feature selection; Generative models; Missing features; Restricted Boltzmann Machine","Big data; Classification (of information); Deep learning; Deep neural networks; Learning algorithms; Neural networks; Complex relationships; Deep boltzmann machines; Feature selection algorithm; Feature selection methods; Generative model; Missing features; Nonlinear activation functions; Restricted boltzmann machine; article; classifier; error; learning; machine; Feature extraction","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85054196401"
"Wang T.; Cao J.; Lai X.; Chen B.","Wang, Tianlei (57193515024); Cao, Jiuwen (35274436100); Lai, Xiaoping (12545697200); Chen, Badong (16177239100)","57193515024; 35274436100; 12545697200; 16177239100","Deep Weighted Extreme Learning Machine","2018","Cognitive Computation","31","10.1007/s12559-018-9602-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054297224&doi=10.1007%2fs12559-018-9602-9&partnerID=40&md5=5528fbeeb3b9a12ab470b3c9f75fe286","Key Lab for IOT and Information Fusion Technology of Zhejiang, Hangzhou Dianzi University, Zhejiang, 310018, China; Institute of Information and Control, Hangzhou Dianzi University, Zhejiang, 310018, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, 710049, China","Wang T., Key Lab for IOT and Information Fusion Technology of Zhejiang, Hangzhou Dianzi University, Zhejiang, 310018, China; Cao J., Key Lab for IOT and Information Fusion Technology of Zhejiang, Hangzhou Dianzi University, Zhejiang, 310018, China, Institute of Information and Control, Hangzhou Dianzi University, Zhejiang, 310018, China; Lai X., Key Lab for IOT and Information Fusion Technology of Zhejiang, Hangzhou Dianzi University, Zhejiang, 310018, China, Institute of Information and Control, Hangzhou Dianzi University, Zhejiang, 310018, China; Chen B., School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, 710049, China","The imbalanced data classification attracts increasing attention in the past years due to the continuous expansion of data available in many areas, such as biomedical engineering, surveillance, and computer vision. Learning from imbalanced data is challenging as most standard algorithms fail to properly represent the inherent complex characteristics of the data distribution. As an emerging technology, the extreme learning machine (ELM) and its variants, including the weighted ELM (WELM) and the boosting weighted ELM (BWELM), have been recently developed for the classification of imbalanced data. However, the WELM suffers the following deficiencies: (i) the sample weight matrix is manually chosen and fixed during the learning phase; (ii) the representation capability, namely the capability to extract features or useful information from the original data, is insufficiently explored due to its shallow structure. The BWELM employs the AdaBoost algorithm to optimize the sample weights. But the representation capability is still restricted by the shallow structure. To alleviate these deficiencies, we propose a novel deep weighted ELM (DWELM) algorithm for imbalanced data classification in this paper. An enhanced stacked multilayer deep representation network trained with the ELM (EH-DrELM) is first proposed to improve the representation capability, and a fast AdaBoost algorithm for imbalanced multiclass data (AdaBoost-ID) is developed to optimize the sample weights. Then, the novel DWELM for the imbalance learning is obtained by combining the above two algorithms. Experimental results on nine imbalanced binary-class datasets, nine imbalanced multiclass datasets, and five large benchmark datasets (three for multiclass and two for binary-class) show that the proposed DWELM achieves a better performance than the WELM and BWELM, as well as several state-of-the-art multilayer network-based learning algorithms. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","AdaBoost; Deep learning; Extreme learning machine; Imbalanced data; Weighted extreme learning machine","Adaptive boosting; Benchmarking; Biomedical engineering; Classification (of information); Data mining; Knowledge acquisition; Multilayers; AdaBoost algorithm; Benchmark datasets; Complex characteristics; Emerging technologies; Extreme learning machine; Imbalanced data; Multi-layer network; Standard algorithms; Deep learning","Springer New York LLC","18669956","","","","Article","Scopus","2-s2.0-85054297224"
"Li Q.; Li Q.; Liu C.; Shashikumar S.P.; Nemati S.; Clifford G.D.","Li, Qiao (57221613252); Li, Qichen (55547138656); Liu, Chengyu (55680778400); Shashikumar, Supreeth P. (57194045059); Nemati, Shamim (23012530600); Clifford, Gari D. (7004468844)","57221613252; 55547138656; 55680778400; 57194045059; 23012530600; 7004468844","Deep learning in the cross-time frequency domain for sleep staging from a single-lead electrocardiogram","2018","Physiological Measurement","67","10.1088/1361-6579/aaf339","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058919863&doi=10.1088%2f1361-6579%2faaf339&partnerID=40&md5=5e878e01d5fdfb87acd41e3ad3b93527","Department of Biomedical Informatics, Emory University, Atlanta, GA, United States; Department of Engineering Science, University of Oxford, Oxford, United Kingdom; School of Instrument Science and Engineering, Southeast University, Nanjing, China; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Department of Biomedical Engineering, Georgia Institute of Technology, United States; Department of Biomedical Informatics, Emory University, GA, United States","Li Q., Department of Biomedical Informatics, Emory University, Atlanta, GA, United States; Li Q., Department of Engineering Science, University of Oxford, Oxford, United Kingdom; Liu C., School of Instrument Science and Engineering, Southeast University, Nanjing, China; Shashikumar S.P., Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Nemati S., Department of Biomedical Informatics, Emory University, Atlanta, GA, United States; Clifford G.D., Department of Biomedical Informatics, Emory University, Atlanta, GA, United States, Department of Biomedical Engineering, Georgia Institute of Technology, United States, Department of Biomedical Informatics, Emory University, GA, United States","Objective: This study classifies sleep stages from a single lead electrocardiogram (ECG) using beat detection, cardiorespiratory coupling in the time-frequency domain and a deep convolutional neural network (CNN). Approach: An ECG-derived respiration (EDR) signal and synchronous beat-to-beat heart rate variability (HRV) time series were derived from the ECG using previously described robust algorithms. A measure of cardiorespiratory coupling (CRC) was extracted by calculating the coherence and cross-spectrogram of the EDR and HRV signal in 5 min windows. A CNN was then trained to classify the sleep stages (wake, rapid-eye-movement (REM) sleep, non-REM (NREM) light sleep and NREM deep sleep) from the corresponding CRC spectrograms. A support vector machine was then used to combine the output of CNN with the other features derived from the ECG, including phase-rectified signal averaging (PRSA), sample entropy, as well as standard spectral and temporal HRV measures. The MIT-BIH Polysomnographic Database (SLPDB), the PhysioNet/Computing in Cardiology Challenge 2018 database (CinC2018) and the Sleep Heart Health Study (SHHS) database, all expert-annotated for sleep stages, were used to train and validate the algorithm. Main results: Ten-fold cross validation results showed that the proposed algorithm achieved an accuracy (Acc) of 75.4% and a Cohen's kappa coefficient of = 0.54 on the out of sample validation data in the classification of Wake, REM, NREM light and deep sleep in SLPDB. This rose to Acc = 81.6% and = 0.63 for the classification of Wake, REM sleep and NREM sleep and Acc = 85.1% and = 0.68 for the classification of NREM sleep versus REM/wakefulness in SLPDB. Significance: The proposed ECG-based sleep stage classification approach that represents the highest reported results on non-electroencephalographic data and uses datasets over ten times larger than those in previous studies. By using a state-of-the-art QRS detector and deep learning model, the system does not require human annotation and can therefore be scaled for mass analysis. © 2018 Institute of Physics and Engineering in Medicine.","cardiorespiratory coupling; cross-time-frequency domain; deep convolutional neural network; electrocardiogram; sleep stage classification","Deep Learning; Electrocardiography; Humans; Neural Networks (Computer); Signal Processing, Computer-Assisted; Sleep Stages; Support Vector Machine; Time Factors; Wakefulness; Classification (of information); Convolution; Database systems; Deep neural networks; Electroencephalography; Eye movements; Frequency domain analysis; Sleep research; Spectrographs; Support vector machines; Wakes; Cardiorespiratory coupling; Convolutional neural network; Cross-time-frequency domain; Heart rate variability; Rapid eye movement; REM sleep; Sleep stage; Sleep stages classifications; Spectrograms; Time frequency domain; artificial neural network; electrocardiography; human; signal processing; sleep stage; support vector machine; time factor; wakefulness; Electrocardiography","IOP Publishing Ltd","09673334","","PMEAE","30524025","Article","Scopus","2-s2.0-85058919863"
"Zago G.T.; Andreão R.V.; Dorizzi B.; Teatini Salles E.O.","Zago, Gabriel Tozatto (56412060700); Andreão, Rodrigo Varejão (9532923300); Dorizzi, Bernadette (6603426803); Teatini Salles, Evandro Ottoni (6701704423)","56412060700; 9532923300; 6603426803; 6701704423","Retinal image quality assessment using deep learning","2018","Computers in Biology and Medicine","77","10.1016/j.compbiomed.2018.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054801284&doi=10.1016%2fj.compbiomed.2018.10.004&partnerID=40&md5=2096d9a9c73a8951db5b2bbfa0d21c69","Department of Control and Automation Engineering, Instituto Federal do Espírito Santo, Brazil; Department of Electrical Engineering, Instituto Federal do Espírito Santo, Brazil; Télécom SudParis, Laboratoire SAMOVAR, 9 rue Charles Fourier, 91011, EVRY, France; Department of Electrical Engineering, Universidade Federal do Espírito Santo, Brazil","Zago G.T., Department of Control and Automation Engineering, Instituto Federal do Espírito Santo, Brazil; Andreão R.V., Department of Electrical Engineering, Instituto Federal do Espírito Santo, Brazil; Dorizzi B., Télécom SudParis, Laboratoire SAMOVAR, 9 rue Charles Fourier, 91011, EVRY, France; Teatini Salles E.O., Department of Electrical Engineering, Universidade Federal do Espírito Santo, Brazil","Poor-quality retinal images do not allow an accurate medical diagnosis, and it is inconvenient for a patient to return to a medical center to repeat the fundus photography exam. In this paper, a robust automatic system is proposed to assess the quality of retinal images at the moment of the acquisition, aiming at assisting health care professionals during a fundus photography exam. We propose a convolutional neural network (CNN) pretrained on non-medical images for extracting general image features. The weights of the CNN are further adjusted via a fine-tuning procedure, resulting in a performant classifier obtained only with a small quantity of labeled images. The CNN performance was evaluated on two publicly available databases (i.e., DRIMDB and ELSA-Brasil) using two different procedures: intra-database and inter-database cross-validation. The CNN achieved an area under the curve (AUC) of 99.98% on DRIMDB and an AUC of 98.56% on ELSA-Brasil in the inter-database experiment, where training and testing were not performed on the same database. These results show the robustness of the proposed model to various image acquisitions without requiring special adaptation, thus making it a good candidate for use in operational clinical scenarios. © 2018 Elsevier Ltd","Convolutional neural networks; Deep learning; Diabetic retinopathy; Image quality; Retinal images","Algorithms; Deep Learning; Diabetic Retinopathy; Diagnostic Techniques, Ophthalmological; Humans; Image Processing, Computer-Assisted; Retina; Convolution; Database systems; Deep learning; Diagnosis; Eye protection; Medical imaging; Neural networks; Ophthalmology; Photography; Area Under the Curve (AUC); Convolutional neural network; Convolutional Neural Networks (CNN); Diabetic retinopathy; Health care professionals; Retinal image; Retinal image quality; Training and testing; Article; artificial neural network; classifier; controlled study; convolutional neural network; deep learning; eye fundus; eye photography; feature extraction; image quality; machine learning; priority journal; quality control; reference database; validation process; algorithm; diabetic retinopathy; diagnostic imaging; human; image processing; procedures; retina; visual system examination; Image quality","Elsevier Ltd","00104825","","CBMDA","30340214","Article","Scopus","2-s2.0-85054801284"
"Chen Z.; He N.; Huang Y.; Qin W.T.; Liu X.; Li L.","Chen, Zhen (55812628400); He, Ningning (57204516357); Huang, Yu (57204608142); Qin, Wen Tao (57205476920); Liu, Xuhan (57218314157); Li, Lei (56714439800)","55812628400; 57204516357; 57204608142; 57205476920; 57218314157; 56714439800","Integration of A Deep Learning Classifier with A Random Forest Approach for Predicting Malonylation Sites","2018","Genomics, Proteomics and Bioinformatics","72","10.1016/j.gpb.2018.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060145768&doi=10.1016%2fj.gpb.2018.08.004&partnerID=40&md5=50c48f6164b6fb882c274466785fb685","School of Basic Medicine, Qingdao University, Qingdao, 266021, China; School of Data Science and Software Engineering, Qingdao University, Qingdao, 266021, China; Department of Biochemistry, Schulich School of Medicine and Dentistry, University of Western Ontario, London, N6A 5C1, Ontario, Canada; Department of Information Technology, Beijing Oriental Yamei Gene Technology Institute Co. Ltd., Beijing, 100078, China; Qingdao Cancer Institute, Qingdao University, Qingdao, 266021, China","Chen Z., School of Basic Medicine, Qingdao University, Qingdao, 266021, China; He N., School of Basic Medicine, Qingdao University, Qingdao, 266021, China; Huang Y., School of Data Science and Software Engineering, Qingdao University, Qingdao, 266021, China; Qin W.T., Department of Biochemistry, Schulich School of Medicine and Dentistry, University of Western Ontario, London, N6A 5C1, Ontario, Canada; Liu X., Department of Information Technology, Beijing Oriental Yamei Gene Technology Institute Co. Ltd., Beijing, 100078, China; Li L., School of Basic Medicine, Qingdao University, Qingdao, 266021, China, School of Data Science and Software Engineering, Qingdao University, Qingdao, 266021, China, Qingdao Cancer Institute, Qingdao University, Qingdao, 266021, China","                             As a newly-identified protein post-translational modification, malonylation is involved in a variety of biological functions. Recognizing malonylation sites in substrates represents an initial but crucial step in elucidating the molecular mechanisms underlying protein malonylation. In this study, we constructed a deep learning (DL) network classifier based on long short-term memory (LSTM) with word embedding (LSTM                             WE                             ) for the prediction of mammalian malonylation sites. LSTM                             WE                              performs better than traditional classifiers developed with common pre-defined feature encodings or a DL classifier based on LSTM with a one-hot vector. The performance of LSTM                             WE                              is sensitive to the size of the training set, but this limitation can be overcome by integration with a traditional machine learning (ML) classifier. Accordingly, an integrated approach called LEMP was developed, which includes LSTM                             WE                              and the random forest classifier with a novel encoding of enhanced amino acid content. LEMP performs not only better than the individual classifiers but also superior to the currently-available malonylation predictors. Additionally, it demonstrates a promising performance with a low false positive rate, which is highly useful in the prediction application. Overall, LEMP is a useful tool for easily identifying malonylation sites with high confidence. LEMP is available at http://www.bioinfogo.org/lemp.                          © 2019 The Authors","Deep learning; LSTM; Malonylation; Random forest; Recurrent neural network","Amino Acid Sequence; Amino Acids; Animals; Deep Learning; Forecasting; Lysine; Machine Learning; Malonates; Protein Processing, Post-Translational; amino acid; lysine; malonic acid derivative; algorithm; amino terminal sequence; Article; bioinformatics; carboxy terminal sequence; comparative study; deep learning; entropy; human; machine learning; nonhuman; prediction; random forest; short term memory; amino acid sequence; animal; chemistry; forecasting; genetics; procedures; protein processing","Beijing Genomics Institute","16720229","","","30639696","Article","Scopus","2-s2.0-85060145768"
"Maggio V.; Chierici M.; Jurman G.; Furlanello C.","Maggio, Valerio (36675258000); Chierici, Marco (16070093000); Jurman, Giuseppe (6602367398); Furlanello, Cesare (6701821823)","36675258000; 16070093000; 6602367398; 6701821823","Distillation of the clinical algorithm improves prognosis by multi-task deep learning in high-risk Neuroblastoma","2018","PLoS ONE","16","10.1371/journal.pone.0208924","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058138691&doi=10.1371%2fjournal.pone.0208924&partnerID=40&md5=25c88793f4543bc1d1865c9768501e23","Fondazione Bruno Kessler, Trento, Italy","Maggio V., Fondazione Bruno Kessler, Trento, Italy; Chierici M., Fondazione Bruno Kessler, Trento, Italy; Jurman G., Fondazione Bruno Kessler, Trento, Italy; Furlanello C., Fondazione Bruno Kessler, Trento, Italy","We introduce the CDRP (Concatenated Diagnostic-Relapse Prognostic) architecture for multi-task deep learning that incorporates a clinical algorithm, e.g., a risk stratification schema to improve prognostic profiling. We present the first application to survival prediction in High-Risk (HR) Neuroblastoma from transcriptomics data, a task that studies from the MAQC consortium have shown to remain the hardest among multiple diagnostic and prognostic endpoints predictable from the same dataset. To obtain a more accurate risk stratification needed for appropriate treatment strategies, CDRP combines a first component (CDRP-A) synthesizing a diagnostic task and a second component (CDRP-N) dedicated to one or more prognostic tasks. The approach leverages the advent of semi-supervised deep learning structures that can flexibly integrate multimodal data or internally create multiple processing paths. CDRP-A is an autoencoder trained on gene expression on the HR/non-HR risk stratification by the Children’s Oncology Group, obtaining a 64-node representation in the bottleneck layer. CDRP-N is a multi-task classifier for two prognostic endpoints, i.e., Event-Free Survival (EFS) and Overall Survival (OS). CDRP-A provides the HR embedding input to the CDRP-N shared layer, from which two branches depart to model EFS and OS, respectively. To control for selection bias, CDRP is trained and evaluated using a Data Analysis Protocol (DAP) developed within the MAQC initiative. CDRP was applied on Illumina RNA-Seq of 498 Neuroblastoma patients (HR: 176) from the SEQC study (12,464 Entrez genes) and on Affymetrix Human Exon Array expression profiles (17,450 genes) of 247 primary diagnostic Neuroblastoma of the TARGET NBL cohort. On the SEQC HR patients, CDRP achieves Matthews Correlation Coefficient (MCC) 0.38 for EFS and MCC = 0.19 for OS in external validation, improving over published SEQC models. We show that a CDRP-N embedding is indeed parametrically associated to increasing severity and the embedding can be used to better stratify patients’ survival. © 2018 Maggio et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Child; Deep Learning; Female; Gene Expression Profiling; Gene Expression Regulation, Neoplastic; Humans; Infant; Male; Neoplasm Recurrence, Local; Neuroblastoma; Prognosis; Progression-Free Survival; Risk Assessment; Article; cancer diagnosis; cancer patient; cancer prognosis; cancer risk; cancer survival; classifier; cohort analysis; Concatenated Diagnostic Relapse Prognostic; controlled study; correlation coefficient; data analysis; event free survival; external validity; female; gene expression; gene expression profiling; hazard ratio; high risk patient; human; intermediate risk patient; intermethod comparison; machine learning; major clinical study; male; neuroblastoma; overall survival; prediction; random forest; risk assessment; RNA sequence; support vector machine; survival analysis; transcriptomics; algorithm; child; gene expression regulation; genetics; infant; neuroblastoma; pathology; prognosis; tumor recurrence","Public Library of Science","19326203","","POLNC","30532223","Article","Scopus","2-s2.0-85058138691"
"Shi H.; Wang H.; Meng X.; Chen R.; Zhang Y.; Su Y.; He Y.","Shi, Huayi (57195985003); Wang, Houyu (55370166000); Meng, Xinyu (57201911655); Chen, Runzhi (57205139235); Zhang, Yishu (57205140034); Su, Yuanyuan (25625260600); He, Yao (35361794600)","57195985003; 55370166000; 57201911655; 57205139235; 57205140034; 25625260600; 35361794600","Setting Up a Surface-Enhanced Raman Scattering Database for Artificial-Intelligence-Based Label-Free Discrimination of Tumor Suppressor Genes","2018","Analytical Chemistry","52","10.1021/acs.analchem.8b03080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058763689&doi=10.1021%2facs.analchem.8b03080&partnerID=40&md5=5bcd1c1dd53b395816cf594cba654ec6","Laboratory of Nanoscale Biochemical Analysis, Jiangsu Key Laboratory for Carbon-Based Functional Materials and Devices, Institute of Functional Nano and Soft Materials (FUNSOM), Collaborative Innovation Center of Suzhou Nano Science and Technology (NANO-CIC), Soochow University, Suzhou, Jiangsu, 215123, China","Shi H., Laboratory of Nanoscale Biochemical Analysis, Jiangsu Key Laboratory for Carbon-Based Functional Materials and Devices, Institute of Functional Nano and Soft Materials (FUNSOM), Collaborative Innovation Center of Suzhou Nano Science and Technology (NANO-CIC), Soochow University, Suzhou, Jiangsu, 215123, China; Wang H., Laboratory of Nanoscale Biochemical Analysis, Jiangsu Key Laboratory for Carbon-Based Functional Materials and Devices, Institute of Functional Nano and Soft Materials (FUNSOM), Collaborative Innovation Center of Suzhou Nano Science and Technology (NANO-CIC), Soochow University, Suzhou, Jiangsu, 215123, China; Meng X., Laboratory of Nanoscale Biochemical Analysis, Jiangsu Key Laboratory for Carbon-Based Functional Materials and Devices, Institute of Functional Nano and Soft Materials (FUNSOM), Collaborative Innovation Center of Suzhou Nano Science and Technology (NANO-CIC), Soochow University, Suzhou, Jiangsu, 215123, China; Chen R., Laboratory of Nanoscale Biochemical Analysis, Jiangsu Key Laboratory for Carbon-Based Functional Materials and Devices, Institute of Functional Nano and Soft Materials (FUNSOM), Collaborative Innovation Center of Suzhou Nano Science and Technology (NANO-CIC), Soochow University, Suzhou, Jiangsu, 215123, China; Zhang Y., Laboratory of Nanoscale Biochemical Analysis, Jiangsu Key Laboratory for Carbon-Based Functional Materials and Devices, Institute of Functional Nano and Soft Materials (FUNSOM), Collaborative Innovation Center of Suzhou Nano Science and Technology (NANO-CIC), Soochow University, Suzhou, Jiangsu, 215123, China; Su Y., Laboratory of Nanoscale Biochemical Analysis, Jiangsu Key Laboratory for Carbon-Based Functional Materials and Devices, Institute of Functional Nano and Soft Materials (FUNSOM), Collaborative Innovation Center of Suzhou Nano Science and Technology (NANO-CIC), Soochow University, Suzhou, Jiangsu, 215123, China; He Y., Laboratory of Nanoscale Biochemical Analysis, Jiangsu Key Laboratory for Carbon-Based Functional Materials and Devices, Institute of Functional Nano and Soft Materials (FUNSOM), Collaborative Innovation Center of Suzhou Nano Science and Technology (NANO-CIC), Soochow University, Suzhou, Jiangsu, 215123, China","The quality of input data in deep learning is tightly associated with the ultimate performance of the machine learner. Taking advantage of the unique merits of surface-enhanced Raman scattering (SERS) methodology in the collection and construction of a database (e.g., abundant intrinsic fingerprint information, noninvasive data acquisition process, strong anti-interfering ability, etc.), herein we set up a SERS-based database of deoxyribonucleic acid (DNA), suitable for artificial intelligence (AI)-based sensing applications. The database is collected and analyzed by silver nanoparticles (Ag NPs)-decorated silicon wafer (Ag NPs@Si) SERS chip, followed by training with a deep neural network (DNN). As proof-of-concept applications, three kinds of representative tumor suppressor genes, i.e., p16, p21, and p53 fragments, are readily discriminated in a label-free manner. Prominent and reproducible SERS spectra of these DNA molecules are collected and employed as input data for DNN learning and training, which enables selective discrimination of DNA target(s). The accuracy rate for the recognition of specific DNA target reached 90.28%. Copyright © 2018 American Chemical Society.","","Artificial Intelligence; Databases, Factual; DNA; Lab-On-A-Chip Devices; Metal Nanoparticles; Silicon; Silver; Spectrum Analysis, Raman; Tumor Suppressor Protein p53; Tumor Suppressor Proteins; Artificial intelligence; Data acquisition; Database systems; Deep neural networks; DNA; Genes; Input output programs; Nucleic acids; Raman scattering; Raman spectroscopy; Silicon wafers; Silver nanoparticles; Tumors; DNA; metal nanoparticle; protein p53; silicon; silver; tumor suppressor protein; Acquisition process; Learning and training; Machine learners; Proof of concept; Sensing applications; Silver nanoparticles (AgNps); Surface enhanced Raman Scattering (SERS); Tumor suppressor genes; artificial intelligence; chemistry; factual database; genetics; lab on a chip; procedures; Raman spectrometry; Surface scattering","American Chemical Society","00032700","","ANCHA","30456938","Article","Scopus","2-s2.0-85058763689"
"Lim S.-M.; Oh H.-C.; Kim J.; Lee J.; Park J.","Lim, Se-Min (57204784533); Oh, Hyeong-Cheol (7402326176); Kim, Jaein (57204786846); Lee, Juwon (57204787967); Park, Jooyoung (58001016900)","57204784533; 7402326176; 57204786846; 57204787967; 58001016900","Lstm-guided coaching assistant for table tennis practice","2018","Sensors","29","10.3390/S18124112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057172956&doi=10.3390%2fS18124112&partnerID=40&md5=3d848143c1bd084ea1940144ca3028d7","Department of Electronic and Information Engineering, Korea University, 2511 Sejong-ro, Sejong-City, 30016, South Korea; Department of Mathematics, Korea University, 145 Anam-ro, Anamdong 5-ga, Seoul, 02841, South Korea; Department of Control and Instrumentation Engineering, Korea University, 2511 Sejong-ro,, Sejong-City, 30016, South Korea","Lim S.-M., Department of Electronic and Information Engineering, Korea University, 2511 Sejong-ro, Sejong-City, 30016, South Korea; Oh H.-C., Department of Electronic and Information Engineering, Korea University, 2511 Sejong-ro, Sejong-City, 30016, South Korea; Kim J., Department of Mathematics, Korea University, 145 Anam-ro, Anamdong 5-ga, Seoul, 02841, South Korea; Lee J., Department of Control and Instrumentation Engineering, Korea University, 2511 Sejong-ro,, Sejong-City, 30016, South Korea; Park J., Department of Control and Instrumentation Engineering, Korea University, 2511 Sejong-ro,, Sejong-City, 30016, South Korea","Recently, wearable devices have become a prominent health care application domain by incorporating a growing number of sensors and adopting smart machine learning technologies. One closely related topic is the strategy of combining the wearable device technology with skill assessment, which can be used in wearable device apps for coaching and/or personal training. Particularly pertinent to skill assessment based on high-dimensional time series data from wearable sensors is classifying whether a player is an expert or a beginner, which skills the player is exercising, and extracting some low-dimensional representations useful for coaching. In this paper, we present a deep learning-based coaching assistant method, which can provide useful information in supporting table tennis practice. Our method uses a combination of LSTM (Long short-term memory) with a deep state space model and probabilistic inference. More precisely, we use the expressive power of LSTM when handling high-dimensional time series data, and state space model and probabilistic inference to extract low-dimensional latent representations useful for coaching. Experimental results show that our method can yield promising results for characterizing high-dimensional time series patterns and for providing useful information when working with wearable IMU (Inertial measurement unit) sensors for table tennis coaching. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Latent features; LSTM; Probabilistic inference; Skill assessment; State space model; Wearable sensors","Biosensing Techniques; Exercise; Humans; Machine Learning; Mentoring; Racquet Sports; Wearable Electronic Devices; Data mining; Information use; Long short-term memory; Sports; State space methods; Time series; Deep learning; High-dimensional; Higher-dimensional; Latent feature; Probabilistic inference; Skill assessment; State-space models; Table-tennis; Time-series data; Wearable devices; devices; electronic device; exercise; genetic procedures; human; machine learning; mentoring; procedures; racquet sport; Wearable sensors","MDPI","14248220","","","30477175","Article","Scopus","2-s2.0-85057172956"
"Majaj N.J.; Pelli D.G.","Majaj, Najib J. (6602251596); Pelli, Denis G. (7003315905)","6602251596; 7003315905","Deep learning-Using machine learning to study biological vision","2018","Journal of Vision","30","10.1167/18.13.2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058464110&doi=10.1167%2f18.13.2&partnerID=40&md5=cd4300e2bd731a31558fcc5d0b27bc04","Center for Neural Science, New York University, New York, NY, United States; Department of Psychology and Center for Neural Science, New York University, New York, NY, United States","Majaj N.J., Center for Neural Science, New York University, New York, NY, United States; Pelli D.G., Department of Psychology and Center for Neural Science, New York University, New York, NY, United States","Many vision science studies employ machine learning, especially the version called ""deep learning."" Neuroscientists use machine learning to decode neural responses. Perception scientists try to understand how living organisms recognize objects. To them, deep neural networks offer benchmark accuracies for recognition of learned stimuli. Originally machine learning was inspired by the brain. Today, machine learning is used as a statistical tool to decode brain activity. Tomorrow, deep neural networks might become our best model of brain function. This brief overview of the use of machine learning in biological vision touches on its strengths, weaknesses, milestones, controversies, and current directions. Here, we hope to help vision scientists assess what role machine learning should play in their research. © 2018 The Authors.","Deep learning; Machine learning; Neural networks; Object recognition","Algorithms; Brain; Deep Learning; Humans; Neural Networks (Computer); Vision, Ocular; algorithm; artificial neural network; brain; human; physiology; vision","Association for Research in Vision and Ophthalmology Inc.","15347362","","","30508427","Article","Scopus","2-s2.0-85058464110"
"Jafarpisheh N.; Teshnehlab M.","Jafarpisheh, Noushin (57203094976); Teshnehlab, Mohammad (23006417100)","57203094976; 23006417100","Cancers classification based on deep neural networks and emotional learning approach","2018","IET Systems Biology","14","10.1049/iet-syb.2018.5002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056889815&doi=10.1049%2fiet-syb.2018.5002&partnerID=40&md5=23cd59783eb4cf6cccb5c39f0f1603c8","Department of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran","Jafarpisheh N., Department of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran; Teshnehlab M., Department of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran","In the present era, enormous factors contribute to causing cancer. So cancer classification cannot rely only on doctor's thoughts. As a result, intelligent algorithms concerning doctor's help are inevitable. Therefore, the authors are motivated to suggest a novel algorithm to classify three cancer datasets; colon, ALL-AML, and leukaemia cancers. Their proposed algorithm is based on the deep neural network and emotional learning process. First of all, by applying the principal component analysis, they had a feature reduction. Then, they used deep neural as a feature extraction. Then, they implemented different classifiers; multi-layer perceptron, support vector machine (SVM), decision tree, and Gaussian mixture model. In the end, because in the real world, especially when working on systems biology, unpredictable events, and uncertainties are undeniable, the robustness of their model against uncertainties is important. So they added Gaussian noise to the input features of the first encoder in each dataset, then, they applied the stacked denoising method. Experimental results disclosed that, generally, using emotional learning increased the accuracy. In addition, the highest accuracy was gained by SVM, 91.66, 92.27, and 96.56% for colon, ALL-AML, and leukaemia, respectively. However, GMM led to the lowest accuracy. The best accuracy gained by GMM was 60%. © 2018, The Institution of Engineering and Technology.","","Computational Biology; Deep Learning; Emotions; Humans; Neoplasms; Classification (of information); Decision trees; Diseases; Gaussian distribution; Gaussian noise (electronic); Learning algorithms; Principal component analysis; Support vector machines; Cancer classification; Denoising methods; Emotional learning; Feature reduction; Gaussian Mixture Model; Intelligent Algorithms; Multi layer perceptron; Systems biology; biology; emotion; human; neoplasm; procedures; Deep neural networks","Institution of Engineering and Technology","17518849","","","30472689","Article","Scopus","2-s2.0-85056889815"
"Liang Y.; Wu D.; Ledesma D.; Davis C.; Slaughter R.; Guo Z.","Liang, Yu (7403499475); Wu, Dalei (11640678700); Ledesma, Dakila (57205368462); Davis, Chris (57205368437); Slaughter, Robert (57205368434); Guo, Zibin (57198560327)","7403499475; 11640678700; 57205368462; 57205368437; 57205368434; 57198560327","Virtual Tai-Chi System: A smart-connected modality for rehabilitation","2018","Smart Health","11","10.1016/j.smhl.2018.07.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059788953&doi=10.1016%2fj.smhl.2018.07.021&partnerID=40&md5=e017bbd62de838809c88cff72239620d","Department of Computer Science and Engineering, University of Tennessee at Chattanooga, United States; Department of Sociology, Anthropology, and Geography, University of Tennessee at Chattanooga, United States","Liang Y., Department of Computer Science and Engineering, University of Tennessee at Chattanooga, United States; Wu D., Department of Computer Science and Engineering, University of Tennessee at Chattanooga, United States; Ledesma D., Department of Computer Science and Engineering, University of Tennessee at Chattanooga, United States; Davis C., Department of Computer Science and Engineering, University of Tennessee at Chattanooga, United States; Slaughter R., Department of Computer Science and Engineering, University of Tennessee at Chattanooga, United States; Guo Z., Department of Sociology, Anthropology, and Geography, University of Tennessee at Chattanooga, United States","This work intends to develop an intelligent, four-dimensional (namely X-Y-Z plus somatosensory), partial control, and virtual-reality-enabled Tai-Chi System (VTCS). Tai-Chi is a traditional mind-body wellness and healing art, and its clinical benefits have been well documented. VTCS integrates Tai-Chi with a series of cutting-edge computer technologies including 4D sensor technology, big-data, signal processing and analysis, human body kinematics, deep learning, virtual reality, and 4D-reconstruction, etc. The aforementioned system will generate a controllable and consistent 4D experience to help, push and coach (HPC) people to get involved in sports activities. In particular, VTCS makes Tai-Chi movements suitable to individuals who suffer from mobility disabilities due to diseases or injuries as an accessible rehabilitation and fitness modality. VTCS consists of the following modules: acquisition, transmission and reconstruction of user׳s 4D data, data preprocessing, identification of user׳s kinetic movement, and individualized movement choreography. Under the support of collaborative hospitals, the physiological and psychological benefits brought about by VTCS will be critically assessed. © 2018 Elsevier Inc.","Deep learning; Kinetics; Rehabilitation; Sensor and actuator; Tai-Chi; Virtual reality","Article; body movement; choreography; decision tree; fitness; gesture; healing; human; image reconstruction; kinematics; machine learning; medical technology; signal processing; support vector machine; Tai Chi; telerehabilitation; time series analysis; virtual reality; virtual Tai Chi system; walking difficulty; wellbeing","Elsevier B.V.","23526483","","","","Article","Scopus","2-s2.0-85059788953"
"Zuallaert J.; Godin F.; Kim M.; Soete A.; Saeys Y.; De Neve W.","Zuallaert, Jasper (57197796771); Godin, Fréderic (55694006500); Kim, Mijung (57202224671); Soete, Arne (55846639500); Saeys, Yvan (6507925214); De Neve, Wesley (7005851618)","57197796771; 55694006500; 57202224671; 55846639500; 6507925214; 7005851618","Splicerover: Interpretable convolutional neural networks for improved splice site prediction","2018","Bioinformatics","68","10.1093/bioinformatics/bty497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058444187&doi=10.1093%2fbioinformatics%2fbty497&partnerID=40&md5=7766b05bd9215f05d5bd403e51b3446b","Center for Biotech Data Science, Department of Environmental Technology, Food Technology and Molecular Biotechnology, Ghent University Global Campus, Songdo, Incheon, 305-701, South Korea; IDLab, Department for Electronics and Information Systems, Ghent University, Ghent, 9000, Belgium; Department of Biomedical Molecular Biology, Ghent University, Ghent, Belgium; Data Mining and Modeling for Biomedicine, VIB Inflammation Research Center, Ghent, Belgium; Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Ghent, Belgium","Zuallaert J., Center for Biotech Data Science, Department of Environmental Technology, Food Technology and Molecular Biotechnology, Ghent University Global Campus, Songdo, Incheon, 305-701, South Korea, IDLab, Department for Electronics and Information Systems, Ghent University, Ghent, 9000, Belgium; Godin F., IDLab, Department for Electronics and Information Systems, Ghent University, Ghent, 9000, Belgium; Kim M., Center for Biotech Data Science, Department of Environmental Technology, Food Technology and Molecular Biotechnology, Ghent University Global Campus, Songdo, Incheon, 305-701, South Korea, IDLab, Department for Electronics and Information Systems, Ghent University, Ghent, 9000, Belgium; Soete A., Department of Biomedical Molecular Biology, Ghent University, Ghent, Belgium, Data Mining and Modeling for Biomedicine, VIB Inflammation Research Center, Ghent, Belgium; Saeys Y., Data Mining and Modeling for Biomedicine, VIB Inflammation Research Center, Ghent, Belgium, Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Ghent, Belgium; De Neve W., Center for Biotech Data Science, Department of Environmental Technology, Food Technology and Molecular Biotechnology, Ghent University Global Campus, Songdo, Incheon, 305-701, South Korea, IDLab, Department for Electronics and Information Systems, Ghent University, Ghent, 9000, Belgium","Motivation: During the last decade, improvements in high-throughput sequencing have generated a wealth of genomic data. Functionally interpreting these sequences and finding the biological signals that are hallmarks of gene function and regulation is currently mostly done using automated genome annotation platforms, which mainly rely on integrated machine learning frameworks to identify different functional sites of interest, including splice sites. Splicing is an essential step in the gene regulation process, and the correct identification of splice sites is a major cornerstone in a genome annotation system. Results: In this paper, we present SpliceRover, a predictive deep learning approach that outperforms the state-of-the-art in splice site prediction. SpliceRover uses convolutional neural networks (CNNs), which have been shown to obtain cutting edge performance on a wide variety of prediction tasks. We adapted this approach to deal with genomic sequence inputs, and show it consistently outperforms already existing approaches, with relative improvements in prediction effectiveness of up to 80.9% when measured in terms of false discovery rate. However, a major criticism of CNNs concerns their ‘black box’ nature, as mechanisms to obtain insight into their reasoning processes are limited. To facilitate interpretability of the SpliceRover models, we introduce an approach to visualize the biologically relevant information learnt. We show that our visualization approach is able to recover features known to be important for splice site prediction (binding motifs around the splice site, presence of polypyrimidine tracts and branch points), as well as reveal new features (e.g. several types of exclusion patterns near splice sites). © The Author(s) 2018. Published by Oxford University Press. All rights reserved.","","Computational Biology; Genomics; High-Throughput Nucleotide Sequencing; Machine Learning; Neural Networks (Computer); RNA Splicing; Software; article; deep learning; prediction; artificial neural network; biology; genomics; high throughput sequencing; machine learning; RNA splicing; software","Oxford University Press","13674803","","BOINF","29931149","Article","Scopus","2-s2.0-85058444187"
"Chen H.-I.H.; Chiu Y.-C.; Zhang T.; Zhang S.; Huang Y.; Chen Y.","Chen, Hung-I Harry (57148954800); Chiu, Yu-Chiao (55330817500); Zhang, Tinghe (57196191482); Zhang, Songyao (57205182206); Huang, Yufei (35558675700); Chen, Yidong (35179060900)","57148954800; 55330817500; 57196191482; 57205182206; 35558675700; 35179060900","GSAE: An autoencoder with embedded gene-set nodes for genomics functional characterization","2018","BMC Systems Biology","33","10.1186/s12918-018-0642-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058915812&doi=10.1186%2fs12918-018-0642-2&partnerID=40&md5=14704ce1a1cb5ddae5a5df38b9c7ab85","The University of Texas at San Antonio, Department of Electrical and Computer Engineering, San Antonio, 78249, TX, United States; The University of Texas Health Science Center at San Antonio, Greehey Children's Cancer Research Institute, San Antonio, 78229, TX, United States; The University of Texas Health Science Center at San Antonio, Department of Epidemiology and Biostatistics, San Antonio, 78229, TX, United States; Northwestern Polytechnical University, Laboratory of Information Fusion Technology of Ministry of Education, School of Automation, Xi'an, Shaanxi, 710072, China","Chen H.-I.H., The University of Texas at San Antonio, Department of Electrical and Computer Engineering, San Antonio, 78249, TX, United States, The University of Texas Health Science Center at San Antonio, Greehey Children's Cancer Research Institute, San Antonio, 78229, TX, United States; Chiu Y.-C., The University of Texas Health Science Center at San Antonio, Greehey Children's Cancer Research Institute, San Antonio, 78229, TX, United States; Zhang T., The University of Texas at San Antonio, Department of Electrical and Computer Engineering, San Antonio, 78249, TX, United States; Zhang S., The University of Texas at San Antonio, Department of Electrical and Computer Engineering, San Antonio, 78249, TX, United States, Northwestern Polytechnical University, Laboratory of Information Fusion Technology of Ministry of Education, School of Automation, Xi'an, Shaanxi, 710072, China; Huang Y., The University of Texas at San Antonio, Department of Electrical and Computer Engineering, San Antonio, 78249, TX, United States; Chen Y., The University of Texas Health Science Center at San Antonio, Greehey Children's Cancer Research Institute, San Antonio, 78229, TX, United States, The University of Texas Health Science Center at San Antonio, Department of Epidemiology and Biostatistics, San Antonio, 78229, TX, United States","Background: Bioinformatics tools have been developed to interpret gene expression data at the gene set level, and these gene set based analyses improve the biologists' capability to discover functional relevance of their experiment design. While elucidating gene set individually, inter-gene sets association is rarely taken into consideration. Deep learning, an emerging machine learning technique in computational biology, can be used to generate an unbiased combination of gene set, and to determine the biological relevance and analysis consistency of these combining gene sets by leveraging large genomic data sets. Results: In this study, we proposed a gene superset autoencoder (GSAE), a multi-layer autoencoder model with the incorporation of a priori defined gene sets that retain the crucial biological features in the latent layer. We introduced the concept of the gene superset, an unbiased combination of gene sets with weights trained by the autoencoder, where each node in the latent layer is a superset. Trained with genomic data from TCGA and evaluated with their accompanying clinical parameters, we showed gene supersets' ability of discriminating tumor subtypes and their prognostic capability. We further demonstrated the biological relevance of the top component gene sets in the significant supersets. Conclusions: Using autoencoder model and gene superset at its latent layer, we demonstrated that gene supersets retain sufficient biological information with respect to tumor subtypes and clinical prognostic significance. Superset also provides high reproducibility on survival analysis and accurate prediction for cancer subtypes. © 2018 The Author(s).","Autoencoder; Deep learning; Gene superset analysis; Survival analysis","Adenocarcinoma of Lung; Breast Neoplasms; Genomics; Humans; Machine Learning; Prognosis; Survival Analysis; breast tumor; genetics; genomics; human; lung adenocarcinoma; machine learning; procedures; prognosis; survival analysis","BioMed Central Ltd.","17520509","","","30577835","Article","Scopus","2-s2.0-85058915812"
"Wei X.; Zhou L.; Chen Z.; Zhang L.; Zhou Y.","Wei, Xiaoyan (57203249201); Zhou, Lin (57204937863); Chen, Ziyi (55855230100); Zhang, Liangjun (57204942648); Zhou, Yi (57189067350)","57203249201; 57204937863; 55855230100; 57204942648; 57189067350","Automatic seizure detection using three-dimensional CNN based on multi-channel EEG","2018","BMC Medical Informatics and Decision Making","102","10.1186/s12911-018-0693-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058059017&doi=10.1186%2fs12911-018-0693-8&partnerID=40&md5=f46db777cf8d73ebb91da3d365f8ae10","Department of Biomedical Engineering, Zhongshan School of Medicine, Sun Yat-sen University, Guangzhou, Guangdong Province, 510080, China; Software Engineering, School of Computer and Data Science, Sun Yat-sen University, Guangzhou, Guangdong Province, 510006, China; Department of Neurology, First Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province, 510080, China","Wei X., Department of Biomedical Engineering, Zhongshan School of Medicine, Sun Yat-sen University, Guangzhou, Guangdong Province, 510080, China; Zhou L., Software Engineering, School of Computer and Data Science, Sun Yat-sen University, Guangzhou, Guangdong Province, 510006, China; Chen Z., Department of Neurology, First Affiliated Hospital, Sun Yat-sen University, Guangzhou, Guangdong Province, 510080, China; Zhang L., Department of Biomedical Engineering, Zhongshan School of Medicine, Sun Yat-sen University, Guangzhou, Guangdong Province, 510080, China; Zhou Y., Department of Biomedical Engineering, Zhongshan School of Medicine, Sun Yat-sen University, Guangzhou, Guangdong Province, 510080, China","Background: Automated seizure detection from clinical EEG data can reduce the diagnosis time and facilitate targeting treatment for epileptic patients. However, current detection approaches mainly rely on limited features manually designed by domain experts, which are inflexible for the detection of a variety of patterns in a large amount of patients' EEG data. Moreover, conventional machine learning algorithms for seizure detection cannot accommodate multi-channel Electroencephalogram (EEG) data effectively, which contains both temporal and spatial information. Recently, deep learning technology has been widely applied to perform image processing tasks, which could learns useful features from data and process multi-channel data automatically. To provide an effective system for automatic seizure detection, we proposed a new three-dimensional (3D) convolutional neural network (CNN) structure, whose inputs are multi-channel EEG signals. Methods: EEG data of 13 patients were collected from one center hospital, which has already been inspected by experts. To represent EEG data in CNN, firstly time series of each channel of EEG data was converted into the two-dimensional image. Then all channel images were combined into 3D images according to the mutual correlation intensity between different electrodes. Finally, a CNN was constructed using 3D kernels to predict different stages of EEG data, including inter-ictal, pre-ictal, and ictal stages. The system performance was evaluated and compared with the traditional feature-based classifier and the two-dimensional (2D) deep learning method. Results: It demonstrated that multi-channel EEG data could provide more information for increasing the specificity and sensitivity in cpmparison result between the single and multi-channel. And the 3D CNN based on multi-channel outperformed the 2D CNN and traditional signal processing methods with an accuracy of more than 90%, an sensitivity of 88.90% and an specificity of 93.78%. Conclusions: This is the first effort to apply 3D CNN in detecting seizures from EEG. It provides a new way of learning patterns simultaneously from multi-channel EEG signals, and demonstrates that deep neural networks in combination with 3D kernels can establish an effective system for seizure detection. © 2018 The Author(s).","Convolutional neural network; Epilepsy; Multi-channel; Seizure detection; Three-dimensional","Electroencephalography; Epilepsy; Humans; Machine Learning; Neural Networks (Computer); Seizures; Signal Processing, Computer-Assisted; artificial neural network; electroencephalography; epilepsy; human; machine learning; procedures; seizure; signal processing","BioMed Central Ltd","14726947","","","30526571","Article","Scopus","2-s2.0-85058059017"
"Qiao J.; Lv Y.; Cao C.; Wang Z.; Li A.","Qiao, Jianping (55788169300); Lv, Yingru (55520508400); Cao, Chongfeng (57200370197); Wang, Zhishun (7410044972); Li, Anning (55227645000)","55788169300; 55520508400; 57200370197; 7410044972; 55227645000","Multivariate Deep Learning Classification of Alzheimer’s Disease Based on Hierarchical Partner Matching Independent Component Analysis","2018","Frontiers in Aging Neuroscience","27","10.3389/fnagi.2018.00417","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076258031&doi=10.3389%2ffnagi.2018.00417&partnerID=40&md5=31b2b451d12e4e7194c63b3494f0796c","Shandong Province Key Laboratory of Medical Physics and Image Processing Technology, Institute of Data Science and Technology, School of Physics and Electronics, Shandong Normal University, Jinan, China; Department of Radiology, Huashan Hospital, Fudan University, Shanghai, China; Department of Emergency, Jinan Central Hospital Affiliated to Shandong University, Jinan, China; Department of Psychiatry, Columbia University, New York, NY, United States; Department of Radiology, Qilu Hospital of Shandong University, Jinan, China","Qiao J., Shandong Province Key Laboratory of Medical Physics and Image Processing Technology, Institute of Data Science and Technology, School of Physics and Electronics, Shandong Normal University, Jinan, China; Lv Y., Department of Radiology, Huashan Hospital, Fudan University, Shanghai, China; Cao C., Department of Emergency, Jinan Central Hospital Affiliated to Shandong University, Jinan, China; Wang Z., Department of Psychiatry, Columbia University, New York, NY, United States; Li A., Department of Radiology, Qilu Hospital of Shandong University, Jinan, China","Machine learning and pattern recognition have been widely investigated in order to look for the biomarkers of Alzheimer’s disease (AD). However, most existing methods extract features by seed-based correlation, which not only requires prior information but also ignores the relationship between resting state functional magnetic resonance imaging (rs-fMRI) voxels. In this study, we proposed a deep learning classification framework with multivariate data-driven based feature extraction for automatic diagnosis of AD. Specifically, a three-level hierarchical partner matching independent components analysis (3LHPM-ICA) approach was proposed first in order to address the issues in spatial individual ICA, including the uncertainty of the numbers of components, the randomness of initial values, and the correspondence of ICs of multiple subjects, resulting in stable and reliable ICs which were applied as the intrinsic brain functional connectivity (FC) features. Second, Granger causality (GC) was utilized to infer directional interaction between the ICs that were identified by the 3LHPM-ICA method and extract the effective connectivity features. Finally, a deep learning classification framework was developed to distinguish AD from controls by fusing the functional and effective connectivities. A resting state fMRI dataset containing 34 AD patients and 34 normal controls (NCs) was applied to the multivariate deep learning platform, leading to a classification accuracy of 95.59%, with a sensitivity of 97.06% and a specificity of 94.12% with leave-one-out cross validation (LOOCV). The experimental results demonstrated that the measures of neural connectivities of ICA and GC followed by deep learning classification represented the most powerful methods of distinguishing AD clinical data from NCs, and these aberrant brain connectivities might serve as robust brain biomarkers for AD. This approach also allows for expansion of the methodology to classify other psychiatric disorders. © Copyright © 2018 Qiao, Lv, Cao, Wang and Li.","Alzheimer’s disease; brain network; deep learning; granger causality; independent component analysis","","Frontiers Media S.A.","16634365","","","","Article","Scopus","2-s2.0-85076258031"
"Babu A.V.; Lashkare S.; Ganguly U.; Rajendran B.","Babu, Anakha V (58825328100); Lashkare, Sandip (55342663700); Ganguly, Udayan (7005142369); Rajendran, Bipin (24469154400)","58825328100; 55342663700; 7005142369; 24469154400","Stochastic learning in deep neural networks based on nanoscale PCMO device characteristics","2018","Neurocomputing","12","10.1016/j.neucom.2018.09.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054063561&doi=10.1016%2fj.neucom.2018.09.019&partnerID=40&md5=86d7b3ecb7a2b23a2f2c6b1bb2c87630","Department of Electrical and Computer Engineering, New Jersey Institute of Technology, 07102, NJ, United States; Department of Electrical Engineering, Indian Institute of Technology, Bombay, India","Babu A.V., Department of Electrical and Computer Engineering, New Jersey Institute of Technology, 07102, NJ, United States; Lashkare S., Department of Electrical Engineering, Indian Institute of Technology, Bombay, India; Ganguly U., Department of Electrical Engineering, Indian Institute of Technology, Bombay, India; Rajendran B., Department of Electrical and Computer Engineering, New Jersey Institute of Technology, 07102, NJ, United States","Deep Neural Networks (DNN) have proven to be highly effective in extracting high level abstractions of input data using multiple neural network layers. However, the huge training times for DNNs in traditional von-Neumann machines have hindered their ubiquitous adoption in IoT and other mobile computing platforms. Recently, acceleration of DNN with a time complexity of O(1) was proposed using the idea of stochastic weight update with resistive processing units (RPU). However, it has been projected that RPU devices require more than 1000 reliable conductance levels, which is a stringent requirement to realize in memristive devices. Here, we study the optimization of stochastic learning for DNNs for the hand-written digit classification benchmark using the characteristics of non-filamentary Pr0.7Ca0.3MnO3 (PCMO) devices that are fabricated using a standard lithography process. The electrical characteristics of these devices exhibit a linear conductance response with an on-off ratio of 1.8 with 26 levels and significant programming variability. We captured these non-ideal behaviors of experimental PCMO device in the simulations to demonstrate stochastic learning with O(1) time complexity, achieving a test accuracy of 88.1% for the hand-written digit recognition benchmark. While the linearity, dynamic range, bit resolution, programming variability and the reset rate of the device conductance to account for its limited dynamic range have to be co-optimized for improving the training efficiency, we show that programming variability has the paramount role in determining the network performance. We also show that if devices with reduced programming variability (5x smaller compared to our experimental device) can be developed keeping all other parameters constant, it is possible to boost the network performance as high as 95%. We also observe that the performance of stochastic DNNs with memristive synapses is independent of the on-off ratio of the devices for a fixed programming variability. Thus, programming variability represents a new optimization corner for on-chip learning of stochastic DNNs. Further, we also evaluate the performance of stochastic inference engines to noise corrupted input test data as a function of the variability in the memristive devices. We demonstrate that noise-resilient inference engines can be achieved if 100 bits are used for stochastic encoding during inference even though the expensive network training can be done with as few as 10 bits. Thus, our studies emphasize the need for optimization of learning strategies for DNNs based on the non-ideal characteristics of experimental nanoscale devices. © 2018 Elsevier B.V.","Artificial Neural Networks (ANN); Deep Neural Networks (DNN); Memristor; Non-Volatile memory (NVM); Stochastic Computing","Calcium compounds; Complex networks; Digital storage; Engines; Lithography; Manganese compounds; Memristors; Nanotechnology; Network layers; Network performance; Neural networks; Praseodymium compounds; Stochastic systems; Ubiquitous computing; Electrical characteristic; High-level abstraction; Limited dynamic ranges; Memristor; Multiple neural networks; Non-ideal characteristics; Non-volatile memory; Stochastic computing; acceleration; article; artificial neural network; conductance; learning; memory; noise; simulation; stochastic model; synapse; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85054063561"
"Montesinos-López A.; Montesinos-López O.A.; Gianola D.; Crossa J.; Hernández-Suárez C.M.","Montesinos-López, Abelardo (36104391100); Montesinos-López, Osval A. (16233976300); Gianola, Daniel (7006290311); Crossa, José (7003797730); Hernández-Suárez, Carlos M. (6603175577)","36104391100; 16233976300; 7006290311; 7003797730; 6603175577","Multi-environment genomic prediction of plant traits using deep learners with dense architecture","2018","G3: Genes, Genomes, Genetics","92","10.1534/g3.118.200740","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058155992&doi=10.1534%2fg3.118.200740&partnerID=40&md5=658812c524af3d6962d32bc760c35778","Departamento de Matemáticas, Centro Universitario de Ciencias Exactas e Ingenierías (CUCEI), Universidad de Guadalajara, Guadalajara, Jalisco, 44430, Mexico; Facultad de Telemática, Universidad de Colima, Colima, 28040, Mexico; Departments of Animal Sciences, Dairy Science, and Biostatistics and Medical Informatics, University of Wisconsin-Madison, Madison, 53706, WI, United States; International Maize and Wheat Improvement Center (CIMMYT), Apdo. Postal 6-641, Ciudad de México, 06600, Mexico; Facultad de Ciencias, Universidad de Colima, Colima, 28040, Mexico","Montesinos-López A., Departamento de Matemáticas, Centro Universitario de Ciencias Exactas e Ingenierías (CUCEI), Universidad de Guadalajara, Guadalajara, Jalisco, 44430, Mexico; Montesinos-López O.A., Facultad de Telemática, Universidad de Colima, Colima, 28040, Mexico; Gianola D., Departments of Animal Sciences, Dairy Science, and Biostatistics and Medical Informatics, University of Wisconsin-Madison, Madison, 53706, WI, United States; Crossa J., International Maize and Wheat Improvement Center (CIMMYT), Apdo. Postal 6-641, Ciudad de México, 06600, Mexico; Hernández-Suárez C.M., Facultad de Ciencias, Universidad de Colima, Colima, 28040, Mexico","Genomic selection is revolutionizing plant breeding and therefore methods that improve prediction accuracy are useful. For this reason, active research is being conducted to build and test methods from other areas and adapt them to the context of genomic selection. In this paper we explore the novel deep learning (DL) methodology in the context of genomic selection. We compared DL methods with densely connected network architecture to one of the most often used genome-enabled prediction models: Genomic Best Linear Unbiased Prediction (GBLUP). We used nine published real genomic data sets to compare a fraction of all possible deep learning models to obtain a ""meta picture"" of the performance of DL methods with densely connected network architecture. In general, the best predictions were obtained with the GBLUP model when genotype environment interaction (G E) was taken into account (8 out of 9 data sets); when the interactions were ignored, the DL method was better than the GBLUP in terms of prediction accuracy in 6 out of the 9 data sets. For this reason, we believe that DL should be added to the data science toolkit of scientists working on animal and plant breeding. This study corroborates the view that there are no universally best prediction machines. © 2018 Montesinos-López et al.","accuracy; deep learning; GBLUP; genomic; GenPred; neural network; prediction; prediction; Resources; Shared Data","Gene-Environment Interaction; Machine Learning; Models, Genetic; Predictive Value of Tests; Quantitative Trait, Heritable; Sequence Analysis, DNA; Triticum; Zea mays; article; genome; genotype environment interaction; human; learning; machine; plant breeding; prediction; scientist; biological model; DNA sequence; genetics; genotype environment interaction; machine learning; maize; predictive value; procedures; quantitative trait; wheat","Genetics Society of America","21601836","","","30291107","Article","Scopus","2-s2.0-85058155992"
"Galbusera F.; Bassani T.; Casaroli G.; Gitto S.; Zanchetta E.; Costa F.; Sconfienza L.M.","Galbusera, Fabio (15047667100); Bassani, Tito (23388372700); Casaroli, Gloria (57189334141); Gitto, Salvatore (57188980176); Zanchetta, Edoardo (57191269722); Costa, Francesco (58090366200); Sconfienza, Luca Maria (24448438200)","15047667100; 23388372700; 57189334141; 57188980176; 57191269722; 58090366200; 24448438200","Generative models: an upcoming innovation in musculoskeletal radiology? A preliminary test in spine imaging","2018","European Radiology Experimental","33","10.1186/s41747-018-0060-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066820541&doi=10.1186%2fs41747-018-0060-7&partnerID=40&md5=e759319af7844ef11296632ee3a3fa65","Laboratory of Biological Structures Mechanics, IRCCS Istituto Ortopedico Galeazzi, via Galeazzi 4, Milan, 20161, Italy; Unit of Diagnostic and Interventional Radiology, IRCCS Istituto Ortopedico Galeazzi, via Galeazzi 4, Milan, 20161, Italy; Department of Neurosurgery, Humanitas Clinical and Research Hospital, Via Manzoni 56, Rozzano, 20089, Italy; Department of Biomedical Sciences for Health, Università degli Studi di Milano, via Carlo Pascal 36, Milan, 20133, Italy","Galbusera F., Laboratory of Biological Structures Mechanics, IRCCS Istituto Ortopedico Galeazzi, via Galeazzi 4, Milan, 20161, Italy; Bassani T., Laboratory of Biological Structures Mechanics, IRCCS Istituto Ortopedico Galeazzi, via Galeazzi 4, Milan, 20161, Italy; Casaroli G., Laboratory of Biological Structures Mechanics, IRCCS Istituto Ortopedico Galeazzi, via Galeazzi 4, Milan, 20161, Italy; Gitto S., Unit of Diagnostic and Interventional Radiology, IRCCS Istituto Ortopedico Galeazzi, via Galeazzi 4, Milan, 20161, Italy; Zanchetta E., Unit of Diagnostic and Interventional Radiology, IRCCS Istituto Ortopedico Galeazzi, via Galeazzi 4, Milan, 20161, Italy; Costa F., Department of Neurosurgery, Humanitas Clinical and Research Hospital, Via Manzoni 56, Rozzano, 20089, Italy; Sconfienza L.M., Unit of Diagnostic and Interventional Radiology, IRCCS Istituto Ortopedico Galeazzi, via Galeazzi 4, Milan, 20161, Italy, Department of Biomedical Sciences for Health, Università degli Studi di Milano, via Carlo Pascal 36, Milan, 20133, Italy","Background: Deep learning is a ground-breaking technology that is revolutionising many research and industrial fields. Generative models are recently gaining interest. Here, we investigate their potential, namely conditional generative adversarial networks, in the field of magnetic resonance imaging (MRI) of the spine, by performing clinically relevant benchmark cases. Methods: First, the enhancement of the resolution of T2-weighted (T2W) images (super-resolution) was tested. Then, automated image-to-image translation was tested in the following tasks: (1) from T1-weighted to T2W images of the lumbar spine and (2) vice versa; (3) from T2W to short time inversion-recovery (STIR) images; (4) from T2W to turbo inversion recovery magnitude (TIRM) images; (5) from sagittal standing x-ray projections to T2W images. Clinical and quantitative assessments of the outputs by means of image quality metrics were performed. The training of the models was performed on MRI and x-ray images from 989 patients. Results: The performance of the models was generally positive and promising, but with several limitations. The number of disc protrusions or herniations showed good concordance (κ = 0.691) between native and super-resolution images. Moderate-to-excellent concordance was found when translating T2W to STIR and TIRM images (κ ≥ 0.842 regarding disc degeneration), while the agreement was poor when translating x-ray to T2W images. Conclusions: Conditional generative adversarial networks are able to generate perceptually convincing synthetic images of the spine in super-resolution and image-to-image translation tasks. Taking into account the limitations of the study, deep learning-based generative methods showed the potential to be an upcoming innovation in musculoskeletal radiology. © 2018, The Author(s).","Lumbar vertebrae; Machine learning (deep learning); Magnetic resonance imaging; Neural network (computer); X-rays","","Springer","25099280","","","30377873","Article","Scopus","2-s2.0-85066820541"
"Chou Y.; Qiu T.; Zhong M.","Chou, Yuanting (57207841552); Qiu, Tianshuang (7006115564); Zhong, Mingjun (7102458852)","57207841552; 7006115564; 7102458852","Classification and recognition of P300 event related potential based on convolutional neural network","2018","Chinese Journal of Biomedical Engineering","3","10.3969/j.issn.0258-8021.2018.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063066230&doi=10.3969%2fj.issn.0258-8021.2018.06.003&partnerID=40&md5=7b812cbea038ff81a3eb75e8b4de8d42","Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, Liaoning, 116024, China; Chinese Society of Biomedical Engineering, China","Chou Y., Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, Liaoning, 116024, China, Chinese Society of Biomedical Engineering, China; Qiu T., Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, Liaoning, 116024, China; Zhong M., Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, Liaoning, 116024, China","To improve the recognition rate of P300 potentials in the brain computer interface system, a novel method based on the improved convolutional neural network was proposed. By transforming the second serially connected convolutional layer of a traditional convolution neural network to three parallel connected convolutional layers, the method widens the network to enhance the ability of feature extraction in the proposed network. Combining the extracted features with the fully connected layers and sigmoid function, a P300 visual evoked potential classifier was constructed. Targeting to the problem of unbalanced data volume between target and non-target stimulus data in BCI competition, this paper adopted an oversampling method. To increase the amount of data, this paper partially averaged the EEC data that contains P300 visual evoked potentials. The training set and test set sample sizes were 25500 and 18000, respectively. Adam optimization method was adopted to train the improved convolutional neural network supervisely. The analysis results showed that the proposed network achieved an accuracy of higher than 95 % when the number of experiments was over 11 times, which is of great significance for the application of brain-computer interface. © 2019 Chinese Academy of Medical Sciences. All rights reserved.","Classification recognition; Convolutional neural network; Deep learning; P300","Article; brain computer interface; classification algorithm; convolutional neural network; diagnostic accuracy; electroencephalogram; event related potential; feature extraction; machine learning; sample size; visual evoked potential","Chinese Academy of Medical Sciences","02588021","","ZSYXE","","Article","Scopus","2-s2.0-85063066230"
"Luo J.; Ning Z.; Zhang S.; Feng Q.; Zhang Y.","Luo, Jiaxiu (57202303903); Ning, Zhenyuan (57194600411); Zhang, Shuixing (35084570500); Feng, Qianjin (14826518100); Zhang, Yu (19838706500)","57202303903; 57194600411; 35084570500; 14826518100; 19838706500","Bag of deep features for preoperative prediction of sentinel lymph node metastasis in breast cancer","2018","Physics in Medicine and Biology","28","10.1088/1361-6560/aaf241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058727631&doi=10.1088%2f1361-6560%2faaf241&partnerID=40&md5=ab3ddab28b9dcb45e11a5838df6feee4","School of Biomedical Engineering, Southern Medical University, Guangzhou, GUANGDONG, 510515, China; Department of Radiology, Guangdong General Hospital, Guangdong Academy of Medical Sciences, No. 106 Zhongshan Er Road, Guangzhou, GUANGDONG, 510080, China","Luo J., School of Biomedical Engineering, Southern Medical University, Guangzhou, GUANGDONG, 510515, China; Ning Z., School of Biomedical Engineering, Southern Medical University, Guangzhou, GUANGDONG, 510515, China; Zhang S., Department of Radiology, Guangdong General Hospital, Guangdong Academy of Medical Sciences, No. 106 Zhongshan Er Road, Guangzhou, GUANGDONG, 510080, China; Feng Q., School of Biomedical Engineering, Southern Medical University, Guangzhou, GUANGDONG, 510515, China; Zhang Y., School of Biomedical Engineering, Southern Medical University, Guangzhou, GUANGDONG, 510515, China","Breast cancer is the most common female malignancy among women. Sentinel lymph node (SLN) status is a crucial prognostic factor for breast cancer. In this paper, we propose an integrated scheme of deep learning and bag-of-features (BOF) model for preoperative prediction of SLN metastasis. Specifically, convolution neural networks (CNNs) are used to extract deep features from the three 2D representative orthogonal views of a segmented 3D volume of interest. Then, we use a BOF model to furtherly encode the all deep features, which makes features more compact and products high-dimension sparse representation. In particular, a kernel fusion method that assembles all features is proposed to build a discriminative support vector machine (SVM) classifier. The bag of deep feature model is evaluated using the diffusion-weighted magnetic resonance imaging (DWI) database of 172 patients, including 74 SLN and 98 non-SLN. The results show that the proposed method achieves area under the curve (AUC) as high as 0.852 (95% confidence interval (CI): 0.716-0.988) at test set. The results demonstrate that the proposed model can potentially provide a noninvasive approach for automatically predicting prediction of SLN metastasis in patients with breast cancer. © 2018 Institute of Physics and Engineering in Medicine.","bag-of-features; convolution neural network; kernel fusion; sentinel lymph node metastasis","Adult; Area Under Curve; Breast Neoplasms; Diffusion Magnetic Resonance Imaging; False Positive Reactions; Female; Humans; Image Processing, Computer-Assisted; Lymphatic Metastasis; Middle Aged; Neoplasms, Second Primary; Preoperative Period; Reproducibility of Results; ROC Curve; Sentinel Lymph Node; Sentinel Lymph Node Biopsy; Support Vector Machine; Body fluids; Convolution; Diseases; Forecasting; Magnetic resonance imaging; Pathology; Support vector machines; Area Under the Curve (AUC); Bag of features; Convolution neural network; Diffusion-weighted magnetic resonance imaging; Kernel fusion; Sentinel lymph node metastasis; Sentinel lymph nodes; Sparse representation; adult; area under the curve; breast tumor; diagnostic imaging; diffusion weighted imaging; false positive result; female; human; image processing; lymph node metastasis; middle aged; pathology; preoperative period; procedures; receiver operating characteristic; reproducibility; second cancer; sentinel lymph node; sentinel lymph node biopsy; support vector machine; Deep learning","Institute of Physics Publishing","00319155","","PHMBA","30523819","Article","Scopus","2-s2.0-85058727631"
"Tiwari P.; Qian J.; Li Q.; Wang B.; Gupta D.; Khanna A.; Rodrigues J.J.P.C.; Hugo C.V.","Tiwari, Prayag (57193601962); Qian, Jia (57202905995); Li, Qiuchi (57043626600); Wang, Benyou (57142881300); Gupta, Deepak (56985108600); Khanna, Ashish (34968180100); Rodrigues, Joel J.P.C. (25930566300); Hugo, C. Victor (57204569341)","57193601962; 57202905995; 57043626600; 57142881300; 56985108600; 34968180100; 25930566300; 57204569341","Detection of subtype blood cells using deep learning","2018","Cognitive Systems Research","92","10.1016/j.cogsys.2018.08.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055419735&doi=10.1016%2fj.cogsys.2018.08.022&partnerID=40&md5=d3f5cf2c89888c1121b0a3456cbb7fd9","Department of Information Engineering, University of Padova, Italy; Department of Applied Mathematics and Computer Science, Denmark Technology University, Denmark; Maharaja Agrasen Institute of Technology, Delhi, India; National Institute of Telecommunications (Inatel), Santa Rita do Sapucaí, MG, Brazil; Instituto de Telecomunicações, Portugal; de Albuquerque, University of Fortaleza (UNIFOR), Fortaleza/CE, CE, Brazil","Tiwari P., Department of Information Engineering, University of Padova, Italy; Qian J., Department of Applied Mathematics and Computer Science, Denmark Technology University, Denmark; Li Q., Department of Information Engineering, University of Padova, Italy; Wang B., Department of Information Engineering, University of Padova, Italy; Gupta D., Maharaja Agrasen Institute of Technology, Delhi, India; Khanna A., Maharaja Agrasen Institute of Technology, Delhi, India; Rodrigues J.J.P.C., National Institute of Telecommunications (Inatel), Santa Rita do Sapucaí, MG, Brazil, Instituto de Telecomunicações, Portugal; Hugo C.V., de Albuquerque, University of Fortaleza (UNIFOR), Fortaleza/CE, CE, Brazil","Deep Learning has already shown power in many application fields, and is accepted by more and more people as a better approach than the traditional machine learning models. In particular, the implementation of deep learning algorithms, especially Convolutional Neural Networks (CNN), brings huge benefits to the medical field, where a huge number of images are to be processed and analyzed. This paper aims to develop a deep learning model to address the blood cell classification problem, which is one of the most challenging problems in blood diagnosis. A CNN-based framework is built to automatically classify the blood cell images into subtypes of the cells. Experiments are conducted on a dataset of 13k images of blood cells with their subtypes, and the results show that our proposed model provide better results in terms of evaluation parameters. © 2018 Elsevier B.V.","Blood cells; Classification; CNN","Blood; Cells; Classification (of information); Computer aided diagnosis; Cytology; Learning algorithms; Medical imaging; Neural networks; Application fields; Blood cell classifications; Blood cell images; Blood cells; Convolutional Neural Networks (CNN); Evaluation parameters; Learning models; Machine learning models; article; blood cell; diagnosis; human; human cell; learning; Deep learning","Elsevier B.V.","13890417","","CSROA","","Article","Scopus","2-s2.0-85055419735"
"Wang J.; Li Y.; Wang Y.; Huang W.","Wang, Jianping (57195296790); Li, Yongxin (54417452800); Wang, Ya (56973840900); Huang, Wenhua (55709665500)","57195296790; 54417452800; 56973840900; 55709665500","Multimodal Data and Machine Learning for Detecting Specific Biomarkers in Pediatric Epilepsy Patients With Generalized Tonic-Clonic Seizures","2018","Frontiers in Neurology","15","10.3389/fneur.2018.01038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083983633&doi=10.3389%2ffneur.2018.01038&partnerID=40&md5=b76a3da38d0492a959958b9284d1a2ae","The Second Affiliated Hospital of Guangzhou Medical University, Guangzhou, China; Guangdong Provincial Key Laboratory of Medical Biomechanics, School of Basic Medical Sciences, Southern Medical University, Guangzhou, China","Wang J., The Second Affiliated Hospital of Guangzhou Medical University, Guangzhou, China; Li Y., Guangdong Provincial Key Laboratory of Medical Biomechanics, School of Basic Medical Sciences, Southern Medical University, Guangzhou, China; Wang Y., Guangdong Provincial Key Laboratory of Medical Biomechanics, School of Basic Medical Sciences, Southern Medical University, Guangzhou, China; Huang W., Guangdong Provincial Key Laboratory of Medical Biomechanics, School of Basic Medical Sciences, Southern Medical University, Guangzhou, China","Previous neuroimaging studies of epilepsy with generalized tonic-clonic seizures (GTCS) focus mainly on adults. However, the neural mechanisms that underline this type of epilepsy remain unclear, especially for children. The aim of the present study was to detect the effect of epilepsy on brains of children with GTCS and to investigate whether the changes in the brain can be used to discriminate between epileptic children and healthy children at the level of the individual. To achieve this purpose, we measured gray matter (GM) volume and fractional amplitude of low-frequency fluctuation (fALFF) differences on multimodel magnetic resonance imaging in 14 children with GTCS and 30 age- and gender-matched healthy controls. The patients showed GM volume reduction and a fALFF increase in the thalamus, hippocampus, temporal and other deep nuclei. A significant decrease of fALFF was mainly found in the default mode network (DMN). In addition, epileptic duration was significantly negatively related to the GM volumes and significantly positively related to the fALFF value of right thalamus. A support vector machine (SVM) applied to the GM volume of the right thalamus correctly identified epileptic children with a statistically significant accuracy of 74.42% (P < 0.002). A SVM applied to the fALFF of the right thalamus correctly identified epileptic children with a statistically significant accuracy of 83.72% (P < 0.002). The consistent neuroimaging results indicated that the right thalamus plays an important role in reflecting the chronic damaging effect of GTCS epilepsy in children. The length of time of a child's epileptic history was correlated with greater GM volume reduction and a fALFF increase in the right thalamus. GM volumes and fALFF values in the right thalamus can identify children with GTCS from the healthy controls with high accuracy and at an individual subject level. These results are likely to be valuable in explaining the clinical problems and understanding the brain abnormalities underlying this disorder. © Copyright © 2018 Wang, Li, Wang and Huang.","epilepsy children; fractional ALFF; generalized tonic-clonic seizures; gray matter volume; resting-state fMRI; support vector machine; voxel-based morphometry","","Frontiers Media S.A.","16642295","","","","Article","Scopus","2-s2.0-85083983633"
"Qiu J.X.; Yoon H.-J.; Srivastava K.; Watson T.P.; Blair Christian J.; Ramanathan A.; Wu X.C.; Fearn P.A.; Tourassi G.D.","Qiu, John X. (57200219582); Yoon, Hong-Jun (34874205500); Srivastava, Kshitij (57205176603); Watson, Thomas P. (57212950188); Blair Christian, J. (57205176784); Ramanathan, Arvind (57204334274); Wu, Xiao C. (57195914635); Fearn, Paul A. (57217963699); Tourassi, Georgia D. (7003845683)","57200219582; 34874205500; 57205176603; 57212950188; 57205176784; 57204334274; 57195914635; 57217963699; 7003845683","Scalable deep text comprehension for Cancer surveillance on high-performance computing","2018","BMC Bioinformatics","8","10.1186/s12859-018-2511-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058912934&doi=10.1186%2fs12859-018-2511-9&partnerID=40&md5=41abc035a8228167c076d527cd5b9da8","Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, United States; University of Memphis, Herff College of Engineering, Memphis, TN, United States; Louisiana Tumor Registry, Louisiana State University Health Sciences Center, New Orleans, LA, United States; Surveillance Research Program, National Cancer Institute, Bethesda, MD, United States","Qiu J.X., Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Yoon H.-J., Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Srivastava K., Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Watson T.P., University of Memphis, Herff College of Engineering, Memphis, TN, United States; Blair Christian J., Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Ramanathan A., Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Wu X.C., Louisiana Tumor Registry, Louisiana State University Health Sciences Center, New Orleans, LA, United States; Fearn P.A., Surveillance Research Program, National Cancer Institute, Bethesda, MD, United States; Tourassi G.D., Biomedical Sciences, Engineering, and Computing Group, Health Data Science Institute, Oak Ridge National Laboratory, Oak Ridge, TN, United States","Background: Deep Learning (DL) has advanced the state-of-the-art capabilities in bioinformatics applications which has resulted in trends of increasingly sophisticated and computationally demanding models trained by larger and larger data sets. This vastly increased computational demand challenges the feasibility of conducting cutting-edge research. One solution is to distribute the vast computational workload across multiple computing cluster nodes with data parallelism algorithms. In this study, we used a High-Performance Computing environment and implemented the Downpour Stochastic Gradient Descent algorithm for data parallelism to train a Convolutional Neural Network (CNN) for the natural language processing task of information extraction from a massive dataset of cancer pathology reports. We evaluated the scalability improvements using data parallelism training and the Titan supercomputer at Oak Ridge Leadership Computing Facility. To evaluate scalability, we used different numbers of worker nodes and performed a set of experiments comparing the effects of different training batch sizes and optimizer functions. Results: We found that Adadelta would consistently converge at a lower validation loss, though requiring over twice as many training epochs as the fastest converging optimizer, RMSProp. The Adam optimizer consistently achieved a close 2nd place minimum validation loss significantly faster; using a batch size of 16 and 32 allowed the network to converge in only 4.5 training epochs. Conclusions: We demonstrated that the networked training process is scalable across multiple compute nodes communicating with message passing interface while achieving higher classification accuracy compared to a traditional machine learning algorithm. © 2018 The Author(s).","","Comprehension; Computing Methodologies; Deep Learning; Humans; Neoplasms; Neural Networks (Computer); Cluster computing; Clustering algorithms; Deep learning; Diseases; Learning algorithms; Message passing; Natural language processing systems; Neural networks; Optimization; Scalability; Stochastic systems; Supercomputers; Bioinformatics applications; Classification accuracy; Computational demands; Computational workload; Convolutional Neural Networks (CNN); High performance computing; Message passing interface; Stochastic gradient descent algorithm; artificial neural network; comprehension; computer analysis; human; neoplasm; pathology; trends; Data mining","BioMed Central Ltd.","14712105","","BBMIC","30577743","Article","Scopus","2-s2.0-85058912934"
"Kazuhiro K.; Werner R.A.; Toriumi F.; Javadi M.S.; Pomper M.G.; Solnes L.B.; Verde F.; Higuchi T.; Rowe S.P.","Kazuhiro, Koshino (57215606537); Werner, Rudolf A. (56073054700); Toriumi, Fujio (22836892600); Javadi, Mehrbod S. (56209777300); Pomper, Martin G. (35248909800); Solnes, Lilja B. (38762090900); Verde, Franco (56512560700); Higuchi, Takahiro (56025382900); Rowe, Steven P. (56112456800)","57215606537; 56073054700; 22836892600; 56209777300; 35248909800; 38762090900; 56512560700; 56025382900; 56112456800","Generative Adversarial Networks for the Creation of Realistic Artificial Brain Magnetic Resonance Images","2018","Tomography (Ann Arbor, Mich.)","59","10.18383/j.tom.2018.00042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078504503&doi=10.18383%2fj.tom.2018.00042&partnerID=40&md5=e277e53a22eb422c5497f7bc60773d07","Department of Biomedical Imaging, National Cardiovascular and Cerebral Research Center, Suita, Japan; Russell H. Morgan Department of Radiology and Radiological Science, Division of Nuclear Medicine and Molecular Imaging, Johns Hopkins School University of Medicine, MD, Baltimore, United States; Department of Nuclear Medicine, University Hospital, University of Würzburg, Würzburg, Germany; Comprehensive Heart Failure Center, University Hospital, University of Würzburg, Würzburg, Germany; Department of Systems Innovation, Graduate School of Engineering, University of Tokyo, Bunkyō-ku, Japan; Department of Urology and The James Buchanan Brady Urological Institute, Johns Hopkins University School of Medicine, Baltimore, MD; and; Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins School University of Medicine, MD, Baltimore, United States","Kazuhiro K., Department of Biomedical Imaging, National Cardiovascular and Cerebral Research Center, Suita, Japan; Werner R.A., Russell H. Morgan Department of Radiology and Radiological Science, Division of Nuclear Medicine and Molecular Imaging, Johns Hopkins School University of Medicine, MD, Baltimore, United States, Department of Nuclear Medicine, University Hospital, University of Würzburg, Würzburg, Germany, Comprehensive Heart Failure Center, University Hospital, University of Würzburg, Würzburg, Germany; Toriumi F., Department of Systems Innovation, Graduate School of Engineering, University of Tokyo, Bunkyō-ku, Japan; Javadi M.S., Russell H. Morgan Department of Radiology and Radiological Science, Division of Nuclear Medicine and Molecular Imaging, Johns Hopkins School University of Medicine, MD, Baltimore, United States; Pomper M.G., Russell H. Morgan Department of Radiology and Radiological Science, Division of Nuclear Medicine and Molecular Imaging, Johns Hopkins School University of Medicine, MD, Baltimore, United States, Department of Urology and The James Buchanan Brady Urological Institute, Johns Hopkins University School of Medicine, Baltimore, MD; and, Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins School University of Medicine, MD, Baltimore, United States; Solnes L.B., Russell H. Morgan Department of Radiology and Radiological Science, Division of Nuclear Medicine and Molecular Imaging, Johns Hopkins School University of Medicine, MD, Baltimore, United States; Verde F., Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins School University of Medicine, MD, Baltimore, United States; Higuchi T., Department of Biomedical Imaging, National Cardiovascular and Cerebral Research Center, Suita, Japan, Department of Nuclear Medicine, University Hospital, University of Würzburg, Würzburg, Germany, Comprehensive Heart Failure Center, University Hospital, University of Würzburg, Würzburg, Germany; Rowe S.P., Russell H. Morgan Department of Radiology and Radiological Science, Division of Nuclear Medicine and Molecular Imaging, Johns Hopkins School University of Medicine, MD, Baltimore, United States, Department of Urology and The James Buchanan Brady Urological Institute, Johns Hopkins University School of Medicine, Baltimore, MD; and, Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins School University of Medicine, MD, Baltimore, United States","Even as medical data sets become more publicly accessible, most are restricted to specific medical conditions. Thus, data collection for machine learning approaches remains challenging, and synthetic data augmentation, such as generative adversarial networks (GAN), may overcome this hurdle. In the present quality control study, deep convolutional GAN (DCGAN)-based human brain magnetic resonance (MR) images were validated by blinded radiologists. In total, 96 T1-weighted brain images from 30 healthy individuals and 33 patients with cerebrovascular accident were included. A training data set was generated from the T1-weighted images and DCGAN was applied to generate additional artificial brain images. The likelihood that images were DCGAN-created versus acquired was evaluated by 5 radiologists (2 neuroradiologists [NRs], vs 3 non-neuroradiologists [NNRs]) in a binary fashion to identify real vs created images. Images were selected randomly from the data set (variation of created images, 40%-60%). None of the investigated images was rated as unknown. Of the created images, the NRs rated 45% and 71% as real magnetic resonance imaging images (NNRs, 24%, 40%, and 44%). In contradistinction, 44% and 70% of the real images were rated as generated images by NRs (NNRs, 10%, 17%, and 27%). The accuracy for the NRs was 0.55 and 0.30 (NNRs, 0.83, 0.72, and 0.64). DCGAN-created brain MR images are similar enough to acquired MR images so as to be indistinguishable in some cases. Such an artificial intelligence algorithm may contribute to synthetic data augmentation for ""data-hungry"" technologies, such as supervised machine learning approaches, in various clinical applications.","AI; artificial intelligence; DCGAN; GAN; machine learning; magnetic resonance imaging; MRI; stroke","","NLM (Medline)","2379139X","","","30588501","Article","Scopus","2-s2.0-85078504503"
"Weigert M.; Schmidt U.; Boothe T.; Müller A.; Dibrov A.; Jain A.; Wilhelm B.; Schmidt D.; Broaddus C.; Culley S.; Rocha-Martins M.; Segovia-Miranda F.; Norden C.; Henriques R.; Zerial M.; Solimena M.; Rink J.; Tomancak P.; Royer L.; Jug F.; Myers E.W.","Weigert, Martin (56661906000); Schmidt, Uwe (57189908064); Boothe, Tobias (57188807810); Müller, Andreas (7201673533); Dibrov, Alexandr (57204814130); Jain, Akanksha (57204819915); Wilhelm, Benjamin (57213341660); Schmidt, Deborah (57204814604); Broaddus, Coleman (57090514900); Culley, Siân (56177001000); Rocha-Martins, Mauricio (55339963700); Segovia-Miranda, Fabián (56462974000); Norden, Caren (8544251500); Henriques, Ricardo (30067763700); Zerial, Marino (7005631145); Solimena, Michele (7006817892); Rink, Jochen (7003908970); Tomancak, Pavel (6508156550); Royer, Loic (57204322516); Jug, Florian (36608176600); Myers, Eugene W. (7201701797)","56661906000; 57189908064; 57188807810; 7201673533; 57204814130; 57204819915; 57213341660; 57204814604; 57090514900; 56177001000; 55339963700; 56462974000; 8544251500; 30067763700; 7005631145; 7006817892; 7003908970; 6508156550; 57204322516; 36608176600; 7201701797","Content-aware image restoration: pushing the limits of fluorescence microscopy","2018","Nature Methods","590","10.1038/s41592-018-0216-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057342134&doi=10.1038%2fs41592-018-0216-7&partnerID=40&md5=2c2fa1c3b02817d5f05de3ad6f6ccd51","Center for Systems Biology Dresden, Dresden, Germany; Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Molecular Diabetology, University Hospital and Faculty of Medicine Carl Gustav Carus, TU Dresden, Dresden, Germany; Paul Langerhans Institute Dresden of the Helmholtz Center Munich at the University Hospital Carl Gustav Carus and Faculty of Medicine of the TU Dresden, Dresden, Germany; German Center for Diabetes Research (DZD e.V.), Neuherberg, Germany; University of Konstanz, Konstanz, Germany; MRC Laboratory for Molecular Cell Biology, University College London, London, United Kingdom; The Francis Crick Institute, London, United Kingdom; CZ Biohub, San Francisco, CA, United States; Department of Computer Science, Technical University Dresden, Dresden, Germany","Weigert M., Center for Systems Biology Dresden, Dresden, Germany, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Schmidt U., Center for Systems Biology Dresden, Dresden, Germany, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Boothe T., Center for Systems Biology Dresden, Dresden, Germany, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Müller A., Molecular Diabetology, University Hospital and Faculty of Medicine Carl Gustav Carus, TU Dresden, Dresden, Germany, Paul Langerhans Institute Dresden of the Helmholtz Center Munich at the University Hospital Carl Gustav Carus and Faculty of Medicine of the TU Dresden, Dresden, Germany, German Center for Diabetes Research (DZD e.V.), Neuherberg, Germany; Dibrov A., Center for Systems Biology Dresden, Dresden, Germany, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Jain A., Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Wilhelm B., Center for Systems Biology Dresden, Dresden, Germany, University of Konstanz, Konstanz, Germany; Schmidt D., Center for Systems Biology Dresden, Dresden, Germany; Broaddus C., Center for Systems Biology Dresden, Dresden, Germany, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Culley S., MRC Laboratory for Molecular Cell Biology, University College London, London, United Kingdom, The Francis Crick Institute, London, United Kingdom; Rocha-Martins M., Center for Systems Biology Dresden, Dresden, Germany, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Segovia-Miranda F., Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Norden C., Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Henriques R., MRC Laboratory for Molecular Cell Biology, University College London, London, United Kingdom, The Francis Crick Institute, London, United Kingdom; Zerial M., Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Solimena M., Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany, Molecular Diabetology, University Hospital and Faculty of Medicine Carl Gustav Carus, TU Dresden, Dresden, Germany, Paul Langerhans Institute Dresden of the Helmholtz Center Munich at the University Hospital Carl Gustav Carus and Faculty of Medicine of the TU Dresden, Dresden, Germany, German Center for Diabetes Research (DZD e.V.), Neuherberg, Germany; Rink J., Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Tomancak P., Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Royer L., Center for Systems Biology Dresden, Dresden, Germany, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany, CZ Biohub, San Francisco, CA, United States; Jug F., Center for Systems Biology Dresden, Dresden, Germany, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Myers E.W., Center for Systems Biology Dresden, Dresden, Germany, Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany, Department of Computer Science, Technical University Dresden, Dresden, Germany","Fluorescence microscopy is a key driver of discoveries in the life sciences, with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample. These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth. In this work we show how content-aware image restoration based on deep learning extends the range of biological phenomena observable by microscopy. We demonstrate on eight concrete examples how microscopy images can be restored even if 60-fold fewer photons are used during acquisition, how near isotropic resolution can be achieved with up to tenfold under-sampling along the axial direction, and how tubular and granular structures smaller than the diffraction limit can be resolved at 20-times-higher frame rates compared to state-of-the-art methods. All developed image restoration methods are freely available as open source software in Python, FIJI, and KNIME. © 2018, The Author(s), under exclusive licence to Springer Nature America, Inc.","","Animals; Drosophila melanogaster; Fluorescent Dyes; HeLa Cells; Humans; Image Processing, Computer-Assisted; Liver; Microscopy, Fluorescence; Photons; Planarians; Retina; Software; Tribolium; Zebrafish; fluorescent dye; Article; confocal microscopy; content aware image restoration; deep learning; fluorescence microscopy; HeLa cell line; image processing; image reconstruction; image segmentation; imaging and display; INS-1 cell line; light exposure; machine learning; microtubule; nonhuman; photon; prediction; priority journal; probability; Schmidtea mediterranea; secretory granule; three dimensional imaging; Tribolium castaneum; animal; chemistry; Drosophila melanogaster; fluorescence microscopy; human; image processing; liver; metabolism; photon; procedures; retina; software; Tribolium; Turbellaria; ultrastructure; zebra fish","Nature Publishing Group","15487091","","","30478326","Article","Scopus","2-s2.0-85057342134"
"Nie A.; Zehnder A.; Page R.L.; Zhang Y.; Pineda A.L.; Rivas M.A.; Bustamante C.D.; Zou J.","Nie, Allen (57212142939); Zehnder, Ashley (25643658900); Page, Rodney L. (7402109892); Zhang, Yuhui (57219794142); Pineda, Arturo Lopez (57197894611); Rivas, Manuel A. (57208733620); Bustamante, Carlos D. (57222596098); Zou, James (26326649300)","57212142939; 25643658900; 7402109892; 57219794142; 57197894611; 57208733620; 57222596098; 26326649300","DeepTag: inferring diagnoses from veterinary clinical notes","2018","npj Digital Medicine","15","10.1038/s41746-018-0067-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089606326&doi=10.1038%2fs41746-018-0067-8&partnerID=40&md5=a052d3c4effaf09e34283932d2ccfafe","Department of Biomedical Data Science, Stanford University, Stanford, 94305, CA, United States; Department of Clinical Sciences, Colorado State University, Fort Collins, 80523, CO, United States; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Chan-Zuckerberg Biohub, San Francisco, 94158, CA, United States","Nie A., Department of Biomedical Data Science, Stanford University, Stanford, 94305, CA, United States; Zehnder A., Department of Biomedical Data Science, Stanford University, Stanford, 94305, CA, United States; Page R.L., Department of Clinical Sciences, Colorado State University, Fort Collins, 80523, CO, United States; Zhang Y., Department of Computer Science and Technology, Tsinghua University, Beijing, China; Pineda A.L., Department of Biomedical Data Science, Stanford University, Stanford, 94305, CA, United States; Rivas M.A., Department of Biomedical Data Science, Stanford University, Stanford, 94305, CA, United States; Bustamante C.D., Department of Biomedical Data Science, Stanford University, Stanford, 94305, CA, United States, Chan-Zuckerberg Biohub, San Francisco, 94158, CA, United States; Zou J., Department of Biomedical Data Science, Stanford University, Stanford, 94305, CA, United States, Chan-Zuckerberg Biohub, San Francisco, 94158, CA, United States","Large scale veterinary clinical records can become a powerful resource for patient care and research. However, clinicians lack the time and resource to annotate patient records with standard medical diagnostic codes and most veterinary visits are captured in free-text notes. The lack of standard coding makes it challenging to use the clinical data to improve patient care. It is also a major impediment to cross-species translational research, which relies on the ability to accurately identify patient cohorts with specific diagnostic criteria in humans and animals. In order to reduce the coding burden for veterinary clinical practice and aid translational research, we have developed a deep learning algorithm, DeepTag, which automatically infers diagnostic codes from veterinary free-text notes. DeepTag is trained on a newly curated dataset of 112,558 veterinary notes manually annotated by experts. DeepTag extends multitask LSTM with an improved hierarchical objective that captures the semantic structures between diseases. To foster human-machine collaboration, DeepTag also learns to abstain in examples when it is uncertain and defers them to human experts, resulting in improved performance. DeepTag accurately infers disease codes from free-text even in challenging cross-hospital settings where the text comes from different clinical settings than the ones used for training. It enables automated disease annotation across a broad range of clinical diagnoses with minimal preprocessing. The technical framework in this work can be applied in other medical domains that currently lack medical coding resources. © 2018, The Author(s).","","Clinical research; Codes (symbols); Long short-term memory; Semantics; Clinical data; Clinical notes; Clinical records; Free texts; Large-scales; Medical diagnostics; Patient care; Patient record; Standard coding; Translational Research; accuracy; Article; automation; coding; conceptual framework; human; learning algorithm; nonhuman; patient care; priority journal; semantics; translational research; veterinary medicine; Diagnosis","Nature Publishing Group","23986352","","","","Article","Scopus","2-s2.0-85089606326"
"Hazan H.; Saunders D.J.; Khan H.; Patel D.; Sanghavi D.T.; Siegelmann H.T.; Kozma R.","Hazan, Hananel (23476905600); Saunders, Daniel J. (57201528306); Khan, Hassaan (57220807773); Patel, Devdhar (57205197819); Sanghavi, Darpan T. (57204643854); Siegelmann, Hava T. (57189345629); Kozma, Robert (7004822939)","23476905600; 57201528306; 57220807773; 57205197819; 57204643854; 57189345629; 7004822939","BindsNET: A machine learning-oriented spiking neural networks library in python","2018","Frontiers in Neuroinformatics","176","10.3389/fninf.2018.00089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059016804&doi=10.3389%2ffninf.2018.00089&partnerID=40&md5=3995c2816f4da3f77cbf228757d861f1","Biologically Inspired Neural and Dynamical Systems Laboratory, College of Computer and Information Sciences, University of Massachusetts Amherst, Amherst, MA, United States","Hazan H., Biologically Inspired Neural and Dynamical Systems Laboratory, College of Computer and Information Sciences, University of Massachusetts Amherst, Amherst, MA, United States; Saunders D.J., Biologically Inspired Neural and Dynamical Systems Laboratory, College of Computer and Information Sciences, University of Massachusetts Amherst, Amherst, MA, United States; Khan H., Biologically Inspired Neural and Dynamical Systems Laboratory, College of Computer and Information Sciences, University of Massachusetts Amherst, Amherst, MA, United States; Patel D., Biologically Inspired Neural and Dynamical Systems Laboratory, College of Computer and Information Sciences, University of Massachusetts Amherst, Amherst, MA, United States; Sanghavi D.T., Biologically Inspired Neural and Dynamical Systems Laboratory, College of Computer and Information Sciences, University of Massachusetts Amherst, Amherst, MA, United States; Siegelmann H.T., Biologically Inspired Neural and Dynamical Systems Laboratory, College of Computer and Information Sciences, University of Massachusetts Amherst, Amherst, MA, United States; Kozma R., Biologically Inspired Neural and Dynamical Systems Laboratory, College of Computer and Information Sciences, University of Massachusetts Amherst, Amherst, MA, United States","                             The development of spiking neural network simulation software is a critical component enabling the modeling of neural systems and the development of biologically inspired algorithms. Existing software frameworks support a wide range of neural functionality, software abstraction levels, and hardware devices, yet are typically not suitable for rapid prototyping or application to problems in the domain of machine learning. In this paper, we describe a new Python package for the simulation of spiking neural networks, specifically geared toward machine learning and reinforcement learning. Our software, called BindsNET                             1                             , enables rapid building and simulation of spiking networks and features user-friendly, concise syntax. BindsNET is built on the PyTorch deep neural networks library, facilitating the implementation of spiking neural networks on fast CPU and GPU computational platforms. Moreover, the BindsNET framework can be adjusted to utilize other existing computing and hardware backends; e.g., TensorFlow and SpiNNaker. We provide an interface with the OpenAI gym library, allowing for training and evaluation of spiking networks on reinforcement learning environments. We argue that this package facilitates the use of spiking networks for large-scale machine learning problems and show some simple examples by using BindsNET in practice.                          © 2018 Hazan, Saunders, Khan, Patel, Sanghavi, Siegelmann and Kozma.","GPU-computing; Machine learning; Python (programming language); PyTorch; Reinforcement learning (RL); Spiking Network","4 aminobutyric acid; AMPA receptor; n methyl dextro aspartic acid receptor; accuracy; algorithm; Article; brain function; coding; cognition; computer language; conceptual framework; language processing; learning; machine learning; medical informatics; memory; nerve cell network; neuromuscular junction; reinforcement; software; synaptic potential","Frontiers Media S.A.","16625196","","","","Article","Scopus","2-s2.0-85059016804"
"Ainscough B.J.; Barnell E.K.; Ronning P.; Campbell K.M.; Wagner A.H.; Fehniger T.A.; Dunn G.P.; Uppaluri R.; Govindan R.; Rohan T.E.; Griffith M.; Mardis E.R.; Swamidass S.J.; Griffith O.L.","Ainscough, Benjamin J. (55542315800); Barnell, Erica K. (56073038800); Ronning, Peter (57204126089); Campbell, Katie M. (57189683708); Wagner, Alex H. (55049381800); Fehniger, Todd A. (7004024926); Dunn, Gavin P. (7202885986); Uppaluri, Ravindra (6602824668); Govindan, Ramaswamy (24176800100); Rohan, Thomas E. (7005205148); Griffith, Malachi (7102075315); Mardis, Elaine R. (7003499321); Swamidass, S. Joshua (10045433000); Griffith, Obi L. (7102837839)","55542315800; 56073038800; 57204126089; 57189683708; 55049381800; 7004024926; 7202885986; 6602824668; 24176800100; 7005205148; 7102075315; 7003499321; 10045433000; 7102837839","A deep learning approach to automate refinement of somatic variant calling from cancer sequencing data","2018","Nature Genetics","47","10.1038/s41588-018-0257-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056204832&doi=10.1038%2fs41588-018-0257-y&partnerID=40&md5=b346b829faa7fbcd0e8aef8f7b1945db","McDonnell Genome Institute, Washington University School of Medicine, St. Louis, MO, United States; Siteman Cancer Center, Washington University School of Medicine, St. Louis, MO, United States; Division of Oncology, Department of Medicine, Washington University School of Medicine, St. Louis, MO, United States; Department of Neurological Surgery, Center for Human Immunology and Immunotherapy Programs, Washington University School of Medicine, St. Louis, MO, United States; Department of Surgery/Otolaryngology, Brigham and Women’s Hospital and Dana-Farber Cancer Institute, Boston, MA, United States; Department of Epidemiology and Population Health, Albert Einstein College of Medicine, Bronx, NY, United States; Department of Genetics, Washington University School of Medicine, St. Louis, MO, United States; Institute for Genomic Medicine, The Research Institute at Nationwide Children’s Hospital, Columbus, OH, United States; Department of Pediatrics, The Ohio State University College of Medicine, Columbus, OH, United States; Department of Pathology and Immunology, Washington University School of Medicine, St. Louis, MO, United States; Institute for Informatics, Washington University School of Medicine, St. Louis, MO, United States","Ainscough B.J., McDonnell Genome Institute, Washington University School of Medicine, St. Louis, MO, United States, Siteman Cancer Center, Washington University School of Medicine, St. Louis, MO, United States; Barnell E.K., McDonnell Genome Institute, Washington University School of Medicine, St. Louis, MO, United States; Ronning P., McDonnell Genome Institute, Washington University School of Medicine, St. Louis, MO, United States; Campbell K.M., McDonnell Genome Institute, Washington University School of Medicine, St. Louis, MO, United States; Wagner A.H., McDonnell Genome Institute, Washington University School of Medicine, St. Louis, MO, United States; Fehniger T.A., Siteman Cancer Center, Washington University School of Medicine, St. Louis, MO, United States, Division of Oncology, Department of Medicine, Washington University School of Medicine, St. Louis, MO, United States; Dunn G.P., Department of Neurological Surgery, Center for Human Immunology and Immunotherapy Programs, Washington University School of Medicine, St. Louis, MO, United States; Uppaluri R., Department of Surgery/Otolaryngology, Brigham and Women’s Hospital and Dana-Farber Cancer Institute, Boston, MA, United States; Govindan R., Siteman Cancer Center, Washington University School of Medicine, St. Louis, MO, United States, Division of Oncology, Department of Medicine, Washington University School of Medicine, St. Louis, MO, United States; Rohan T.E., Department of Epidemiology and Population Health, Albert Einstein College of Medicine, Bronx, NY, United States; Griffith M., McDonnell Genome Institute, Washington University School of Medicine, St. Louis, MO, United States, Siteman Cancer Center, Washington University School of Medicine, St. Louis, MO, United States, Division of Oncology, Department of Medicine, Washington University School of Medicine, St. Louis, MO, United States, Department of Genetics, Washington University School of Medicine, St. Louis, MO, United States; Mardis E.R., Institute for Genomic Medicine, The Research Institute at Nationwide Children’s Hospital, Columbus, OH, United States, Department of Pediatrics, The Ohio State University College of Medicine, Columbus, OH, United States; Swamidass S.J., Department of Pathology and Immunology, Washington University School of Medicine, St. Louis, MO, United States, Institute for Informatics, Washington University School of Medicine, St. Louis, MO, United States; Griffith O.L., McDonnell Genome Institute, Washington University School of Medicine, St. Louis, MO, United States, Siteman Cancer Center, Washington University School of Medicine, St. Louis, MO, United States, Division of Oncology, Department of Medicine, Washington University School of Medicine, St. Louis, MO, United States, Department of Genetics, Washington University School of Medicine, St. Louis, MO, United States","Cancer genomic analysis requires accurate identification of somatic variants in sequencing data. Manual review to refine somatic variant calls is required as a final step after automated processing. However, manual variant refinement is time-consuming, costly, poorly standardized, and non-reproducible. Here, we systematized and standardized somatic variant refinement using a machine learning approach. The final model incorporates 41,000 variants from 440 sequencing cases. This model accurately recapitulated manual refinement labels for three independent testing sets (13,579 variants) and accurately predicted somatic variants confirmed by orthogonal validation sequencing data (212,158 variants). The model improves on manual somatic refinement by reducing bias on calls otherwise subject to high inter-reviewer variability. © 2018, The Author(s), under exclusive licence to Springer Nature America, Inc.","","Algorithms; Computer Simulation; Deep Learning; DNA Mutational Analysis; Electronic Data Processing; High-Throughput Nucleotide Sequencing; Humans; Mutation; Neoplasms; Polymorphism, Single Nucleotide; Reproducibility of Results; Sequence Analysis, DNA; Software; Article; automation; cancer research; genetic screening; genetic variability; learning; machine learning; priority journal; sequence analysis; somatic variant refinement; standardization; validation study; algorithm; computer simulation; devices; dna mutational analysis; DNA sequence; evaluation study; genetics; high throughput sequencing; human; information processing; mutation; neoplasm; procedures; reproducibility; single nucleotide polymorphism; software","Nature Publishing Group","10614036","","NGENE","30397337","Article","Scopus","2-s2.0-85056204832"
"Baldi P.; Sadowski P.","Baldi, P. (7101759672); Sadowski, P. (56074914700)","7101759672; 56074914700","Learning in the machine: Recirculation is random backpropagation","2018","Neural Networks","5","10.1016/j.neunet.2018.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054565863&doi=10.1016%2fj.neunet.2018.09.006&partnerID=40&md5=2d952b52ec3897a055cc252d764b084a","Department of Computer Science, University of California, Irvine, Irvine, 92697, CA, United States","Baldi P., Department of Computer Science, University of California, Irvine, Irvine, 92697, CA, United States; Sadowski P., Department of Computer Science, University of California, Irvine, Irvine, 92697, CA, United States","Learning in physical neural systems must rely on learning rules that are local in both space and time. Optimal learning in deep neural architectures requires that non-local information be available to the deep synapses. Thus, in general, optimal learning in physical neural systems requires the presence of a deep learning channel to communicate non-local information to deep synapses, in a direction opposite to the forward propagation of the activities. Theoretical arguments suggest that for circular autoencoders, an important class of neural architectures where the output layer is identical to the input layer, alternative algorithms may exist that enable local learning without the need for additional learning channels, by using the forward activation channel as the deep learning channel. Here we systematically identify, classify, and study several such local learning algorithms, based on the general idea of recirculating information from the output layer to the hidden layers. We show through simulations and mathematical derivations that these algorithms are robust and converge to critical points of the global error function. In most cases, we show that these recirculation algorithms are very similar to an adaptive form of random backpropagation, where each hidden layer receives a linearly transformed, slowly-varying, version of the output error. © 2018 Elsevier Ltd","Autoencoders; Backpropagation; Convergence; Random backpropagation; Recirculation; Unsupervised learning","Algorithms; Deep Learning; Machine Learning; Neural Networks (Computer); Backpropagation; Backpropagation algorithms; Classification (of information); Deep learning; Functions; Neural networks; Unsupervised learning; Alternative algorithms; Autoencoders; Convergence; Global error function; Mathematical derivation; Neural architectures; Recirculations; Theoretical arguments; article; learning algorithm; machine; simulation; theoretical study; algorithm; artificial neural network; machine learning; trends; Learning algorithms","Elsevier Ltd","08936080","","NNETE","30317133","Article","Scopus","2-s2.0-85054565863"
"Balducci F.; Impedovo D.; Pirlo G.","Balducci, Fabrizio (57062552400); Impedovo, Donato (24821831600); Pirlo, Giuseppe (55906867800)","57062552400; 24821831600; 55906867800","Detection and validation of tow-away road sign licenses through deep learning methods","2018","Sensors (Switzerland)","3","10.3390/s18124147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057549386&doi=10.3390%2fs18124147&partnerID=40&md5=6140ff438382d36199b9fd431d207af1","Dipartimento di Informatica, Università degli studi di Bari Aldo Moro, Bari, 70125, Italy","Balducci F., Dipartimento di Informatica, Università degli studi di Bari Aldo Moro, Bari, 70125, Italy; Impedovo D., Dipartimento di Informatica, Università degli studi di Bari Aldo Moro, Bari, 70125, Italy; Pirlo G., Dipartimento di Informatica, Università degli studi di Bari Aldo Moro, Bari, 70125, Italy","This work presents the practical design of a system that faces the problem of identification and validation of private no-parking road signs. This issue is very important for the public city administrations since many people, after receiving a code that identifies the signal at the entrance of their private car garage as valid, forget to renew the code validity through the payment of a city tax, causing large money shortages to the public administration. The goal of the system is twice since, after recognition of the official road sign pattern, its validity must be controlled by extracting the code put in a specific sub-region inside it. Despite a lot of work on the road signs’ topic having been carried out, a complete benchmark dataset also considering the particular setting of the Italian law is today not available for comparison, thus the second goal of this work is to provide experimental results that exploit machine learning and deep learning techniques that can be satisfactorily used in industrial applications. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Italian road sign; Pattern recognition; Tow-away sign","Benchmarking; Codes (symbols); Pattern recognition; Pattern recognition systems; Public administration; Roads and streets; Benchmark datasets; Learning methods; Learning techniques; Road signs; Sub-regions; Tow-away sign; Deep learning","MDPI AG","14248220","","","30486317","Article","Scopus","2-s2.0-85057549386"
"Sun T.; Lai L.; Pei J.","Sun, Tanlin (56739760800); Lai, Luhua (7202615995); Pei, Jianfeng (7103299043)","56739760800; 7202615995; 7103299043","Analysis of protein features and machine learning algorithms for prediction of druggable proteins","2018","Quantitative Biology","13","10.1007/s40484-018-0157-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057102377&doi=10.1007%2fs40484-018-0157-2&partnerID=40&md5=94d815b3bbdce4acc8c6aaec1cae0b5e","Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China; Beijing National Laboratory for Molecular Science, State Key Laboratory for Structural Chemistry of Unstable and Stable Species, College of Chemistry and Molecular Engineering, Peking University, Beijing, 100871, China; Peking-Tsinghua Center for Life Sciences, Peking University, Beijing, 100871, China","Sun T., Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China; Lai L., Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China, Beijing National Laboratory for Molecular Science, State Key Laboratory for Structural Chemistry of Unstable and Stable Species, College of Chemistry and Molecular Engineering, Peking University, Beijing, 100871, China, Peking-Tsinghua Center for Life Sciences, Peking University, Beijing, 100871, China; Pei J., Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China","Background: Computational tools have been widely used in drug discovery process since they reduce the time and cost. Prediction of whether a protein is druggable is fundamental and crucial for drug research pipeline. Sequence based protein function prediction plays vital roles in many research areas. Training data, protein features selection and machine learning algorithms are three indispensable elements that drive the successfulness of the models. Methods: In this study, we tested the performance of different combinations of protein features and machine learning algorithms, based on FDA-approved small molecules’ targets, in druggable proteins prediction.We also enlarged the dataset to include the targets of small molecules that were in experiment or clinical investigation. Results: We found that although the 146-d vector used by Li et al. with neuron network achieved the best training accuracy of 91.10%, overlapped 3-gram word2vec with logistic regression achieved best prediction accuracy on independent test set (89.55%) and on newly approved-targets. Enlarged dataset with targets of small molecules in experiment and clinical investigation were trained. Unfortunately, the best training accuracy was only 75.48%. In addition, we applied our models to predict potential targets for references in future study. Conclusions: Our study indicates the potential ability of word2vec in the prediction of druggable protein. And the training dataset of druggable protein should not be extended to targets that are lack of verification. The target prediction package could be found on https://doi.org/github.com/pkumdl/target_prediction. [Figure not available: see fulltext.]. © 2018, Higher Education Press and Springer-Verlag GmbH Germany, part of Springer Nature.","deep learning; drug target; druggable protein; word2vec","","Higher Education Press","20954689","","","","Article","Scopus","2-s2.0-85057102377"
"Du F.; Zhang J.; Ji N.; Shi G.; Zhang C.","Du, Fang (57203568743); Zhang, Jiangshe (9737712100); Ji, Nannan (56016736200); Shi, Guang (57194587070); Zhang, Chunxia (55703936800)","57203568743; 9737712100; 56016736200; 57194587070; 55703936800","An effective hierarchical extreme learning machine based multimodal fusion framework","2018","Neurocomputing","15","10.1016/j.neucom.2018.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054558260&doi=10.1016%2fj.neucom.2018.09.005&partnerID=40&md5=d1932700500a9ca2208857b81fb2815f","School of Mathematics and Statistics, Xi'an Jiaotong University, No.28, Xianning West Road, Xi'an, Shaanxi, China","Du F., School of Mathematics and Statistics, Xi'an Jiaotong University, No.28, Xianning West Road, Xi'an, Shaanxi, China; Zhang J., School of Mathematics and Statistics, Xi'an Jiaotong University, No.28, Xianning West Road, Xi'an, Shaanxi, China; Ji N., School of Mathematics and Statistics, Xi'an Jiaotong University, No.28, Xianning West Road, Xi'an, Shaanxi, China; Shi G., School of Mathematics and Statistics, Xi'an Jiaotong University, No.28, Xianning West Road, Xi'an, Shaanxi, China; Zhang C., School of Mathematics and Statistics, Xi'an Jiaotong University, No.28, Xianning West Road, Xi'an, Shaanxi, China","Deep learning has been successfully applied to multimodal representation learning. Similar with single modal deep learning method, such multimodal deep learning methods consist of a greedy layer-wise feedforward propagation and a backpropagation (BP) fine-tune conducted by diverse targets. These models have the drawback of time consuming. While, extreme learning machine (ELM) is a fast learning algorithm for single hidden layer feedforward neural network. And previous works has shown the effectiveness of ELM based hierarchical framework for multilayer perceptron. In this paper, we introduce an ELM based hierarchical framework for multimodal data. The proposed architecture consists of three main components: (1) self-taught feature extraction for specific modality by an ELM-based sparse autoencoder, (2) fused representation learning based on the features learned by previous step and (3) supervised feature classification based on the fused representation. This is an exact feedforward framework that once a layer is established, its weights are fixed without fine-tuning. Therefore, it has much better learning efficiency than the gradient based multimodal deep learning methods. We conduct experiments on MNIST, XRMB and NUS datasets, the proposed algorithm obtains faster convergence and achieves better classification performance compared with the other existing multimodal deep learning models. © 2018","Deep learning; Extreme learning machine; Multimodal fusion; Multimodal learning","Backpropagation; Classification (of information); Deep learning; Feedforward neural networks; Knowledge acquisition; Network layers; Classification performance; Extreme learning machine; Feature classification; Learning efficiency; Multi-modal fusion; Multi-modal learning; Proposed architectures; Single-hidden layer feedforward neural networks; article; feature extraction; learning algorithm; perceptron; Learning algorithms","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85054558260"
"Wang H.; Yu Y.; Cai Y.; Chen L.; Chen X.","Wang, Hai (56193358000); Yu, Yijie (57204785049); Cai, Yingfeng (26423580200); Chen, Long (58408359400); Chen, Xiaobo (36522588800)","56193358000; 57204785049; 26423580200; 58408359400; 36522588800","A vehicle recognition algorithm based on deep transfer learning with a multiple feature subspace distribution","2018","Sensors","22","10.3390/s18124109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057147402&doi=10.3390%2fs18124109&partnerID=40&md5=94947f37eb1fdc171b1694d5b1866d4e","School of Automotive and Traffic Engineering, Jiangsu University, Zhenjiang, 212013, China; Automotive Engineering Research Institute, Jiangsu University, Zhenjiang, 212013, China","Wang H., School of Automotive and Traffic Engineering, Jiangsu University, Zhenjiang, 212013, China; Yu Y., School of Automotive and Traffic Engineering, Jiangsu University, Zhenjiang, 212013, China; Cai Y., Automotive Engineering Research Institute, Jiangsu University, Zhenjiang, 212013, China; Chen L., Automotive Engineering Research Institute, Jiangsu University, Zhenjiang, 212013, China; Chen X., Automotive Engineering Research Institute, Jiangsu University, Zhenjiang, 212013, China","Vehicle detection is a key component of environmental sensing systems for Intelligent Vehicles (IVs). The traditional shallow model and offline learning-based vehicle detection method are not able to satisfy the real-world challenges of environmental complexity and scene dynamics. Focusing on these problems, this work proposes a vehicle detection algorithm based on a multiple feature subspace distribution deep model with online transfer learning. Based on the multiple feature subspace distribution hypothesis, a deep model is established in which multiple Restricted Boltzmann Machines (RBMs) construct the lower layers and a Deep Belief Network (DBN) composes the superstructure. For this deep model, an unsupervised feature extraction method is applied, which is based on sparse constraints. Then, a transfer learning method with online sample generation is proposed based on the deep model. Finally, the entire classifier is retrained online with supervised learning. The experiment is actuated using the KITTI road image datasets. The performance of the proposed method is compared with many state-of-the-art methods and it is demonstrated that the proposed deep transfer learning-based algorithm outperformed existing state-of-the-art methods. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep transfer learning; Intelligent vehicles; Multiple subspace feature distribution; Vehicle recognition","E-learning; Feature extraction; Learning algorithms; Learning systems; Transfer learning; Vehicles; Deep belief network (DBN); Environmental complexity; Environmental sensing; Feature extraction methods; Learning-based algorithms; Restricted boltzmann machine; State-of-the-art methods; Transfer learning methods; Deep learning","MDPI AG","14248220","","","30477172","Article","Scopus","2-s2.0-85057147402"
"Hu B.; Wang H.; Wang L.; Yuan W.","Hu, Baofang (55419515300); Wang, Hong (58466003800); Wang, Lutong (57203748365); Yuan, Weihua (58124495100)","55419515300; 58466003800; 57203748365; 58124495100","Adverse drug reaction predictions using stacking deep heterogeneous information network embedding approach","2018","Molecules","22","10.3390/molecules23123193","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057605292&doi=10.3390%2fmolecules23123193&partnerID=40&md5=8213aa4affb11fc2f2a32fbac42f826c","School of Information Science and Engineering, Shandong Normal University, Jinan, 250014, China; School of Data and Computer Science, Shandong Women’s University, Jinan, 250014, China; Shandong Provincial Key Laboratory for Distributed Computer Software Novel Technology, Shandong Normal University, Jinan, 250014, China","Hu B., School of Information Science and Engineering, Shandong Normal University, Jinan, 250014, China, School of Data and Computer Science, Shandong Women’s University, Jinan, 250014, China, Shandong Provincial Key Laboratory for Distributed Computer Software Novel Technology, Shandong Normal University, Jinan, 250014, China; Wang H., School of Information Science and Engineering, Shandong Normal University, Jinan, 250014, China, Shandong Provincial Key Laboratory for Distributed Computer Software Novel Technology, Shandong Normal University, Jinan, 250014, China; Wang L., School of Information Science and Engineering, Shandong Normal University, Jinan, 250014, China, Shandong Provincial Key Laboratory for Distributed Computer Software Novel Technology, Shandong Normal University, Jinan, 250014, China; Yuan W., School of Information Science and Engineering, Shandong Normal University, Jinan, 250014, China, Shandong Provincial Key Laboratory for Distributed Computer Software Novel Technology, Shandong Normal University, Jinan, 250014, China","Inferring potential adverse drug reactions is an important and challenging task for the drug discovery and healthcare industry. Many previous studies in computational pharmacology have proposed utilizing multi-source drug information to predict drug side effects have and achieved initial success. However, most of the prediction methods mainly rely on direct similarities inferred from drug information and cannot fully utilize the drug information about the impact of protein–protein interactions (PPI) on potential drug targets. Moreover, most of the methods are designed for specific tasks. In this work, we propose a novel heterogeneous network embedding approach for learning drug representations called SDHINE, which integrates PPI information into drug embeddings and is generic for different adverse drug reaction (ADR) prediction tasks. To integrate heterogeneous drug information and learn drug representations, we first design different meta-path-based proximities to calculate drug similarities, especially target propagation meta-path-based proximity based on PPI network, and then construct a semi-supervised stacking deep neural network model that is jointly optimized by the defined meta-path proximities. Extensive experiments with three state-of-the-art network embedding methods on three ADR prediction tasks demonstrate the effectiveness of the SDHINE model. Furthermore, we compare the drug representations in terms of drug differentiation by mapping the representations into 2D space; the results show that the performance of our approach is superior to that of the comparison methods. © 2018 by the authors.","Adverse drug reaction prediction; Heterogeneous information network embedding; Meta-path-based proximity; Stacking denoising auto-encoder","Algorithms; Drug Discovery; Drug-Related Side Effects and Adverse Reactions; Machine Learning; Neural Networks (Computer); adverse drug reaction; algorithm; artificial neural network; drug development; machine learning","MDPI AG","14203049","","MOLEF","30518099","Article","Scopus","2-s2.0-85057605292"
"Avati A.; Jung K.; Harman S.; Downing L.; Ng A.; Shah N.H.","Avati, Anand (57201864029); Jung, Kenneth (13607618300); Harman, Stephanie (55157878300); Downing, Lance (57023597700); Ng, Andrew (35410071600); Shah, Nigam H. (7401823709)","57201864029; 13607618300; 55157878300; 57023597700; 35410071600; 7401823709","Improving palliative care with deep learning","2018","BMC Medical Informatics and Decision Making","181","10.1186/s12911-018-0677-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058340075&doi=10.1186%2fs12911-018-0677-8&partnerID=40&md5=65a53b12289efdd5bbe930251e7d43c4","Department of Computer Science, Stanford University, Stanford, CA, United States; Center for Biomedical Informatics Research, Stanford University, Stanford, CA, United States; Department of Medicine, Stanford University School of Medicine, Stanford, CA, United States","Avati A., Department of Computer Science, Stanford University, Stanford, CA, United States; Jung K., Center for Biomedical Informatics Research, Stanford University, Stanford, CA, United States; Harman S., Department of Medicine, Stanford University School of Medicine, Stanford, CA, United States; Downing L., Center for Biomedical Informatics Research, Stanford University, Stanford, CA, United States; Ng A., Department of Computer Science, Stanford University, Stanford, CA, United States; Shah N.H., Center for Biomedical Informatics Research, Stanford University, Stanford, CA, United States","Background: Access to palliative care is a key quality metric which most healthcare organizations strive to improve. The primary challenges to increasing palliative care access are a combination of physicians over-estimating patient prognoses, and a shortage of palliative staff in general. This, in combination with treatment inertia can result in a mismatch between patient wishes, and their actual care towards the end of life. Methods: In this work, we address this problem, with Institutional Review Board approval, using machine learning and Electronic Health Record (EHR) data of patients. We train a Deep Neural Network model on the EHR data of patients from previous years, to predict mortality of patients within the next 3-12 month period. This prediction is used as a proxy decision for identifying patients who could benefit from palliative care. Results: The EHR data of all admitted patients are evaluated every night by this algorithm, and the palliative care team is automatically notified of the list of patients with a positive prediction. In addition, we present a novel technique for decision interpretation, using which we provide explanations for the model's predictions. Conclusion: The automatic screening and notification saves the palliative care team the burden of time consuming chart reviews of all patients, and allows them to take a proactive approach in reaching out to such patients rather then relying on referrals from the treating physicians. © 2018 The Author(s).","Deep learning; Electronic health records; Interpretation; Palliative care","Clinical Decision-Making; Deep Learning; Electronic Health Records; Humans; Palliative Care; Patient Selection; Prognosis; adult; article; electronic health record; human; institutional review; machine learning; medical record review; mortality; night; palliative therapy; physician; prediction; clinical decision making; electronic health record; patient selection; prognosis","BioMed Central Ltd","14726947","","","30537977","Article","Scopus","2-s2.0-85058340075"
"Chen W.-K.; Liu X.-Y.; Fang W.-H.; Dral P.O.; Cui G.","Chen, Wen-Kai (57211480503); Liu, Xiang-Yang (56597328900); Fang, Wei-Hai (55490416500); Dral, Pavlo O. (27267482300); Cui, Ganglong (16244537000)","57211480503; 56597328900; 55490416500; 27267482300; 16244537000","Deep Learning for Nonadiabatic Excited-State Dynamics","2018","Journal of Physical Chemistry Letters","119","10.1021/acs.jpclett.8b03026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056840720&doi=10.1021%2facs.jpclett.8b03026&partnerID=40&md5=a37740748182a52cfcd16937979bf8f3","Key Laboratory of Theoretical and Computational Photochemistry, Ministry of Education, Beijing Normal University, Beijing, 100875, China; Max-Planck-Institut fur Kohlenforschung, Kaiser-Wilhelm-Platz 1, Mülheim an der Ruhr, 45470, Germany","Chen W.-K., Key Laboratory of Theoretical and Computational Photochemistry, Ministry of Education, Beijing Normal University, Beijing, 100875, China; Liu X.-Y., Key Laboratory of Theoretical and Computational Photochemistry, Ministry of Education, Beijing Normal University, Beijing, 100875, China; Fang W.-H., Key Laboratory of Theoretical and Computational Photochemistry, Ministry of Education, Beijing Normal University, Beijing, 100875, China; Dral P.O., Max-Planck-Institut fur Kohlenforschung, Kaiser-Wilhelm-Platz 1, Mülheim an der Ruhr, 45470, Germany; Cui G., Key Laboratory of Theoretical and Computational Photochemistry, Ministry of Education, Beijing Normal University, Beijing, 100875, China","                             In this work we show that deep learning (DL) can be used for exploring complex and highly nonlinear multistate potential energy surfaces of polyatomic molecules and related nonadiabatic dynamics. Our DL is based on deep neural networks (DNNs), which are used as accurate representations of the CASSCF ground- and excited-state potential energy surfaces (PESs) of CH                             2                             NH. After geometries near conical intersection are included in the training set, the DNN models accurately reproduce excited-state topological structures; photoisomerization paths; and, importantly, conical intersections. We have also demonstrated that the results from nonadiabatic dynamics run with the DNN models are very close to those from the dynamics run with the pure ab initio method. The present work should encourage further studies of using machine learning methods to explore excited-state potential energy surfaces and nonadiabatic dynamics of polyatomic molecules.                          Copyright © 2018 American Chemical Society.","","Deep neural networks; Molecules; Potential energy; Potential energy surfaces; Quantum chemistry; Ab initio method; Conical intersection; Excited-state dynamics; Machine learning methods; Non-adiabatic; Non-adiabatic dynamics; Polyatomic molecules; Topological structure; Excited states","American Chemical Society","19487185","","","30403870","Article","Scopus","2-s2.0-85056840720"
"Steiner D.F.; Macdonald R.; Liu Y.; Truszkowski P.; Hipp J.D.; Gammage C.; Thng F.; Peng L.; Stumpe M.C.","Steiner, David F. (57204607770); Macdonald, Robert (57204604166); Liu, Yun (57200691380); Truszkowski, Peter (57199352011); Hipp, Jason D. (57210950636); Gammage, Christopher (15020640800); Thng, Florence (57204605306); Peng, Lily (57192709975); Stumpe, Martin C. (55754596300)","57204607770; 57204604166; 57200691380; 57199352011; 57210950636; 15020640800; 57204605306; 57192709975; 55754596300","Impact of Deep Learning Assistance on the Histopathologic Review of Lymph Nodes for Metastatic Breast Cancer","2018","American Journal of Surgical Pathology","305","10.1097/PAS.0000000000001151","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056358333&doi=10.1097%2fPAS.0000000000001151&partnerID=40&md5=2dfbb446dcf977ac3665e9e387c9fa05","Google AI Healthcare, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Verily Life Sciences, Mountain View, CA, United States","Steiner D.F., Google AI Healthcare, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Macdonald R., Google AI Healthcare, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Liu Y., Google AI Healthcare, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Truszkowski P., Google AI Healthcare, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Hipp J.D., Google AI Healthcare, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Gammage C., Google AI Healthcare, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Thng F., Verily Life Sciences, Mountain View, CA, United States; Peng L., Google AI Healthcare, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Stumpe M.C., Google AI Healthcare, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States","Advances in the quality of whole-slide images have set the stage for the clinical use of digital images in anatomic pathology. Along with advances in computer image analysis, this raises the possibility for computer-Assisted diagnostics in pathology to improve histopathologic interpretation and clinical care. To evaluate the potential impact of digital assistance on interpretation of digitized slides, we conducted a multireader multicase study utilizing our deep learning algorithm for the detection of breast cancer metastasis in lymph nodes. Six pathologists reviewed 70 digitized slides from lymph node sections in 2 reader modes, unassisted and assisted, with a wash-out period between sessions. In the assisted mode, the deep learning algorithm was used to identify and outline regions with high likelihood of containing tumor. Algorithm-Assisted pathologists demonstrated higher accuracy than either the algorithm or the pathologist alone. In particular, algorithm assistance significantly increased the sensitivity of detection for micrometastases (91% vs. 83%, P=0.02). In addition, average review time per image was significantly shorter with assistance than without assistance for both micrometastases (61 vs. 116 s, P=0.002) and negative images (111 vs. 137 s, P=0.018). Lastly, pathologists were asked to provide a numeric score regarding the difficulty of each image classification. On the basis of this score, pathologists considered the image review of micrometastases to be significantly easier when interpreted with assistance (P=0.0005). Utilizing a proof of concept assistant tool, this study demonstrates the potential of a deep learning algorithm to improve pathologist accuracy and efficiency in a digital pathology workflow. © Copyright © 2018 The Author(s). Published by Wolters Kluwer Health, Inc.","artificial intelligence; breast cancer; computer aided detection; digital pathology; machine learning","Biopsy; Breast Neoplasms; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Image Interpretation, Computer-Assisted; Lymph Nodes; Lymphatic Metastasis; Neoplasm Micrometastasis; Observer Variation; Pathology, Clinical; Pattern Recognition, Automated; Predictive Value of Tests; Proof of Concept Study; Reproducibility of Results; Time Factors; Workflow; automated pattern recognition; biopsy; breast tumor; computer assisted diagnosis; evaluation study; female; human; lymph node; lymph node metastasis; micrometastasis; observer variation; pathology; predictive value; procedures; proof of concept; reproducibility; time factor; workflow","Lippincott Williams and Wilkins","01475185","","AJSPD","30312179","Article","Scopus","2-s2.0-85056358333"
"Phan A.V.; Nguyen M.L.; Nguyen Y.L.H.; Bui L.T.","Phan, Anh Viet (57191071971); Nguyen, Minh Le (55664630500); Nguyen, Yen Lam Hoang (57204422389); Bui, Lam Thu (8961832500)","57191071971; 55664630500; 57204422389; 8961832500","DGCNN: A convolutional neural network over large-scale labeled graphs","2018","Neural Networks","115","10.1016/j.neunet.2018.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055479097&doi=10.1016%2fj.neunet.2018.09.001&partnerID=40&md5=cb429f0a80bb6caf44beacc2b75bdb6d","Japan Advanced Institute of Science and Technology (JAIST), Nomi city, 923-1211, Japan; Research Group in Computational Intelligence, Le Quy Don Technical University, 236 Hoang Quoc Viet St., Ha Noi, Viet Nam","Phan A.V., Japan Advanced Institute of Science and Technology (JAIST), Nomi city, 923-1211, Japan, Research Group in Computational Intelligence, Le Quy Don Technical University, 236 Hoang Quoc Viet St., Ha Noi, Viet Nam; Nguyen M.L., Japan Advanced Institute of Science and Technology (JAIST), Nomi city, 923-1211, Japan; Nguyen Y.L.H., Japan Advanced Institute of Science and Technology (JAIST), Nomi city, 923-1211, Japan; Bui L.T., Research Group in Computational Intelligence, Le Quy Don Technical University, 236 Hoang Quoc Viet St., Ha Noi, Viet Nam","Exploiting graph-structured data has many real applications in domains including natural language semantics, programming language processing, and malware analysis. A variety of methods has been developed to deal with such data. However, learning graphs of large-scale, varying shapes and sizes is a big challenge for any method. In this paper, we propose a multi-view multi-layer convolutional neural network on labeled directed graphs (DGCNN), in which convolutional filters are designed flexibly to adapt to dynamic structures of local regions inside graphs. The advantages of DGCNN are that we do not need to align vertices between graphs, and that DGCNN can process large-scale dynamic graphs with hundred thousands of nodes. To verify the effectiveness of DGCNN, we conducted experiments on two tasks: malware analysis and software defect prediction. The results show that DGCNN outperforms the baselines, including several deep neural networks. © 2018 Elsevier Ltd","abstract syntax trees (ASTs); Control flow graphs (CFGs); Convolutional neural networks (CNNs); Labeled directed graphs","Algorithms; Computer Graphics; Natural Language Processing; Neural Networks (Computer); Semantics; Computer crime; Convolution; Deep neural networks; Flow graphs; Graphic methods; Malware; Network layers; Neural networks; Semantics; Abstract Syntax Trees; Control flow graphs; Convolutional neural network; Graph structured data; Large-scale dynamics; Natural language semantics; Real applications; Software defect prediction; algorithm; analytic method; Article; artificial neural network; convolutional neural network; large scale production; machine learning; mathematical model; priority journal; semantics; training; computer graphics; natural language processing; trends; Trees (mathematics)","Elsevier Ltd","08936080","","NNETE","30458952","Article","Scopus","2-s2.0-85055479097"
"Madani A.; Ong J.R.; Tibrewal A.; Mofrad M.R.K.","Madani, Ali (55980592600); Ong, Jia Rui (57219524113); Tibrewal, Anshul (57835521300); Mofrad, Mohammad R. K. (10040081000)","55980592600; 57219524113; 57835521300; 10040081000","Deep echocardiography: data-efficient supervised and semi-supervised deep learning towards automated diagnosis of cardiac disease","2018","npj Digital Medicine","157","10.1038/s41746-018-0065-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135598377&doi=10.1038%2fs41746-018-0065-x&partnerID=40&md5=2a609821cc11ebe208f1bb159d905bce","Molecular Cell Biomechanics Laboratory, Departments of Bioengineering and Mechanical Engineering, University of California, Berkeley, CA, United States; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, United States; UCSF-Berkeley Graduate Program in Bioengineering, Berkeley, CA, United States","Madani A., Molecular Cell Biomechanics Laboratory, Departments of Bioengineering and Mechanical Engineering, University of California, Berkeley, CA, United States; Ong J.R., Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, United States; Tibrewal A., Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, United States; Mofrad M.R.K., Molecular Cell Biomechanics Laboratory, Departments of Bioengineering and Mechanical Engineering, University of California, Berkeley, CA, United States, UCSF-Berkeley Graduate Program in Bioengineering, Berkeley, CA, United States","Deep learning and computer vision algorithms can deliver highly accurate and automated interpretation of medical imaging to augment and assist clinicians. However, medical imaging presents uniquely pertinent obstacles such as a lack of accessible data or a high-cost of annotation. To address this, we developed data-efficient deep learning classifiers for prediction tasks in cardiology. Using pipeline supervised models to focus relevant structures, we achieve an accuracy of 94.4% for 15-view still-image echocardiographic view classification and 91.2% accuracy for binary left ventricular hypertrophy classification. We then develop semi-supervised generative adversarial network models that can learn from both labeled and unlabeled data in a generalizable fashion. We achieve greater than 80% accuracy in view classification with only 4% of labeled data used in solely supervised techniques and achieve 92.3% accuracy for left ventricular hypertrophy classification. In exploring trade-offs between model type, resolution, data resources, and performance, we present a comprehensive analysis and improvements of efficient deep learning solutions for medical imaging assessment especially in cardiology. © 2018, The Author(s).","","Classification (of information); Deep learning; Echocardiography; Economic and social effects; Generative adversarial networks; Medical imaging; Pathology; Automated diagnosis; Automated interpretation; Cardiac disease; Computer vision algorithms; High costs; Highly accurate; Learning classifiers; Left ventricular hypertrophies; Prediction tasks; Semi-supervised; accuracy; algorithm; Article; automation; classification; classifier; echocardiography; heart disease; heart left ventricle hypertrophy; image segmentation; priority journal; supervised machine learning; Cardiology","Nature Publishing Group","23986352","","","","Article","Scopus","2-s2.0-85135598377"
"Meyer A.; Zverinski D.; Pfahringer B.; Kempfert J.; Kuehne T.; Sündermann S.H.; Stamm C.; Hofmann T.; Falk V.; Eickhoff C.","Meyer, Alexander (56308158300); Zverinski, Dina (57205207855); Pfahringer, Boris (57205204032); Kempfert, Jörg (35292515900); Kuehne, Titus (6603086969); Sündermann, Simon H (36085538600); Stamm, Christof (7006133274); Hofmann, Thomas (56735589800); Falk, Volkmar (26867592300); Eickhoff, Carsten (36767177300)","56308158300; 57205207855; 57205204032; 35292515900; 6603086969; 36085538600; 7006133274; 56735589800; 26867592300; 36767177300","Machine learning for real-time prediction of complications in critical care: a retrospective study","2018","The Lancet Respiratory Medicine","202","10.1016/S2213-2600(18)30300-X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059098244&doi=10.1016%2fS2213-2600%2818%2930300-X&partnerID=40&md5=e0eaf87af07b543f6e7a356eced96460","Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany; Institute of Imaging Science and Computational Modelling, Charité – Universitätsmedizin Berlin, Berlin, Germany; Department of Cardiovascular Surgery, Charité – Universitätsmedizin Berlin, Berlin, Germany; Berlin Center for Regenerative Therapies, Charité – Universitätsmedizin Berlin, Berlin, Germany; DZHK (German Centre for Cardiovascular Research), Partner Site Berlin, Berlin, Germany; Department of Computer Science, ETH Zurich, Zurich, Switzerland; Berlin Institute of Health, Berlin, Germany; Center for Biomedical Informatics, Brown University, Providence, RI, United States","Meyer A., Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany, DZHK (German Centre for Cardiovascular Research), Partner Site Berlin, Berlin, Germany, Berlin Institute of Health, Berlin, Germany; Zverinski D., Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany, Department of Computer Science, ETH Zurich, Zurich, Switzerland; Pfahringer B., Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany, Berlin Institute of Health, Berlin, Germany; Kempfert J., Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany; Kuehne T., Institute of Imaging Science and Computational Modelling, Charité – Universitätsmedizin Berlin, Berlin, Germany; Sündermann S.H., Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany, Department of Cardiovascular Surgery, Charité – Universitätsmedizin Berlin, Berlin, Germany; Stamm C., Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany, Berlin Center for Regenerative Therapies, Charité – Universitätsmedizin Berlin, Berlin, Germany, DZHK (German Centre for Cardiovascular Research), Partner Site Berlin, Berlin, Germany; Hofmann T., Department of Computer Science, ETH Zurich, Zurich, Switzerland; Falk V., Department of Cardiothoracic and Vascular Surgery, Deutsches Herzzentrum Berlin, Berlin, Germany, Department of Cardiovascular Surgery, Charité – Universitätsmedizin Berlin, Berlin, Germany, DZHK (German Centre for Cardiovascular Research), Partner Site Berlin, Berlin, Germany; Eickhoff C., Department of Computer Science, ETH Zurich, Zurich, Switzerland, Center for Biomedical Informatics, Brown University, Providence, RI, United States","Background: The large amount of clinical signals in intensive care units can easily overwhelm health-care personnel and can lead to treatment delays, suboptimal care, or clinical errors. The aim of this study was to apply deep machine learning methods to predict severe complications during critical care in real time after cardiothoracic surgery. Methods: We used deep learning methods (recurrent neural networks) to predict several severe complications (mortality, renal failure with a need for renal replacement therapy, and postoperative bleeding leading to operative revision) in post cardiosurgical care in real time. Adult patients who underwent major open heart surgery from Jan 1, 2000, to Dec 31, 2016, in a German tertiary care centre for cardiovascular diseases formed the main derivation dataset. We measured the accuracy and timeliness of the deep learning model's forecasts and compared predictive quality to that of established standard-of-care clinical reference tools (clinical rule for postoperative bleeding, Simplified Acute Physiology Score II for mortality, and the Kidney Disease: Improving Global Outcomes staging criteria for acute renal failure) using positive predictive value (PPV), negative predictive value, sensitivity, specificity, area under the curve (AUC), and the F1 measure (which computes a harmonic mean of sensitivity and PPV). Results were externally retrospectively validated with 5898 cases from the published MIMIC-III dataset. Findings: Of 47 559 intensive care admissions (corresponding to 42 007 patients), we included 11 492 (corresponding to 9269 patients). The deep learning models yielded accurate predictions with the following PPV and sensitivity scores: PPV 0·90 and sensitivity 0·85 for mortality, 0·87 and 0·94 for renal failure, and 0·84 and 0·74 for bleeding. The predictions significantly outperformed the standard clinical reference tools, improving the absolute complication prediction AUC by 0·29 (95% CI 0·23–0·35) for bleeding, by 0·24 (0·19–0·29) for mortality, and by 0·24 (0·13–0·35) for renal failure (p<0·0001 for all three analyses). The deep learning methods showed accurate predictions immediately after patient admission to the intensive care unit. We also observed an increase in performance in our validation cohort when the machine learning approach was tested against clinical reference tools, with absolute improvements in AUC of 0·09 (95% CI 0·03–0·15; p=0·0026) for bleeding, of 0·18 (0·07–0·29; p=0·0013) for mortality, and of 0·25 (0·18–0·32; p<0·0001) for renal failure. Interpretation: The observed improvements in prediction for all three investigated clinical outcomes have the potential to improve critical care. These findings are noteworthy in that they use routinely collected clinical data exclusively, without the need for any manual processing. The deep machine learning method showed AUC scores that significantly surpass those of clinical reference tools, especially soon after admission. Taken together, these properties are encouraging for prospective deployment in critical care settings to direct the staff's attention towards patients who are most at risk. Funding: No specific funding. © 2018 Elsevier Ltd","","Aged; Cardiac Surgical Procedures; Deep Learning; Female; Humans; Intensive Care Units; Male; Middle Aged; Outcome Assessment (Health Care); Postoperative Hemorrhage; Predictive Value of Tests; Renal Insufficiency; Retrospective Studies; ROC Curve; adult; aged; Article; artificial neural network; cardiac surgery intensive care unit; cardiovascular disease; cohort analysis; controlled study; diagnostic accuracy; disease severity; female; Germany; human; kidney failure; machine learning; major clinical study; male; mortality; open heart surgery; postoperative care; postoperative complication; postoperative hemorrhage; prediction; predictive value; priority journal; recurrent neural network; renal replacement therapy; reoperation; retrospective study; sensitivity and specificity; Simplified Acute Physiology Score; tertiary care center; heart surgery; intensive care unit; kidney failure; middle aged; outcome assessment; postoperative hemorrhage; receiver operating characteristic; statistics and numerical data; validation study","Lancet Publishing Group","22132600","","","30274956","Article","Scopus","2-s2.0-85059098244"
"Xia F.; Shukla M.; Brettin T.; Garcia-Cardona C.; Cohn J.; Allen J.E.; Maslov S.; Holbeck S.L.; Doroshow J.H.; Evrard Y.A.; Stahlberg E.A.; Stevens R.L.","Xia, Fangfang (15761155800); Shukla, Maulik (56266020000); Brettin, Thomas (34976299400); Garcia-Cardona, Cristina (55200807700); Cohn, Judith (12773828500); Allen, Jonathan E. (55477892900); Maslov, Sergei (7007164417); Holbeck, Susan L. (6701842278); Doroshow, James H. (57205585558); Evrard, Yvonne A. (57190219520); Stahlberg, Eric A. (8974986200); Stevens, Rick L. (57221587276)","15761155800; 56266020000; 34976299400; 55200807700; 12773828500; 55477892900; 7007164417; 6701842278; 57205585558; 57190219520; 8974986200; 57221587276","Predicting tumor cell line response to drug pairs with deep learning","2018","BMC Bioinformatics","81","10.1186/s12859-018-2509-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058926597&doi=10.1186%2fs12859-018-2509-3&partnerID=40&md5=943670e4663f3c0b3f8da01ca38ebc9c","Computing, Environment and Life Sciences, Argonne National Laboratory, Lemont, IL, United States; Computation Institute, The University of Chicago, Chicago, IL, United States; Center for Nonlinear Studies, Los Alamos National Laboratory, Los Alamos, NM, United States; Computer Science, Los Alamos National Laboratory, Los Alamos, NM, United States; Computation Directorate, Lawrence Livermore National Laboratory, Livermore, CA, United States; Department of Bioengineering and Carl R. Woese Institute for Genomic Biology, University of Illinois at Urbana-Champaign, Urbana, IL, United States; Developmental Therapeutics Branch, National Cancer Institute, Frederick, MD, United States; Data Science and Information Technology Program, Frederick National Laboratory for Cancer Research, Frederick, MD, United States","Xia F., Computing, Environment and Life Sciences, Argonne National Laboratory, Lemont, IL, United States, Computation Institute, The University of Chicago, Chicago, IL, United States; Shukla M., Computing, Environment and Life Sciences, Argonne National Laboratory, Lemont, IL, United States; Brettin T., Computing, Environment and Life Sciences, Argonne National Laboratory, Lemont, IL, United States; Garcia-Cardona C., Center for Nonlinear Studies, Los Alamos National Laboratory, Los Alamos, NM, United States; Cohn J., Computer Science, Los Alamos National Laboratory, Los Alamos, NM, United States; Allen J.E., Computation Directorate, Lawrence Livermore National Laboratory, Livermore, CA, United States; Maslov S., Department of Bioengineering and Carl R. Woese Institute for Genomic Biology, University of Illinois at Urbana-Champaign, Urbana, IL, United States; Holbeck S.L., Developmental Therapeutics Branch, National Cancer Institute, Frederick, MD, United States; Doroshow J.H., Developmental Therapeutics Branch, National Cancer Institute, Frederick, MD, United States; Evrard Y.A., Developmental Therapeutics Branch, National Cancer Institute, Frederick, MD, United States; Stahlberg E.A., Data Science and Information Technology Program, Frederick National Laboratory for Cancer Research, Frederick, MD, United States; Stevens R.L., Computing, Environment and Life Sciences, Argonne National Laboratory, Lemont, IL, United States, Computation Institute, The University of Chicago, Chicago, IL, United States","Background: The National Cancer Institute drug pair screening effort against 60 well-characterized human tumor cell lines (NCI-60) presents an unprecedented resource for modeling combinational drug activity. Results: We present a computational model for predicting cell line response to a subset of drug pairs in the NCI-ALMANAC database. Based on residual neural networks for encoding features as well as predicting tumor growth, our model explains 94% of the response variance. While our best result is achieved with a combination of molecular feature types (gene expression, microRNA and proteome), we show that most of the predictive power comes from drug descriptors. To further demonstrate value in detecting anticancer therapy, we rank the drug pairs for each cell line based on model predicted combination effect and recover 80% of the top pairs with enhanced activity. Conclusions: We present promising results in applying deep learning to predicting combinational drug response. Our feature analysis indicates screening data involving more cell lines are needed for the models to make better use of molecular features. © 2018 The Author(s).","Combination therapy; Deep learning; In silico drug screening; Machine learning","Cell Line, Tumor; Deep Learning; Drug Evaluation, Preclinical; Humans; National Cancer Institute (U.S.); Neural Networks (Computer); United States; Cell culture; Diagnosis; Drug therapy; Essential oils; Forecasting; Gene expression; Learning systems; RNA; Tumors; Anti-cancer therapies; Combination effects; Combination therapy; Computational model; Drug screening; Human tumor cell lines; Molecular feature; National Cancer Institute; artificial neural network; human; national health organization; preclinical study; procedures; trends; tumor cell line; United States; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","30577754","Article","Scopus","2-s2.0-85058926597"
"Li X.; Zhu D.; Levy P.","Li, Xiangrui (57202296156); Zhu, Dongxiao (8833182000); Levy, Phillip (57203678471)","57202296156; 8833182000; 57203678471","Leveraging auxiliary measures: A deep multi-task neural network for predictive modeling in clinical research","2018","BMC Medical Informatics and Decision Making","3","10.1186/s12911-018-0676-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058295299&doi=10.1186%2fs12911-018-0676-9&partnerID=40&md5=94de03063e75d604d97d932eec5ba265","Department of Computer Science, Wayne State University, Detroit, MI, United States; Department of Emergency Medicine, Wayne State University, Detroit, MI, United States; Integrative Biosciences Center, Wayne State University, Detroit, MI, United States","Li X., Department of Computer Science, Wayne State University, Detroit, MI, United States; Zhu D., Department of Computer Science, Wayne State University, Detroit, MI, United States; Levy P., Department of Emergency Medicine, Wayne State University, Detroit, MI, United States, Integrative Biosciences Center, Wayne State University, Detroit, MI, United States","Background: Accurate predictive modeling in clinical research enables effective early intervention that patients are most likely to benefit from. However, due to the complex biological nature of disease progression, capturing the highly non-linear information from low-level input features is quite challenging. This requires predictive models with high-capacity. In practice, clinical datasets are often of limited size, bringing danger of overfitting for high-capacity models. To address these two challenges, we propose a deep multi-task neural network for predictive modeling. Methods: The proposed network leverages clinical measures as auxiliary targets that are related to the primary target. The predictions for the primary and auxiliary targets are made simultaneously by the neural network. Network structure is specifically designed to capture the clinical relevance by learning a shared feature representation between the primary and auxiliary targets. We apply the proposed model in a hypertension dataset and a breast cancer dataset, where the primary tasks are to predict the left ventricular mass indexed to body surface area and the time of recurrence of breast cancer. Moreover, we analyze the weights of the proposed neural network to rank input features for model interpretability. Results: The experimental results indicate that the proposed model outperforms other different models, achieving the best predictive accuracy (mean squared error 199.76 for hypertension data, 860.62 for Wisconsin prognostic breast cancer data) with the ability to rank features according to their contributions to the targets. The ranking is supported by previous related research. Conclusion: We propose a novel effective method for clinical predictive modeling by combing the deep neural network and multi-task learning. By leveraging auxiliary measures clinically related to the primary target, our method improves the predictive accuracy. Based on featue ranking, our model is interpreted and shows consistency with previous studies on cardiovascular diseases and cancers. © 2018 The Author(s).","Auxiliary task; Deep neural network; Multi-task learning; Predictive modeling","Breast Neoplasms; Humans; Hypertension; Machine Learning; Neural Networks (Computer); Predictive Value of Tests; Prognosis; Risk Assessment; artificial neural network; breast tumor; complication; human; hypertension; machine learning; predictive value; prognosis; risk assessment","BioMed Central Ltd","14726947","","","30537954","Article","Scopus","2-s2.0-85058295299"
"Su C.; Tong J.; Zhu Y.; Cui P.; Wang F.","Su, Chang (55750735500); Tong, Jie (57204955328); Zhu, Yongjun (56015852600); Cui, Peng (34568700100); Wang, Fei (56177292700)","55750735500; 57204955328; 56015852600; 34568700100; 56177292700","Network embedding in biomedical data science","2018","Briefings in Bioinformatics","110","10.1093/bib/bby117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065239814&doi=10.1093%2fbib%2fbby117&partnerID=40&md5=b859febcbaec2306ecebd008453ef1d5","Department of Healthcare Policy and Research, Weill Cornell Medicine at Cornell University, 425 East 61 Street, New York, 10065, NY, United States; Department of Mechanical and Aerospace Engineering, New York University, New York, NY, United States; Department of Library and Information Science, Sungkyunkwan University, Seoul, South Korea; Department of Computer Science and Technology, Tsinghua University, Beijing, China","Su C., Department of Healthcare Policy and Research, Weill Cornell Medicine at Cornell University, 425 East 61 Street, New York, 10065, NY, United States; Tong J., Department of Mechanical and Aerospace Engineering, New York University, New York, NY, United States; Zhu Y., Department of Library and Information Science, Sungkyunkwan University, Seoul, South Korea; Cui P., Department of Computer Science and Technology, Tsinghua University, Beijing, China; Wang F., Department of Healthcare Policy and Research, Weill Cornell Medicine at Cornell University, 425 East 61 Street, New York, 10065, NY, United States","Owning to the rapid development of computer technologies, an increasing number of relational data have been emerging in modern biomedical research. Many network-based learning methods have been proposed to perform analysis on such data, which provide people a deep understanding of topology and knowledge behind the biomedical networks and benefit a lot of applications for human healthcare. However, most network-based methods suffer from high computational and space cost. There remain challenges on handling high dimensionality and sparsity of the biomedical networks. The latest advances in network embedding technologies provide new effective paradigms to solve the network analysis problem. It converts network into a low-dimensional space while maximally preserves structural properties. In this way, downstream tasks such as link prediction and node classification can be done by traditional machine learning methods. In this survey, we conduct a comprehensive review of the literature on applying network embedding to advance the biomedical domain. We first briefly introduce the widely used network embedding models. After that, we carefully discuss how the network embedding approaches were performed on biomedical networks as well as how they accelerated the downstream tasks in biomedical science. Finally, we discuss challenges the existing network embedding applications in biomedical domains are faced with and suggest several promising future directions for a better improvement in human healthcare. © 2018 The Author(s) 2018. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.","biomedical informatics; biomedical knowledge graphs; biomedical networks; graph embedding; network embedding; network-based learning","article; data science; embedding; human; human experiment; machine learning; prediction; biomedicine; information science; learning; machine learning; network analysis","Oxford University Press","14675463","","","30535359","Article","Scopus","2-s2.0-85065239814"
"Zhang Y.; Hamada M.","Zhang, Yiqian (57205252081); Hamada, Michiaki (24484814700)","57205252081; 24484814700","DeepM6ASeq: Prediction and characterization of m6A-containing sequences using deep learning","2018","BMC Bioinformatics","92","10.1186/s12859-018-2516-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059265094&doi=10.1186%2fs12859-018-2516-4&partnerID=40&md5=f0eb246974995e7e44f22f0db45d120d","Department of Electrical Engineering and Bioscience, Faculty of Science and Engineering, Waseda University, 55N-06-10, 3-4-1 Okubo, Tokyo, Shinjuku-ku, 169-8555, Japan; AIST-Waseda University Computational Bio Big-Data Open Innovation Laboratory (CBBD-OIL), 3-4-1, Okubo, Tokyo, Shinjuku-ku, 169-8555, Japan; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), 2-41-6 Aomi, Tokyo, Koto-ku, 135-0064, Japan; Institute for Medical-oriented Structural Biology, Waseda University, 2-2, Wakamatsu-cho, Tokyo, Shinjuku-ku, 162-8480, Japan; Graduate School of Medicine, Nippon Medical School, 1-1-5, Sendagi, Tokyo, Bunkyo-ku, 113-8602, Japan","Zhang Y., Department of Electrical Engineering and Bioscience, Faculty of Science and Engineering, Waseda University, 55N-06-10, 3-4-1 Okubo, Tokyo, Shinjuku-ku, 169-8555, Japan, AIST-Waseda University Computational Bio Big-Data Open Innovation Laboratory (CBBD-OIL), 3-4-1, Okubo, Tokyo, Shinjuku-ku, 169-8555, Japan; Hamada M., Department of Electrical Engineering and Bioscience, Faculty of Science and Engineering, Waseda University, 55N-06-10, 3-4-1 Okubo, Tokyo, Shinjuku-ku, 169-8555, Japan, AIST-Waseda University Computational Bio Big-Data Open Innovation Laboratory (CBBD-OIL), 3-4-1, Okubo, Tokyo, Shinjuku-ku, 169-8555, Japan, Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), 2-41-6 Aomi, Tokyo, Koto-ku, 135-0064, Japan, Institute for Medical-oriented Structural Biology, Waseda University, 2-2, Wakamatsu-cho, Tokyo, Shinjuku-ku, 162-8480, Japan, Graduate School of Medicine, Nippon Medical School, 1-1-5, Sendagi, Tokyo, Bunkyo-ku, 113-8602, Japan","Background: N6-methyladensine (m6A) is a common and abundant RNA methylation modification found in various species. As a type of post-transcriptional methylation, m6A plays an important role in diverse RNA activities such as alternative splicing, an interplay with microRNAs and translation efficiency. Although existing tools can predict m6A at single-base resolution, it is still challenging to extract the biological information surrounding m6A sites. Results: We implemented a deep learning framework, named DeepM6ASeq, to predict m6A-containing sequences and characterize surrounding biological features based on miCLIP-Seq data, which detects m6A sites at single-base resolution. DeepM6ASeq showed better performance as compared to other machine learning classifiers. Moreover, an independent test on m6A-Seq data, which identifies m6A-containing genomic regions, revealed that our model is competitive in predicting m6A-containing sequences. The learned motifs from DeepM6ASeq correspond to known m6A readers. Notably, DeepM6ASeq also identifies a newly recognized m6A reader: FMR1. Besides, we found that a saliency map in the deep learning model could be utilized to visualize locations of m6A sites. Conculsion: We developed a deep-learning-based framework to predict and characterize m6A-containing sequences and hope to help investigators to gain more insights for m6A research. The source code is available at https://github.com/rreybeyb/DeepM6ASeq. © 2018 The Author(s).","Deep learning; N6-methyladenosine; RNA modification","Adenosine; Alternative Splicing; Animals; Brain; Carcinoma, Hepatocellular; Computational Biology; Deep Learning; Embryonic Stem Cells; Humans; Liver Neoplasms; Methylation; Mice; RNA; Sequence Analysis, RNA; Zebrafish; Alkylation; Forecasting; Methylation; RNA; adenosine; N(6)-methyladenosine; RNA; Alternative splicing; Biological features; Biological information; Learning frameworks; Learning models; N6-methyladenosine; Post-transcriptional; Rna modifications; alternative RNA splicing; analogs and derivatives; animal; biology; brain; chemistry; cytology; embryonic stem cell; genetics; human; liver cell carcinoma; liver tumor; metabolism; methylation; mouse; pathology; procedures; sequence analysis; zebra fish; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","30598068","Article","Scopus","2-s2.0-85059265094"
"Biswal S.; Sun H.; Goparaju B.; Brandon Westover M.; Sun J.; Bianchi M.T.","Biswal, Siddharth (57038270500); Sun, Haoqi (57201066109); Goparaju, Balaji (56091976400); Brandon Westover, M. (55384180400); Sun, Jimeng (9737233900); Bianchi, Matt T. (7402561525)","57038270500; 57201066109; 56091976400; 55384180400; 9737233900; 7402561525","Expert-level sleep scoring with deep neural networks","2018","Journal of the American Medical Informatics Association","185","10.1093/jamia/ocy131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058591379&doi=10.1093%2fjamia%2focy131&partnerID=40&md5=03723d17ff3446d5ec5d4bf84d78fca0","School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Neurology Department, Massachusetts General Hospital, Wang 720, Boston, MA, United States; Division of Sleep Medicine, Harvard Medical School, Boston, MA, United States; Massachusetts General Hospital, 55 Fruit Street, Boston, 02114, MA, United States","Biswal S., School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Sun H., Neurology Department, Massachusetts General Hospital, Wang 720, Boston, MA, United States; Goparaju B., Neurology Department, Massachusetts General Hospital, Wang 720, Boston, MA, United States, Division of Sleep Medicine, Harvard Medical School, Boston, MA, United States; Brandon Westover M., Neurology Department, Massachusetts General Hospital, Wang 720, Boston, MA, United States, Massachusetts General Hospital, 55 Fruit Street, Boston, 02114, MA, United States; Sun J., School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Bianchi M.T., Neurology Department, Massachusetts General Hospital, Wang 720, Boston, MA, United States, Division of Sleep Medicine, Harvard Medical School, Boston, MA, United States","Objectives: Scoring laboratory polysomnography (PSG) data remains a manual task of visually annotating 3 primary categories: sleep stages, sleep disordered breathing, and limb movements. Attempts to automate this process have been hampered by the complexity of PSG signals and physiological heterogeneity between patients. Deep neural networks, which have recently achieved expert-level performance for other complex medical tasks, are ideally suited to PSG scoring, given sufficient training data. Methods: We used a combination of deep recurrent and convolutional neural networks (RCNN) for supervised learning of clinical labels designating sleep stages, sleep apnea events, and limb movements. The data for testing and training were derived from 10 000 clinical PSGs and 5804 research PSGs. Results: When trained on the clinical dataset, the RCNN reproduces PSG diagnostic scoring for sleep staging, sleep apnea, and limb movements with accuracies of 87.6%, 88.2% and 84.7% on held-out test data, a level of performance comparable to human experts. The RCNN model performs equally well when tested on the independent research PSG database. Only small reductions in accuracy were noted when training on limited channels to mimic at-home monitoring devices: frontal leads only for sleep staging, and thoracic belt signals only for the apnea-hypopnea index. Conclusions: By creating accurate deep learning models for sleep scoring, our work opens the path toward broader and more timely access to sleep diagnostics. Accurate scoring automation can improve the utility and efficiency of in-lab and at-home approaches to sleep diagnostics, potentially extending the reach of sleep expertise beyond specialty clinics. © The Author(s) 2018.","Deep learning; EEG analysis; Neural network; Sleep scoring","Classification; Datasets as Topic; Electroencephalography; Humans; Machine Learning; Models, Biological; Neural Networks (Computer); Polysomnography; Sleep; Sleep Apnea Syndromes; Sleep Stages; apnea hypopnea index; Article; artificial neural network; comparative study; evaluation study; human; learning; limb movement; mathematical computing; physiological process; polysomnography; scoring system; sleep; sleep disordered breathing; sleep stage; task performance; biological model; classification; electroencephalography; information processing; machine learning; pathophysiology; physiology; polysomnography; procedures; sleep; sleep disordered breathing","Oxford University Press","10675027","","JAMAF","30445569","Article","Scopus","2-s2.0-85058591379"
"Schwyzer M.; Ferraro D.A.; Muehlematter U.J.; Curioni-Fontecedro A.; Huellner M.W.; von Schulthess G.K.; Kaufmann P.A.; Burger I.A.; Messerli M.","Schwyzer, Moritz (55418848400); Ferraro, Daniela A. (57204673820); Muehlematter, Urs J. (57196050494); Curioni-Fontecedro, Alessandra (23987880700); Huellner, Martin W. (24461743300); von Schulthess, Gustav K. (7102938515); Kaufmann, Philipp A. (7201922417); Burger, Irene A. (34867843800); Messerli, Michael (57191670383)","55418848400; 57204673820; 57196050494; 23987880700; 24461743300; 7102938515; 7201922417; 34867843800; 57191670383","Automated detection of lung cancer at ultralow dose PET/CT by deep neural networks – Initial results","2018","Lung Cancer","92","10.1016/j.lungcan.2018.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056645279&doi=10.1016%2fj.lungcan.2018.11.001&partnerID=40&md5=cd5d483c309be2426d9a4a521dad1d79","Department of Nuclear Medicine, University Hospital Zurich, University of Zurich, Switzerland; Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Switzerland; Department of Medical Oncology, University Hospital Zurich, University of Zurich, Switzerland","Schwyzer M., Department of Nuclear Medicine, University Hospital Zurich, University of Zurich, Switzerland, Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Switzerland; Ferraro D.A., Department of Nuclear Medicine, University Hospital Zurich, University of Zurich, Switzerland; Muehlematter U.J., Department of Nuclear Medicine, University Hospital Zurich, University of Zurich, Switzerland, Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Switzerland; Curioni-Fontecedro A., Department of Medical Oncology, University Hospital Zurich, University of Zurich, Switzerland; Huellner M.W., Department of Nuclear Medicine, University Hospital Zurich, University of Zurich, Switzerland; von Schulthess G.K., Department of Nuclear Medicine, University Hospital Zurich, University of Zurich, Switzerland; Kaufmann P.A., Department of Nuclear Medicine, University Hospital Zurich, University of Zurich, Switzerland; Burger I.A., Department of Nuclear Medicine, University Hospital Zurich, University of Zurich, Switzerland; Messerli M., Department of Nuclear Medicine, University Hospital Zurich, University of Zurich, Switzerland","Objectives: We evaluated whether machine learning may be helpful for the detection of lung cancer in FDG-PET imaging in the setting of ultralow dose PET scans. Materials and methods: We studied the performance of an artificial neural network discriminating lung cancer patients (n = 50) from controls (n = 50) without pulmonary malignancies. A total of 3936 PET slices including images in which the lung tumor is visually present and image slices of patients with no lung cancer were exported. The diagnostic performance of the artificial neural network based on clinical standard dose PET images (PET100%) as well as with a tenfold (PET10%) and thirtyfold (PET3.3%) reduced radiation dose (∼0.11 mSv) was assessed. Results: The area under the curve of the deep learning algorithm for lung cancer detection was 0.989, 0.983 and 0.970 for standard dose images (PET100%), and reduced dose PET10%, and PET3.3% reconstruction, respectively. The artificial neural network achieved a sensitivity of 95.9% and 91.5% and a specificity of 98.1% and 94.2%, at standard dose and ultralow dose PET3.3%, respectively. Conclusion: Our results suggest that machine learning algorithms may aid fully automated lung cancer detection even at very low effective radiation doses of 0.11 mSv. Further improvement of this technology might improve the specificity of lung cancer screening efforts and could lead to new applications of FDG-PET. © 2018 Elsevier B.V.","Artificial intelligence; Deep learning; Low dose; Lung cancer; PET/CT","Early Detection of Cancer; Humans; Lung Neoplasms; Neural Networks (Computer); Positron Emission Tomography Computed Tomography; Reproducibility of Results; Retrospective Studies; ROC Curve; fluorodeoxyglucose f 18; area under the curve; Article; artificial neural network; body mass; cancer diagnosis; controlled study; diagnostic accuracy; diagnostic test accuracy study; false negative result; false positive result; human; image reconstruction; learning algorithm; lung cancer; machine learning; positron emission tomography-computed tomography; predictive value; priority journal; radiation dose reduction; retrospective study; sensitivity and specificity; diagnostic imaging; early cancer diagnosis; lung tumor; positron emission tomography-computed tomography; procedures; receiver operating characteristic; reproducibility","Elsevier Ireland Ltd","01695002","","LUCAE","30527183","Article","Scopus","2-s2.0-85056645279"
"Song W.; Wang S.; Yang B.; Lu Y.; Zhao X.; Liu X.","Song, Wenzhuo (57203597030); Wang, Shengsheng (56346199800); Yang, Bo (57200878440); Lu, You (57206597542); Zhao, Xuehua (55577834400); Liu, Xueyan (57155377300)","57203597030; 56346199800; 57200878440; 57206597542; 55577834400; 57155377300","Learning node and edge embeddings for signed networks","2018","Neurocomputing","24","10.1016/j.neucom.2018.08.072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053192430&doi=10.1016%2fj.neucom.2018.08.072&partnerID=40&md5=d93f02b2e39539258b57c8b76f7f194c","College of computer science and technology, Jilin University, Changchun, 130012, China; Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, China; Department of Computer Science, Virginia Tech, Blacksburg, 24060, VA, United States; School of Digital Media, Shenzhen Institute of Information Technology, Shenzhen, 518172, China","Song W., College of computer science and technology, Jilin University, Changchun, 130012, China, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, China; Wang S., College of computer science and technology, Jilin University, Changchun, 130012, China, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, China; Yang B., College of computer science and technology, Jilin University, Changchun, 130012, China, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, China; Lu Y., Department of Computer Science, Virginia Tech, Blacksburg, 24060, VA, United States; Zhao X., Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, China, School of Digital Media, Shenzhen Institute of Information Technology, Shenzhen, 518172, China; Liu X., College of computer science and technology, Jilin University, Changchun, 130012, China, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, China","Machine learning tasks for edges and nodes in networks heavily rely on feature engineering which requires expert knowledge and careful effort. Recent years, people become interested in the low dimensional vector representation of nodes and edges. However, existing methods on signed networks only aim to learn the node vectors, resulting in omitting edge information and extra effort to design edge vectors. In this work, we develop a framework for learning both nodes and edge vectors for signed networks. Thus, we can directly use edge vectors to represent the properties of the edges, and thereby improving the performance of link-oriented tasks. Our framework for learning network features is as below. We assume that there is a global mapping between the node and edge vector spaces. This assumption allows us to transform the problem into learning the mapping function and the node vectors. We propose node proximity for signed networks, a definition that is generalized from the second-order node proximity for unsigned networks. It provides a unified objective function that can preserve both the node and edge pattern of the network. Based on this definition, we propose two signed network representation methods. The first method is neural network signed network embedding (nSNE). It learns the node vectors and the mapping function via neural networks approach, which can uses the power of deep learning to fit with the data. The second method is light signed network embedding (lSNE). It specifies the mapping function as simply and linear function. It has fewer parameters to estimate and is equal to factorize both similarity and sign matrixes. We compare our methods with three state-of-the-art methods on four datasets. The results show that our methods are competitive. © 2018 Elsevier B.V.","Network embedding; Network representation learning; Neural networks; Signed social networks","Mapping; Neural networks; Vector spaces; Vectors; Expert knowledge; Feature engineerings; Linear functions; Mapping functions; Network embedding; Network representation; Objective functions; Signed social networks; article; embedding; human; learning; social network; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85053192430"
"Wasserthal J.; Neher P.; Maier-Hein K.H.","Wasserthal, Jakob (57201069385); Neher, Peter (39863354800); Maier-Hein, Klaus H. (55647018100)","57201069385; 39863354800; 55647018100","TractSeg - Fast and accurate white matter tract segmentation","2018","NeuroImage","292","10.1016/j.neuroimage.2018.07.070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051647630&doi=10.1016%2fj.neuroimage.2018.07.070&partnerID=40&md5=f3b522957c400d29ff51659680d30689","Division of Medical Image Computing (MIC), German Cancer Research Center (DKFZ), Im Neuenheimer Feld 581, Heidelberg, 69120, Germany; Medical Faculty Heidelberg, University of Heidelberg, Im Neuenheimer Feld 672, Heidelberg, 69120, Germany; Section of Automated Image Analysis, Heidelberg University Hospital, Im Neuenheimer Feld 672, Heidelberg, 69120, Germany","Wasserthal J., Division of Medical Image Computing (MIC), German Cancer Research Center (DKFZ), Im Neuenheimer Feld 581, Heidelberg, 69120, Germany, Medical Faculty Heidelberg, University of Heidelberg, Im Neuenheimer Feld 672, Heidelberg, 69120, Germany; Neher P., Division of Medical Image Computing (MIC), German Cancer Research Center (DKFZ), Im Neuenheimer Feld 581, Heidelberg, 69120, Germany; Maier-Hein K.H., Division of Medical Image Computing (MIC), German Cancer Research Center (DKFZ), Im Neuenheimer Feld 581, Heidelberg, 69120, Germany, Section of Automated Image Analysis, Heidelberg University Hospital, Im Neuenheimer Feld 672, Heidelberg, 69120, Germany","The individual course of white matter fiber tracts is an important factor for analysis of white matter characteristics in healthy and diseased brains. Diffusion-weighted MRI tractography in combination with region-based or clustering-based selection of streamlines is a unique combination of tools which enables the in-vivo delineation and analysis of anatomically well-known tracts. This, however, currently requires complex, computationally intensive processing pipelines which take a lot of time to set up. TractSeg is a novel convolutional neural network-based approach that directly segments tracts in the field of fiber orientation distribution function (fODF) peaks without using tractography, image registration or parcellation. We demonstrate that the proposed approach is much faster than existing methods while providing unprecedented accuracy, using a population of 105 subjects from the Human Connectome Project. We also show initial evidence that TractSeg is able to generalize to differently acquired data sets for most of the bundles. The code and data are openly available at https://github.com/MIC-DKFZ/TractSeg/ and https://doi.org/10.5281/zenodo.1088277, respectively. © 2018 The Authors","Deep learning; Diffusion-weighted imaging; Fiber tractography; Machine learning; Segmentation","Adult; Connectome; Deep Learning; Diffusion Tensor Imaging; Humans; Nerve Net; Neuroimaging; White Matter; adult; article; connectome; diffusion weighted imaging; female; human; human experiment; image analysis; machine learning; major clinical study; male; tractography; white matter; anatomy and histology; diagnostic imaging; diffusion tensor imaging; nerve cell network; neuroimaging; procedures; white matter","Academic Press Inc.","10538119","","NEIME","30086412","Article","Scopus","2-s2.0-85051647630"
"Wu C.; Guo S.; Hong Y.; Xiao B.; Wu Y.; Zhang Q.","Wu, Congling (57193572500); Guo, Shengwen (27168170800); Hong, Yanjia (57204971557); Xiao, Benheng (57204965901); Wu, Yupeng (57193576054); Zhang, Qin (23062517400)","57193572500; 27168170800; 57204971557; 57204965901; 57193576054; 23062517400","Discrimination and conversion prediction of mild cognitive impairment using convolutional neural networks","2018","Quantitative Imaging in Medicine and Surgery","46","10.21037/qims.2018.10.17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058181437&doi=10.21037%2fqims.2018.10.17&partnerID=40&md5=468b4c66e1c3abcb31ae5f33727d15f7","Department of Biomedical Engineering, South China University of Technology, Guangzhou, 510006, China","Wu C., Department of Biomedical Engineering, South China University of Technology, Guangzhou, 510006, China; Guo S., Department of Biomedical Engineering, South China University of Technology, Guangzhou, 510006, China; Hong Y., Department of Biomedical Engineering, South China University of Technology, Guangzhou, 510006, China; Xiao B., Department of Biomedical Engineering, South China University of Technology, Guangzhou, 510006, China; Wu Y., Department of Biomedical Engineering, South China University of Technology, Guangzhou, 510006, China; Zhang Q., Department of Biomedical Engineering, South China University of Technology, Guangzhou, 510006, China","Background: Recently, studies have demonstrated that machine learning techniques, particularly cutting-edge deep learning technology, have achieved significant progression on the classification of Alzheimer’s disease (AD) and its prodromal phase, mild cognitive impairment (MCI). Moreover, accurate prediction of the progress and the conversion risk from MCI to probable AD has been of great importance in clinical application. Methods: In this study, the baseline MR images and follow-up information during 3 years of 150 normal controls (NC), 150 patients with stable MCI (sMCI) and 157 converted MCI (cMCI) were collected from the Alzheimer’s Disease Neuroimaging Initiative (ADNI). The deep convolutional neural networks (CNNs) were adopted to distinguish different stages of MCI from the NC group, and predict the conversion time from MCI to AD. Two CNN architectures including GoogleNet and CaffeNet were explored and evaluated in multiple classifications and estimations of conversion risk using transfer learning from pre-trained ImageNet (via fine-tuning) and five-fold cross-validation. A novel data augmentation approach using random views aggregation was applied to generate abundant image patches from the original MR scans. Results: The GoogleNet acquired accuracies with 97.58%, 67.33% and 84.71% in three-way discrimination among the NC, sMCI and cMCI groups respectively, whereas the CaffeNet obtained promising accuracies of 98.71%, 72.04% and 92.35% in the NC, sMCI and cMCI classifications. Furthermore, the accuracy measures of conversion risk of patients with cMCI ranged from 71.25% to 83.25% in different time points using GoogleNet, whereas the CaffeNet achieved remarkable accuracy measures from 95.42% to 97.01% in conversion risk prediction. Conclusions: The experimental results demonstrated that the proposed methods had prominent capability in classification among the 3 groups such as sMCI, cMCI and NC, and exhibited significant ability in conversion risk prediction of patients with MCI. © Quantitative Imaging in Medicine and Surgery. All rights reserved.","Classification; Conversion risk prediction; Deep convolutional neural network (deep CNN); Mild cognitive impairment (MCI); Transfer learning","Article; artificial neural network; controlled study; differential diagnosis; female; follow up; human; major clinical study; male; mild cognitive impairment; nuclear magnetic resonance imaging; patient risk; prediction","AME Publishing Company","22234292","","","","Article","Scopus","2-s2.0-85058181437"
"Macomber M.W.; Phillips M.; Tarapov I.; Jena R.; Nori A.; Carter D.; Folgoc L.L.; Criminisi A.; Nyflot M.J.","Macomber, Meghan W. (55973077900); Phillips, Mark (7402769478); Tarapov, Ivan (57204742073); Jena, Rajesh (12139241000); Nori, Aditya (15832336400); Carter, David (57204741684); Folgoc, Loic Le (55626727700); Criminisi, Antonio (6603756861); Nyflot, Matthew J. (23470221100)","55973077900; 7402769478; 57204742073; 12139241000; 15832336400; 57204741684; 55626727700; 6603756861; 23470221100","Autosegmentation of prostate anatomy for radiation treatment planning using deep decision forests of radiomic features","2018","Physics in Medicine and Biology","21","10.1088/1361-6560/aaeaa4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056910941&doi=10.1088%2f1361-6560%2faaeaa4&partnerID=40&md5=10bf410589a1a71cf48c4270a33a6589","Department of Radiation Oncology, University of Washington, Seattle, WA, United States; Microsoft Research, Redmond, WA, United States; Department of Oncology, University of Cambridge, Cambridge, United Kingdom; Microsoft Research, Cambridge, United Kingdom; Department of Radiology, University of Washington, Seattle, WA, United States","Macomber M.W., Department of Radiation Oncology, University of Washington, Seattle, WA, United States; Phillips M., Department of Radiation Oncology, University of Washington, Seattle, WA, United States; Tarapov I., Microsoft Research, Redmond, WA, United States; Jena R., Department of Oncology, University of Cambridge, Cambridge, United Kingdom; Nori A., Microsoft Research, Cambridge, United Kingdom; Carter D., Microsoft Research, Cambridge, United Kingdom; Folgoc L.L., Microsoft Research, Cambridge, United Kingdom; Criminisi A., Microsoft Research, Cambridge, United Kingdom; Nyflot M.J., Department of Radiation Oncology, University of Washington, Seattle, WA, United States, Department of Radiology, University of Washington, Seattle, WA, United States","Machine learning for image segmentation could provide expedited clinic workflow and better standardization of contour delineation. We evaluated a new model using deep decision forests of image features in order to contour pelvic anatomy on treatment planning CTs. 193 CT scans from one UK and two US institutions for patients undergoing radiotherapy treatment for prostate cancer from 2012-2016 were anonymized. A decision forest autosegmentation model was trained on a random selection of 94 images from Institution 1 and tested on 99 scans from Institution 1, 2, and 3. The accuracy of model contours was measured with the Dice similarity coefficient (DSC) and the median slice-wise Hausdorff distance (MSHD) using clinical contours as the ground truth reference. Two comparison studies were performed. The accuracy of the model was compared to four commercial software packages on twenty randomly-selected images. Additionally, inter-observer variability (IOV) of contours between three radiation oncology experts and the original contours was evaluated on ten randomly-selected images. The highest median values of DSC across all institutions were 0.94-0.97 for bladder (with interquartile range, or IQR, of 0.92-0.98) and 0.96-0.97 (IQR 0.94-0.97) for femurs. Good agreement was seen for prostate, with median DSC 0.75-0.76 (IQR 0.67-0.82), and rectum, with median DSC 0.71-0.82 (IQR 0.63-0.87). The lowest median scores were 0.49-0.70 for seminal vesicles (IQR 0.31-0.79). For the commercial software comparison, model-based segmentation produced higher DSC than atlas-based segmentation, with decision forests producing highest DSC for all organs of interest. For the interobserver study, variability in DSC between observers was similar to the agreement between the model and ground truth. Deep decision forests of radiomic features can generate contours of pelvic anatomy with reasonable agreement with physician contours. This method could be useful for automated treatment planning, and autosegmentation may improve efficiency and increase standardization in the clinic. © 2018 Institute of Physics and Engineering in Medicine.","autosegmentation; deep decision forests; radiomics","Humans; Image Processing, Computer-Assisted; Male; Models, Anatomic; Observer Variation; Pattern Recognition, Automated; Prostate; Prostatic Neoplasms; Radiotherapy Planning, Computer-Assisted; Tomography, X-Ray Computed; Diseases; Forestry; Image segmentation; Learning algorithms; Learning systems; Oncology; Radiotherapy; Standardization; Urology; Atlas-based segmentation; Auto segmentation; Decision forest; Interobserver variability; Model-based segmentation; Radiation treatment planning; radiomics; Similarity coefficients; anatomic model; anatomy and histology; automated pattern recognition; diagnostic imaging; human; image processing; male; observer variation; procedures; prostate; prostate tumor; radiotherapy planning system; x-ray computed tomography; Computerized tomography","Institute of Physics Publishing","00319155","","PHMBA","30465543","Article","Scopus","2-s2.0-85056910941"
"Ferreira Da Costa J.; Silva D.; Caamaño O.; Brea J.M.; Loza M.I.; Munteanu C.R.; Pazos A.; García-Mera X.; González-Díaz H.","Ferreira Da Costa, Joana (36160217900); Silva, David (57202252575); Caamaño, Olga (6603871345); Brea, José M. (6603008588); Loza, Maria Isabel (7003766926); Munteanu, Cristian R. (35230297200); Pazos, Alejandro (7006526793); García-Mera, Xerardo (6701392096); González-Díaz, Humbert (6603767394)","36160217900; 57202252575; 6603871345; 6603008588; 7003766926; 35230297200; 7006526793; 6701392096; 6603767394","Perturbation Theory/Machine Learning Model of ChEMBL Data for Dopamine Targets: Docking, Synthesis, and Assay of New l -Prolyl- l -leucyl-glycinamide Peptidomimetics","2018","ACS Chemical Neuroscience","40","10.1021/acschemneuro.8b00083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047635881&doi=10.1021%2facschemneuro.8b00083&partnerID=40&md5=bf71113ede4fdf77a0259cc648961a57","Department of Organic Chemistry, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain; CIMUS, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain; Department of Pharmacology, Pharmacy and Pharmaceutical Technology, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain; Instituto de Investigacion Biomedica de A Coruña (INIBIC), Complexo Hospitalario Universitario de A Coruña (CHUAC), A Coruña, 15006, Spain; Computer Science Department, Faculty of Computer Science, University of A Coruna, A Coruña, 15071, Spain; Department of Organic Chemistry II, University of Basque Country UPV/EHU, Leioa, 48940, Spain; IKERBASQUE, Basque Foundation for Science, Bilbao, 48011, Spain","Ferreira Da Costa J., Department of Organic Chemistry, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain; Silva D., Department of Organic Chemistry, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain; Caamaño O., Department of Organic Chemistry, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain; Brea J.M., CIMUS, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain, Department of Pharmacology, Pharmacy and Pharmaceutical Technology, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain; Loza M.I., CIMUS, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain, Department of Pharmacology, Pharmacy and Pharmaceutical Technology, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain; Munteanu C.R., Instituto de Investigacion Biomedica de A Coruña (INIBIC), Complexo Hospitalario Universitario de A Coruña (CHUAC), A Coruña, 15006, Spain; Pazos A., Instituto de Investigacion Biomedica de A Coruña (INIBIC), Complexo Hospitalario Universitario de A Coruña (CHUAC), A Coruña, 15006, Spain, Computer Science Department, Faculty of Computer Science, University of A Coruna, A Coruña, 15071, Spain; García-Mera X., Department of Organic Chemistry, University of Santiago de Compostela, Santiago de Compostela, 15782, Spain; González-Díaz H., Department of Organic Chemistry II, University of Basque Country UPV/EHU, Leioa, 48940, Spain, IKERBASQUE, Basque Foundation for Science, Bilbao, 48011, Spain","Predicting drug-protein interactions (DPIs) for target proteins involved in dopamine pathways is a very important goal in medicinal chemistry. We can tackle this problem using Molecular Docking or Machine Learning (ML) models for one specific protein. Unfortunately, these models fail to account for large and complex big data sets of preclinical assays reported in public databases. This includes multiple conditions of assays, such as different experimental parameters, biological assays, target proteins, cell lines, organism of the target, or organism of assay. On the other hand, perturbation theory (PT) models allow us to predict the properties of a query compound or molecular system in experimental assays with multiple boundary conditions based on a previously known case of reference. In this work, we report the first PTML (PT + ML) study of a large ChEMBL data set of preclinical assays of compounds targeting dopamine pathway proteins. The best PTML model found predicts 50000 cases with accuracy of 70-91% in training and external validation series. We also compared the linear PTML model with alternative PTML models trained with multiple nonlinear methods (artificial neural network (ANN), Random Forest, Deep Learning, etc.). Some of the nonlinear methods outperform the linear model but at the cost of a notable increment of the complexity of the model. We illustrated the practical use of the new model with a proof-of-concept theoretical-experimental study. We reported for the first time the organic synthesis, chemical characterization, and pharmacological assay of a new series of l-prolyl-l-leucyl-glycinamide (PLG) peptidomimetic compounds. In addition, we performed a molecular docking study for some of these compounds with the software Vina AutoDock. The work ends with a PTML model predictive study of the outcomes of the new compounds in a large number of assays. Therefore, this study offers a new computational methodology for predicting the outcome for any compound in new assays. This PTML method focuses on the prediction with a simple linear model of multiple pharmacological parameters (IC50, EC50, Ki, etc.) for compounds in assays involving different cell lines used, organisms of the protein target, or organism of assay for proteins in the dopamine pathway. Copyright © 2018 American Chemical Society.","ChEMBL; machine learning; peptide organic synthesis; PLG peptidomimetics","Allosteric Regulation; Databases, Chemical; Deep Learning; Dopamine; Humans; Machine Learning; Models, Molecular; Molecular Docking Simulation; MSH Release-Inhibiting Hormone; Neural Networks, Computer; Nonlinear Dynamics; Peptidomimetics; Receptors, Dopamine D2; Software; alpha adrenergic receptor; dextro [3,5 bis(azidomethyl) 1 (tert butoxycarbonyl)]prolyl levo leucyl levo alanine; dextro [3,5 bis(azidomethyl) 1 (tert butoxycarbonyl)]prolyl levo valyl levo alanylamide; dextro [3,5 bis(azidomethyl)]prolyl levo valyl levo alanine hydrochloride; dextro [3,5 bis(azidomethyl)]prolyl levo valyl levo alanylamide hydrochloride; dopamine 1 receptor; dopamine 2 receptor; dopamine 3 receptor; dopamine 4 receptor; dopamine receptor; dopamine transporter; levo [3,5 bis(azidomethyl) 1 (tert butoxycarbonyl)]prolyl levo valyl levo alanylamide; levo [3,5 bis(azidomethyl)]prolyl levo valyl levo alanine hydrochloride; levo [3,5 bis(azidomethyl)]prolyl levo valyl levo alanylamide hydrochloride; methyl dextro [3,5 bis(azidomethyl) 1 (tert butoxycarbonyl)]prolyl levo valyl levo alanilate; methyl dextro [3,5 bis(azidomethyl)]prolyl levo valyl levo alanilate hydrochloride; methyl levo [3,5 bis(azidomethyl) 1 (tert butoxycarbonyl)]prolyl levo valyl levo alanilate; methyl levo [3,5 bis(azidomethyl)]prolyl levo valyl levo alanilate hydrochloride; noradrenalin; noradrenalin transporter; peptidomimetic agent; prolylleucylglycinamide; serotonin receptor; serotonin transporter; unclassified drug; dopamine; dopamine 2 receptor; melanostatin; peptidomimetic agent; animal cell; Article; artificial neural network; biological activity; comparative study; deep learning; diastereoisomer; drug protein binding; drug receptor binding; EC50; female; human; human cell; hydrophobicity; IC50; intrinsic activity; machine learning; molecular docking; nonhuman; peptide synthesis; perceptron; perturbation theory; pharmacological parameters; preclinical study; priority journal; protein targeting; random forest; receiver operating characteristic; selectivity index; sensitivity and specificity; statistical model; theoretical model; allosterism; chemical database; chemistry; metabolism; molecular model; nonlinear system; software","American Chemical Society","19487193","","ACNCD","29791132","Article","Scopus","2-s2.0-85047635881"
"Arabi H.; Dowling J.A.; Burgos N.; Han X.; Greer P.B.; Koutsouvelis N.; Zaidi H.","Arabi, Hossein (57220877447); Dowling, Jason A. (57210097371); Burgos, Ninon (55887379000); Han, Xiao (55286810300); Greer, Peter B. (57204782270); Koutsouvelis, Nikolaos (57189645699); Zaidi, Habib (7004977873)","57220877447; 57210097371; 55887379000; 55286810300; 57204782270; 57189645699; 7004977873","Comparative study of algorithms for synthetic CT generation from MRI: Consequences for MRI-guided radiation planning in the pelvic region","2018","Medical Physics","97","10.1002/mp.13187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054705445&doi=10.1002%2fmp.13187&partnerID=40&md5=cf726771771065ce3c5e5665b258bc39","Division of Nuclear Medicine and Molecular Imaging, Geneva University Hospital, Geneva, CH-1211, Switzerland; CSIRO Australian e-Health Research Centre, Herston, QLD, Australia; Inria Paris, Aramis Project-Team, Institut du Cerveau et de la Moelle épinière, ICM, Inserm U 1127, CNRS, UMR 7225, Sorbonne Université, Paris, F-75013, France; Elekta Inc., Maryland Heights, 63043, MO, United States; Calvary Mater Newcastle Hospital, Waratah, NSW, Australia; University of Newcastle, Callaghan, NSW, Australia; Division of Radiation Oncology, Geneva University Hospital, Geneva, CH-1211, Switzerland; Geneva University Neurocenter, University of Geneva, Geneva, 1205, Switzerland; Department of Nuclear Medicine and Molecular Imaging, University of Groningen, Groningen, Netherlands; Department of Nuclear Medicine, University of Southern Denmark, Odense, DK-500, Denmark","Arabi H., Division of Nuclear Medicine and Molecular Imaging, Geneva University Hospital, Geneva, CH-1211, Switzerland; Dowling J.A., CSIRO Australian e-Health Research Centre, Herston, QLD, Australia; Burgos N., Inria Paris, Aramis Project-Team, Institut du Cerveau et de la Moelle épinière, ICM, Inserm U 1127, CNRS, UMR 7225, Sorbonne Université, Paris, F-75013, France; Han X., Elekta Inc., Maryland Heights, 63043, MO, United States; Greer P.B., Calvary Mater Newcastle Hospital, Waratah, NSW, Australia, University of Newcastle, Callaghan, NSW, Australia; Koutsouvelis N., Division of Radiation Oncology, Geneva University Hospital, Geneva, CH-1211, Switzerland; Zaidi H., Division of Nuclear Medicine and Molecular Imaging, Geneva University Hospital, Geneva, CH-1211, Switzerland, Geneva University Neurocenter, University of Geneva, Geneva, 1205, Switzerland, Department of Nuclear Medicine and Molecular Imaging, University of Groningen, Groningen, Netherlands, Department of Nuclear Medicine, University of Southern Denmark, Odense, DK-500, Denmark","Purpose: Magnetic resonance imaging (MRI)-guided radiation therapy (RT) treatment planning is limited by the fact that the electron density distribution required for dose calculation is not readily provided by MR imaging. We compare a selection of novel synthetic CT generation algorithms recently reported in the literature, including segmentation-based, atlas-based and machine learning techniques, using the same cohort of patients and quantitative evaluation metrics. Methods: Six MRI-guided synthetic CT generation algorithms were evaluated: one segmentation technique into a single tissue class (water-only), four atlas-based techniques, namely, median value of atlas images (ALMedian), atlas-based local weighted voting (ALWV), bone enhanced atlas-based local weighted voting (ALWV-Bone), iterative atlas-based local weighted voting (ALWV-Iter), and a machine learning technique using deep convolution neural network (DCNN). Results: Organ auto-contouring from MR images was evaluated for bladder, rectum, bones, and body boundary. Overall, DCNN exhibited higher segmentation accuracy resulting in Dice indices (DSC) of 0.93 ± 0.17, 0.90 ± 0.04, and 0.93 ± 0.02 for bladder, rectum, and bones, respectively. On the other hand, ALMedian showed the lowest accuracy with DSC of 0.82 ± 0.20, 0.81 ± 0.08, and 0.88 ± 0.04, respectively. DCNN reached the best performance in terms of accurate derivation of synthetic CT values within each organ, with a mean absolute error within the body contour of 32.7 ± 7.9 HU, followed by the advanced atlas-based methods (ALWV: 40.5 ± 8.2 HU, ALWV-Iter: 42.4 ± 8.1 HU, ALWV-Bone: 44.0 ± 8.9 HU). ALMedian led to the highest error (52.1 ± 11.1 HU). Considering the dosimetric evaluation results, ALWV-Iter, ALWV, DCNN and ALWV-Bone led to similar mean dose estimation within each organ at risk and target volume with less than 1% dose discrepancy. However, the two-dimensional gamma analysis demonstrated higher pass rates for ALWV-Bone, DCNN, ALMedian and ALWV-Iter at 1%/1 mm criterion with 94.99 ± 5.15%, 94.59 ± 5.65%, 93.68 ± 5.53% and 93.10 ± 5.99% success, respectively, while ALWV and water-only resulted in 86.91 ± 13.50% and 80.77 ± 12.10%, respectively. Conclusions: Overall, machine learning and advanced atlas-based methods exhibited promising performance by achieving reliable organ segmentation and synthetic CT generation. DCNN appears to have slightly better performance by achieving accurate automated organ segmentation and relatively small dosimetric errors (followed closely by advanced atlas-based methods, which in some cases achieved similar performance). However, the DCNN approach showed higher vulnerability to anatomical variation, where a greater number of outliers was observed with this method. Considering the dosimetric results obtained from the evaluated methods, the challenge of electron density estimation from MR images can be resolved with a clinically tolerable error. © 2018 American Association of Physicists in Medicine","atlas-based; CT synthesis; machine learning; MRI-guided radiotherapy planning; segmentation","Algorithms; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Pelvis; Tomography, X-Ray Computed; Computerized tomography; Image enhancement; Image segmentation; Iterative methods; Learning algorithms; Machine learning; Radiotherapy; Risk perception; Atlas-based; Atlas-based methods; Convolution neural network; CT synthesis; Machine-learning; Magnetic resonance imaging-guided radiotherapy planning; Performance; Radiotherapy planning; Segmentation; Weighted voting; algorithm; Article; artificial neural network; bladder; clinical article; cohort analysis; comparative study; human; image segmentation; nuclear magnetic resonance imaging; pelvis; rectum; treatment planning; x-ray computed tomography; diagnostic imaging; image processing; machine learning; pelvis; procedures; Magnetic resonance imaging","John Wiley and Sons Ltd","00942405","","MPHYA","30216462","Article","Scopus","2-s2.0-85054705445"
"Wen M.; Cong P.; Zhang Z.; Lu H.; Li T.","Wen, Ming (56113633700); Cong, Peisheng (7004919296); Zhang, Zhimin (56125415400); Lu, Hongmei (8389639500); Li, Tonghua (7406375224)","56113633700; 7004919296; 56125415400; 8389639500; 7406375224","DeepMirTar: A deep-learning approach for predicting human miRNA targets","2018","Bioinformatics","62","10.1093/bioinformatics/bty424","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056388335&doi=10.1093%2fbioinformatics%2fbty424&partnerID=40&md5=10167f10687048ebaea336369f2bb483","College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; School of Chemical Science and Engineering, Tongji University, Shanghai, 200092, China","Wen M., College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; Cong P., School of Chemical Science and Engineering, Tongji University, Shanghai, 200092, China; Zhang Z., College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; Lu H., College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; Li T., School of Chemical Science and Engineering, Tongji University, Shanghai, 200092, China","Motivation MicroRNAs (miRNAs) are small non-coding RNAs that function in RNA silencing and post-transcriptional regulation of gene expression by targeting messenger RNAs (mRNAs). Because the underlying mechanisms associated with miRNA binding to mRNA are not fully understood, a major challenge of miRNA studies involves the identification of miRNA-target sites on mRNA. In silico prediction of miRNA-target sites can expedite costly and time-consuming experimental work by providing the most promising miRNA-target-site candidates. Results In this study, we reported the design and implementation of DeepMirTar, a deep-learning-based approach for accurately predicting human miRNA targets at the site level. The predicted miRNA-target sites are those having canonical or non-canonical seed, and features, including high-level expert-designed, low-level expert-designed and raw-data-level, were used to represent the miRNA-target site. Comparison with other state-of-the-art machine-learning methods and existing miRNA-target-prediction tools indicated that DeepMirTar improved overall predictive performance. Availability and implementation DeepMirTar is freely available at https://github.com/Bjoux2/DeepMirTar-SdA. Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author(s) 2018. Published by Oxford University Press. All rights reserved.","","Algorithms; Computational Biology; Gene Expression Regulation; Humans; Machine Learning; MicroRNAs; RNA Interference; RNA, Messenger; messenger RNA; microRNA; algorithm; biology; gene expression regulation; human; machine learning; RNA interference","Oxford University Press","13674803","","BOINF","29868708","Article","Scopus","2-s2.0-85056388335"
"Li J.; Speier W.; Ho K.C.; Sarma K.V.; Gertych A.; Knudsen B.S.; Arnold C.W.","Li, Jiayun (57202745945); Speier, William (36870001000); Ho, King Chung (57194193885); Sarma, Karthik V. (56480098200); Gertych, Arkadiusz (7801318586); Knudsen, Beatrice S. (7004937729); Arnold, Corey W. (18436092400)","57202745945; 36870001000; 57194193885; 56480098200; 7801318586; 7004937729; 18436092400","An EM-based semi-supervised deep learning approach for semantic segmentation of histopathological images from radical prostatectomies","2018","Computerized Medical Imaging and Graphics","44","10.1016/j.compmedimag.2018.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053452681&doi=10.1016%2fj.compmedimag.2018.08.003&partnerID=40&md5=28597f2c918ccb1916151c46ce40b6f7","Department of Bioengineering, University of California, Los Angeles, CA, United States; Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States; Department of Surgery, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Department of Pathology and Laboratory Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Department of Biomedical Sciences, Cedars-Sinai Medical Center, Los Angeles, CA, United States","Li J., Department of Bioengineering, University of California, Los Angeles, CA, United States, Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States; Speier W., Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States; Ho K.C., Department of Bioengineering, University of California, Los Angeles, CA, United States, Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States; Sarma K.V., Department of Bioengineering, University of California, Los Angeles, CA, United States, Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States; Gertych A., Department of Surgery, Cedars-Sinai Medical Center, Los Angeles, CA, United States, Department of Pathology and Laboratory Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Knudsen B.S., Department of Pathology and Laboratory Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States, Department of Biomedical Sciences, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Arnold C.W., Department of Bioengineering, University of California, Los Angeles, CA, United States, Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States","Automated Gleason grading is an important preliminary step for quantitative histopathological feature extraction. Different from the traditional task of classifying small pre-selected homogeneous regions, semantic segmentation provides pixel-wise Gleason predictions across an entire slide. Deep learning-based segmentation models can automatically learn visual semantics from data, which alleviates the need for feature engineering. However, performance of deep learning models is limited by the scarcity of large-scale fully annotated datasets, which can be both expensive and time-consuming to create. One way to address this problem is to leverage external weakly labeled datasets to augment models trained on the limited data. In this paper, we developed an expectation maximization-based approach constrained by an approximated prior distribution in order to extract useful representations from a large number of weakly labeled images generated from low-magnification annotations. This method was utilized to improve the performance of a model trained on a limited fully annotated dataset. Our semi-supervised approach trained with 135 fully annotated and 1800 weakly annotated tiles achieved a mean Jaccard Index of 49.5% on an independent test set, which was 14% higher than the initial model trained only on the fully annotated dataset. © 2018 Elsevier Ltd","Expectation maximization; Histopathological image segmentation; Prostate cancer; Semi-supervised deep learning","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Male; Prostate; Prostatectomy; Prostatic Neoplasms; Supervised Machine Learning; Diseases; Grading; Image segmentation; Maximum principle; Semantics; Statistical tests; Automated Gleason grading; Expectation - maximizations; Histopathological images; Learning-based segmentation; Prostate cancers; Radical prostatectomy; Semantic segmentation; Semi-supervised; Article; classifier; Gleason score; histopathology; human; image analysis; image processing; image segmentation; learning; priority journal; prostate cancer; prostatectomy; supervised machine learning; algorithm; diagnostic imaging; male; pathology; procedures; prostate; prostate tumor; Deep learning","Elsevier Ltd","08956111","","CMIGE","30243216","Article","Scopus","2-s2.0-85053452681"
"Xiao Y.; Wu J.; Lin Z.; Zhao X.","Xiao, Yawen (57195772156); Wu, Jun (56377181800); Lin, Zongli (7404229141); Zhao, Xiaodong (55472192700)","57195772156; 56377181800; 7404229141; 55472192700","A semi-supervised deep learning method based on stacked sparse auto-encoder for cancer prediction using RNA-seq data","2018","Computer Methods and Programs in Biomedicine","71","10.1016/j.cmpb.2018.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054745104&doi=10.1016%2fj.cmpb.2018.10.004&partnerID=40&md5=85c972f31b9622b95de320bb16a99bd9","Department of Automation, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing of Ministry of Education, Shanghai, 200240, China; The Center for Bioinformatics and Computational Biology, Shanghai Key Laboratory of Regulatory Biology, the Institute of Biomedical Sciences and School of Life Sciences, East China Normal University, Shanghai, 200241, China; Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, P.O. Box 400743, Charlottesville, 22904-4743, VA, United States; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China","Xiao Y., Department of Automation, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing of Ministry of Education, Shanghai, 200240, China; Wu J., The Center for Bioinformatics and Computational Biology, Shanghai Key Laboratory of Regulatory Biology, the Institute of Biomedical Sciences and School of Life Sciences, East China Normal University, Shanghai, 200241, China; Lin Z., Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, P.O. Box 400743, Charlottesville, 22904-4743, VA, United States; Zhao X., School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China","Background and objective: Cancer has become a complex health problem due to its high mortality. Over the past few decades, with the rapid development of the high-throughput sequencing technology and the application of various machine learning methods, remarkable progress in cancer research has been made based on gene expression data. At the same time, a growing amount of high-dimensional data has been generated, such as RNA-seq data, which calls for superior machine learning methods able to deal with mass data effectively in order to make accurate treatment decision. Methods: In this paper, we present a semi-supervised deep learning strategy, the stacked sparse auto-encoder (SSAE) based classification, for cancer prediction using RNA-seq data. The proposed SSAE based method employs the greedy layer-wise pre-training and a sparsity penalty term to help capture and extract important information from the high-dimensional data and then classify the samples. Results: We tested the proposed SSAE model on three public RNA-seq data sets of three types of cancers and compared the prediction performance with several commonly-used classification methods. The results indicate that our approach outperforms the other methods for all the three cancer data sets in various metrics. Conclusions: The proposed SSAE based semi-supervised deep learning model shows its promising ability to process high-dimensional gene expression data and is proved to be effective and accurate for cancer prediction. © 2018 Elsevier B.V.","Cancer prediction; Deep learning; Gene expression data; Semi-supervised learning; Stacked sparse auto-encoder","Algorithms; Breast Neoplasms; Deep Learning; Diagnosis, Computer-Assisted; False Positive Reactions; Female; Gene Expression Regulation, Neoplastic; Humans; Lung Neoplasms; Male; Pattern Recognition, Automated; Reproducibility of Results; RNA; Sequence Analysis, RNA; Software; Stomach Neoplasms; Supervised Machine Learning; Artificial intelligence; Clustering algorithms; Data mining; Deep learning; Diseases; Forecasting; Gene expression; Learning algorithms; RNA; Signal encoding; Supervised learning; RNA; Auto encoders; Cancer prediction; Classification methods; Gene Expression Data; High-throughput sequencing; Machine learning methods; Prediction performance; Semi- supervised learning; article; cancer model; case report; clinical article; gene expression; human; learning; prediction; punishment; algorithm; automated pattern recognition; breast tumor; computer assisted diagnosis; false positive result; female; gene expression regulation; genetics; lung tumor; male; procedures; reproducibility; sequence analysis; software; stomach tumor; supervised machine learning; Classification (of information)","Elsevier Ireland Ltd","01692607","","CMPBE","30415723","Article","Scopus","2-s2.0-85054745104"
"Saha S.K.; Fernando B.; Cuadros J.; Xiao D.; Kanagasingam Y.","Saha, Sajib Kumar (57189333447); Fernando, Basura (36975184500); Cuadros, Jorge (8425006900); Xiao, Di (55223331900); Kanagasingam, Yogesan (6506620581)","57189333447; 36975184500; 8425006900; 55223331900; 6506620581","Automated Quality Assessment of Colour Fundus Images for Diabetic Retinopathy Screening in Telemedicine","2018","Journal of Digital Imaging","65","10.1007/s10278-018-0084-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046024185&doi=10.1007%2fs10278-018-0084-9&partnerID=40&md5=c4e32fc370f40b36b0cf8b0fc6896ea6","Australian e-Health Research Centre, CSIRO, Perth, 6014, WA, Australia; ACRV, The Australian National University, Canberra, 0200, ACT, Australia; University of California, Berkeley, CA, United States","Saha S.K., Australian e-Health Research Centre, CSIRO, Perth, 6014, WA, Australia; Fernando B., ACRV, The Australian National University, Canberra, 0200, ACT, Australia; Cuadros J., University of California, Berkeley, CA, United States; Xiao D., Australian e-Health Research Centre, CSIRO, Perth, 6014, WA, Australia; Kanagasingam Y., Australian e-Health Research Centre, CSIRO, Perth, 6014, WA, Australia","Fundus images obtained in a telemedicine program are acquired at different sites that are captured by people who have varying levels of experience. These result in a relatively high percentage of images which are later marked as unreadable by graders. Unreadable images require a recapture which is time and cost intensive. An automated method that determines the image quality during acquisition is an effective alternative. To determine the image quality during acquisition, we describe here an automated method for the assessment of image quality in the context of diabetic retinopathy. The method explicitly applies machine learning techniques to access the image and to determine ‘accept’ and ‘reject’ categories. ‘Reject’ category image requires a recapture. A deep convolution neural network is trained to grade the images automatically. A large representative set of 7000 colour fundus images was used for the experiment which was obtained from the EyePACS that were made available by the California Healthcare Foundation. Three retinal image analysis experts were employed to categorise these images into ‘accept’ and ‘reject’ classes based on the precise definition of image quality in the context of DR. The network was trained using 3428 images. The method shows an accuracy of 100% to successfully categorise ‘accept’ and ‘reject’ images, which is about 2% higher than the traditional machine learning method. On a clinical trial, the proposed method shows 97% agreement with human grader. The method can be easily incorporated with the fundus image capturing system in the acquisition centre and can guide the photographer whether a recapture is necessary or not. © 2018, Society for Imaging Informatics in Medicine.","Automated quality assessment; Colour fundus image; Deep learning; Diabetic retinopathy; Telemedicine","Algorithms; Diabetic Retinopathy; Fundus Oculi; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Retina; Telemedicine; Artificial intelligence; Automation; Color; Deep learning; Eye protection; Image acquisition; Telemedicine; Convolution neural network; Diabetic retinopathy; Diabetic retinopathy screening; Fundus image; Machine learning methods; Machine learning techniques; Quality assessment; Retinal image analysis; algorithm; artificial neural network; diabetic retinopathy; diagnostic imaging; eye fundus; human; image processing; machine learning; procedures; retina; telemedicine; Image quality","Springer New York LLC","08971889","","JDIME","29704086","Article","Scopus","2-s2.0-85046024185"
"Giuffrida M.V.; Doerner P.; Tsaftaris S.A.","Giuffrida, Mario Valerio (56605978200); Doerner, Peter (7004244419); Tsaftaris, Sotirios A. (6505952824)","56605978200; 7004244419; 6505952824","Pheno-Deep Counter: a unified and versatile deep learning architecture for leaf counting","2018","Plant Journal","66","10.1111/tpj.14064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053412091&doi=10.1111%2ftpj.14064&partnerID=40&md5=f7ce5c6d50888f33a21abd524560eb3d","Institute for Digital Communications, School of Engineering, University of Edinburgh, Thomas Bayes Road, Edinburgh, EH9 3FG, United Kingdom; IMT School for Advanced Studies, Piazza S. Francesco 19, Lucca, 55100, Italy; School of Biological Sciences, University of Edinburgh, Mayfield Road, Edinburgh, EH9 3JR, United Kingdom; The Alan Turing Institute, 96 Euston Road, London, NW1 2DB, United Kingdom","Giuffrida M.V., Institute for Digital Communications, School of Engineering, University of Edinburgh, Thomas Bayes Road, Edinburgh, EH9 3FG, United Kingdom, IMT School for Advanced Studies, Piazza S. Francesco 19, Lucca, 55100, Italy; Doerner P., School of Biological Sciences, University of Edinburgh, Mayfield Road, Edinburgh, EH9 3JR, United Kingdom; Tsaftaris S.A., Institute for Digital Communications, School of Engineering, University of Edinburgh, Thomas Bayes Road, Edinburgh, EH9 3FG, United Kingdom, The Alan Turing Institute, 96 Euston Road, London, NW1 2DB, United Kingdom","Direct observation of morphological plant traits is tedious and a bottleneck for high-throughput phenotyping. Hence, interest in image-based analysis is increasing, with the requirement for software that can reliably extract plant traits, such as leaf count, preferably across a variety of species and growth conditions. However, current leaf counting methods do not work across species or conditions and therefore may lack broad utility. In this paper, we present Pheno-Deep Counter, a single deep network that can predict leaf count in two-dimensional (2D) plant images of different species with a rosette-shaped appearance. We demonstrate that our architecture can count leaves from multi-modal 2D images, such as visible light, fluorescence and near-infrared. Our network design is flexible, allowing for inputs to be added or removed to accommodate new modalities. Furthermore, our architecture can be used as is without requiring dataset-specific customization of the internal structure of the network, opening its use to new scenarios. Pheno-Deep Counter is able to produce accurate predictions in many plant species and, once trained, can count leaves in a few seconds. Through our universal and open source approach to deep counting we aim to broaden utilization of machine learning-based approaches to leaf counting. Our implementation can be downloaded at https://bitbucket.org/tuttoweb/pheno-deep-counter. © 2018 The Authors The Plant Journal published by John Wiley & Sons Ltd and Society for Experimental Biology.","deep learning; image-based plant phenotyping; leaf counting; machine learning; multimodal; night images","Artificial Intelligence; Computer Programs; Counting; Fluorescence; Images; Interest; Leaves; Plants; Deep Learning; Image Processing, Computer-Assisted; Machine Learning; Phenotype; Plant Leaves; Plants; Software; Artificial intelligence; Infrared devices; Learning systems; Network architecture; Open source software; Plants (botany); High-throughput phenotyping; Image-based analysis; leaf counting; Learning architectures; Multi-modal; night images; Plant phenotyping; Two Dimensional (2 D); anatomy and histology; image processing; machine learning; phenotype; plant; plant leaf; procedures; software; Deep learning","Blackwell Publishing Ltd","09607412","","PLJUE","30101442","Article","Scopus","2-s2.0-85053412091"
"Moorman J.R.","Moorman, J. Randall (7005818721)","7005818721","A crossroads in predictive analytics monitoring for clinical medicine","2018","Journal of Electrocardiology","2","10.1016/j.jelectrocard.2018.07.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052916335&doi=10.1016%2fj.jelectrocard.2018.07.023&partnerID=40&md5=1620cf4d86bc1cd980403a06dc180021","University of Virginia School of Medicine, Department of Medicine, Division of Cardiovascular Medicine, 1215 Lee Street, Box 800158, Charlottesville, 22908, VA, United States","Moorman J.R., University of Virginia School of Medicine, Department of Medicine, Division of Cardiovascular Medicine, 1215 Lee Street, Box 800158, Charlottesville, 22908, VA, United States","A new goal for medical informatics is to develop robust tools that integrate clinical data on a patient in order to estimate the risk of imminent adverse events. This new field of predictive analytics monitoring is growing very quickly. Its claims, however, can be vulnerable when clinicians fail to use the best mathematical and statistical tools, when quantitative scientists fail to grasp the nuances of clinical medicine, and when either fails to incorporate knowledge of physiology. Its potential, though is clear: we can provide more effective clinical decision support and make better predictive analytics monitoring tools if we apply principles learned from physiology and mathematics to the right problems in clinical medicine. © 2018 Elsevier Inc.","","Decision Support Systems, Clinical; Deep Learning; Electronic Health Records; Humans; Medical Informatics; Models, Statistical; Predictive Value of Tests; Risk Assessment; Article; attention based time aware neural network; data extraction; early diagnosis; electronic health record; human; machine learning; mathematical analysis; medical informatics; newborn sepsis; patient information; personalized medicine; prediction; predictive analytics monitoring; prematurity; priority journal; recurrent neural network; clinical decision support system; electronic health record; medical informatics; predictive value; risk assessment; statistical model","Churchill Livingstone Inc.","00220736","","JECAB","30195845","Article","Scopus","2-s2.0-85052916335"
"Themistocleous C.; Eckerström M.; Kokkinakis D.","Themistocleous, Charalambos (57191582543); Eckerström, Marie (55596250800); Kokkinakis, Dimitrios (24331949100)","57191582543; 55596250800; 24331949100","Identification of Mild Cognitive Impairment From Speech in Swedish Using Deep Sequential Neural Networks","2018","Frontiers in Neurology","35","10.3389/fneur.2018.00975","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078279354&doi=10.3389%2ffneur.2018.00975&partnerID=40&md5=4e70dc71cfe974ba2f6b83d759cc36a0","The Swedish Language Bank, Department of Swedish, University of Gothenburg, Gothenburg, Sweden; Department of Neurology, Johns Hopkins University, School of Medicine, Baltimore, MD, United States; Department of Psychiatry and Neurochemistry, Institute of Neuroscience and Physiology, University of Gothenburg, Gothenburg, Sweden","Themistocleous C., The Swedish Language Bank, Department of Swedish, University of Gothenburg, Gothenburg, Sweden, Department of Neurology, Johns Hopkins University, School of Medicine, Baltimore, MD, United States; Eckerström M., Department of Psychiatry and Neurochemistry, Institute of Neuroscience and Physiology, University of Gothenburg, Gothenburg, Sweden; Kokkinakis D., The Swedish Language Bank, Department of Swedish, University of Gothenburg, Gothenburg, Sweden","While people with mild cognitive impairment (MCI) portray noticeably incipient memory difficulty in remembering events and situations along with problems in decision making, planning, and finding their way in familiar environments, detailed neuropsychological assessments also indicate deficits in language performance. To this day, there is no cure for dementia but early-stage treatment can delay the progression of MCI; thus, the development of valid tools for identifying early cognitive changes is of great importance. In this study, we provide an automated machine learning method, using Deep Neural Network Architectures, that aims to identify MCI. Speech materials were obtained using a reading task during evaluation sessions, as part of the Gothenburg MCI research study. Measures of vowel duration, vowel formants (F1 to F5), and fundamental frequency were calculated from speech signals. To learn the acoustic characteristics associated with MCI vs. healthy controls, we have trained and evaluated ten Deep Neural Network Architectures and measured how accurately they can diagnose participants that are unknown to the model. We evaluated the models using two evaluation tasks: a 5-fold crossvalidation and by splitting the data into 90% training and 10% evaluation set. The findings suggest first, that the acoustic features provide significant information for the identification of MCI; second, the best Deep Neural Network Architectures can classify MCI and healthy controls with high classification accuracy (M = 83%); and third, the model has the potential to offer higher accuracy than 84% if trained with more data (cf., SD≈15%). The Deep Neural Network Architecture proposed here constitutes a method that contributes to the early diagnosis of cognitive decline, quantify the progression of the condition, and enable suitable therapeutics. © Copyright © 2018 Themistocleous, Eckerström and Kokkinakis.","dementia; machine learning; MCI; neural network; prosody; speech production; vowels","","Frontiers Media S.A.","16642295","","","","Article","Scopus","2-s2.0-85078279354"
"Alam M.; Vidyaratne L.; Iftekharuddin K.M.","Alam, M. (57206168686); Vidyaratne, L. (56401821600); Iftekharuddin, K.M. (7005905201)","57206168686; 56401821600; 7005905201","Novel deep generative simultaneous recurrent model for efficient representation learning","2018","Neural Networks","6","10.1016/j.neunet.2018.04.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051775204&doi=10.1016%2fj.neunet.2018.04.020&partnerID=40&md5=f501c10f7488ce4f05214600af1ea84f","The Vision Lab in Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, 23529, VA, United States","Alam M., The Vision Lab in Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, 23529, VA, United States; Vidyaratne L., The Vision Lab in Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, 23529, VA, United States; Iftekharuddin K.M., The Vision Lab in Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, 23529, VA, United States","Representation learning plays an important role for building effective deep neural network models. Deep generative probabilistic models have shown to be efficient in the data representation learning task which is usually carried out in an unsupervised fashion. Throughout the past decade, there has been almost exclusive focus on the learning algorithms to improve representation capability of the generative models. However, effective data representation requires improvement in both learning algorithm and architecture of the generative models. Therefore, improvement to the neural architecture is critical for improved data representation capability of deep generative models. Furthermore, the prevailing class of deep generative models such as deep belief network (DBN), deep Boltzman machine (DBM) and deep sigmoid belief network (DSBN) are inherently unidirectional and lack recurrent connections ubiquitous in the biological neuronal structures. Introduction of recurrent connections may offer further improvement in data representation learning performance to the deep generative models. Consequently, for the first time in literature, this work proposes a deep recurrent generative model known as deep simultaneous recurrent belief network (D-SRBN) to efficiently learn representations from unlabeled data. Experimentation on four benchmark datasets: MNIST, Caltech 101 Silhouettes, OCR letters and Omniglot show that the proposed D-SRBN model achieves superior representation learning performance while utilizing less computing resources when compared to the four state-of-the-art generative models such as deep belief network (DBN), DBM, DSBN and VAE (variational auto-encoder). © 2018 Elsevier Ltd","Deep generative models; Directed graphical models; Representational learning; Simultaneous recurrent network (SRN); Variational inference","Algorithms; Cognition; Models, Statistical; Neural Networks (Computer); Neurons; Benchmarking; Deep neural networks; Network architecture; Generative model; GraphicaL model; Recurrent networks; Representational learning; Variational inference; Article; controlled study; deep belief network; deep Boltzman machine; deep sigmoid belief network; deep simultaneous recurrent belief network; information processing; intermethod comparison; machine learning; priority journal; variational autoencoder; algorithm; artificial neural network; cognition; nerve cell; statistical model; Learning algorithms","Elsevier Ltd","08936080","","NNETE","30143328","Article","Scopus","2-s2.0-85051775204"
"Chen L.; Xu G.; Wang Y.; Wang J.","Chen, Longting (57037203400); Xu, Guanghua (55632209100); Wang, Yi (57211420044); Wang, Jianhua (56044346100)","57037203400; 55632209100; 57211420044; 56044346100","Detection of weak transient signals based on unsupervised learning for bearing fault diagnosis","2018","Neurocomputing","19","10.1016/j.neucom.2018.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050276905&doi=10.1016%2fj.neucom.2018.07.004&partnerID=40&md5=ea513b88f103c678d1bfdb8edd8a3f86","School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, 710049, China","Chen L., School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Xu G., School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, 710049, China, State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Wang Y., School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Wang J., School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, 710049, China","Transient impulse contains abundant information of bearings status. When fault occurs, it is activated and would recur periodically or quasi-periodically. Its period can indicate where defects lie in. However, transient impulse is easily swallowed by background noise or interferences in part or in whole, especially at early stage of fault. This problem brings hard obstacles into faults detection. Considering that transient impulses are periodical or quasi-periodical and vibration signal has local similarity, the single transient impulse can be seen as one of shift-invariant features. In view of this, this paper derives adaptive and non-linear signal decomposition formulas and further proposes adaptive and unsupervised feature learning method by using convolutional restricted Boltzmann machine model. With respecting local waveform structures, this method can automatically capture shift-invariant patterns hidden in original signal and decompose the original signal into several sub-components at the cost of minimizing reconstruction error. Among these sub-components, the fault-related information, i.e., transient impulses signal, could be extracted likely. It provides a promising idea for intelligent signal processing by using unsupervised learning. Afterwards, Maximizing kurtosis is applied to select optimally latent fault component. Two real bearing experiments validate this method is effective and reliable in extraction of weak transient impulses. © 2018 Elsevier Ltd","Bearing fault detection; Convolutional restricted Boltzmann machine; Shift-invariant feature learning; Signal decomposition; Unsupervised deep learning","Convolution; Deep learning; Electric fault currents; Signal distortion; Signal processing; Unsupervised learning; Bearing fault detection; Bearing fault diagnosis; Intelligent signal processing; Reconstruction error; Restricted boltzmann machine; Shift invariant; Signal decomposition; Unsupervised feature learning; article; decomposition; diagnosis; extraction; learning; machine; noise; signal processing; vibration; waveform; Fault detection","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85050276905"
"Pelka O.; Nensa F.; Friedrich C.M.","Pelka, Obioma (57190736323); Nensa, Felix (55611423600); Friedrich, Christoph M. (35232936500)","57190736323; 55611423600; 35232936500","Annotation of enhanced radiographs for medical image retrieval with deep convolutional neural networks","2018","PLoS ONE","24","10.1371/journal.pone.0206229","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056307328&doi=10.1371%2fjournal.pone.0206229&partnerID=40&md5=6362fc320ff1fb74e15ce4f8b18e064f","Department of Computer Science, University of Applied Sciences and Arts Dortmund (FHDO), Dortmund, NRW, Germany; Faculty of Medicine, University of Duisburg-Essen, Essen, NRW, Germany; Department of Diagnostic and Interventional Radiology and Neuroradiology, University Hospital Essen, Essen, NRW, Germany; Institute for Medical Informatics, Biometry and Epidemiology (IMIBE), University Hospital Essen, Essen, NRW, Germany","Pelka O., Department of Computer Science, University of Applied Sciences and Arts Dortmund (FHDO), Dortmund, NRW, Germany, Faculty of Medicine, University of Duisburg-Essen, Essen, NRW, Germany; Nensa F., Department of Diagnostic and Interventional Radiology and Neuroradiology, University Hospital Essen, Essen, NRW, Germany; Friedrich C.M., Department of Computer Science, University of Applied Sciences and Arts Dortmund (FHDO), Dortmund, NRW, Germany, Institute for Medical Informatics, Biometry and Epidemiology (IMIBE), University Hospital Essen, Essen, NRW, Germany","The number of images taken per patient scan has rapidly increased due to advances in software, hardware and digital imaging in the medical domain. There is the need for medical image annotation systems that are accurate as manual annotation is impractical, time-consuming and prone to errors. This paper presents modeling approaches performed to automatically classify and annotate radiographs using several classification schemes, which can be further applied for automatic content-based image retrieval (CBIR) and computer-aided diagnosis (CAD). Different image preprocessing and enhancement techniques were applied to augment grayscale radiographs by virtually adding two extra layers. The Image Retrieval in Medical Applications (IRMA) Code, a mono-hierarchical multi-axial code, served as a basis for this work. To extensively evaluate the image enhancement techniques, five classification schemes including the complete IRMA code were adopted. The deep convolutional neural network systems Inception-v3 and Inception-ResNet-v2, and Random Forest models with 1000 trees were trained using extracted Bag-of-Keypoints visual representations. The classification model performances were evaluated using the ImageCLEF 2009 Medical Annotation Task test set. The applied visual enhancement techniques proved to achieve better annotation accuracy in all classification schemes. © 2018 Pelka et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Radiography; Article; artificial neural network; classification; classifier; controlled study; deep convolutional neural network; human; image enhancement; image processing; image retrieval; image retrieval in medical applications code; inception resnet v2; inception v3; prediction; radiography; random forest; algorithm; computer assisted diagnosis; machine learning; procedures; radiography; statistics and numerical data","Public Library of Science","19326203","","POLNC","30419028","Article","Scopus","2-s2.0-85056307328"
"Xu C.; Xu L.; Gao Z.; Zhao S.; Zhang H.; Zhang Y.; Du X.; Zhao S.; Ghista D.; Liu H.; Li S.","Xu, Chenchu (57195625791); Xu, Lei (35270676000); Gao, Zhifan (55320405200); Zhao, Shen (55208477900); Zhang, Heye (58447662800); Zhang, Yanping (35303881100); Du, Xiuquan (26321470100); Zhao, Shu (34969832100); Ghista, Dhanjoo (7007177778); Liu, Huafeng (7409750199); Li, Shuo (57189925356)","57195625791; 35270676000; 55320405200; 55208477900; 58447662800; 35303881100; 26321470100; 34969832100; 7007177778; 7409750199; 57189925356","Direct delineation of myocardial infarction without contrast agents using a joint motion feature learning architecture","2018","Medical Image Analysis","99","10.1016/j.media.2018.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053287118&doi=10.1016%2fj.media.2018.09.001&partnerID=40&md5=7fe6ae2b741e20591c9dfae141f52bb9","Western University, London, ON, Canada; School of Computer Science and Technology, Anhui University, Hefei, China; Department of Medical Imaging, Beijing Anzhen Hospital, Capital Medical University, Beijing, China; School of Biomedical Engineering, Sun Yat-Sen University, Shenzhen, China; University 2020 Foundation, MA, United States; Department of Optical Engineering, Zhejiang University, Hangzhou, China","Xu C., Western University, London, ON, Canada, School of Computer Science and Technology, Anhui University, Hefei, China; Xu L., Department of Medical Imaging, Beijing Anzhen Hospital, Capital Medical University, Beijing, China; Gao Z., Western University, London, ON, Canada; Zhao S., Western University, London, ON, Canada; Zhang H., School of Biomedical Engineering, Sun Yat-Sen University, Shenzhen, China; Zhang Y., School of Computer Science and Technology, Anhui University, Hefei, China; Du X., School of Computer Science and Technology, Anhui University, Hefei, China; Zhao S., School of Computer Science and Technology, Anhui University, Hefei, China; Ghista D., University 2020 Foundation, MA, United States; Liu H., Department of Optical Engineering, Zhejiang University, Hangzhou, China; Li S., Western University, London, ON, Canada","Changes in mechanical properties of myocardium caused by a infarction can lead to kinematic abnormalities. This phenomenon has inspired us to develop this work for delineation of myocardial infarction area directly from non-contrast agents cardiac MR imaging sequences. The main contribution of this work is to develop a new joint motion feature learning architecture to efficiently establish direct correspondences between motion features and tissue properties. This architecture consists of three seamless connected function layers: the heart localization layers can automatically crop the region of interest (ROI) sequences involving the left ventricle from the cardiac MR imaging sequences; the motion feature extraction layers, using long short-term memory-recurrent neural networks, a) builds patch-based motion features through local intensity changes between fixed-size patch sequences (cropped from image sequences), and b) uses optical flow techniques to build image-based features through global intensity changes between adjacent images to describe the motion of each pixel; the fully connected discriminative layers can combine two types of motion features together in each pixel and then build the correspondences between motion features and tissue identities (that is, infarct or not) in each pixel. We validated the performance of our framework in 165 cine cardiac MR imaging datasets by comparing to the ground truths manually segmented from delayed Gadolinium-enhanced MR cardiac images by two radiologists with more than 10 years of experience. Our experimental results show that our proposed method has a high and stable accuracy (pixel-level: 95.03%) and consistency (Kappa statistic: 0.91; Dice: 89.87%; RMSE: 0.72 mm; Hausdorff distance: 5.91 mm) compared to manual delineation results. Overall, the advantage of our framework is that it can determine the tissue identity in each pixel from its motion pattern captured by normal cine cardiac MR images, which makes it an attractive tool for the clinical diagnosis of infarction. © 2018 Elsevier B.V.","Deep learning; Motion feature; Myocardial infarction; Optical flow","Heart Ventricles; Humans; Magnetic Resonance Imaging; Motion; Myocardial Infarction; Biomechanics; Cardiology; Deep learning; Diagnosis; Heart; Image segmentation; Magnetic resonance imaging; Network architecture; Optical flows; Pixels; Recurrent neural networks; Tissue; gadolinium pentetate meglumine; Clinical diagnosis; Hausdorff distance; Image-based features; Motion feature extraction; Motion features; Myocardial Infarction; Optical flow techniques; The region of interest (ROI); algorithm; Article; clinical feature; controlled study; disease classification; false positive result; feature extraction; heart infarction; heart left ventricle; human; image analysis; image enhancement; kappa statistics; learning; major clinical study; nuclear magnetic resonance imaging; optic flow; priority journal; retrospective study; short term memory; ST segment elevation myocardial infarction; support vector machine; velocity; heart infarction; heart ventricle; motion; pathophysiology; procedures; Image enhancement","Elsevier B.V.","13618415","","MIAEC","30227385","Article","Scopus","2-s2.0-85053287118"
"Cobb A.N.; Eguia E.; Janjua H.; Kuo P.C.","Cobb, Adrienne N. (56669451500); Eguia, Emanuel (57201216450); Janjua, Haroon (57202914708); Kuo, Paul C. (7201622499)","56669451500; 57201216450; 57202914708; 7201622499","Put me in the game coach! Resident participation in high-risk surgery in the era of big data","2018","Journal of Surgical Research","12","10.1016/j.jss.2018.06.041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049775031&doi=10.1016%2fj.jss.2018.06.041&partnerID=40&md5=0ce1bb2443ff6c2615d9d1655e92ba12","Department of Surgery, Loyola University Medical Center, Maywood, Illinois, United States; Department of Surgery, One:MAP Section of Surgical Analytics, Loyola University Chicago, Maywood, Illinois, United States; Department of Surgery, University of South Florida, Tampa, Florida, United States","Cobb A.N., Department of Surgery, Loyola University Medical Center, Maywood, Illinois, United States, Department of Surgery, One:MAP Section of Surgical Analytics, Loyola University Chicago, Maywood, Illinois, United States; Eguia E., Department of Surgery, Loyola University Medical Center, Maywood, Illinois, United States, Department of Surgery, One:MAP Section of Surgical Analytics, Loyola University Chicago, Maywood, Illinois, United States; Janjua H., Department of Surgery, Loyola University Medical Center, Maywood, Illinois, United States, Department of Surgery, One:MAP Section of Surgical Analytics, Loyola University Chicago, Maywood, Illinois, United States; Kuo P.C., Department of Surgery, One:MAP Section of Surgical Analytics, Loyola University Chicago, Maywood, Illinois, United States, Department of Surgery, University of South Florida, Tampa, Florida, United States","Background: With the emphasis on quality metrics guiding reimbursement, concerns have emerged regarding resident participation in patient care. This study aimed to evaluate whether resident participation in high-risk elective general surgery procedures is safe. Materials and methods: The American College of Surgeons National Surgical Quality Improvement Program database (2005-2012) was used to identify patients undergoing one of five high-risk general surgery procedures. Resident and nonresident groups were created using a 2:1 propensity score match. Postoperative outcomes were calculated using univariate statistics and multivariable logistic regression for the two groups. Predictors of mortality and morbidity were identified using machine learning in the form of decision trees. Results: Twenty-five thousand three hundred sixty three patients met our inclusion criteria. Following matching, each group contained 500 patients and was comparable for matched characteristics. Thirty-day mortality was similar between the groups (2.4% versus 2.6%; P = 0.839). Deep surgical site infection (0% versus 1.6%; P = 0.005), urinary tract infection (5% versus 2.5%; P = 0.029), and operative time (275.6 min versus 250 min; P = 0.0064) were significantly higher with resident participation. Resident participation was not predictive of mortality or complications, while age, American society of anesthesiologists class, and functional status were leading predictors of both. Conclusions: Despite growing time constraints and pressure to perform, surgical resident participation remains safe. Residents should be given active roles in the operating room, even in the most challenging cases. © 2018 Elsevier Inc.","Operative experience; Resident participation; Surgery residency; Surgical education","Aged; Clinical Competence; Databases, Factual; Female; Hospital Mortality; Humans; Internship and Residency; Male; Middle Aged; Operating Rooms; Operative Time; Postoperative Complications; Quality Improvement; Surgical Procedures, Operative; Survival Rate; Treatment Outcome; Work Engagement; abdominal aortic aneurysm; acute kidney failure; adult; age; anesthesiologist; aneurysm rupture; aneurysm surgery; Article; cerebrovascular accident; cohort analysis; decision tree; deep vein thrombosis; elective surgery; esophagus resection; female; functional status; general surgery; heart infarction; hernioplasty; hiatus hernia; hospital mortality; hospital readmission; human; length of stay; liver resection; lung embolism; machine learning; major clinical study; male; medical society; middle aged; morbidity; open surgery; operation duration; pancreaticoduodenectomy; patient safety; personal experience; pneumonia; postoperative hemorrhage; postoperative thrombosis; priority journal; propensity score; rectum abdominoperineal resection; residency education; sepsis; stomach fundoplication; surgical infection; surgical mortality; surgical risk; surgical training; total quality management; urinary tract infection; wound dehiscence; aged; clinical competence; education; factual database; medical education; operating room; postoperative complication; statistics and numerical data; surgery; survival rate; treatment outcome; work engagement","Academic Press Inc.","00224804","","JSGRA","30463734","Article","Scopus","2-s2.0-85049775031"
"Abraham B.; Nair M.S.","Abraham, Bejoy (57203010680); Nair, Madhu S. (24475038000)","57203010680; 24475038000","Computer-aided classification of prostate cancer grade groups from MRI images using texture features and stacked sparse autoencoder","2018","Computerized Medical Imaging and Graphics","63","10.1016/j.compmedimag.2018.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052954845&doi=10.1016%2fj.compmedimag.2018.08.006&partnerID=40&md5=19e07b4852e9228a8c2f8e8f76b07b88","Department of Computer Science, University of Kerala, Kariavattom, Thiruvananthapuram, 695581, Kerala, India; Department of Computer Science, Cochin University of Science and Technology, Kochi, 682022, Kerala, India","Abraham B., Department of Computer Science, University of Kerala, Kariavattom, Thiruvananthapuram, 695581, Kerala, India; Nair M.S., Department of Computer Science, Cochin University of Science and Technology, Kochi, 682022, Kerala, India","A novel method to determine the Grade Group (GG) in prostate cancer (PCa) using multi-parametric magnetic resonance imaging (mpMRI) biomarkers is investigated in this paper. In this method, high-level features are extracted from hand-crafted texture features using a deep network of stacked sparse autoencoders (SSAE) and classified them using a softmax classifier (SMC). Transaxial T2 Weighted (T2W), Apparent Diffusion Coefficient (ADC) and high B-Value Diffusion-Weighted (BVAL) images obtained from PROSTATEx-2 2017 challenge dataset are used in this technique. The method was evaluated on the challenge dataset composed of a training set of 112 lesions and a test set of 70 lesions. It achieved a quadratic-weighted Kappa score of 0.2772 on evaluation using test dataset of the challenge. It also reached a Positive Predictive Value (PPV) of 80% in predicting PCa with GG > 1. The method achieved first place in the challenge, winning over 43 methods submitted by 21 groups. A 3-fold cross-validation using training data of the challenge was further performed and the method achieved a quadratic-weighted kappa score of 0.2326 and Positive Predictive Value (PPV) of 80.26% in predicting PCa with GG > 1. Even though the training dataset is a highly imbalanced one, the method was able to achieve a fair kappa score. Being one of the pioneer methods which attempted to classify prostate cancer into 5 grade groups from MRI images, it could serve as a base method for further investigations and improvements. © 2018 Elsevier Ltd","Deep learning; Gleason grade; Multiparametric MRI; Prostate cancer; Stacked sparse autoencoder; Texture features","Algorithms; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Neoplasm Grading; Prostate; Prostatic Neoplasms; Calcium compounds; Deep learning; Image classification; Image enhancement; Magnetic resonance imaging; Statistical tests; Surface diffusion; Urology; Apparent diffusion coefficient; Auto encoders; Computer Aided Classification; High-level features; Positive predictive values; Prostate cancers; Softmax classifiers; Texture features; accuracy; Article; back propagation; cancer diagnosis; cancer grading; computer assisted radiography; controlled study; diagnostic accuracy; diagnostic test accuracy study; feature extraction; Gleason score; human; image processing; machine learning; male; nuclear magnetic resonance imaging; prediction; predictive value; priority journal; prostate cancer; sigmoid; stacked sparse autoencoder; algorithm; cancer grading; computer assisted diagnosis; diagnostic imaging; nuclear magnetic resonance imaging; pathology; procedures; prostate; prostate tumor; Diseases","Elsevier Ltd","08956111","","CMIGE","30205334","Article","Scopus","2-s2.0-85052954845"
"Mocanu D.C.; Mocanu E.; Stone P.; Nguyen P.H.; Gibescu M.; Liotta A.","Mocanu, Decebal Constantin (55904289600); Mocanu, Elena (23005384000); Stone, Peter (7203001213); Nguyen, Phuong H. (57193913951); Gibescu, Madeleine (22834212900); Liotta, Antonio (13408852200)","55904289600; 23005384000; 7203001213; 57193913951; 22834212900; 13408852200","Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science","2018","Nature Communications","324","10.1038/s41467-018-04316-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048843263&doi=10.1038%2fs41467-018-04316-3&partnerID=40&md5=37a2272c936f61ff1feedf17620642b8","Department of Mathematics and Computer Science, Eindhoven University of Technology, De Rondom 70, AP Eindhoven, 5612, Netherlands; Department of Electrical Engineering, Eindhoven University of Technology, De Rondom 70, AP Eindhoven, Netherlands; Department of Mechanical Engineering, Eindhoven University of Technology, De Rondom 70, AP Eindhoven, 5612, Netherlands; Department of Computer Science, University of Texas at Austin, 2317 Speedway, Austin, 78712-1757, TX, United States; Data Science Centre, University of Derby UK, Quaker Way, Derby, DE13HD, United Kingdom","Mocanu D.C., Department of Mathematics and Computer Science, Eindhoven University of Technology, De Rondom 70, AP Eindhoven, 5612, Netherlands, Department of Electrical Engineering, Eindhoven University of Technology, De Rondom 70, AP Eindhoven, Netherlands; Mocanu E., Department of Electrical Engineering, Eindhoven University of Technology, De Rondom 70, AP Eindhoven, Netherlands, Department of Mechanical Engineering, Eindhoven University of Technology, De Rondom 70, AP Eindhoven, 5612, Netherlands; Stone P., Department of Computer Science, University of Texas at Austin, 2317 Speedway, Austin, 78712-1757, TX, United States; Nguyen P.H., Department of Electrical Engineering, Eindhoven University of Technology, De Rondom 70, AP Eindhoven, Netherlands; Gibescu M., Department of Electrical Engineering, Eindhoven University of Technology, De Rondom 70, AP Eindhoven, Netherlands; Liotta A., Data Science Centre, University of Derby UK, Quaker Way, Derby, DE13HD, United Kingdom","Through the success of deep learning in various domains, artificial neural networks are currently among the most used artificial intelligence methods. Taking inspiration from the network properties of biological neural networks (e.g. sparsity, scale-freeness), we argue that (contrary to general practice) artificial neural networks, too, should not have fully-connected layers. Here we propose sparse evolutionary training of artificial neural networks, an algorithm which evolves an initial sparse topology (Erdos-Rényi random graph) of two consecutive layers of neurons into a scale-free topology, during learning. Our method replaces artificial neural networks fully-connected layers with sparse ones before training, reducing quadratically the number of parameters, with no decrease in accuracy. We demonstrate our claims on restricted Boltzmann machines, multi-layer perceptrons, and convolutional neural networks for unsupervised and supervised learning on 15 datasets. Our approach has the potential to enable artificial neural networks to scale up beyond what is currently possible. © 2018 The Author(s).","","accuracy assessment; artificial neural network; connectivity; machinery; parameterization; supervised learning; topology; training; article; artificial neural network; case report; clinical article; learning; machine; nerve cell; perceptron; scale up","Nature Publishing Group","20411723","","","29921910","Article","Scopus","2-s2.0-85048843263"
"Lucas C.; Kemmling A.; Bouteldja N.; Aulmann L.F.; Mamlouk A.M.; Heinrich M.P.","Lucas, Christian (55579267900); Kemmling, André (6602286904); Bouteldja, Nassim (57194390590); Aulmann, Linda F. (57204921791); Mamlouk, Amir Madany (6505964507); Heinrich, Mattias P. (52363917500)","55579267900; 6602286904; 57194390590; 57204921791; 6505964507; 52363917500","Learning to predict ischemic stroke growth on acute CT perfusion data by interpolating low -dimensional shape representations","2018","Frontiers in Neurology","28","10.3389/fneur.2018.00989","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057779241&doi=10.3389%2ffneur.2018.00989&partnerID=40&md5=a03f586d60eff58832dbc63885d7c930","Institute of Medical Informatics, University of Lübeck, Lübeck, Germany; Graduate School for Computing in Medicine and Life Sciences, University of Lübeck, Lübeck, Germany; Department of Clinical Radiology, University Hospital Münster, Münster, Germany; Institute of Neuroradiology, University Medical Center Schleswig-Holstein, Lübeck, Germany; Institute for Neuro- and Bioinformatics, University of Lübeck, Lübeck, Germany","Lucas C., Institute of Medical Informatics, University of Lübeck, Lübeck, Germany, Graduate School for Computing in Medicine and Life Sciences, University of Lübeck, Lübeck, Germany; Kemmling A., Department of Clinical Radiology, University Hospital Münster, Münster, Germany; Bouteldja N., Institute of Medical Informatics, University of Lübeck, Lübeck, Germany; Aulmann L.F., Institute of Neuroradiology, University Medical Center Schleswig-Holstein, Lübeck, Germany; Mamlouk A.M., Institute for Neuro- and Bioinformatics, University of Lübeck, Lübeck, Germany; Heinrich M.P., Institute of Medical Informatics, University of Lübeck, Lübeck, Germany","Cerebrovascular diseases, in particular ischemic stroke, are one of the leading global causes of death in developed countries. Perfusion CT and/or MRI are ideal imaging modalities for characterizing affected ischemic tissue in the hyper-acute phase. If infarct growth over time could be predicted accurately from functional acute imaging protocols together with advanced machine-learning based image analysis, the expected benefits of treatment options could be better weighted against potential risks. The quality of the outcome prediction by convolutional neural networks (CNNs) is so far limited, which indicates that even highly complex deep learning algorithms are not fully capable of directly learning physiological principles of tissue salvation through weak supervision due to a lack of data (e.g., follow-up segmentation). In this work, we address these current shortcomings by explicitly taking into account clinical expert knowledge in the form of segmentations of the core and its surrounding penumbra in acute CT perfusion images (CTP), that are trained to be represented in a low-dimensional non-linear shape space. Employing a multi-scale CNN (U-Net) together with a convolutional auto-encoder, we predict lesion tissue probabilities for new patients. The predictions are physiologically constrained to a shape embedding that encodes a continuous progression between the core and penumbra extents. The comparison to a simple interpolation in the original voxel space and an unconstrained CNN shows that the use of such a shape space can be advantageous to predict time-dependent growth of stroke lesions on acute perfusion data, yielding a Dice score overlap of 0.46 for predictions from expert segmentations of core and penumbra. Our interpolation method models monotone infarct growth robustly on a linear time scale to automatically predict clinically plausible tissue outcomes that may serve as a basis for more clinical measures such as the expected lesion volume increase and can support the decision making on treatment options and triage. © 2007 - 2018 Frontiers Media S.A. All Rights Reserved.","CT; Growth; Ischemic; Learning; Perfusion; Prediction; Shape; Stroke","adult; aged; Article; brain ischemia; computer assisted tomography; controlled study; convolutional neural network; female; follow up; human; image analysis; learning; learning algorithm; male; nerve cell network; prediction; scoring system","Frontiers Media S.A.","16642295","","","","Article","Scopus","2-s2.0-85057779241"
"Chu J.; Dong W.; He K.; Duan H.; Huang Z.","Chu, Jiebin (57204291627); Dong, Wei (55509650200); He, Kunlun (7202010630); Duan, Huilong (7102630467); Huang, Zhengxing (8593282000)","57204291627; 55509650200; 7202010630; 7102630467; 8593282000","Using neural attention networks to detect adverse medical events from electronic health records","2018","Journal of Biomedical Informatics","22","10.1016/j.jbi.2018.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055088515&doi=10.1016%2fj.jbi.2018.10.002&partnerID=40&md5=7bde7d79d0ac82f75143bec3466b3ca6","College of Biomedical Engineering and Instrument Science, Zhejiang University, China; Department of Cardiology, Chinese PLA General Hospital, China","Chu J., College of Biomedical Engineering and Instrument Science, Zhejiang University, China; Dong W., Department of Cardiology, Chinese PLA General Hospital, China; He K., Department of Cardiology, Chinese PLA General Hospital, China; Duan H., College of Biomedical Engineering and Instrument Science, Zhejiang University, China; Huang Z., College of Biomedical Engineering and Instrument Science, Zhejiang University, China","The detection of Adverse Medical Events (AMEs) plays an important role in disease management in ensuring efficient treatment delivery and quality improvement of health services. Recently, with the rapid development of hospital information systems, a large volume of Electronic Health Records (EHRs) have been produced, in which AMEs are regularly documented in a free-text manner. In this study, we are concerned with the problem of AME detection by utilizing a large volume of unstructured EHR data. To address this challenge, we propose a neural attention network-based model to incorporate the contextual information of words into AME detection. Specifically, we develop a context-aware attention mechanism to locate salient words with respect to the target AMEs in patient medical records. And then we combine the proposed context attention mechanism with the deep learning tactic to boost the performance of AME detection. We validate our proposed model on a real clinical dataset that consists of 8845 medical records of patients with cardiovascular diseases. The experimental results show that our proposed model advances state-of-the-art models and achieves competitive performance in terms of AME detection. © 2018 Elsevier Inc.","Adverse medical event; Cardiovascular disease; Deep learning; Electronic health record; Neural attention network","Algorithms; Area Under Curve; Cardiovascular Diseases; China; Databases, Factual; Deep Learning; Electronic Health Records; Hemorrhage; Hospital Information Systems; Hospitals; Humans; Medical Informatics; Myocardial Ischemia; Myocardial Revascularization; Neural Networks (Computer); Cardiology; Deep learning; Records management; Adverse medical event; Cardio-vascular disease; Competitive performance; Contextual information; Electronic health record; Electronic health record (EHRs); Hospital information systems; Network-based modeling; adverse event; Article; artificial neural network; bleeding; cardiovascular disease; electronic health record; health service; hospital information system; human; ischemia; logistic regression analysis; neural attention network; priority journal; revascularization; support vector machine; algorithm; area under the curve; cardiovascular disease; China; electronic health record; factual database; heart muscle ischemia; heart muscle revascularization; hospital; medical informatics; procedures; Diseases","Academic Press Inc.","15320464","","JBIOB","30336262","Article","Scopus","2-s2.0-85055088515"
"Li H.; Jiang G.; Zhang J.; Wang R.; Wang Z.; Zheng W.-S.; Menze B.","Li, Hongwei (57007362000); Jiang, Gongfa (57203758821); Zhang, Jianguo (57419074700); Wang, Ruixuan (14822745000); Wang, Zhaolei (57203760652); Zheng, Wei-Shi (25928152800); Menze, Bjoern (35299840300)","57007362000; 57203758821; 57419074700; 14822745000; 57203760652; 25928152800; 35299840300","Fully convolutional network ensembles for white matter hyperintensities segmentation in MR images","2018","NeuroImage","138","10.1016/j.neuroimage.2018.07.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052893805&doi=10.1016%2fj.neuroimage.2018.07.005&partnerID=40&md5=5576d8040f515b425c0b2227459bce96","School of Data and Computer Science, Sun Yat-sen University, China; Computing, School of Science and Engineering, University of Dundee, United Kingdom; Department of Computer Science, Technical University of Munich, Germany","Li H., School of Data and Computer Science, Sun Yat-sen University, China, Computing, School of Science and Engineering, University of Dundee, United Kingdom, Department of Computer Science, Technical University of Munich, Germany; Jiang G., School of Data and Computer Science, Sun Yat-sen University, China; Zhang J., Computing, School of Science and Engineering, University of Dundee, United Kingdom; Wang R., School of Data and Computer Science, Sun Yat-sen University, China; Wang Z., School of Data and Computer Science, Sun Yat-sen University, China; Zheng W.-S., School of Data and Computer Science, Sun Yat-sen University, China; Menze B., Department of Computer Science, Technical University of Munich, Germany","White matter hyperintensities (WMH) are commonly found in the brains of healthy elderly individuals and have been associated with various neurological and geriatric disorders. In this paper, we present a study using deep fully convolutional network and ensemble models to automatically detect such WMH using fluid attenuation inversion recovery (FLAIR) and T1 magnetic resonance (MR) scans. The algorithm was evaluated and ranked 1st in the WMH Segmentation Challenge at MICCAI 2017. In the evaluation stage, the implementation of the algorithm was submitted to the challenge organizers, who then independently tested it on a hidden set of 110 cases from 5 scanners. Averaged dice score, precision and robust Hausdorff distance obtained on held-out test datasets were 80%, 84% and 6.30 mm respectively. These were the highest achieved in the challenge, suggesting the proposed method is the state-of-the-art. Detailed descriptions and quantitative analysis on key components of the system were provided. Furthermore, a study of cross-scanner evaluation is presented to discuss how the combination of modalities affect the generalization capability of the system. The adaptability of the system to different scanners and protocols is also investigated. A quantitative study is further presented to show the effect of ensemble size and the effectiveness of the ensemble model. Additionally, software and models of our method are made publicly available. The effectiveness and generalization capability of the proposed system show its potential for real-world clinical practice. © 2018 Elsevier Inc.","Brain lesion segmentation; Deep learning; Ensemble models; MICCAI WMH segmentation challenge; White matter hyperintensities","Algorithms; Brain; Datasets as Topic; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Neuroimaging; White Matter; Article; controlled study; deep fully convolutional network; human; image processing; image segmentation; machine learning; major clinical study; mathematical model; measurement accuracy; measurement precision; nuclear magnetic resonance imaging; priority journal; quantitative analysis; white matter; algorithm; brain; computer assisted diagnosis; diagnostic imaging; information processing; neuroimaging; nuclear magnetic resonance imaging; procedures; white matter","Academic Press Inc.","10538119","","NEIME","30125711","Article","Scopus","2-s2.0-85052893805"
"Korvigo I.; Holmatov M.; Zaikovskii A.; Skoblov M.","Korvigo, Ilia (57090785200); Holmatov, Maxim (57201086060); Zaikovskii, Anatolii (57202230019); Skoblov, Mikhail (8979068100)","57090785200; 57201086060; 57202230019; 8979068100","Putting hands to rest: efficient deep CNN-RNN architecture for chemical named entity recognition with no hand-crafted rules","2018","Journal of Cheminformatics","34","10.1186/s13321-018-0280-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047534001&doi=10.1186%2fs13321-018-0280-0&partnerID=40&md5=5d280bd85ed52d2732362558cd5cd32e","Laboratory of Functional Analysis of the Genome, Moscow Institute of Physics and Technology, Moscow, Russian Federation; All-Russia Institute for Agricultural Microbiology, St. Petersburg, Russian Federation; ITMO University, St. Petersburg, Russian Federation; St. Petersburg State Pediatric Medical University, St. Petersburg, Russian Federation; N.N. Petrov Institute of Oncology, Department of Tumor Biology, St. Petersburg, Russian Federation; St. Petersburg State University, St. Petersburg, Russian Federation; School of Biomedicine, Far Eastern Federal University, Vladivostok, Russian Federation; Laboratory of Functional Genomics, Research Centre for Medical Genetics, Moscow, Russian Federation","Korvigo I., Laboratory of Functional Analysis of the Genome, Moscow Institute of Physics and Technology, Moscow, Russian Federation, All-Russia Institute for Agricultural Microbiology, St. Petersburg, Russian Federation, ITMO University, St. Petersburg, Russian Federation; Holmatov M., St. Petersburg State Pediatric Medical University, St. Petersburg, Russian Federation, N.N. Petrov Institute of Oncology, Department of Tumor Biology, St. Petersburg, Russian Federation; Zaikovskii A., St. Petersburg State University, St. Petersburg, Russian Federation; Skoblov M., Laboratory of Functional Analysis of the Genome, Moscow Institute of Physics and Technology, Moscow, Russian Federation, School of Biomedicine, Far Eastern Federal University, Vladivostok, Russian Federation, Laboratory of Functional Genomics, Research Centre for Medical Genetics, Moscow, Russian Federation","Chemical named entity recognition (NER) is an active field of research in biomedical natural language processing. To facilitate the development of new and superior chemical NER systems, BioCreative released the CHEMDNER corpus, an extensive dataset of diverse manually annotated chemical entities. Most of the systems trained on the corpus rely on complicated hand-crafted rules or curated databases for data preprocessing, feature extraction and output post-processing, though modern machine learning algorithms, such as deep neural networks, can automatically design the rules with little to none human intervention. Here we explored this approach by experimenting with various deep learning architectures for targeted tokenisation and named entity recognition. Our final model, based on a combination of convolutional and stateful recurrent neural networks with attention-like loops and hybrid word- and character-level embeddings, reaches near human-level performance on the testing dataset with no manually asserted rules. To make our model easily accessible for standalone use and integration in third-party software, we’ve developed a Python package with a minimalistic user interface. © 2018, The Author(s).","Biocreative; Chemdner; Chemical; Conditional random fields; Convolutional neural network; Deep learning; Named entities recognition; Neural attention; Recurrent neural network; Text mining; Tokenisation","","Springer","17582946","","","","Article","Scopus","2-s2.0-85047534001"
"Li X.; Chen H.; Qi X.; Dou Q.; Fu C.-W.; Heng P.-A.","Li, Xiaomeng (57192493244); Chen, Hao (56493367600); Qi, Xiaojuan (57189658166); Dou, Qi (56903795500); Fu, Chi-Wing (7402802915); Heng, Pheng-Ann (7006677755)","57192493244; 56493367600; 57189658166; 56903795500; 7402802915; 7006677755","H-DenseUNet: Hybrid Densely Connected UNet for Liver and Tumor Segmentation from CT Volumes","2018","IEEE Transactions on Medical Imaging","1524","10.1109/TMI.2018.2845918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048473372&doi=10.1109%2fTMI.2018.2845918&partnerID=40&md5=beea300d2680d6afca16d10ba207d8eb","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Imsight Medical Technology, Inc., Shenzhen, 518000, China","Li X., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Chen H., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, Imsight Medical Technology, Inc., Shenzhen, 518000, China; Qi X., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Dou Q., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Fu C.-W., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Heng P.-A., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong","Liver cancer is one of the leading causes of cancer death. To assist doctors in hepatocellular carcinoma diagnosis and treatment planning, an accurate and automatic liver and tumor segmentation method is highly demanded in the clinical practice. Recently, fully convolutional neural networks (FCNs), including 2-D and 3-D FCNs, serve as the backbone in many volumetric image segmentation. However, 2-D convolutions cannot fully leverage the spatial information along the third dimension while 3-D convolutions suffer from high computational cost and GPU memory consumption. To address these issues, we propose a novel hybrid densely connected UNet (H-DenseUNet), which consists of a 2-D DenseUNet for efficiently extracting intra-slice features and a 3-D counterpart for hierarchically aggregating volumetric contexts under the spirit of the auto-context algorithm for liver and tumor segmentation. We formulate the learning process of the H-DenseUNet in an end-to-end manner, where the intra-slice representations and inter-slice features can be jointly optimized through a hybrid feature fusion layer. We extensively evaluated our method on the data set of the MICCAI 2017 Liver Tumor Segmentation Challenge and 3DIRCADb data set. Our method outperformed other state-of-the-arts on the segmentation results of tumors and achieved very competitive performance for liver segmentation even with a single model. © 2018 IEEE.","CT; deep learning; hybrid features; liver tumor segmentation","Algorithms; Cone-Beam Computed Tomography; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Liver; Liver Neoplasms; Computerized tomography; Convolution; Deep learning; Diagnosis; Diseases; Neural networks; Tumors; Competitive performance; Convolutional neural network; Hepatocellular carcinoma; Hybrid features; Liver tumor segmentations; Segmentation results; Spatial informations; Volumetric image segmentation; Article; artificial neural network; cancer mortality; clinical evaluation; clinical practice; computer assisted tomography; controlled study; feature extraction; fully convolutional neural network; human; hybrid; hybrid densely connected UNet; image analysis; image segmentation; learning algorithm; liver; liver cell carcinoma; machine learning; physician; random forest; three dimensional imaging; tumor volume; volumetry; algorithm; computer assisted diagnosis; cone beam computed tomography; diagnostic imaging; liver tumor; procedures; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29994201","Article","Scopus","2-s2.0-85048473372"
"Yıldırım Ö.; Pławiak P.; Tan R.-S.; Acharya U.R.","Yıldırım, Özal (55293146500); Pławiak, Paweł (55939473200); Tan, Ru-San (7201984906); Acharya, U. Rajendra (7004510847)","55293146500; 55939473200; 7201984906; 7004510847","Arrhythmia detection using deep convolutional neural network with long duration ECG signals","2018","Computers in Biology and Medicine","549","10.1016/j.compbiomed.2018.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053715332&doi=10.1016%2fj.compbiomed.2018.09.009&partnerID=40&md5=29e2e04e5336fe03bbefec62cba10905","Department of Computer Engineering, Munzur University, Tunceli, Turkey; Institute of Telecomputing, Faculty of Physics, Mathematics and Computer Science Cracow University of Technology, Krakow, Poland; Department of Cardiology, National Heart Centre Singapore, Singapore; Duke-NUS Medical School, Singapore; Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, Singapore School of Social Sciences, Singapore; School of Medicine, Faculty of Health and Medical Sciences, Taylor's University, Subang Jaya, 47500, Malaysia","Yıldırım Ö., Department of Computer Engineering, Munzur University, Tunceli, Turkey; Pławiak P., Institute of Telecomputing, Faculty of Physics, Mathematics and Computer Science Cracow University of Technology, Krakow, Poland; Tan R.-S., Department of Cardiology, National Heart Centre Singapore, Singapore, Duke-NUS Medical School, Singapore; Acharya U.R., Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore, Department of Biomedical Engineering, School of Science and Technology, Singapore School of Social Sciences, Singapore, School of Medicine, Faculty of Health and Medical Sciences, Taylor's University, Subang Jaya, 47500, Malaysia","This article presents a new deep learning approach for cardiac arrhythmia (17 classes) detection based on long-duration electrocardiography (ECG) signal analysis. Cardiovascular disease prevention is one of the most important tasks of any health care system as about 50 million people are at risk of heart disease in the world. Although automatic analysis of ECG signal is very popular, current methods are not satisfactory. The goal of our research was to design a new method based on deep learning to efficiently and quickly classify cardiac arrhythmias. Described research are based on 1000 ECG signal fragments from the MIT - BIH Arrhythmia database for one lead (MLII) from 45 persons. Approach based on the analysis of 10-s ECG signal fragments (not a single QRS complex) is applied (on average, 13 times less classifications/analysis). A complete end-to-end structure was designed instead of the hand-crafted feature extraction and selection used in traditional methods. Our main contribution is to design a new 1D-Convolutional Neural Network model (1D-CNN). The proposed method is 1) efficient, 2) fast (real-time classification) 3) non-complex and 4) simple to use (combined feature extraction and selection, and classification in one stage). Deep 1D-CNN achieved a recognition overall accuracy of 17 cardiac arrhythmia disorders (classes) at a level of 91.33% and classification time per single sample of 0.015 s. Compared to the current research, our results are one of the best results to date, and our solution can be implemented in mobile devices and cloud computing. © 2018 Elsevier Ltd","cardiac arrhythmias; Convolutional neural networks; Deep learning; ECG classification","Adult; Aged; Aged, 80 and over; Algorithms; Arrhythmias, Cardiac; Cardiovascular Diseases; Cloud Computing; Deep Learning; Diagnosis, Computer-Assisted; Electrocardiography; Electronic Data Processing; Female; Humans; Machine Learning; Male; Middle Aged; Neural Networks (Computer); Pacemaker, Artificial; Reproducibility of Results; Signal Processing, Computer-Assisted; Software; Telemedicine; Young Adult; Cardiology; Complex networks; Convolution; Deep learning; Deep neural networks; Diseases; Electrocardiography; Extraction; Feature extraction; Health risks; Heart; mHealth; Mobile telecommunication systems; Neural networks; Signal analysis; Arrhythmia detection; Cardiac arrhythmia; Cardio-vascular disease; Classification time; Convolutional neural network; Deep convolutional neural networks; Ecg classifications; Feature extraction and selection; adult; aged; Article; artificial neural network; clinical article; cloud computing; convolutional neural network; disease classification; electrocardiography; extraction; feature extraction; female; heart arrhythmia; human; male; priority journal; algorithm; artificial heart pacemaker; artificial neural network; cardiovascular disease; computer assisted diagnosis; electrocardiography; heart arrhythmia; information processing; machine learning; middle aged; procedures; reproducibility; signal processing; software; telemedicine; very elderly; young adult; Biomedical signal processing","Elsevier Ltd","00104825","","CBMDA","30245122","Article","Scopus","2-s2.0-85053715332"
"Islam J.; Zhang Y.","Islam, Jyoti (57192205721); Zhang, Yanqing (57202590512)","57192205721; 57202590512","Brain MRI analysis for Alzheimer’s disease diagnosis using an ensemble system of deep convolutional neural networks","2018","Brain Informatics","279","10.1186/s40708-018-0080-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048741280&doi=10.1186%2fs40708-018-0080-3&partnerID=40&md5=b5a5a02e3e9399c5ba75c2f51329fea2","Department of Computer Science, Georgia State University, Atlanta, 30302-5060, GA, United States","Islam J., Department of Computer Science, Georgia State University, Atlanta, 30302-5060, GA, United States; Zhang Y., Department of Computer Science, Georgia State University, Atlanta, 30302-5060, GA, United States","Alzheimer’s disease is an incurable, progressive neurological brain disorder. Earlier detection of Alzheimer’s disease can help with proper treatment and prevent brain tissue damage. Several statistical and machine learning models have been exploited by researchers for Alzheimer’s disease diagnosis. Analyzing magnetic resonance imaging (MRI) is a common practice for Alzheimer’s disease diagnosis in clinical research. Detection of Alzheimer’s disease is exacting due to the similarity in Alzheimer’s disease MRI data and standard healthy MRI data of older people. Recently, advanced deep learning techniques have successfully demonstrated human-level performance in numerous fields including medical image analysis. We propose a deep convolutional neural network for Alzheimer’s disease diagnosis using brain MRI data analysis. While most of the existing approaches perform binary classification, our model can identify different stages of Alzheimer’s disease and obtains superior performance for early-stage diagnosis. We conducted ample experiments to demonstrate that our proposed model outperformed comparative baselines on the Open Access Series of Imaging Studies dataset. © 2018, The Author(s).","Alzheimer’s disease; Brain imaging; Convolutional neural network; Deep learning; MRI; Neurological disorder","","Springer Berlin Heidelberg","21984018","","","","Article","Scopus","2-s2.0-85048741280"
"Volkova K.V.; Dagaev N.I.; Kiselev A.S.; Kasumov V.R.; Aleksandrov M.V.; Osadchiy A.E.","Volkova, K.V. (57200205669); Dagaev, N.I. (56049676100); Kiselev, A.S. (57200200601); Kasumov, V.R. (14045450100); Aleksandrov, M.V. (7004578812); Osadchiy, A.E. (57200203650)","57200205669; 56049676100; 57200200601; 14045450100; 7004578812; 57200203650","The Brain–Computer Interface: Experience of Construction, Use, and Potential Routes to Improving Performance","2018","Neuroscience and Behavioral Physiology","0","10.1007/s11055-018-0677-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057108727&doi=10.1007%2fs11055-018-0677-2&partnerID=40&md5=126d7046499f23fa4c792efe1ed99aca","Center for Neuroeconomics and Cognitive Research, National Research University Higher School of Economics, Moscow, Russian Federation; Moscow Institute of Physics and Technology (State University), Dolgoprudnyi, Moscow Oblast, Russian Federation; Polenov Russian Neurosurgical Research Institute, Branch of Almazov North-West Federal Medical Research Center, St. Petersburg, Russian Federation","Volkova K.V., Center for Neuroeconomics and Cognitive Research, National Research University Higher School of Economics, Moscow, Russian Federation; Dagaev N.I., Center for Neuroeconomics and Cognitive Research, National Research University Higher School of Economics, Moscow, Russian Federation; Kiselev A.S., Moscow Institute of Physics and Technology (State University), Dolgoprudnyi, Moscow Oblast, Russian Federation; Kasumov V.R., Polenov Russian Neurosurgical Research Institute, Branch of Almazov North-West Federal Medical Research Center, St. Petersburg, Russian Federation; Aleksandrov M.V., Polenov Russian Neurosurgical Research Institute, Branch of Almazov North-West Federal Medical Research Center, St. Petersburg, Russian Federation; Osadchiy A.E., Center for Neuroeconomics and Cognitive Research, National Research University Higher School of Economics, Moscow, Russian Federation","Neurocomputer interfaces or, as they have come to be known in the Russian literature, brain–computer interfaces (BCI), are used in several areas and have the potential for uses in solving both research and applied tasks. Pilot studies in the clinical application of BCI to poststroke neurorehabilitation are currently under way [Frolov et al., 2013; Ang et al., 2010], and there are prospects for the use of BCI for direct restoration of movement/communication capabilities by creating an alternative information exchange channel with intelligent prostheses and the surroundings. Studies using electrophysiological data generate the need to process multidimensional, nonstationary signals, refl ecting complex physiological processes. Interfaces based on noninvasive technologies for recording brain activity do not as yet provide reliable information links with the user’s brain. The results of our studies show that improvements in the working characteristics of these systems can be obtained by constructing new machine learning algorithms considering the physiological and psychoemotional characteristics of BCI use. These algorithms can be developed either in the classical Bayesian paradigm or using state-of-the-art deep learning techniques. In addition, the creation of methods for the physiological interpretation of nonlinear decision rules found by multilayered structures opens up new potentials for the automatic and objective extraction of knowledge from experimental neurophysiological data. Despite the attractiveness of noninvasive technologies, radical increases in the throughput of BCI communication channels and the use of this technology to control prostheses can only be obtained using invasive methods of recording brain activity. Electrocorticograms (ECoG) are the least invasive of these technologies, and in the concluding part of this work we will demonstrate that ECoG can be used for decoding of the kinematic characteristics of finger movements. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","brain–computer interface; deep learning; ECoG; EEG; sensorimotor rhythm","algorithm; Article; artificial neural network; Bayesian learning; brain computer interface; brain function; classifier; communication skill; controlled study; data extraction; electrocorticography; electroencephalogram; electroencephalography phase synchronization; emotionality; human; invasive procedure; kinematics; knowledge base; learning algorithm; machine learning; magnetoencephalography; neurophysiology; non invasive procedure; physiological process; signal processing; total quality management","Springer New York LLC","00970549","","NBHPB","","Article","Scopus","2-s2.0-85057108727"
"Li D.","Li, Dongping (57193813396)","57193813396","AUTOMATIC DETECTION of CARDIOVASCULAR DISEASE USING DEEP KERNEL EXTREME LEARNING MACHINE","2018","Biomedical Engineering - Applications, Basis and Communications","2","10.4015/S1016237218500382","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052744443&doi=10.4015%2fS1016237218500382&partnerID=40&md5=b7c30534c9340e28ece8177c035d5ec0","Institute of Information Science and Technology, Kunming University, Kunming, 650214, China","Li D., Institute of Information Science and Technology, Kunming University, Kunming, 650214, China","The electrocardiogram (ECG) is a principal signal employed to automatically diagnose cardiovascular disease in shallow and deep learning models. However, ECG feature extraction is required and this may reduce diagnosis accuracy in traditional shallow learning models, while backward propagation (BP) algorithm used by the traditional deep learning models has the disadvantages of local minimization and slow convergence rate. To solve these problems, a new deep learning algorithm called deep kernel extreme learning machine (DKELM) is proposed by combining the extreme learning machine auto-encoder (ELM-AE) and kernel ELM (KELM). In the new DKELM architecture with M+1 hidden layers, ELM-AEs are employed by the front M hidden layers for feature extraction in the unsupervised learning process, which can effectively extract abstract features from the original ECG signal. To overcome the ""dimension disaster"" problem, the kernel function is introduced into ELM to act as classifier by the M+1th hidden layer in the supervised learning process. The experiments demonstrate that DKELM outperforms the BP neural network, support vector machine (SVM), extreme learning machine (ELM), deep auto-encoder (DAE), deep belief network (DBN) in classification accuracy. Though the accuracy of convolutional neural network (CNN) is almost the same as DKELM, the computing time of CNN is much longer than DKELM. © 2018 National Taiwan University.","Auto-encoder; Deep neural network; Electrocardiogram signals; Extreme learning machine; Kernel function; MIT-BIH arrhythmia database","Biomedical signal processing; Cardiology; Deep neural networks; Diseases; Electrocardiography; Extraction; Feature extraction; Knowledge acquisition; Neural networks; Signal encoding; Support vector machines; Auto encoders; Cardio-vascular disease; Convolutional Neural Networks (CNN); Deep belief network (DBN); ECG Feature extractions; Electrocardiogram signal; Extreme learning machine; Kernel function; Article; automation; cardiovascular disease; deep kernel extreme learning machine; diagnostic accuracy; discrete wavelet transform; feature extraction; human; kernel method; learning algorithm; support vector machine; Learning algorithms","World Scientific Publishing Co. Pte Ltd","10162372","","YIGOE","","Article","Scopus","2-s2.0-85052744443"
"Li Y.; Tian Y.; Qin Z.; Yan A.","Li, Yang (56454592500); Tian, Yujia (57204758952); Qin, Zijian (57194196623); Yan, Aixia (35197459200)","56454592500; 57204758952; 57194196623; 35197459200","Classification of HIV-1 Protease Inhibitors by Machine Learning Methods","2018","ACS Omega","11","10.1021/acsomega.8b01843","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057007940&doi=10.1021%2facsomega.8b01843&partnerID=40&md5=1a14f51005905179429b3440a66f0ff4","State Key Laboratory of Chemical Resource Engineering, Department of Pharmaceutical Engineering, Beijing University of Chemical Technology, P.O. Box 53, 15 BeiSanHuan East Road, Beijing, 100029, China; Institute of Science and Technology, Shandong University of Traditional Chinese Medicine, Ji'nan, 250355, Shandong, China","Li Y., State Key Laboratory of Chemical Resource Engineering, Department of Pharmaceutical Engineering, Beijing University of Chemical Technology, P.O. Box 53, 15 BeiSanHuan East Road, Beijing, 100029, China, Institute of Science and Technology, Shandong University of Traditional Chinese Medicine, Ji'nan, 250355, Shandong, China; Tian Y., State Key Laboratory of Chemical Resource Engineering, Department of Pharmaceutical Engineering, Beijing University of Chemical Technology, P.O. Box 53, 15 BeiSanHuan East Road, Beijing, 100029, China; Qin Z., State Key Laboratory of Chemical Resource Engineering, Department of Pharmaceutical Engineering, Beijing University of Chemical Technology, P.O. Box 53, 15 BeiSanHuan East Road, Beijing, 100029, China; Yan A., State Key Laboratory of Chemical Resource Engineering, Department of Pharmaceutical Engineering, Beijing University of Chemical Technology, P.O. Box 53, 15 BeiSanHuan East Road, Beijing, 100029, China","HIV-1 protease plays an important role in the processing of virus infection. Protease is an effective therapeutic target for the treatment of HIV-1. Our data set is based on a selection of 4855 HIV-1 protease inhibitors (PIs) from ChEMBL. A series of 15 classification models for predicting the active inhibitors were built by machine learning methods, including k-nearest neighors (K-NN), decision tree (DT), random forest (RF), support vector machine (SVM), and deep neural network (DNN). The molecular structures were characterized by (1) fingerprint descriptors including MACCS fingerprints and PubChem fingerprints and (2) physicochemical descriptors calculated by CORINA Symphony. The prediction accuracies of all of the models are more than 70% on the test set; the best accuracy of 83.07% was obtained by model 4A, which was built by the SVM method based on MACCS fingerprint descriptors. Nine consensus models were built with three kinds of different descriptors, which combined all of the machine learning methods using the ""consensus prediction"". Model C3a developed with MACCS fingerprint descriptors showed the highest accuracy on both training set (91.96%) and test set (83.15%). An external validation set including 35 989 compounds from DUD database and 239 active inhibitors from the recent literature was used to verify the performance of our model. The best prediction accuracy of 98.37% was obtained by model 3C, which was built by RF based on CORINA Symphony descriptors. In addition, from the analysis of molecular descriptors, it shows that the aromatic system and atoms related to hydrogen bonding provide important contributions to the bioactivity of PIs. Copyright © 2018 American Chemical Society.","","","American Chemical Society","24701343","","","","Article","Scopus","2-s2.0-85057007940"
"Xiao T.; Qi X.; Chen Y.; Jiang Y.","Xiao, Tao (57201771969); Qi, Xingxing (57210541630); Chen, Yuzong (34876158000); Jiang, Yuyang (56173699500)","57201771969; 57210541630; 34876158000; 56173699500","Development of Ligand-based Big Data Deep Neural Network Models for Virtual Screening of Large Compound Libraries","2018","Molecular Informatics","14","10.1002/minf.201800031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056360583&doi=10.1002%2fminf.201800031&partnerID=40&md5=99a0a6b7180926c63a7cae15c7c1f6d8","Department of Chemistry, Tsinghua University, Beijing, 100084, China; The State Key Laboratory of Chemical Oncogenomics, the Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055, China; Bioinformatics and Drug Design Group, Department of Pharmacy, National, University of Singapore, Singapore, 117543, Singapore; Shenzhen Kivita Innovative Drug Institute, Shenzhen, 518055, China; School of Pharmaceutical Sciences, Tsinghua University, Beijing, 100084, China","Xiao T., Department of Chemistry, Tsinghua University, Beijing, 100084, China, The State Key Laboratory of Chemical Oncogenomics, the Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055, China; Qi X., The State Key Laboratory of Chemical Oncogenomics, the Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055, China; Chen Y., Bioinformatics and Drug Design Group, Department of Pharmacy, National, University of Singapore, Singapore, 117543, Singapore, Shenzhen Kivita Innovative Drug Institute, Shenzhen, 518055, China; Jiang Y., The State Key Laboratory of Chemical Oncogenomics, the Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055, China, School of Pharmaceutical Sciences, Tsinghua University, Beijing, 100084, China","High-performance ligand-based virtual screening (VS) models have been developed using various computational methods, including the deep neural network (DNN) method. There are high expectations for exploration of the advanced capabilities of DNN to improve VS performance, and this capability has been optimally achieved using large data training datasets. However, their ability to screen large compound libraries has not been evaluated. There is a need for developing and evaluating ligand-based large data DNN VS models for large compound libraries. In this study, we developed ligand-based large data DNN VS models for inhibitors of six anticancer targets using 0.5 M training compounds. The developed VS models were evaluated by 10-fold cross-validation, achieving 77.9-97.8 % sensitivity, 99.9-100 % specificity, 0.82-0.98 Matthews correlation coefficient and 0.98-0.99 area under the curve, outperforming random forest models. Moreover, DNN VS models developed by pre-2015 inhibitors identified 50 % of post-2015 inhibitors with a 0.01-0.09 % false positive rate in screening 89 M PubChem compounds, also outperforming previous models. Experimental assays of the selected virtual hits of the EGFR inhibitor model led to reasonable novel structures of EGFR inhibitors. Our results confirmed the usefulness of the large data DNN model as a ligand-based VS tool to screen large compound libraries. © 2018 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","deep learning; EGFR; large compound library; ligand-based virtual screening; machine learning","Big Data; Databases, Chemical; Drug Discovery; ErbB Receptors; Humans; Ligands; Molecular Docking Simulation; Neural Networks (Computer); Small Molecule Libraries; antineoplastic agent; epidermal growth factor receptor kinase inhibitor; gelatinase inhibitor; ligand; mammalian target of rapamycin inhibitor; metalloproteinase inhibitor; molecular scaffold; phosphatidylinositol 3 kinase inhibitor; epidermal growth factor receptor; ligand; Article; artificial neural network; big data; classification; drug structure; false positive result; high throughput screening; in vitro study; ligand based virtual screening; machine learning; nerve cell network; priority journal; random forest; sensitivity and specificity; support vector machine; virtual reality; antagonists and inhibitors; artificial neural network; chemical database; chemistry; drug development; human; molecular docking; molecular library; pharmacology; procedures","Wiley-VCH Verlag","18681743","","MIONB","29882343","Article","Scopus","2-s2.0-85056360583"
"Sun Z.; Chiong R.; Hu Z.-P.","Sun, Zhe (57189890285); Chiong, Raymond (23395951300); Hu, Zheng-ping (34770819300)","57189890285; 23395951300; 34770819300","An extended dictionary representation approach with deep subspace learning for facial expression recognition","2018","Neurocomputing","28","10.1016/j.neucom.2018.07.045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053045385&doi=10.1016%2fj.neucom.2018.07.045&partnerID=40&md5=398336107a5579b50e8a94888f6c1aae","School of Information Science and Engineering, Yanshan University, Hebei Street, Qinhuangdao, Hebei, China; School of Electrical Engineering and Computing, The University of Newcastle, University Drive, Callaghan, 2308, NSW, Australia","Sun Z., School of Information Science and Engineering, Yanshan University, Hebei Street, Qinhuangdao, Hebei, China; Chiong R., School of Electrical Engineering and Computing, The University of Newcastle, University Drive, Callaghan, 2308, NSW, Australia; Hu Z.-P., School of Information Science and Engineering, Yanshan University, Hebei Street, Qinhuangdao, Hebei, China","Deep subspace learning (DSL) models based on the principal component analysis network (PCANet) and linear discriminant analysis network (LDANet) have shown to be promising alternatives to deep learning models when there are computing power and training data constraints. However, high dimensionality of the feature space remains a major issue for DSL models. This paper presents a novel DSL approach based on an extended dictionary representation with deep subspace features for facial expression recognition. First, we propose the use of feature pooling with DSL by adding rank-based average pooling between each subspace mapping layer. We then use spatial pyramid pooling in the output layer to overcome the high-dimensionality problem. After that, the extended dictionary is formed by expanding the feature dictionary. Finally, we apply sparse representation classification with squared ℓ2-regularization to improve the recognition accuracy. Comprehensive experiments based on several well-established datasets confirm that our proposed approach has superior performance compared to both the baseline as well as state-of-the-art PCANet and LDANet methods, not just in terms of accuracy but also robustness against block occlusion and random corruption. © 2018","Extended dictionary representation; Facial expression recognition; Feature pooling with deep subspace learning; LDANet; PCANet","Digital subscriber lines; Discriminant analysis; DSL; Face recognition; Principal component analysis; Extended dictionary representation; Facial expression recognition; LDANet; PCANet; Subspace learning; accuracy; Article; controlled study; deep subspace learning; discriminant analysis; extended dictionary representation; facial expression; facial recognition; female; human; machine learning; male; principal component analysis; priority journal; spatial analysis; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85053045385"
"Xiao X.; Djurisic M.; Hoogi A.; Sapp R.W.; Shatz C.J.; Rubin D.L.","Xiao, Xuerong (57203623814); Djurisic, Maja (6601992226); Hoogi, Assaf (22937529600); Sapp, Richard W. (56395191500); Shatz, Carla J. (7006147605); Rubin, Daniel L. (7202307112)","57203623814; 6601992226; 22937529600; 56395191500; 7006147605; 7202307112","Automated dendritic spine detection using convolutional neural networks on maximum intensity projected microscopic volumes","2018","Journal of Neuroscience Methods","8","10.1016/j.jneumeth.2018.08.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052487945&doi=10.1016%2fj.jneumeth.2018.08.019&partnerID=40&md5=0d91ecb20f3cbe33fc12109a1c8d584c","Department of Electrical Engineering, Stanford University, David Packard Building, 350 Serra Mall, Stanford, 94305, CA, United States; Departments of Biology and Neurobiology, and Bio-X, Stanford University, James H. Clark Center, 318 Campus Dr, Stanford, 94305, CA, United States; Department of Biomedical Data Science, Stanford University, Medical School Office Building, 1265 Welch Rd, Stanford, 94305, CA, United States","Xiao X., Department of Electrical Engineering, Stanford University, David Packard Building, 350 Serra Mall, Stanford, 94305, CA, United States; Djurisic M., Departments of Biology and Neurobiology, and Bio-X, Stanford University, James H. Clark Center, 318 Campus Dr, Stanford, 94305, CA, United States; Hoogi A., Department of Biomedical Data Science, Stanford University, Medical School Office Building, 1265 Welch Rd, Stanford, 94305, CA, United States; Sapp R.W., Departments of Biology and Neurobiology, and Bio-X, Stanford University, James H. Clark Center, 318 Campus Dr, Stanford, 94305, CA, United States; Shatz C.J., Departments of Biology and Neurobiology, and Bio-X, Stanford University, James H. Clark Center, 318 Campus Dr, Stanford, 94305, CA, United States; Rubin D.L., Department of Biomedical Data Science, Stanford University, Medical School Office Building, 1265 Welch Rd, Stanford, 94305, CA, United States","Background: Dendritic spines are structural correlates of excitatory synapses in the brain. Their density and structure are shaped by experience, pointing to their role in memory encoding. Dendritic spine imaging, followed by manual analysis, is a primary way to study spines. However, an approach that analyses dendritic spines images in an automated and unbiased manner is needed to fully capture how spines change with normal experience, as well as in disease. New method: We propose an approach based on fully convolutional neural networks (FCNs) to detect dendritic spines in two-dimensional maximum-intensity projected images from confocal fluorescent micrographs. We experiment on both fractionally strided convolution and efficient sub-pixel convolutions. Dendritic spines far from the dendritic shaft are pruned by extraction of the shaft to reduce false positives. Performance of the proposed method is evaluated by comparing predicted spine positions to those manually marked by experts. Results: The averaged distance between predicted and manually annotated spines is 2.81 ± 2.63 pixels (0.082 ± 0.076 microns) and 2.87 ± 2.33 pixels (0.084 ± 0.068 microns) based on two different experts. FCN-based detection achieves F scores > 0.80 for both sets of expert annotations. Comparison with existing methods: Our method significantly outperforms two well-known software, NeuronStudio and Neurolucida (p-value < 0.02). Conclusions: FCN architectures used in this work allow for automated dendritic spine detection. Superior outcomes are possible even with small training data-sets. The proposed method may generalize to other datasets on larger scales. © 2018 Elsevier B.V.","Convolutional neural networks; Deep learning; Dendritic spine detection","Animals; Dendritic Spines; Imaging, Three-Dimensional; Male; Mice; Microscopy, Confocal; Neural Networks (Computer); Pattern Recognition, Automated; accuracy; Article; clinical evaluation; comparative study; dendritic spine; diagnostic test accuracy study; false negative result; false positive result; fully convolutional neural network; human; imaging and display; machine learning; maximal intensity projection; neuroimaging; position; prediction; priority journal; two-dimensional imaging; validation process; visual cortex; animal; artificial neural network; automated pattern recognition; confocal microscopy; male; mouse; procedures; three dimensional imaging","Elsevier B.V.","01650270","","JNMED","30130608","Article","Scopus","2-s2.0-85052487945"
"Bobrov E.; Georgievskaya A.; Kiselev K.; Sevastopolsky A.; Zhavoronkov A.; Gurov S.; Rudakov K.; Tobar M.P.B.; Jaspers S.; Clemann S.","Bobrov, Eugene (57204955857); Georgievskaya, Anastasia (57204955063); Kiselev, Konstantin (57204955979); Sevastopolsky, Artem (57195675236); Zhavoronkov, Alex (39862415800); Gurov, Sergey (57192988543); Rudakov, Konstantin (6603540895); Tobar, Maria del Pilar Bonilla (57204949557); Jaspers, Sören (7003534930); Clemann, Sven (6507975498)","57204955857; 57204955063; 57204955979; 57195675236; 39862415800; 57192988543; 6603540895; 57204949557; 7003534930; 6507975498","PhotoAgeClock: Deep learning algorithms for development of noninvasive visual biomarkers of aging","2018","Aging","60","10.18632/aging.101629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057278319&doi=10.18632%2faging.101629&partnerID=40&md5=1444e108d56ace3a49d20eda7e29c824","HautAI OU, Tallinn, Estonia; Lomonosov Moscow State University, Moscow, Russian Federation; Federal Research Center 'Computer Science and Control' of the Russian Academy of Sciences, Moscow, Russian Federation; Skolkovo Institute of Science and Technology, Moscow, Russian Federation; Insilico Medicine, Rockville, 20850, MD, United States; The Buck Institute for Research on Aging, Novato, 94945, CA, United States; The Biogerontology Research Foundation, London, United Kingdom; Beiersdorf AG, Hamburg, Germany","Bobrov E., HautAI OU, Tallinn, Estonia, Lomonosov Moscow State University, Moscow, Russian Federation; Georgievskaya A., HautAI OU, Tallinn, Estonia, Federal Research Center 'Computer Science and Control' of the Russian Academy of Sciences, Moscow, Russian Federation; Kiselev K., HautAI OU, Tallinn, Estonia; Sevastopolsky A., HautAI OU, Tallinn, Estonia, Skolkovo Institute of Science and Technology, Moscow, Russian Federation; Zhavoronkov A., Insilico Medicine, Rockville, 20850, MD, United States, The Buck Institute for Research on Aging, Novato, 94945, CA, United States, The Biogerontology Research Foundation, London, United Kingdom; Gurov S., Lomonosov Moscow State University, Moscow, Russian Federation; Rudakov K., Federal Research Center 'Computer Science and Control' of the Russian Academy of Sciences, Moscow, Russian Federation; Tobar M.P.B., Beiersdorf AG, Hamburg, Germany; Jaspers S., Beiersdorf AG, Hamburg, Germany; Clemann S., Beiersdorf AG, Hamburg, Germany","Aging biomarkers are the qualitative and quantitative indicators of the aging processes of the human body. Estimation of biological age is important for assessing the physiological state of an organism. The advent of machine learning lead to the development of the many age predictors commonly referred to as the ""aging clocks"" varying in biological relevance, ease of use, cost, actionability, interpretability, and applications. Here we present and investigate a novel non-invasive class of visual photographic biomarkers of aging. We developed a simple and accurate predictor of chronological age using just the anonymized images of eye corners called the PhotoAgeClock. Deep neural networks were trained on 8414 anonymized high-resolution images of eye corners labeled with the correct chronological age. For people within the age range of 20 to 80 in a specific population, the model was able to achieve a mean absolute error of 2.3 years and 95% Pearson and Spearman correlation. © Bobrov et al.","Age prediction; Biomedical imaging; Computer vision; Deep learning; Photographic aging biomarker; Photographic aging clock","Adult; Aged; Aged, 80 and over; Aging; Algorithms; Biomarkers; Deep Learning; Face; Female; Humans; Machine Learning; Middle Aged; Neural Networks, Computer; Skin Aging; Young Adult; biological marker; adult; aged; aging; algorithm; cutaneous parameters; face; female; human; machine learning; middle aged; physiology; very elderly; young adult","Impact Journals LLC","19454589","","","30414596","Article","Scopus","2-s2.0-85057278319"
"Hasan M.M.; Chopin J.P.; Laga H.; Miklavcic S.J.","Hasan, Md Mehedi (57191158500); Chopin, Joshua P. (56957993400); Laga, Hamid (8717100800); Miklavcic, Stanley J. (6602178232)","57191158500; 56957993400; 8717100800; 6602178232","Detection and analysis of wheat spikes using Convolutional Neural Networks","2018","Plant Methods","164","10.1186/s13007-018-0366-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056653363&doi=10.1186%2fs13007-018-0366-8&partnerID=40&md5=17440cb0cdde1cccae4fb663fd03565a","University of South Australia, Phenomics and Bioinformatics Research Centre, Mawson Lakes, Adelaide, 5095, Australia; Murdoch University, School of Engineering and Information Technology, Perth, 6150, WA, Australia","Hasan M.M., University of South Australia, Phenomics and Bioinformatics Research Centre, Mawson Lakes, Adelaide, 5095, Australia; Chopin J.P., University of South Australia, Phenomics and Bioinformatics Research Centre, Mawson Lakes, Adelaide, 5095, Australia; Laga H., Murdoch University, School of Engineering and Information Technology, Perth, 6150, WA, Australia; Miklavcic S.J., University of South Australia, Phenomics and Bioinformatics Research Centre, Mawson Lakes, Adelaide, 5095, Australia","Background: Field phenotyping by remote sensing has received increased interest in recent years with the possibility of achieving high-throughput analysis of crop fields. Along with the various technological developments, the application of machine learning methods for image analysis has enhanced the potential for quantitative assessment of a multitude of crop traits. For wheat breeding purposes, assessing the production of wheat spikes, as the grain-bearing organ, is a useful proxy measure of grain production. Thus, being able to detect and characterize spikes from images of wheat fields is an essential component in a wheat breeding pipeline for the selection of high yielding varieties. Results: We have applied a deep learning approach to accurately detect, count and analyze wheat spikes for yield estimation. We have tested the approach on a set of images of wheat field trial comprising 10 varieties subjected to three fertilizer treatments. The images have been captured over one season, using high definition RGB cameras mounted on a land-based imaging platform, and viewing the wheat plots from an oblique angle. A subset of in-field images has been accurately labeled by manually annotating all the spike regions. This annotated dataset, called SPIKE, is then used to train four region-based Convolutional Neural Networks (R-CNN) which take, as input, images of wheat plots, and accurately detect and count spike regions in each plot. The CNNs also output the spike density and a classification probability for each plot. Using the same R-CNN architecture, four different models were generated based on four different datasets of training and testing images captured at various growth stages. Despite the challenging field imaging conditions, e.g., variable illumination conditions, high spike occlusion, and complex background, the four R-CNN models achieve an average detection accuracy ranging from 88 to $$94\%$$ 94 % across different sets of test images. The most robust R-CNN model, which achieved the highest accuracy, is then selected to study the variation in spike production over 10 wheat varieties and three treatments. The SPIKE dataset and the trained CNN are the main contributions of this paper. Conclusion: With the availability of good training datasets such us the SPIKE dataset proposed in this article, deep learning techniques can achieve high accuracy in detecting and counting spikes from complex wheat field images. The proposed robust R-CNN model, which has been trained on spike images captured during different growth stages, is optimized for application to a wider variety of field scenarios. It accurately quantifies the differences in yield produced by the 10 varieties we have studied, and their respective responses to fertilizer treatment. We have also observed that the other R-CNN models exhibit more specialized performances. The data set and the R-CNN model, which we make publicly available, have the potential to greatly benefit plant breeders by facilitating the high throughput selection of high yielding varieties. © 2018 The Author(s).","Deep learning; Field imaging; Plant phenotyping; Spike detection; Statistical analysis","","BioMed Central Ltd.","17464811","","","","Article","Scopus","2-s2.0-85056653363"
"Li M.H.; Mestre T.A.; Fox S.H.; Taati B.","Li, Michael H. (56647154300); Mestre, Tiago A. (57202566818); Fox, Susan H. (7401924307); Taati, Babak (24470279600)","56647154300; 57202566818; 7401924307; 24470279600","Vision-based assessment of parkinsonism and levodopa-induced dyskinesia with pose estimation","2018","Journal of NeuroEngineering and Rehabilitation","72","10.1186/s12984-018-0446-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056275676&doi=10.1186%2fs12984-018-0446-z&partnerID=40&md5=3647d7f0dd5a6a8e0deae8045e6d6675","Toronto Rehabilitation Institute, University Health Network, 550 University Ave, Toronto, M5G 2A2, ON, Canada; Institute of Biomaterials and Biomedical Engineering, University of Toronto, 164 College St, Toronto, M5S 3G9, ON, Canada; Edmond J. Safra Program in Parkinson's Disease, Toronto Western Hospital, University Health Network, 399 Bathurst St, Toronto, M5T 2S8, ON, Canada; Ottawa Hospital Research Institute, 1053 Carling Ave, Ottawa, K1Y 4E9, ON, Canada; Division of Neurology, Department of Medicine, 1053 Carling Ave, Ottawa, K1Y 4E9, ON, Canada; Division of Neurology, University of Toronto, 200 Elizabeth St, Toronto, M5G 2C4, ON, Canada; Department of Computer Science, University of Toronto, 10 King's College Road, Toronto, M5S 3G4, ON, Canada","Li M.H., Toronto Rehabilitation Institute, University Health Network, 550 University Ave, Toronto, M5G 2A2, ON, Canada, Institute of Biomaterials and Biomedical Engineering, University of Toronto, 164 College St, Toronto, M5S 3G9, ON, Canada; Mestre T.A., Edmond J. Safra Program in Parkinson's Disease, Toronto Western Hospital, University Health Network, 399 Bathurst St, Toronto, M5T 2S8, ON, Canada, Ottawa Hospital Research Institute, 1053 Carling Ave, Ottawa, K1Y 4E9, ON, Canada, Division of Neurology, Department of Medicine, 1053 Carling Ave, Ottawa, K1Y 4E9, ON, Canada, Division of Neurology, University of Toronto, 200 Elizabeth St, Toronto, M5G 2C4, ON, Canada; Fox S.H., Edmond J. Safra Program in Parkinson's Disease, Toronto Western Hospital, University Health Network, 399 Bathurst St, Toronto, M5T 2S8, ON, Canada, Division of Neurology, University of Toronto, 200 Elizabeth St, Toronto, M5G 2C4, ON, Canada; Taati B., Toronto Rehabilitation Institute, University Health Network, 550 University Ave, Toronto, M5G 2A2, ON, Canada, Institute of Biomaterials and Biomedical Engineering, University of Toronto, 164 College St, Toronto, M5S 3G9, ON, Canada, Department of Computer Science, University of Toronto, 10 King's College Road, Toronto, M5S 3G4, ON, Canada","Background: Despite the effectiveness of levodopa for treatment of Parkinson's disease (PD), prolonged usage leads to development of motor complications, most notably levodopa-induced dyskinesia (LID). Persons with PD and their physicians must regularly modify treatment regimens and timing for optimal relief of symptoms. While standardized clinical rating scales exist for assessing the severity of PD symptoms, they must be administered by a trained medical professional and are inherently subjective. Computer vision is an attractive, non-contact, potential solution for automated assessment of PD, made possible by recent advances in computational power and deep learning algorithms. The objective of this paper was to evaluate the feasibility of vision-based assessment of parkinsonism and LID using pose estimation. Methods: Nine participants with PD and LID completed a levodopa infusion protocol, where symptoms were assessed at regular intervals using the Unified Dyskinesia Rating Scale (UDysRS) and Unified Parkinson's Disease Rating Scale (UPDRS). Movement trajectories of individual joints were extracted from videos of PD assessment using Convolutional Pose Machines, a pose estimation algorithm built with deep learning. Features of the movement trajectories (e.g. kinematic, frequency) were used to train random forests to detect and estimate the severity of parkinsonism and LID. Communication and drinking tasks were used to assess LID, while leg agility and toe tapping tasks were used to assess parkinsonism. Feature sets from tasks were also combined to predict total UDysRS and UPDRS Part III scores. Results: For LID, the communication task yielded the best results (detection: AUC = 0.930, severity estimation: r = 0.661). For parkinsonism, leg agility had better results for severity estimation (r = 0.618), while toe tapping was better for detection (AUC = 0.773). UDysRS and UPDRS Part III scores were predicted with r = 0.741 and 0.530, respectively. Conclusion: The proposed system provides insight into the potential of computer vision and deep learning for clinical application in PD and demonstrates promising performance for the future translation of deep learning to PD clinical practices. Convenient and objective assessment of PD symptoms will facilitate more frequent touchpoints between patients and clinicians, leading to better tailoring of treatment and quality of care. © 2018 The Author(s).","Computer vision; Deep learning; Levodopa-induced dyskinesia; Parkinsonism; Pose estimation","Aged; Algorithms; Antiparkinson Agents; Biomechanical Phenomena; Deep Learning; Dyskinesia, Drug-Induced; Female; Humans; Levodopa; Male; Middle Aged; Parkinson Disease; Video Recording; levodopa; antiparkinson agent; levodopa; adult; agility; Article; clinical article; clinical evaluation; clinical indicator; communication skill; convolutional pose machine; disease severity assessment; drug efficacy; feature extraction; female; human; illness trajectory; learning algorithm; levodopa-induced dyskinesia; male; motor dysfunction assessment; motor function test; parkinsonism; priority journal; random forest; self evaluation; symptom assessment; Unified Dyskinesia Rating Scale; Unified Parkinson Disease Rating Scale; validation process; videorecording; aged; algorithm; biomechanics; clinical trial; dyskinesia; middle aged; Parkinson disease; videorecording","BioMed Central Ltd.","17430003","","","30400914","Article","Scopus","2-s2.0-85056275676"
"Li T.; Chen J.; Hu C.; Ma Y.; Wu Z.; Wan W.; Huang Y.; Jia F.; Gong C.; Wan S.; Li L.","Li, Tianpeng (57200214789); Chen, Jiansheng (55717653300); Hu, Chunhua (55723101200); Ma, Yu (57192714561); Wu, Zhiyuan (57204237967); Wan, Weitao (57200216698); Huang, Yiqing (57204238513); Jia, Fuming (57194130431); Gong, Chen (57213762416); Wan, Sen (56235892900); Li, Luming (7501447770)","57200214789; 55717653300; 55723101200; 57192714561; 57204237967; 57200216698; 57204238513; 57194130431; 57213762416; 56235892900; 7501447770","Automatic timed up-and-go sub-task segmentation for Parkinson's disease patients using video-based activity classification","2018","IEEE Transactions on Neural Systems and Rehabilitation Engineering","50","10.1109/TNSRE.2018.2875738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055024215&doi=10.1109%2fTNSRE.2018.2875738&partnerID=40&md5=2d5f2ce2cb2e9cf274b26a6240213994","Department of Electronic Engineering, Tsinghua University, Beijing, 100084, China; School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Tsinghua University, Beijing, 100084, China; Tsinghua University, Yuquan Hospital, Beijing, 100040, China; National Engineering Laboratory for Neuromodulation, PrecisionMedicine and Healthcare Research Center, Center of Epilepsy, School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, China; Beijing Institute for Brain Disorders, Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Beijing, 100084, China","Li T., Department of Electronic Engineering, Tsinghua University, Beijing, 100084, China; Chen J., Department of Electronic Engineering, Tsinghua University, Beijing, 100084, China; Hu C., School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Tsinghua University, Beijing, 100084, China; Ma Y., Tsinghua University, Yuquan Hospital, Beijing, 100040, China; Wu Z., Department of Electronic Engineering, Tsinghua University, Beijing, 100084, China; Wan W., Department of Electronic Engineering, Tsinghua University, Beijing, 100084, China; Huang Y., Department of Electronic Engineering, Tsinghua University, Beijing, 100084, China; Jia F., School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Tsinghua University, Beijing, 100084, China; Gong C., School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Tsinghua University, Beijing, 100084, China; Wan S., School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Tsinghua University, Beijing, 100084, China; Li L., National Engineering Laboratory for Neuromodulation, PrecisionMedicine and Healthcare Research Center, Center of Epilepsy, School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, China, Beijing Institute for Brain Disorders, Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Beijing, 100084, China","The timed up-and-go (TUG) test has been widely accepted as a standard assessment for measuring the basic functional mobility of patients with Parkinson's disease. Several basic mobility sub-tasks 'Sit,' 'Sit-to-Stand,' 'Walk,' 'Turn,' 'Walk-Back,' and 'Sit-Back' are included in a TUG test. It has been shown that the time costs of these sub-tasks are useful clinical parameters for the assessment of Parkinson's disease. Several automatic methods have been proposed to segment and time these sub-tasks in a TUG test. However, these methods usually require either well-controlled environments for the TUG video recording or information from special devices, such as wearable inertial sensors, ambient sensors, or depth cameras. In this paper, an automatic TUG sub-task segmentation method using video-based activity classification is proposed and validated in a study with 24 Parkinson's disease patients. Videos used in this paper are recorded in semi-controlled environments with various backgrounds. The state-of-the-art deep learning-base 2-D human pose estimation technologies are used for feature extraction. A support vector machine and a long short-term memory network are then used for the activity classification and the subtask segmentation. Our method can be used to automatically acquire clinical parameters for the assessment of Parkinson's disease using TUG videos-only, leading to the possibility of remote monitoring of the patients' condition. © 2018 IEEE.","human pose estimation; Parkinson's disease; sub-task segmentation; Timed up-and-go","Aged; Algorithms; Biomechanical Phenomena; Female; Humans; Male; Middle Aged; Mobility Limitation; Neural Networks (Computer); Parkinson Disease; Posture; Reproducibility of Results; Support Vector Machine; Video Recording; Walking; Cameras; Deep learning; Functional assessment; Hospitals; Long short-term memory; Remote patient monitoring; Support vector machines; Video recording; Human pose estimations; Parkinson; Parkinson's disease; Subtasks; Timed up and go; Two-dimensional displays; Video sequences; algorithm; Article; clinical article; human; image segmentation; motor dysfunction; Parkinson disease; short term memory; support vector machine; timed up and go test; videorecording; aged; algorithm; artificial neural network; biomechanics; body position; classification; female; male; middle aged; Parkinson disease; pathophysiology; reproducibility; videorecording; walking; walking difficulty; Wearable sensors","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","30334764","Article","Scopus","2-s2.0-85055024215"
"Zhang Y.; Saxe A.M.; Advani M.S.; Lee A.A.","Zhang, Yao (57211360254); Saxe, Andrew M. (34572994500); Advani, Madhu S. (55629137900); Lee, Alpha A. (55578168200)","57211360254; 34572994500; 55629137900; 55578168200","Energy–entropy competition and the effectiveness of stochastic gradient descent in machine learning","2018","Molecular Physics","31","10.1080/00268976.2018.1483535","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048874289&doi=10.1080%2f00268976.2018.1483535&partnerID=40&md5=5178163e1d6c36d6cea9106095b8527c","Cavendish Laboratory, University of Cambridge, Cambridge, United Kingdom; Center for Brain Science, Harvard University, Cambridge, MA, United States","Zhang Y., Cavendish Laboratory, University of Cambridge, Cambridge, United Kingdom; Saxe A.M., Center for Brain Science, Harvard University, Cambridge, MA, United States; Advani M.S., Center for Brain Science, Harvard University, Cambridge, MA, United States; Lee A.A., Cavendish Laboratory, University of Cambridge, Cambridge, United Kingdom","Finding parameters that minimise a loss function is at the core of many machine learning methods. The Stochastic Gradient Descent (SGD) algorithm is widely used and delivers state-of-the-art results for many problems. Nonetheless, SGD typically cannot find the global minimum, thus its empirical effectiveness is hitherto mysterious. We derive a correspondence between parameter inference and free energy minimisation in statistical physics. The degree of undersampling plays the role of temperature. Analogous to the energy–entropy competition in statistical physics, wide but shallow minima can be optimal if the system is undersampled, as is typical in many applications. Moreover, we show that the stochasticity in the algorithm has a non-trivial correlation structure which systematically biases it towards wide minima. We illustrate our argument with two prototypical models: image classification using deep learning and a linear neural network where we can analytically reveal the relationship between entropy and out-of-sample error. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","energy landscape; high-dimensional inference; Machine learning; neural network","Artificial intelligence; Entropy; Free energy; Global optimization; Learning systems; Neural networks; Statistical Physics; Stochastic systems; Correlation structure; Energy landscape; High dimensional inference; Linear neural network; Machine learning methods; Out-of-sample errors; Parameter inference; Stochastic gradient descent; Deep learning","Taylor and Francis Ltd.","00268976","","MOPHA","","Article","Scopus","2-s2.0-85048874289"
"Liang M.; Ye T.; Fu H.","Liang, Muxuan (56779426100); Ye, Ting (57203126057); Fu, Haoda (14065756800)","56779426100; 57203126057; 14065756800","Estimating individualized optimal combination therapies through outcome weighted deep learning algorithms","2018","Statistics in Medicine","9","10.1002/sim.7902","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050582097&doi=10.1002%2fsim.7902&partnerID=40&md5=bffdb7107df3b12ca821f6d5a41d68cd","Department of Statistics, University of Wisconsin-Madison, Madison, WI, United States; Eli Lilly and Company, Indianapolis, IN, United States","Liang M., Department of Statistics, University of Wisconsin-Madison, Madison, WI, United States; Ye T., Department of Statistics, University of Wisconsin-Madison, Madison, WI, United States; Fu H., Eli Lilly and Company, Indianapolis, IN, United States","With the advancement in drug development, multiple treatments are available for a single disease. Patients can often benefit from taking multiple treatments simultaneously. For example, patients in Clinical Practice Research Datalink with chronic diseases such as type 2 diabetes can receive multiple treatments simultaneously. Therefore, it is important to estimate what combination therapy from which patients can benefit the most. However, to recommend the best treatment combination is not a single label but a multilabel classification problem. In this paper, we propose a novel outcome weighted deep learning algorithm to estimate individualized optimal combination therapy. The Fisher consistency of the proposed loss function under certain conditions is also provided. In addition, we extend our method to a family of loss functions, which allows adaptive changes based on treatment interactions. We demonstrate the performance of our methods through simulations and real data analysis. © 2018 John Wiley & Sons, Ltd.","deep learning; individualized treatment recommendation; multilabel classification; outcome weighted learning; precision medicine","Algorithms; Decision Support Techniques; Drug Therapy, Combination; Humans; Machine Learning; Models, Statistical; Precision Medicine; Statistics as Topic; Stochastic Processes; Treatment Outcome; Article; clinical research; data analysis; human; learning algorithm; mathematical computing; non insulin dependent diabetes mellitus; personalized medicine; simulation; stochastic model; algorithm; combination drug therapy; decision support system; machine learning; Markov chain; procedures; statistical model; statistics; treatment outcome","John Wiley and Sons Ltd","02776715","","SMEDD","30014497","Article","Scopus","2-s2.0-85050582097"
"Staartjes V.E.; Serra C.; Muscas G.; Maldaner N.; Akeret K.; van Niftrik C.H.B.; Fierstra J.; Holzmann D.; Regli L.","Staartjes, Victor E. (57190836125); Serra, Carlo (50263014800); Muscas, Giovanni (57337381500); Maldaner, Nicolai (56444482700); Akeret, Kevin (57203789230); van Niftrik, Christiaan H.B. (57087287200); Fierstra, Jorn (35777972500); Holzmann, David (55949041100); Regli, Luca (7004240836)","57190836125; 50263014800; 57337381500; 56444482700; 57203789230; 57087287200; 35777972500; 55949041100; 7004240836","Utility of deep neural networks in predicting gross-total resection after transsphenoidal surgery for pituitary adenoma: A pilot study","2018","Neurosurgical Focus","44","10.3171/2018.8.FOCUS18243","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055906408&doi=10.3171%2f2018.8.FOCUS18243&partnerID=40&md5=47468898d1cd89c093eb476a452521c9","Department of Neurosurgery, Clinical Neuroscience Center, University Hospital Zurich, University of Zurich, Switzerland; Department of Neurosurgery, Tuscany School of Neurosurgery, University of Firenze, Italy; Department of Otorhinolaryngology, Head and Neck Surgery, University Hospital Zurich, University of Zurich, Switzerland","Staartjes V.E., Department of Neurosurgery, Clinical Neuroscience Center, University Hospital Zurich, University of Zurich, Switzerland; Serra C., Department of Neurosurgery, Clinical Neuroscience Center, University Hospital Zurich, University of Zurich, Switzerland; Muscas G., Department of Neurosurgery, Tuscany School of Neurosurgery, University of Firenze, Italy; Maldaner N., Department of Neurosurgery, Clinical Neuroscience Center, University Hospital Zurich, University of Zurich, Switzerland; Akeret K., Department of Neurosurgery, Clinical Neuroscience Center, University Hospital Zurich, University of Zurich, Switzerland; van Niftrik C.H.B., Department of Neurosurgery, Clinical Neuroscience Center, University Hospital Zurich, University of Zurich, Switzerland; Fierstra J., Department of Neurosurgery, Clinical Neuroscience Center, University Hospital Zurich, University of Zurich, Switzerland; Holzmann D., Department of Otorhinolaryngology, Head and Neck Surgery, University Hospital Zurich, University of Zurich, Switzerland; Regli L., Department of Neurosurgery, Clinical Neuroscience Center, University Hospital Zurich, University of Zurich, Switzerland","OBJECTIVE Gross-total resection (GTR) is often the primary surgical goal in transsphenoidal surgery for pituitary adenoma. Existing classifications are effective at predicting GTR but are often hampered by limited discriminatory ability in moderate cases and by poor interrater agreement. Deep learning, a subset of machine learning, has recently established itself as highly effective in forecasting medical outcomes. In this pilot study, the authors aimed to evaluate the utility of using deep learning to predict GTR after transsphenoidal surgery for pituitary adenoma. METHODS Data from a prospective registry were used. The authors trained a deep neural network to predict GTR from 16 preoperatively available radiological and procedural variables. Class imbalance adjustment, cross-validation, and random dropout were applied to prevent overfitting and ensure robustness of the predictive model. The authors subsequently compared the deep learning model to a conventional logistic regression model and to the Knosp classification as a gold standard. RESULTS Overall, 140 patients who underwent endoscopic transsphenoidal surgery were included. GTR was achieved in 95 patients (68%), with a mean extent of resection of 96.8% ± 10.6%. Intraoperative high-field MRI was used in 116 (83%) procedures. The deep learning model achieved excellent area under the curve (AUC; 0.96), accuracy (91%), sensitivity (94%), and specificity (89%). This represents an improvement in comparison with the Knosp classification (AUC: 0.87, accuracy: 81%, sensitivity: 92%, specificity: 70%) and a statistically significant improvement in comparison with logistic regression (AUC: 0.86, accuracy: 82%, sensitivity: 81%, specificity: 83%) (all p < 0.001). CONCLUSIONS In this pilot study, the authors demonstrated the utility of applying deep learning to preoperatively predict the likelihood of GTR with excellent performance. Further training and validation in a prospective multicentric cohort will enable the development of an easy-to-use interface for use in clinical practice. © AANS 2018.","Deep learning; Deep neural network; Outcome prediction; Pituitary adenoma; Pituitary surgery; Transsphenoidal surgery","Adenoma; Adult; Aged; Deep Learning; Female; Humans; Male; Middle Aged; Neural Networks (Computer); Neuroendoscopy; Pilot Projects; Pituitary Neoplasms; Predictive Value of Tests; Sphenoid Bone; adenoma; adult; aged; artificial neural network; diagnostic imaging; female; human; hypophysis tumor; male; middle aged; neuroendoscopy; pilot study; predictive value; sphenoid","American Association of Neurological Surgeons","10920684","","","30453454","Article","Scopus","2-s2.0-85055906408"
"Stewart J.; Sprivulis P.; Dwivedi G.","Stewart, Jonathon (7404792512); Sprivulis, Peter (6604096056); Dwivedi, Girish (10340469500)","7404792512; 6604096056; 10340469500","Artificial intelligence and machine learning in emergency medicine","2018","EMA - Emergency Medicine Australasia","95","10.1111/1742-6723.13145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050483873&doi=10.1111%2f1742-6723.13145&partnerID=40&md5=bbbf8ee27d22b507246608142165808d","Royal Perth Hospital, Perth, WA, Australia","Stewart J., Royal Perth Hospital, Perth, WA, Australia; Sprivulis P., Royal Perth Hospital, Perth, WA, Australia; Dwivedi G., Royal Perth Hospital, Perth, WA, Australia","Interest in artificial intelligence (AI) research has grown rapidly over the past few years, in part thanks to the numerous successes of modern machine learning techniques such as deep learning, the availability of large datasets and improvements in computing power. AI is proving to be increasingly applicable to healthcare and there is a growing list of tasks where algorithms have matched or surpassed physician performance. Despite the successes there remain significant concerns and challenges surrounding algorithm opacity, trust and patient data security. Notwithstanding these challenges, AI technologies will likely become increasingly integrated into emergency medicine in the coming years. This perspective presents an overview of current AI research relevant to emergency medicine. © 2018 Australasian College for Emergency Medicine","artificial intelligence; deep learning; emergency medicine; machine learning","Emergency Medicine; Humans; Machine Learning; Outcome Assessment (Health Care); Precision Medicine; adult; article; artificial intelligence; emergency medicine; human; machine learning; patient coding; physician; trust; emergency medicine; machine learning; outcome assessment; personalized medicine; procedures; standards; trends","Blackwell Publishing","17426731","","EMAMC","30014578","Article","Scopus","2-s2.0-85050483873"
"Yang Y.; Yan L.-F.; Zhang X.; Han Y.; Nan H.-Y.; Hu Y.-C.; Hu B.; Yan S.-L.; Zhang J.; Cheng D.-L.; Ge X.-W.; Cui G.-B.; Zhao D.; Wang W.","Yang, Yang (57223139185); Yan, Lin-Feng (36169657100); Zhang, Xin (55569925100); Han, Yu (56410204700); Nan, Hai-Yan (36169354900); Hu, Yu-Chuan (56512576000); Hu, Bo (57200790368); Yan, Song-Lin (57204788925); Zhang, Jin (57200801144); Cheng, Dong-Liang (57204791690); Ge, Xiang-Wei (57204786123); Cui, Guang-Bin (9746835700); Zhao, Di (56701350400); Wang, Wen (7501758370)","57223139185; 36169657100; 55569925100; 56410204700; 36169354900; 56512576000; 57200790368; 57204788925; 57200801144; 57204791690; 57204786123; 9746835700; 56701350400; 7501758370","Glioma grading on conventional MR images: A deep learning study with transfer learning","2018","Frontiers in Neuroscience","202","10.3389/fnins.2018.00804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057197740&doi=10.3389%2ffnins.2018.00804&partnerID=40&md5=becdc2fecf6cda72916d8e8855ab66c5","Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Computer Network Information Center, Chinese Academy of Sciences, Beijing, China; Student Brigade, Fourth Military Medical University, Xi’an, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","Yang Y., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Yan L.-F., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Zhang X., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Han Y., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Nan H.-Y., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Hu Y.-C., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Hu B., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Yan S.-L., Computer Network Information Center, Chinese Academy of Sciences, Beijing, China; Zhang J., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Cheng D.-L., Student Brigade, Fourth Military Medical University, Xi’an, China; Ge X.-W., Student Brigade, Fourth Military Medical University, Xi’an, China; Cui G.-B., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China; Zhao D., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Wang W., Functional and Molecular Imaging Key Lab. of Shaanxi Province, Department of Radiology, Tangdu Hospital, Fourth Military Medical University, Xi’an, China","Background: Accurate glioma grading before surgery is of the utmost importance in treatment planning and prognosis prediction. But previous studies on magnetic resonance imaging (MRI) images were not effective enough. According to the remarkable performance of convolutional neural network (CNN) in medical domain, we hypothesized that a deep learning algorithm can achieve high accuracy in distinguishing the World Health Organization (WHO) low grade and high grade gliomas. Methods: One hundred and thirteen glioma patients were retrospectively included. Tumor images were segmented with a rectangular region of interest (ROI), which contained about 80% of the tumor. Then, 20% data were randomly selected and leaved out at patient-level as test dataset. AlexNet and GoogLeNet were both trained from scratch and fine-tuned from models that pre-trained on the large scale natural image database, ImageNet, to magnetic resonance images. The classification task was evaluated with five-fold cross-validation (CV) on patient-level split. Results: The performance measures, including validation accuracy, test accuracy and test area under curve (AUC), averaged from five-fold CV of GoogLeNet which trained from scratch were 0.867, 0.909, and 0.939, respectively. With transfer learning and fine-tuning, better performances were obtained for both AlexNet and GoogLeNet, especially for AlexNet. Meanwhile, GoogLeNet performed better than AlexNet no matter trained from scratch or learned from pre-trained model. Conclusion: In conclusion, we demonstrated that the application of CNN, especially trained with transfer learning and fine-tuning, to preoperative glioma grading improves the performance, compared with either the performance of traditional machine learning method based on hand-crafted features, or even the CNNs trained from scratch. Copyright © 2018 Yang, Yan, Zhang, Han, Nan, Hu, Hu, Yan, Zhang, Cheng, Ge, Cui, Zhao and Wang.","Convolutional neural network (CNN); Deep learning; Glioma grading; Magnetic resonance imaging (MRI); Transfer learning","accuracy; adolescent; adult; aged; Article; artificial neural network; cancer grading; child; clinical evaluation; cohort analysis; convolutional neural network; deep learning algorithm; female; glioma; human; learning algorithm; major clinical study; male; nuclear magnetic resonance imaging; prediction; retrospective study; risk reduction; sensitivity and specificity; temporal lobe; transfer of learning","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85057197740"
"Akhavan Aghdam M.; Sharifi A.; Pedram M.M.","Akhavan Aghdam, Maryam (57201942222); Sharifi, Arash (24725517500); Pedram, Mir Mohsen (55389555600)","57201942222; 24725517500; 55389555600","Combination of rs-fMRI and sMRI Data to Discriminate Autism Spectrum Disorders in Young Children Using Deep Belief Network","2018","Journal of Digital Imaging","103","10.1007/s10278-018-0093-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046545759&doi=10.1007%2fs10278-018-0093-8&partnerID=40&md5=178a2d34f2589f4bb12a2e77f650366e","Department of Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran; Department of Electrical and Computer Engineering, Kharazmi University, Tehran, Iran","Akhavan Aghdam M., Department of Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran; Sharifi A., Department of Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran; Pedram M.M., Department of Electrical and Computer Engineering, Kharazmi University, Tehran, Iran","In recent years, the use of advanced magnetic resonance (MR) imaging methods such as functional magnetic resonance imaging (fMRI) and structural magnetic resonance imaging (sMRI) has recorded a great increase in neuropsychiatric disorders. Deep learning is a branch of machine learning that is increasingly being used for applications of medical image analysis such as computer-aided diagnosis. In a bid to classify and represent learning tasks, this study utilized one of the most powerful deep learning algorithms (deep belief network (DBN)) for the combination of data from Autism Brain Imaging Data Exchange I and II (ABIDE I and ABIDE II) datasets. The DBN was employed so as to focus on the combination of resting-state fMRI (rs-fMRI), gray matter (GM), and white matter (WM) data. This was done based on the brain regions that were defined using the automated anatomical labeling (AAL), in order to classify autism spectrum disorders (ASDs) from typical controls (TCs). Since the diagnosis of ASD is much more effective at an early age, only 185 individuals (116 ASD and 69 TC) ranging in age from 5 to 10 years were included in this analysis. In contrast, the proposed method is used to exploit the latent or abstract high-level features inside rs-fMRI and sMRI data while the old methods consider only the simple low-level features extracted from neuroimages. Moreover, combining multiple data types and increasing the depth of DBN can improve classification accuracy. In this study, the best combination comprised rs-fMRI, GM, and WM for DBN of depth 3 with 65.56% accuracy (sensitivity = 84%, specificity = 32.96%, F1 score = 74.76%) obtained via 10-fold cross-validation. This result outperforms previously presented methods on ABIDE I dataset. © 2018, Society for Imaging Informatics in Medicine.","Autism spectrum disorder; Deep belief network; Gray matter; rs-fMRI; sMRI; White matter","Autism Spectrum Disorder; Brain; Brain Mapping; Child; Child, Preschool; Diagnosis, Differential; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Sensitivity and Specificity; Brain; Brain mapping; Classification (of information); Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Diseases; Electronic data interchange; Learning algorithms; Magnetic resonance imaging; Magnetism; Resonance; Spectrum analysis; Autism spectrum disorders; Deep belief networks; Gray matter; rs-fMRI; sMRI; White matter; autism; brain; brain mapping; child; computer assisted diagnosis; diagnostic imaging; differential diagnosis; female; human; machine learning; male; nuclear magnetic resonance imaging; pathophysiology; preschool child; procedures; sensitivity and specificity; Deep learning","Springer New York LLC","08971889","","JDIME","29736781","Article","Scopus","2-s2.0-85046545759"
"Poplin R.; Chang P.-C.; Alexander D.; Schwartz S.; Colthurst T.; Ku A.; Newburger D.; Dijamco J.; Nguyen N.; Afshar P.T.; Gross S.S.; Dorfman L.; McLean C.Y.; Depristo M.A.","Poplin, Ryan (37026985800); Chang, Pi-Chuan (57202510552); Alexander, David (34767889600); Schwartz, Scott (57204155458); Colthurst, Thomas (6506813384); Ku, Alexander (57204152670); Newburger, Dan (24385282700); Dijamco, Jojo (57204155211); Nguyen, Nam (57213920942); Afshar, Pegah T (36165443000); Gross, Sam S (58376178400); Dorfman, Lizzie (57204155128); McLean, Cory Y (25637321300); Depristo, Mark A (6602278308)","37026985800; 57202510552; 34767889600; 57204155458; 6506813384; 57204152670; 24385282700; 57204155211; 57213920942; 36165443000; 58376178400; 57204155128; 25637321300; 6602278308","A universal snp and small-indel variant caller using deep neural networks","2018","Nature Biotechnology","575","10.1038/nbt.4235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054719134&doi=10.1038%2fnbt.4235&partnerID=40&md5=5afa1861108b64a211b952108a7b99e9","Verily Life Sciences, Mountain View, CA, United States; Google Inc., Mountain View, CA, United States","Poplin R., Verily Life Sciences, Mountain View, CA, United States, Google Inc., Mountain View, CA, United States; Chang P.-C., Google Inc., Mountain View, CA, United States; Alexander D., Google Inc., Mountain View, CA, United States; Schwartz S., Google Inc., Mountain View, CA, United States; Colthurst T., Google Inc., Mountain View, CA, United States; Ku A., Google Inc., Mountain View, CA, United States; Newburger D., Verily Life Sciences, Mountain View, CA, United States; Dijamco J., Verily Life Sciences, Mountain View, CA, United States; Nguyen N., Verily Life Sciences, Mountain View, CA, United States; Afshar P.T., Verily Life Sciences, Mountain View, CA, United States; Gross S.S., Verily Life Sciences, Mountain View, CA, United States; Dorfman L., Verily Life Sciences, Mountain View, CA, United States, Google Inc., Mountain View, CA, United States; McLean C.Y., Verily Life Sciences, Mountain View, CA, United States, Google Inc., Mountain View, CA, United States; Depristo M.A., Verily Life Sciences, Mountain View, CA, United States, Google Inc., Mountain View, CA, United States","Despite rapid advances in sequencing technologies, accurately calling genetic variants present in an individual genome from billions of short, errorful sequence reads remains challenging. Here we show that a deep convolutional neural network can call genetic variation in aligned next-generation sequencing read data by learning statistical relationships between images of read pileups around putative variant and true genotype calls. The approach, called DeepVariant, outperforms existing state-of-the-art tools. The learned model generalizes across genome builds and mammalian species, allowing nonhuman sequencing projects to benefit from the wealth of human ground-truth data. We further show that DeepVariant can learn to call variants in a variety of sequencing technologies and experimental designs, including deep whole genomes from 10X Genomics and Ion Ampliseq exomes, highlighting the benefits of using more automated and generalizable techniques for variant calling. © 2018, Nature Publishing Group. All rights reserved.","","Animals; DNA Mutational Analysis; Genome, Human; Genomics; Genotype; High-Throughput Nucleotide Sequencing; Humans; INDEL Mutation; Mammals; Neural Networks (Computer); Polymorphism, Single Nucleotide; Sequence Analysis, DNA; Software; Genes; Mammals; Neural networks; Convolutional neural network; Genetic variants; Genetic variation; Ground truth data; Mammalian species; Next-generation sequencing; State of the art; Statistical relationship; deep neural network; deepvariant; exome; experimental design; female; genetic variability; genetic variation; human; human genome; indel mutation; Letter; machine learning; male; next generation sequencing; priority journal; single nucleotide polymorphism; animal; artificial neural network; dna mutational analysis; DNA sequence; genetics; genomics; genotype; high throughput sequencing; human genome; indel mutation; mammal; software; Deep neural networks","Nature Publishing Group","10870156","","NABIF","30247488","Article","Scopus","2-s2.0-85054719134"
"Lin W.; Tong T.; Gao Q.; Guo D.; Du X.; Yang Y.; Guo G.; Xiao M.; Du M.; Qu X.","Lin, Weiming (57204792632); Tong, Tong (55625986800); Gao, Qinquan (55598017400); Guo, Di (26636947000); Du, Xiaofeng (29367449500); Yang, Yonggui (57201951023); Guo, Gang (54944381200); Xiao, Min (57204787369); Du, Min (36463370900); Qu, Xiaobo (22958150800)","57204792632; 55625986800; 55598017400; 26636947000; 29367449500; 57201951023; 54944381200; 57204787369; 36463370900; 22958150800","Convolutional neural networks-based MRI image analysis for the Alzheimer’s disease prediction from mild cognitive impairment","2018","Frontiers in Neuroscience","250","10.3389/fnins.2018.00777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057167169&doi=10.3389%2ffnins.2018.00777&partnerID=40&md5=888a4552cd9e039d16ad3d927b5840a1","College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; School of Opto-Electronic and Communication Engineering, Xiamen University of Technology, Xiamen, China; Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou, China; Imperial Vision Technology, Fuzhou, China; School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China; Department of Radiology, Xiamen 2nd Hospital, Xiamen, China; Fujian Provincial Key Laboratory of Eco-Industrial Green Technology, Nanping, China; Department of Electronic Science, Xiamen University, Xiamen, China","Lin W., College of Physics and Information Engineering, Fuzhou University, Fuzhou, China, School of Opto-Electronic and Communication Engineering, Xiamen University of Technology, Xiamen, China, Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou, China; Tong T., Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou, China, Imperial Vision Technology, Fuzhou, China; Gao Q., College of Physics and Information Engineering, Fuzhou University, Fuzhou, China, Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou, China, Imperial Vision Technology, Fuzhou, China; Guo D., School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China; Du X., School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, China; Yang Y., Department of Radiology, Xiamen 2nd Hospital, Xiamen, China; Guo G., Department of Radiology, Xiamen 2nd Hospital, Xiamen, China; Xiao M., School of Opto-Electronic and Communication Engineering, Xiamen University of Technology, Xiamen, China; Du M., College of Physics and Information Engineering, Fuzhou University, Fuzhou, China, Fujian Provincial Key Laboratory of Eco-Industrial Green Technology, Nanping, China; Qu X., Department of Electronic Science, Xiamen University, Xiamen, China","Mild cognitive impairment (MCI) is the prodromal stage of Alzheimer’s disease (AD). Identifying MCI subjects who are at high risk of converting to AD is crucial for effective treatments. In this study, a deep learning approach based on convolutional neural networks (CNN), is designed to accurately predict MCI-to-AD conversion with magnetic resonance imaging (MRI) data. First, MRI images are prepared with age-correction and other processing. Second, local patches, which are assembled into 2.5 dimensions, are extracted from these images. Then, the patches from AD and normal controls (NC) are used to train a CNN to identify deep learning features of MCI subjects. After that, structural brain image features are mined with FreeSurfer to assist CNN. Finally, both types of features are fed into an extreme learning machine classifier to predict the AD conversion. The proposed approach is validated on the standardized MRI datasets from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) project. This approach achieves an accuracy of 79.9% and an area under the receiver operating characteristic curve (AUC) of 86.1% in leave-one-out cross validations. Compared with other state-of-the-art methods, the proposed one outperforms others with higher accuracy and AUC, while keeping a good balance between the sensitivity and specificity. Results demonstrate great potentials of the proposed CNN-based approach for the prediction of MCI-to-AD conversion with solely MRI data. Age correction and assisted structural brain image features can boost the prediction performance of CNN. Copyright © 2018 Lin, Tong, Gao, Guo, Du, Yang, Guo, Xiao, Du, Qu and The Alzheimer’s Disease Neuroimaging Initiative.","Alzheimer’s disease; Convolutional neural networks; Deep learning; Magnetic resonance imaging; Mild cognitive impairment","adult; aged; Alzheimer disease; area under the curve; Article; artificial neural network; brain region; cognitive defect; controlled study; diagnostic accuracy; disease severity; female; high risk patient; human; image analysis; image processing; learning; machine learning; major clinical study; male; neuroimaging; nuclear magnetic resonance imaging; sensitivity and specificity; very elderly","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85057167169"
"Mikkonen H.G.; van de Graaff R.; Mikkonen A.T.; Clarke B.O.; Dasika R.; Wallis C.J.; Reichman S.M.","Mikkonen, Hannah G. (57192961853); van de Graaff, Robert (6508386706); Mikkonen, Antti T. (57190032161); Clarke, Bradley O. (34167665800); Dasika, Raghava (6507327822); Wallis, Christian J. (57192959089); Reichman, Suzie M. (7003642605)","57192961853; 6508386706; 57190032161; 34167665800; 6507327822; 57192959089; 7003642605","Environmental and anthropogenic influences on ambient background concentrations of fluoride in soil","2018","Environmental Pollution","37","10.1016/j.envpol.2018.07.083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054690263&doi=10.1016%2fj.envpol.2018.07.083&partnerID=40&md5=2cd337356637e4cb6e3ce127d63743e4","School of Engineering, RMIT University, Melbourne, Victoria, Australia; Centre for Environmental Sustainability and Remediation, RMIT University, Victoria, Australia; CDM Smith, Richmond, Victoria, Australia; van de Graaff & Associates Pty Ltd, Mitcham, Victoria, Australia; School of Science, RMIT University, Victoria, Australia; Australian Contaminated Land Consultants Association, Victoria, Australia","Mikkonen H.G., School of Engineering, RMIT University, Melbourne, Victoria, Australia, Centre for Environmental Sustainability and Remediation, RMIT University, Victoria, Australia, CDM Smith, Richmond, Victoria, Australia; van de Graaff R., van de Graaff & Associates Pty Ltd, Mitcham, Victoria, Australia; Mikkonen A.T., CDM Smith, Richmond, Victoria, Australia; Clarke B.O., Centre for Environmental Sustainability and Remediation, RMIT University, Victoria, Australia, School of Science, RMIT University, Victoria, Australia; Dasika R., Australian Contaminated Land Consultants Association, Victoria, Australia; Wallis C.J., CDM Smith, Richmond, Victoria, Australia; Reichman S.M., School of Engineering, RMIT University, Melbourne, Victoria, Australia, Centre for Environmental Sustainability and Remediation, RMIT University, Victoria, Australia","Excess exposure to fluoride causes substantive health burden in humans and livestock globally. However, few studies have assessed the distribution and controls of variability of ambient background concentrations of fluoride in soil. Ambient background concentrations of fluoride in soil were collated for Greater Melbourne, Greater Geelong, Ballarat and Mitchell in Victoria, Australia (n = 1005). Correlation analysis and machine learning techniques were used to identify environmental and anthropogenic influences of fluoride variability in soil. Sub-soils (>0.3 m deep), in some areas overlying siltstone and sandstone, and to a lesser extent, overlying basalt, were naturally enriched with fluoride at concentrations above ecological thresholds for grazing animals. Soil fluoride enrichment was predominantly influenced by parent material (mineralogy), precipitation (illuviation), leaching during palaeoclimates and marine inputs. Industrial air pollution did not significantly influence ambient background concentrations of fluoride at a regional scale. However, agricultural practices (potentially the use of phosphate fertilisers) were indicated to have resulted in added fluoride to surface soils overlying sediments. Geospatial variables alone were not sufficient to accurately model ambient background soil fluoride concentrations. A multiple regression model based on soil chemistry and parent material was shown to accurately predict ambient background fluoride concentrations in soils and support assessment of fluoride enrichment in the environment. Few studies have assessed environmental/anthropogenic controls of background fluoride concentrations at a regional scale (e.g. not associated with a key point source of contamination). For the first time, a geochemical regression tree model for the estimation of ambient background fluoride concentrations in soil has been developed and is shown to have promise for application for predicting areas of fluoride enrichment/risk in soils. © 2018 Elsevier Ltd","Australia; Background; Cubist; Fluoride; Regression tree model; Soil","Agriculture; Environmental Monitoring; Fertilizers; Fluorides; Humans; Phosphates; Soil; Soil Pollutants; Victoria; Australia; Ballarat; Geelong; Melbourne; Victoria [Australia]; Animalia; Fluorine compounds; Forestry; Learning systems; Minerals; Regression analysis; Sediments; Soils; fluoride; fertilizer; fluoride; fluorophosphate; phosphate; Australia; Background; Cubist; Fluoride; Regression tree models; anthropogenic effect; concentration (composition); enrichment; environmental factor; fluoride; machine learning; pollutant source; pollution monitoring; soil pollution; air pollution; Alberta; Article; basalt; controlled study; fluid balance; leaching; paleoclimate; precipitation; rock; soil chemistry; soil pollution; surface soil; Victoria; weathering; agriculture; analysis; chemistry; environmental monitoring; human; soil; soil pollutant; Fluoride minerals","Elsevier Ltd","02697491","","ENPOE","30082154","Article","Scopus","2-s2.0-85054690263"
"Schwemmer M.A.; Skomrock N.D.; Sederberg P.B.; Ting J.E.; Sharma G.; Bockbrader M.A.; Friedenberg D.A.","Schwemmer, Michael A. (37085444100); Skomrock, Nicholas D. (57192917864); Sederberg, Per B. (6506963719); Ting, Jordyn E. (57213194243); Sharma, Gaurav (57208200916); Bockbrader, Marcia A. (6507484812); Friedenberg, David A. (55961372800)","37085444100; 57192917864; 6506963719; 57213194243; 57208200916; 6507484812; 55961372800","Meeting brain–computer interface user performance expectations using a deep neural network decoding framework","2018","Nature Medicine","101","10.1038/s41591-018-0171-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053818943&doi=10.1038%2fs41591-018-0171-y&partnerID=40&md5=e30ba25cb91aaa8e560a92d81f19c6ee","Advanced Analytics, Battelle Memorial Institute, Columbus, OH, United States; Department of Psychology, University of Virginia, Charlottesville, VA, United States; Medical Devices and Neuromodulation, Battelle Memorial Institute, Columbus, OH, United States; Neurological Institute, Ohio State University, Columbus, OH, United States; Department of Physical Medicine and Rehabilitation, Ohio State University, Columbus, OH, United States","Schwemmer M.A., Advanced Analytics, Battelle Memorial Institute, Columbus, OH, United States; Skomrock N.D., Advanced Analytics, Battelle Memorial Institute, Columbus, OH, United States; Sederberg P.B., Department of Psychology, University of Virginia, Charlottesville, VA, United States; Ting J.E., Medical Devices and Neuromodulation, Battelle Memorial Institute, Columbus, OH, United States; Sharma G., Medical Devices and Neuromodulation, Battelle Memorial Institute, Columbus, OH, United States; Bockbrader M.A., Neurological Institute, Ohio State University, Columbus, OH, United States, Department of Physical Medicine and Rehabilitation, Ohio State University, Columbus, OH, United States; Friedenberg D.A., Advanced Analytics, Battelle Memorial Institute, Columbus, OH, United States","Brain–computer interface (BCI) neurotechnology has the potential to reduce disability associated with paralysis by translating neural activity into control of assistive devices1–9. Surveys of potential end-users have identified key BCI system features10–14, including high accuracy, minimal daily setup, rapid response times, and multifunctionality. These performance characteristics are primarily influenced by the BCI’s neural decoding algorithm1,15, which is trained to associate neural activation patterns with intended user actions. Here, we introduce a new deep neural network16 decoding framework for BCI systems enabling discrete movements that addresses these four key performance characteristics. Using intracortical data from a participant with tetraplegia, we provide offline results demonstrating that our decoder is highly accurate, sustains this performance beyond a year without explicit daily retraining by combining it with an unsupervised updating procedure3,17–20, responds faster than competing methods8, and can increase functionality with minimal retraining by using a technique known as transfer learning21. We then show that our participant can use the decoder in real-time to reanimate his paralyzed forearm with functional electrical stimulation (FES), enabling accurate manipulation of three objects from the grasp and release test (GRT)22. These results demonstrate that deep neural network decoders can advance the clinical translation of BCI technology. © 2018, The Author(s), under exclusive licence to Springer Nature America, Inc.","","Adult; Algorithms; Brain; Brain-Computer Interfaces; Electric Stimulation; Hand Strength; Humans; Male; Motivation; Movement; Nerve Net; Quadriplegia; User-Computer Interface; adult; brain computer interface; case report; clinical article; deep neural network; forearm; functional electrical stimulation; human; Letter; male; nerve cell network; primary motor cortex; priority journal; quadriplegia; reaction time; support vector machine; transfer of learning; algorithm; brain; brain computer interface; computer interface; electrostimulation; hand strength; motivation; movement (physiology); nerve cell network; pathophysiology; physiology; quadriplegia; standards; trends","Nature Publishing Group","10788956","","NAMEF","30250141","Article","Scopus","2-s2.0-85053818943"
"naceur M.B.; Saouli R.; Akil M.; Kachouri R.","naceur, Mostefa Ben (57209365224); Saouli, Rachida (57188876060); Akil, Mohamed (7004665340); Kachouri, Rostom (24528485500)","57209365224; 57188876060; 7004665340; 24528485500","Fully Automatic Brain Tumor Segmentation using End-To-End Incremental Deep Neural Networks in MRI images","2018","Computer Methods and Programs in Biomedicine","181","10.1016/j.cmpb.2018.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054156079&doi=10.1016%2fj.cmpb.2018.09.007&partnerID=40&md5=1f434393096ca5f25272ccda6571b1d0","Smart Computer Sciences Laboratory, Department of Computer Sciences, University of Biskra, Biskra, Algeria; Gaspard Monge Computer Science Laboratory, ESIEE-Paris, University Paris-Est Marne-la-Vallée, France","naceur M.B., Smart Computer Sciences Laboratory, Department of Computer Sciences, University of Biskra, Biskra, Algeria, Gaspard Monge Computer Science Laboratory, ESIEE-Paris, University Paris-Est Marne-la-Vallée, France; Saouli R., Smart Computer Sciences Laboratory, Department of Computer Sciences, University of Biskra, Biskra, Algeria; Akil M., Gaspard Monge Computer Science Laboratory, ESIEE-Paris, University Paris-Est Marne-la-Vallée, France; Kachouri R., Gaspard Monge Computer Science Laboratory, ESIEE-Paris, University Paris-Est Marne-la-Vallée, France","Background and Objective: Nowadays, getting an efficient Brain Tumor Segmentation in Multi-Sequence MR images as soon as possible, gives an early clinical diagnosis, treatment and follow-up. The aim of this study is to develop a new deep learning model for the segmentation of brain tumors. The proposed models are used to segment the brain tumors of Glioblastomas (with both high and low grade). Glioblastomas have four properties: different sizes, shapes, contrasts, in addition, Glioblastomas appear anywhere in the brain. Methods: In this paper, we propose three end-to-end Incremental Deep Convolutional Neural Networks models for fully automatic Brain Tumor Segmentation. Our proposed models are different from the other CNNs-based models that follow the technique of trial and error process which does not use any guided approach to get the suitable hyper-parameters. Moreover, we adopt the technique of Ensemble Learning to design a more efficient model. For solving the problem of training CNNs model, we propose a new training strategy which takes into account the most influencing hyper-parameters by bounding and setting a roof to these hyper-parameters to accelerate the training. Results: Our experiment results reported on BRATS-2017 dataset. The proposed deep learning models achieve the state-of-the-art performance without any post-processing operations. Indeed, our models achieve in average 0.88 Dice score over the complete region. Moreover, the efficient design with the advantage of GPU implementation, allows our three deep learning models to achieve brain segmentation results in average 20.87 s. Conclusions: The proposed deep learning models are effective for the segmentation of brain tumors and allow to obtain high accurate results. Moreover, the proposed models could help the physician experts to reduce the time of diagnostic. © 2018 Elsevier B.V.","Brain tumor segmentation; Convolutional neural networks; Deep learning; Fully automatic; Hyper-parameters; Training","Algorithms; Brain; Brain Neoplasms; Diagnosis, Computer-Assisted; Glioblastoma; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Pattern Recognition, Automated; Brain; Convolution; Deep learning; Diagnosis; Image segmentation; Magnetic resonance imaging; Neural networks; Personnel training; Tumors; Brain tumor segmentation; Clinical diagnosis; Convolutional neural network; Deep convolutional neural networks; Fully automatic; Hyper-parameter; State-of-the-art performance; Trial-and-error process; Article; brain tumor; convolutional neural network; end to end incremental deep neural network; glioblastoma; human; image segmentation; machine learning; neuroimaging; nuclear magnetic resonance imaging; problem solving; study design; task performance; algorithm; artificial neural network; automated pattern recognition; brain; brain tumor; computer assisted diagnosis; diagnostic imaging; image processing; machine learning; pathology; procedures; Deep neural networks","Elsevier Ireland Ltd","01692607","","CMPBE","30415717","Article","Scopus","2-s2.0-85054156079"
"Imrie F.; Bradley A.R.; Van Der Schaar M.; Deane C.M.","Imrie, Fergus (57196214743); Bradley, Anthony R. (56394988200); Van Der Schaar, Mihaela (35605361700); Deane, Charlotte M. (7004460109)","57196214743; 56394988200; 35605361700; 7004460109","Protein Family-Specific Models Using Deep Neural Networks and Transfer Learning Improve Virtual Screening and Highlight the Need for More Data","2018","Journal of Chemical Information and Modeling","92","10.1021/acs.jcim.8b00350","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055102643&doi=10.1021%2facs.jcim.8b00350&partnerID=40&md5=1804b8c5cefc4791122db79af607cc2e","Oxford Protein Informatics Group, Department of Statistics, University of Oxford, Oxford, OX1 3LB, United Kingdom; Structural Genomics Consortium, University of Oxford, Oxford, OX3 7DQ, United Kingdom; Department of Chemistry, University of Oxford, Oxford, OX1 3TA, United Kingdom; Diamond Light Source Ltd., Didcot, OX11 0DE, United Kingdom; Department of Engineering, University of Oxford, Oxford, OX1 3PJ, United Kingdom; Alan Turing Institute, London, NW1 2DB, United Kingdom","Imrie F., Oxford Protein Informatics Group, Department of Statistics, University of Oxford, Oxford, OX1 3LB, United Kingdom; Bradley A.R., Structural Genomics Consortium, University of Oxford, Oxford, OX3 7DQ, United Kingdom, Department of Chemistry, University of Oxford, Oxford, OX1 3TA, United Kingdom, Diamond Light Source Ltd., Didcot, OX11 0DE, United Kingdom; Van Der Schaar M., Department of Engineering, University of Oxford, Oxford, OX1 3PJ, United Kingdom, Alan Turing Institute, London, NW1 2DB, United Kingdom; Deane C.M., Oxford Protein Informatics Group, Department of Statistics, University of Oxford, Oxford, OX1 3LB, United Kingdom","Machine learning has shown enormous potential for computer-aided drug discovery. Here we show how modern convolutional neural networks (CNNs) can be applied to structure-based virtual screening. We have coupled our densely connected CNN (DenseNet) with a transfer learning approach which we use to produce an ensemble of protein family-specific models. We conduct an in-depth empirical study and provide the first guidelines on the minimum requirements for adopting a protein family-specific model. Our method also highlights the need for additional data, even in data-rich protein families. Our approach outperforms recent benchmarks on the DUD-E data set and an independent test set constructed from the ChEMBL database. Using a clustered cross-validation on DUD-E, we achieve an average AUC ROC of 0.92 and a 0.5% ROC enrichment factor of 79. This represents an improvement in early enrichment of over 75% compared to a recent machine learning benchmark. Our results demonstrate that the continued improvements in machine learning architecture for computer vision apply to structure-based virtual screening. © 2018 American Chemical Society.","","Computer-Aided Design; Databases, Pharmaceutical; Databases, Protein; Drug Discovery; Humans; Ligands; Machine Learning; Molecular Docking Simulation; Neural Networks (Computer); Proteins; Computer aided instruction; Convolutional neural networks; Data communication systems; Deep neural networks; E-learning; Learning systems; Proteins; Statistical tests; Transfer learning; ligand; protein; Additional datum; Computer-aided drug discovery; Cross validation; Empirical studies; Enrichment factors; Minimum requirements; Structure-based; Virtual Screening; artificial neural network; chemistry; computer aided design; drug database; drug development; human; machine learning; metabolism; molecular docking; procedures; protein database; Deep learning","American Chemical Society","15499596","","JCISD","30273487","Article","Scopus","2-s2.0-85055102643"
"Xiao R.; Xu Y.; Pelter M.M.; Fidler R.; Badilini F.; Mortara D.W.; Hu X.","Xiao, Ran (57196439389); Xu, Yuan (56098843400); Pelter, Michele M. (7004886338); Fidler, Richard (56029925100); Badilini, Fabio (57203006991); Mortara, David W. (6602452978); Hu, Xiao (55603985300)","57196439389; 56098843400; 7004886338; 56029925100; 57203006991; 6602452978; 55603985300","Monitoring significant ST changes through deep learning","2018","Journal of Electrocardiology","18","10.1016/j.jelectrocard.2018.07.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050954611&doi=10.1016%2fj.jelectrocard.2018.07.026&partnerID=40&md5=0bb3edab6cccbcb8adf38ba6c48d0ced","Department of Physiological Nursing, University of California, San Francisco, CA, United States; Department of Neurological Surgery, University of California, San Francisco, CA, United States; Institute for Computational Health Sciences, University of California, San Francisco, CA, United States; Core Faculty, UCB/UCSF Graduate Group in Bioengineering, University of California, San Francisco, CA, United States","Xiao R., Department of Physiological Nursing, University of California, San Francisco, CA, United States; Xu Y., Department of Physiological Nursing, University of California, San Francisco, CA, United States; Pelter M.M., Department of Physiological Nursing, University of California, San Francisco, CA, United States; Fidler R., Department of Physiological Nursing, University of California, San Francisco, CA, United States; Badilini F., Department of Physiological Nursing, University of California, San Francisco, CA, United States; Mortara D.W., Department of Physiological Nursing, University of California, San Francisco, CA, United States; Hu X., Department of Physiological Nursing, University of California, San Francisco, CA, United States, Department of Neurological Surgery, University of California, San Francisco, CA, United States, Institute for Computational Health Sciences, University of California, San Francisco, CA, United States, Core Faculty, UCB/UCSF Graduate Group in Bioengineering, University of California, San Francisco, CA, United States","[No abstract available]","","Algorithms; Arrhythmias, Cardiac; Clinical Alarms; Deep Learning; Electrocardiography, Ambulatory; Humans; Risk Assessment; Sensitivity and Specificity; acute coronary syndrome; alarm fatigue; Article; controlled study; coronary care unit; deep learning; fatigue; heart muscle ischemia; Holter monitoring; human; image quality; machine learning; non ST segment elevation myocardial infarction; priority journal; sensitivity and specificity; ST segment; ST segment elevation myocardial infarction; unstable angina pectoris; alarm monitor; algorithm; ambulatory electrocardiography; heart arrhythmia; pathophysiology; risk assessment","Churchill Livingstone Inc.","00220736","","JECAB","30082087","Article","Scopus","2-s2.0-85050954611"
"Shin Y.; Balasingham I.","Shin, Younghak (44061719700); Balasingham, Ilangko (6602773063)","44061719700; 6602773063","Automatic polyp frame screening using patch based combined feature and dictionary learning","2018","Computerized Medical Imaging and Graphics","26","10.1016/j.compmedimag.2018.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052461448&doi=10.1016%2fj.compmedimag.2018.08.001&partnerID=40&md5=e0e8da8f510a4c56e16545b9d692795f","Department Electronics Systems at Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Intervention Centre, Oslo University Hospital, NO-0027, Oslo, Norway; Institute of Clinical Medicine, University of Oslo, the Norwegian University of Science and Technology (NTNU), Norway","Shin Y., Department Electronics Systems at Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Balasingham I., Intervention Centre, Oslo University Hospital, NO-0027, Oslo, Norway, Institute of Clinical Medicine, University of Oslo, the Norwegian University of Science and Technology (NTNU), Norway","Polyps in the colon can potentially become malignant cancer tissues where early detection and removal lead to high survival rate. Certain types of polyps can be difficult to detect even for highly trained physicians. Inspired by aforementioned problem our study aims to improve the human detection performance by developing an automatic polyp screening framework as a decision support tool. We use a small image patch based combined feature method. Features include shape and color information and are extracted using histogram of oriented gradient and hue histogram methods. Dictionary learning based training is used to learn features and final feature vector is formed using sparse coding. For classification, we use patch image classification based on linear support vector machine and whole image thresholding. The proposed framework is evaluated using three public polyp databases. Our experimental results show that the proposed scheme successfully classified polyps and normal images with over 95% of classification accuracy, sensitivity, specificity and precision. In addition, we compare performance of the proposed scheme with conventional feature based methods and the convolutional neural network (CNN) based deep learning approach which is the state of the art technique in many image classification applications. © 2018 Elsevier Ltd","Colonoscopy; Computer-aided detection; Dictionary learning; Polyp classification; Shape and color feature; Sparse coding","Algorithms; Brain; Early Detection of Cancer; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Prostate; Support Vector Machine; Urinary Bladder; Chemical detection; Codes (symbols); Computer aided instruction; Decision support systems; Deep learning; Graphic methods; Image retrieval; Neural networks; Colonoscopy; Color features; Computer aided detection; Dictionary learning; Sparse coding; Article; artificial neural network; automatic polyp frame screening; automation; book; clinical classification; clinical evaluation; clinical feature; colon polyp; colonoscopy; color; comparative study; computer assisted diagnosis; controlled study; convolutional neural network; data base; decision support system; feature extraction; histogram; human; image analysis; image processing; image segmentation; learning; priority journal; screening test; sensitivity and specificity; support vector machine; algorithm; bladder; brain; computer assisted diagnosis; diagnostic imaging; early cancer diagnosis; machine learning; male; nuclear magnetic resonance imaging; procedures; prostate; Image classification","Elsevier Ltd","08956111","","CMIGE","30172091","Article","Scopus","2-s2.0-85052461448"
"Stepniewska-Dziubinska M.M.; Zielenkiewicz P.; Siedlecki P.","Stepniewska-Dziubinska, Marta M. (57195419331); Zielenkiewicz, Piotr (7004305289); Siedlecki, Pawel (36875328100)","57195419331; 7004305289; 36875328100","Development and evaluation of a deep learning model for protein–ligand binding affinity prediction","2018","Bioinformatics","313","10.1093/bioinformatics/bty374","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055601628&doi=10.1093%2fbioinformatics%2fbty374&partnerID=40&md5=900ee124b381b2c2d65e86909f4af058","Institute of Biochemistry and Biophysics, Polish Academy of Sciences, Warsaw, 02-106, Poland; Department of Systems Biology, Institute of Experimental Plant Biology and Biotechnology, University of Warsaw, Warsaw, 02-096, Poland","Stepniewska-Dziubinska M.M., Institute of Biochemistry and Biophysics, Polish Academy of Sciences, Warsaw, 02-106, Poland; Zielenkiewicz P., Institute of Biochemistry and Biophysics, Polish Academy of Sciences, Warsaw, 02-106, Poland, Department of Systems Biology, Institute of Experimental Plant Biology and Biotechnology, University of Warsaw, Warsaw, 02-096, Poland; Siedlecki P., Institute of Biochemistry and Biophysics, Polish Academy of Sciences, Warsaw, 02-106, Poland, Department of Systems Biology, Institute of Experimental Plant Biology and Biotechnology, University of Warsaw, Warsaw, 02-096, Poland","Motivation: Structure based ligand discovery is one of the most successful approaches for augmenting the drug discovery process. Currently, there is a notable shift towards machine learning (ML) methodologies to aid such procedures. Deep learning has recently gained considerable attention as it allows the model to ’learn’ to extract features that are relevant for the task at hand. Results: We have developed a novel deep neural network estimating the binding affinity of ligand–receptor complexes. The complex is represented with a 3D grid, and the model utilizes a 3D convolution to produce a feature map of this representation, treating the atoms of both proteins and ligands in the same manner. Our network was tested on the CASF-2013 ’scoring power’ benchmark and Astex Diverse Set and outperformed classical scoring functions. © The Author(s) 2018. Published by Oxford University Press.","","Deep Learning; Ligands; Machine Learning; Protein Binding; Proteins; ligand; protein; protein binding; machine learning","Oxford University Press","13674803","","BOINF","29757353","Article","Scopus","2-s2.0-85055601628"
"Hosny A.; Parmar C.; Coroller T.P.; Grossmann P.; Zeleznik R.; Kumar A.; Bussink J.; Gillies R.J.; Mak R.H.; Aerts H.J.W.L.","Hosny, Ahmed (57197806283); Parmar, Chintan (55862758900); Coroller, Thibaud P. (56141905700); Grossmann, Patrick (56195622800); Zeleznik, Roman (57204940139); Kumar, Avnish (57214420342); Bussink, Johan (7003338676); Gillies, Robert J. (7102089341); Mak, Raymond H. (8597064200); Aerts, Hugo J. W. L. (16479697600)","57197806283; 55862758900; 56141905700; 56195622800; 57204940139; 57214420342; 7003338676; 7102089341; 8597064200; 16479697600","Deep learning for lung cancer prognostication: A retrospective multi-cohort radiomics study","2018","PLoS Medicine","355","10.1371/journal.pmed.1002711","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058016498&doi=10.1371%2fjournal.pmed.1002711&partnerID=40&md5=af7f06f14ed7e2a21904208f27c57166","Department of Radiation Oncology, Dana-Farber Cancer Institute, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States; Department of Radiation Oncology, Radboud University Medical Center, Nijmegen, Netherlands; Department of Cancer Physiology, H. Lee Moffitt Cancer Center and Research Institute, Tampa, FL, United States; Department of Radiology, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States","Hosny A., Department of Radiation Oncology, Dana-Farber Cancer Institute, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States; Parmar C., Department of Radiation Oncology, Dana-Farber Cancer Institute, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States; Coroller T.P., Department of Radiation Oncology, Dana-Farber Cancer Institute, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States; Grossmann P., Department of Radiation Oncology, Dana-Farber Cancer Institute, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States; Zeleznik R., Department of Radiation Oncology, Dana-Farber Cancer Institute, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States; Kumar A., Department of Radiation Oncology, Dana-Farber Cancer Institute, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States; Bussink J., Department of Radiation Oncology, Radboud University Medical Center, Nijmegen, Netherlands; Gillies R.J., Department of Cancer Physiology, H. Lee Moffitt Cancer Center and Research Institute, Tampa, FL, United States; Mak R.H., Department of Radiology, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States; Aerts H.J.W.L., Department of Radiation Oncology, Dana-Farber Cancer Institute, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States, Department of Radiology, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States","Background: Non-small-cell lung cancer (NSCLC) patients often demonstrate varying clinical courses and outcomes, even within the same tumor stage. This study explores deep learning applications in medical imaging allowing for the automated quantification of radiographic characteristics and potentially improving patient stratification. Methods and findings: We performed an integrative analysis on 7 independent datasets across 5 institutions totaling 1,194 NSCLC patients (age median = 68.3 years [range 32.5–93.3], survival median = 1.7 years [range 0.0–11.7]). Using external validation in computed tomography (CT) data, we identified prognostic signatures using a 3D convolutional neural network (CNN) for patients treated with radiotherapy (n = 771, age median = 68.0 years [range 32.5–93.3], survival median = 1.3 years [range 0.0–11.7]). We then employed a transfer learning approach to achieve the same for surgery patients (n = 391, age median = 69.1 years [range 37.2–88.0], survival median = 3.1 years [range 0.0–8.8]). We found that the CNN predictions were significantly associated with 2-year overall survival from the start of respective treatment for radiotherapy (area under the receiver operating characteristic curve [AUC] = 0.70 [95% CI 0.63–0.78], p < 0.001) and surgery (AUC = 0.71 [95% CI 0.60–0.82], p < 0.001) patients. The CNN was also able to significantly stratify patients into low and high mortality risk groups in both the radiotherapy (p < 0.001) and surgery (p = 0.03) datasets. Additionally, the CNN was found to significantly outperform random forest models built on clinical parameters—including age, sex, and tumor node metastasis stage—as well as demonstrate high robustness against test–retest (intraclass correlation coefficient = 0.91) and inter-reader (Spearman’s rank-order correlation = 0.88) variations. To gain a better understanding of the characteristics captured by the CNN, we identified regions with the most contribution towards predictions and highlighted the importance of tumor-surrounding tissue in patient stratification. We also present preliminary findings on the biological basis of the captured phenotypes as being linked to cell cycle and transcriptional processes. Limitations include the retrospective nature of this study as well as the opaque black box nature of deep learning networks. Conclusions: Our results provide evidence that deep learning networks may be used for mortality risk stratification based on standard-of-care CT images from NSCLC patients. This evidence motivates future research into better deciphering the clinical and biological basis of deep learning networks as well as validation in prospective data. © 2018 Hosny et al. http://creativecommons.org/licenses/by/4.0/.","","Adult; Aged; Aged, 80 and over; Carcinoma, Non-Small-Cell Lung; Clinical Decision-Making; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Lung Neoplasms; Male; Middle Aged; Neoplasm Staging; Predictive Value of Tests; Preliminary Data; Radiographic Image Interpretation, Computer-Assisted; Reproducibility of Results; Retrospective Studies; Risk Assessment; Risk Factors; Tomography, X-Ray Computed; adult; aged; Article; artificial neural network; benchmarking; cancer mortality; cancer staging; cell cycle assay; cell proliferation assay; computer assisted tomography; correlation coefficient; cross-sectional study; diagnostic imaging; disease course; female; follow up; gene set enrichment analysis; genetic analysis; human; image analysis; machine learning; major clinical study; male; mathematical model; mortality risk; multicenter study; non small cell lung cancer; observational study; outcome assessment; overall survival; retrospective study; survival analysis; very elderly; clinical decision making; clinical trial; computer assisted diagnosis; diagnostic imaging; lung tumor; middle aged; mortality; non small cell lung cancer; pathology; predictive value; preliminary data; procedures; reproducibility; risk assessment; risk factor; x-ray computed tomography","Public Library of Science","15491277","","","30500819","Article","Scopus","2-s2.0-85058016498"
"Jimenez-Carretero D.; Abrishami V.; Fernández-de-Manuel L.; Palacios I.; Quílez-Álvarez A.; Díez-Sánchez A.; del Pozo M.A.; Montoya M.C.","Jimenez-Carretero, Daniel (54787900600); Abrishami, Vahid (36442344800); Fernández-de-Manuel, Laura (35761036100); Palacios, Irene (57200571368); Quílez-Álvarez, Antonio (57204481360); Díez-Sánchez, Alberto (57204481090); del Pozo, Miguel A. (21736668300); Montoya, María C. (57191269969)","54787900600; 36442344800; 35761036100; 57200571368; 57204481360; 57204481090; 21736668300; 57191269969","Tox_(R)CNN: Deep learning-based nuclei profiling tool for drug toxicity screening","2018","PLoS Computational Biology","35","10.1371/journal.pcbi.1006238","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058122388&doi=10.1371%2fjournal.pcbi.1006238&partnerID=40&md5=698e33c3cddf69d1661ce55f9bd4602a","Cellomics Unit, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain; Mechanoadaptation and Caveolae biology, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain","Jimenez-Carretero D., Cellomics Unit, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain; Abrishami V., Cellomics Unit, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain; Fernández-de-Manuel L., Cellomics Unit, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain; Palacios I., Cellomics Unit, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain; Quílez-Álvarez A., Cellomics Unit, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain; Díez-Sánchez A., Mechanoadaptation and Caveolae biology, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain; del Pozo M.A., Mechanoadaptation and Caveolae biology, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain; Montoya M.C., Cellomics Unit, Cell & Developmental Biology Area, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain","Toxicity is an important factor in failed drug development, and its efficient identification and prediction is a major challenge in drug discovery. We have explored the potential of microscopy images of fluorescently labeled nuclei for the prediction of toxicity based on nucleus pattern recognition. Deep learning algorithms obtain abstract representations of images through an automated process, allowing them to efficiently classify complex patterns, and have become the state-of-the art in machine learning for computer vision. Here, deep convolutional neural networks (CNN) were trained to predict toxicity from images of DAPI-stained cells pre-treated with a set of drugs with differing toxicity mechanisms. Different cropping strategies were used for training CNN models, the nuclei-cropping-based Tox_CNN model outperformed other models classifying cells according to health status. Tox_CNN allowed automated extraction of feature maps that clustered compounds according to mechanism of action. Moreover, fully automated region-based CNNs (RCNN) were implemented to detect and classify nuclei, providing per-cell toxicity prediction from raw screening images. We validated both Tox_(R)CNN models for detection of pre-lethal toxicity from nuclei images, which proved to be more sensitive and have broader specificity than established toxicity readouts. These models predicted toxicity of drugs with mechanisms of action other than those they had been trained for and were successfully transferred to other cell assays. The Tox_(R)CNN models thus provide robust, sensitive, and cost-effective tools for in vitro screening of drug-induced toxicity. These models can be adopted for compound prioritization in drug screening campaigns, and could thereby increase the efficiency of drug discovery. © 2018 Jimenez-Carretero et al. http://creativecommons.org/licenses/by/4.0/.","","Algorithms; Automation; Cell Nucleus; Deep Learning; Drug-Related Side Effects and Adverse Reactions; Fluorescent Dyes; Image Interpretation, Computer-Assisted; Indoles; Neural Networks (Computer); Automation; Cells; Cost effectiveness; Cytology; Deep neural networks; Forecasting; Learning algorithms; Neural network models; Pattern recognition; 4',6 diamidino 2 phenylindole; fluorescent dye; indole derivative; Abstract representation; Automated process; Complex pattern; Convolutional neural network; Drug development; Drug discovery; Mechanism of action; Microscopy images; Neural network model; Profiling tools; animal cell; Article; artificial neural network; cell assay; cell line; cell nucleus; computer model; controlled study; cost effectiveness analysis; cytotoxicity; drug induced disease; drug mechanism; drug research; drug screening; embryo; image segmentation; in vitro study; mouse; nonhuman; prediction; staining; supervised machine learning; toxicity region based convolutional neural network; toxicity testing; adverse drug reaction; algorithm; artificial neural network; automation; chemistry; computer assisted diagnosis; drug effect; procedures; Toxicity","Public Library of Science","1553734X","","","30500821","Article","Scopus","2-s2.0-85058122388"
"Krivák R.; Hoksza D.","Krivák, Radoslav (56607285200); Hoksza, David (23389209600)","56607285200; 23389209600","P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure","2018","Journal of Cheminformatics","192","10.1186/s13321-018-0285-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051512048&doi=10.1186%2fs13321-018-0285-8&partnerID=40&md5=0eb7309e0a4cebe49e312096ae255038","Department of Software Engineering, Charles University, Prague, Czech Republic","Krivák R., Department of Software Engineering, Charles University, Prague, Czech Republic; Hoksza D., Department of Software Engineering, Charles University, Prague, Czech Republic","Background: Ligand binding site prediction from protein structure has many applications related to elucidation of protein function and structure based drug discovery. It often represents only one step of many in complex computational drug design efforts. Although many methods have been published to date, only few of them are suitable for use in automated pipelines or for processing large datasets. These use cases require stability and speed, which disqualifies many of the recently introduced tools that are either template based or available only as web servers. Results: We present P2Rank, a stand-alone template-free tool for prediction of ligand binding sites based on machine learning. It is based on prediction of ligandability of local chemical neighbourhoods that are centered on points placed on the solvent accessible surface of a protein. We show that P2Rank outperforms several existing tools, which include two widely used stand-alone tools (Fpocket, SiteHound), a comprehensive consensus based tool (MetaPocket 2.0), and a recent deep learning based method (DeepSite). P2Rank belongs to the fastest available tools (requires under 1 s for prediction on one protein), with additional advantage of multi-threaded implementation. Conclusions: P2Rank is a new open source software package for ligand binding site prediction from protein structure. It is available as a user-friendly stand-alone command line program and a Java library. P2Rank has a lightweight installation and does not depend on other bioinformatics tools or large structural or sequence databases. Thanks to its speed and ability to make fully automated predictions, it is particularly well suited for processing large datasets or as a component of scalable structural bioinformatics pipelines. © 2018, The Author(s).","Binding site prediction; Ligand binding sites; Machine learning; Protein pockets; Protein surface descriptors; Random forests","","Springer","17582946","","","","Article","Scopus","2-s2.0-85051512048"
"Nielsen A.A.K.; Voigt C.A.","Nielsen, Alec A. K. (55748104100); Voigt, Christopher A. (35581059600)","55748104100; 35581059600","Deep learning to predict the lab-of-origin of engineered DNA","2018","Nature Communications","46","10.1038/s41467-018-05378-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051285009&doi=10.1038%2fs41467-018-05378-z&partnerID=40&md5=ae59451ca6d5042141b3776bc6eb9bbf","Synthetic Biology Center, Department of Biological Engineering, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States","Nielsen A.A.K., Synthetic Biology Center, Department of Biological Engineering, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States; Voigt C.A., Synthetic Biology Center, Department of Biological Engineering, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States","Genetic engineering projects are rapidly growing in scale and complexity, driven by new tools to design and construct DNA. There is increasing concern that widened access to these technologies could lead to attempts to construct cells for malicious intent, illegal drug production, or to steal intellectual property. Determining the origin of a DNA sequence is difficult and time-consuming. Here deep learning is applied to predict the lab-of-origin of a DNA sequence. A convolutional neural network was trained on the Addgene plasmid dataset that contained 42,364 engineered DNA sequences from 2230 labs as of February 2016. The network correctly identifies the source lab 48% of the time and 70% it appears in the top 10 predicted labs. Often, there is not a single “smoking gun” that affiliates a DNA sequence with a lab. Rather, it is a combination of design choices that are individually common but collectively reveal the designer. © 2018, The Author(s).","","Bayes Theorem; Deep Learning; DNA; Genetic Engineering; Image Processing, Computer-Assisted; Mutation; Neural Networks (Computer); Plasmids; Software; Synthetic Biology; DNA; artificial neural network; data set; DNA; genetic engineering; plasmid; Article; artificial neural network; controlled study; convolutional neural network; deep learning; DNA determination; DNA sequence; genetic engineering; laboratory; machine learning; plasmid; prediction; artificial neural network; Bayes theorem; genetic engineering; image processing; metabolism; mutation; procedures; software; synthetic biology","Nature Publishing Group","20411723","","","30087331","Article","Scopus","2-s2.0-85051285009"
"Feinberg E.N.; Sur D.; Wu Z.; Husic B.E.; Mai H.; Li Y.; Sun S.; Yang J.; Ramsundar B.; Pande V.S.","Feinberg, Evan N. (56545320800); Sur, Debnil (57194690075); Wu, Zhenqin (57195509174); Husic, Brooke E. (57191904030); Mai, Huanghao (57204620577); Li, Yang (57196302368); Sun, Saisai (57204623728); Yang, Jianyi (55719581300); Ramsundar, Bharath (56097570200); Pande, Vijay S. (7004966384)","56545320800; 57194690075; 57195509174; 57191904030; 57204620577; 57196302368; 57204623728; 55719581300; 56097570200; 7004966384","PotentialNet for Molecular Property Prediction","2018","ACS Central Science","250","10.1021/acscentsci.8b00507","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056374934&doi=10.1021%2facscentsci.8b00507&partnerID=40&md5=834621db0a9a31c0b244a817d74f1158","Program in Biophysics, Stanford University, Stanford, 94305, CA, United States; Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Department of Chemistry, Stanford University, Stanford, 94305, CA, United States; School of Mathematical Sciences, College of Life Sciences, Nankai University, Tianjin, 300071, China; Department of Bioengineering, Stanford University, Stanford, 94305, CA, United States","Feinberg E.N., Program in Biophysics, Stanford University, Stanford, 94305, CA, United States; Sur D., Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Wu Z., Department of Chemistry, Stanford University, Stanford, 94305, CA, United States; Husic B.E., Department of Chemistry, Stanford University, Stanford, 94305, CA, United States; Mai H., Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Li Y., School of Mathematical Sciences, College of Life Sciences, Nankai University, Tianjin, 300071, China; Sun S., School of Mathematical Sciences, College of Life Sciences, Nankai University, Tianjin, 300071, China; Yang J., School of Mathematical Sciences, College of Life Sciences, Nankai University, Tianjin, 300071, China; Ramsundar B., Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Pande V.S., Department of Bioengineering, Stanford University, Stanford, 94305, CA, United States","The arc of drug discovery entails a multiparameter optimization problem spanning vast length scales. The key parameters range from solubility (angstroms) to protein-ligand binding (nanometers) to in vivo toxicity (meters). Through feature learning - instead of feature engineering - deep neural networks promise to outperform both traditional physics-based and knowledge-based machine learning models for predicting molecular properties pertinent to drug discovery. To this end, we present the PotentialNet family of graph convolutions. These models are specifically designed for and achieve state-of-the-art performance for protein-ligand binding affinity. We further validate these deep neural networks by setting new standards of performance in several ligand-based tasks. In parallel, we introduce a new metric, the Regression Enrichment Factor EFχ(R), to measure the early enrichment of computational models for chemical data. Finally, we introduce a cross-validation strategy based on structural homology clustering that can more accurately measure model generalizability, which crucially distinguishes the aims of machine learning for drug discovery from standard machine learning tasks. © Copyright 2018 American Chemical Society.","","Artificial intelligence; Binding energy; Knowledge based systems; Ligands; Proteins; Computational model; Feature engineerings; Machine learning models; Molecular properties; Multi-parameter optimizations; Protein-ligand binding affinities; State-of-the-art performance; Structural homology; Deep neural networks","American Chemical Society","23747943","","","","Article","Scopus","2-s2.0-85056374934"
"Zhou H.; Cao H.; Skolnick J.","Zhou, Hongyi (57376621900); Cao, Hongnan (26666522300); Skolnick, Jeffrey (7103056580)","57376621900; 26666522300; 7103056580","FINDSITEcomb2.0: A New Approach for Virtual Ligand Screening of Proteins and Virtual Target Screening of Biomolecules","2018","Journal of Chemical Information and Modeling","28","10.1021/acs.jcim.8b00309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055186019&doi=10.1021%2facs.jcim.8b00309&partnerID=40&md5=1afde53572b4b72495d22fb961ec75f9","Center for the Study of Systems Biology, School of Biological Sciences, Georgia Institute of Technology, 950 Atlantic Drive, NW, Atlanta, 30332-2000, GA, United States","Zhou H., Center for the Study of Systems Biology, School of Biological Sciences, Georgia Institute of Technology, 950 Atlantic Drive, NW, Atlanta, 30332-2000, GA, United States; Cao H., Center for the Study of Systems Biology, School of Biological Sciences, Georgia Institute of Technology, 950 Atlantic Drive, NW, Atlanta, 30332-2000, GA, United States; Skolnick J., Center for the Study of Systems Biology, School of Biological Sciences, Georgia Institute of Technology, 950 Atlantic Drive, NW, Atlanta, 30332-2000, GA, United States","Computational approaches for predicting protein-ligand interactions can facilitate drug lead discovery and drug target determination. We have previously developed a threading/structural-based approach, FINDSITEcomb, for the virtual ligand screening of proteins that has been extensively experimentally validated. Even when low resolution predicted protein structures are employed, FINDSITEcomb has the advantage of being faster and more accurate than traditional high-resolution structure-based docking methods. It also overcomes the limitations of traditional QSAR methods that require a known set of seed ligands that bind to the given protein target. Here, we further improve FINDSITEcomb by enhancing its template ligand selection from the PDB/DrugBank/ChEMBL libraries of known protein-ligand interactions by (1) parsing the template proteins and their corresponding binding ligands in the DrugBank and ChEMBL libraries into domains so that the ligands with falsely matched domains to the targets will not be selected as template ligands; (2) applying various thresholds to filter out falsely matched template structures in the structure comparison process and thus their corresponding ligands for template ligand selection. With a sequence identity cutoff of 30% of target to templates and modeled target structures, FINDSITEcomb2.0 is shown to significantly improve upon FINDSITEcomb on the DUD-E benchmark set by increasing the 1% enrichment factor from 16.7 to 22.1, with a p-value of 4.3 × 10-3 by the Student t-test. With an 80% sequence identity cutoff of target to templates for the DUD-E set and modeled target structures, FINDSITEcomb2.0, having a 1% ROC enrichment factor of 52.39, also outperforms state-of-the-art methods that employ machine learning such as a deep convolutional neural network, CNN, with an enrichment of 29.65. Thus, FINDSITEcomb2.0 represents a significant improvement in the state-of-the-art. The FINDSITEcomb2.0 web service is freely available for academic users at http://pwp.gatech.edu/cssb/FINDSITE-COMB-2. © 2018 American Chemical Society.","","Binding Sites; Databases, Pharmaceutical; Databases, Protein; Drug Discovery; Humans; Ligands; Molecular Docking Simulation; Protein Binding; Protein Conformation; Proteins; Software; Convolutional neural networks; Deep neural networks; Libraries; Matched filters; Proteins; Web services; ligand; protein; protein binding; Computational approach; Enrichment factors; High-resolution structures; Protein-ligand interactions; State-of-the-art methods; Structure comparisons; Template structures; Virtual ligand screening; binding site; chemistry; drug database; drug development; human; metabolism; molecular docking; procedures; protein conformation; protein database; software; Ligands","American Chemical Society","15499596","","JCISD","30278128","Article","Scopus","2-s2.0-85055186019"
"Rehman A.; Abbas N.; Saba T.; Rahman S.I.U.; Mehmood Z.; Kolivand H.","Rehman, Amjad (35093155800); Abbas, Naveed (55853745600); Saba, Tanzila (36110026100); Rahman, Syed Ijaz ur (57204418844); Mehmood, Zahid (57190517865); Kolivand, Hoshang (45061059500)","35093155800; 55853745600; 36110026100; 57204418844; 57190517865; 45061059500","Classification of acute lymphoblastic leukemia using deep learning","2018","Microscopy Research and Technique","205","10.1002/jemt.23139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055496111&doi=10.1002%2fjemt.23139&partnerID=40&md5=b63338f3899c667e1073ee02b4ec609b","College of Computer and Information Systems, Al Yamamah University, Riyadh, Saudi Arabia; Department of Computer Science, Islamia College University Peshawar, Pakistan; College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia; Department of Software Engineering, University of Engineering and Technology Taxila, Pakistan; Department of Computer Science, Liverpool John Moores University, Liverpool, United Kingdom","Rehman A., College of Computer and Information Systems, Al Yamamah University, Riyadh, Saudi Arabia; Abbas N., Department of Computer Science, Islamia College University Peshawar, Pakistan; Saba T., College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia; Rahman S.I.U., Department of Computer Science, Islamia College University Peshawar, Pakistan; Mehmood Z., Department of Software Engineering, University of Engineering and Technology Taxila, Pakistan; Kolivand H., Department of Computer Science, Liverpool John Moores University, Liverpool, United Kingdom","Acute Leukemia is a life-threatening disease common both in children and adults that can lead to death if left untreated. Acute Lymphoblastic Leukemia (ALL) spreads out in children's bodies rapidly and takes the life within a few weeks. To diagnose ALL, the hematologists perform blood and bone marrow examination. Manual blood testing techniques that have been used since long time are often slow and come out with the less accurate diagnosis. This work improves the diagnosis of ALL with a computer-aided system, which yields accurate result by using image processing and deep learning techniques. This research proposed a method for the classification of ALL into its subtypes and reactive bone marrow (normal) in stained bone marrow images. A robust segmentation and deep learning techniques with the convolutional neural network are used to train the model on the bone marrow images to achieve accurate classification results. Experimental results thus obtained and compared with the results of other classifiers Naïve Bayesian, KNN, and SVM. Experimental results reveal that the proposed method achieved 97.78% accuracy. The obtained results exhibit that the proposed approach could be used as a tool to diagnose Acute Lymphoblastic Leukemia and its sub-types that will definitely assist pathologists. © 2018 Wiley Periodicals, Inc.","acute lymphoblastic leukemia; bone marrow; deep learning; segmentation and classification","Bone Marrow; Deep Learning; Hematologic Tests; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Neural Networks (Computer); Pattern Recognition, Automated; Precursor Cell Lymphoblastic Leukemia-Lymphoma; Blood; Computer aided diagnosis; Deep learning; Image enhancement; Image segmentation; Learning algorithms; Neural networks; Support vector machines; Acute leukaemia; Acute lymphoblastic leukaemias; Blood testing; Bone marrow; Bone marrow images; Deep learning; Learning techniques; Segmentation and classification; Spread outs; Testing technique; acute lymphoblastic leukemia; artificial neural network; automated pattern recognition; blood examination; bone marrow; classification; computer assisted diagnosis; human; image processing; pathology; procedures; Diseases","Wiley-Liss Inc.","1059910X","","MRTEE","30351463","Article","Scopus","2-s2.0-85055496111"
"Chen L.; Li Y.; Chen W.; Liu X.; Yu Z.; Zhang S.","Chen, Li (57022319700); Li, Yuanju (57204291576); Chen, Weipeng (57201480041); Liu, Xinglong (57215645041); Yu, Zhonghua (56299027800); Zhang, Siyuan (57204283867)","57022319700; 57204291576; 57201480041; 57215645041; 56299027800; 57204283867","Utilizing soft constraints to enhance medical relation extraction from the history of present illness in electronic medical records","2018","Journal of Biomedical Informatics","9","10.1016/j.jbi.2018.09.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055133836&doi=10.1016%2fj.jbi.2018.09.013&partnerID=40&md5=858b5e28b48f7f47a41392f2439e82a9","Department of Computer Science, Sichuan University, Chengdu, China; School of Basic Medicine, Chengdu University of TCM, Chengdu, China","Chen L., Department of Computer Science, Sichuan University, Chengdu, China; Li Y., Department of Computer Science, Sichuan University, Chengdu, China; Chen W., Department of Computer Science, Sichuan University, Chengdu, China; Liu X., School of Basic Medicine, Chengdu University of TCM, Chengdu, China; Yu Z., Department of Computer Science, Sichuan University, Chengdu, China; Zhang S., Department of Computer Science, Sichuan University, Chengdu, China","Relation extraction between medical concepts from electronic medical records has pervasive applications as well as significance. However, previous researches utilizing machine learning algorithms judge the semantic types of medical concept pair mentions independently. In fact, different concept pair mentions in the same context are of dependencies which can provide beneficial evidences for identifying their relation types. To the best of our knowledge, only one study has considered such dependencies in discharge summaries. However, its hard constraints are not applied effectively to the History of Present Illness (HPI) in electronic Medical Records. According to the writing characteristics of HPI records, we generalize two regularities of dependencies among concept pairs mentioned in an HPI record to enhance the performance of relation extraction. We incorporate the two soft constraints corresponding to the regularities and the posterior probabilities returned by a local classifier into a joint inference process which applies Integer Quadratic Programming method to carry out collective classification for all concept pair mentions in an HPI record. We implement four local classification models including support vector machine, logistics regression, random forest and piecewise convolutional neural networks to examine the performance of our approach. A series of experimental results demonstrate that our collective classification method has made a principal improvement and outperforms the other state-of-the-art methods. © 2018 Elsevier Inc.","Electronic medical record; History of present illness; Integer quadratic programming; Relation extraction; Soft constraints","Algorithms; China; Deep Learning; Electronic Health Records; Humans; Medical Informatics; Models, Statistical; Probability; Regression Analysis; Reproducibility of Results; Support Vector Machine; Decision trees; Diseases; Extraction; Integer programming; Learning algorithms; Learning systems; Medical computing; Neural networks; Quadratic programming; Semantics; Collective classifications; Convolutional neural network; Electronic medical record; Pervasive applications; Quadratic programming method; Relation extraction; Soft constraint; State-of-the-art methods; article; electronic medical record; extraction; human; human experiment; joint; probability; random forest; support vector machine; writing; algorithm; China; electronic health record; medical informatics; procedures; regression analysis; reproducibility; statistical model; support vector machine; Computer programming","Academic Press Inc.","15320464","","JBIOB","30292854","Article","Scopus","2-s2.0-85055133836"
"Uesawa Y.","Uesawa, Yoshihiro (6602801701)","6602801701","Quantitative structure–activity relationship analysis using deep learning based on a novel molecular image input technique","2018","Bioorganic and Medicinal Chemistry Letters","37","10.1016/j.bmcl.2018.08.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052845488&doi=10.1016%2fj.bmcl.2018.08.032&partnerID=40&md5=46a5f26ca2a7acee0bbd55901aa8f8fe","Department of Medical Molecular Informatics, Meiji Pharmaceutical University, 2-522-1 Noshio, Kiyose, 204-8588, Tokyo, Japan","Uesawa Y., Department of Medical Molecular Informatics, Meiji Pharmaceutical University, 2-522-1 Noshio, Kiyose, 204-8588, Tokyo, Japan","Quantitative structure–activity relationship (QSAR) analysis uses structural, quantum chemical, and physicochemical features calculated from molecular geometry as explanatory variables predicting physiological activity. Recently, deep learning based on advanced artificial neural networks has demonstrated excellent performance in the discipline of QSAR research. While it has properties of feature representation learning that directly calculate feature values from molecular structure, the use of this potential function is limited in QSAR modeling. The present study applied this function of feature representation learning to QSAR analysis by incorporating 360° images of molecular conformations into deep learning. Accordingly, I successfully constructed a highly versatile identification model for chemical compounds that induce mitochondrial membrane potential disruption with the external validation area under the receiver operating characteristic curve of ≥0.9. © 2018 The Author(s)","Deep learning; In silico; Mitochondrial membrane potential disruption; Molecular imagery; Quantitative structure–activity relationship; Three-dimensional structure","Deep Learning; Models, Chemical; Molecular Conformation; Molecular Structure; Quantitative Structure-Activity Relationship; ROC Curve; analytic method; area under the curve; Article; chemical structure; conformation; deep learning; deep snap procedure; external validity; image analysis; machine learning; measurement accuracy; measurement precision; mitochondrial membrane potential; molecular image input technique; molecular imaging; prediction; quantitative structure activity relationship; receiver operating characteristic; sensitivity and specificity; structure activity relation; chemical model; quantitative structure activity relation","Elsevier Ltd","0960894X","","BMCLE","30177377","Article","Scopus","2-s2.0-85052845488"
"Malafeev A.; Laptev D.; Bauer S.; Omlin X.; Wierzbicka A.; Wichniak A.; Jernajczyk W.; Riener R.; Buhmann J.; Achermann P.","Malafeev, Alexander (36665052400); Laptev, Dmitry (36473337100); Bauer, Stefan (56410381900); Omlin, Ximena (35146407700); Wierzbicka, Aleksandra (56230313900); Wichniak, Adam (6603162491); Jernajczyk, Wojciech (6602543297); Riener, Robert (7003404145); Buhmann, Joachim (7004241909); Achermann, Peter (7006009726)","36665052400; 36473337100; 56410381900; 35146407700; 56230313900; 6603162491; 6602543297; 7003404145; 7004241909; 7006009726","Automatic human sleep stage scoring using deep neural networks","2018","Frontiers in Neuroscience","102","10.3389/fnins.2018.00781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057207852&doi=10.3389%2ffnins.2018.00781&partnerID=40&md5=98147a7ef106078df0edff4b3bbc2e04","Chronobiology and Sleep Research, Institute of Pharmacology and Toxicology, University of Zurich, Zurich, Switzerland; Neuroscience Center Zurich, University of Zurich, ETH Zurich, Zurich, Switzerland; Center for Interdisciplinary Sleep Research, University of Zurich, Zurich, Switzerland; Information Science and Engineering, Institute for Machine Learning, ETH Zurich, Zurich, Switzerland; Max Planck Institute for Intelligent Systems, Tübingen, Germany; Sensory-Motor Systems Lab., ETH Zurich, Zurich, Switzerland; Sleep Disorders Center, Department of Clinical Neurophysiology, Institute of Psychiatry and Neurology in Warsaw, Warsaw, Poland; Third Department of Psychiatry and Sleep Disorders Center, Institute of Psychiatry and Neurology in Warsaw, Warsaw, Poland; University Hospital Balgrist (SCI Center), Medical Faculty, University of Zurich, Zurich, Switzerland","Malafeev A., Chronobiology and Sleep Research, Institute of Pharmacology and Toxicology, University of Zurich, Zurich, Switzerland, Neuroscience Center Zurich, University of Zurich, ETH Zurich, Zurich, Switzerland, Center for Interdisciplinary Sleep Research, University of Zurich, Zurich, Switzerland; Laptev D., Information Science and Engineering, Institute for Machine Learning, ETH Zurich, Zurich, Switzerland; Bauer S., Information Science and Engineering, Institute for Machine Learning, ETH Zurich, Zurich, Switzerland, Max Planck Institute for Intelligent Systems, Tübingen, Germany; Omlin X., Neuroscience Center Zurich, University of Zurich, ETH Zurich, Zurich, Switzerland, Sensory-Motor Systems Lab., ETH Zurich, Zurich, Switzerland; Wierzbicka A., Sleep Disorders Center, Department of Clinical Neurophysiology, Institute of Psychiatry and Neurology in Warsaw, Warsaw, Poland; Wichniak A., Third Department of Psychiatry and Sleep Disorders Center, Institute of Psychiatry and Neurology in Warsaw, Warsaw, Poland; Jernajczyk W., Sleep Disorders Center, Department of Clinical Neurophysiology, Institute of Psychiatry and Neurology in Warsaw, Warsaw, Poland; Riener R., Neuroscience Center Zurich, University of Zurich, ETH Zurich, Zurich, Switzerland, Center for Interdisciplinary Sleep Research, University of Zurich, Zurich, Switzerland, Sensory-Motor Systems Lab., ETH Zurich, Zurich, Switzerland, University Hospital Balgrist (SCI Center), Medical Faculty, University of Zurich, Zurich, Switzerland; Buhmann J., Information Science and Engineering, Institute for Machine Learning, ETH Zurich, Zurich, Switzerland; Achermann P., Chronobiology and Sleep Research, Institute of Pharmacology and Toxicology, University of Zurich, Zurich, Switzerland, Center for Interdisciplinary Sleep Research, University of Zurich, Zurich, Switzerland","The classification of sleep stages is the first and an important step in the quantitative analysis of polysomnographic recordings. Sleep stage scoring relies heavily on visual pattern recognition by a human expert and is time consuming and subjective. Thus, there is a need for automatic classification. In this work we developed machine learning algorithms for sleep classification: random forest (RF) classification based on features and artificial neural networks (ANNs) working both with features and raw data. We tested our methods in healthy subjects and in patients. Most algorithms yielded good results comparable to human interrater agreement. Our study revealed that deep neural networks (DNNs) working with raw data performed better than feature-based methods. We also demonstrated that taking the local temporal structure of sleep into account a priori is important. Our results demonstrate the utility of neural network architectures for the classification of sleep. Copyright © 2018 Malafeev, Laptev, Bauer, Omlin, Wierzbicka, Wichniak, Jernajczyk, Riener, Buhmann and Achermann.","Artificial neural networks; Automatic scoring; Deep learning; EEG; Features; Random forest; Raw data; Sleep","adult; article; artificial neural network; controlled study; electroencephalogram; human; machine learning; random forest; sleep stage","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85057207852"
"Brent R.; Boucheron L.","Brent, Roger (7103203767); Boucheron, Laura (8358435400)","7103203767; 8358435400","Deep learning to predict microscope images","2018","Nature Methods","22","10.1038/s41592-018-0194-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055767422&doi=10.1038%2fs41592-018-0194-9&partnerID=40&md5=863d628cbacb263bc28345605f7538c0","Division of Basic Sciences, Fred Hutchinson Cancer Research Center, Seattle, WA, United States; Klipsch School of Electrical and Computer Engineering, New Mexico State University, Las Cruces, NM, United States","Brent R., Division of Basic Sciences, Fred Hutchinson Cancer Research Center, Seattle, WA, United States; Boucheron L., Klipsch School of Electrical and Computer Engineering, New Mexico State University, Las Cruces, NM, United States","A type of neural network first described in 2015 can be trained to translate between images of the same field of view acquired by different modalities. Trained networks can use information inherent in grayscale images of cells to predict fluorescent signals. © 2018, Springer Nature America, Inc.","","Deep Learning; Imaging, Three-Dimensional; Machine Learning; Microscopy; article; learning; microscope image; machine learning; microscopy; three dimensional imaging","Nature Publishing Group","15487091","","","30377365","Article","Scopus","2-s2.0-85055767422"
"Antonio V.A.A.; Ono N.; Saito A.; Sato T.; Altaf-Ul-Amin M.; Kanaya S.","Antonio, Victor Andrew A. (57203867603); Ono, Naoaki (35238088200); Saito, Akira (55017269800); Sato, Tetsuo (58970967200); Altaf-Ul-Amin, Md. (6602333260); Kanaya, Shigehiko (7103034802)","57203867603; 35238088200; 55017269800; 58970967200; 6602333260; 7103034802","Classification of lung adenocarcinoma transcriptome subtypes from pathological images using deep convolutional networks","2018","International Journal of Computer Assisted Radiology and Surgery","15","10.1007/s11548-018-1835-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053236143&doi=10.1007%2fs11548-018-1835-2&partnerID=40&md5=4b7086a3e17962d63cab0d544706c498","Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Japan; Data Science Center, Nara Institute of Science and Technology, Ikoma, Japan; Division for Health Service Promotion, University of Tokyo, Tokyo, Japan; Graduate School of information Science, Nara Institute of Science and Technology, Ikoma, Japan","Antonio V.A.A., Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Japan; Ono N., Data Science Center, Nara Institute of Science and Technology, Ikoma, Japan; Saito A., Division for Health Service Promotion, University of Tokyo, Tokyo, Japan; Sato T., Graduate School of information Science, Nara Institute of Science and Technology, Ikoma, Japan; Altaf-Ul-Amin M., Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Japan; Kanaya S., Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Japan","Purpose: Convolutional neural networks have become rapidly popular for image recognition and image analysis because of its powerful potential. In this paper, we developed a method for classifying subtypes of lung adenocarcinoma from pathological images using neural network whose that can evaluate phenotypic features from wider area to consider cellular distributions. Methods: In order to recognize the types of tumors, we need not only to detail features of cells, but also to incorporate statistical distribution of the different types of cells. Variants of autoencoders as building blocks of pre-trained convolutional layers of neural networks are implemented. A sparse deep autoencoder which minimizes local information entropy on the encoding layer is then proposed and applied to images of size 2048 × 2048. We applied this model for feature extraction from pathological images of lung adenocarcinoma, which is comprised of three transcriptome subtypes previously defined by the Cancer Genome Atlas network. Since the tumor tissue is composed of heterogeneous cell populations, recognition of tumor transcriptome subtypes requires more information than local pattern of cells. The parameters extracted using this approach will then be used in multiple reduction stages to perform classification on larger images. Results: We were able to demonstrate that these networks successfully recognize morphological features of lung adenocarcinoma. We also performed classification and reconstruction experiments to compare the outputs of the variants. The results showed that the larger input image that covers a certain area of the tissue is required to recognize transcriptome subtypes. The sparse autoencoder network with 2048 × 2048 input provides a 98.9% classification accuracy. Conclusion: This study shows the potential of autoencoders as a feature extraction paradigm and paves the way for a whole slide image analysis tool to predict molecular subtypes of tumors from pathological features. © 2018, The Author(s).","Autoencoder; Computer-aided diagnosis; Deep learning; Independent subspace analysis; Lung cancer","Adenocarcinoma of Lung; Biopsy; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Transcriptome; transcriptome; transcriptome; algorithm; Article; cancer classification; cell population; convolutional neural network; entropy; feature extraction; first cervical vertebra; histopathology; human; image analysis; image processing; lung adenocarcinoma; machine learning; priority journal; artificial neural network; biopsy; classification; genetics; lung adenocarcinoma; procedures","Springer Verlag","18616410","","","30159833","Article","Scopus","2-s2.0-85053236143"
"Feng B.; Hoskins W.; Zhang Y.; Meng Z.; Samuels D.C.; Wang J.; Xia R.; Liu C.; Tang J.; Guo Y.","Feng, Bing (56574673700); Hoskins, William (56516374700); Zhang, Yan (56048949400); Meng, Zibo (57222589286); Samuels, David C. (7005039547); Wang, Jiandong (57204006867); Xia, Ruofan (57194546359); Liu, Chao (57196716214); Tang, Jijun (8948124600); Guo, Yan (8555122500)","56574673700; 56516374700; 56048949400; 57222589286; 7005039547; 57204006867; 57194546359; 57196716214; 8948124600; 8555122500","Bi-stream CNN Down Syndrome screening model based on genotyping array","2018","BMC Medical Genomics","8","10.1186/s12920-018-0416-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056699742&doi=10.1186%2fs12920-018-0416-0&partnerID=40&md5=7a4d675aff026ee6c9fce0846591b021","College of Education, Zhejiang University, Hangzhou, Zhejiang, 310058, China; Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States; School of Medicine, University of New Mexico, Albuquerque, 87131, NM, United States; Vanderbilt University School of Medicine, Vanderbilt University, Nashville, 37232, TN, United States; School of Computer Science and Technology, Tianjin University, Tianjin, 300072, China","Feng B., College of Education, Zhejiang University, Hangzhou, Zhejiang, 310058, China, Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States; Hoskins W., Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States; Zhang Y., Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States, School of Computer Science and Technology, Tianjin University, Tianjin, 300072, China; Meng Z., Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States; Samuels D.C., Vanderbilt University School of Medicine, Vanderbilt University, Nashville, 37232, TN, United States; Wang J., Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States; Xia R., Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States; Liu C., College of Education, Zhejiang University, Hangzhou, Zhejiang, 310058, China; Tang J., College of Education, Zhejiang University, Hangzhou, Zhejiang, 310058, China, Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States, School of Computer Science and Technology, Tianjin University, Tianjin, 300072, China; Guo Y., School of Medicine, University of New Mexico, Albuquerque, 87131, NM, United States","Background: Human Down syndrome (DS) is usually caused by genomic micro-duplications and dosage imbalances of human chromosome 21. It is associated with many genomic and phenotype abnormalities. Even though human DS occurs about 1 per 1,000 births worldwide, which is a very high rate, researchers haven't found any effective method to cure DS. Currently, the most efficient ways of human DS prevention are screening and early detection. Methods: In this study, we used deep learning techniques and analyzed a set of Illumina genotyping array data. We built a bi-stream convolutional neural networks model to screen/predict the occurrence of DS. Firstly, we built image input data by converting the intensities of each SNP site into chromosome SNP maps. Next, we proposed a bi-stream convolutional neural network (CNN) architecture with nine layers and two branch models. We further merged two CNN branch models into one model in the fourth convolutional layer, and output the prediction in the last layer. Results: Our bi-stream CNN model achieved 99.3% average accuracies, and very low false-positive and false-negative rates, which was necessary for further applications in disease prediction and medical practice. We further visualized the feature maps and learned filters from intermediate convolutional layers, which showed the genomic patterns and correlated SNPs variations in human DS genomes. We also compared our methods with other CNN and traditional machine learning models. We further analyzed and discussed the characteristics and strengths of our bi-stream CNN model. Conclusions: Our bi-stream model used two branch CNN models to learn the local genome features and regional patterns among adjacent genes and SNP sites from two chromosomes simultaneously. It achieved the best performance in all evaluating metrics when compared with two single-stream CNN models and three traditional machine-learning algorithms. The visualized feature maps also provided opportunities to study the genomic markers and pathway components associated with Human DS, which provided insights for gene therapy and genomic medicine developments. © 2018 The Author(s).","Convolutional neural networks; Deep learning; Genotyping; Human down syndrome","Chromosome Mapping; Deep Learning; Down Syndrome; Genotype; Humans; Neural Networks (Computer); Polymorphism, Single Nucleotide; Article; artificial neural network; bi stream convolutional neural network; chromosomal mapping; controlled study; diagnostic accuracy; Down syndrome; false negative result; false positive result; genetic screening; genotype; human; human genome; medical practice; prediction; priority journal; single nucleotide polymorphism; Down syndrome; genetics; genotype","BioMed Central Ltd.","17558794","","","30453947","Article","Scopus","2-s2.0-85056699742"
"Treder M.; Lauermann J.L.; Eter N.","Treder, Maximilian (57192311362); Lauermann, Jost Lennart (57194019160); Eter, Nicole (6701536193)","57192311362; 57194019160; 6701536193","Deep learning-based detection and classification of geographic atrophy using a deep convolutional neural network classifier","2018","Graefe's Archive for Clinical and Experimental Ophthalmology","42","10.1007/s00417-018-4098-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051519801&doi=10.1007%2fs00417-018-4098-2&partnerID=40&md5=8b6d1345c5eb0b853d78716392de10cd","Department of Ophthalmology, University of Muenster Medical Center, Domagkstraße 15, Muenster, 48149, Germany","Treder M., Department of Ophthalmology, University of Muenster Medical Center, Domagkstraße 15, Muenster, 48149, Germany; Lauermann J.L., Department of Ophthalmology, University of Muenster Medical Center, Domagkstraße 15, Muenster, 48149, Germany; Eter N., Department of Ophthalmology, University of Muenster Medical Center, Domagkstraße 15, Muenster, 48149, Germany","Purpose To automatically detect and classify geographic atrophy (GA) in fundus autofluorescence (FAF) images using a deep learning algorithm. Methods In this study, FAF images of patients with GA, a healthy comparable group and a comparable group with other retinal diseases (ORDs) were used to train a multi-layer deep convolutional neural network (DCNN) (1) to detect GA and (2) to differentiate in GA between a diffuse-trickling pattern (dt-GA) and other GA FAF patterns (ndt-GA) in FAF images. 1. For the automated detection of GA in FAF images, two classifiers were built (GAvs. healthy/GAvs. ORD). The DCNN was trained and validated with 400 FAF images in each case (GA 200, healthy 200, or ORD 200). For the subsequent testing, the built classifiers were then tested with 60 untrained FAF images in each case (AMD 30, healthy 30, or ORD 30). Hereby, both classifiers automatically determined a GA probability score and a normal FAF probability score or an ORD probability score. 2. To automatically differentiate between dt-GA and ndt-GA, the DCNN was trained and validated with 200 FAF images (dt-GA 72; ndt-GA 138). Afterwards, the built classifier was tested with 20 untrained FAF images (dt-GA 10; ndt-GA 10) and a dt-GA probability score and an ndt-GA probability score was calculated. For both classifiers, the performance of the training and validation procedure after 500 training steps was measured by determining training accuracy, validation accuracy, and cross entropy. Results For the GA classifiers (GAvs. healthy/GAvs. ORD), the achieved training accuracy was 99/98%, the validation accuracy 96/91%, and the cross entropy 0.062/0.100. For the dt-GA classifier, the training accuracy was 99%, the validation accuracy 77%, and the cross entropy 0.166. The mean GA probability score was 0.981 ± 0.048 (GA vs. healthy)/0.972 ± 0.439 (GA vs. ORD) in the GA image group and 0.01 ± 0.016 (healthy)/0.061 ± 0.072 (ORD) in the comparison groups (p < 0.001). The mean dt-GA probability score was 0.807 ± 0.116 in the dt-GA image group and 0.180 ± 0.100 in the ndt-GA image group (p < 0.001). Conclusion For the first time, this study describes the use of a deep learning-based algorithm to automatically detect and classify GA in FAF. Hereby, the created classifiers showed excellent results. With further developments, this model may be a tool to predict the individual progression risk of GA and give relevant information for future therapeutic approaches. © Springer-Verlag GmbH Germany, part of Springer Nature 2018.","Deep convolutional neural network; Deep learning; Fundus autofluorescence; Geographic atrophy; Machine learning","Aged; Algorithms; Diagnosis, Computer-Assisted; Disease Progression; Female; Fluorescein Angiography; Fundus Oculi; Geographic Atrophy; Healthy Volunteers; Humans; Machine Learning; Male; Middle Aged; Neural Networks (Computer); Reproducibility of Results; Sensitivity and Specificity; Tomography, Optical Coherence; aged; algorithm; artificial neural network; classification; computer assisted diagnosis; disease exacerbation; eye fundus; female; fluorescence angiography; geographic atrophy; human; machine learning; male; middle aged; normal human; optical coherence tomography; procedures; reproducibility; sensitivity and specificity; validation study","Springer Science and Business Media Deutschland GmbH","0721832X","","GACOD","30091055","Article","Scopus","2-s2.0-85051519801"
"Rajpurkar P.; Irvin J.; Ball R.L.; Zhu K.; Yang B.; Mehta H.; Duan T.; Ding D.; Bagul A.; Langlotz C.P.; Patel B.N.; Yeom K.W.; Shpanskaya K.; Blankenberg F.G.; Seekins J.; Amrhein T.J.; Mong D.A.; Halabi S.S.; Zucker E.J.; Ng A.Y.; Lungren M.P.","Rajpurkar, Pranav (57056352800); Irvin, Jeremy (57204714660); Ball, Robyn L. (57194281693); Zhu, Kaylie (57204715724); Yang, Brandon (57204714799); Mehta, Hershel (57034933600); Duan, Tony (57207765785); Ding, Daisy (57204716164); Bagul, Aarti (57204715339); Langlotz, Curtis P. (20134955200); Patel, Bhavik N. (57202858916); Yeom, Kristen W. (16204680400); Shpanskaya, Katie (55700743700); Blankenberg, Francis G. (7004255827); Seekins, Jayne (57204714157); Amrhein, Timothy J. (55480415900); Mong, David A. (6603141114); Halabi, Safwan S. (56056991200); Zucker, Evan J. (50062153600); Ng, Andrew Y. (35410071600); Lungren, Matthew P. (36729660500)","57056352800; 57204714660; 57194281693; 57204715724; 57204714799; 57034933600; 57207765785; 57204716164; 57204715339; 20134955200; 57202858916; 16204680400; 55700743700; 7004255827; 57204714157; 55480415900; 6603141114; 56056991200; 50062153600; 35410071600; 36729660500","Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists","2018","PLoS Medicine","735","10.1371/journal.pmed.1002686","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056802942&doi=10.1371%2fjournal.pmed.1002686&partnerID=40&md5=3e61d245883af7b6fa34d726a9302f5d","Department of Computer Science, Stanford University, Stanford, CA, United States; Department of Medicine, Quantitative Sciences Unit, Stanford University, Stanford, CA, United States; Department of Radiology, Stanford University, Stanford, CA, United States; Department of Radiology, Duke University, Durham, NC, United States; Department of Radiology, University of Colorado, Denver, CO, United States","Rajpurkar P., Department of Computer Science, Stanford University, Stanford, CA, United States; Irvin J., Department of Computer Science, Stanford University, Stanford, CA, United States; Ball R.L., Department of Medicine, Quantitative Sciences Unit, Stanford University, Stanford, CA, United States; Zhu K., Department of Computer Science, Stanford University, Stanford, CA, United States; Yang B., Department of Computer Science, Stanford University, Stanford, CA, United States; Mehta H., Department of Computer Science, Stanford University, Stanford, CA, United States; Duan T., Department of Computer Science, Stanford University, Stanford, CA, United States; Ding D., Department of Computer Science, Stanford University, Stanford, CA, United States; Bagul A., Department of Computer Science, Stanford University, Stanford, CA, United States; Langlotz C.P., Department of Radiology, Stanford University, Stanford, CA, United States; Patel B.N., Department of Radiology, Stanford University, Stanford, CA, United States; Yeom K.W., Department of Radiology, Stanford University, Stanford, CA, United States; Shpanskaya K., Department of Radiology, Stanford University, Stanford, CA, United States; Blankenberg F.G., Department of Radiology, Stanford University, Stanford, CA, United States; Seekins J., Department of Radiology, Stanford University, Stanford, CA, United States; Amrhein T.J., Department of Radiology, Duke University, Durham, NC, United States; Mong D.A., Department of Radiology, University of Colorado, Denver, CO, United States; Halabi S.S., Department of Radiology, Stanford University, Stanford, CA, United States; Zucker E.J., Department of Radiology, Stanford University, Stanford, CA, United States; Ng A.Y., Department of Computer Science, Stanford University, Stanford, CA, United States; Lungren M.P., Department of Radiology, Stanford University, Stanford, CA, United States","Background: Chest radiograph interpretation is critical for the detection of thoracic diseases, including tuberculosis and lung cancer, which affect millions of people worldwide each year. This time-consuming task typically requires expert radiologists to read the images, leading to fatigue-based diagnostic error and lack of diagnostic expertise in areas of the world where radiologists are not available. Recently, deep learning approaches have been able to achieve expert-level performance in medical image interpretation tasks, powered by large network architectures and fueled by the emergence of large labeled datasets. The purpose of this study is to investigate the performance of a deep learning algorithm on the detection of pathologies in chest radiographs compared with practicing radiologists. Methods and findings: We developed CheXNeXt, a convolutional neural network to concurrently detect the presence of 14 different pathologies, including pneumonia, pleural effusion, pulmonary masses, and nodules in frontal-view chest radiographs. CheXNeXt was trained and internally validated on the ChestX-ray8 dataset, with a held-out validation set consisting of 420 images, sampled to contain at least 50 cases of each of the original pathology labels. On this validation set, the majority vote of a panel of 3 board-certified cardiothoracic specialist radiologists served as reference standard. We compared CheXNeXt’s discriminative performance on the validation set to the performance of 9 radiologists using the area under the receiver operating characteristic curve (AUC). The radiologists included 6 board-certified radiologists (average experience 12 years, range 4–28 years) and 3 senior radiology residents, from 3 academic institutions. We found that CheXNeXt achieved radiologist-level performance on 11 pathologies and did not achieve radiologist-level performance on 3 pathologies. The radiologists achieved statistically significantly higher AUC performance on cardiomegaly, emphysema, and hiatal hernia, with AUCs of 0.888 (95% confidence interval [CI] 0.863–0.910), 0.911 (95% CI 0.866–0.947), and 0.985 (95% CI 0.974–0.991), respectively, whereas CheXNeXt’s AUCs were 0.831 (95% CI 0.790–0.870), 0.704 (95% CI 0.567–0.833), and 0.851 (95% CI 0.785–0.909), respectively. CheXNeXt performed better than radiologists in detecting atelectasis, with an AUC of 0.862 (95% CI 0.825–0.895), statistically significantly higher than radiologists' AUC of 0.808 (95% CI 0.777–0.838); there were no statistically significant differences in AUCs for the other 10 pathologies. The average time to interpret the 420 images in the validation set was substantially longer for the radiologists (240 minutes) than for CheXNeXt (1.5 minutes). The main limitations of our study are that neither CheXNeXt nor the radiologists were permitted to use patient history or review prior examinations and that evaluation was limited to a dataset from a single institution. Conclusions: In this study, we developed and validated a deep learning algorithm that classified clinically important abnormalities in chest radiographs at a performance level comparable to practicing radiologists. Once tested prospectively in clinical settings, the algorithm could have the potential to expand patient access to chest radiograph diagnostics. © 2018 Rajpurkar et al. http://creativecommons.org/licenses/by/4.0/.","","Clinical Competence; Deep Learning; Diagnosis, Computer-Assisted; Humans; Pneumonia; Predictive Value of Tests; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Radiologists; Reproducibility of Results; Retrospective Studies; accuracy; algorithm; area under the curve; Article; artificial neural network; atelectasis; cardiomegaly; clinical practice; comparative study; diagnostic error; edema; effusion; emphysema; fatigue; fibrosis; hernia; lung nodule; machine learning; pathology; performance; pleura effusion; pleura thickening; pneumonia; pneumothorax; predictive value; prevalence; probability learning; radiodiagnosis; radiologist; receiver operating characteristic; sensitivity and specificity; statistical analysis; thorax radiography; training; validation process; clinical competence; computer assisted diagnosis; diagnostic imaging; human; procedures; radiologist; reproducibility; retrospective study; thorax radiography; validation study","Public Library of Science","15491277","","","30457988","Article","Scopus","2-s2.0-85056802942"
"Rivas R.; Montazeri N.; Le N.X.T.; Hristidis V.","Rivas, Ryan (57188680266); Montazeri, Niloofar (55769964100); Le, Nhat XT (57194612821); Hristidis, Vagelis (6507537461)","57188680266; 55769964100; 57194612821; 6507537461","Automatic classification of online doctor reviews: Evaluation of text classifier algorithms","2018","Journal of Medical Internet Research","25","10.2196/11141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056546927&doi=10.2196%2f11141&partnerID=40&md5=5386c02058a130e50a9dc2c2fed2a714","Department of Computer Science and Engineering, University of California, Riverside, 363 Winston Chung Hall, 900 University Avenue, Riverside, 92521, CA, United States","Rivas R., Department of Computer Science and Engineering, University of California, Riverside, 363 Winston Chung Hall, 900 University Avenue, Riverside, 92521, CA, United States; Montazeri N., Department of Computer Science and Engineering, University of California, Riverside, 363 Winston Chung Hall, 900 University Avenue, Riverside, 92521, CA, United States; Le N.X.T., Department of Computer Science and Engineering, University of California, Riverside, 363 Winston Chung Hall, 900 University Avenue, Riverside, 92521, CA, United States; Hristidis V., Department of Computer Science and Engineering, University of California, Riverside, 363 Winston Chung Hall, 900 University Avenue, Riverside, 92521, CA, United States","Background: An increasing number of doctor reviews are being generated by patients on the internet. These reviews address a diverse set of topics (features), including wait time, office staff, doctor’s skills, and bedside manners. Most previous work on automatic analysis of Web-based customer reviews assumes that (1) product features are described unambiguously by a small number of keywords, for example, battery for phones and (2) the opinion for each feature has a positive or negative sentiment. However, in the domain of doctor reviews, this setting is too restrictive: a feature such as visit duration for doctor reviews may be expressed in many ways and does not necessarily have a positive or negative sentiment. Objective: This study aimed to adapt existing and propose novel text classification methods on the domain of doctor reviews. These methods are evaluated on their accuracy to classify a diverse set of doctor review features. Methods: We first manually examined a large number of reviews to extract a set of features that are frequently mentioned in the reviews. Then we proposed a new algorithm that goes beyond bag-of-words or deep learning classification techniques by leveraging natural language processing (NLP) tools. Specifically, our algorithm automatically extracts dependency tree patterns and uses them to classify review sentences. Results: We evaluated several state-of-the-art text classification algorithms as well as our dependency tree-based classifier algorithm on a real-world doctor review dataset. We showed that methods using deep learning or NLP techniques tend to outperform traditional bag-of-words methods. In our experiments, the 2 best methods used NLP techniques; on average, our proposed classifier performed 2.19% better than an existing NLP-based method, but many of its predictions of specific opinions were incorrect. Conclusions: We conclude that it is feasible to classify doctor reviews. Automatically classifying these reviews would allow patients to easily search for doctors based on their personal preference criteria. ©Ryan Rivas, Niloofar Montazeri, Nhat XT Le, Vagelis Hristidis.","Health care; Patient reported outcome measures; Patient satisfaction; Quality indicators; Supervised machine learning","Algorithms; Attitude; Humans; Internet; Language; Machine Learning; Patient Reported Outcome Measures; Physicians; Quality Indicators, Health Care; Review Literature as Topic; adult; article; classification algorithm; classifier; human; natural language processing; patient satisfaction; patient-reported outcome; prediction; supervised machine learning; algorithm; attitude; health care quality; Internet; language; literature; machine learning; patient-reported outcome; physician; standards","JMIR Publications Inc.","14388871","","","30425030","Article","Scopus","2-s2.0-85056546927"
"Berishvili V.P.; Voronkov A.E.; Radchenko E.V.; Palyulin V.A.","Berishvili, Vladimir P. (57201620970); Voronkov, Andrew E. (10046263700); Radchenko, Eugene V. (8088593300); Palyulin, Vladimir A. (7004680906)","57201620970; 10046263700; 8088593300; 7004680906","Machine Learning Classification Models to Improve the Docking-based Screening: A Case of PI3K-Tankyrase Inhibitors","2018","Molecular Informatics","21","10.1002/minf.201800030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056345937&doi=10.1002%2fminf.201800030&partnerID=40&md5=0f01289f362c3912ddfe9e00f4af82d2","Department of Chemistry, Lomonosov Moscow State University, Leninskie gory 1/3, Moscow, 119991, Russian Federation; Digital BioPharm Ltd., Hovseterveien 42 A, H0301, Oslo, 0768, Norway","Berishvili V.P., Department of Chemistry, Lomonosov Moscow State University, Leninskie gory 1/3, Moscow, 119991, Russian Federation; Voronkov A.E., Department of Chemistry, Lomonosov Moscow State University, Leninskie gory 1/3, Moscow, 119991, Russian Federation, Digital BioPharm Ltd., Hovseterveien 42 A, H0301, Oslo, 0768, Norway; Radchenko E.V., Department of Chemistry, Lomonosov Moscow State University, Leninskie gory 1/3, Moscow, 119991, Russian Federation; Palyulin V.A., Department of Chemistry, Lomonosov Moscow State University, Leninskie gory 1/3, Moscow, 119991, Russian Federation","One of the major challenges in the current drug discovery is the improvement of the docking-based virtual screening performance. It is especially important in the rational design of compounds with desired polypharmacology or selectivity profiles. To address this problem, we present a methodology for the development of target-specific scoring functions possessing high screening power. These scoring functions were built using the machine learning methods for the dual target inhibitors of PI3Kα and tankyrase, promising targets for colorectal cancer therapy. The Deep Neural Network models achieve the external test AUC ROC values of 0.96 and 0.93 for the random split and 0.90 and 0.84 for the time-based split of the PI3Kα and tankyrase inhibitors, respectively. In addition, the impact of the training set size and the actives/decoys ratio on the model quality was assessed. The study demonstrates that the optimized scoring functions could significantly improve the docking screening power for each individual target. This is very useful in the design of multitarget or selective drugs wherein the screening filters are applied in sequence. © 2018 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","Docking; drug discovery; machine learning; virtual screening","Binding Sites; Databases, Chemical; Drug Discovery; Humans; Machine Learning; Molecular Docking Simulation; Phosphatidylinositol 3-Kinases; Protein Binding; Protein Kinase Inhibitors; Small Molecule Libraries; Tankyrases; phosphatidylinositol 3 kinase inhibitor; tankyrase inhibitor; phosphatidylinositol 3 kinase; protein binding; protein kinase inhibitor; tankyrase; area under the curve; Article; classification; colorectal cancer; discriminant analysis; k nearest neighbor; machine learning; molecular docking; priority journal; random forest; support vector machine; binding site; chemical database; chemistry; drug development; human; machine learning; metabolism; molecular docking; molecular library; pharmacology; procedures","Wiley-VCH Verlag","18681743","","MIONB","29901257","Article","Scopus","2-s2.0-85056345937"
"Zeng H.; Yang C.; Dai G.; Qin F.; Zhang J.; Kong W.","Zeng, Hong (52164967700); Yang, Chen (57221193978); Dai, Guojun (7202576846); Qin, Feiwei (55485132000); Zhang, Jianhai (36717145000); Kong, Wanzeng (12804023400)","52164967700; 57221193978; 7202576846; 55485132000; 36717145000; 12804023400","EEG classification of driver mental states by deep learning","2018","Cognitive Neurodynamics","148","10.1007/s11571-018-9496-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050196689&doi=10.1007%2fs11571-018-9496-y&partnerID=40&md5=a773f9236c5198d15fd03cb546167646","School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China","Zeng H., School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Yang C., School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Dai G., School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Qin F., School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Zhang J., School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Kong W., School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China","Driver fatigue is attracting more and more attention, as it is the main cause of traffic accidents, which bring great harm to society and families. This paper proposes to use deep convolutional neural networks, and deep residual learning, to predict the mental states of drivers from electroencephalography (EEG) signals. Accordingly we have developed two mental state classification models called EEG-Conv and EEG-Conv-R. Tested on intra- and inter-subject, our results show that both models outperform the traditional LSTM- and SVM-based classifiers. Our major findings include (1) Both EEG-Conv and EEG-Conv-R yield very good classification performance for mental state prediction; (2) EEG-Conv-R is more suitable for inter-subject mental state prediction; (3) EEG-Conv-R converges more quickly than EEG-Conv. In summary, our proposed classifiers have better predictive power and are promising for application in practical brain-computer interaction. © 2018, Springer Nature B.V.","Driver fatigue; EEG-Conv; EEG-Conv-R; Electroencephalography (EEG); Residual learning","adult; Article; biological model; car driver; classifier; controlled study; disease classification; dysthymia; electroencephalography; functional assessment; human; human computer interaction; learning; long term memory; mental function; nerve cell network; prediction; short term memory; support vector machine","Springer Netherlands","18714080","","","","Article","Scopus","2-s2.0-85050196689"
"Hou F.; Wu Z.; Hu Z.; Xiao Z.; Wang L.; Zhang X.; Li G.","Hou, Fang (57200914526); Wu, Zhenyao (57198578540); Hu, Zheng (57210558852); Xiao, Zhourong (57190250455); Wang, Li (57043972700); Zhang, Xiangwen (57208478294); Li, Guozhu (55621529900)","57200914526; 57198578540; 57210558852; 57190250455; 57043972700; 57208478294; 55621529900","Comparison Study on the Prediction of Multiple Molecular Properties by Various Neural Networks","2018","Journal of Physical Chemistry A","24","10.1021/acs.jpca.8b09376","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056803403&doi=10.1021%2facs.jpca.8b09376&partnerID=40&md5=0f4f96703e6660cabc63e011111d685d","Key Laboratory for Green Chemical Technology, Ministry of Education, School of Chemical Engineering and Technology, Tianjin University, Tianjin, 300072, China; Collaborative Innovation Center of Chemical Science and Engineering (Tianjin), Tianjin, 300072, China; School of Computer Software, Tianjin University, Tianjin, 300072, China","Hou F., Key Laboratory for Green Chemical Technology, Ministry of Education, School of Chemical Engineering and Technology, Tianjin University, Tianjin, 300072, China; Wu Z., School of Computer Software, Tianjin University, Tianjin, 300072, China; Hu Z., Key Laboratory for Green Chemical Technology, Ministry of Education, School of Chemical Engineering and Technology, Tianjin University, Tianjin, 300072, China; Xiao Z., Key Laboratory for Green Chemical Technology, Ministry of Education, School of Chemical Engineering and Technology, Tianjin University, Tianjin, 300072, China; Wang L., Key Laboratory for Green Chemical Technology, Ministry of Education, School of Chemical Engineering and Technology, Tianjin University, Tianjin, 300072, China, Collaborative Innovation Center of Chemical Science and Engineering (Tianjin), Tianjin, 300072, China; Zhang X., Key Laboratory for Green Chemical Technology, Ministry of Education, School of Chemical Engineering and Technology, Tianjin University, Tianjin, 300072, China, Collaborative Innovation Center of Chemical Science and Engineering (Tianjin), Tianjin, 300072, China; Li G., Key Laboratory for Green Chemical Technology, Ministry of Education, School of Chemical Engineering and Technology, Tianjin University, Tianjin, 300072, China, Collaborative Innovation Center of Chemical Science and Engineering (Tianjin), Tianjin, 300072, China","Various neural networks, including a single layer neural network (SLNN), a deep neural network (DNN) with multilayers, and a convolution neural network (CNN) have been developed and investigated to predict multiple molecular properties simultaneously. The data set of this work contains∼134 kilo molecules and their 15 properties (including rotational constant A, B, and C, dipole moment, isotropic polarizability, energy of HOMO, energy of LUMO, HOMO-LUMO gap energy, electronic spatial extent, zero point vibrational energy, internal energy at 0 K, internal energy at 298.15 K, enthalpy at 298.15 K, free energy at 298.15 K, and heat capacity at 298.15 K) at the hybrid density functional theory (DFT) level from the QM9 database. Coulomb matrix (CM) converted from the database representing every molecule uniquely and its eigenvalue are respectively used as the input of machine learning. The accuracies of predictions have been compared among SLNN, DNN and CNN by analyzing their mean absolute errors (MAEs). Using eigenvalues as input, both SLNN and DNN can give higher accuracy for the prediction of specific energy properties (U0, U, H, and G). For the prediction of all 15 molecular properties at a time, DNN with a 3-layers network exhibits the best results using the full CM as input. The number of layers in DNN play a key role in the prediction of multiple molecular properties simultaneously. This work may provide possibility and guidance for the selection of different neural networks and input data forms for prediction and validation of multiple parameters according to different needs. Copyright © 2018 American Chemical Society.","","Density functional theory; Eigenvalues and eigenfunctions; Forecasting; Free energy; Molecules; Network layers; Specific heat; Convolution neural network; Hybrid density functional theory; Internal energies; Mean absolute error; Molecular properties; Multiple parameters; Rotational constants; Zero-point vibrational energies; Deep neural networks","American Chemical Society","10895639","","JPCAF","30285444","Article","Scopus","2-s2.0-85056803403"
"Han W.; Yang Z.; Lu J.; Xie S.","Han, Wei (57196720018); Yang, Zuyuan (24451480400); Lu, Jun (57199237929); Xie, Shengli (7401936935)","57196720018; 24451480400; 57199237929; 7401936935","Supervised threshold-based heart sound classification algorithm","2018","Physiological Measurement","24","10.1088/1361-6579/aae7fa","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057725866&doi=10.1088%2f1361-6579%2faae7fa&partnerID=40&md5=49721d0deb166c8f0c65b6049babc443","School of Automation, Guangdong University of Technology, Guangzhou, China; Guangdong Institute of Intelligent Manufacturing, Guangzhou, China","Han W., School of Automation, Guangdong University of Technology, Guangzhou, China, Guangdong Institute of Intelligent Manufacturing, Guangzhou, China; Yang Z., School of Automation, Guangdong University of Technology, Guangzhou, China; Lu J., School of Automation, Guangdong University of Technology, Guangzhou, China; Xie S., School of Automation, Guangdong University of Technology, Guangzhou, China","Objective: Deep classification networks have been one of the predominant methods for classifying heart sound recordings. To satisfy their demand for sample size, the most commonly used method for data augmentation is that which divides each heart sound instance into a number of segments, with each segment labelled as the same category as its origin and used as a new sample for training or forecasting. However, performing this poses a crucial issue as to how to determine the category of a predicted heart sound instance from its segments' prediction results. Approach: To solve this issue, this paper establishes a mathematical formula to connect the classification performance of these heart sound instances with the prediction results of their segments via a threshold which is supervised by the training set. The optimal value of the proposed threshold is calculated by maximizing the prediction accuracy of the training instances. Seeking the optimal threshold by a gradient-based method, we prove that a continuous function can closely approximate a part of the function of accuracy which transforms the discrete function of accuracy into a continuous function. The optimal threshold is used to recognize the undetermined heart sound recording. Main results: Experimental results show the classification performance from a 10-fold cross-validation, measured by the commonly used scales of sensitivity, specificity and mean accuracy (MAcc). The proposed algorithm improves the MAcc by about 4% by modifying the baseline. In addition, the MAcc surpasses the champion of the PhysioNet/Computing in Cardiology Challenge 2016. Significance: Our study develops a methodology to determine the category of a predicted heart sound instance from its segments' prediction results, thus assisting in the data augmentation exercise which is necessary to provide sufficient data for deep classification networks. Our method significantly improves the classification performance. © 2018 Institute of Physics and Engineering in Medicine.","deep neural network; heart sound classification; heart sound segmentation; supervised threshold","Heart Sounds; Signal Processing, Computer-Assisted; Supervised Machine Learning; Audio recordings; Classification (of information); Deep neural networks; Forecasting; Functions; Heart; Classification networks; Classification performance; Deep classifications; Heart sound classification; Heart sound segmentation; Heart sounds; Sound classification; Sound segmentation; Supervised threshold; heart sound; signal processing; supervised machine learning; Cardiology","IOP Publishing Ltd","09673334","","PMEAE","30500785","Article","Scopus","2-s2.0-85057725866"
"Istepanian R.S.H.; Al-Anzi T.","Istepanian, Robert S.H. (35499491700); Al-Anzi, Turki (56648079600)","35499491700; 56648079600","m-Health 2.0: New perspectives on mobile health, machine learning and big data analytics","2018","Methods","70","10.1016/j.ymeth.2018.05.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048786854&doi=10.1016%2fj.ymeth.2018.05.015&partnerID=40&md5=fa6ec772accd3b6b89f196adcce34b54","Institute of Global Health Innovation, Faculty of Medicine – Imperial College, London, United Kingdom; Health Information Management and Technology Department, College of Public Health, Imam Abdulrahman Bin Faisal University, Saudi Arabia","Istepanian R.S.H., Institute of Global Health Innovation, Faculty of Medicine – Imperial College, London, United Kingdom; Al-Anzi T., Health Information Management and Technology Department, College of Public Health, Imam Abdulrahman Bin Faisal University, Saudi Arabia","Mobile health (m-Health) has been repeatedly called the biggest technological breakthrough of our modern times. Similarly, the concept of big data in the context of healthcare is considered one of the transformative drivers for intelligent healthcare delivery systems. In recent years, big data has become increasingly synonymous with mobile health, however key challenges of ‘Big Data and mobile health’ remain largely untackled. This is becoming particularly important with the continued deluge of the structured and unstructured data sets generated on daily basis from the proliferation of mobile health applications within different healthcare systems and products globally. The aim of this paper is of twofold. First we present the relevant big data issues from the mobile health (m-Health) perspective. In particular we discuss these issues from the technological areas and building blocks (communications, sensors and computing) of mobile health and the newly defined (m-Health 2.0) concept. The second objective is to present the relevant rapprochement issues of big m-Health data analytics with m-Health. Further, we also present the current and future roles of machine and deep learning within the current smart phone centric m-health model. The critical balance between these two important areas will depend on how different stakeholder from patients, clinicians, healthcare providers, medical and m-health market businesses and regulators will perceive these developments. These new perspectives are essential for better understanding the fine balance between the new insights of how intelligent and connected the future mobile health systems will look like and the inherent risks and clinical complexities associated with the big data sets and analytical tools used in these systems. These topics will be subject for extensive work and investigations in the foreseeable future for the areas of data analytics, computational and artificial intelligence methods applied for mobile health. © 2018 Elsevier Inc.","","Artificial Intelligence; Big Data; Data Mining; Data Science; Humans; Machine Learning; Smartphone; Telemedicine; Article; artificial intelligence; big data analytics; clinician; computer analysis; data analysis; government regulation; health care industry; health care personnel; human; interpersonal communication; machine learning; marketing; patient; priority journal; data mining; smartphone; telemedicine; trends","Academic Press Inc.","10462023","","MTHDE","29890285","Article","Scopus","2-s2.0-85048786854"
"Miao S.; Xu T.; Wu Y.; Xie H.; Wang J.; Jing S.; Zhang Y.; Zhang X.; Yang Y.; Zhang X.; Shan T.; Wang L.; Xu H.; Wang S.; Liu Y.","Miao, Shumei (56200452600); Xu, Tingyu (57199173957); Wu, Yonghui (55645924700); Xie, Hui (55586089700); Wang, Jingqi (56580826200); Jing, Shenqi (7102238007); Zhang, Yaoyun (56500740300); Zhang, Xiaoliang (57203620419); Yang, Yinshuang (57203620147); Zhang, Xin (57207317843); Shan, Tao (54080347400); Wang, Li (57188740317); Xu, Hua (55493876700); Wang, Shui (8233016100); Liu, Yun (55899963300)","56200452600; 57199173957; 55645924700; 55586089700; 56580826200; 7102238007; 56500740300; 57203620419; 57203620147; 57207317843; 54080347400; 57188740317; 55493876700; 8233016100; 55899963300","Extraction of BI-RADS findings from breast ultrasound reports in Chinese using deep learning approaches","2018","International Journal of Medical Informatics","26","10.1016/j.ijmedinf.2018.08.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052472150&doi=10.1016%2fj.ijmedinf.2018.08.009&partnerID=40&md5=42572259279f52db3fbf1328f89bb26e","Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China; School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, United States; Department of Breast Diseases, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Department of Medical Informatics, Medical School, Nantong University, Nantong, Jiangsu, China; Department of Breast Diseases, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Guangzhou Rd 300, Nanjing, 210096, Jiangsu, China","Miao S., Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China, Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China; Xu T., Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China, Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China; Wu Y., School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, United States; Xie H., Department of Breast Diseases, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China; Wang J., School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, United States; Jing S., Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China, Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China; Zhang Y., School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, United States; Zhang X., Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China, Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China; Yang Y., Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China, Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China; Zhang X., Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China, Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China; Shan T., Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China, Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China; Wang L., Department of Medical Informatics, Medical School, Nantong University, Nantong, Jiangsu, China; Xu H., School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, United States; Wang S., Department of Breast Diseases, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China, Department of Breast Diseases, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Guangzhou Rd 300, Nanjing, 210096, Jiangsu, China; Liu Y., Department of Information, The First Affiliated Hospital of Nanjing Medical University & Jiangsu Province Hospital, Nanjing, Jiangsu, China, Institute of Medical Informatics and Management, Nanjing Medical University, Nanjing, Jiangsu, China","Background: The wide adoption of electronic health record systems (EHRs) in hospitals in China has made large amounts of data available for clinical research including breast cancer. Unfortunately, much of detailed clinical information is embedded in clinical narratives e.g., breast radiology reports. The American College of Radiology (ACR) has developed a Breast Imaging Reporting and Data System (BI-RADS) to standardize the clinical findings from breast radiology reports. Objectives: This study aims to develop natural language processing (NLP) methods to extract BI-RADS findings from breast ultrasound reports in Chinese, thus to support clinical operation and breast cancer research in China. Methods: We developed and compared three different types of NLP approaches, including a rule-based method, a traditional machine learning-based method using the Conditional Random Fields (CRF) algorithm, and deep learning-based approaches, to extract all BI-RADS finding categories from breast ultrasound reports in Chinese. Results: Using a manually annotated dataset containing 540 reports, our evaluation shows that the deep learning-based method achieved the best F1-score of 0.904, when compared with rule-based and CRF-based approaches (0.848 and 0.881 respectively). Conclusions: This is the first study that applies deep learning technologies to BI-RADS findings extraction in Chinese breast ultrasound reports, demonstrating its potential on enabling international collaborations on breast cancer research. © 2018 Elsevier B.V.","Clinical natural language processing; Deep learning; Named entity recognition","Algorithms; Breast Neoplasms; China; Deep Learning; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Radiology Information Systems; Ultrasonography, Mammary; Clinical research; Diseases; Extraction; Learning algorithms; Medical imaging; Natural language processing systems; Radiation; Radiology; Random processes; Ultrasonics; American college of radiologies; Breast imaging reporting and data systems; Conditional random field; Electronic health record systems; International collaborations; Learning-based approach; Learning-based methods; Named entity recognition; algorithm; Article; breast cancer; breast imaging reporting and data system; cancer patient; cancer research; Chinese; clinical evaluation; comparative study; Conditional Random Fields algorithm; data extraction; deep learning; echomammography; elasticity; electronic health record; human; information processing; language processing; machine learning; natural language processing; priority journal; vascularization; algorithm; breast tumor; China; computer assisted diagnosis; diagnostic imaging; echomammography; female; machine learning; procedures; radiology information system; Deep learning","Elsevier Ireland Ltd","13865056","","IJMIF","30342682","Article","Scopus","2-s2.0-85052472150"
"Lee H.-C.; Yoon S.B.; Yang S.-M.; Kim W.H.; Ryu H.-G.; Jung C.-W.; Suh K.-S.; Lee K.H.","Lee, Hyung-Chul (55578791400); Yoon, Soo Bin (57205093484); Yang, Seong-Mi (56549144700); Kim, Won Ho (55509272400); Ryu, Ho-Geol (7202277246); Jung, Chul-Woo (13309597200); Suh, Kyung-Suk (7202645048); Lee, Kook Hyun (8116218500)","55578791400; 57205093484; 56549144700; 55509272400; 7202277246; 13309597200; 7202645048; 8116218500","Prediction of acute kidney injury after liver transplantation: Machine learning approaches vs. logistic regression model","2018","Journal of Clinical Medicine","126","10.3390/jcm7110428","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063322319&doi=10.3390%2fjcm7110428&partnerID=40&md5=ffafca206c909dc4e6f0f49df4597d45","Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul, 03080, South Korea; Department of Anesthesiology and Pain Medicine, Seoul National University College of Medicine, Seoul, 03080, South Korea; Department of Surgery, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea","Lee H.-C., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul, 03080, South Korea; Yoon S.B., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul, 03080, South Korea; Yang S.-M., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul, 03080, South Korea; Kim W.H., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul, 03080, South Korea, Department of Anesthesiology and Pain Medicine, Seoul National University College of Medicine, Seoul, 03080, South Korea; Ryu H.-G., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul, 03080, South Korea, Department of Anesthesiology and Pain Medicine, Seoul National University College of Medicine, Seoul, 03080, South Korea; Jung C.-W., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul, 03080, South Korea, Department of Anesthesiology and Pain Medicine, Seoul National University College of Medicine, Seoul, 03080, South Korea; Suh K.-S., Department of Surgery, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea; Lee K.H., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul, 03080, South Korea, Department of Anesthesiology and Pain Medicine, Seoul National University College of Medicine, Seoul, 03080, South Korea","Acute kidney injury (AKI) after liver transplantation has been reported to be associated with increased mortality. Recently, machine learning approaches were reported to have better predictive ability than the classic statistical analysis. We compared the performance of machine learning approaches with that of logistic regression analysis to predict AKI after liver transplantation. We reviewed 1211 patients and preoperative and intraoperative anesthesia and surgery-related variables were obtained. The primary outcome was postoperative AKI defined by acute kidney injury network criteria. The following machine learning techniques were used: decision tree, random forest, gradient boosting machine, support vector machine, naïve Bayes, multilayer perceptron, and deep belief networks. These techniques were compared with logistic regression analysis regarding the area under the receiver-operating characteristic curve (AUROC). AKI developed in 365 patients (30.1%). The performance in terms of AUROC was best in gradient boosting machine among all analyses to predict AKI of all stages (0.90, 95% confidence interval [CI] 0.86–0.93) or stage 2 or 3 AKI. The AUROC of logistic regression analysis was 0.61 (95% CI 0.56–0.66). Decision tree and random forest techniques showed moderate performance (AUROC 0.86 and 0.85, respectively). The AUROC of support the vector machine, naïve Bayes, neural network, and deep belief network was smaller than that of the other models. In our comparison of seven machine learning approaches with logistic regression analysis, the gradient boosting machine showed the best performance with the highest AUROC. An internet-based risk estimator was developed based on our model of gradient boosting. However, prospective studies are required to validate our results. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Acute kidney injury; Liver transplantation; Machine learning","basiliximab; dopamine; ephedrine; methylprednisolone; noradrenalin; acute kidney failure; area under the curve; Article; cardiac index; Child Pugh score; cohort analysis; decision tree; female; human; liver transplantation; machine learning; major clinical study; male; mortality; observational study; perceptron; random forest; receiver operating characteristic; retrospective study; support vector machine; urine volume","MDPI","20770383","","","","Article","Scopus","2-s2.0-85063322319"
"Liu C.; Bellec G.; Vogginger B.; Kappel D.; Partzsch J.; Neumärker F.; Höppner S.; Maass W.; Furber S.B.; Legenstein R.; Mayr C.G.","Liu, Chen (57196115636); Bellec, Guillaume (56272871100); Vogginger, Bernhard (50662105600); Kappel, David (56094973100); Partzsch, Johannes (30567750400); Neumärker, Felix (57193132873); Höppner, Sebastian (35223172800); Maass, Wolfgang (7005129380); Furber, Steve B. (7004528676); Legenstein, Robert (6603322416); Mayr, Christian G. (16313308800)","57196115636; 56272871100; 50662105600; 56094973100; 30567750400; 57193132873; 35223172800; 7005129380; 7004528676; 6603322416; 16313308800","Memory-efficient deep learning on a SpiNNaker 2 prototype","2018","Frontiers in Neuroscience","39","10.3389/fnins.2018.00840","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057173985&doi=10.3389%2ffnins.2018.00840&partnerID=40&md5=a90b2fb3d00c00ef2e60e3bf1f3b8531","VLSI-Systems and Neuromorphic Circuits, Department of Electrical Engineering and Information Technology, Institute of Circuits and Systems, Technische Universität Dresden, Dresden, Germany; Institute for Theoretical Computer Science, Graz University of Technology, Graz, Austria; Bernstein Center for Computational Neuroscience, III Physikalisches Institut – Biophysik, Georg-August Universität, Göttingen, Germany; Advanced Processor Technologies Group, School of Computer Science, University of Manchester, Manchester, United Kingdom","Liu C., VLSI-Systems and Neuromorphic Circuits, Department of Electrical Engineering and Information Technology, Institute of Circuits and Systems, Technische Universität Dresden, Dresden, Germany; Bellec G., Institute for Theoretical Computer Science, Graz University of Technology, Graz, Austria; Vogginger B., VLSI-Systems and Neuromorphic Circuits, Department of Electrical Engineering and Information Technology, Institute of Circuits and Systems, Technische Universität Dresden, Dresden, Germany; Kappel D., VLSI-Systems and Neuromorphic Circuits, Department of Electrical Engineering and Information Technology, Institute of Circuits and Systems, Technische Universität Dresden, Dresden, Germany, Institute for Theoretical Computer Science, Graz University of Technology, Graz, Austria, Bernstein Center for Computational Neuroscience, III Physikalisches Institut – Biophysik, Georg-August Universität, Göttingen, Germany; Partzsch J., VLSI-Systems and Neuromorphic Circuits, Department of Electrical Engineering and Information Technology, Institute of Circuits and Systems, Technische Universität Dresden, Dresden, Germany; Neumärker F., VLSI-Systems and Neuromorphic Circuits, Department of Electrical Engineering and Information Technology, Institute of Circuits and Systems, Technische Universität Dresden, Dresden, Germany; Höppner S., VLSI-Systems and Neuromorphic Circuits, Department of Electrical Engineering and Information Technology, Institute of Circuits and Systems, Technische Universität Dresden, Dresden, Germany; Maass W., Institute for Theoretical Computer Science, Graz University of Technology, Graz, Austria; Furber S.B., Advanced Processor Technologies Group, School of Computer Science, University of Manchester, Manchester, United Kingdom; Legenstein R., Institute for Theoretical Computer Science, Graz University of Technology, Graz, Austria; Mayr C.G., VLSI-Systems and Neuromorphic Circuits, Department of Electrical Engineering and Information Technology, Institute of Circuits and Systems, Technische Universität Dresden, Dresden, Germany","The memory requirement of deep learning algorithms is considered incompatible with the memory restriction of energy-efficient hardware. A low memory footprint can be achieved by pruning obsolete connections or reducing the precision of connection strengths after the network has been trained. Yet, these techniques are not applicable to the case when neural networks have to be trained directly on hardware due to the hard memory constraints. Deep Rewiring (DEEP R) is a training algorithm which continuously rewires the network while preserving very sparse connectivity all along the training procedure. We apply DEEP R to a deep neural network implementation on a prototype chip of the 2nd generation SpiNNaker system. The local memory of a single core on this chip is limited to 64 KB and a deep network architecture is trained entirely within this constraint without the use of external memory. Throughout training, the proportion of active connections is limited to 1.3%. On the handwritten digits dataset MNIST, this extremely sparse network achieves 96.6% classification accuracy at convergence. Utilizing the multi-processor feature of the SpiNNaker system, we found very good scaling in terms of computation time, per-core memory consumption, and energy constraints. When compared to a X86 CPU implementation, neural network training on the SpiNNaker 2 prototype improves power and energy consumption by two orders of magnitude. Copyright © 2018 Liu, Bellec, Vogginger, Kappel, Partzsch, Neumärker, Höppner, Maass, Furber, Legenstein and Mayr.","Deep rewiring; Energy efficient hardware; Memory footprint; Parallelism; Pruning; Sparsity; SpiNNaker","algorithm; Article; artificial neural network; classification; energy; functional connectivity; machine learning; measurement accuracy; memory; training","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85057173985"
"Mardt A.; Pasquali L.; Wu H.; Noé F.","Mardt, Andreas (57200144757); Pasquali, Luca (57200150166); Wu, Hao (55703652800); Noé, Frank (23985788000)","57200144757; 57200150166; 55703652800; 23985788000","VAMPnets for deep learning of molecular kinetics","2018","Nature Communications","347","10.1038/s41467-017-02388-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039927762&doi=10.1038%2fs41467-017-02388-1&partnerID=40&md5=81667d2532bbee1dc2648b58138ce93c","Department of Mathematics and Computer Science, Freie Universität Berlin, Arnimallee 6, Berlin, 14195, Germany","Mardt A., Department of Mathematics and Computer Science, Freie Universität Berlin, Arnimallee 6, Berlin, 14195, Germany; Pasquali L., Department of Mathematics and Computer Science, Freie Universität Berlin, Arnimallee 6, Berlin, 14195, Germany; Wu H., Department of Mathematics and Computer Science, Freie Universität Berlin, Arnimallee 6, Berlin, 14195, Germany; Noé F., Department of Mathematics and Computer Science, Freie Universität Berlin, Arnimallee 6, Berlin, 14195, Germany","There is an increasing demand for computing the relevant structures, equilibria, and long-timescale kinetics of biomolecular processes, such as protein-drug binding, from high-throughput molecular dynamics simulations. Current methods employ transformation of simulated coordinates into structural features, dimension reduction, clustering the dimension-reduced data, and estimation of a Markov state model or related model of the interconversion rates between molecular structures. This handcrafted approach demands a substantial amount of modeling expertise, as poor decisions at any step will lead to large modeling errors. Here we employ the variational approach for Markov processes (VAMP) to develop a deep learning framework for molecular kinetics using neural networks, dubbed VAMPnets. A VAMPnet encodes the entire mapping from molecular coordinates to Markov states, thus combining the whole data processing pipeline in a single end-to-end framework. Our method performs equally or better than state-of-the-art Markov modeling methods and provides easily interpretable few-state kinetic models. © 2017 The Author(s).","","Algorithms; Kinetics; Machine Learning; Markov Chains; Molecular Dynamics Simulation; Neural Networks (Computer); Protein Binding; Protein Folding; protein binding; chemical binding; data processing; error analysis; learning; Markov chain; molecular analysis; neurology; reaction kinetics; analytical error; Article; artificial neural network; chemical structure; conceptual framework; data processing; kinetics; machine learning; Markov chain; molecular dynamics; molecular model; variational approach for Markov process; algorithm; artificial neural network; kinetics; protein folding","Nature Publishing Group","20411723","","","29295994","Article","Scopus","2-s2.0-85039927762"
"Jasial S.; Gilberg E.; Blaschke T.; Bajorath J.","Jasial, Swarit (56525185600); Gilberg, Erik (56786129900); Blaschke, Thomas (57195580983); Bajorath, Jürgen (7101742328)","56525185600; 56786129900; 57195580983; 7101742328","Machine Learning Distinguishes with High Accuracy between Pan-Assay Interference Compounds That Are Promiscuous or Represent Dark Chemical Matter","2018","Journal of Medicinal Chemistry","25","10.1021/acs.jmedchem.8b01404","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056803512&doi=10.1021%2facs.jmedchem.8b01404&partnerID=40&md5=f282afa8e96c9af13540d5e43df8e459","Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany","Jasial S., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany; Gilberg E., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany; Blaschke T., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany; Bajorath J., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany","Assay interference compounds give rise to false-positives and cause substantial problems in medicinal chemistry. Nearly 500 compound classes have been designated as pan-assay interference compounds (PAINS), which typically occur as substructures in other molecules. The structural environment of PAINS substructures is likely to play an important role for their potential reactivity. Given the large number of PAINS and their highly variable structural contexts, it is difficult to study context dependence on the basis of expert knowledge. Hence, we applied machine learning to predict PAINS that are promiscuous and distinguish them from others that are mostly inactive. Surprisingly accurate models can be derived using different methods such as support vector machines, random forests, or deep neural networks. Moreover, structural features that favor correct predictions have been identified, mapped, and categorized, shedding light on the structural context dependence of PAINS effects. The machine learning models presented herein further extend the capacity of PAINS filters. © 2018 American Chemical Society.","","Computational Biology; Drug Discovery; Machine Learning; Models, Statistical; ROC Curve; Article; machine learning; measurement accuracy; nerve cell network; random forest; support vector machine; biology; drug development; procedures; receiver operating characteristic; statistical model","American Chemical Society","00222623","","JMCMA","30422657","Article","Scopus","2-s2.0-85056803512"
"Perkuhn M.; Stavrinou P.; Thiele F.; Shakirin G.; Mohan M.; Garmpis D.; Kabbasch C.; Borggrefe J.","Perkuhn, Michael (8578734900); Stavrinou, Pantelis (23989326900); Thiele, Frank (57197138262); Shakirin, Georgy (13005359900); Mohan, Manoj (57204089668); Garmpis, Dionysios (57204084355); Kabbasch, Christoph (53881506500); Borggrefe, Jan (36112753100)","8578734900; 23989326900; 57197138262; 13005359900; 57204089668; 57204084355; 53881506500; 36112753100","Clinical Evaluation of a Multiparametric Deep Learning Model for Glioblastoma Segmentation Using Heterogeneous Magnetic Resonance Imaging Data from Clinical Routine","2018","Investigative Radiology","50","10.1097/RLI.0000000000000484","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054429256&doi=10.1097%2fRLI.0000000000000484&partnerID=40&md5=2ed17b30c054e35b0381de97eaa8c56f","Department of Radiology, University Hospital Cologne, Cologne, Germany; Clinical Applications Research, Aachen, Germany; Department of Neurosurgery, University Hospital Cologne, Cologne, Germany; Philips Healthcare, Bangalore, India","Perkuhn M., Department of Radiology, University Hospital Cologne, Cologne, Germany, Clinical Applications Research, Aachen, Germany; Stavrinou P., Department of Neurosurgery, University Hospital Cologne, Cologne, Germany; Thiele F., Department of Radiology, University Hospital Cologne, Cologne, Germany, Clinical Applications Research, Aachen, Germany; Shakirin G., Department of Radiology, University Hospital Cologne, Cologne, Germany, Clinical Applications Research, Aachen, Germany; Mohan M., Philips Healthcare, Bangalore, India; Garmpis D., Department of Radiology, University Hospital Cologne, Cologne, Germany; Kabbasch C., Department of Radiology, University Hospital Cologne, Cologne, Germany; Borggrefe J., Department of Radiology, University Hospital Cologne, Cologne, Germany","Objectives The aims of this study were, first, to evaluate a deep learning-based, automatic glioblastoma (GB) tumor segmentation algorithm on clinical routine data from multiple centers and compare the results to a ground truth, manual expert segmentation, and second, to evaluate the quality of the segmentation results across heterogeneous acquisition protocols of routinely acquired clinical magnetic resonance imaging (MRI) examinations from multiple centers. Materials and Methods The data consisted of preoperative MRI scans (T1, T2, FLAIR, and contrast-enhanced [CE] T1) of 64 patients with an initial diagnosis of primary GB, which were acquired in 15 institutions with varying protocols. All images underwent preprocessing (coregistration, skull stripping, resampling to isotropic resolution, normalization) and were fed into an independently trained deep learning model based on DeepMedic, a multilayer, multiscale convolutional neural network for detection and segmentation of tumor compartments. Automatic segmentation results for the whole tumor, necrosis, and CE tumor were compared with manual segmentations. Results Whole tumor and CE tumor compartments were correctly detected in 100% of the cases; necrosis was correctly detected in 91% of the cases. A high segmentation accuracy comparable to interrater variability was achieved for the whole tumor (mean dice similarity coefficient [DSC], 0.86 ± 0.09) and CE tumor (DSC, 0.78 ± 0.15). The DSC for tumor necrosis was 0.62 ± 0.30. We have observed robust segmentation quality over heterogeneous image acquisition protocols, for example, there were no correlations between resolution and segmentation accuracy of the single tumor compartments. Furthermore, no relevant correlation was found between quality of automatic segmentation and volume of interest properties (surface-to-volume ratio and volume). Conclusions The proposed approach for automatic segmentation of GB proved to be robust on routine clinical data and showed on all tumor compartments a high automatic detection rate and a high accuracy, comparable to interrater variability. Further work on improvements of the segmentation accuracy for the necrosis compartments should be guided by the evaluation of the clinical relevance. Therefore, we propose this approach as a suitable building block for automatic tumor segmentation to support radiologists or neurosurgeons in the preoperative reading of GB MRI images and characterization of primary GB. © Wolters Kluwer Health, Inc. All rights reserved.","deep learning; Gb; Glioblastoma; machine learning; MRI; tumor segmentation","Adult; Aged; Aged, 80 and over; Algorithms; Brain; Brain Neoplasms; Deep Learning; Female; Glioblastoma; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Retrospective Studies; Article; artificial neural network; cancer diagnosis; clinical evaluation; comparative study; correlation analysis; deep learning model; diffusion weighted imaging; glioblastoma; image processing; image segmentation; information processing; learning algorithm; machine learning; magnetic field; measurement accuracy; multimodal imaging; nuclear magnetic resonance imaging; predictive value; priority journal; sensitivity analysis; susceptibility weighted imaging; tumor localization; tumor necrosis; tumor segmentation; adult; aged; algorithm; brain; brain tumor; diagnostic imaging; female; glioblastoma; human; male; middle aged; nuclear magnetic resonance imaging; procedures; retrospective study; very elderly","Lippincott Williams and Wilkins","00209996","","INVRA","29863600","Article","Scopus","2-s2.0-85054429256"
"Ito N.; Kawahira H.; Nakashima H.; Uesato M.; Miyauchi H.; Matsubara H.","Ito, Nao (57203723007); Kawahira, Hiroshi (7004663412); Nakashima, Hirotaka (18936161500); Uesato, Masaya (6602303228); Miyauchi, Hideaki (7005275770); Matsubara, Hisahiro (57221205763)","57203723007; 7004663412; 18936161500; 6602303228; 7005275770; 57221205763","Endoscopic diagnostic support system for cT1b colorectal cancer using deep learning","2018","Oncology (Switzerland)","66","10.1159/000491636","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052742338&doi=10.1159%2f000491636&partnerID=40&md5=36f30d8db72f9b57b6c5b42a058265f4","Department of Medical System Engineering, Graduate School of Engineering, Chiba University, Chiba, Japan; Center for Frontier Medical Engineering, Chiba University, Chiba, Japan; Department of Gastroenterology, Foundation for Detection of Early Gastric Carcinoma, Tokyo, Japan; Department of Frontier Surgery, Chiba University Graduate School of Medicine, Chiba, Japan; Medical Simulation Center, Jichi Medical University, 3311-1, Yakushiji, Shimotuke-Shi, Tochigi, 329-0498, Japan","Ito N., Department of Medical System Engineering, Graduate School of Engineering, Chiba University, Chiba, Japan; Kawahira H., Center for Frontier Medical Engineering, Chiba University, Chiba, Japan, Medical Simulation Center, Jichi Medical University, 3311-1, Yakushiji, Shimotuke-Shi, Tochigi, 329-0498, Japan; Nakashima H., Department of Gastroenterology, Foundation for Detection of Early Gastric Carcinoma, Tokyo, Japan; Uesato M., Department of Frontier Surgery, Chiba University Graduate School of Medicine, Chiba, Japan; Miyauchi H., Department of Frontier Surgery, Chiba University Graduate School of Medicine, Chiba, Japan; Matsubara H., Department of Frontier Surgery, Chiba University Graduate School of Medicine, Chiba, Japan","Objective: This study aimed to use convolutional neural network (CNN), a deep learning software, to assist in cT1b diagnosis. Methods: This retrospective study used 190 colon lesion images from 41 cases of colon endoscopies performed between February 2015 and October 2016. Unenhanced colon endoscopy images (520 × 520 pixels) with white light were used. Images included 14 cTis cases with endoscopic resection and 14 cT1a and 13 cT1b cases with surgical resection. Protruding, flat, and recessed lesions were analyzed. AlexNet and Caffe were used for machine learning. Fine tuning of data to increase image numbers was performed. Oversampling for the training images was conducted to avoid impartiality in image numbers, and learning was carried out. The 3-fold cross-validation method was used. Sensitivity, specificity, accuracy, and area under the curve (AUC) values in the receiver operating characteristic curve were calculated for each group. Results: The results were the average of obtained values. With CNN learning, cT1b sensitivity, specificity, and accuracy were 67.5, 89.0, and 81.2%, respectively, and AUC was 0.871. Conclusion: Quantitative diagnosis is possible using an endoscopic diagnostic support system with machine learning, without relying on the skill and experience of endoscopists. Moreover, this system could be used to objectively evaluate endoscopic diagnoses. © 2018S. Karger AG, Basel.","Colorectal cancer; Convolutional neural network; Diagnosis; Endoscopy","Area Under Curve; Colorectal Neoplasms; Colposcopy; Decision Support Systems, Clinical; Deep Learning; Humans; Machine Learning; Neoplasm Staging; Neural Networks (Computer); ROC Curve; area under the curve; Article; artificial neural network; clinical article; colon polyp; colorectal cancer; controlled study; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; endoscopic surgery; endoscopist; experience; human; intestine endoscopy; lymph node dissection; machine learning; priority journal; receiver operating characteristic; retrospective study; sensitivity and specificity; skill; software; validation process; artificial neural network; cancer staging; clinical decision support system; colorectal tumor; colposcopy; diagnostic imaging; pathology; procedures","S. Karger AG","00302414","","ONCOB","30130758","Article","Scopus","2-s2.0-85052742338"
"Almaslukh B.; Artoli A.M.; Al-Muhtadi J.","Almaslukh, Bandar (57203879108); Artoli, Abdel Monim (6602217012); Al-Muhtadi, Jalal (6602495413)","57203879108; 6602217012; 6602495413","A robust deep learning approach for position-independent smartphone-based human activity recognition","2018","Sensors (Switzerland)","59","10.3390/s18113726","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056041488&doi=10.3390%2fs18113726&partnerID=40&md5=71b4c927c1ca13bcec2301faefbda0db","Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia","Almaslukh B., Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia; Artoli A.M., Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia; Al-Muhtadi J., Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia","Recently, modern smartphones equipped with a variety of embedded-sensors, such as accelerometers and gyroscopes, have been used as an alternative platform for human activity recognition (HAR), since they are cost-effective, unobtrusive and they facilitate real-time applications. However, the majority of the related works have proposed a position-dependent HAR, i.e., the target subject has to fix the smartphone in a pre-defined position. Few studies have tackled the problem of position-independent HAR. They have tackled the problem either using handcrafted features that are less influenced by the position of the smartphone or by building a position-aware HAR. The performance of these studies still needs more improvement to produce a reliable smartphone-based HAR. Thus, in this paper, we propose a deep convolution neural network model that provides a robust position-independent HAR system. We build and evaluate the performance of the proposed model using the RealWorld HAR public dataset. We find that our deep learning proposed model increases the overall performance compared to the state-of-the-art traditional machine learning method from 84% to 88% for position-independent HAR. In addition, the position detection performance of our model improves superiorly from 89% to 98%. Finally, the recognition time of the proposed model is evaluated in order to validate the applicability of the model for real-time applications. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution neural networks; Deep learning; Human activity recognition; Position detection; Position-independent; Smartphone","Adult; Algorithms; Deep Learning; Female; Human Activities; Humans; Male; Neural Networks (Computer); Smartphone; Time Factors; Convolution; Cost effectiveness; Pattern recognition; Smartphones; Convolution neural network; Human activity recognition; Machine learning methods; Position dependents; Position detection; Position-independent; Pre-defined position; Real-time application; adult; algorithm; artificial neural network; female; human; human activities; male; smartphone; time factor; Deep learning","MDPI AG","14248220","","","30388855","Article","Scopus","2-s2.0-85056041488"
"Ma W.; Qiu Z.; Song J.; Li J.; Cheng Q.; Zhai J.; Ma C.","Ma, Wenlong (57203481073); Qiu, Zhixu (57190273914); Song, Jie (57190287109); Li, Jiajia (57211980469); Cheng, Qian (57190278914); Zhai, Jingjing (57075729300); Ma, Chuang (35203701000)","57203481073; 57190273914; 57190287109; 57211980469; 57190278914; 57075729300; 35203701000","A deep convolutional neural network approach for predicting phenotypes from genotypes","2018","Planta","111","10.1007/s00425-018-2976-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051862153&doi=10.1007%2fs00425-018-2976-9&partnerID=40&md5=0c78c201d1f8043050dd2029165179a5","State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China; Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&F University, Yangling, 712100, Shaanxi, China; Biomass Energy Center for Arid and Semi-arid Lands, Northwest A&F University, Shaanxi, 712100, Yangling, China","Ma W., State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China, Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&F University, Yangling, 712100, Shaanxi, China; Qiu Z., State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China, Biomass Energy Center for Arid and Semi-arid Lands, Northwest A&F University, Shaanxi, 712100, Yangling, China; Song J., State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China, Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&F University, Yangling, 712100, Shaanxi, China; Li J., State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China, Biomass Energy Center for Arid and Semi-arid Lands, Northwest A&F University, Shaanxi, 712100, Yangling, China; Cheng Q., State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China, Biomass Energy Center for Arid and Semi-arid Lands, Northwest A&F University, Shaanxi, 712100, Yangling, China; Zhai J., State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China, Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&F University, Yangling, 712100, Shaanxi, China; Ma C., State Key Laboratory of Crop Stress Biology for Arid Areas, Center of Bioinformatics, College of Life Sciences, Northwest A&F University, Yangling, 712100, Shaanxi, China, Key Laboratory of Biology and Genetics Improvement of Maize in Arid Area of Northwest Region, Ministry of Agriculture, Northwest A&F University, Yangling, 712100, Shaanxi, China","Main conclusion: Deep learning is a promising technology to accurately select individuals with high phenotypic values based on genotypic data. Abstract: Genomic selection (GS) is a promising breeding strategy by which the phenotypes of plant individuals are usually predicted based on genome-wide markers of genotypes. In this study, we present a deep learning method, named DeepGS, to predict phenotypes from genotypes. Using a deep convolutional neural network, DeepGS uses hidden variables that jointly represent features in genotypes when making predictions; it also employs convolution, sampling and dropout strategies to reduce the complexity of high-dimensional genotypic data. We used a large GS dataset to train DeepGS and compared its performance with other methods. The experimental results indicate that DeepGS can be used as a complement to the commonly used RR-BLUP in the prediction of phenotypes from genotypes. The complementarity between DeepGS and RR-BLUP can be utilized using an ensemble learning approach for more accurately selecting individuals with high phenotypic values, even for the absence of outlier individuals and subsets of genotypic markers. The source codes of DeepGS and the ensemble learning approach have been packaged into Docker images for facilitating their applications in different GS programs. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.","Deep learning; Ensemble learning; Genomic selection; Genotypic marker; High phenotypic values; Machine learning","Genetic Association Studies; Genome-Wide Association Study; Machine Learning; Models, Genetic; Neural Networks (Computer); Plants; Selection, Genetic; artificial neural network; biological model; genetic association study; genetic selection; genetics; genome-wide association study; machine learning; plant; procedures","Springer Verlag","00320935","","PLANA","30101399","Article","Scopus","2-s2.0-85051862153"
"Guo D.; Zhong M.; Ji H.; Liu Y.; Yang R.","Guo, Dingfei (55831472000); Zhong, Maiying (55443388900); Ji, Hongquan (56746989300); Liu, Yang (56524689000); Yang, Rui (57213114979)","55831472000; 55443388900; 56746989300; 56524689000; 57213114979","A hybrid feature model and deep learning based fault diagnosis for unmanned aerial vehicle sensors","2018","Neurocomputing","95","10.1016/j.neucom.2018.08.046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053723961&doi=10.1016%2fj.neucom.2018.08.046&partnerID=40&md5=bb08f11d75ec8b2d810320c5548afca0","School of Instrumentation Science and Opto-electronic Engineering, Beihang University, Beijing, 100191, China; College of Electrical Engineering and Automation, Shandong University of Science and Technology, Qingdao, 266590, China","Guo D., School of Instrumentation Science and Opto-electronic Engineering, Beihang University, Beijing, 100191, China; Zhong M., College of Electrical Engineering and Automation, Shandong University of Science and Technology, Qingdao, 266590, China; Ji H., College of Electrical Engineering and Automation, Shandong University of Science and Technology, Qingdao, 266590, China; Liu Y., College of Electrical Engineering and Automation, Shandong University of Science and Technology, Qingdao, 266590, China; Yang R., College of Electrical Engineering and Automation, Shandong University of Science and Technology, Qingdao, 266590, China","Fault diagnosis plays an important role in guaranteeing system safety and reliability for unmanned aerial vehicles (UAVs). In this study, a hybrid feature model and deep learning based fault diagnosis for UAV sensors is proposed. The residual signals of different sensor faults, including global positioning system (GPS), inertial measurement unit (IMU), air data system (ADS), were collected. This paper used short time fourier transform (STFT) to transform the residual signal to the corresponding time-frequency map. Then, a convolutional neural network (CNN) was used to extract the feature of the map and the fault diagnosis of the UAV sensors was implemented. Finally, the performance of the proposed methodology is evaluated through flight experiments of the UAV. From the visualization, the sensor faults information can be extracted by CNN and the fault diagnosis logic between the residuals and the health status can be constructed successfully. © 2018 Elsevier B.V.","Convolutional neural network; Deep learning; Model based fault diagnosis; Short-time fourier transform; UAV sensors","Antennas; Convolution; Deep learning; Failure analysis; Global positioning system; Neural networks; Unmanned aerial vehicles (UAV); Air data system(ADS); Convolutional neural network; Convolutional Neural Networks (CNN); Flight experiments; Inertial Measurement Unit (IMU); Model-based fault diagnosis; Short time Fourier transforms; Time-frequency map; air data system; Article; artificial neural network; deep learning based fault diagnosis; Fourier transformation; global positioning system; hybrid feature model; inertial measurement unit; machine learning; mathematical model; measurement; methodology; priority journal; simulation; statistical model; unmanned aerial vehicle sensor; Fault detection","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85053723961"
"Mouliere F.; Chandrananda D.; Piskorz A.M.; Moore E.K.; Morris J.; Ahlborn L.B.; Mair R.; Goranova T.; Marass F.; Heider K.; Wan J.C.M.; Supernat A.; Hudecova I.; Gounaris I.; Ros S.; Jimenez-Linan M.; Garcia-Corbacho J.; Patel K.; Østrup O.; Murphy S.; Eldridge M.D.; Gale D.; Stewart G.D.; Burge J.; Cooper W.N.; Van Der Heijden M.S.; Massie C.E.; Watts C.; Corrie P.; Pacey S.; Brindle K.M.; Baird R.D.; Mau-Sørensen M.; Parkinson C.A.; Smith C.G.; Brenton J.D.; Rosenfeld N.","Mouliere, Florent (36630830500); Chandrananda, Dineika (56157012000); Piskorz, Anna M. (36990433500); Moore, Elizabeth K. (57214373342); Morris, James (57222728206); Ahlborn, Lise Barlebo (56334888800); Mair, Richard (57035767600); Goranova, Teodora (14060343800); Marass, Francesco (35519967000); Heider, Katrin (57204602333); Wan, Jonathan C.M. (57190954700); Supernat, Anna (36524044200); Hudecova, Irena (56074248600); Gounaris, Ioannis (57191747575); Ros, Susana (57197168102); Jimenez-Linan, Mercedes (6506068146); Garcia-Corbacho, Javier (57191751840); Patel, Keval (56581061100); Østrup, Olga (34969587400); Murphy, Suzanne (57194390474); Eldridge, Matthew D. (57206039789); Gale, Davina (55236373600); Stewart, Grant D. (7402286894); Burge, Johanna (36570023700); Cooper, Wendy N. (7402018445); Van Der Heijden, Michiel S. (7005587639); Massie, Charles E. (24481863300); Watts, Colin (57189639274); Corrie, Pippa (6602159773); Pacey, Simon (22958012500); Brindle, Kevin M. (7006147738); Baird, Richard D. (7201567425); Mau-Sørensen, Morten (55798653200); Parkinson, Christine A. (22035609200); Smith, Christopher G. (57216536923); Brenton, James D. (58309935800); Rosenfeld, Nitzan (6604022727)","36630830500; 56157012000; 36990433500; 57214373342; 57222728206; 56334888800; 57035767600; 14060343800; 35519967000; 57204602333; 57190954700; 36524044200; 56074248600; 57191747575; 57197168102; 6506068146; 57191751840; 56581061100; 34969587400; 57194390474; 57206039789; 55236373600; 7402286894; 36570023700; 7402018445; 7005587639; 24481863300; 57189639274; 6602159773; 22958012500; 7006147738; 7201567425; 55798653200; 22035609200; 57216536923; 58309935800; 6604022727","Enhanced detection of circulating tumor DNA by fragment size analysis","2018","Science Translational Medicine","590","10.1126/scitranslmed.aat4921","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056346478&doi=10.1126%2fscitranslmed.aat4921&partnerID=40&md5=bb9ce852d4fe09283e3ceeb065f68540","Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom; Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Cambridge University Hospitals NHS Foundation Trust, Cambridge, CB2 0QQ, United Kingdom; Department of Oncology, Rigshospitalet, Copenhagen University Hospital, Copenhagen, DK-2100, Denmark; Centre for Genomic Medicine, Rigshospitalet, Copenhagen University Hospital, Copenhagen, DK-2100, Denmark; Division of Neurosurgery, Department of Clinical Neurosciences, University of Cambridge, Cambridge, CB2 0QQ, United Kingdom; Department of Biosystems Science and Engineering, ETH Zurich, Basel, 4058, Switzerland; Swiss Institute of Bioinformatics, Basel, 4058, Switzerland; Department of Medical Biotechnology, Intercollegiate Faculty of Biotechnology, University of Gdańsk, Medical University of Gdańsk, Gdańsk, 80-211, Poland; Clinical Trials Unit, Clinic Institute of Haematological and Oncological Diseases, Hospital Clinic de Barcelona, Barcelona, 170 08036, Spain; Academic Urology Group, Department of Surgery, University of Cambridge, Cambridge, CB2 0QQ, United Kingdom; Division of Molecular Carcinogenesis, Netherlands Cancer Institute, Amsterdam, 1066 CX, Netherlands; Depart-ment of Medical Oncology, Netherlands Cancer Institute, Amsterdam, 1066 CX, Netherlands; Department of Oncology, University of Cambridge, Cambridge, CB2 0XZ, United Kingdom; Institute of Cancer Genomics Science, University of Birmingham, Birmingham, B15 2TT, United Kingdom; Department of Biochemistry, University of Cambridge, Cambridge, CB2 1QW, United Kingdom; Early Phase Clinical Trials and Breast Cancer Research Teams, Cancer Research UK Cambridge Centre, Cambridge, CB2 0QQ, United Kingdom; Department of Oncology, Hutchison/MRC Research Centre, University of Cambridge, Cambridge, CB2 0XZ, United Kingdom; NIHR Cambridge Biomedical Research Centre, Cambridge, CB2 0QQ, United Kingdom; Amsterdam UMC, Vrije Universiteit Amsterdam, Department of Pathology, Cancer Center Amsterdam, de Boelelaan 1117, Amsterdam, 1081 HV, Netherlands","Mouliere F., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Amsterdam UMC, Vrije Universiteit Amsterdam, Department of Pathology, Cancer Center Amsterdam, de Boelelaan 1117, Amsterdam, 1081 HV, Netherlands; Chandrananda D., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Piskorz A.M., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Moore E.K., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Cambridge University Hospitals NHS Foundation Trust, Cambridge, CB2 0QQ, United Kingdom; Morris J., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Ahlborn L.B., Department of Oncology, Rigshospitalet, Copenhagen University Hospital, Copenhagen, DK-2100, Denmark, Centre for Genomic Medicine, Rigshospitalet, Copenhagen University Hospital, Copenhagen, DK-2100, Denmark; Mair R., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Division of Neurosurgery, Department of Clinical Neurosciences, University of Cambridge, Cambridge, CB2 0QQ, United Kingdom; Goranova T., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Marass F., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Department of Biosystems Science and Engineering, ETH Zurich, Basel, 4058, Switzerland, Swiss Institute of Bioinformatics, Basel, 4058, Switzerland; Heider K., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Wan J.C.M., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Supernat A., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Department of Medical Biotechnology, Intercollegiate Faculty of Biotechnology, University of Gdańsk, Medical University of Gdańsk, Gdańsk, 80-211, Poland; Hudecova I., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Gounaris I., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Cambridge University Hospitals NHS Foundation Trust, Cambridge, CB2 0QQ, United Kingdom; Ros S., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Jimenez-Linan M., Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Cambridge University Hospitals NHS Foundation Trust, Cambridge, CB2 0QQ, United Kingdom; Garcia-Corbacho J., Clinical Trials Unit, Clinic Institute of Haematological and Oncological Diseases, Hospital Clinic de Barcelona, Barcelona, 170 08036, Spain; Patel K., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Østrup O., Centre for Genomic Medicine, Rigshospitalet, Copenhagen University Hospital, Copenhagen, DK-2100, Denmark; Murphy S., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Eldridge M.D., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Gale D., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Stewart G.D., Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Cambridge University Hospitals NHS Foundation Trust, Cambridge, CB2 0QQ, United Kingdom, Academic Urology Group, Department of Surgery, University of Cambridge, Cambridge, CB2 0QQ, United Kingdom; Burge J., Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Academic Urology Group, Department of Surgery, University of Cambridge, Cambridge, CB2 0QQ, United Kingdom; Cooper W.N., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Van Der Heijden M.S., Division of Molecular Carcinogenesis, Netherlands Cancer Institute, Amsterdam, 1066 CX, Netherlands, Depart-ment of Medical Oncology, Netherlands Cancer Institute, Amsterdam, 1066 CX, Netherlands; Massie C.E., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Department of Oncology, University of Cambridge, Cambridge, CB2 0XZ, United Kingdom; Watts C., Institute of Cancer Genomics Science, University of Birmingham, Birmingham, B15 2TT, United Kingdom; Corrie P., Cambridge University Hospitals NHS Foundation Trust, Cambridge, CB2 0QQ, United Kingdom; Pacey S., Cambridge University Hospitals NHS Foundation Trust, Cambridge, CB2 0QQ, United Kingdom, Department of Oncology, University of Cambridge, Cambridge, CB2 0XZ, United Kingdom; Brindle K.M., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Department of Biochemistry, University of Cambridge, Cambridge, CB2 1QW, United Kingdom; Baird R.D., Early Phase Clinical Trials and Breast Cancer Research Teams, Cancer Research UK Cambridge Centre, Cambridge, CB2 0QQ, United Kingdom; Mau-Sørensen M., Department of Oncology, Rigshospitalet, Copenhagen University Hospital, Copenhagen, DK-2100, Denmark; Parkinson C.A., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Cambridge University Hospitals NHS Foundation Trust, Cambridge, CB2 0QQ, United Kingdom, Department of Oncology, Hutchison/MRC Research Centre, University of Cambridge, Cambridge, CB2 0XZ, United Kingdom, NIHR Cambridge Biomedical Research Centre, Cambridge, CB2 0QQ, United Kingdom; Smith C.G., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom; Brenton J.D., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom, Cambridge University Hospitals NHS Foundation Trust, Cambridge, CB2 0QQ, United Kingdom, Department of Oncology, Hutchison/MRC Research Centre, University of Cambridge, Cambridge, CB2 0XZ, United Kingdom; Rosenfeld N., Cancer Research UK Cambridge Institute, University of Cambridge, Cambridge, CB2 0RE, United Kingdom, Cancer Research UK Major Centre–Cambridge, Cancer Research UK Cambridge Institute, Cambridge, CB2 0RE, United Kingdom","Existing methods to improve detection of circulating tumor DNA (ctDNA) have focused on genomic alterations but have rarely considered the biological properties of plasma cell-free DNA (cfDNA). We hypothesized that differences in fragment lengths of circulating DNA could be exploited to enhance sensitivity for detecting the presence of ctDNA and for noninvasive genomic analysis of cancer. We surveyed ctDNA fragment sizes in 344 plasma samples from 200 patients with cancer using low-pass whole-genome sequencing (0.4×). To establish the size distribution of mutant ctDNA, tumor-guided personalized deep sequencing was performed in 19 patients. We detected enrichment of ctDNA in fragment sizes between 90 and 150 bp and developed methods for in vitro and in silico size selection of these fragments. Selecting fragments between 90 and 150 bp improved detection of tumor DNA, with more than twofold median enrichment in >95% of cases and more than fourfold enrichment in >10% of cases. Analysis of size-selected cfDNA identified clinically actionable mutations and copy number alterations that were otherwise not detected. Identification of plasma samples from patients with advanced cancer was improved by predictive models integrating fragment length and copy number analysis of cfDNA, with area under the curve (AUC) >0.99 compared to AUC <0.80 without fragmentation features. Increased identification of cfDNA from patients with glioma, renal, and pancreatic cancer was achieved with AUC > 0.91 compared to AUC < 0.5 without fragmentation features. Fragment size analysis and selective sequencing of specific fragment sizes can boost ctDNA detection and could complement or provide an alternative to deeper sequencing of cfDNA. Copyright © 2018 The Authors, some rights reserved.","","Animals; Circulating Tumor DNA; DNA Copy Number Variations; Genome, Human; Humans; Machine Learning; Mice; Mutation; Whole Genome Sequencing; circulating tumor DNA; DNA fragment; circulating tumor DNA; advanced cancer; Article; cancer patient; controlled study; copy number variation; gene mutation; gene sequence; genetic analysis; glioma; human; human tissue; in vitro study; kidney cancer; machine learning; major clinical study; mathematical model; non invasive procedure; pancreas cancer; personalized medicine; plasma; prediction; priority journal; sequence analysis; tumor gene; whole genome sequencing; animal; blood; chemistry; genetics; human genome; mouse; mutation","American Association for the Advancement of Science","19466234","","","30404863","Article","Scopus","2-s2.0-85056346478"
"Kabir M.; Arif M.; Ahmad S.; Ali Z.; Swati Z.N.K.; Yu D.-J.","Kabir, Muhammad (56740196100); Arif, Muhammad (56452459100); Ahmad, Saeed (57213511614); Ali, Zakir (54920849000); Swati, Zar Nawab Khan (57204147436); Yu, Dong-Jun (7404666882)","56740196100; 56452459100; 57213511614; 54920849000; 57204147436; 7404666882","Intelligent computational method for discrimination of anticancer peptides by incorporating sequential and evolutionary profiles information","2018","Chemometrics and Intelligent Laboratory Systems","48","10.1016/j.chemolab.2018.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054679211&doi=10.1016%2fj.chemolab.2018.09.007&partnerID=40&md5=03b4fb05057c88fd19999078818bf6e9","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China; Department of Computer Science, Karakoram International University, Gilgit-Baltistan, 15100, Pakistan","Kabir M., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China; Arif M., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China; Ahmad S., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China; Ali Z., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China; Swati Z.N.K., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China, Department of Computer Science, Karakoram International University, Gilgit-Baltistan, 15100, Pakistan; Yu D.-J., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China","Cancer is one of the prominent threats to human life worldwide. Traditional therapeutic mechanisms like chemotherapy, radiation and surgical operations are exploited for its treatment. However, these clinical treatments are unfavorable, challenging and have severe impacts on human body. Recently, the discovery of anticancer peptides (ACPs) has become an influential anticancer drug agent due to their nontoxic characteristic and safe cellular uptake of therapeutic drugs. In this regard, much progress has been made to develop computational methods for ACPs prediction to accelerate their effectiveness against cancer. However, challenges remain in terms of discriminative feature representation, typical imbalance issue and prediction performance. In this study, we report a novel predictor, TargetACP, by integrating sequential and evolutionary-profiles information solely from primary protein sequences. Synthetic minority oversampling technique is utilized to cope with imbalance phenomenon between minority (ACPs) and majority (non-ACPs) samples. Finally, Support vector machine is employed as a learning hypothesis. Experimental results demonstrated that our predictor achieved an accuracy of 98.78% on benchmark dataset using jackknife cross-validation test. The generalization capability of the proposed method was evaluated through independent dataset which yielded accuracy of 94.66%. The empirical outcomes revealed that our model outperformed existing methods on same datasets. Furthermore, it is anticipated that TargetACP model will provide deep insights to pharmaceutical industry to design new anticancer drugs and research community to innovate new ideas in the area of bioinformatics, proteomics and computational biology. © 2018 Elsevier B.V.","Anticancer peptides; Composite protein sequence representation; Position-specific scoring matrix; Split amino acid composition; Support vector machine","antineoplastic agent; peptide derivative; accuracy; algorithm; amino acid sequence; Article; bioinformatics; biology; classification; classifier; drug design; drug industry; human; k nearest neighbor; mathematical computing; outcome assessment; priority journal; proteomics; random forest; support vector machine","Elsevier B.V.","01697439","","CILSE","","Article","Scopus","2-s2.0-85054679211"
"Zhang Z.; Hu Z.; Yang H.; Zhu R.; Zuo D.","Zhang, Zhan (55606660000); Hu, Ze (57193441418); Yang, Haiqin (13403893400); Zhu, Rong (58595181600); Zuo, Decheng (11339633500)","55606660000; 57193441418; 13403893400; 58595181600; 11339633500","Factorization machines and deep views-based co-training for improving answer quality prediction in online health expert question-answering services","2018","Journal of Biomedical Informatics","7","10.1016/j.jbi.2018.09.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054008199&doi=10.1016%2fj.jbi.2018.09.011&partnerID=40&md5=9d71054e2ee3114774c8d1a87502c0d2","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Department of Computing, Hang Seng Management College, Hong Kong, Hong Kong; MTdata, Meitu, China","Zhang Z., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Hu Z., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Yang H., Department of Computing, Hang Seng Management College, Hong Kong, Hong Kong, MTdata, Meitu, China; Zhu R., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Zuo D., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China","In online health expert question-answering (HQA) services, it is significant to automatically determine the quality of the answers. There are two prominent challenges in this task. First, the answers are usually written in short text, which makes it difficult to absorb the text semantic information. Second, it usually lacks sufficient labeled data but contains a huge amount of unlabeled data. To tackle these challenges, we propose a novel deep co-training framework based on factorization machines (FM) and deep textual views to intelligently and automatically identify the quality of HQA systems. More specifically, we exploit additional domain-specific semantic information from domain-specific word embeddings to expand the semantic space of short text and apply FM to excavate the non-independent interaction relationships among diverse features within individual views for improving the performance of the base classifier via co-training. Our learned deep textual views, the convolutional neural networks (CNN) view which focuses on extracting local features using convolution filters to locally model short text and the dependency-sensitive convolutional neural networks (DSCNN) view which focuses on capturing long-distance dependency information within the text to globally model short text, can then overcome the challenge of feature sparseness in the short text answers from the doctors. The developed co-training framework can effectively mine the highly non-linear semantic information embedded in the unlabeled data and expose the highly non-linear relationships between different views, which minimizes the labeling effort. Finally, we conduct extensive empirical evaluations and demonstrate that our proposed method can significantly improve the predictive performance of the answer quality in the context of HQA services. © 2018 Elsevier Inc.","Answer quality predicting; Convolutional neural networks; Deep co-training; Deep views; Factorization machines; Online health expert question-answering services","Algorithms; Communication; Humans; Internet; Machine Learning; Neural Networks (Computer); Predictive Value of Tests; Semantics; Software; Telemedicine; Classification (of information); Convolution; E-learning; Factorization; Health; Natural language processing systems; Neural networks; Answer quality predicting; Co-training; Convolutional neural network; Deep views; Factorization machines; Question-answering services; algorithm; Article; artificial neural network; controlled study; convolutional neural network; CS CoT algorithm; deep textual view; dependency sensitive convolutional neural network; factorization machine; human; information processing; information service; logistic regression analysis; online health expert question answering service; prediction; priority journal; random subspace split algorithm; RSS CoT algorithm; support vector machine; transductive support vector machine; algorithm; artificial neural network; Internet; interpersonal communication; machine learning; predictive value; procedures; semantics; software; telemedicine; Semantics","Academic Press Inc.","15320464","","JBIOB","30240803","Article","Scopus","2-s2.0-85054008199"
"Zhang P.; Ke Y.; Zhang Z.; Wang M.; Li P.; Zhang S.","Zhang, Pengbin (57204541145); Ke, Yinghai (35784422100); Zhang, Zhenxin (57069455200); Wang, Mingli (57204003630); Li, Peng (57209542263); Zhang, Shuangyue (57204542307)","57204541145; 35784422100; 57069455200; 57204003630; 57209542263; 57204542307","Urban land use and land cover classification using novel deep learning models based on high spatial resolution satellite imagery","2018","Sensors (Switzerland)","146","10.3390/s18113717","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056030105&doi=10.3390%2fs18113717&partnerID=40&md5=65f033eb67a239a8dab638f82f81dfe0","Laboratory Cultivation Base of Environment Process and Digital Simulation, Capital Normal University, Beijing, 100048, China; EarthSTAR Inc, Beijing, 100101, China; Beijing Laboratory of Water Resource Security, Capital Normal University, Beijing, 100048, China; Beijing Advanced Innovation Center for Imaging Technology, Capital Normal University, Beijing, 100048, China","Zhang P., Laboratory Cultivation Base of Environment Process and Digital Simulation, Capital Normal University, Beijing, 100048, China, EarthSTAR Inc, Beijing, 100101, China; Ke Y., Laboratory Cultivation Base of Environment Process and Digital Simulation, Capital Normal University, Beijing, 100048, China, Beijing Laboratory of Water Resource Security, Capital Normal University, Beijing, 100048, China; Zhang Z., Laboratory Cultivation Base of Environment Process and Digital Simulation, Capital Normal University, Beijing, 100048, China, Beijing Advanced Innovation Center for Imaging Technology, Capital Normal University, Beijing, 100048, China; Wang M., Laboratory Cultivation Base of Environment Process and Digital Simulation, Capital Normal University, Beijing, 100048, China, Beijing Laboratory of Water Resource Security, Capital Normal University, Beijing, 100048, China; Li P., Laboratory Cultivation Base of Environment Process and Digital Simulation, Capital Normal University, Beijing, 100048, China, Beijing Laboratory of Water Resource Security, Capital Normal University, Beijing, 100048, China; Zhang S., Laboratory Cultivation Base of Environment Process and Digital Simulation, Capital Normal University, Beijing, 100048, China, Beijing Laboratory of Water Resource Security, Capital Normal University, Beijing, 100048, China","Urban land cover and land use mapping plays an important role in urban planning and management. In this paper, novel multi-scale deep learning models, namely ASPP-Unet and ResASPP-Unet are proposed for urban land cover classification based on very high resolution (VHR) satellite imagery. The proposed ASPP-Unet model consists of a contracting path which extracts the high-level features, and an expansive path, which up-samples the features to create a high-resolution output. The atrous spatial pyramid pooling (ASPP) technique is utilized in the bottom layer in order to incorporate multi-scale deep features into a discriminative feature. The ResASPP-Unet model further improves the architecture by replacing each layer with residual unit. The models were trained and tested based on WorldView-2 (WV2) and WorldView-3 (WV3) imageries over the city of Beijing. Model parameters including layer depth and the number of initial feature maps (IFMs) as well as the input image bands were evaluated in terms of their impact on the model performances. It is shown that the ResASPP-Unet model with 11 layers and 64 IFMs based on 8-band WV2 imagery produced the highest classification accuracy (87.1% for WV2 imagery and 84.0% for WV3 imagery). The ASPP-Unet model with the same parameter setting produced slightly lower accuracy, with overall accuracy of 85.2% for WV2 imagery and 83.2% for WV3 imagery. Overall, the proposed models outperformed the state-of-the-art models, e.g., U-Net, convolutional neural network (CNN) and Support Vector Machine (SVM) model over both WV2 and WV3 images, and yielded robust and efficient urban land cover classification results. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","CNN; Deep learning; High spatial resolution satellite imagery; U-net; Urban land cover classification","Deep learning; Image classification; Image resolution; Land use; Neural networks; Support vector machines; Classification accuracy; Convolutional Neural Networks (CNN); Discriminative features; High spatial resolution satellite imagery; High-level features; High-resolution output; Urban land cover classification; Very high resolution; Satellite imagery","MDPI AG","14248220","","","30388781","Article","Scopus","2-s2.0-85056030105"
"Ziletti A.; Kumar D.; Scheffler M.; Ghiringhelli L.M.","Ziletti, Angelo (55037502000); Kumar, Devinder (57914587200); Scheffler, Matthias (7102229641); Ghiringhelli, Luca M. (16063967000)","55037502000; 57914587200; 7102229641; 16063967000","Insightful classification of crystal structures using deep learning","2018","Nature Communications","229","10.1038/s41467-018-05169-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050405146&doi=10.1038%2fs41467-018-05169-6&partnerID=40&md5=4ea4398bc66d603f9cae03fcfc1b9d86","Theory Department, Fritz-Haber-Institut der Max-Planck-Gesellschaft, Faradayweg 4-6, Berlin, 14195, Germany; University of Waterloo, 200 University Avenue West, Waterloo, N2L 3G1, ON, Canada; Vector Institute of AI, Toronto, M5G 1M1, ON, Canada","Ziletti A., Theory Department, Fritz-Haber-Institut der Max-Planck-Gesellschaft, Faradayweg 4-6, Berlin, 14195, Germany; Kumar D., University of Waterloo, 200 University Avenue West, Waterloo, N2L 3G1, ON, Canada, Vector Institute of AI, Toronto, M5G 1M1, ON, Canada; Scheffler M., Theory Department, Fritz-Haber-Institut der Max-Planck-Gesellschaft, Faradayweg 4-6, Berlin, 14195, Germany; Ghiringhelli L.M., Theory Department, Fritz-Haber-Institut der Max-Planck-Gesellschaft, Faradayweg 4-6, Berlin, 14195, Germany","Computational methods that automatically extract knowledge from data are critical for enabling data-driven materials science. A reliable identification of lattice symmetry is a crucial first step for materials characterization and analytics. Current methods require a user-specified threshold, and are unable to detect average symmetries for defective structures. Here, we propose a machine learning-based approach to automatically classify structures by crystal symmetry. First, we represent crystals by calculating a diffraction image, then construct a deep learning neural network model for classification. Our approach is able to correctly classify a dataset comprising more than 100,000 simulated crystal structures, including heavily defective ones. The internal operations of the neural network are unraveled through attentive response maps, demonstrating that it uses the same landmarks a materials scientist would use, although never explicitly instructed to do so. Our study paves the way for crystal structure recognition of - possibly noisy and incomplete - three-dimensional structural data in big-data materials science. © 2018 The Author(s).","","algorithm; crustal structure; crystal structure; data set; image analysis; image classification; machine learning; numerical method; threshold; article; crystal structure; diffraction; human; machine learning; materials science; nervous system; scientist; simulation","Nature Publishing Group","20411723","","","30018362","Article","Scopus","2-s2.0-85050405146"
"Mahmood F.; Chen R.; Durr N.J.","Mahmood, Faisal (56647751100); Chen, Richard (57202356119); Durr, Nicholas J. (16303771500)","56647751100; 57202356119; 16303771500","Unsupervised Reverse Domain Adaptation for Synthetic Medical Images via Adversarial Training","2018","IEEE Transactions on Medical Imaging","173","10.1109/TMI.2018.2842767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047988584&doi=10.1109%2fTMI.2018.2842767&partnerID=40&md5=459a833a45de174cc5ba7c7c7e31119f","Department of Biomedical Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States; Department of Computer Science, Johns Hopkins University, Baltimore, 21218, MD, United States","Mahmood F., Department of Biomedical Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States; Chen R., Department of Computer Science, Johns Hopkins University, Baltimore, 21218, MD, United States; Durr N.J., Department of Biomedical Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States","To realize the full potential of deep learning for medical imaging, large annotated datasets are required for training. Such datasets are difficult to acquire due to privacy issues, lack of experts available for annotation, underrepresentation of rare conditions, and poor standardization. The lack of annotated data has been addressed in conventional vision applications using synthetic images refined via unsupervised adversarial training to look like real images. However, this approach is difficult to extend to general medical imaging because of the complex and diverse set of features found in real human tissues. We propose a novel framework that uses a reverse flow, where adversarial training is used to make real medical images more like synthetic images, and clinically-relevant features are preserved via self-regularization. These domain-adapted synthetic-like images can then be accurately interpreted by networks trained on large datasets of synthetic medical images. We implement this approach on the notoriously difficult task of depth-estimation from monocular endoscopy which has a variety of applications in colonoscopy, robotic surgery, and invasive endoscopic procedures. We train a depth estimator on a large data set of synthetic images generated using an accurate forward model of an endoscope and an anatomically-realistic colon. Our analysis demonstrates that the structural similarity of endoscopy depth estimation in a real pig colon predicted from a network trained solely on synthetic data improved by 78.7% by using reverse domain adaptation. © 2018 IEEE.","adversarial training; Convolutional neural networks; domain adaptation; endoscopy; GANs; medical imaging; synthetic data","Databases, Factual; Endoscopy; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Neural Networks (Computer); Unsupervised Machine Learning; Data structures; Deep learning; Endoscopy; Estimation; Gallium nitride; III-V semiconductors; Neural networks; Personnel training; Robotic surgery; Convolutional neural network; Domain adaptation; GANs; Medical diagnostic imaging; Synthetic data; adaptation; animal tissue; Article; biological variation; cadaver; colonoscopy; diagnostic imaging; endoscopic surgery; endoscopy; histopathology; human; human tissue; image segmentation; laparoscopic surgery; nonhuman; pig; qualitative analysis; qualitative research; quantitative study; topography; artificial neural network; computer assisted diagnosis; factual database; image processing; procedures; unsupervised machine learning; Medical imaging","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29993538","Article","Scopus","2-s2.0-85047988584"
"Zhou Z.; Kuo H.-C.; Peng H.; Long F.","Zhou, Zhi (55728173600); Kuo, Hsien-Chi (57202420253); Peng, Hanchuan (15061795400); Long, Fuhui (7102119365)","55728173600; 57202420253; 15061795400; 7102119365","DeepNeuron: an open deep learning toolbox for neuron tracing","2018","Brain Informatics","46","10.1186/s40708-018-0081-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048284269&doi=10.1186%2fs40708-018-0081-2&partnerID=40&md5=7d4377d8b3b87ff83befac7a0f2d2629","Allen Institute for Brain Science, Seattle, United States; Southeast University – Allen Institute Joint Center for Neuron Morphology, Southeast University, Nanjing, China","Zhou Z., Allen Institute for Brain Science, Seattle, United States, Southeast University – Allen Institute Joint Center for Neuron Morphology, Southeast University, Nanjing, China; Kuo H.-C., Allen Institute for Brain Science, Seattle, United States; Peng H., Allen Institute for Brain Science, Seattle, United States, Southeast University – Allen Institute Joint Center for Neuron Morphology, Southeast University, Nanjing, China; Long F., Allen Institute for Brain Science, Seattle, United States","Reconstructing three-dimensional (3D) morphology of neurons is essential for understanding brain structures and functions. Over the past decades, a number of neuron tracing tools including manual, semiautomatic, and fully automatic approaches have been developed to extract and analyze 3D neuronal structures. Nevertheless, most of them were developed based on coding certain rules to extract and connect structural components of a neuron, showing limited performance on complicated neuron morphology. Recently, deep learning outperforms many other machine learning methods in a wide range of image analysis and computer vision tasks. Here we developed a new Open Source toolbox, DeepNeuron, which uses deep learning networks to learn features and rules from data and trace neuron morphology in light microscopy images. DeepNeuron provides a family of modules to solve basic yet challenging problems in neuron tracing. These problems include but not limited to: (1) detecting neuron signal under different image conditions, (2) connecting neuronal signals into tree(s), (3) pruning and refining tree morphology, (4) quantifying the quality of morphology, and (5) classifying dendrites and axons in real time. We have tested DeepNeuron using light microscopy images including bright-field and confocal images of human and mouse brain, on which DeepNeuron demonstrates robustness and accuracy in neuron tracing. © 2018, The Author(s).","Deep learning; DeepNeuron; Neuron morphology; Neuron tracing","Forestry; Morphology; Neurons; Automatic approaches; DeepNeuron; Machine learning methods; Neuron morphologies; Neuron tracings; Neuronal structure; Structural component; Threedimensional (3-d); accuracy; Article; artificial neural network; axon; dendrite; human; image analysis; machine learning; microscopy; morphology; mouse; nerve cell; nonhuman; signal detection; Deep learning","Springer Berlin Heidelberg","21984018","","","","Article","Scopus","2-s2.0-85048284269"
"Uppu S.; Krishna A.","Uppu, Suneetha (16176809800); Krishna, Aneesh (57209052897)","16176809800; 57209052897","A deep hybrid model to detect multi-locus interacting SNPs in the presence of noise","2018","International Journal of Medical Informatics","10","10.1016/j.ijmedinf.2018.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054669801&doi=10.1016%2fj.ijmedinf.2018.09.003&partnerID=40&md5=5cffcc082e8b092138844fffaa62d057","School of Electrical Engineering, Computing and Mathematical Sciences, Curtin University, Kent Street, Perth, Australia","Uppu S., School of Electrical Engineering, Computing and Mathematical Sciences, Curtin University, Kent Street, Perth, Australia; Krishna A., School of Electrical Engineering, Computing and Mathematical Sciences, Curtin University, Kent Street, Perth, Australia","Identifying genetic variants associated with complex diseases is a central focus of genome-wide association studies. These studies extensively adopt univariate analysis by ignoring interaction effects. It is widely accepted that the etiology of most complex diseases depends on interactions between genetic variants and / or environmental factors. Several machine learning and data mining methods have been consistently successful in exposing these interaction effects. However, there has been no major breakthrough due to various biological complexities, and statistical computational challenges facing in the field of genetic epidemiology, despite of many efforts. Deep learning is emerging machine learning approach that promises to reveal the hidden patterns of big data for accurate predictions. In this study, a deep neural network is unified with a random forest by forming hybrid architecture, for achieving reliable detection of multi-locus interactions between single nucleotide polymorphisms. The proposed hybrid method is evaluated on various simulated scenarios in the absence of main effect for six epistasis models. The best model with optimal hyper-parameters (grid and random grid search) is chosen to enhance the power of the method by maximising the model's prediction accuracy. The performance metrics of each model is analysed for both training and validation. Further, the performance of the method in the presence of noise due to missing data, genotyping errors, genetic heterogeneity, and phenocopy, and their combined effects are evaluated. The power of the method in detecting two-locus interactions is compared with the previous methods in the presence and absence of noise. On an average, the power of the proposed method is much higher than the previous methods for all simulated scenarios. Finally, findings are confirmed on a chronical dialysis patient's data, obtained from the published study performed at the Kaohsiung Chang Gung Memorial Hospital. It is observed that the interaction between SNP 21 (2) and SNP 28 (2) in the mitochondrial D-loop has the highest risk for the disease manifestation. © 2018 Elsevier B.V.","Deep neural networks; Genetic heterogeneity; Genome-wide association studies; Genotyping error; Phenocopy; Random forest; SNP-SNP interactions","Case-Control Studies; Computational Biology; Epistasis, Genetic; Genetic Loci; Genome-Wide Association Study; Humans; Machine Learning; Models, Theoretical; Polymorphism, Single Nucleotide; Signal-To-Noise Ratio; Artificial intelligence; Association reactions; Complex networks; Data mining; Decision trees; Deep neural networks; Genes; Genetic heterogeneities; Genome-wide association studies; Genotyping errors; Phenocopy; Random forests; accuracy; adult; Article; back propagation; controlled study; data mining; epistasis; evaluation study; female; gene frequency; gene locus; genetic epidemiology; genetic heterogeneity; genetic variability; genome-wide association study; genotype; hemodialysis patient; human; machine learning; major clinical study; male; middle aged; mitochondrion; phenocopy; phenotype; prediction; priority journal; random forest; single nucleotide polymorphism; statistical analysis; univariate analysis; validation process; biology; case control study; genome-wide association study; machine learning; procedures; signal noise ratio; theoretical model; Big data","Elsevier Ireland Ltd","13865056","","IJMIF","30342681","Article","Scopus","2-s2.0-85054669801"
"Wang D.; Shan H.; Xin J.","Wang, Dongshu (56102953500); Shan, Hui (57203762991); Xin, Jianbin (55817481000)","56102953500; 57203762991; 55817481000","Brain-like emergent auditory learning: A developmental method","2018","Hearing Research","4","10.1016/j.heares.2018.08.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052875585&doi=10.1016%2fj.heares.2018.08.010&partnerID=40&md5=4c2116baf86a94bd2d8164dc3c055bb9","School of Electrical Engineering, Zhengzhou University, No.100, Science Road, Zhengzhou, 450001, China","Wang D., School of Electrical Engineering, Zhengzhou University, No.100, Science Road, Zhengzhou, 450001, China; Shan H., School of Electrical Engineering, Zhengzhou University, No.100, Science Road, Zhengzhou, 450001, China; Xin J., School of Electrical Engineering, Zhengzhou University, No.100, Science Road, Zhengzhou, 450001, China","Compared with machine audition, the human auditory system can recognize speech accurately and quickly. This paper proposes a new developmental network (DN) that simulates the human auditory system and constructs an artificial auditory model for speech recognition. The new model simulates each key element of the human auditory pathway as a deep network; in particular, an additional layer in the network is considered to simulate the function of the superior colliculus in the thalamus for speech context integration. The mel-frequency cepstral coefficient (MFCC) is used to extract the features of the speech signal as the sensory input of the DN. The emergent feature of DN model provides an explanation of how such internal neurons represent the short speech context when they are not supervised by the external world. The experimental results show that the recognition rates of English words and phrases can be improved significantly compared to those reported in the existing literature. The proposed DN model provides a new method to solve difficult problems, such as universal speech recognition, in traditional machine audition systems. Meanwhile, the same learning principle can potentially be used in or adapted to other computational contexts and applications. © 2018 Elsevier B.V.","Auditory system; Developmental network; Emergent representation; MFCC; Speech recognition","Auditory Pathways; Brain; Computer Simulation; Humans; Models, Neurological; Recognition (Psychology); Speech Perception; article; auditory nervous system; controlled study; hearing; human; human experiment; learning; machine; nerve cell; sensory stimulation; speech discrimination; superior colliculus; thalamus; auditory nervous system; biological model; brain; comparative study; computer simulation; physiology; recognition; speech perception","Elsevier B.V.","03785955","","HERED","30193803","Article","Scopus","2-s2.0-85052875585"
"Wang Z.; Majewicz Fey A.","Wang, Ziheng (57201478801); Majewicz Fey, Ann (57201480174)","57201478801; 57201480174","Deep learning with convolutional neural network for objective skill evaluation in robot-assisted surgery","2018","International Journal of Computer Assisted Radiology and Surgery","174","10.1007/s11548-018-1860-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053922496&doi=10.1007%2fs11548-018-1860-1&partnerID=40&md5=85256d25ab4ec40422f4981e63bf4514","Department of Mechanical Engineering, University of Texas at Dallas, Richardson, 75080, TX, United States; Department of Surgery, UT Southwestern Medical Center, Dallas, 75390, TX, United States","Wang Z., Department of Mechanical Engineering, University of Texas at Dallas, Richardson, 75080, TX, United States; Majewicz Fey A., Department of Mechanical Engineering, University of Texas at Dallas, Richardson, 75080, TX, United States, Department of Surgery, UT Southwestern Medical Center, Dallas, 75390, TX, United States","Purpose: With the advent of robot-assisted surgery, the role of data-driven approaches to integrate statistics and machine learning is growing rapidly with prominent interests in objective surgical skill assessment. However, most existing work requires translating robot motion kinematics into intermediate features or gesture segments that are expensive to extract, lack efficiency, and require significant domain-specific knowledge. Methods: We propose an analytical deep learning framework for skill assessment in surgical training. A deep convolutional neural network is implemented to map multivariate time series data of the motion kinematics to individual skill levels. Results: We perform experiments on the public minimally invasive surgical robotic dataset, JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS). Our proposed learning model achieved competitive accuracies of 92.5%, 95.4%, and 91.3%, in the standard training tasks: Suturing, Needle-passing, and Knot-tying, respectively. Without the need of engineered features or carefully tuned gesture segmentation, our model can successfully decode skill information from raw motion profiles via end-to-end learning. Meanwhile, the proposed model is able to reliably interpret skills within a 1–3 second window, without needing an observation of entire training trial. Conclusion: This study highlights the potential of deep architectures for efficient online skill assessment in modern surgical training. © 2018, CARS.","Convolutional neural network; Deep learning; Motion analysis; Surgical robotics; Surgical skill evaluation","Biomechanical Phenomena; Clinical Competence; Deep Learning; Gestures; Humans; Machine Learning; Neural Networks (Computer); Robotics; article; controlled study; gesture; kinematics; learning; motion; robot assisted surgery; skill; surgery; surgical training; time series analysis; artificial neural network; biomechanics; clinical competence; education; human; machine learning; robotics","Springer Verlag","18616410","","","30255463","Article","Scopus","2-s2.0-85053922496"
"Bart E.; Hegdé J.","Bart, Evgeniy (22333809100); Hegdé, Jay (8901371600)","22333809100; 8901371600","Deep synthesis of realistic medical images: A novel tool in clinical research and training","2018","Frontiers in Neuroinformatics","4","10.3389/fninf.2018.00082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058981713&doi=10.3389%2ffninf.2018.00082&partnerID=40&md5=a1f3d81f363163d664c5be99c3420184","Palo Alto Research Center, Palo Alto, CA, United States; Department of Neuroscience and Regenerative Medicine, James and Jean Culver Vision Discovery Institute, The Graduate School, Augusta University, Augusta, GA, United States; Department of Ophthalmology, Medical College of Georgia, Augusta University, Augusta, GA, United States","Bart E., Palo Alto Research Center, Palo Alto, CA, United States; Hegdé J., Department of Neuroscience and Regenerative Medicine, James and Jean Culver Vision Discovery Institute, The Graduate School, Augusta University, Augusta, GA, United States, Department of Ophthalmology, Medical College of Georgia, Augusta University, Augusta, GA, United States","Making clinical decisions based on medical images is fundamentally an exercise in statistical decision-making. This is because in this case, the decision-maker must distinguish between image features that are clinically diagnostic (i.e., signal) from a large amount of non-diagnostic features. (i.e., noise). To perform this task, the decision-maker must have learned the underlying statistical distributions of the signal and noise to begin with. The same is true for machine learning algorithms that perform a given diagnostic task. In order to train and test human experts or expert machine systems in any diagnostic or analytical task, it is advisable to use large sets of images, so as to capture the underlying statistical distributions adequately. Large numbers of images are also useful in clinical and scientific research about the underlying diagnostic process, which remains poorly understood. Unfortunately, it is often difficult to obtain medical images of given specific descriptions in sufficiently large numbers. This represents a significant barrier to progress in the arenas of clinical care, education, and research. Here we describe a novel methodology that helps overcome this barrier. This method leverages the burgeoning technologies of deep learning (DL) and deep synthesis (DS) to synthesize medical images de novo. We provide a proof-of-principle of this approach using mammograms as an illustrative case. During the initial, prerequisite DL phase of the study, we trained a publicly available deep learning neural network (DNN), using open-sourced, radiologically vetted mammograms as labeled examples. During the subsequent DS phase of the study, the fully trained DNN was made to synthesize, de novo, images that capture the image statistics of a given input image. The resulting images indicated that our DNN was able to faithfully capture the image statistics of visually diverse sets of mammograms. We also briefly outline rigorous psychophysical testing methods to measure the extent to which synthesized mammography were sufficiently alike their original counterparts to human experts. These tests reveal that mammography experts fail to distinguish synthesized mammograms from their original counterparts at a statistically significant level, suggesting that the synthesized images were sufficiently realistic. Taken together, these results demonstrate that deep synthesis has the potential to be impactful in all fields in which medical images play a key role, most notably in radiology and pathology. © 2018 Bart and Hegdé.","Deep learning; Deep neural network; Perceptual metamerism; Psychophysical; Representational similarity analysis; Signal detection","article; clinical research; controlled study; education; human; human experiment; machine learning; mammography; radiology; signal detection; statistical distribution; statistics; synthesis","Frontiers Media S.A.","16625196","","","","Article","Scopus","2-s2.0-85058981713"
"Rannen Triki A.; Blaschko M.B.; Jung Y.M.; Song S.; Han H.J.; Kim S.I.; Joo C.","Rannen Triki, Amal (57207770894); Blaschko, Matthew B. (24829297300); Jung, Yoon Mo (57194626351); Song, Seungri (57191728081); Han, Hyun Ju (41561156500); Kim, Seung Il (55748367700); Joo, Chulmin (7005698235)","57207770894; 24829297300; 57194626351; 57191728081; 41561156500; 55748367700; 7005698235","Intraoperative margin assessment of human breast tissue in optical coherence tomography images using deep neural networks","2018","Computerized Medical Imaging and Graphics","13","10.1016/j.compmedimag.2018.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052468834&doi=10.1016%2fj.compmedimag.2018.06.002&partnerID=40&md5=8cc8066db5e841897d729b4c572142be","ESAT-PSI, KU Leuven, Kasteelpark Arenberg 10, Leuven, B-3001, Belgium; Yonsei University, 50 Yonsei-ro, Sinchon-dong, Seodaemun-gu, Seoul, South Korea; Sungkyunkwan University, 300 Cheoncheon-dong, Jangan-gu, Suwon, South Korea","Rannen Triki A., ESAT-PSI, KU Leuven, Kasteelpark Arenberg 10, Leuven, B-3001, Belgium, Yonsei University, 50 Yonsei-ro, Sinchon-dong, Seodaemun-gu, Seoul, South Korea; Blaschko M.B., ESAT-PSI, KU Leuven, Kasteelpark Arenberg 10, Leuven, B-3001, Belgium; Jung Y.M., Sungkyunkwan University, 300 Cheoncheon-dong, Jangan-gu, Suwon, South Korea; Song S., Yonsei University, 50 Yonsei-ro, Sinchon-dong, Seodaemun-gu, Seoul, South Korea; Han H.J., Yonsei University, 50 Yonsei-ro, Sinchon-dong, Seodaemun-gu, Seoul, South Korea; Kim S.I., Yonsei University, 50 Yonsei-ro, Sinchon-dong, Seodaemun-gu, Seoul, South Korea; Joo C., Yonsei University, 50 Yonsei-ro, Sinchon-dong, Seodaemun-gu, Seoul, South Korea","Assessing the surgical margin during breast lumpectomy operations can avoid the need for additional surgery. Optical coherence tomography (OCT) is an imaging technique that has been proven to be efficient for this purpose. However, to avoid overloading the surgeon during the operation, automatic cancer detection at the surface of the removed tissue is needed. This work explores automated margin assessment on a sample of patient data collected at the Pathology Department, Severance Hospital (Seoul, South Korea). Some methods based on the spatial statistics of the images have been developed, but the obtained results are still far from human performance. In this work, we investigate the possibility to use deep neural networks (DNNs) for real time margin assessment, demonstrating performance significantly better than the reported literature and close to the level of a human expert. Since the goal is to detect the presence of cancer, a patch-based classification method is proposed, as it is sufficient for detection, and requires training data that is easier and cheaper to collect than for other approaches such as segmentation. For that purpose, we train a DNN architecture that was proved to be efficient for small images on patches extracted from images containing only cancer or only normal tissue as determined by pathologists in a university hospital. As the number of available images in all such studies is by necessity small relative to other deep network applications such as ImageNet, a good regularization method is needed. In this work, we propose to use a recently introduced function norm regularization that attempts to directly control the function complexity, in contrast to classical approaches such as weight decay and DropOut. As neither the code nor the data of previous results are publicly available, the obtained results are compared with reported results in the literature for a conservative comparison. Moreover, our method is applied to locally collected data on several data configurations. The reported results are the average over the different trials. The experimental results show that the use of DNNs yields significantly better results than other techniques when evaluated in terms of sensitivity, specificity, F1 score, G-mean and Matthews correlation coefficient. Function norm regularization yielded higher and more robust results than competing regularization methods. We have demonstrated a system that shows high promise for (partially) automated margin assessment of human breast tissue, Equal error rate (EER) is reduced from approximately 12% (the lowest reported in the literature) to 5% – a 58% reduction. The method is computationally feasible for intraoperative application (less than 2 s per image) at the only cost of a longer offline training time. © 2018 Elsevier Ltd","Breast cancer; Deep Neural Network (DNN); Function norm; Margin assessment; Optical Coherence Tomography (OCT); Regularization","Algorithms; Breast Neoplasms; Female; Humans; Margins of Excision; Nerve Net; Radiographic Image Enhancement; Tomography, X-Ray Computed; Classification (of information); Diseases; Dynamic loads; Hospital data processing; Hospitals; Medical imaging; Optical tomography; Tissue; Transplantation (surgical); Breast Cancer; Classification methods; Correlation coefficient; Intra-operative applications; Margin assessment; Regularization; Regularization methods; Seoul , South Korea; Article; breast tissue; cancer diagnosis; correlation coefficient; data analysis; deep neural network; error; human; human tissue; intraoperative period; lumpectomy; machine learning; optical coherence tomography; pathologist; priority journal; quantitative analysis; sensitivity and specificity; surgical margin; university hospital; algorithm; breast tumor; female; image enhancement; nerve cell network; procedures; x-ray computed tomography; Deep neural networks","Elsevier Ltd","08956111","","CMIGE","30172090","Article","Scopus","2-s2.0-85052468834"
"Ye W.; Chen C.; Wang Z.; Chu I.-H.; Ong S.P.","Ye, Weike (57192412200); Chen, Chi (57840930400); Wang, Zhenbin (55258833600); Chu, Iek-Heng (53979434900); Ong, Shyue Ping (57203196608)","57192412200; 57840930400; 55258833600; 53979434900; 57203196608","Deep neural networks for accurate predictions of crystal stability","2018","Nature Communications","184","10.1038/s41467-018-06322-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053549978&doi=10.1038%2fs41467-018-06322-x&partnerID=40&md5=6bfdd20cc417af7eb8e3c9e3258d3ffa","Department of Chemistry and Biochemistry, University of California San Diego, 9500 Gilman Dr, Mail Code 0303, La Jolla, 92093-0448, CA, United States; Department of NanoEngineering, University of California San Diego, 9500 Gilman Dr, Mail Code, 0448, La Jolla, 92093-0448, CA, United States","Ye W., Department of Chemistry and Biochemistry, University of California San Diego, 9500 Gilman Dr, Mail Code 0303, La Jolla, 92093-0448, CA, United States; Chen C., Department of NanoEngineering, University of California San Diego, 9500 Gilman Dr, Mail Code, 0448, La Jolla, 92093-0448, CA, United States; Wang Z., Department of NanoEngineering, University of California San Diego, 9500 Gilman Dr, Mail Code, 0448, La Jolla, 92093-0448, CA, United States; Chu I.-H., Department of NanoEngineering, University of California San Diego, 9500 Gilman Dr, Mail Code, 0448, La Jolla, 92093-0448, CA, United States; Ong S.P., Department of NanoEngineering, University of California San Diego, 9500 Gilman Dr, Mail Code, 0448, La Jolla, 92093-0448, CA, United States","Predicting the stability of crystals is one of the central problems in materials science. Today, density functional theory (DFT) calculations remain comparatively expensive and scale poorly with system size. Here we show that deep neural networks utilizing just two descriptors—the Pauling electronegativity and ionic radii—can predict the DFT formation energies of C3A2D3O12 garnets and ABO3 perovskites with low mean absolute errors (MAEs) of 7–10 meV atom−1 and 20–34 meV atom−1, respectively, well within the limits of DFT accuracy. Further extension to mixed garnets and perovskites with little loss in accuracy can be achieved using a binary encoding scheme, addressing a critical gap in the extension of machine-learning models from fixed stoichiometry crystals to infinite universe of mixed-species crystals. Finally, we demonstrate the potential of these models to rapidly transverse vast chemical spaces to accurately identify stable compositions, accelerating the discovery of novel materials with potentially superior properties. © 2018, The Author(s).","","accuracy assessment; artificial neural network; chemical composition; crystal structure; density; ion; machine learning; stoichiometry; article; cosmos; crystal; density functional theory; error; machine learning; prediction; stoichiometry","Nature Publishing Group","20411723","","","30228262","Article","Scopus","2-s2.0-85053549978"
"Bien N.; Rajpurkar P.; Ball R.L.; Irvin J.; Park A.; Jones E.; Bereket M.; Patel B.N.; Yeom K.W.; Shpanskaya K.; Halabi S.; Zucker E.; Fanton G.; Amanatullah D.F.; Beaulieu C.F.; Riley G.M.; Stewart R.J.; Blankenberg F.G.; Larson D.B.; Jones R.H.; Langlotz C.P.; Ng A.Y.; Lungren M.P.","Bien, Nicholas (57204809867); Rajpurkar, Pranav (57056352800); Ball, Robyn L. (57194281693); Irvin, Jeremy (57204714660); Park, Allison (57204805527); Jones, Erik (57204809490); Bereket, Michael (58719143300); Patel, Bhavik N. (57202858916); Yeom, Kristen W. (16204680400); Shpanskaya, Katie (55700743700); Halabi, Safwan (56056991200); Zucker, Evan (50062153600); Fanton, Gary (7003867900); Amanatullah, Derek F. (36869201000); Beaulieu, Christopher F. (57204084528); Riley, Geoffrey M. (7102483008); Stewart, Russell J. (57191078763); Blankenberg, Francis G. (7004255827); Larson, David B. (35725554000); Jones, Ricky H. (56719859000); Langlotz, Curtis P. (20134955200); Ng, Andrew Y. (35410071600); Lungren, Matthew P. (36729660500)","57204809867; 57056352800; 57194281693; 57204714660; 57204805527; 57204809490; 58719143300; 57202858916; 16204680400; 55700743700; 56056991200; 50062153600; 7003867900; 36869201000; 57204084528; 7102483008; 57191078763; 7004255827; 35725554000; 56719859000; 20134955200; 35410071600; 36729660500","Deep-learning-assisted diagnosis for knee magnetic resonance imaging: Development and retrospective validation of MRNet","2018","PLoS Medicine","402","10.1371/journal.pmed.1002699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057229138&doi=10.1371%2fjournal.pmed.1002699&partnerID=40&md5=6fc5f728aa863a4b7c0fec638242f24d","Department of Computer Science, Stanford University, Stanford, CA, United States; Quantitative Sciences Unit, Department of Medicine, Stanford University, Stanford, CA, United States; Department of Radiology, Stanford University, Stanford, CA, United States; Department of Orthopedic Surgery, Stanford University, Stanford, CA, United States","Bien N., Department of Computer Science, Stanford University, Stanford, CA, United States; Rajpurkar P., Department of Computer Science, Stanford University, Stanford, CA, United States; Ball R.L., Quantitative Sciences Unit, Department of Medicine, Stanford University, Stanford, CA, United States; Irvin J., Department of Computer Science, Stanford University, Stanford, CA, United States; Park A., Department of Computer Science, Stanford University, Stanford, CA, United States; Jones E., Department of Computer Science, Stanford University, Stanford, CA, United States; Bereket M., Department of Computer Science, Stanford University, Stanford, CA, United States; Patel B.N., Department of Radiology, Stanford University, Stanford, CA, United States; Yeom K.W., Department of Radiology, Stanford University, Stanford, CA, United States; Shpanskaya K., Department of Radiology, Stanford University, Stanford, CA, United States; Halabi S., Department of Radiology, Stanford University, Stanford, CA, United States; Zucker E., Department of Radiology, Stanford University, Stanford, CA, United States; Fanton G., Department of Orthopedic Surgery, Stanford University, Stanford, CA, United States; Amanatullah D.F., Department of Orthopedic Surgery, Stanford University, Stanford, CA, United States; Beaulieu C.F., Department of Radiology, Stanford University, Stanford, CA, United States; Riley G.M., Department of Radiology, Stanford University, Stanford, CA, United States; Stewart R.J., Department of Radiology, Stanford University, Stanford, CA, United States; Blankenberg F.G., Department of Radiology, Stanford University, Stanford, CA, United States; Larson D.B., Department of Radiology, Stanford University, Stanford, CA, United States; Jones R.H., Department of Radiology, Stanford University, Stanford, CA, United States; Langlotz C.P., Department of Radiology, Stanford University, Stanford, CA, United States; Ng A.Y., Department of Computer Science, Stanford University, Stanford, CA, United States; Lungren M.P., Department of Radiology, Stanford University, Stanford, CA, United States","Background: Magnetic resonance imaging (MRI) of the knee is the preferred method for diagnosing knee injuries. However, interpretation of knee MRI is time-intensive and subject to diagnostic error and variability. An automated system for interpreting knee MRI could prioritize high-risk patients and assist clinicians in making diagnoses. Deep learning methods, in being able to automatically learn layers of features, are well suited for modeling the complex relationships between medical images and their interpretations. In this study we developed a deep learning model for detecting general abnormalities and specific diagnoses (anterior cruciate ligament [ACL] tears and meniscal tears) on knee MRI exams. We then measured the effect of providing the model’s predictions to clinical experts during interpretation. Methods and findings: Our dataset consisted of 1,370 knee MRI exams performed at Stanford University Medical Center between January 1, 2001, and December 31, 2012 (mean age 38.0 years; 569 [41.5%] female patients). The majority vote of 3 musculoskeletal radiologists established reference standard labels on an internal validation set of 120 exams. We developed MRNet, a convolutional neural network for classifying MRI series and combined predictions from 3 series per exam using logistic regression. In detecting abnormalities, ACL tears, and meniscal tears, this model achieved area under the receiver operating characteristic curve (AUC) values of 0.937 (95% CI 0.895, 0.980), 0.965 (95% CI 0.938, 0.993), and 0.847 (95% CI 0.780, 0.914), respectively, on the internal validation set. We also obtained a public dataset of 917 exams with sagittal T1-weighted series and labels for ACL injury from Clinical Hospital Centre Rijeka, Croatia. On the external validation set of 183 exams, the MRNet trained on Stanford sagittal T2-weighted series achieved an AUC of 0.824 (95% CI 0.757, 0.892) in the detection of ACL injuries with no additional training, while an MRNet trained on the rest of the external data achieved an AUC of 0.911 (95% CI 0.864, 0.958). We additionally measured the specificity, sensitivity, and accuracy of 9 clinical experts (7 board-certified general radiologists and 2 orthopedic surgeons) on the internal validation set both with and without model assistance. Using a 2-sided Pearson’s chi-squared test with adjustment for multiple comparisons, we found no significant differences between the performance of the model and that of unassisted general radiologists in detecting abnormalities. General radiologists achieved significantly higher sensitivity in detecting ACL tears (p-value = 0.002; q-value = 0.019) and significantly higher specificity in detecting meniscal tears (p-value = 0.003; q-value = 0.019). Using a 1-tailed t test on the change in performance metrics, we found that providing model predictions significantly increased clinical experts’ specificity in identifying ACL tears (p-value < 0.001; q-value = 0.006). The primary limitations of our study include lack of surgical ground truth and the small size of the panel of clinical experts. Conclusions: Our deep learning model can rapidly generate accurate clinical pathology classifications of knee MRI exams from both internal and external datasets. Moreover, our results support the assertion that deep learning models can improve the performance of clinical experts during medical imaging interpretation. Further research is needed to validate the model prospectively and to determine its utility in the clinical setting. © 2018 Bien et al. http://creativecommons.org/licenses/by/4.0/.","","Adult; Anterior Cruciate Ligament Injuries; Automation; Databases, Factual; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Image Interpretation, Computer-Assisted; Knee; Magnetic Resonance Imaging; Male; Middle Aged; Predictive Value of Tests; Reproducibility of Results; Retrospective Studies; Tibial Meniscus Injuries; Young Adult; adult; anterior cruciate ligament rupture; Article; artificial neural network; chronic pain; computer assisted diagnosis; computer model; computer prediction; controlled study; diagnostic test accuracy study; external validity; female; follow up; human; iliotibial band friction syndrome; internal validity; joint effusion; knee; knee fracture; knee meniscus rupture; limb injury; machine learning; major clinical study; male; measurement accuracy; musculoskeletal radiologist; nuclear magnetic resonance imaging; osteoarthritis; preoperative evaluation; probability; receiver operating characteristic; retrospective study; sensitivity analysis; sensitivity and specificity; sprain; anterior cruciate ligament injury; automation; diagnostic imaging; factual database; knee; knee meniscus rupture; middle aged; nuclear magnetic resonance imaging; predictive value; procedures; reproducibility; validation study; young adult","Public Library of Science","15491277","","","30481176","Article","Scopus","2-s2.0-85057229138"
"Pelt D.M.; Batenburg K.J.; Sethian J.A.","Pelt, Daniël M. (55913231800); Batenburg, Kees Joost (55879451400); Sethian, James A. (7005832375)","55913231800; 55879451400; 7005832375","Improving tomographic reconstruction from limited data using mixed-scale dense convolutional neural networks","2018","Journal of Imaging","71","10.3390/jimaging4110128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063210361&doi=10.3390%2fjimaging4110128&partnerID=40&md5=9a026527144994c5d3092c6e546aec12","Centrum Wiskunde and Informatica, Science Park 123, Amsterdam, 1098 XG, Netherlands; Department of Mathematics, University of California, Berkeley, 94720, CA, United States; Center for Applied Mathematics for Energy Research Applications, Lawrence Berkeley National Laboratory, Berkeley, 94720, CA, United States","Pelt D.M., Centrum Wiskunde and Informatica, Science Park 123, Amsterdam, 1098 XG, Netherlands; Batenburg K.J., Centrum Wiskunde and Informatica, Science Park 123, Amsterdam, 1098 XG, Netherlands; Sethian J.A., Department of Mathematics, University of California, Berkeley, 94720, CA, United States, Center for Applied Mathematics for Energy Research Applications, Lawrence Berkeley National Laboratory, Berkeley, 94720, CA, United States","In many applications of tomography, the acquired data are limited in one or more ways due to unavoidable experimental constraints. In such cases, popular direct reconstruction algorithms tend to produce inaccurate images, and more accurate iterative algorithms often have prohibitively high computational costs. Using machine learning to improve the image quality of direct algorithms is a recently proposed alternative, for which promising results have been shown. However, previous attempts have focused on using encoder-decoder networks, which have several disadvantages when applied to large tomographic images, preventing wide application in practice. Here, we propose the use of the Mixed-Scale Dense convolutional neural network architecture, which was specifically designed to avoid these disadvantages, to improve tomographic reconstruction from limited data. Results are shown for various types of data limitations and object types, for both simulated data and large-scale real-world experimental data. The results are compared with popular tomographic reconstruction algorithms and machine learning algorithms, showing that Mixed-Scale Dense networks are able to significantly improve reconstruction quality even with severely limited data, and produce more accurate results than existing algorithms. © 2018 by the authors.","Deep learning; Image reconstruction; Machine learning; Tomography","Convolution; Deep learning; Image enhancement; Iterative methods; Learning algorithms; Network architecture; Neural networks; Tomography; Computational costs; Convolutional neural network; Deep learning; Direct algorithms; Images reconstruction; Iterative algorithm; Limited data; Machine-learning; Reconstruction algorithms; Tomographic reconstruction; Image reconstruction","MDPI","2313433X","","","","Article","Scopus","2-s2.0-85063210361"
"Byra M.; Styczynski G.; Szmigielski C.; Kalinowski P.; Michałowski Ł.; Paluszkiewicz R.; Ziarkiewicz-Wróblewska B.; Zieniewicz K.; Sobieraj P.; Nowicki A.","Byra, Michał (56414988400); Styczynski, Grzegorz (6602523216); Szmigielski, Cezary (6508277122); Kalinowski, Piotr (23473323700); Michałowski, Łukasz (56764490600); Paluszkiewicz, Rafał (56251293600); Ziarkiewicz-Wróblewska, Bogna (6603594205); Zieniewicz, Krzysztof (7004549325); Sobieraj, Piotr (56990037100); Nowicki, Andrzej (56214353800)","56414988400; 6602523216; 6508277122; 23473323700; 56764490600; 56251293600; 6603594205; 7004549325; 56990037100; 56214353800","Transfer learning with deep convolutional neural network for liver steatosis assessment in ultrasound images","2018","International Journal of Computer Assisted Radiology and Surgery","173","10.1007/s11548-018-1843-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051671083&doi=10.1007%2fs11548-018-1843-2&partnerID=40&md5=58ee89a87e0d8ca98912411158ca4f63","Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Pawińskiego 5B, Warsaw, 02-106, Poland; Department of Internal Medicine, Hypertension and Vascular Diseases, Medical University of Warsaw, Warsaw, Poland; Department of General, Transplant and Liver Surgery, Medical University of Warsaw, Warsaw, Poland; Department of Pathology, Center for Biostructure Research, Medical University of Warsaw, Warsaw, Poland","Byra M., Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Pawińskiego 5B, Warsaw, 02-106, Poland; Styczynski G., Department of Internal Medicine, Hypertension and Vascular Diseases, Medical University of Warsaw, Warsaw, Poland; Szmigielski C., Department of Internal Medicine, Hypertension and Vascular Diseases, Medical University of Warsaw, Warsaw, Poland; Kalinowski P., Department of General, Transplant and Liver Surgery, Medical University of Warsaw, Warsaw, Poland; Michałowski Ł., Department of Pathology, Center for Biostructure Research, Medical University of Warsaw, Warsaw, Poland; Paluszkiewicz R., Department of General, Transplant and Liver Surgery, Medical University of Warsaw, Warsaw, Poland; Ziarkiewicz-Wróblewska B., Department of Pathology, Center for Biostructure Research, Medical University of Warsaw, Warsaw, Poland; Zieniewicz K., Department of General, Transplant and Liver Surgery, Medical University of Warsaw, Warsaw, Poland; Sobieraj P., Department of Internal Medicine, Hypertension and Vascular Diseases, Medical University of Warsaw, Warsaw, Poland; Nowicki A., Department of Ultrasound, Institute of Fundamental Technological Research, Polish Academy of Sciences, Pawińskiego 5B, Warsaw, 02-106, Poland","Purpose: The nonalcoholic fatty liver disease is the most common liver abnormality. Up to date, liver biopsy is the reference standard for direct liver steatosis quantification in hepatic tissue samples. In this paper we propose a neural network-based approach for nonalcoholic fatty liver disease assessment in ultrasound. Methods: We used the Inception-ResNet-v2 deep convolutional neural network pre-trained on the ImageNet dataset to extract high-level features in liver B-mode ultrasound image sequences. The steatosis level of each liver was graded by wedge biopsy. The proposed approach was compared with the hepatorenal index technique and the gray-level co-occurrence matrix algorithm. After the feature extraction, we applied the support vector machine algorithm to classify images containing fatty liver. Based on liver biopsy, the fatty liver was defined to have more than 5% of hepatocytes with steatosis. Next, we used the features and the Lasso regression method to assess the steatosis level. Results: The area under the receiver operating characteristics curve obtained using the proposed approach was equal to 0.977, being higher than the one obtained with the hepatorenal index method, 0.959, and much higher than in the case of the gray-level co-occurrence matrix algorithm, 0.893. For regression the Spearman correlation coefficients between the steatosis level and the proposed approach, the hepatorenal index and the gray-level co-occurrence matrix algorithm were equal to 0.78, 0.80 and 0.39, respectively. Conclusions: The proposed approach may help the sonographers automatically diagnose the amount of fat in the liver. The presented approach is efficient and in comparison with other methods does not require the sonographers to select the region of interest. © 2018, The Author(s).","Convolutional neural networks; Deep learning; Hepatorenal index; Nonalcoholic fatty liver disease; Transfer learning; Ultrasound imaging","Adult; Algorithms; Fatty Liver; Female; Humans; Liver; Male; Neural Networks (Computer); ROC Curve; Support Vector Machine; Ultrasonography; adult; Article; artificial neural network; B scan; classification algorithm; diagnostic accuracy; diagnostic test accuracy study; female; hepatorenal index; human; human tissue; image analysis; liver biopsy; liver cell; major clinical study; male; nonalcoholic fatty liver; parameters; priority journal; sensitivity and specificity; support vector machine; transfer of learning; algorithm; diagnostic imaging; echography; fatty liver; liver; procedures; receiver operating characteristic; support vector machine","Springer Verlag","18616410","","","30094778","Article","Scopus","2-s2.0-85051671083"
"Iqbal T.; Ali H.","Iqbal, Talha (57204137944); Ali, Hazrat (56501336300)","57204137944; 56501336300","Generative Adversarial Network for Medical Images (MI-GAN)","2018","Journal of Medical Systems","157","10.1007/s10916-018-1072-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054633488&doi=10.1007%2fs10916-018-1072-9&partnerID=40&md5=9f65c2a5308a5c9f6749a13079cc5494","Department of Electrical Engineering, COMSATS University Islamabad, Abbottabad Campus, Islamabad, Pakistan","Iqbal T., Department of Electrical Engineering, COMSATS University Islamabad, Abbottabad Campus, Islamabad, Pakistan; Ali H., Department of Electrical Engineering, COMSATS University Islamabad, Abbottabad Campus, Islamabad, Pakistan","Deep learning algorithms produces state-of-the-art results for different machine learning and computer vision tasks. To perform well on a given task, these algorithms require large dataset for training. However, deep learning algorithms lack generalization and suffer from over-fitting whenever trained on small dataset, especially when one is dealing with medical images. For supervised image analysis in medical imaging, having image data along with their corresponding annotated ground-truths is costly as well as time consuming since annotations of the data is done by medical experts manually. In this paper, we propose a new Generative Adversarial Network for Medical Imaging (MI-GAN). The MI-GAN generates synthetic medical images and their segmented masks, which can then be used for the application of supervised analysis of medical images. Particularly, we present MI-GAN for synthesis of retinal images. The proposed method generates precise segmented images better than the existing techniques. The proposed model achieves a dice coefficient of 0.837 on STARE dataset and 0.832 on DRIVE dataset which is state-of-the-art performance on both the datasets. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Deep learning; GAN; Medical imaging; Retinal images; Style transfer","Algorithms; Deep Learning; Diagnostic Techniques, Ophthalmological; Image Processing, Computer-Assisted; Retina; algorithm; diagnostic imaging; image processing; procedures; retina; visual system examination","Springer New York LLC","01485598","","JMSYD","30315368","Article","Scopus","2-s2.0-85054633488"
"Safder U.; Nam K.; Kim D.; Shahlaei M.; Yoo C.","Safder, Usman (57201878117); Nam, KiJeon (57195405510); Kim, Dongwoo (57190440343); Shahlaei, Mohsen (26428548900); Yoo, ChangKyoo (7201746395)","57201878117; 57195405510; 57190440343; 26428548900; 7201746395","Quantitative structure-property relationship (QSPR) models for predicting the physicochemical properties of polychlorinated biphenyls (PCBs) using deep belief network","2018","Ecotoxicology and Environmental Safety","22","10.1016/j.ecoenv.2018.06.061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048963668&doi=10.1016%2fj.ecoenv.2018.06.061&partnerID=40&md5=4e6df0d10f94863997b6c328718ca6f8","Dept. of Environmental Science and Engineering, College of Engineering, Center for Environmental Studies, Kyung Hee University, Seocheon-dong 1, Giheung-gu, Yongin-Si, 446-701, Gyeonggi-Do, South Korea; Nano Drug Delivery Research Center, Kermanshah University of Medical Sciences, Kermanshah, Iran","Safder U., Dept. of Environmental Science and Engineering, College of Engineering, Center for Environmental Studies, Kyung Hee University, Seocheon-dong 1, Giheung-gu, Yongin-Si, 446-701, Gyeonggi-Do, South Korea; Nam K., Dept. of Environmental Science and Engineering, College of Engineering, Center for Environmental Studies, Kyung Hee University, Seocheon-dong 1, Giheung-gu, Yongin-Si, 446-701, Gyeonggi-Do, South Korea; Kim D., Dept. of Environmental Science and Engineering, College of Engineering, Center for Environmental Studies, Kyung Hee University, Seocheon-dong 1, Giheung-gu, Yongin-Si, 446-701, Gyeonggi-Do, South Korea; Shahlaei M., Nano Drug Delivery Research Center, Kermanshah University of Medical Sciences, Kermanshah, Iran; Yoo C., Dept. of Environmental Science and Engineering, College of Engineering, Center for Environmental Studies, Kyung Hee University, Seocheon-dong 1, Giheung-gu, Yongin-Si, 446-701, Gyeonggi-Do, South Korea","Octanol/water partition coefficient (log P), octanol/air partition coefficient (log KOA) and bioconcentration factor (log BCF) are important physiochemical properties of organic substances. Quantitative structure-property relationship (QSPR) models are a promising alternative method of reducing and replacing experimental steps in determination of log P, log KOA and log BCF. In the current study, we propose a new QSPR model based on a deep belief network (DBN) to predict the physicochemical properties of polychlorinated biphenyls (PCBs). The prediction accuracy of the proposed model was compared to the results of previous reported models. The predictive ability of the DBN model, validated with a test set, is clearly superior to the other models. All results showed that the proposed model is robust and satisfactory, and can effectively predict the physiochemical properties of PCBs without highly reliable experimental values. © 2018 Elsevier Inc.","Deep belief network (DBN); DRAGON molecular descriptors; Polychlorinated biphenyls (PCBs); Quantitative structure-property relationship (QSPR)","Acacia koa; polychlorinated biphenyl; artificial neural network; bioaccumulation; partition coefficient; PCB; physicochemical property; regression analysis; algorithm; Article; chemical analysis; correlational study; machine learning; measurement accuracy; physical chemistry; prediction; quantitative structure property relation; stochastic model; validation process","Academic Press","01476513","","EESAD","","Article","Scopus","2-s2.0-85048963668"
"Waytowich N.; Lawhern V.J.; Garcia J.O.; Cummings J.; Faller J.; Sajda P.; Vettel J.M.","Waytowich, Nicholas (36683457800); Lawhern, Vernon J. (35795485600); Garcia, Javier O. (21742595700); Cummings, Jennifer (7402590891); Faller, Josef (37046898400); Sajda, Paul (57204342918); Vettel, Jean M. (6506702696)","36683457800; 35795485600; 21742595700; 7402590891; 37046898400; 57204342918; 6506702696","Compact convolutional neural networks for classification of asynchronous steady-state visual evoked potentials","2018","Journal of Neural Engineering","129","10.1088/1741-2552/aae5d8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056633525&doi=10.1088%2f1741-2552%2faae5d8&partnerID=40&md5=ab532fd3958656a040108fda35a7a91a","U S Army Research Laboratory, Aberdeen Proving Ground, MD, United States; Laboratory for Intelligent Imaging and Neural Computing, Columbia University, New York, NY, United States; Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States; Department of Physiological Brain Sciences, University of California, Santa Barbara, CA, United States","Waytowich N., U S Army Research Laboratory, Aberdeen Proving Ground, MD, United States, Laboratory for Intelligent Imaging and Neural Computing, Columbia University, New York, NY, United States; Lawhern V.J., U S Army Research Laboratory, Aberdeen Proving Ground, MD, United States; Garcia J.O., U S Army Research Laboratory, Aberdeen Proving Ground, MD, United States, Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States; Cummings J., Laboratory for Intelligent Imaging and Neural Computing, Columbia University, New York, NY, United States; Faller J., Laboratory for Intelligent Imaging and Neural Computing, Columbia University, New York, NY, United States; Sajda P., Laboratory for Intelligent Imaging and Neural Computing, Columbia University, New York, NY, United States; Vettel J.M., U S Army Research Laboratory, Aberdeen Proving Ground, MD, United States, Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States, Department of Physiological Brain Sciences, University of California, Santa Barbara, CA, United States","Objective. Steady-state visual evoked potentials (SSVEPs) are neural oscillations from the parietal and occipital regions of the brain that are evoked from flickering visual stimuli. SSVEPs are robust signals measurable in the electroencephalogram (EEG) and are commonly used in brain-computer interfaces (BCIs). However, methods for high-accuracy decoding of SSVEPs usually require hand-crafted approaches that leverage domain-specific knowledge of the stimulus signals, such as specific temporal frequencies in the visual stimuli and their relative spatial arrangement. When this knowledge is unavailable, such as when SSVEP signals are acquired asynchronously, such approaches tend to fail. Approach. In this paper, we show how a compact convolutional neural network (Compact-CNN), which only requires raw EEG signals for automatic feature extraction, can be used to decode signals from a 12-class SSVEP dataset without the need for user-specific calibration. Main results. The Compact-CNN demonstrates across subject mean accuracy of approximately 80%, out-performing current state-of-the-art, hand-crafted approaches using canonical correlation analysis (CCA) and Combined-CCA. Furthermore, the Compact-CNN approach can reveal the underlying feature representation, revealing that the deep learner extracts additional phase- and amplitude-related features associated with the structure of the dataset. Significance. We discuss how our Compact-CNN shows promise for BCI applications that allow users to freely gaze/attend to any stimulus at any time (e.g. asynchronous BCI) as well as provides a method for analyzing SSVEP signals in a way that might augment our understanding about the basic processing in the visual cortex. © 2018 IOP Publishing Ltd.","brain-computer interface; convolutional neural networks; deep learning; steady-state visual evoked potentials","Adult; Algorithms; Brain-Computer Interfaces; Electroencephalography; Evoked Potentials, Visual; Healthy Volunteers; Humans; Machine Learning; Neural Networks (Computer); Photic Stimulation; Reproducibility of Results; Signal Processing, Computer-Assisted; Visual Cortex; article; brain computer interface; calibration; controlled study; correlation analysis; electroencephalogram; feature extraction; gaze; human; human experiment; learning; steady state; stimulus; visual cortex; visual evoked potential; adult; algorithm; artificial neural network; brain computer interface; classification; electroencephalography; machine learning; normal human; photostimulation; physiology; reproducibility; signal processing; visual evoked potential","Institute of Physics Publishing","17412560","","","30279309","Article","Scopus","2-s2.0-85056633525"
"Zhang L.; Fang X.; Bo H.; Wang T.; Lu H.","Zhang, Lihe (35757157000); Fang, Xiang (57202580998); Bo, Hongguang (9733411000); Wang, Tiantian (55430891400); Lu, Huchuan (8218163400)","35757157000; 57202580998; 9733411000; 55430891400; 8218163400","Deep multi-level networks with multi-task learning for saliency detection","2018","Neurocomputing","10","10.1016/j.neucom.2018.05.105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048804047&doi=10.1016%2fj.neucom.2018.05.105&partnerID=40&md5=2f5048354de6145d572943c020c19f6d","School of Information and Communication Engineering, Dalian University of Technology, Dalian, 116023, China","Zhang L., School of Information and Communication Engineering, Dalian University of Technology, Dalian, 116023, China; Fang X., School of Information and Communication Engineering, Dalian University of Technology, Dalian, 116023, China; Bo H., School of Information and Communication Engineering, Dalian University of Technology, Dalian, 116023, China; Wang T., School of Information and Communication Engineering, Dalian University of Technology, Dalian, 116023, China; Lu H., School of Information and Communication Engineering, Dalian University of Technology, Dalian, 116023, China","Category-independent region proposals have been utilized for salient objects detection in recent works. However, these works may fail when the extracted proposals have poor overlap with salient objects. In this paper, we demonstrate segment-level saliency prediction can provide these methods with complementary information to improve detection results. In addition, classification loss (i.e., softmax) can distinguish positive samples from negative ones and similarity loss (i.e., triplet) can enlarge the contrast difference between samples with different class labels. We propose a joint optimization of the two losses to further promote the performance. Finally, a multi-layer cellular automata model is incorporated to generate the final saliency map with fine shape boundary and object-level highlighting. The proposed method has achieved state-of-the-art results on four benchmark datasets. © 2018 Elsevier B.V.","Convolutional neural networks; Multi-task learning; Saliency detection","Learning systems; Neural networks; Benchmark datasets; Cellular automata modeling; Convolutional neural network; Joint optimization; Multi-level networks; Multitask learning; Region proposals; Saliency detection; algorithm; Article; artificial neural network; automated pattern recognition; classifier; convolutional neural network; image analysis; machine learning; multitask learning; priority journal; saliency detection; Object detection","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85048804047"
"Bramer D.; Wei G.-W.","Bramer, David (57200494902); Wei, Guo-Wei (57210276955)","57200494902; 57210276955","Blind prediction of protein B-factor and flexibility","2018","Journal of Chemical Physics","19","10.1063/1.5048469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054423886&doi=10.1063%2f1.5048469&partnerID=40&md5=8b544a82655e9ea37156e4229e5b8030","Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States; Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, 48824, MI, United States; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824, MI, United States","Bramer D., Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States; Wei G.-W., Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States, Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, 48824, MI, United States, Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824, MI, United States","The Debye-Waller factor, a measure of X-ray attenuation, can be experimentally observed in protein X-ray crystallography. Previous theoretical models have made strong inroads in the analysis of beta (B)-factors by linearly fitting protein B-factors from experimental data. However, the blind prediction of B-factors for unknown proteins is an unsolved problem. This work integrates machine learning and advanced graph theory, namely, multiscale weighted colored graphs (MWCGs), to blindly predict B-factors of unknown proteins. MWCGs are local features that measure the intrinsic flexibility due to a protein structure. Global features that connect the B-factors of different proteins, e.g., the resolution of X-ray crystallography, are introduced to enable the cross-protein B-factor predictions. Several machine learning approaches, including ensemble methods and deep learning, are considered in the present work. The proposed method is validated with hundreds of thousands of experimental B-factors. Extensive numerical results indicate that the blind B-factor predictions obtained from the present method are more accurate than the least squares fittings using traditional methods. © 2018 Author(s).","","Algorithms; Animals; Computer Graphics; Crystallography, X-Ray; Databases, Protein; Elasticity; Humans; Machine Learning; Protein Conformation; Receptors, Fc; Artificial intelligence; Deep learning; Forecasting; Graph theory; Least squares approximations; Numerical methods; Proteins; Self assembly; X ray analysis; X rays; Fc receptor; IgA receptor; Blind predictions; Debye Waller factor; Least squares fitting; Machine learning approaches; Numerical results; Protein structures; Protein x-ray crystallography; X-ray attenuation; algorithm; animal; chemistry; computer graphics; elasticity; human; machine learning; procedures; protein conformation; protein database; X ray crystallography; X ray crystallography","American Institute of Physics Inc.","00219606","","JCPSA","30292224","Article","Scopus","2-s2.0-85054423886"
"Li F.; Liu W.; Yu H.","Li, Fei (57215065441); Liu, Weisong (57204355702); Yu, Hong (35785447400)","57215065441; 57204355702; 35785447400","Extraction of information related to adverse drug events from electronic health record notes: Design of an end-to-end model based on deep learning","2018","JMIR Medical Informatics","38","10.2196/12159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067837394&doi=10.2196%2f12159&partnerID=40&md5=00150899ea3702d09653b4e1ddbeb05b","Department of Computer Science, University of Massachusetts Lowell, Lowell, MA, United States; Center for Healthcare Organization and Implementation Research, Bedford Veterans Affairs Medical Center, Bedford, MA, United States; Department of Medicine, University of Massachusetts Medical School, Worcester, MA, United States; School of Computer Science, University of Massachusetts, Amherst, MA, United States","Li F., Department of Computer Science, University of Massachusetts Lowell, Lowell, MA, United States, Center for Healthcare Organization and Implementation Research, Bedford Veterans Affairs Medical Center, Bedford, MA, United States, Department of Medicine, University of Massachusetts Medical School, Worcester, MA, United States; Liu W., Department of Computer Science, University of Massachusetts Lowell, Lowell, MA, United States, Center for Healthcare Organization and Implementation Research, Bedford Veterans Affairs Medical Center, Bedford, MA, United States, Department of Medicine, University of Massachusetts Medical School, Worcester, MA, United States; Yu H., Department of Computer Science, University of Massachusetts Lowell, Lowell, MA, United States, Center for Healthcare Organization and Implementation Research, Bedford Veterans Affairs Medical Center, Bedford, MA, United States, Department of Medicine, University of Massachusetts Medical School, Worcester, MA, United States, School of Computer Science, University of Massachusetts, Amherst, MA, United States","Background: Pharmacovigilance and drug-safety surveillance are crucial for monitoring adverse drug events (ADEs), but the main ADE-reporting systems such as Food and Drug Administration Adverse Event Reporting System face challenges such as underreporting. Therefore, as complementary surveillance, data on ADEs are extracted from electronic health record (EHR) notes via natural language processing (NLP). As NLP develops, many up-to-date machine-learning techniques are introduced in this field, such as deep learning and multi-task learning (MTL). However, only a few studies have focused on employing such techniques to extract ADEs. Objective: We aimed to design a deep learning model for extracting ADEs and related information such as medications and indications. Since extraction of ADE-related information includes two steps-named entity recognition and relation extraction-our second objective was to improve the deep learning model using multi-task learning between the two steps. Methods: We employed the dataset from the Medication, Indication and Adverse Drug Events (MADE) 1.0 challenge to train and test our models. This dataset consists of 1089 EHR notes of cancer patients and includes 9 entity types such as Medication, Indication, and ADE and 7 types of relations between these entities. To extract information from the dataset, we proposed a deep-learning model that uses a bidirectional long short-term memory (BiLSTM) conditional random field network to recognize entities and a BiLSTM-Attention network to extract relations. To further improve the deep-learning model, we employed three typical MTL methods, namely, hard parameter sharing, parameter regularization, and task relation learning, to build three MTL models, called HardMTL, RegMTL, and LearnMTL, respectively. Results: Since extraction of ADE-related information is a two-step task, the result of the second step (ie, relation extraction) was used to compare all models. We used microaveraged precision, recall, and F1 as evaluation metrics. Our deep learning model achieved state-of-the-art results (F1=65.9%), which is significantly higher than that (F1=61.7%) of the best system in the MADE1.0 challenge. HardMTL further improved the F1 by 0.8%, boosting the F1 to 66.7%, whereas RegMTL and LearnMTL failed to boost the performance. Conclusions: Deep learning models can significantly improve the performance of ADE-related information extraction. MTL may be effective for named entity recognition and relation extraction, but it depends on the methods, data, and other factors. Our results can facilitate research on ADE detection, NLP, and machine learning. © 2018 JMIR Publications Inc.. All right reserved.","Adverse drug event; Deep learning; Multi-task learning; Named entity recognition; Natural language processing; Relation extraction","","JMIR Publications Inc.","22919694","","","","Article","Scopus","2-s2.0-85067837394"
"Mazo C.; Bernal J.; Trujillo M.; Alegre E.","Mazo, Claudia (55348155300); Bernal, Jose (57202547109); Trujillo, Maria (23393938300); Alegre, Enrique (55901820900)","55348155300; 57202547109; 23393938300; 55901820900","Transfer learning for classification of cardiovascular tissues in histological images","2018","Computer Methods and Programs in Biomedicine","56","10.1016/j.cmpb.2018.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051947652&doi=10.1016%2fj.cmpb.2018.08.006&partnerID=40&md5=1905d14052eab2e6b0e023c23df3f33f","University College Dublin, CeADAR: Centre for Applied Data Analytics Research, School of Computer Science, Dublin, Ireland; Universitat de Girona, Institute of Computer Vision and Robotics, Girona, Spain; Universidad del Valle, Computer and Systems Engineering School, Cali, Colombia; Universidad de León, Industrial and Informatics Engineering School, León, Spain","Mazo C., University College Dublin, CeADAR: Centre for Applied Data Analytics Research, School of Computer Science, Dublin, Ireland; Bernal J., Universitat de Girona, Institute of Computer Vision and Robotics, Girona, Spain; Trujillo M., Universidad del Valle, Computer and Systems Engineering School, Cali, Colombia; Alegre E., Universidad de León, Industrial and Informatics Engineering School, León, Spain","Background and Objective: Automatic classification of healthy tissues and organs based on histology images is an open problem, mainly due to the lack of automated tools. Solutions in this regard have potential in educational medicine and medical practices. Some preliminary advances have been made using image processing techniques and classical supervised learning. Due to the breakthrough performance of deep learning in various areas, we present an approach to recognise and classify, automatically, fundamental tissues and organs using Convolutional Neural Networks (CNN). Methods: We adapt four popular CNNs architectures – ResNet, VGG19, VGG16 and Inception – to this problem through transfer learning. The resulting models are evaluated at three stages. Firstly, all the transferred networks are compared to each other. Secondly, the best resulting fine-tuned model is compared to an ad-hoc 2D multi-path model to outline the importance of transfer learning. Thirdly, the same model is evaluated against the state-of-the-art method, a cascade SVM using LBP-based descriptors, to contrast a traditional machine learning approach and a representation learning one. The evaluation task consists of separating six classes accurately: smooth muscle of the elastic artery, smooth muscle of the large vein, smooth muscle of the muscular artery, cardiac muscle, loose connective tissue, and light regions. The different networks are tuned on 6000 blocks of 100 × 100 pixels and tested on 7500. Results: Our proposal yields F-score values between 0.717 and 0.928. The highest and lowest performances are for cardiac muscle and smooth muscle of the large vein, respectively. The main issue leading to limited classification scores for the latter class is its similarity with the elastic artery. However, this confusion is evidenced during manual annotation as well. Our algorithm reached improvements in F-score between 0.080 and 0.220 compared to the state-of-the-art machine learning approach. Conclusions: We conclude that it is possible to classify healthy cardiovascular tissues and organs automatically using CNNs and that deep learning holds great promise to improve tissue and organs classification. We left our training and test sets, models and source code publicly available to the research community. © 2018 Elsevier B.V.","Cardiovascular system; Fundamental tissues; Histological images; Organs; SVM; Transfer learning","Algorithms; Cardiovascular System; Deep Learning; Histological Techniques; Humans; Image Processing, Computer-Assisted; Machine Learning; Models, Anatomic; Models, Cardiovascular; Neural Networks (Computer); Reference Values; Support Vector Machine; Cardiovascular system; Collagen; Histology; Image classification; Medicine; Muscle; Neural networks; Automatic classification; Convolutional Neural Networks (CNN); Histological images; Image processing technique; Loose connective tissues; Machine learning approaches; Organs; Transfer learning; artery; article; cardiac muscle; cardiovascular tissue; histopathology; human; human experiment; human tissue; machine learning; nervous system; transfer of learning; venous smooth muscle; algorithm; anatomic model; anatomy and histology; artificial neural network; biological model; cardiovascular system; histology; image processing; machine learning; procedures; reference value; statistics and numerical data; support vector machine; Deep learning","Elsevier Ireland Ltd","01692607","","CMPBE","30337082","Article","Scopus","2-s2.0-85051947652"
"Su Z.; Liang X.; Guo J.; Gao C.; Luo X.","Su, Zhuo (36916006800); Liang, Xiangguo (57192819798); Guo, Jiaming (57192820935); Gao, Chengying (9333513300); Luo, Xiaonan (8293331200)","36916006800; 57192819798; 57192820935; 9333513300; 8293331200","An edge-refined vectorized deep colorization model for grayscale-to-color images","2018","Neurocomputing","12","10.1016/j.neucom.2018.05.082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048190277&doi=10.1016%2fj.neucom.2018.05.082&partnerID=40&md5=05fc36c6883a4df9523668fc2b807f2e","School of Data and Computer Science, National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangdong, China; School of Computer Science and Information Security, Guilin University of Electronic Technology, Guangxi, China","Su Z., School of Data and Computer Science, National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangdong, China; Liang X., School of Data and Computer Science, National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangdong, China; Guo J., School of Data and Computer Science, National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangdong, China; Gao C., School of Data and Computer Science, National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangdong, China; Luo X., School of Computer Science and Information Security, Guilin University of Electronic Technology, Guangxi, China","To handle the colorization problem, we propose an edge-refined vectorized deep colorization model. We discuss the reasonable network parameters like the patch size, amount of layers, convolutional kernel size and amount. To improve the colorization performance and simplify the model, two neural networks are respectively trained to obtain the value of U and V components since the model is in YUV color space. In the training stage, we alternately apply two loss metric functions in the deep model to suppress the training errors and verify our training scheme by quantitative analysis. To address the potential boundary artifacts, we propose three kinds of refinement schemes and make a comparison on their performances. In the experiment section, we not only validate the reasonableness of our network parameters setting, but also conduct further exploration and analysis. Moreover, our experiments demonstrate this model can output more visual satisfactory colorization and obtain a better quantitative result when compared with the state-of-the-art methods. Last, we prove our method has extensive application domains and can be applied to stylistic colorization. © 2018 Elsevier B.V.","Colorization model; Deep convolution networks; Edge-aware filter","Convolution; Boundary artifacts; Convolutional kernel; Edge aware; Network parameters; Quantitative result; State-of-the-art methods; Training errors; Training schemes; Article; artifact; artificial neural network; color; color image; controlled study; forward propagation; grayscale image; image processing; image quality; imaging and display; kernel method; linear regression analysis; machine learning; mathematical parameters; measurement accuracy; noise reduction; nonlinear system; priority journal; quantitative analysis; semantics; signal noise ratio; structural similarity index; systematic error; validation process; vectorized deep colorization model; Color","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85048190277"
"Gadermayr M.; Wimmer G.; Kogler H.; Vécsei A.; Merhof D.; Uhl A.","Gadermayr, M. (50361333000); Wimmer, G. (12790538100); Kogler, H. (56079344500); Vécsei, A. (55187184700); Merhof, D. (13103575700); Uhl, A. (7005841206)","50361333000; 12790538100; 56079344500; 55187184700; 13103575700; 7005841206","Automated classification of celiac disease during upper endoscopy: Status quo and quo vadis","2018","Computers in Biology and Medicine","11","10.1016/j.compbiomed.2018.04.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046751117&doi=10.1016%2fj.compbiomed.2018.04.020&partnerID=40&md5=9ba9a047c97d17688c82a8be18a5ca2c","Institute of Imaging & Computer Vision, RWTH Aachen University, Aachen, 52074, Germany; Department of Computer Sciences, University of Salzburg, Salzburg, 5020, Austria; St. Anna Children's Hospital, Vienna, Austria","Gadermayr M., Institute of Imaging & Computer Vision, RWTH Aachen University, Aachen, 52074, Germany; Wimmer G., Department of Computer Sciences, University of Salzburg, Salzburg, 5020, Austria; Kogler H., St. Anna Children's Hospital, Vienna, Austria; Vécsei A., St. Anna Children's Hospital, Vienna, Austria; Merhof D., Institute of Imaging & Computer Vision, RWTH Aachen University, Aachen, 52074, Germany; Uhl A., Department of Computer Sciences, University of Salzburg, Salzburg, 5020, Austria","A large amount of digital image material is routinely captured during esophagogastroduodenoscopies but, for the most part, is not used for confirming the diagnosis process of celiac disease which is primarily based on histological examination of biopsies. Recently, considerable effort has been undertaken to make use of image material by developing semi- or fully-automated systems to improve the diagnostic workup. Recently, focus was especially laid on developing state-of-the-art deep learning architectures, exploiting the endoscopist's expert knowledge and on making systems fully automated and thereby completely observer independent. In this work, we summarize recent trends in the field of computer-aided celiac disease diagnosis based on upper endoscopy and discuss about recent progress, remaining challenges, limitations currently prohibiting a deployment in clinical practice and future efforts to tackle them. © 2018 The Authors","Celiac disease; Classification; Computer-aided diagnosis; Decision support; Deep learning; Observer independent","Algorithms; Automation; Biopsy; Celiac Disease; Decision Making; Deep Learning; Diagnosis, Computer-Assisted; Duodenum; Endoscopy; Gastroscopy; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Observer Variation; Pattern Recognition, Automated; Automation; Classification (of information); Computer aided instruction; Decision support systems; Deep learning; Endoscopy; Image enhancement; Automated classification; Celiac disease; Clinical practices; Decision supports; Expert knowledge; Histological examination; Learning architectures; Observer independent; Article; celiac disease; clinical practice; diagnostic accuracy; disease classification; endoscopist; endoscopy; esophagogastroduodenoscopy; histology; human; knowledge; learning; priority journal; algorithm; artificial neural network; automated pattern recognition; automation; biopsy; celiac disease; computer assisted diagnosis; decision making; diagnostic imaging; duodenum; gastroscopy; image processing; machine learning; observer variation; procedures; Computer aided diagnosis","Elsevier Ltd","00104825","","CBMDA","29739614","Article","Scopus","2-s2.0-85046751117"
"Chemali E.; Kollmeyer P.J.; Preindl M.; Emadi A.","Chemali, Ephrem (57189580868); Kollmeyer, Phillip J. (36675205100); Preindl, Matthias (36025772200); Emadi, Ali (7007140517)","57189580868; 36675205100; 36025772200; 7007140517","State-of-charge estimation of Li-ion batteries using deep neural networks: A machine learning approach","2018","Journal of Power Sources","475","10.1016/j.jpowsour.2018.06.104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051653123&doi=10.1016%2fj.jpowsour.2018.06.104&partnerID=40&md5=4a459ef11d5c013a66deb570bfa9bdaf","Department of Electrical and Computer Engineering, McMaster Institute for Automotive Research and Technology, McMaster University, Hamilton, ON, Canada; Department of Electrical Engineering, Columbia University in the City of New York, New York, NY, United States","Chemali E., Department of Electrical and Computer Engineering, McMaster Institute for Automotive Research and Technology, McMaster University, Hamilton, ON, Canada; Kollmeyer P.J., Department of Electrical and Computer Engineering, McMaster Institute for Automotive Research and Technology, McMaster University, Hamilton, ON, Canada; Preindl M., Department of Electrical Engineering, Columbia University in the City of New York, New York, NY, United States; Emadi A., Department of Electrical and Computer Engineering, McMaster Institute for Automotive Research and Technology, McMaster University, Hamilton, ON, Canada","Accurate State of Charge (SOC) estimation is crucial to ensure the safe and reliable operation of Li-ion batteries, which are increasingly being used in Electric Vehicles (EV), grid-tied load-leveling applications as well as manned and unmanned aerial vehicles to name a few applications. In this paper, a novel approach using Deep Feedforward Neural Networks (DNN) is used for battery SOC estimation where battery measurements are directly mapped to SOC. Training data is generated in the lab by applying drive cycle loads at various ambient temperatures to a Li-ion battery so that the battery is exposed to variable dynamics. The DNN's ability to encode the dependencies in time into the network weights and in the process provide accurate estimates of SOC is presented. Moreover, data recorded at ambient temperatures lying between −20 °C and 25 °C are fed into the DNN during training. Once trained, this single DNN is able to estimate SOC at various ambient temperature conditions. The DNN is validated over many different datasets and achieves a Mean Absolute Error (MAE) of 1.10% over a 25 °C dataset as well as an MAE of 2.17% over a −20 °C dataset. © 2018","Battery management systems; Deep neural networks; Energy storage system; Li-ion batteries; Machine learning; State of charge estimation","Antennas; Charging (batteries); Deep neural networks; Digital storage; Feedforward neural networks; Ions; Learning systems; Lithium-ion batteries; Temperature; Energy storage systems; Machine learning approaches; Mean absolute error; Reliable operation; State of charge estimations (SOC); State-of-charge estimation; Temperature conditions; Variable dynamics; Battery management systems","Elsevier B.V.","03787753","","JPSOD","","Article","Scopus","2-s2.0-85051653123"
"Lee Y.H.","Lee, Young Han (43262256000)","43262256000","Efficiency Improvement in a Busy Radiology Practice: Determination of Musculoskeletal Magnetic Resonance Imaging Protocol Using Deep-Learning Convolutional Neural Networks","2018","Journal of Digital Imaging","58","10.1007/s10278-018-0066-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044939478&doi=10.1007%2fs10278-018-0066-y&partnerID=40&md5=7b862a283a08c5283a95e3be69600a47","Department of Radiology, Research Institute of Radiological Science, YUHS-KRIBB Medical Convergence Research Institute and Center for Clinical Imaging Data Science, Yonsei University College of Medicine, 50-1 Yonsei-ro, Seodaemun-gu, Seoul, 03722, South Korea","Lee Y.H., Department of Radiology, Research Institute of Radiological Science, YUHS-KRIBB Medical Convergence Research Institute and Center for Clinical Imaging Data Science, Yonsei University College of Medicine, 50-1 Yonsei-ro, Seodaemun-gu, Seoul, 03722, South Korea","The purposes of this study are to evaluate the feasibility of protocol determination with a convolutional neural networks (CNN) classifier based on short-text classification and to evaluate the agreements by comparing protocols determined by CNN with those determined by musculoskeletal radiologists. Following institutional review board approval, the database of a hospital information system (HIS) was queried for lists of MRI examinations, referring department, patient age, and patient gender. These were exported to a local workstation for analyses: 5258 and 1018 consecutive musculoskeletal MRI examinations were used for the training and test datasets, respectively. The subjects for pre-processing were routine or tumor protocols and the contents were word combinations of the referring department, region, contrast media (or not), gender, and age. The CNN Embedded vector classifier was used with Word2Vec Google news vectors. The test set was tested with each classification model and results were output as routine or tumor protocols. The CNN determinations were evaluated using the receiver operating characteristic (ROC) curves. The accuracies were evaluated by a radiologist-confirmed protocol as the reference protocols. The optimal cut-off values for protocol determination between routine protocols and tumor protocols was 0.5067 with a sensitivity of 92.10%, a specificity of 95.76%, and an area under curve (AUC) of 0.977. The overall accuracy was 94.2% for the ConvNet model. All MRI protocols were correct in the pelvic bone, upper arm, wrist, and lower leg MRIs. Deep-learning-based convolutional neural networks were clinically utilized to determine musculoskeletal MRI protocols. CNN-based text learning and applications could be extended to other radiologic tasks besides image interpretations, improving the work performance of the radiologist. © 2018, Society for Imaging Informatics in Medicine.","Artificial neural networks; Image protocols; Machine learning; Magnetic resonance imaging protocol","Algorithms; Databases, Factual; Deep Learning; Efficiency, Organizational; Feasibility Studies; Female; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Musculoskeletal Diseases; Musculoskeletal System; Neural Networks (Computer); Sensitivity and Specificity; Workflow; Classification (of information); Contrast media; Convolution; Deep neural networks; Image enhancement; Learning algorithms; Learning systems; Magnetic levitation vehicles; Magnetic resonance imaging; Musculoskeletal system; Neural networks; Text processing; Tumors; Classification models; Convolutional neural network; Convolutional Neural Networks (CNN); Efficiency improvement; Hospital information systems; Institutional review boards; Receiver Operating Characteristic (ROC) curves; Short text classifications; algorithm; artificial neural network; computer assisted diagnosis; diagnostic imaging; factual database; feasibility study; female; human; male; middle aged; musculoskeletal disease; musculoskeletal system; nuclear magnetic resonance imaging; organization and management; procedures; sensitivity and specificity; workflow; Internet protocols","Springer New York LLC","08971889","","JDIME","29619578","Article","Scopus","2-s2.0-85044939478"
"Reddy B.K.; Delen D.","Reddy, Bhargava K (57203798198); Delen, Dursun (55887961100)","57203798198; 55887961100","Predicting hospital readmission for lupus patients: An RNN-LSTM-based deep-learning methodology","2018","Computers in Biology and Medicine","103","10.1016/j.compbiomed.2018.08.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052738184&doi=10.1016%2fj.compbiomed.2018.08.029&partnerID=40&md5=ae4b2b963c10a7eb52a4923ed8af2c8b","UCB Biosciences, Inc., 8010 Arco Corporate Drive, Suite 100, Raleigh, 27617, NC, United States; Department of Management Science and Information Systems, Spears School of Business, Oklahoma State University, Tulsa, 74106, OK, United States","Reddy B.K., UCB Biosciences, Inc., 8010 Arco Corporate Drive, Suite 100, Raleigh, 27617, NC, United States; Delen D., Department of Management Science and Information Systems, Spears School of Business, Oklahoma State University, Tulsa, 74106, OK, United States","Hospital readmission is one of the critical metrics used for measuring the performance of hospitals. The HITECH Act imposes penalties when patients are readmitted to hospitals if they are diagnosed with one of the six conditions mentioned in the Act. However, patients diagnosed with lupus are the sixth highest in terms of rehospitalization. The heterogeneity in the disease and patient characteristics makes it very hard to predict rehospitalization. This research utilizes deep learning methods to predict rehospitalization within 30 days by extracting the temporal relationships in the longitudinal EHR clinical data. Prediction results from deep learning methods such as LSTM are evaluated and compared with traditional classification methods such as penalized logistic regression and artificial neural networks. The simple recurrent neural network method and its variant, gated recurrent unit network, are also developed and validated to compare their performance against the proposed LSTM model. The results indicated that the deep learning method RNN-LSTM has a significantly better performance (with an AUC of.70) compared to traditional classification methods such as ANN (with an AUC of 0.66) and penalized logistic regression (with an AUC of 0.63). The rationale for the better performance of the deep learning method may be due to its ability to leverage the temporal relationships of the disease state in patients over time and to capture the progression of the disease—relevant clinical information from patients’ prior visits is carried forward in the memory, which may have enabled the higher predictability for the deep learning methods. © 2018 Elsevier Ltd","Deep learning; LSTM; Lupus; Machine learning; Predictive analytics; Readmission","Deep Learning; Female; Humans; Lupus Erythematosus, Systemic; Male; Models, Biological; Neural Networks (Computer); Patient Readmission; Predictive Value of Tests; Clinical research; Forecasting; Hospitals; Learning systems; Long short-term memory; Patient monitoring; Predictive analytics; Regression analysis; Classification methods; Clinical information; LSTM; Lupus; Penalized logistic regression; Readmission; Simple recurrent neural networks; Temporal relationships; adult; Article; artificial neural network; classification algorithm; evaluation study; female; hospital readmission; human; learning; logistic regression analysis; lupus vulgaris; major clinical study; male; methodology; middle aged; motivation; predictive value; priority journal; short term memory; artificial neural network; biological model; systemic lupus erythematosus; Deep learning","Elsevier Ltd","00104825","","CBMDA","30195164","Article","Scopus","2-s2.0-85052738184"
"Liu Y.; Qin Z.; Wan T.; Luo Z.","Liu, Yifan (57214948424); Qin, Zengchang (8935532300); Wan, Tao (57201584590); Luo, Zhenbo (56489163400)","57214948424; 8935532300; 57201584590; 56489163400","Auto-painter: Cartoon image generation from sketch by using conditional Wasserstein generative adversarial networks","2018","Neurocomputing","107","10.1016/j.neucom.2018.05.045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048541722&doi=10.1016%2fj.neucom.2018.05.045&partnerID=40&md5=40fac2c9c7e394651641da88dd971334","Intelligent Computing and Machine Learning Lab, School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Department of Biological Science and Medical Engineering, Beijing Advanced Innovation Centre for Biomedical Engineering, Beihang University, China; Samsung Telecommunication Research Institute, Beijing, China","Liu Y., Intelligent Computing and Machine Learning Lab, School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Qin Z., Intelligent Computing and Machine Learning Lab, School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Wan T., Department of Biological Science and Medical Engineering, Beijing Advanced Innovation Centre for Biomedical Engineering, Beihang University, China; Luo Z., Samsung Telecommunication Research Institute, Beijing, China","Recently, realistic image generation using deep neural networks has become a hot topic in machine learning and computer vision. Such an image can be generated at pixel level by learning from a large collection of images. Learning to generate colorful cartoon images from black-and-white sketches is not only an interesting research problem, but also a useful application in digital entertainment. In this paper, we investigate the sketch-to-image synthesis problem by using conditional generative adversarial networks (cGAN). We propose a model called auto-painter which can automatically generate compatible colors given a sketch. Wasserstein distance is used in training cGAN to overcome model collapse and enable the model converged much better. The new model is not only capable of painting hand-draw sketch with compatible colors, but also allowing users to indicate preferred colors. Experimental results on different sketch datasets show that the auto-painter performs better than other existing image-to-image methods. © 2018 Elsevier B.V.","Auto-painter; Deep learning; GAN; Neural networks; Wasserstein distance; WGAN","Color; Deep learning; Deep neural networks; Neural networks; Adversarial networks; Auto-painter; Digital entertainment; Image synthesis; Realistic images; Research problems; Wasserstein distance; WGAN; algorithm; art; Article; artificial neural network; auto painter; conditional Wasserstein generative adversarial network; controlled study; image analysis; image quality; image synthesis; limit of quantitation; machine learning; measurement accuracy; priority journal; supervised machine learning; Drawing (graphics)","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85048541722"
"Lückehe D.; von Voigt G.","Lückehe, Daniel (56313421300); von Voigt, Gabriele (8899065500)","56313421300; 8899065500","Evolutionary image simplification for lung nodule classification with convolutional neural networks","2018","International Journal of Computer Assisted Radiology and Surgery","7","10.1007/s11548-018-1794-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047667069&doi=10.1007%2fs11548-018-1794-7&partnerID=40&md5=766759fdb8144b554d97a792d1362c09","Computational Health Informatics, Leibniz University Hanover, Schloßwender Str. 5, Hanover, 30159, Germany","Lückehe D., Computational Health Informatics, Leibniz University Hanover, Schloßwender Str. 5, Hanover, 30159, Germany; von Voigt G., Computational Health Informatics, Leibniz University Hanover, Schloßwender Str. 5, Hanover, 30159, Germany","Purpose: Understanding decisions of deep learning techniques is important. Especially in the medical field, the reasons for a decision in a classification task are as crucial as the pure classification results. In this article, we propose a new approach to compute relevant parts of a medical image. Knowing the relevant parts makes it easier to understand decisions. Methods: In our approach, a convolutional neural network is employed to learn structures of images of lung nodules. Then, an evolutionary algorithm is applied to compute a simplified version of an unknown image based on the learned structures by the convolutional neural network. In the simplified version, irrelevant parts are removed from the original image. Results: In the results, we show simplified images which allow the observer to focus on the relevant parts. In these images, more than 50% of the pixels are simplified. The simplified pixels do not change the meaning of the images based on the learned structures by the convolutional neural network. An experimental analysis shows the potential of the approach. Besides the examples of simplified images, we analyze the run time development. Conclusions: Simplified images make it easier to focus on relevant parts and to find reasons for a decision. The combination of an evolutionary algorithm employing a learned convolutional neural network is well suited for the simplification task. From a research perspective, it is interesting which areas of the images are simplified and which parts are taken as relevant. © 2018, CARS.","Convolutional neural networks; Evolutionary algorithm; Image simplification; Understanding deep learning","Algorithms; Automatic Data Processing; Decision Making; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Lung; Lung Neoplasms; Machine Learning; Neural Networks (Computer); Software; Solitary Pulmonary Nodule; Article; artificial neural network; convolutional neural network; disease classification; evolutionary algorithm; learning; lung nodule; priority journal; algorithm; computer assisted diagnosis; decision making; diagnostic imaging; human; image processing; information processing; lung; lung nodule; lung tumor; machine learning; software","Springer Verlag","18616410","","","29845453","Article","Scopus","2-s2.0-85047667069"
"Liang C.; Li H.; Lei M.; Du Q.","Liang, Chen (57208711708); Li, Hongqing (58431685300); Lei, Mingjun (57204071424); Du, Qingyun (55631817500)","57208711708; 58431685300; 57204071424; 55631817500","Dongting Lake water level forecast and its relationship with the Three Gorges Dam based on a long short-term memory network","2018","Water (Switzerland)","88","10.3390/w10101389","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054396338&doi=10.3390%2fw10101389&partnerID=40&md5=74ccff10f5202b14a13f8c62f6fd20c6","School of Resource and Environmental Science, Wuhan University, 129 Luoyu Road, Wuhan, 430079, China; Changjiang Water Resources Protection Institute, Wuhan, 430010, China; Yangtze River Water Resources Protection Bureau, Wuhan, 430010, China; Key Laboratory of Geographic Information System, Ministry of Education, Wuhan University, 129 Luoyu Road, Wuhan, 430079, China; Key Laboratory of Digital Mapping and Land Information Application Engineering, National Administration of Surveying, Mapping and Geo-information, Wuhan University, 129 Luoyu Road, Wuhan, 430079, China","Liang C., School of Resource and Environmental Science, Wuhan University, 129 Luoyu Road, Wuhan, 430079, China; Li H., Changjiang Water Resources Protection Institute, Wuhan, 430010, China; Lei M., Yangtze River Water Resources Protection Bureau, Wuhan, 430010, China; Du Q., School of Resource and Environmental Science, Wuhan University, 129 Luoyu Road, Wuhan, 430079, China, Key Laboratory of Geographic Information System, Ministry of Education, Wuhan University, 129 Luoyu Road, Wuhan, 430079, China, Key Laboratory of Digital Mapping and Land Information Application Engineering, National Administration of Surveying, Mapping and Geo-information, Wuhan University, 129 Luoyu Road, Wuhan, 430079, China","To study the Dongting Lake water level variation and its relationship with the upstream Three Gorges Dam (TGD), a deep learning method based on a Long Short-Term Memory (LSTM) network is used to establish a model that predicts the daily water levels of Dongting Lake. Seven factors are used as the input for the LSTM model and eight years of daily data (from 2003 to 2012) are used to train the model. Then, the model is applied to the test dataset (from 2011 to 2013) for forecasting and is evaluated using the root mean squared error (RMSE) and the coefficient of determination (R2). The test shows the LSTM model has better accuracy compared to the support vector machine (SVM) model. Furthermore, the model is adjusted to simulate the situation where the TGD does not exist to explore the dam's impact. The experiment shows that the water level of Dongting Lake drops conspicuously every year from September to November during the TGD impounding period, and the water level increases mildly during dry seasons due to TGD replenishment. Additionally, the impact of the TGD results in a water level decline in Dongting Lake during flood peaks and a subsequent lagged rise. This research provides a tool for flood forecasting and offers a reference for TGD water regulation. © 2018 by the authors.","Deep learning; Dongting Lake; LSTM network; The Three Gorges Dam; Water level forecast","","MDPI AG","20734441","","","","Article","Scopus","2-s2.0-85054396338"
"Faust O.; Shenfield A.; Kareem M.; San T.R.; Fujita H.; Acharya U.R.","Faust, Oliver (14830975900); Shenfield, Alex (8907736400); Kareem, Murtadha (57202962443); San, Tan Ru (57202954732); Fujita, Hamido (35611951900); Acharya, U. Rajendra (7004510847)","14830975900; 8907736400; 57202962443; 57202954732; 35611951900; 7004510847","Automated detection of atrial fibrillation using long short-term memory network with RR interval signals","2018","Computers in Biology and Medicine","223","10.1016/j.compbiomed.2018.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049985774&doi=10.1016%2fj.compbiomed.2018.07.001&partnerID=40&md5=b61bf3b6f3a98985ed68375295b00af3","Department of Engineering and Mathematics, Sheffield Hallam University, United Kingdom; National Heart Centre Singapore, Singapore; Fac. of Software and Information Science, Iwate Prefectural University, Iwate, Japan; Department of Electronic & Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, SUSS, Singapore; School of Medicine, Faculty of Health and Medical Sciences, Taylors University, Subang Jaya, 47500, Malaysia","Faust O., Department of Engineering and Mathematics, Sheffield Hallam University, United Kingdom; Shenfield A., Department of Engineering and Mathematics, Sheffield Hallam University, United Kingdom; Kareem M., Department of Engineering and Mathematics, Sheffield Hallam University, United Kingdom; San T.R., National Heart Centre Singapore, Singapore; Fujita H., Fac. of Software and Information Science, Iwate Prefectural University, Iwate, Japan; Acharya U.R., Department of Electronic & Computer Engineering, Ngee Ann Polytechnic, Singapore, Department of Biomedical Engineering, School of Science and Technology, SUSS, Singapore, School of Medicine, Faculty of Health and Medical Sciences, Taylors University, Subang Jaya, 47500, Malaysia","Atrial Fibrillation (AF), either permanent or intermittent (paroxysnal AF), increases the risk of cardioembolic stroke. Accurate diagnosis of AF is obligatory for initiation of effective treatment to prevent stroke. Long term cardiac monitoring improves the likelihood of diagnosing paroxysmal AF. We used a deep learning system to detect AF beats in Heart Rate (HR) signals. The data was partitioned with a sliding window of 100 beats. The resulting signal blocks were directly fed into a deep Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM). The system was validated and tested with data from the MIT-BIH Atrial Fibrillation Database. It achieved 98.51% accuracy with 10-fold cross-validation (20 subjects) and 99.77% with blindfold validation (3 subjects). The proposed system structure is straight forward, because there is no need for information reduction through feature extraction. All the complexity resides in the deep learning system, which gets the entire information from a signal block. This setup leads to the robust performance for unknown data, as measured with the blind fold validation. The proposed Computer-Aided Diagnosis (CAD) system can be used for long-term monitoring of the human heart. To the best of our knowledge, the proposed system is the first to incorporate deep learning for AF beat detection. © 2018 Elsevier Ltd","Atrial fibrillation; Deep learning; Heart rate; Recurrent neural network","Algorithms; Atrial Fibrillation; Data Collection; Databases, Factual; Deep Learning; Diagnosis, Computer-Assisted; Electrocardiography; Electronic Data Processing; Heart Rate; Humans; Monitoring, Physiologic; Neural Networks (Computer); Reproducibility of Results; Risk; Sensitivity and Specificity; Signal Processing, Computer-Assisted; Software; Support Vector Machine; Brain; Computer aided diagnosis; Deep learning; Diseases; Heart; Recurrent neural networks; 10-fold cross-validation; Atrial fibrillation; Computer Aided Diagnosis(CAD); Heart rates; Information reduction; Long term monitoring; R-r interval signals; Recurrent neural network (RNN); accuracy; Article; artificial neural network; atrial fibrillation; automation; cardioembolic stroke; clinical article; computer assisted diagnosis; electrocardiogram; heart rate; human; learning algorithm; monitoring; paroxysmal atrial fibrillation; priority journal; RR interval; signal processing; algorithm; artificial neural network; atrial fibrillation; electrocardiography; factual database; information processing; physiologic monitoring; procedures; reproducibility; risk; sensitivity and specificity; software; support vector machine; Long short-term memory","Elsevier Ltd","00104825","","CBMDA","30031535","Article","Scopus","2-s2.0-85049985774"
"Russo D.P.; Zorn K.M.; Clark A.M.; Zhu H.; Ekins S.","Russo, Daniel P. (57188754026); Zorn, Kimberley M. (57201902863); Clark, Alex M. (55732793400); Zhu, Hao (7404664097); Ekins, Sean (57203197233)","57188754026; 57201902863; 55732793400; 7404664097; 57203197233","Comparing Multiple Machine Learning Algorithms and Metrics for Estrogen Receptor Binding Prediction","2018","Molecular Pharmaceutics","109","10.1021/acs.molpharmaceut.8b00546","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052320338&doi=10.1021%2facs.molpharmaceut.8b00546&partnerID=40&md5=72503bb6a60d90bad56296eb14241cc4","Collaborations Pharmaceuticals, Inc., 840 Main Campus Drive, Raleigh, 27606, NC, United States; Rutgers Center for Computational and Integrative Biology, Camden, 08102, NJ, United States; Molecular Materials Informatics, Inc., Montreal, H3J 2S1, QC, Canada","Russo D.P., Collaborations Pharmaceuticals, Inc., 840 Main Campus Drive, Raleigh, 27606, NC, United States, Rutgers Center for Computational and Integrative Biology, Camden, 08102, NJ, United States; Zorn K.M., Collaborations Pharmaceuticals, Inc., 840 Main Campus Drive, Raleigh, 27606, NC, United States; Clark A.M., Molecular Materials Informatics, Inc., Montreal, H3J 2S1, QC, Canada; Zhu H., Rutgers Center for Computational and Integrative Biology, Camden, 08102, NJ, United States; Ekins S., Collaborations Pharmaceuticals, Inc., 840 Main Campus Drive, Raleigh, 27606, NC, United States","Many chemicals that disrupt endocrine function have been linked to a variety of adverse biological outcomes. However, screening for endocrine disruption using in vitro or in vivo approaches is costly and time-consuming. Computational methods, e.g., quantitative structure-activity relationship models, have become more reliable due to bigger training sets, increased computing power, and advanced machine learning algorithms, such as multilayered artificial neural networks. Machine learning models can be used to predict compounds for endocrine disrupting capabilities, such as binding to the estrogen receptor (ER), and allow for prioritization and further testing. In this work, an exhaustive comparison of multiple machine learning algorithms, chemical spaces, and evaluation metrics for ER binding was performed on public data sets curated using in-house cheminformatics software (Assay Central). Chemical features utilized in modeling consisted of binary fingerprints (ECFP6, FCFP6, ToxPrint, or MACCS keys) and continuous molecular descriptors from RDKit. Each feature set was subjected to classic machine learning algorithms (Bernoulli Naive Bayes, AdaBoost Decision Tree, Random Forest, Support Vector Machine) and Deep Neural Networks (DNN). Models were evaluated using a variety of metrics: recall, precision, F1-score, accuracy, area under the receiver operating characteristic curve, Cohen's Kappa, and Matthews correlation coefficient. For predicting compounds within the training set, DNN has an accuracy higher than that of other methods; however, in 5-fold cross validation and external test set predictions, DNN and most classic machine learning models perform similarly regardless of the data set or molecular descriptors used. We have also used the rank normalized scores as a performance-criteria for each machine learning method, and Random Forest performed best on the validation set when ranked by metric or by data sets. These results suggest classic machine learning algorithms may be sufficient to develop high quality predictive models of ER activity. © Copyright 2018 American Chemical Society.","Bayesian; deep learning; estrogen receptor; machine learning; support vector machine","Algorithms; Animals; Bayes Theorem; Humans; Machine Learning; Protein Binding; Receptors, Estrogen; Software; Support Vector Machine; estrogen receptor; estrogen receptor; protein binding; Article; artificial neural network; Bayesian learning; decision tree; hydrogen bond; machine learning; priority journal; protein binding; random forest; software; support vector machine; algorithm; animal; Bayes theorem; human; metabolism","American Chemical Society","15438384","","MPOHB","30114914","Article","Scopus","2-s2.0-85052320338"
"Zhao T.; Ruan D.","Zhao, Tingting (56662650500); Ruan, Dan (35265014200)","56662650500; 35265014200","A 2.5D assembly framework to segment high-dimensionality medical images by Bayesian aggregation of parallel 2D CNNs","2018","Biomedical Physics and Engineering Express","2","10.1088/2057-1976/aad29f","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056466704&doi=10.1088%2f2057-1976%2faad29f&partnerID=40&md5=335f7c3a6a686368fff8f5c82e2a9be6","Department of Radiation Oncology, University of California, Los Angeles, 90095, CA, United States","Zhao T., Department of Radiation Oncology, University of California, Los Angeles, 90095, CA, United States; Ruan D., Department of Radiation Oncology, University of California, Los Angeles, 90095, CA, United States","Deep learning neural networks have been widely used in general 2D image processing tasks. However, its application to process high-dimensional medical images is impeded by the need to tailor the network for specific considerations on imaging systems and/or biological characteristics, and the high memory/computation cost as the image dimensionality increases. This study aims to design an assembly 2.5D image segmentation framework based on native 2D convolutional neural network (CNN), which is naturally adaptable to problem dimensionality changes in an economical way and intrinsically amicable to parallel processing. In particular, we perform soft segmentation along each 2D fiber using one native 2D CNN, aggregate such decisions based on Bayesian rule, and apply an (optional) polish step to geometrically regularize the raw segmentation. Validation experiments on volumetric CT liver segmentation demonstrate higher segmentation accuracy with pronounced cost-saving benefit, compared to the state-of-the-art 3D CNN and triplanar approaches. © 2018 IOP Publishing Ltd.","Bayesian aggregation; convolutional neural network; image segmentation","Article; Bayes theorem; comparative study; cone beam computed tomography; convolutional neural network; cost control; diagnostic accuracy; diagnostic imaging; image processing; image segmentation; machine learning; two-dimensional imaging; validation process; wavelet transformation","Institute of Physics Publishing","20571976","","","","Article","Scopus","2-s2.0-85056466704"
"Hop P.; Allgood B.; Yu J.","Hop, Patrick (57202381544); Allgood, Brandon (57223430727); Yu, Jessen (57202386956)","57202381544; 57223430727; 57202386956","Geometric Deep Learning Autonomously Learns Chemical Features That Outperform Those Engineered by Domain Experts","2018","Molecular Pharmaceutics","35","10.1021/acs.molpharmaceut.7b01144","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048072605&doi=10.1021%2facs.molpharmaceut.7b01144&partnerID=40&md5=ea5821337bce2c0aad2237b4f2a3866e","Numerate Inc., San Francisco, 94107, CA, United States","Hop P., Numerate Inc., San Francisco, 94107, CA, United States; Allgood B., Numerate Inc., San Francisco, 94107, CA, United States; Yu J., Numerate Inc., San Francisco, 94107, CA, United States","Artificial Intelligence has advanced at an unprecedented pace, backing recent breakthroughs in natural language processing, speech recognition, and computer vision: domains where the data is euclidean in nature. More recently, considerable progress has been made in engineering deep-learning architectures that can accept non-Euclidean data such as graphs and manifolds: geometric deep learning. This progress is of considerable interest to the drug discovery community, as molecules can naturally be represented as graphs, where atoms are nodes and bonds are edges. In this work, we explore the performance of geometric deep-learning methods in the context of drug discovery, comparing machine learned features against the domain expert engineered features that are mainstream in the pharmaceutical industry. © 2018 American Chemical Society.","artifical intelligence; drug discovery; geometric deep learning; pharmaceutics","Algorithms; Artificial Intelligence; Deep Learning; Drug Discovery; Machine Learning; Neural Networks (Computer); Article; artificial intelligence; drug design; drug industry; embedding; learning algorithm; machine learning; natural language processing; priority journal; random forest; algorithm; artificial intelligence; artificial neural network; drug development","American Chemical Society","15438384","","MPOHB","29863875","Article","Scopus","2-s2.0-85048072605"
"Kim H.; Lee S.-B.; Son Y.; Czosnyka M.; Kim D.-J.","Kim, Hakseung (55696991300); Lee, Seung-Bo (58847807500); Son, Yunsik (52364782100); Czosnyka, Marek (8054670300); Kim, Dong-Joo (55742896600)","55696991300; 58847807500; 52364782100; 8054670300; 55742896600","Hemodynamic Instability and Cardiovascular Events after Traumatic Brain Injury Predict Outcome after Artifact Removal with Deep Belief Network Analysis","2018","Journal of Neurosurgical Anesthesiology","9","10.1097/ANA.0000000000000462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048769981&doi=10.1097%2fANA.0000000000000462&partnerID=40&md5=68d798e67d5ca848fbf94a80ffc3cb1b","Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 02841, South Korea; Department of Computer Engineering, Dongguk University, Seoul, South Korea; Department of Clinical Neurosciences, Division of Neurosurgery, University of Cambridge, Cambridge, United Kingdom","Kim H., Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 02841, South Korea; Lee S.-B., Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 02841, South Korea; Son Y., Department of Computer Engineering, Dongguk University, Seoul, South Korea; Czosnyka M., Department of Clinical Neurosciences, Division of Neurosurgery, University of Cambridge, Cambridge, United Kingdom; Kim D.-J., Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 02841, South Korea","Background: Hemodynamic instability and cardiovascular events heavily affect the prognosis of traumatic brain injury. Physiological signals are monitored to detect these events. However, the signals are often riddled with faulty readings, which jeopardize the reliability of the clinical parameters obtained from the signals. A machine-learning model for the elimination of artifactual events shows promising results for improving signal quality. However, the actual impact of the improvements on the performance of the clinical parameters after the elimination of the artifacts is not well studied. Materials and Methods: The arterial blood pressure of 99 subjects with traumatic brain injury was continuously measured for 5 consecutive days, beginning on the day of admission. The machine-learning deep belief network was constructed to automatically identify and remove false incidences of hypotension, hypertension, bradycardia, tachycardia, and alterations in cerebral perfusion pressure (CPP). Results: The prevalences of hypotension and tachycardia were significantly reduced by 47.5% and 13.1%, respectively, after suppressing false incidents (P=0.01). Hypotension was particularly effective at predicting outcome favorability and mortality after artifact elimination (P=0.015 and 0.027, respectively). In addition, increased CPP was also statistically significant in predicting outcomes (P=0.02). Conclusions: The prevalence of false incidents due to signal artifacts can be significantly reduced using machine-learning. Some clinical events, such as hypotension and alterations in CPP, gain particularly high predictive capacity for patient outcomes after artifacts are eliminated from physiological signals. © 2017 Wolters Kluwer Health, Inc. All rights reserved.","arterial pressure; brain injuries; computer-assisted; machine-learning; signal processing; traumatic","Adolescent; Adult; Aged; Artifacts; Brain Injuries, Traumatic; Cardiovascular Diseases; Cerebrovascular Circulation; False Positive Reactions; Female; Hemodynamics; Humans; Intracranial Hypotension; Machine Learning; Male; Middle Aged; Predictive Value of Tests; Prevalence; Tachycardia; Young Adult; dopamine; mannitol; noradrenalin; adolescent; adult; aged; arterial pressure; Article; artifact; bradycardia; brain perfusion; cardiovascular disease; Glasgow outcome scale; heart hemodynamics; human; hypertension; hyperventilation; hypotension; machine learning; major clinical study; middle aged; mortality; outcome assessment; priority journal; systolic blood pressure; tachycardia; traumatic brain injury; young adult; brain circulation; cardiovascular disease; complication; false positive result; female; hemodynamics; intracranial hypotension; machine learning; male; pathophysiology; predictive value; prevalence; tachycardia; traumatic brain injury","Lippincott Williams and Wilkins","08984921","","JNANE","28991060","Article","Scopus","2-s2.0-85048769981"
"Wang P.; Xiao X.; Glissen Brown J.R.; Berzin T.M.; Tu M.; Xiong F.; Hu X.; Liu P.; Song Y.; Zhang D.; Yang X.; Li L.; He J.; Yi X.; Liu J.; Liu X.","Wang, Pu (57204137962); Xiao, Xiao (57204138969); Glissen Brown, Jeremy R. (57190855621); Berzin, Tyler M. (35760130200); Tu, Mengtian (57204142790); Xiong, Fei (56205761700); Hu, Xiao (56658086000); Liu, Peixi (57207222059); Song, Yan (56658104000); Zhang, Di (57207712171); Yang, Xue (57544184400); Li, Liangping (56416815700); He, Jiong (57204148350); Yi, Xin (57204142014); Liu, Jingjia (57204142090); Liu, Xiaogang (57203493440)","57204137962; 57204138969; 57190855621; 35760130200; 57204142790; 56205761700; 56658086000; 57207222059; 56658104000; 57207712171; 57544184400; 56416815700; 57204148350; 57204142014; 57204142090; 57203493440","Development and validation of a deep-learning algorithm for the detection of polyps during colonoscopy","2018","Nature Biomedical Engineering","342","10.1038/s41551-018-0301-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054667648&doi=10.1038%2fs41551-018-0301-3&partnerID=40&md5=05a61aec26212e4e3ae88a6f503595d7","Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; Shanghai Wision AI Co., Ltd, Shanghai, China; Beth Israel Deaconess Medical Center and Harvard Medical School, Center for Advanced Endoscopy, Boston, MA, United States","Wang P., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; Xiao X., Shanghai Wision AI Co., Ltd, Shanghai, China; Glissen Brown J.R., Beth Israel Deaconess Medical Center and Harvard Medical School, Center for Advanced Endoscopy, Boston, MA, United States; Berzin T.M., Beth Israel Deaconess Medical Center and Harvard Medical School, Center for Advanced Endoscopy, Boston, MA, United States; Tu M., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; Xiong F., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; Hu X., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; Liu P., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; Song Y., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; Zhang D., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; Yang X., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; Li L., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China; He J., Shanghai Wision AI Co., Ltd, Shanghai, China; Yi X., Shanghai Wision AI Co., Ltd, Shanghai, China; Liu J., Shanghai Wision AI Co., Ltd, Shanghai, China; Liu X., Sichuan Academy of Medical Sciences & Sichuan Provincial People’s Hospital, Chengdu, China","The detection and removal of precancerous polyps via colonoscopy is the gold standard for the prevention of colon cancer. However, the detection rate of adenomatous polyps can vary significantly among endoscopists. Here, we show that a machine-learning algorithm can detect polyps in clinical colonoscopies, in real time and with high sensitivity and specificity. We developed the deep-learning algorithm by using data from 1,290 patients, and validated it on newly collected 27,113 colonoscopy images from 1,138 patients with at least one detected polyp (per-image-sensitivity, 94.38%; per-image-specificity, 95.92%; area under the receiver operating characteristic curve, 0.984), on a public database of 612 polyp-containing images (per-image-sensitivity, 88.24%), on 138 colonoscopy videos with histologically confirmed polyps (per-image-sensitivity of 91.64%; per-polyp-sensitivity, 100%), and on 54 unaltered full-range colonoscopy videos without polyps (per-image-specificity, 95.40%). By using a multi-threaded processing system, the algorithm can process at least 25 frames per second with a latency of 76.80 ± 5.60 ms in real-time video analysis. The software may aid endoscopists while performing colonoscopies, and help assess differences in polyp and adenoma detection performance among endoscopists. © 2018, The Author(s), under exclusive licence to Springer Nature Limited.","","Algorithms; Area Under Curve; Colonic Neoplasms; Colonic Polyps; Colonoscopy; Databases, Factual; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Precancerous Conditions; ROC Curve; Software; Deep learning; Endoscopy; Detection performance; Detection rates; Frames per seconds; High sensitivity; Image sensitivity; Processing systems; Real-time video analysis; Receiver operating characteristic curves; adult; algorithm; Article; colon polyp; colonoscopy; deep learning algorithm; disease surveillance; false positive result; female; human; image analysis; latent period; major clinical study; male; sensitivity and specificity; validation study; area under the curve; colon polyp; colon tumor; colonoscopy; computer assisted diagnosis; factual database; pathology; precancer; procedures; receiver operating characteristic; software; Learning algorithms","Nature Publishing Group","2157846X","","","31015647","Article","Scopus","2-s2.0-85054667648"
"Goudarzi S.; Kama M.N.; Anisi M.H.; Soleymani S.A.; Doctor F.","Goudarzi, Shidrokh (55874697000); Kama, Mohd Nazri (57216753681); Anisi, Mohammad Hossein (24469576200); Soleymani, Seyed Ahmad (55875827500); Doctor, Faiyaz (8282157700)","55874697000; 57216753681; 24469576200; 55875827500; 8282157700","Self-organizing traffic flow prediction with an optimized deep belief network for internet of vehicles","2018","Sensors (Switzerland)","39","10.3390/s18103459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055076535&doi=10.3390%2fs18103459&partnerID=40&md5=3568a9feff11c55f21ce0e5e992dfbaa","Advanced Informatics School, Universiti Teknologi Malaysia Kuala Lumpur (UTM), Jalan Semarak, Kuala Lumpur, 54100, Malaysia; School of Computer Science and Electronic Engineering, University of Essex, Colchester, CO4 3SQ, United Kingdom; Faculty of Computing, Universiti Teknologi Malaysia Kuala Lumpur (UTM), Skudai, 81310, Johor, Malaysia","Goudarzi S., Advanced Informatics School, Universiti Teknologi Malaysia Kuala Lumpur (UTM), Jalan Semarak, Kuala Lumpur, 54100, Malaysia; Kama M.N., Advanced Informatics School, Universiti Teknologi Malaysia Kuala Lumpur (UTM), Jalan Semarak, Kuala Lumpur, 54100, Malaysia; Anisi M.H., School of Computer Science and Electronic Engineering, University of Essex, Colchester, CO4 3SQ, United Kingdom; Soleymani S.A., Faculty of Computing, Universiti Teknologi Malaysia Kuala Lumpur (UTM), Skudai, 81310, Johor, Malaysia; Doctor F., School of Computer Science and Electronic Engineering, University of Essex, Colchester, CO4 3SQ, United Kingdom","To assist in the broadcasting of time-critical traffic information in an Internet of Vehicles (IoV) and vehicular sensor networks (VSN), fast network connectivity is needed. Accurate traffic information prediction can improve traffic congestion and operation efficiency, which helps to reduce commute times, noise and carbon emissions. In this study, we present a novel approach for predicting the traffic flow volume by using traffic data in self-organizing vehicular networks. The proposed method is based on using a probabilistic generative neural network techniques called deep belief network (DBN) that includes multiple layers of restricted Boltzmann machine (RBM) auto-encoders. Time series data generated from the roadside units (RSUs) for five highway links are used by a three layer DBN to extract and learn key input features for constructing a model to predict traffic flow. Back-propagation is utilized as a general learning algorithm for fine-tuning the weight parameters among the visible and hidden layers of RBMs. During the training process the firefly algorithm (FFA) is applied for optimizing the DBN topology and learning rate parameter. Monte Carlo simulations are used to assess the accuracy of the prediction model. The results show that the proposed model achieves superior performance accuracy for predicting traffic flow in comparison with other approaches applied in the literature. The proposed approach can help to solve the problem of traffic congestion, and provide guidance and advice for road users and traffic regulators. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep belief network; Historical time traffic flows; Optimization; Restricted boltzmann machine; Traffic flow prediction","Air navigation; Backpropagation algorithms; Deep learning; Forecasting; Intelligent systems; Learning algorithms; Monte Carlo methods; Motor transportation; Optimization; Parameter estimation; Pollution control; Sensor networks; Street traffic control; Deep belief network (DBN); Deep belief networks; Neural network techniques; Operation efficiencies; Restricted boltzmann machine; Traffic flow; Traffic flow prediction; Vehicular sensor network; Traffic congestion","MDPI AG","14248220","","","30326567","Article","Scopus","2-s2.0-85055076535"
"Bai S.; An S.","Bai, Shuang (55065362000); An, Shan (57202495145)","55065362000; 57202495145","A survey on automatic image caption generation","2018","Neurocomputing","155","10.1016/j.neucom.2018.05.080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048571947&doi=10.1016%2fj.neucom.2018.05.080&partnerID=40&md5=392912fbedc35cb9de5e2e66a06faeb7","School of Electronic and Information Engineering, Beijing Jiaotong University, No.3 Shang Yuan Cun, Hai Dian District, Beijing, China; Beijing Jingdong Shangke Information Technology Co., Ltd, Beijing, China","Bai S., School of Electronic and Information Engineering, Beijing Jiaotong University, No.3 Shang Yuan Cun, Hai Dian District, Beijing, China; An S., Beijing Jingdong Shangke Information Technology Co., Ltd, Beijing, China","Image captioning means automatically generating a caption for an image. As a recently emerged research area, it is attracting more and more attention. To achieve the goal of image captioning, semantic information of images needs to be captured and expressed in natural languages. Connecting both research communities of computer vision and natural language processing, image captioning is a quite challenging task. Various approaches have been proposed to solve this problem. In this paper, we present a survey on advances in image captioning research. Based on the technique adopted, we classify image captioning approaches into different categories. Representative methods in each category are summarized, and their strengths and limitations are talked about. In this paper, we first discuss methods used in early work which are mainly retrieval and template based. Then, we focus our main attention on neural network based methods, which give state of the art results. Neural network based methods are further divided into subcategories based on the specific framework they use. Each subcategory of neural network based methods are discussed in detail. After that, state of the art methods are compared on benchmark datasets. Following that, discussions on future research directions are presented. © 2018","Attention mechanism; Deep neural networks; Encoder–decoder framework; Image captioning; Multimodal embedding; Sentence template","Natural language processing systems; Semantics; Surveys; Attention mechanisms; Future research directions; Image captioning; Multi-modal; Research communities; Semantic information; Sentence template; State-of-the-art methods; Article; artificial neural network; automation; benchmarking; controlled study; deep neural network; image captioning; image processing; imaging and display; machine learning; multimodal learning; natural language processing; priority journal; selective attention; semantics; signal noise ratio; software; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85048571947"
"Ibragimov B.; Toesca D.; Chang D.; Yuan Y.; Koong A.; Xing L.","Ibragimov, Bulat (40761505000); Toesca, Diego (57192543024); Chang, Daniel (9943395500); Yuan, Yixuan (55932867600); Koong, Albert (6701338558); Xing, Lei (7103349003)","40761505000; 57192543024; 9943395500; 55932867600; 6701338558; 7103349003","Development of deep neural network for individualized hepatobiliary toxicity prediction after liver SBRT","2018","Medical Physics","97","10.1002/mp.13122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053511609&doi=10.1002%2fmp.13122&partnerID=40&md5=9ff782cc7e2d9c80b43aace743279760","Department of Radiation Oncology, Stanford University School of Medicine, Stanford, CA, United States; Department of Electronic Engineering, City University of Hong Kong, Hong Kong; Department of Radiation Oncology, MD Anderson Cancer Center, Houston, TX, United States","Ibragimov B., Department of Radiation Oncology, Stanford University School of Medicine, Stanford, CA, United States; Toesca D., Department of Radiation Oncology, Stanford University School of Medicine, Stanford, CA, United States; Chang D., Department of Radiation Oncology, Stanford University School of Medicine, Stanford, CA, United States; Yuan Y., Department of Electronic Engineering, City University of Hong Kong, Hong Kong; Koong A., Department of Radiation Oncology, MD Anderson Cancer Center, Houston, TX, United States; Xing L., Department of Radiation Oncology, Stanford University School of Medicine, Stanford, CA, United States","Background: Accurate prediction of radiation toxicity of healthy organs-at-risks (OARs) critically determines the radiation therapy (RT) success. The existing dose–volume histogram-based metric may grossly under/overestimate the therapeutic toxicity after 27% in liver RT and 50% in head-and-neck RT. We propose the novel paradigm for toxicity prediction by leveraging the enormous potential of deep learning and go beyond the existing dose/volume histograms. Experimental Design: We employed a database of 125 liver stereotactic body RT (SBRT) cases with follow-up data to train deep learning-based toxicity predictor. Convolutional neural networks (CNNs) were applied to discover the consistent patterns in 3D dose plans associated with toxicities. To enhance the predicting power, we first pretrain the CNNs with transfer learning from 3D CT images of 2644 human organs. CNNs were then trained on liver SBRT cases. Furthermore, nondosimetric pretreatment features, such as patients’ demographics, underlying liver diseases, liver-directed therapies, were inputted into the fully connected neural network for more comprehensive prediction. The saliency maps of CNNs were used to estimate the toxicity risks associated with irradiation of anatomical regions of specific OARs. In addition, we applied machine learning solutions to map numerical pretreatment features with hepatobiliary toxicity manifestation. Results: Among 125 liver SBRT patients, 58 were treated for liver metastases, 36 for hepatocellular carcinoma, 27 for cholangiocarcinoma, and 4 for other histologies. We observed that CNN we able to achieve accurate hepatobiliary toxicity prediction with the AUC of 0.79, whereas combining CNN for 3D dose plan analysis and fully connected neural networks for numerical feature analysis resulted in AUC of 0.85. Deep learning produces almost two times fewer false-positive toxicity predictions in comparison to DVH-based predictions, when the number of false negatives, i.e., missed toxicities, was minimized. The CNN saliency maps automatically estimated the toxicity risks for portal vein (PV) regions. We discovered that irradiation of the proximal portal vein is associated with two times higher toxicity risks (risk score: 0.66) that irradiation of the left portal vein (risk score: 0.31). Conclusions: The framework offers clinically accurate tools for hepatobiliary toxicity prediction and automatic identification of anatomical regions that are critical to spare during SBRT. © 2018 American Association of Physicists in Medicine","convolutional neural networks; liver cancer; SBRT; toxicity prediction","Biliary Tract; Humans; Liver; Neural Networks (Computer); Organs at Risk; Precision Medicine; Radiosurgery; Radiotherapy Dosage; Radiotherapy Planning, Computer-Assisted; Risk; Treatment Failure; Automation; Computerized tomography; Convolution; Deep neural networks; Diseases; Forecasting; Graphic methods; Image enhancement; Image segmentation; Irradiation; Radiation; Radiotherapy; Risk perception; Convolutional neural network; Dose-volume histograms; Fully connected neural network; Hepatobiliary; Liver cancers; Organs at risks; Portal veins; Pre-treatments; Stereotactic body RT; Toxicity predictions; accuracy; adult; aged; Article; artificial neural network; bile duct carcinoma; computer assisted tomography; false negative result; false positive result; female; hepatic portal vein; hepatobiliary disease; human; liver cell carcinoma; liver metastasis; liver toxicity; machine learning; major clinical study; male; predictive value; radiation hazard; radiotherapy dosage; stereotactic body radiation therapy; three dimensional imaging; treatment planning; hepatobiliary system; liver; organs at risk; personalized medicine; radiation response; radiosurgery; radiotherapy planning system; risk; treatment failure; Toxicity","John Wiley and Sons Ltd","00942405","","MPHYA","30098025","Article","Scopus","2-s2.0-85053511609"
"Wang Y.; Liao Y.; Zhang Y.; He J.; Li S.; Bian Z.; Zhang H.; Gao Y.; Meng D.; Zuo W.; Zeng D.; Ma J.","Wang, Yongbo (57200527856); Liao, Yuting (57200527393); Zhang, Yuanke (36190321000); He, Ji (57190275491); Li, Sui (57202323226); Bian, Zhaoying (36970884200); Zhang, Hao (57052995300); Gao, Yuanyuan (57213345398); Meng, Deyu (23393058400); Zuo, Wangmeng (56888903800); Zeng, Dong (55647508500); Ma, Jianhua (55647757200)","57200527856; 57200527393; 36190321000; 57190275491; 57202323226; 36970884200; 57052995300; 57213345398; 23393058400; 56888903800; 55647508500; 55647757200","Iterative quality enhancement via residual-artifact learning networks for low-dose CT","2018","Physics in Medicine and Biology","36","10.1088/1361-6560/aae511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055188129&doi=10.1088%2f1361-6560%2faae511&partnerID=40&md5=ac6193063dcd800b44aedd3a0ea6c215","School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China; Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China; Department of Biomedical Engineering, Johns Hopkins University, Baltimore, 21205, MD, United States; School of Mathematics, Statistics and Ministry, Education Key Laboratory of Intelligent Networks and Network Security, Xi'An Jiaotong University, Shaanxi, 710049, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150000, China","Wang Y., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China; Liao Y., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China; Zhang Y., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China; He J., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China; Li S., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China; Bian Z., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China; Zhang H., Department of Biomedical Engineering, Johns Hopkins University, Baltimore, 21205, MD, United States; Gao Y., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China; Meng D., School of Mathematics, Statistics and Ministry, Education Key Laboratory of Intelligent Networks and Network Security, Xi'An Jiaotong University, Shaanxi, 710049, China; Zuo W., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150000, China; Zeng D., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China; Ma J., School of Biomedical Engineering, Southern Medical University, Guangzhou, 510515, China, Guangzhou Key Laboratory of Medical Radiation Imaging and Detection Technology, Southern Medical University, Guangdong, 510515, China","Radiation exposure and the associated risk of cancer for patients in computed tomography (CT) scans have been major clinical concerns. The radiation exposure can be reduced effectively via lowering the x-ray tube current (mA). However, this strategy may lead to excessive noise and streak artifacts in the conventional filtered back-projection reconstructed images. To address this issue, some deep convolutional neural network (ConvNet) based approaches have been developed for low-dose CT imaging inspired by the recent development of machine learning. Nevertheless, some of the image textures reconstructed by the ConvNet could be corrupted by the severe streaks, especially in ultra-low-dose cases, which could be close to prostheses and hamper diagnosis. Therefore, in this work, we propose an iterative residual-artifact learning ConvNet (IRLNet) approach to improve the reconstruction performance over the ConvNet based approaches. Specifically, the proposed IRLNet estimates the high-frequency details within the noise and then removes them iteratively; after eliminating severe streaks in the low-dose CT images, the residual low-frequency details can be processed through the conventional network. Moreover, the proposed IRLNet scheme can be extended for robust handling of quantitative dual energy CT/cerebral perfusion CT imaging, and statistical iterative reconstruction. Real patient data are used to evaluate the proposed IRLNet, and the experimental results demonstrate that the proposed IRLNet approach outperforms the previous ConvNet based approaches in reducing the image noise and streak artifacts efficiently at the same time as preserving edge details well, suggesting that the proposed IRLNet approach can be used to improve the CT image quality, especially in ultra-low-dose cases. © 2018 Institute of Physics and Engineering in Medicine.","cerebral perfusion CT; deep learning; dual energy CT; image restoration; low dose CT; statistical image reconstruction","Algorithms; Artifacts; Brain Diseases; Humans; Machine Learning; Neural Networks (Computer); Plaque, Atherosclerotic; Radiation Dosage; Radiation Exposure; Radiographic Image Interpretation, Computer-Assisted; Radionuclide Imaging; Tomography, X-Ray Computed; Deep learning; Deep neural networks; Diagnosis; Hospital data processing; Image enhancement; Image reconstruction; Image texture; Neural networks; X ray tubes; Cerebral perfusion; Computed tomography scan; Deep convolutional neural networks; Dual-energy CT; Filtered back projection; Low-dose CT; Statistical image reconstruction; Statistical iterative reconstruction; algorithm; artifact; artificial neural network; atherosclerotic plaque; brain disease; computer assisted diagnosis; diagnostic imaging; human; machine learning; pathology; procedures; radiation dose; radiation exposure; scintiscanning; x-ray computed tomography; Computerized tomography","Institute of Physics Publishing","00319155","","PHMBA","30265251","Article","Scopus","2-s2.0-85055188129"
"Wang M.; Deng W.","Wang, Mei (57215104088); Deng, Weihong (8905974100)","57215104088; 8905974100","Deep visual domain adaptation: A survey","2018","Neurocomputing","1338","10.1016/j.neucom.2018.05.083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048819256&doi=10.1016%2fj.neucom.2018.05.083&partnerID=40&md5=60aa82367df367aa819019790ea79239","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China","Wang M., School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Deng W., School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China","Deep domain adaptation has emerged as a new learning technique to address the lack of massive amounts of labeled data. Compared to conventional methods, which learn shared feature subspaces or reuse important source instances with shallow representations, deep domain adaptation methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning. There have been comprehensive surveys for shallow domain adaptation, but few timely reviews the emerging deep learning based methods. In this paper, we provide a comprehensive survey of deep domain adaptation methods for computer vision applications with four major contributions. First, we present a taxonomy of different deep domain adaptation scenarios according to the properties of data that define how two domains are diverged. Second, we summarize deep domain adaptation approaches into several categories based on training loss, and analyze and compare briefly the state-of-the-art methods under these categories. Third, we overview the computer vision applications that go beyond image classification, such as face recognition, semantic segmentation and object detection. Fourth, some potential deficiencies of current methods and several future directions are highlighted. © 2018 Elsevier B.V.","Computer vision applications; Deep domain adaptation; Deep networks; Transfer learning","Computer vision; Face recognition; Image segmentation; Object detection; Semantics; Surveys; Computer vision applications; Conventional methods; Deep networks; Domain adaptation; Learning-based methods; Semantic segmentation; State-of-the-art methods; Transfer learning; Article; artificial neural network; deep visual domain adaptation; facial recognition; geometry; image processing; learning algorithm; machine learning; mathematical computing; object relation; priority journal; semantics; taxonomy; vision; visual adaptation; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85048819256"
"Kim D.H.; Wit H.; Thurston M.","Kim, Daniel H. (57005694600); Wit, Huub (57204044901); Thurston, Mark (57204047877)","57005694600; 57204044901; 57204047877","Artificial intelligence in the diagnosis of Parkinson's disease from ioflupane-123 single-photon emission computed tomography dopamine transporter scans using transfer learning","2018","Nuclear Medicine Communications","30","10.1097/MNM.0000000000000890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054239673&doi=10.1097%2fMNM.0000000000000890&partnerID=40&md5=1011df9e81f734ea82d77f9a123c9873","Department of Medical Imaging, Royal Devon and Exeter NHS Trust, Barrack Road, Exeter, EX2 5DW, United Kingdom; Department of Medical Imaging, Plymouth Hospitals NHS Trust, Plymouth, United Kingdom","Kim D.H., Department of Medical Imaging, Royal Devon and Exeter NHS Trust, Barrack Road, Exeter, EX2 5DW, United Kingdom; Wit H., Department of Medical Imaging, Royal Devon and Exeter NHS Trust, Barrack Road, Exeter, EX2 5DW, United Kingdom; Thurston M., Department of Medical Imaging, Plymouth Hospitals NHS Trust, Plymouth, United Kingdom","Objective The objective of this study was to identify the extent to which artificial intelligence could be used in the diagnosis of Parkinson's disease from ioflupane-123 (123 I) single-photon emission computed tomography (SPECT) dopamine transporter scans using transfer learning. Materials and methods A data set of 54 normal and 54 abnormal 123 I SPECT scans was amplified 44-fold using a process of image augmentation. This resulted in a training set of 2376 normal and 2376 abnormal images. This was used to retrain the top layer of the Inception v3 network. The resulting neural network functioned as a classifier for new 123 I SPECT scans as either normal or abnormal. A completely separate set of 45 123 I SPECT scans were used for final testing of the network. Results The area under the receiver-operator curve in final testing was 0.87. This corresponded to a test sensitivity of 96.3%, a specificity of 66.7%, a positive predictive value of 81.3% and a negative predictive value of 92.3%, using an optimum diagnostic threshold. Conclusion This study has provided proof of concept for the use of transfer learning, from convolutional neural networks pretrained on nonmedical images, for the interpretation of 123 I SPECT scans. This has been shown to be possible in this study even with a very small sample size. This technique is likely to be applicable to many areas of diagnostic imaging. Copyright © 2018 Wolters Kluwer Health, Inc. All rights reserved.","artificial intelligence; deep learning; image processing; neural networks; Parkinson's disease; transfer learning","Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Nortropanes; Parkinson Disease; Tomography, Emission-Computed, Single-Photon; dopamine transporter; ioflupane 123; radioisotope; unclassified drug; ioflupane; nortropane derivative; accuracy; Article; artificial intelligence; artificial neural network; human; image analysis; Parkinson disease; predictive value; sensitivity and specificity; single photon emission computed tomography; transfer of learning; diagnostic imaging; image processing; machine learning; metabolism; Parkinson disease; procedures","Lippincott Williams and Wilkins","01433636","","NMCOD","30080748","Article","Scopus","2-s2.0-85054239673"
"Zhang Y.; Wang X.; Hou Z.; Li J.","Zhang, Yu (57200260594); Wang, Xuwen (57203242644); Hou, Zhen (57022859400); Li, Jiao (57397332800)","57200260594; 57203242644; 57022859400; 57397332800","Clinical named entity recognition from chinese electronic health records via machine learning methods","2018","JMIR Medical Informatics","44","10.2196/medinform.9965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071456212&doi=10.2196%2fmedinform.9965&partnerID=40&md5=de1c32de464a6c18c3deb45730dbca9d","Institute of Medical Information and Library, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China","Zhang Y., Institute of Medical Information and Library, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China; Wang X., Institute of Medical Information and Library, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China; Hou Z., Institute of Medical Information and Library, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China; Li J., Institute of Medical Information and Library, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China","Background: Electronic health records (EHRs) are important data resources for clinical studies and applications. Physicians or clinicians describe patients' disorders or treatment procedures in EHRs using free text (unstructured) clinical notes. The narrative information plays an important role in patient treatment and clinical research. However, it is challenging to make machines understand the clinical narratives. Objective: This study aimed to automatically identify Chinese clinical entities from free text in EHRs and make machines semantically understand diagnoses, tests, body parts, symptoms, treatments, and so on. Methods: The dataset we used for this study is the benchmark dataset with human annotated Chinese EHRs, released by the China Conference on Knowledge Graph and Semantic Computing 2017 clinical named entity recognition challenge task. Overall, 2 machine learning models, the conditional random fields (CRF) method and bidirectional long short-term memory (LSTM)-CRF, were applied to recognize clinical entities from Chinese EHR data. To train the CRF-based model, we selected features such as bag of Chinese characters, part-of-speech tags, character types, and the position of characters. For the bidirectional LSTM-CRF-based model, character embeddings and segmentation information were used as features. In addition, we also employed a dictionary-based approach as the baseline for the purpose of performance evaluation. Precision, recall, and the harmonic average of precision and recall (F1 score) were used to evaluate the performance of the methods. Results: Experiments on the test set showed that our methods were able to automatically identify types of Chinese clinical entities such as diagnosis, test, symptom, body part, and treatment simultaneously. With regard to overall performance, CRF and bidirectional LSTM-CRF achieved a precision of 0.9203 and 0.9112, recall of 0.8709 and 0.8974, and F1 score of 0.8949 and 0.9043, respectively. The results also indicated that our methods performed well in recognizing each type of clinical entity, in which the ""symptom"" type achieved the best F1 score of over 0.96. Moreover, as the number of features increased, the F1 score of the CRF model increased from 0.8547 to 0.8949. Conclusions: In this study, we employed two computational methods to simultaneously identify types of Chinese clinical entities from free text in EHRs. With training, these methods can effectively identify various types of clinical entities (eg, symptom and treatment) with high accuracy. The deep learning model, bidirectional LSTM-CRF, can achieve better performance than the CRF model with little feature engineering. This study contributed to translating human-readable health information into machine-readable information. © 2018 JMIR Publications Inc.. All right reserved.","Bidirectional LSTM-CRF; Clinical named entity recognition; Diagnosis; Electronic health records; Human body; Machine learning; Physical examination; Syndrome; Treatment","","JMIR Publications Inc.","22919694","","","","Article","Scopus","2-s2.0-85071456212"
"Wong K.C.L.; Syeda-Mahmood T.; Moradi M.","Wong, Ken C.L. (22936010400); Syeda-Mahmood, Tanveer (7003810087); Moradi, Mehdi (57208604625)","22936010400; 7003810087; 57208604625","Building medical image classifiers with very limited data using segmentation networks","2018","Medical Image Analysis","53","10.1016/j.media.2018.07.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051394285&doi=10.1016%2fj.media.2018.07.010&partnerID=40&md5=87dace4b1feb8db176c72fb27055df9f","IBM Research – Almaden Research Center, San Jose, CA, United States","Wong K.C.L., IBM Research – Almaden Research Center, San Jose, CA, United States; Syeda-Mahmood T., IBM Research – Almaden Research Center, San Jose, CA, United States; Moradi M., IBM Research – Almaden Research Center, San Jose, CA, United States","Deep learning has shown promising results in medical image analysis, however, the lack of very large annotated datasets confines its full potential. Although transfer learning with ImageNet pre-trained classification models can alleviate the problem, constrained image sizes and model complexities can lead to unnecessary increase in computational cost and decrease in performance. As many common morphological features are usually shared by different classification tasks of an organ, it is greatly beneficial if we can extract such features to improve classification with limited samples. Therefore, inspired by the idea of curriculum learning, we propose a strategy for building medical image classifiers using features from segmentation networks. By using a segmentation network pre-trained on similar data as the classification task, the machine can first learn the simpler shape and structural concepts before tackling the actual classification problem which usually involves more complicated concepts. Using our proposed framework on a 3D three-class brain tumor type classification problem, we achieved 82% accuracy on 191 testing samples with 91 training samples. When applying to a 2D nine-class cardiac semantic level classification problem, we achieved 86% accuracy on 263 testing samples with 108 training samples. Comparisons with ImageNet pre-trained classifiers and classifiers trained from scratch are presented. © 2018 Elsevier B.V.","Convolutional neural network; Deep learning; Fully convolutional network; Image classification; Image segmentation; Transfer learning","Brain Neoplasms; Deep Learning; Glioma; Heart; Humans; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Neoplasm Grading; Classification (of information); Convolution; Deep learning; Image segmentation; Medical image processing; Medical imaging; Neural networks; Sampling; Semantics; Classification models; Classification tasks; Computational costs; Convolutional networks; Convolutional neural network; Morphological features; Transfer learning; Type classifications; Article; brain tumor; classifier; computed tomographic angiography; diagnostic accuracy; diagnostic imaging; diagnostic test accuracy study; human; image segmentation; information processing; neuroimaging; nuclear magnetic resonance imaging; priority journal; tumor classification; tumor diagnosis; brain tumor; cancer grading; computer assisted diagnosis; glioma; heart; nuclear magnetic resonance imaging; pathology; procedures; three dimensional imaging; Image classification","Elsevier B.V.","13618415","","MIAEC","30119038","Article","Scopus","2-s2.0-85051394285"
"Iakovidis D.K.; Georgakopoulos S.V.; Vasilakakis M.; Koulaouzidis A.; Plagianakos V.P.","Iakovidis, Dimitris K. (6603967427); Georgakopoulos, Spiros V. (56288724200); Vasilakakis, Michael (57192311487); Koulaouzidis, Anastasios (14627591700); Plagianakos, Vassilis P. (6701826890)","6603967427; 56288724200; 57192311487; 14627591700; 6701826890","Detecting and Locating Gastrointestinal Anomalies Using Deep Learning and Iterative Cluster Unification","2018","IEEE Transactions on Medical Imaging","142","10.1109/TMI.2018.2837002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047012325&doi=10.1109%2fTMI.2018.2837002&partnerID=40&md5=8cb9b1f334a132cbec84f04748d148e0","Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35131, Greece; Endoscopy Unit, Royal Infirmary of Edinburgh, Edinburgh, EH16 4SA, United Kingdom","Iakovidis D.K., Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35131, Greece; Georgakopoulos S.V., Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35131, Greece; Vasilakakis M., Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35131, Greece; Koulaouzidis A., Endoscopy Unit, Royal Infirmary of Edinburgh, Edinburgh, EH16 4SA, United Kingdom; Plagianakos V.P., Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, 35131, Greece","This paper proposes a novel methodology for automatic detection and localization of gastrointestinal (GI) anomalies in endoscopic video frame sequences. Training is performed with weakly annotated images, using only image-level, semantic labels instead of detailed, and pixel-level annotations. This makes it a cost-effective approach for the analysis of large videoendoscopy repositories. Other advantages of the proposed methodology include its capability to suggest possible locations of GI anomalies within the video frames, and its generality, in the sense that abnormal frame detection is based on automatically derived image features. It is implemented in three phases: 1) it classifies the video frames into abnormal or normal using a weakly supervised convolutional neural network (WCNN) architecture; 2) detects salient points from deeper WCNN layers, using a deep saliency detection algorithm; and 3) localizes GI anomalies using an iterative cluster unification (ICU) algorithm. ICU is based on a pointwise cross-feature-map (PCFM) descriptor extracted locally from the detected salient points using information derived from the WCNN. Results, from extensive experimentation using publicly available collections of gastrointestinal endoscopy video frames, are presented. The data sets used include a variety of GI anomalies. Both anomaly detection and localization performance achieved, in terms of the area under receiver operating characteristic (AUC), were >80%. The highest AUC for anomaly detection was obtained on conventional gastroscopy images, reaching 96%, and the highest AUC for anomaly localization was obtained on wireless capsule endoscopy images, reaching 88%. © 2017 IEEE.","computer-aided detection and diagnosis; Endoscopy; gastrointestinal tract; machine learning","Algorithms; Databases, Factual; Deep Learning; Gastrointestinal Diseases; Gastrointestinal Tract; Gastroscopy; Humans; Image Interpretation, Computer-Assisted; Video Recording; Cluster computing; Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Cost effectiveness; Endoscopy; Feature extraction; Image segmentation; Iterative methods; Learning algorithms; Learning systems; Neural networks; Personnel training; Semantics; Computer-aided detection and diagnosis; Convolutional neural network; Gastrointestinal endoscopies; Gastrointestinal tract; Image color analysis; Lesions; Receiver operating characteristics; Wireless capsule endoscopy image; Article; artificial neural network; automation; capsule endoscopy; controlled study; cost effectiveness analysis; deep learning; deep saliency detection algorithm; diagnostic accuracy; diagnostic test accuracy study; feature extraction; gastrointestinal disease; gastrointestinal endoscopy; gastroscopy; human; image analysis; iterative cluster unification algorithm; learning algorithm; receiver operating characteristic; sensitivity and specificity; videoendoscopy; weakly supervised convolutional neural network; algorithm; computer assisted diagnosis; diagnostic imaging; factual database; gastrointestinal disease; gastrointestinal tract; procedures; videorecording; Deep learning","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29994763","Article","Scopus","2-s2.0-85047012325"
"Ma L.; Li H.; Meng F.; Wu Q.; Ngi Ngan K.","Ma, Lei (57192995620); Li, Hongliang (36444908600); Meng, Fanman (55272985700); Wu, Qingbo (57199303465); Ngi Ngan, King (7005884930)","57192995620; 36444908600; 55272985700; 57199303465; 7005884930","Global and local semantics-preserving based deep hashing for cross-modal retrieval","2018","Neurocomputing","36","10.1016/j.neucom.2018.05.052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048559552&doi=10.1016%2fj.neucom.2018.05.052&partnerID=40&md5=6393fbf4cf4799b8921d02f49e2e192f","School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China","Ma L., School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Li H., School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Meng F., School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Wu Q., School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Ngi Ngan K., School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China","Cross-modal hashing methods map similar data entities from heterogeneous data sources to binary codes with smaller Hamming distance. However, most existing cross-modal hashing methods learn the hash codes with the hand-crafted features which will not generate optimal hash codes and achieve satisfactory performance. Deep cross-modal hashing methods integrate feature learning and hash coding into an end-to-end learning framework which have achieved promising results. However, these deep cross-modal hashing methods do not well preserve the discriminative ability and the global multilevel similarity in hash learning procedure. In this paper, we propose a global and local semantics-preserving based deep hashing method for cross-modal retrieval. More specifically, a large margin is enforced between similar hash codes and dissimilar hash codes from an inter-modal view to learn discriminative hash codes. Therefore the learned hash codes can well preserve local semantic structure. Sequently, the supervised information with the global multilevel similarity is introduced to learn semantics-preserving hash codes for each intra-modal view. As a consequence, the global semantic structure can be preserved into the hash codes. Furthermore, a consistent regularization constraint is added to generate unified hash codes. Ultimately, the feature learning procedure and the hash coding procedure are integrated into an end-to-end learning framework. To verify the effectiveness of the proposed method, extensive experiments are conducted on several datasets, and the experimental results demonstrate that the proposed method achieves superior performance. © 2018 Elsevier B.V.","Cross-modal hashing; Deep learning; Metric learning; Semantic preserving","Codes (symbols); Deep learning; Hamming distance; Semantics; Cross-modal; Discriminative ability; Feature learning; Heterogeneous data sources; Learning frameworks; Learning procedures; Metric learning; Semantic structures; Article; artificial neural network; back propagation; controlled study; information retrieval; intermethod comparison; learning algorithm; measurement precision; priority journal; probability; semantics; sensitivity analysis; stochastic model; supervised machine learning; Hash functions","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85048559552"
"Mamoshina P.; Kochetov K.; Putin E.; Cortese F.; Aliper A.; Lee W.-S.; Ahn S.-M.; Uhn L.; Skjodt N.; Kovalchuk O.; Scheibye-Knudsen M.; Zhavoronkov A.","Mamoshina, Polina (56893719500); Kochetov, Kirill (57191620092); Putin, Evgeny (57189310406); Cortese, Franco (56295145600); Aliper, Alexander (54889030500); Lee, Won-Suk (57204165210); Ahn, Sung-Min (7401989966); Uhn, Lee (57204167123); Skjodt, Neil (57215989616); Kovalchuk, Olga (7003878362); Scheibye-Knudsen, Morten (25633162000); Zhavoronkov, Alex (39862415800)","56893719500; 57191620092; 57189310406; 56295145600; 54889030500; 57204165210; 7401989966; 57204167123; 57215989616; 7003878362; 25633162000; 39862415800","Population specific biomarkers of human aging: A big data study using South Korean, Canadian, and Eastern European patient populations","2018","Journals of Gerontology - Series A Biological Sciences and Medical Sciences","111","10.1093/gerona/gly005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050306913&doi=10.1093%2fgerona%2fgly005&partnerID=40&md5=4921571a558865073d703f79bf999e07","Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, MD, United States; Computer Science Department, University of Oxford, United Kingdom; Computer Technologies Lab, ITMO University, St.-Petersburg, Russian Federation; Department of Biomedical and Molecular Sciences, Queen's University School of Medicine, Queen's University, Kingston, ON, Canada; Biogerontology Research Foundation, Oxford, United Kingdom; Canadian Longevity Alliance, ON, Canada; Gachon University Gil Medical Center, Incheon, South Korea; Canada Cancer and Aging Research Laboratories, Lethbridge, AB, Canada; University of Lethbridge, AB, Canada; Center for Healthy Aging, Department of Cellular and Molecular Medicine, University of Copenhagen, Denmark","Mamoshina P., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, MD, United States, Computer Science Department, University of Oxford, United Kingdom; Kochetov K., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, MD, United States, Computer Technologies Lab, ITMO University, St.-Petersburg, Russian Federation; Putin E., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, MD, United States, Computer Technologies Lab, ITMO University, St.-Petersburg, Russian Federation; Cortese F., Department of Biomedical and Molecular Sciences, Queen's University School of Medicine, Queen's University, Kingston, ON, Canada, Biogerontology Research Foundation, Oxford, United Kingdom, Canadian Longevity Alliance, ON, Canada; Aliper A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, MD, United States; Lee W.-S., Gachon University Gil Medical Center, Incheon, South Korea; Ahn S.-M., Gachon University Gil Medical Center, Incheon, South Korea; Uhn L., Gachon University Gil Medical Center, Incheon, South Korea; Skjodt N., Canada Cancer and Aging Research Laboratories, Lethbridge, AB, Canada, University of Lethbridge, AB, Canada; Kovalchuk O., Canada Cancer and Aging Research Laboratories, Lethbridge, AB, Canada, University of Lethbridge, AB, Canada; Scheibye-Knudsen M., Center for Healthy Aging, Department of Cellular and Molecular Medicine, University of Copenhagen, Denmark; Zhavoronkov A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University, Baltimore, MD, United States, Biogerontology Research Foundation, Oxford, United Kingdom","Accurate and physiologically meaningful biomarkers for human aging are key to assessing antiaging therapies. Given ethnic differences in health, diet, lifestyle, behavior, environmental exposures, and even average rate of biological aging, it stands to reason that aging clocks trained on datasets obtained from specific ethnic populations are more likely to account for these potential confounding factors, resulting in an enhanced capacity to predict chronological age and quantify biological age. Here, we present a deep learning-based hematological aging clock modeled using the large combined dataset of Canadian, South Korean, and Eastern European population blood samples that show increased predictive accuracy in individual populations compared to population specific hematologic aging clocks. The performance of models was also evaluated on publicly available samples of the American population from the National Health and Nutrition Examination Survey (NHANES). In addition, we explored the association between age predicted by both population specific and combined hematological clocks and all-cause mortality. Overall, this study suggests (a) the population specificity of aging patterns and (b) hematologic clocks predicts all-cause mortality. The proposed models were added to the freely-available Aging.AI system expanding the range of tools for analysis of human aging. © The Author(s) 2018. Published by Oxford University Press on behalf of The Gerontological Society of America.","Biochemistry aging clocks; Biological age; Deep Learning; Deep Neural Networks; Machine Learning","Adult; Aged; Aged, 80 and over; Aging; Biomarkers; Blood Glucose; Canada; Cholesterol; Datasets as Topic; Deep Learning; Erythrocytes; Europe, Eastern; Female; Health Surveys; Hemoglobins; Humans; Male; Middle Aged; Models, Statistical; Neural Networks (Computer); Republic of Korea; Serum Albumin; Sex Factors; Sodium; Triglycerides; Urea; Young Adult; biological marker; cholesterol; hemoglobin; serum albumin; sodium; triacylglycerol; urea; adult; aged; aging; artificial neural network; blood; Canada; Eastern Europe; erythrocyte; female; glucose blood level; health survey; human; information processing; male; middle aged; sex factor; South Korea; statistical model; very elderly; young adult","Oxford University Press","10795006","","JGASF","29340580","Article","Scopus","2-s2.0-85050306913"
"Lane T.; Russo D.P.; Zorn K.M.; Clark A.M.; Korotcov A.; Tkachenko V.; Reynolds R.C.; Perryman A.L.; Freundlich J.S.; Ekins S.","Lane, Thomas (57200699895); Russo, Daniel P. (57188754026); Zorn, Kimberley M. (57201902863); Clark, Alex M. (55732793400); Korotcov, Alexandru (11739705900); Tkachenko, Valery (35775650900); Reynolds, Robert C. (7401829883); Perryman, Alexander L. (6603054613); Freundlich, Joel S. (8919176600); Ekins, Sean (57203197233)","57200699895; 57188754026; 57201902863; 55732793400; 11739705900; 35775650900; 7401829883; 6603054613; 8919176600; 57203197233","Comparing and Validating Machine Learning Models for Mycobacterium tuberculosis Drug Discovery","2018","Molecular Pharmaceutics","76","10.1021/acs.molpharmaceut.8b00083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046457540&doi=10.1021%2facs.molpharmaceut.8b00083&partnerID=40&md5=515f86873bb5e88ef7ad3d131795b627","Collaborations Pharmaceuticals, Inc., Main Campus Drive, Lab 3510, Raleigh, 27606, NC, United States; Department of Biochemistry and Biophysics, University of North Carolina, Chapel Hill, 27599, NC, United States; Rutgers Center for Computational and Integrative Biology, Camden, 08102, NJ, United States; Molecular Materials Informatics, Inc., 1900 St. Jacques #302, Montreal, H3J 2S1, QC, Canada; Science Data Software, LLC, 14914 Bradwill Court, Rockville, 20850, MD, United States; Department of Medicine, Division of Hematology and Oncology, University of Alabama at Birmingham, NP 2540 J, 1720 Second Avenue South, Birmingham, 35294-3300, AL, United States; Department of Pharmacology, Physiology and Neuroscience, Rutgers University, New Jersey Medical School, Newark, 07103, NJ, United States; Division of Infectious Diseases, Department of Medicine, Ruy V. Lourenço Center, Study of Emerging and Re-emerging Pathogens, Rutgers University, New Jersey Medical School, Newark, 07103, NJ, United States","Lane T., Collaborations Pharmaceuticals, Inc., Main Campus Drive, Lab 3510, Raleigh, 27606, NC, United States, Department of Biochemistry and Biophysics, University of North Carolina, Chapel Hill, 27599, NC, United States; Russo D.P., Collaborations Pharmaceuticals, Inc., Main Campus Drive, Lab 3510, Raleigh, 27606, NC, United States, Rutgers Center for Computational and Integrative Biology, Camden, 08102, NJ, United States; Zorn K.M., Collaborations Pharmaceuticals, Inc., Main Campus Drive, Lab 3510, Raleigh, 27606, NC, United States; Clark A.M., Molecular Materials Informatics, Inc., 1900 St. Jacques #302, Montreal, H3J 2S1, QC, Canada; Korotcov A., Science Data Software, LLC, 14914 Bradwill Court, Rockville, 20850, MD, United States; Tkachenko V., Science Data Software, LLC, 14914 Bradwill Court, Rockville, 20850, MD, United States; Reynolds R.C., Department of Medicine, Division of Hematology and Oncology, University of Alabama at Birmingham, NP 2540 J, 1720 Second Avenue South, Birmingham, 35294-3300, AL, United States; Perryman A.L., Department of Pharmacology, Physiology and Neuroscience, Rutgers University, New Jersey Medical School, Newark, 07103, NJ, United States; Freundlich J.S., Department of Pharmacology, Physiology and Neuroscience, Rutgers University, New Jersey Medical School, Newark, 07103, NJ, United States, Division of Infectious Diseases, Department of Medicine, Ruy V. Lourenço Center, Study of Emerging and Re-emerging Pathogens, Rutgers University, New Jersey Medical School, Newark, 07103, NJ, United States; Ekins S., Collaborations Pharmaceuticals, Inc., Main Campus Drive, Lab 3510, Raleigh, 27606, NC, United States","Tuberculosis is a global health dilemma. In 2016, the WHO reported 10.4 million incidences and 1.7 million deaths. The need to develop new treatments for those infected with Mycobacterium tuberculosis (Mtb) has led to many large-scale phenotypic screens and many thousands of new active compounds identified in vitro. However, with limited funding, efforts to discover new active molecules against Mtb needs to be more efficient. Several computational machine learning approaches have been shown to have good enrichment and hit rates. We have curated small molecule Mtb data and developed new models with a total of 18,886 molecules with activity cutoffs of 10 μM, 1 μM, and 100 nM. These data sets were used to evaluate different machine learning methods (including deep learning) and metrics and to generate predictions for additional molecules published in 2017. One Mtb model, a combined in vitro and in vivo data Bayesian model at a 100 nM activity yielded the following metrics for 5-fold cross validation: accuracy = 0.88, precision = 0.22, recall = 0.91, specificity = 0.88, kappa = 0.31, and MCC = 0.41. We have also curated an evaluation set (n = 153 compounds) published in 2017, and when used to test our model, it showed the comparable statistics (accuracy = 0.83, precision = 0.27, recall = 1.00, specificity = 0.81, kappa = 0.36, and MCC = 0.47). We have also compared these models with additional machine learning algorithms showing Bayesian machine learning models constructed with literature Mtb data generated by different laboratories generally were equivalent to or outperformed deep neural networks with external test sets. Finally, we have also compared our training and test sets to show they were suitably diverse and different in order to represent useful evaluation sets. Such Mtb machine learning models could help prioritize compounds for testing in vitro and in vivo. © 2018 American Chemical Society.","deep learning; drug discovery; machine learning; support vector machine; tuberculosis","Antitubercular Agents; Bayes Theorem; Drug Discovery; Machine Learning; Mycobacterium tuberculosis; Support Vector Machine; tuberculostatic agent; tuberculostatic agent; Article; Bayesian learning; controlled study; decision tree; drug development; hydrogen bond; IC50; learning algorithm; machine learning; measurement accuracy; MIC90; molecular weight; Mycobacterium tuberculosis; nonhuman; priority journal; random forest; support vector machine; tuberculosis; Bayes theorem; drug development; drug effect; machine learning; Mycobacterium tuberculosis","American Chemical Society","15438384","","MPOHB","29672063","Article","Scopus","2-s2.0-85046457540"
"Ehteshami Bejnordi B.; Mullooly M.; Pfeiffer R.M.; Fan S.; Vacek P.M.; Weaver D.L.; Herschorn S.; Brinton L.A.; van Ginneken B.; Karssemeijer N.; Beck A.H.; Gierach G.L.; van der Laak J.A.W.M.; Sherman M.E.","Ehteshami Bejnordi, Babak (56986708300); Mullooly, Maeve (55208230100); Pfeiffer, Ruth M. (56418948100); Fan, Shaoqi (57195838388); Vacek, Pamela M. (7005379516); Weaver, Donald L. (7403128664); Herschorn, Sally (57202525391); Brinton, Louise A. (57217609698); van Ginneken, Bram (57202688150); Karssemeijer, Nico (24332021400); Beck, Andrew H. (35363449100); Gierach, Gretchen L. (6507137915); van der Laak, Jeroen A. W. M. (6701833644); Sherman, Mark E. (35374273000)","56986708300; 55208230100; 56418948100; 57195838388; 7005379516; 7403128664; 57202525391; 57217609698; 57202688150; 24332021400; 35363449100; 6507137915; 6701833644; 35374273000","Using deep convolutional neural networks to identify and classify tumor-associated stroma in diagnostic breast biopsies","2018","Modern Pathology","139","10.1038/s41379-018-0073-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048495121&doi=10.1038%2fs41379-018-0073-z&partnerID=40&md5=4e28b910c73306a6584cc24eac6da3a6","Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Division of Cancer Epidemiology and Genetics, National Cancer Institute, Bethesda, MD, United States; Cancer Prevention Fellowship Program, Division of Cancer Prevention, National Cancer Institute, Bethesda, MD, United States; Department of Medical Biostatistics, University of Vermont, Burlington, VT, United States; Department of Pathology, University of Vermont, Burlington, VT, United States; University of Vermont Cancer Center, Burlington, VT, United States; Department of Radiology, University of Vermont, Burlington, VT, United States; PathAI, Inc., Cambridge, MA, United States; Department of Pathology, Radboud University Medical Center, Nijmegen, Netherlands; Mayo Clinic, Jacksonville, FL, United States","Ehteshami Bejnordi B., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Mullooly M., Division of Cancer Epidemiology and Genetics, National Cancer Institute, Bethesda, MD, United States, Cancer Prevention Fellowship Program, Division of Cancer Prevention, National Cancer Institute, Bethesda, MD, United States; Pfeiffer R.M., Division of Cancer Epidemiology and Genetics, National Cancer Institute, Bethesda, MD, United States; Fan S., Division of Cancer Epidemiology and Genetics, National Cancer Institute, Bethesda, MD, United States; Vacek P.M., Department of Medical Biostatistics, University of Vermont, Burlington, VT, United States; Weaver D.L., Department of Pathology, University of Vermont, Burlington, VT, United States; Herschorn S., University of Vermont Cancer Center, Burlington, VT, United States, Department of Radiology, University of Vermont, Burlington, VT, United States; Brinton L.A., Division of Cancer Epidemiology and Genetics, National Cancer Institute, Bethesda, MD, United States; van Ginneken B., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Karssemeijer N., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Beck A.H., Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States, PathAI, Inc., Cambridge, MA, United States; Gierach G.L., Division of Cancer Epidemiology and Genetics, National Cancer Institute, Bethesda, MD, United States; van der Laak J.A.W.M., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands, Department of Pathology, Radboud University Medical Center, Nijmegen, Netherlands; Sherman M.E., Mayo Clinic, Jacksonville, FL, United States","The breast stromal microenvironment is a pivotal factor in breast cancer development, growth and metastases. Although pathologists often detect morphologic changes in stroma by light microscopy, visual classification of such changes is subjective and non-quantitative, limiting its diagnostic utility. To gain insights into stromal changes associated with breast cancer, we applied automated machine learning techniques to digital images of 2387 hematoxylin and eosin stained tissue sections of benign and malignant image-guided breast biopsies performed to investigate mammographic abnormalities among 882 patients, ages 40–65 years, that were enrolled in the Breast Radiology Evaluation and Study of Tissues (BREAST) Stamp Project. Using deep convolutional neural networks, we trained an algorithm to discriminate between stroma surrounding invasive cancer and stroma from benign biopsies. In test sets (928 whole-slide images from 330 patients), this algorithm could distinguish biopsies diagnosed as invasive cancer from benign biopsies solely based on the stromal characteristics (area under the receiver operator characteristics curve = 0.962). Furthermore, without being trained specifically using ductal carcinoma in situ as an outcome, the algorithm detected tumor-associated stroma in greater amounts and at larger distances from grade 3 versus grade 1 ductal carcinoma in situ. Collectively, these results suggest that algorithms based on deep convolutional neural networks that evaluate only stroma may prove useful to classify breast biopsies and aid in understanding and evaluating the biology of breast lesions. © 2018, United States & Canadian Academy of Pathology.","","Adult; Aged; Biopsy; Breast Neoplasms; Deep Learning; Female; Humans; Middle Aged; Tumor Microenvironment; adult; aged; Article; artificial neural network; breast biopsy; breast disease; breast tissue; cancer diagnosis; cancer patient; deep convolutional neural network; female; human; human tissue; image guided biopsy; interventional ultrasonography; intraductal carcinoma; lobular carcinoma in situ; major clinical study; mammography; needle biopsy; priority journal; stereotactic vacuum assisted biopsy; stroma; tissue section; tumor associated breast stroma; tumor biopsy; tumor invasion; biopsy; breast tumor; classification; middle aged; pathology; tumor microenvironment","Nature Publishing Group","08933952","","MODPE","29899550","Article","Scopus","2-s2.0-85048495121"
"Plis S.M.; Amin M.F.; Chekroud A.; Hjelm D.; Damaraju E.; Lee H.J.; Bustillo J.R.; Cho K.; Pearlson G.D.; Calhoun V.D.","Plis, Sergey M. (8970496000); Amin, Md Faijul (57212936581); Chekroud, Adam (56088756800); Hjelm, Devon (56321732500); Damaraju, Eswar (35195551400); Lee, Hyo Jong (55706807400); Bustillo, Juan R. (7004136211); Cho, KyungHyun (55722769200); Pearlson, Godfrey D. (57202572400); Calhoun, Vince D. (57898536200)","8970496000; 57212936581; 56088756800; 56321732500; 35195551400; 55706807400; 7004136211; 55722769200; 57202572400; 57898536200","Reading the (functional) writing on the (structural) wall: Multimodal fusion of brain structure and function via a deep neural network based translation approach reveals novel impairments in schizophrenia","2018","NeuroImage","44","10.1016/j.neuroimage.2018.07.047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050870950&doi=10.1016%2fj.neuroimage.2018.07.047&partnerID=40&md5=49aedf4607324da31c59b8b9f9277517","The Mind Research Network, 1101 Yale Blvd, Albuquerque, 87106, NM, United States; Human Neuroscience Laboratory, Yale University, New Haven, 06520, CT, United States; Division of Computer Science and Engineering, CAIIT, Chonbuk National University, Jeonju, South Korea; Department of Psychiatry and Neurosciences, University of New Mexico, Albuquerque, 87131, NM, United States; Courant Institute & Center for Data Science, New York University, New York, 10012, NY, United States; Olin Neuropsychiatry Research Center, Hartford Hospital (IOL Campus), Hartford, CT, United States; Department of Psychiatry and Neurobiology, Yale University School of Medicine, New Haven, CT, United States; Dept. of Electrical and Computer Engineering, University of New Mexico, Albuquerque, 87131, NM, United States; Intel Corporation, 5000 W Chandler Blvd, Chandler, 85226, AZ, United States","Plis S.M., The Mind Research Network, 1101 Yale Blvd, Albuquerque, 87106, NM, United States; Amin M.F., The Mind Research Network, 1101 Yale Blvd, Albuquerque, 87106, NM, United States, Intel Corporation, 5000 W Chandler Blvd, Chandler, 85226, AZ, United States; Chekroud A., Human Neuroscience Laboratory, Yale University, New Haven, 06520, CT, United States; Hjelm D., The Mind Research Network, 1101 Yale Blvd, Albuquerque, 87106, NM, United States; Damaraju E., The Mind Research Network, 1101 Yale Blvd, Albuquerque, 87106, NM, United States; Lee H.J., Division of Computer Science and Engineering, CAIIT, Chonbuk National University, Jeonju, South Korea; Bustillo J.R., Department of Psychiatry and Neurosciences, University of New Mexico, Albuquerque, 87131, NM, United States; Cho K., Courant Institute & Center for Data Science, New York University, New York, 10012, NY, United States; Pearlson G.D., Olin Neuropsychiatry Research Center, Hartford Hospital (IOL Campus), Hartford, CT, United States, Department of Psychiatry and Neurobiology, Yale University School of Medicine, New Haven, CT, United States; Calhoun V.D., The Mind Research Network, 1101 Yale Blvd, Albuquerque, 87106, NM, United States, Department of Psychiatry and Neurosciences, University of New Mexico, Albuquerque, 87131, NM, United States, Dept. of Electrical and Computer Engineering, University of New Mexico, Albuquerque, 87131, NM, United States","This work presents a novel approach to finding linkage/association between multimodal brain imaging data, such as structural MRI (sMRI) and functional MRI (fMRI). Motivated by the machine translation domain, we employ a deep learning model, and consider two different imaging views of the same brain like two different languages conveying some common facts. That analogy enables finding linkages between two modalities. The proposed translation-based fusion model contains a computing layer that learns “alignments” (or links) between dynamic connectivity features from fMRI data and static gray matter patterns from sMRI data. The approach is evaluated on a multi-site dataset consisting of eyes-closed resting state imaging data collected from 298 subjects (age- and gender matched 154 healthy controls and 144 patients with schizophrenia). Results are further confirmed on an independent dataset consisting of eyes-open resting state imaging data from 189 subjects (age- and gender matched 91 healthy controls and 98 patients with schizophrenia). We used dynamic functional connectivity (dFNC) states as the functional features and ICA-based sources from gray matter densities as the structural features. The dFNC states characterized by weakly correlated intrinsic connectivity networks (ICNs) were found to have stronger association with putamen and insular gray matter pattern, while the dFNC states of profuse strongly correlated ICNs exhibited stronger links with the gray matter pattern in precuneus, posterior cingulate cortex (PCC), and temporal cortex. Further investigation with the estimated link strength (or alignment score) showed significant group differences between healthy controls and patients with schizophrenia in several key regions including temporal lobe, and linked these to connectivity states showing less occupancy in healthy controls. Moreover, this novel approach revealed significant correlation between a cognitive score (attention/vigilance) and the function/structure alignment score that was not detected when data modalities were considered separately. © 2018","Deep learning; Multimodal fusion; Psychosis; Schizophrenia","Adult; Connectome; Deep Learning; Female; Gray Matter; Humans; Magnetic Resonance Imaging; Male; Middle Aged; Nerve Net; Psychotic Disorders; Schizophrenia; adult; age; Article; brain dysfunction; brain function; brain region; controlled study; eyelid closure; female; functional assessment; functional connectivity; functional magnetic resonance imaging; gender; gray matter; human; intrinsic connectivity network; major clinical study; male; nerve cell network; neuroimaging; posterior cingulate; precuneus; priority journal; putamen; resting state network; schizophrenia; temporal lobe; connectome; diagnostic imaging; middle aged; nerve cell network; nuclear magnetic resonance imaging; pathophysiology; physiology; procedures; psychosis; schizophrenia","Academic Press Inc.","10538119","","NEIME","30055372","Article","Scopus","2-s2.0-85050870950"
"Kim M.; Oh I.; Ahn J.","Kim, Minseon (57204181042); Oh, Ilhwan (57203880394); Ahn, Jaegyoon (24832881000)","57204181042; 57203880394; 24832881000","An improved method for prediction of cancer prognosis by network learning","2018","Genes","32","10.3390/genes9100478","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054791295&doi=10.3390%2fgenes9100478&partnerID=40&md5=66c851e2a0f6918e633ffc80662acb00","Department of Computer Science and Engineering, Incheon National University, Incheon, 22012, South Korea","Kim M., Department of Computer Science and Engineering, Incheon National University, Incheon, 22012, South Korea; Oh I., Department of Computer Science and Engineering, Incheon National University, Incheon, 22012, South Korea; Ahn J., Department of Computer Science and Engineering, Incheon National University, Incheon, 22012, South Korea","Accurate identification of prognostic biomarkers is an important yet challenging goal in bioinformatics. Many bioinformatics approaches have been proposed for this purpose, but there is still room for improvement. In this paper, we propose a novel machine learning-based method for more accurate identification of prognostic biomarker genes and use them for prediction of cancer prognosis. The proposed method specifies the candidate prognostic gene module by graph learning using the generative adversarial networks (GANs) model, and scores genes using a PageRank algorithm. We applied the proposed method to multiple-omics data that included copy number, gene expression, DNA methylation, and somatic mutation data for five cancer types. The proposed method showed better prediction accuracy than did existing methods. We identified many prognostic genes and their roles in their biological pathways. We also showed that the genes identified from different omics data were complementary, which led to improved accuracy in prediction using multi-omics data. © 2018, MDPI AG. All rights reserved.","Cancer prognosis; Deep learning; Gans; Multi-omics; Pagerank","biological marker; Article; cancer classification; cancer prognosis; carcinogenesis; copy number variation; DNA methylation; gene cluster; gene expression; gene identification; generative adversarial network; genetic algorithm; genetic analysis; human; machine learning; measurement accuracy; network learning; oncogene; predictive value; principal component analysis; somatic mutation","MDPI","20734425","","","","Article","Scopus","2-s2.0-85054791295"
"Huang J.; Liu H.; Dai J.; Cai W.","Huang, Jianqing (57203162195); Liu, Hecong (57195521052); Dai, Jinghang (57225840177); Cai, Weiwei (57192108361)","57203162195; 57195521052; 57225840177; 57192108361","Reconstruction for limited-data nonlinear tomographic absorption spectroscopy via deep learning","2018","Journal of Quantitative Spectroscopy and Radiative Transfer","56","10.1016/j.jqsrt.2018.07.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050745704&doi=10.1016%2fj.jqsrt.2018.07.011&partnerID=40&md5=8407da3ec35921029b307e2b8715600f","Key Lab of Education Ministry for Power Machinery and Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, 200240, Shanghai, China","Huang J., Key Lab of Education Ministry for Power Machinery and Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, 200240, Shanghai, China; Liu H., Key Lab of Education Ministry for Power Machinery and Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, 200240, Shanghai, China; Dai J., Key Lab of Education Ministry for Power Machinery and Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, 200240, Shanghai, China; Cai W., Key Lab of Education Ministry for Power Machinery and Engineering, School of Mechanical Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, 200240, Shanghai, China","Nonlinear tomographic absorption spectroscopy (NTAS) is an emerging gas sensing technique for reactive flows that has been proven to be capable of simultaneously imaging temperature and concentration of absorbing gas. However, the nonlinear tomographic problems are typically solved with an optimization algorithm such as simulated annealing which suffers from high computational cost. This problem becomes more severe when thousands of tomographic data needs to be processed for the temporal resolution of turbulent flames. To overcome this limitation, in this work we propose a reconstruction method based on convolutional neural networks (CNN) which can take full advantage of the large amount tomographic data to build an efficient neural networks to rapidly predict the reconstruction by feeding the sinograms to it. Simulative studies were performed to investigate how the parameters will affect the performance of neural networks. The results show that CNN can effectively reduce the computational cost and at the same time achieve a similar accuracy level as SA. The successful demonstration CNN in this work indicates possible applications of other sophisticated deep neural networks such as deep belief networks (DBN) and generative adversarial networks (GAN) to nonlinear tomography. © 2018 Elsevier Ltd. © 2018 Elsevier Ltd","Absorption spectroscopy; Combustion diagnostics; Convolutional neural networks; Nonlinear tomography","Absorption spectroscopy; Convolution; Deep neural networks; Neural networks; Simulated annealing; Tomography; Adversarial networks; Combustion diagnostics; Convolutional neural network; Convolutional Neural Networks (CNN); Deep belief network (DBN); Optimization algorithms; Reconstruction method; Temporal resolution; artificial neural network; atomic absorption spectroscopy; combustion; machine learning; tomography; Image reconstruction","Elsevier Ltd","00224073","","","","Article","Scopus","2-s2.0-85050745704"
"Chierici M.; Giulini M.; Bussola N.; Jurman G.; Furlanello C.","Chierici, Marco (16070093000); Giulini, Marco (57206221228); Bussola, Nicole (57205407123); Jurman, Giuseppe (6602367398); Furlanello, Cesare (6701821823)","16070093000; 57206221228; 57205407123; 6602367398; 6701821823","Machine learning models for predicting endocrine disruption potential of environmental chemicals","2018","Journal of Environmental Science and Health - Part C Environmental Carcinogenesis and Ecotoxicology Reviews","10","10.1080/10590501.2018.1537155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059908168&doi=10.1080%2f10590501.2018.1537155&partnerID=40&md5=0d038bb8d00449e23424d69e98738a01","Fondazione Bruno Kessler, Trento, Italy; Centre for Integrative Biology, University of Trento, Trento, Italy","Chierici M., Fondazione Bruno Kessler, Trento, Italy; Giulini M., Fondazione Bruno Kessler, Trento, Italy; Bussola N., Fondazione Bruno Kessler, Trento, Italy, Centre for Integrative Biology, University of Trento, Trento, Italy; Jurman G., Fondazione Bruno Kessler, Trento, Italy; Furlanello C., Fondazione Bruno Kessler, Trento, Italy","We introduce here ML4Tox, a framework offering Deep Learning and Support Vector Machine models to predict agonist, antagonist, and binding activities of chemical compounds, in this case for the estrogen receptor ligand-binding domain. The ML4Tox models have been developed with a 10 × 5-fold cross-validation schema on the training portion of the CERAPP ToxCast dataset, formed by 1677 chemicals, each described by 777 molecular features. On the CERAPP “All Literature” evaluation set (agonist: 6319 compounds; antagonist 6539; binding 7283), ML4Tox significantly improved sensitivity over published results on all three tasks, with agonist: 0.78 vs 0.56; antagonist: 0.69 vs 0.11; binding: 0.66 vs 0.26. © 2018, © 2018 Taylor & Francis Group, LLC.","deep learning; machine learning; toxicology","Computer Simulation; Endocrine Disruptors; Environmental Pollutants; Machine Learning; Protein Binding; Quantitative Structure-Activity Relationship; Receptors, Estrogen; Support Vector Machine; Toxicity Tests; Artificial intelligence; Binding sites; Learning systems; endocrine disruptor; environmental chemical; estrogen receptor; endocrine disruptor; estrogen receptor; protein binding; Binding activities; Endocrine disruption; Environmental chemicals; Estrogen receptor ligand binding domains; Machine learning models; Molecular feature; Support vector machine models; toxicology; Article; binding affinity; binding site; deep learning; endocrine disease; human; ligand binding; nonhuman; prediction; receptor binding; support vector machine; computer simulation; machine learning; pollutant; procedures; quantitative structure activity relation; support vector machine; toxicity; toxicity testing; Deep learning","Taylor and Francis Inc.","10590501","","JSHRE","30628533","Article","Scopus","2-s2.0-85059908168"
"Hwang D.; Kim K.Y.; Kang S.K.; Seo S.; Paeng J.C.; Lee D.S.; Lee J.S.","Hwang, Donghwi (57202416594); Kim, Kyeong Yun (57026534300); Kang, Seung Kwan (57193692307); Seo, Seongho (55992472900); Paeng, Jin Chul (6602895031); Lee, Dong Soo (56580452900); Lee, Jae Sung (56008822800)","57202416594; 57026534300; 57193692307; 55992472900; 6602895031; 56580452900; 56008822800","Improving the accuracy of simultaneously reconstructed activity and attenuation maps using deep learning","2018","Journal of Nuclear Medicine","117","10.2967/jnumed.117.202317","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051292160&doi=10.2967%2fjnumed.117.202317&partnerID=40&md5=7eb26f15bf73a0f78fafe024c8a45fcd","Department of Biomedical Sciences, Seoul National University, Seoul, South Korea; Department of Nuclear Medicine, Seoul National University, College of Medicine, 103 Daehak-ro, Jongno-gu, Seoul, 03080, South Korea; Department of Neuroscience, College of Medicine, Gachon University, Incheon, South Korea; Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, South Korea; Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Suwon, South Korea","Hwang D., Department of Biomedical Sciences, Seoul National University, Seoul, South Korea, Department of Nuclear Medicine, Seoul National University, College of Medicine, 103 Daehak-ro, Jongno-gu, Seoul, 03080, South Korea; Kim K.Y., Department of Biomedical Sciences, Seoul National University, Seoul, South Korea, Department of Nuclear Medicine, Seoul National University, College of Medicine, 103 Daehak-ro, Jongno-gu, Seoul, 03080, South Korea; Kang S.K., Department of Biomedical Sciences, Seoul National University, Seoul, South Korea, Department of Nuclear Medicine, Seoul National University, College of Medicine, 103 Daehak-ro, Jongno-gu, Seoul, 03080, South Korea; Seo S., Department of Neuroscience, College of Medicine, Gachon University, Incheon, South Korea; Paeng J.C., Department of Nuclear Medicine, Seoul National University, College of Medicine, 103 Daehak-ro, Jongno-gu, Seoul, 03080, South Korea, Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, South Korea; Lee D.S., Department of Nuclear Medicine, Seoul National University, College of Medicine, 103 Daehak-ro, Jongno-gu, Seoul, 03080, South Korea, Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, South Korea, Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Suwon, South Korea; Lee J.S., Department of Biomedical Sciences, Seoul National University, Seoul, South Korea, Department of Nuclear Medicine, Seoul National University, College of Medicine, 103 Daehak-ro, Jongno-gu, Seoul, 03080, South Korea, Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, South Korea","Simultaneous reconstruction of activity and attenuation using the maximum-likelihood reconstruction of activity and attenuation (MLAA) augmented by time-of-flight information is a promising method for PET attenuation correction. However, it still suffers from several problems, including crosstalk artifacts, slow convergence speed, and noisy attenuation maps (μ-maps). In this work, we developed deep convolutional neural networks (CNNs) to overcome these MLAA limitations, and we verified their feasibility using a clinical brain PET dataset. Methods: We applied the proposed method to one of the most challenging PET cases for simultaneous image reconstruction (18F-fluorinated-N-3-fluoropropyl-2-β-carboxymethoxy- 3-β-(4-iodophenyl)nortropane [18F-FP-CIT] PET scans with highly specific binding to striatum of the brain). Three different CNN architectures (convolutional autoencoder [CAE], Unet, and Hybrid of CAE) were designed and trained to learn a CT-derived μ-map (μ-CT) from the MLAA-generated activity distribution and μ-map (μ-MLAA). The PET/CT data of 40 patients with suspected Parkinson disease were used for 5-fold cross-validation. For the training of CNNs, 800,000 transverse PET and CT slices augmented from 32 patient datasets were used. The similarity to μ-CT of the CNNgenerated μ-maps (μ-CAE, μ-Unet, and μ-Hybrid) and μ-MLAA was compared using Dice similarity coefficients. In addition, we compared the activity concentration of specific (striatum) and nonspecific (cerebellum and occipital cortex) binding regions and the binding ratios in the striatum in the PET activity images reconstructed using those μ-maps. Results: The CNNs generated less noisy and more uniform μ-maps than the original μ-MLAA. Moreover, the air cavities and bones were better resolved in the proposed CNN outputs. In addition, the proposed deep learning approach was useful for mitigating the crosstalk problem in the MLAA reconstruction. The Hybrid network of CAE and Unet yielded the most similar μ-maps to μ-CT (Dice similarity coefficient in the whole head 5 0.79 in the bone and 0.72 in air cavities), resulting in only about a 5% error in activity and binding ratio quantification. Conclusion: The proposed deep learning approach is promising for accurate attenuation correction of activity distribution in time-of-flight PET systems. Copyright © 2018 by the Society of Nuclear Medicine and Molecular Imaging.","Crosstalk; Deep learning; Denoising; Quantification; Simultaneous reconstruction","Aged; Brain; Deep Learning; Dopamine; Female; Humans; Image Processing, Computer-Assisted; Male; Positron Emission Tomography Computed Tomography; Time Factors; dopamine transporter; fluorinated n 3 fluoropropyl 2 beta carboxymethoxy 3 beta (4 iodophenyl)nortropane f 18; fluorine 18; tracer; unclassified drug; dopamine; Article; artificial neural network; cerebellar slice; clinical article; controlled study; convolutional autoencoder; convolutional neural network; corpus striatum; dopaminergic activity; female; human; Hybrid of convolutional autoencoder; image reconstruction; information processing; intermethod comparison; machine learning; male; maximum likelihood reconstruction of activity and attenuation; occipital cortex; Parkinson disease; positron emission tomography-computed tomography; priority journal; receptor cross-talk; retrospective study; time of flight mass spectrometry; Unet; aged; brain; diagnostic imaging; image processing; metabolism; procedures; time factor","Society of Nuclear Medicine Inc.","01615505","","JNMEA","29449446","Article","Scopus","2-s2.0-85051292160"
"Qureshi A.H.; Nakamura Y.; Yoshikawa Y.; Ishiguro H.","Qureshi, Ahmed Hussain (55849495300); Nakamura, Yutaka (55871593000); Yoshikawa, Yuichiro (7201413552); Ishiguro, Hiroshi (26643316500)","55849495300; 55871593000; 7201413552; 26643316500","Intrinsically motivated reinforcement learning for human–robot interaction in the real-world","2018","Neural Networks","47","10.1016/j.neunet.2018.03.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044999508&doi=10.1016%2fj.neunet.2018.03.014&partnerID=40&md5=2068fa734bded6b6a9a51d89c0ff6d10","Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan","Qureshi A.H., Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan; Nakamura Y., Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan; Yoshikawa Y., Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan; Ishiguro H., Department of System Innovation, Graduate School of Engineering Science, Osaka University, 1-3 Machikaneyama, Toyonaka, Osaka, Japan","For a natural social human–robot interaction, it is essential for a robot to learn the human-like social skills. However, learning such skills is notoriously hard due to the limited availability of direct instructions from people to teach a robot. In this paper, we propose an intrinsically motivated reinforcement learning framework in which an agent gets the intrinsic motivation-based rewards through the action-conditional predictive model. By using the proposed method, the robot learned the social skills from the human–robot interaction experiences gathered in the real uncontrolled environments. The results indicate that the robot not only acquired human-like social skills but also took more human-like decisions, on a test dataset, than a robot which received direct rewards for the task achievement. © 2018 Elsevier Ltd","Deep reinforcement learning; Human–robot interaction; Intrinsic motivation; Real-world robotics; Social robots","Deep Learning; Humans; Neural Networks (Computer); Robotics; Social Skills; User-Computer Interface; Deep learning; Motivation; Reinforcement learning; Statistical tests; Human like; Intrinsic motivation; Predictive modeling; Real-world; Robot interactions; Social robots; Social skills; Article; controlled study; decision making; human; human experiment; man machine interaction; mathematical model; motivation; normal human; prediction; priority journal; reinforcement; reward; robotics; social competence; task performance; artificial neural network; computer interface; procedures; social competence; Human robot interaction","Elsevier Ltd","08936080","","NNETE","29631753","Article","Scopus","2-s2.0-85044999508"
"Banzato T.; Bernardini M.; Cherubini G.B.; Zotti A.","Banzato, Tommaso (26323554400); Bernardini, Marco (7005635653); Cherubini, Giunio B. (8284321000); Zotti, Alessandro (7003376347)","26323554400; 7005635653; 8284321000; 7003376347","A methodological approach for deep learning to distinguish between meningiomas and gliomas on canine MR-images","2018","BMC Veterinary Research","40","10.1186/s12917-018-1638-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055204750&doi=10.1186%2fs12917-018-1638-2&partnerID=40&md5=281bdd9d196fb4d4d6047baf3bb6f816","Department of Animal Medicine, Production and Health, University of Padua, Viale dell'Università 16, AGRIPOLIS, Legnaro, Padua, 35020, Italy; Portoni Rossi Veterinary Hospital, Via Roma 57, Zola Predosa, Bologna, 40069, Italy; Dick White Referrals, Six Mile Bottom, Cambridgeshire, CB8 0UH, United Kingdom","Banzato T., Department of Animal Medicine, Production and Health, University of Padua, Viale dell'Università 16, AGRIPOLIS, Legnaro, Padua, 35020, Italy; Bernardini M., Department of Animal Medicine, Production and Health, University of Padua, Viale dell'Università 16, AGRIPOLIS, Legnaro, Padua, 35020, Italy, Portoni Rossi Veterinary Hospital, Via Roma 57, Zola Predosa, Bologna, 40069, Italy; Cherubini G.B., Dick White Referrals, Six Mile Bottom, Cambridgeshire, CB8 0UH, United Kingdom; Zotti A., Department of Animal Medicine, Production and Health, University of Padua, Viale dell'Università 16, AGRIPOLIS, Legnaro, Padua, 35020, Italy","Background: Distinguishing between meningeal-based and intra-axial lesions by means of magnetic resonance (MR) imaging findings may occasionally be challenging. Meningiomas and gliomas account for most of the total primary brain neoplasms in dogs, and differentiating between these two forms is mandatory in choosing the correct therapy. The aims of the present study are: 1) to determine the accuracy of a deep convolutional neural network (CNN, GoogleNet) in discriminating between meningiomas and gliomas in pre- and post-contrast T1 images and T2 images; 2) to develop an image classifier, based on the combination of CNN and MRI sequence displaying the highest accuracy, to predict whether a lesion is a meningioma or a glioma. Results: Eighty cases with a final diagnosis of meningioma (n = 56) and glioma (n = 24) from two different institutions were included in the study. A pre-trained CNN was retrained on our data through a process called transfer learning. To evaluate CNN accuracy in the different imaging sequences, the dataset was divided into a training, a validation and a test set. The accuracy of the CNN was calculated on the test set. The combination between post-contrast T1 images and CNN was chosen in developing the image classifier (trCNN). Ten images from challenging cases were excluded from the database in order to test trCNN accuracy; the trCNN was trained on the remainder of the dataset of post-contrast T1 images, and correctly classified all the selected images. To compensate for the imbalance between meningiomas and gliomas in the dataset, the Matthews correlation coefficient (MCC) was also calculated. The trCNN showed an accuracy of 94% (MCC = 0.88) on post-contrast T1 images, 91% (MCC = 0.81) on pre-contrast T1-images and 90% (MCC = 0.8) on T2 images. Conclusions: The developed trCNN could be a reliable tool in distinguishing between different meningiomas and gliomas from MR images. © 2018 The Author(s).","Convolutional neural network; Glioma; Histopathology; Magnetic resonance imaging; Meningioma","Animals; Brain Neoplasms; Diagnosis, Differential; Dog Diseases; Dogs; Glioma; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Meningioma; Neural Networks (Computer); accuracy; Article; artificial neural network; clinical article; convolutional neural network; glioma; histopathology; human; human tissue; image analysis; learning; meningioma; nuclear magnetic resonance imaging; sensitivity and specificity; trained convolutional neural network; animal; artificial neural network; brain tumor; computer assisted diagnosis; diagnostic imaging; differential diagnosis; dog; dog disease; glioma; image processing; machine learning; meningioma; nuclear magnetic resonance imaging; procedures; veterinary medicine","BioMed Central Ltd.","17466148","","","30348148","Article","Scopus","2-s2.0-85055204750"
"Tsubaki M.; Mizoguchi T.","Tsubaki, Masashi (57206022071); Mizoguchi, Teruyasu (7201437776)","57206022071; 7201437776","Fast and Accurate Molecular Property Prediction: Learning Atomic Interactions and Potentials with Neural Networks","2018","Journal of Physical Chemistry Letters","18","10.1021/acs.jpclett.8b01837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052301498&doi=10.1021%2facs.jpclett.8b01837&partnerID=40&md5=be0bed6dd41be44b5709106330808a40","National Institute of Advanced Industrial Science and Technology (AIST), Tokyo Waterfront General BIO-IT Research Building, 2-3-26 Aomi, Koto-ku, Tokyo, 135-0064, Japan; Institute of Industrial Science, University of Tokyo, 4-6-1 Komaba, Meguro-Ku, Tokyo, 153-8505, Japan","Tsubaki M., National Institute of Advanced Industrial Science and Technology (AIST), Tokyo Waterfront General BIO-IT Research Building, 2-3-26 Aomi, Koto-ku, Tokyo, 135-0064, Japan; Mizoguchi T., Institute of Industrial Science, University of Tokyo, 4-6-1 Komaba, Meguro-Ku, Tokyo, 153-8505, Japan","The discovery of molecules with specific properties is crucial to developing effective materials and useful drugs. Recently, to accelerate such discoveries with machine learning, deep neural networks (DNNs) have been applied to quantum chemistry calculations based on the density functional theory (DFT). While various DNNs for quantum chemistry have been proposed, these networks require various chemical descriptors as inputs and a large number of learning parameters to model atomic interactions. In this paper, we propose a new DNN-based molecular property prediction that (i) does not depend on descriptors, (ii) is more compact, and (iii) involves additional neural networks to model the interactions between all the atoms in a molecular structure. In the consideration of the molecular structure, we also model the potentials between all the atoms; this allows the neural networks to simultaneously learn the atomic interactions and potentials. We emphasize that these atomic ""pair"" interactions and potentials are characterized using the global molecular structure, a function of the depth of the neural networks; this leads to the implicit or indirect consideration of atomic ""many-body"" interactions and potentials within the DNNs. In the evaluation of our model with the benchmark QM9 data set, we achieved fast and accurate prediction performances for various quantum chemical properties. In addition, we analyzed the effects of learning the interactions and potentials on each property. Furthermore, we demonstrated an extrapolation evaluation, i.e., we trained a model with small molecules and tested it with large molecules. We believe that insights into the extrapolation evaluation will be useful for developing more practical applications in DNN-based molecular property predictions. © 2018 American Chemical Society.","","Atoms; Density functional theory; Extrapolation; Forecasting; Molecular structure; Molecules; Quantum chemistry; Accurate prediction; Atomic interactions; Chemical descriptors; Effective materials; Learning parameters; Molecular properties; Quantum chemistry calculations; Specific properties; Deep neural networks","American Chemical Society","19487185","","","30081630","Article","Scopus","2-s2.0-85052301498"
"Sodmann P.; Vollmer M.; Nath N.; Kaderali L.","Sodmann, Philipp (57201496686); Vollmer, Marcus (57191278321); Nath, Neetika (57200505844); Kaderali, Lars (57210104492)","57201496686; 57191278321; 57200505844; 57210104492","A convolutional neural network for ECG annotation as the basis for classification of cardiac rhythms","2018","Physiological Measurement","69","10.1088/1361-6579/aae304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055907619&doi=10.1088%2f1361-6579%2faae304&partnerID=40&md5=1437445ff5d5929fc05633a3b449a748","Institute of Bioinformatics, University Medicine Greifswald, Greifswald, Germany; DZHK (German Center for Cardiological Research), Partner Site Greifswald, Greifswald, Germany","Sodmann P., Institute of Bioinformatics, University Medicine Greifswald, Greifswald, Germany, DZHK (German Center for Cardiological Research), Partner Site Greifswald, Greifswald, Germany; Vollmer M., Institute of Bioinformatics, University Medicine Greifswald, Greifswald, Germany, DZHK (German Center for Cardiological Research), Partner Site Greifswald, Greifswald, Germany; Nath N., Institute of Bioinformatics, University Medicine Greifswald, Greifswald, Germany; Kaderali L., Institute of Bioinformatics, University Medicine Greifswald, Greifswald, Germany, DZHK (German Center for Cardiological Research), Partner Site Greifswald, Greifswald, Germany","Objective: Electrocardiography is the most common tool to diagnose cardiovascular diseases. Annotation, segmentation and rhythm classification of ECGs are challenging tasks, especially in the presence of atrial fibrillation and other arrhythmias. Our aim is to increase the accuracy of heart rhythm estimation by the use of extreme gradient boosting trees and the development of a deep convolutional neural network for ECG segmentation. Approach: We trained a convolutional neural network with waveforms from PhysioNet databases to annotate QRS complexes, P waves, T waves, noise and interbeat ECG segments that characterize the essences of normal and irregular heart beats. We evaluated true positive rates, positive predictive values and mean absolute differences of our annotation based on reference annotations of the QT and MIT-BIH P-wave database. Moreover, we compared the results with standard QRS detectors and Ecgpuwave. Extreme gradient boosting trees were used to determine the heart rhythm based on hand-crafted features. More precisely, a noise estimation function was used in combination with heart rate and interval data. Furthermore we defined particular features based on ECG morphology, appearance of P waves and detection of irregular beats. We examined the feature importance and identified key features for normal sinus rhythm, atrial fibrillation, alternative rhythm and noisy recordings. The classification performance was evaluated externally using F 1 scores by applying the algorithm to the hidden test set provided by the PhysioNet/CinC Challenge 2017. Main results: The true positive rate of the convolutional neural network in detection of manually revised R peaks in the QT database was and the positive predictive value was . The detection of P and T waves reached a true positive rate of and respectively, given a 50 ms tolerance when comparing the reference to the test annotation set. The rhythm classification performance reached an overall F 1 score of 0.82 when applying the algorithm to the hidden test set. Significance: We achieved a shared rank #9 in the post-challenge phase of the PhysioNet/CinC Challenge 2017. © 2018 Institute of Physics and Engineering in Medicine.","convolutional neural network; deep learning; ECG; ECG annotation; heart rhythm; machine learning; XGBoost","Artifacts; Atrial Fibrillation; Diagnosis, Computer-Assisted; Electrocardiography; Heart Rate; Humans; Neural Networks (Computer); Sensitivity and Specificity; Supervised Machine Learning; Cardiology; Classification (of information); Convolution; Database systems; Deep neural networks; Diseases; Forestry; Heart; Seismic waves; Atrial fibrillation; Convolutional neural network; Deep learning; ECG annotation; Gradient boosting; Heart rhythm; P waves; PhysioNet; True positive rates; Xgboost; artifact; artificial neural network; atrial fibrillation; computer assisted diagnosis; electrocardiography; evaluation study; heart rate; human; procedures; sensitivity and specificity; supervised machine learning; Electrocardiography","IOP Publishing Ltd","09673334","","PMEAE","30235165","Article","Scopus","2-s2.0-85055907619"
"Kim J.; Kim H.; Huh S.; Lee J.; Choi K.","Kim, Jaehyun (58165567600); Kim, Heesu (57196215747); Huh, Subin (57202419047); Lee, Jinho (55020581200); Choi, Kiyoung (7403949508)","58165567600; 57196215747; 57202419047; 55020581200; 7403949508","Deep neural networks with weighted spikes","2018","Neurocomputing","85","10.1016/j.neucom.2018.05.087","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048261932&doi=10.1016%2fj.neucom.2018.05.087&partnerID=40&md5=2e85bd07dfa8a3eca580ab2fbbf134ba","Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; IBM Research, Burnet Rd, Austin, 11501, TX, United States","Kim J., Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Kim H., Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Huh S., Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Lee J., IBM Research, Burnet Rd, Austin, 11501, TX, United States; Choi K., Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea","Spiking neural networks are being regarded as one of the promising alternative techniques to overcome the high energy costs of artificial neural networks. It is supported by many researches showing that a deep convolutional neural network can be converted into a spiking neural network with near zero accuracy loss. However, the advantage on energy consumption of spiking neural networks comes at a cost of long classification latency due to the use of Poisson-distributed spike trains (rate coding), especially in deep networks. In this paper, we propose to use weighted spikes, which can greatly reduce the latency by assigning a different weight to a spike depending on which time phase it belongs. Experimental results on MNIST, SVHN, CIFAR-10, and CIFAR-100 show that the proposed spiking neural networks with weighted spikes achieve significant reduction in classification latency and number of spikes, which leads to faster and more energy-efficient spiking neural networks than the conventional spiking neural networks with rate coding. We also show that one of the state-of-the-art networks the deep residual network can be converted into spiking neural network without accuracy loss. © 2018 Elsevier B.V.","Spiking neural network; Supervised learning; Weighted spike","Energy efficiency; Energy utilization; Intelligent agents; Neural networks; Supervised learning; Accuracy loss; Deep convolutional neural networks; Deep networks; Energy efficient; High-energy costs; Spiking neural networks; State of the art; Weighted spike; Article; artificial neural network; classification; latent period; mathematical parameters; measurement accuracy; priority journal; spiking neural network; supervised machine learning; weighted spike; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85048261932"
"Zhang J.; Wu Y.","Zhang, Junming (56288904500); Wu, Yan (56991563200)","56288904500; 56991563200","Complex-valued unsupervised convolutional neural networks for sleep stage classification","2018","Computer Methods and Programs in Biomedicine","43","10.1016/j.cmpb.2018.07.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050990647&doi=10.1016%2fj.cmpb.2018.07.015&partnerID=40&md5=677aa551e1efbb1383c71984bbcc9b81","College of Electronics & Information Engineering, Tongji University, Shanghai, 201804, China","Zhang J., College of Electronics & Information Engineering, Tongji University, Shanghai, 201804, China; Wu Y., College of Electronics & Information Engineering, Tongji University, Shanghai, 201804, China","Background and objective: Despite numerous deep learning methods being developed for automatic sleep stage classification, almost all the models need labeled data. However, obtaining labeled data is a subjective process. Therefore, the labels will be different between two experts. At the same time, obtaining labeled data also is a time-consuming task. Even an experienced expert requires hours to annotate the sleep stage patterns. More important, as the development of wearable sleep devices, it is very difficult to obtain labeled sleep data. Therefore, unsupervised training algorithm is very important for sleep stage classification. Hence, a new sleep stage classification method named complex-valued unsupervised convolutional neural networks (CUCNN) is proposed in this study. Methods: The CUCNN operates with complex-valued inputs, outputs, and weights, and its training strategy is greedy layer-wise training. It is composed of three phases: phase encoder, unsupervised training and complex-valued classification. Phase encoder is used to translate real-valued inputs into complex numbers. In the unsupervised training phase, the complex-valued K-means is used to learn filters which will be used in the convolution. Results: The classification performances of handcrafted features are compared with those of learned features via CUCNN. The total accuracy (TAC) and kappa coefficient of the sleep stage from UCD dataset are 87% and 0.8, respectively. Moreover, the comparison experiments indicate that the TACs of the CUCNN from UCD and MIT-BIH datasets outperform these of unsupervised convolutional neural networks (UCNN) by 12.9% and 13%, respectively. Additionally, the convergence of CUCNN is much faster than that of UCNN in most cases. Conclusions: The proposed method is fully automated and can learn features in an unsupervised fashion. Results show that unsupervised training and automatic feature extraction on sleep data are possible, which are very important for home sleep monitoring. © 2018 Elsevier B.V.","Complex-valued convolutional neural networks; Complex-valued k-means; EEG; Sleep stage; Unsupervised training","Adult; Aged; Algorithms; Databases, Factual; Deep Learning; Electroencephalography; Female; Humans; Male; Middle Aged; Neural Networks (Computer); Sleep Stages; Unsupervised Machine Learning; Wearable Electronic Devices; Complex networks; Convolution; Deep learning; Electroencephalography; Neural networks; Signal encoding; Sleep research; Automatic feature extraction; Classification methods; Classification performance; Convolutional neural network; K-means; Sleep stage; Time-consuming tasks; Unsupervised training; Article; artificial neural network; classification; classification algorithm; clinical article; comparative study; complex valued unsupervised convolutional neural network; controlled study; electroencephalogram; feature extraction; home monitoring; human; kappa statistics; polysomnography; sleep disordered breathing; sleep stage; training; unsupervised machine learning; adult; aged; algorithm; devices; electroencephalography; electronic device; evaluation study; factual database; female; male; middle aged; statistics and numerical data; unsupervised machine learning; Data mining","Elsevier Ireland Ltd","01692607","","CMPBE","30195426","Article","Scopus","2-s2.0-85050990647"
"Harangi B.","Harangi, Balazs (36198305300)","36198305300","Skin lesion classification with ensembles of deep convolutional neural networks","2018","Journal of Biomedical Informatics","267","10.1016/j.jbi.2018.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052633192&doi=10.1016%2fj.jbi.2018.08.006&partnerID=40&md5=976b6f7af1e908dca4d1dbd7b68c53df","Faculty of Informatics, University of Debrecen, POB 400, Debrecen, 4002, Hungary","Harangi B., Faculty of Informatics, University of Debrecen, POB 400, Debrecen, 4002, Hungary","Skin cancer is a major public health problem with over 123,000 newly diagnosed cases worldwide in every year. Melanoma is the deadliest form of skin cancer, responsible for over 9000 deaths in the United States each year. Thus, reliable automatic melanoma screening systems would provide a great help for clinicians to detect the malignant skin lesions as early as possible. In the last five years, the efficiency of deep learning-based methods increased dramatically and their performances seem to outperform conventional image processing methods in classification tasks. However, this type of machine learning-based approaches have a main drawback, namely they require thousands of labeled images per classes for their training. In this paper, we investigate how we can create an ensemble of deep convolutional neural networks to improve further their individual accuracies in the task of classifying dermoscopy images into the three classes melanoma, nevus, and seborrheic keratosis when we have no opportunity to train them on adequate number of annotated images. To achieve high classification accuracy, we fuse the outputs of the classification layers of four different deep neural network architectures. More specifically, we propose the aggregation of robust convolutional neural networks (CNNs) into one framework, where the final classification is achieved based on the weighted output of the member CNNs. For aggregation, we consider different fusion-based methods and select the best performing one for this problem. Our experimental results also prove that the creation of an ensemble of different neural networks is a meaningful approach, since each of the applied fusion strategies outperforms the individual networks regarding classification accuracy. The average area under the receiver operating characteristic curve has been found to be 0.891 for the 3-class classification task. For an objective evaluation of our approach, we have tested its performance on the official test database of the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 challenge on Skin Lesion Analysis Towards Melanoma Detection dedicated to skin cancer recognition. © 2018 Elsevier Inc.","Deep convolutional neural network; Ensemble-based system; Information fusion; Melanoma detection","Algorithms; Databases, Factual; Dermoscopy; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Keratosis, Seborrheic; Machine Learning; Melanocytes; Melanoma; Neural Networks (Computer); Nevus; ROC Curve; Skin Neoplasms; Convolution; Dermatology; Diagnosis; Diseases; Image classification; Image enhancement; Information fusion; Learning algorithms; Medical imaging; Network architecture; Neural networks; Oncology; Classification accuracy; Convolutional neural network; Deep convolutional neural networks; Ensemble-based systems; Image processing - methods; Learning-based methods; Melanoma detection; Receiver operating characteristic curves; algorithm; area under the curve; Article; artificial neural network; convolutional neural network; deep convolutional neural network; epiluminescence microscopy; genetic algorithm; measurement accuracy; melanoma; nevus; priority journal; receiver operating characteristic; seborrheic keratosis; sensitivity and specificity; simulated annealing algorithm; stochastic gradient descent algorithm; theoretical model; computer assisted diagnosis; diagnostic imaging; factual database; human; image processing; machine learning; melanocyte; melanoma; nevus; pathology; procedures; seborrheic keratosis; skin tumor; Deep neural networks","Academic Press Inc.","15320464","","JBIOB","30103029","Article","Scopus","2-s2.0-85052633192"
"Küstner T.; Gatidis S.; Liebgott A.; Schwartz M.; Mauch L.; Martirosian P.; Schmidt H.; Schwenzer N.F.; Nikolaou K.; Bamberg F.; Yang B.; Schick F.","Küstner, T. (56549927000); Gatidis, S. (26658018800); Liebgott, A. (57189597296); Schwartz, M. (57199182657); Mauch, L. (55762682000); Martirosian, P. (6506369484); Schmidt, H. (14024984100); Schwenzer, N.F. (12783996100); Nikolaou, K. (55744104000); Bamberg, F. (23975531900); Yang, B. (55584795030); Schick, F. (7004668646)","56549927000; 26658018800; 57189597296; 57199182657; 55762682000; 6506369484; 14024984100; 12783996100; 55744104000; 23975531900; 55584795030; 7004668646","A machine-learning framework for automatic reference-free quality assessment in MRI","2018","Magnetic Resonance Imaging","43","10.1016/j.mri.2018.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050778340&doi=10.1016%2fj.mri.2018.07.003&partnerID=40&md5=2fd6152b4f3ff314df3883a6070c0c22","Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany; Department of Radiology, University of Tübingen, Tübingen, Germany; Section on Experimental Radiology, University of Tübingen, Germany","Küstner T., Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany, Section on Experimental Radiology, University of Tübingen, Germany; Gatidis S., Department of Radiology, University of Tübingen, Tübingen, Germany; Liebgott A., Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany, Department of Radiology, University of Tübingen, Tübingen, Germany; Schwartz M., Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany, Section on Experimental Radiology, University of Tübingen, Germany; Mauch L., Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany; Martirosian P., Section on Experimental Radiology, University of Tübingen, Germany; Schmidt H., Department of Radiology, University of Tübingen, Tübingen, Germany; Schwenzer N.F., Department of Radiology, University of Tübingen, Tübingen, Germany; Nikolaou K., Department of Radiology, University of Tübingen, Tübingen, Germany; Bamberg F., Department of Radiology, University of Tübingen, Tübingen, Germany; Yang B., Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany; Schick F., Section on Experimental Radiology, University of Tübingen, Germany","Magnetic resonance (MR) imaging offers a wide variety of imaging techniques. A large amount of data is created per examination which needs to be checked for sufficient quality in order to derive a meaningful diagnosis. This is a manual process and therefore time- and cost-intensive. Any imaging artifacts originating from scanner hardware, signal processing or induced by the patient may reduce the image quality and complicate the diagnosis or any image post-processing. Therefore, the assessment or the ensurance of sufficient image quality in an automated manner is of high interest. Usually no reference image is available or difficult to define. Therefore, classical reference-based approaches are not applicable. Model observers mimicking the human observers (HO) can assist in this task. Thus, we propose a new machine-learning-based reference-free MR image quality assessment framework which is trained on HO-derived labels to assess MR image quality immediately after each acquisition. We include the concept of active learning and present an efficient blinded reading platform to reduce the effort in the HO labeling procedure. Derived image features and the applied classifiers (support-vector-machine, deep neural network) are investigated for a cohort of 250 patients. The MR image quality assessment framework can achieve a high test accuracy of 93.7% for estimating quality classes on a 5-point Likert-scale. The proposed MR image quality assessment framework is able to provide an accurate and efficient quality estimation which can be used as a prospective quality assurance including automatic acquisition adaptation or guided MR scanner operation, and/or as a retrospective quality assessment including support of diagnostic decisions or quality control in cohort studies. © 2018 Elsevier Inc.","Deep learning; Image quality assessment; Machine-learning; Magnetic resonance imaging; Non-reference/blind","Adult; Aged; Databases, Factual; Deep Learning; Female; Fourier Analysis; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Neural Networks (Computer); Observer Variation; Prospective Studies; Retrospective Studies; ROC Curve; Signal Processing, Computer-Assisted; Support Vector Machine; Article; artificial neural network; cohort analysis; conceptual framework; controlled study; data analysis; human; image analysis; image processing; image quality; Likert scale; machine learning; measurement accuracy; nuclear magnetic resonance imaging; principal component analysis; priority journal; quality control; retrospective study; signal processing; support vector machine; task performance; adult; aged; factual database; female; Fourier analysis; male; middle aged; observer variation; procedures; prospective study; receiver operating characteristic; support vector machine","Elsevier Inc.","0730725X","","MRIMD","30036653","Article","Scopus","2-s2.0-85050778340"
"Putin E.; Asadulaev A.; Vanhaelen Q.; Ivanenkov Y.; Aladinskaya A.V.; Aliper A.; Zhavoronkov A.","Putin, Evgeny (57189310406); Asadulaev, Arip (57202188009); Vanhaelen, Quentin (54790233000); Ivanenkov, Yan (6508137923); Aladinskaya, Anastasia V. (57185845700); Aliper, Alex (54889030500); Zhavoronkov, Alex (39862415800)","57189310406; 57202188009; 54790233000; 6508137923; 57185845700; 54889030500; 39862415800","Adversarial Threshold Neural Computer for Molecular de Novo Design","2018","Molecular Pharmaceutics","142","10.1021/acs.molpharmaceut.7b01137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053318904&doi=10.1021%2facs.molpharmaceut.7b01137&partnerID=40&md5=b3f21b4c52ab4e7924af15d5e7658deb","Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States; Computer Technologies Lab, ITMO University, St. Petersburg, 197101, Russian Federation; Moscow Institute of Physics and Technology, State University, 9 Institutskiy Lane, Dolgoprudny City, Moscow Region, 141700, Russian Federation; Institute of Biochemistry and Genetics Russian, Academy of Science (IBG RAS), Ufa Scientific Centre, Oktyabrya Prospekt 71, Ufa, 450054, Russian Federation; Biogerontology Research Foundation, Oxford, OX1 1RU, United Kingdom","Putin E., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States, Computer Technologies Lab, ITMO University, St. Petersburg, 197101, Russian Federation; Asadulaev A., Computer Technologies Lab, ITMO University, St. Petersburg, 197101, Russian Federation; Vanhaelen Q., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States; Ivanenkov Y., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States, Moscow Institute of Physics and Technology, State University, 9 Institutskiy Lane, Dolgoprudny City, Moscow Region, 141700, Russian Federation, Institute of Biochemistry and Genetics Russian, Academy of Science (IBG RAS), Ufa Scientific Centre, Oktyabrya Prospekt 71, Ufa, 450054, Russian Federation; Aladinskaya A.V., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States, Moscow Institute of Physics and Technology, State University, 9 Institutskiy Lane, Dolgoprudny City, Moscow Region, 141700, Russian Federation; Aliper A., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States; Zhavoronkov A., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States, Biogerontology Research Foundation, Oxford, OX1 1RU, United Kingdom","                             In this article, we propose the deep neural network Adversarial Threshold Neural Computer (ATNC). The ATNC model is intended for the de novo design of novel small-molecule organic structures. The model is based on generative adversarial network architecture and reinforcement learning. ATNC uses a Differentiable Neural Computer as a generator and has a new specific block, called adversarial threshold (AT). AT acts as a filter between the agent (generator) and the environment (discriminator + objective reward functions). Furthermore, to generate more diverse molecules we introduce a new objective reward function named Internal Diversity Clustering (IDC). In this work, ATNC is tested and compared with the ORGANIC model. Both models were trained on the SMILES string representation of the molecules, using four objective functions (internal similarity, Muegge druglikeness filter, presence or absence of sp                             3                             -rich fragments, and IDC). The SMILES representations of 15K druglike molecules from the ChemDiv collection were used as a training data set. For the different functions, ATNC outperforms ORGANIC. Combined with the IDC, ATNC generates 72% of valid and 77% of unique SMILES strings, while ORGANIC generates only 7% of valid and 86% of unique SMILES strings. For each set of molecules generated by ATNC and ORGANIC, we analyzed distributions of four molecular descriptors (number of atoms, molecular weight, logP, and tpsa) and calculated five chemical statistical features (internal diversity, number of unique heterocycles, number of clusters, number of singletons, and number of compounds that have not been passed through medicinal chemistry filters). Analysis of key molecular descriptors and chemical statistical features demonstrated that the molecules generated by ATNC elicited better druglikeness properties. We also performed in vitro validation of the molecules generated by ATNC; results indicated that ATNC is an effective method for producing hit compounds.                          © 2018 American Chemical Society.","deep neural network; generative adversarial network; molecular de novo design; reinforcement learning","Machine Learning; Neural Networks (Computer); new drug; adversarial threshold neural computer; Article; chemical analysis; in vitro study; machine learning; model; priority journal; statistical analysis; artificial neural network","American Chemical Society","15438384","","MPOHB","29569445","Article","Scopus","2-s2.0-85053318904"
"Hu C.; Wu Q.; Li H.; Jian S.; Li N.; Lou Z.","Hu, Caihong (56267117300); Wu, Qiang (57196087430); Li, Hui (57206829018); Jian, Shengqi (53986329100); Li, Nan (57206693527); Lou, Zhengzheng (36572300400)","56267117300; 57196087430; 57206829018; 53986329100; 57206693527; 36572300400","Deep learning with a long short-term memory networks approach for rainfall-runoff simulation","2018","Water (Switzerland)","354","10.3390/w10111543","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055787858&doi=10.3390%2fw10111543&partnerID=40&md5=621233639fb6190f77aebade8d48e10a","School ofWater Conservancy and Environment, Zhengzhou University, Zhengzhou, 450001, China; School of Information Engineering, Zhengzhou University, Zhengzhou, 450001, China","Hu C., School ofWater Conservancy and Environment, Zhengzhou University, Zhengzhou, 450001, China; Wu Q., School ofWater Conservancy and Environment, Zhengzhou University, Zhengzhou, 450001, China; Li H., School of Information Engineering, Zhengzhou University, Zhengzhou, 450001, China; Jian S., School ofWater Conservancy and Environment, Zhengzhou University, Zhengzhou, 450001, China; Li N., School ofWater Conservancy and Environment, Zhengzhou University, Zhengzhou, 450001, China; Lou Z., School of Information Engineering, Zhengzhou University, Zhengzhou, 450001, China","Considering the high random and non-static property of the rainfall-runoff process, lots of models are being developed in order to learn about such a complex phenomenon. Recently, Machine learning techniques such as the Artificial Neural Network (ANN) and other networks have been extensively used by hydrologists for rainfall-runoff modelling as well as for other fields of hydrology. However, deep learning methods such as the state-of-the-art for LSTM networks are little studied in hydrological sequence time-series predictions. We deployed ANN and LSTM network models for simulating the rainfall-runoff process based on flood events from 1971 to 2013 in Fen River basin monitored through 14 rainfall stations and one hydrologic station in the catchment. The experimental data were from 98 rainfall-runoff events in this period. In between 86 rainfall-runoff events were used as training set, and the rest were used as test set. The results show that the two networks are all suitable for rainfall-runoff models and better than conceptual and physical based models. LSTM models outperform the ANN models with the values of R2 and NSE beyond 0.9, respectively. Considering different lead time modelling the LSTM model is also more stable than ANN model holding better simulation performance. The special units of forget gate makes LSTM model better simulation and more intelligent than ANN model. In this study, we want to propose new data-driven methods for flood forecasting. © 2018 by the authors.","Flood events; LSTM; Rainfall-runoff","China; Fen River; Shanxi; Catchments; Deep learning; Flood control; Floods; Rain; Runoff; Flood event; LSTM; Machine learning techniques; Rainfall - Runoff modelling; Rainfall runoff; Rainfall-runoff events; Rainfall-runoff process; Rainfall-runoff simulations; algorithm; artificial neural network; catchment; flood; flood forecasting; machine learning; rainfall-runoff modeling; simulation; Long short-term memory","MDPI AG","20734441","","","","Article","Scopus","2-s2.0-85055787858"
"Li C.; Deng C.; Zhou S.; Zhao B.; Huang G.-B.","Li, Cheng (57188820563); Deng, Chenwei (25958671000); Zhou, Shichao (56828414700); Zhao, Baojun (7403059245); Huang, Guang-Bin (7403425167)","57188820563; 25958671000; 56828414700; 7403059245; 7403425167","Conditional Random Mapping for Effective ELM Feature Representation","2018","Cognitive Computation","7","10.1007/s12559-018-9557-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046824283&doi=10.1007%2fs12559-018-9557-x&partnerID=40&md5=db4303479925fb224c9c05733ce881e2","School of Information and Electronics, Beijing Institute of Technology, 5 South Zhongguancun Street, Haidian District, Beijing, China; School of EEE, Nanyang Technological University, Singapore, Singapore","Li C., School of Information and Electronics, Beijing Institute of Technology, 5 South Zhongguancun Street, Haidian District, Beijing, China; Deng C., School of Information and Electronics, Beijing Institute of Technology, 5 South Zhongguancun Street, Haidian District, Beijing, China; Zhou S., School of Information and Electronics, Beijing Institute of Technology, 5 South Zhongguancun Street, Haidian District, Beijing, China; Zhao B., School of Information and Electronics, Beijing Institute of Technology, 5 South Zhongguancun Street, Haidian District, Beijing, China; Huang G.-B., School of EEE, Nanyang Technological University, Singapore, Singapore","Extreme learning machine (ELM) has been extensively studied, due to its fast training and good generalization. Unfortunately, the existing ELM-based feature representation methods are uncompetitive with state-of-the-art deep neural networks (DNNs) when conducting some complex visual recognition tasks. This weakness is mainly caused by two critical defects: (1) random feature mappings (RFM) by ad hoc probability distribution is unable to well project various input data into discriminative feature spaces; (2) in the ELM-based hierarchical architectures, features from previous layer are scattered via RFM in the current layer, which leads to abstracting higher level features ineffectively. To address these issues, we aim to take advantage of label information for optimizing random mapping in the ELM, utilizing an efficient label alignment metric to learn a conditional random feature mapping (CRFM) in a supervised manner. Moreover, we proposed a new CRFM-based single-layer ELM (CELM) and then extended CELM to the supervised multi-layer learning architecture (ML-CELM). Extensive experiments on various widely used datasets demonstrate our approach is more effective than original ELM-based and other existing DNN feature representation methods with rapid training/testing speed. The proposed CELM and ML-CELM are able to achieve discriminative and robust feature representation, and have shown superiority in various simulations in terms of generalization and speed. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","CELM; Conditional random feature mapping; Extreme learning machine; ML-CELM","Deep neural networks; Knowledge acquisition; Network architecture; Probability distributions; CELM; Discriminative features; Extreme learning machine; Feature representation; Hierarchical architectures; Learning architectures; ML-CELM; Random features; Mapping","Springer New York LLC","18669956","","","","Article","Scopus","2-s2.0-85046824283"
"Mauldin T.R.; Canby M.E.; Metsis V.; Ngu A.H.H.; Rivera C.C.","Mauldin, Taylor R. (57204160040); Canby, Marc E. (57204162651); Metsis, Vangelis (25923561200); Ngu, Anne H. H. (57204339312); Rivera, Coralys Cubero (57204156629)","57204160040; 57204162651; 25923561200; 57204339312; 57204156629","Smartfall: A smartwatch-based fall detection system using deep learning","2018","Sensors (Switzerland)","174","10.3390/s18103363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054727788&doi=10.3390%2fs18103363&partnerID=40&md5=9d1bd04c42015c15f6db44e7cdca53b8","Department of Computer Science, Texas State University, San Marcos, 78666, TX, United States; Department of Computer Science, Rice University, Houston, 77005, TX, United States; Department of Computer Science, University of Puerto Rico, San Juan, 00927, Puerto Rico","Mauldin T.R., Department of Computer Science, Texas State University, San Marcos, 78666, TX, United States; Canby M.E., Department of Computer Science, Rice University, Houston, 77005, TX, United States; Metsis V., Department of Computer Science, Texas State University, San Marcos, 78666, TX, United States; Ngu A.H.H., Department of Computer Science, Texas State University, San Marcos, 78666, TX, United States; Rivera C.C., Department of Computer Science, University of Puerto Rico, San Juan, 00927, Puerto Rico","This paper presents SmartFall, an Android app that uses accelerometer data collected from a commodity-based smartwatch Internet of Things (IoT) device to detect falls. The smartwatch is paired with a smartphone that runs the SmartFall application, which performs the computation necessary for the prediction of falls in real time without incurring latency in communicating with a cloud server, while also preserving data privacy. We experimented with both traditional (Support Vector Machine and Naive Bayes) and non-traditional (Deep Learning) machine learning algorithms for the creation of fall detection models using three different fall datasets (Smartwatch, Notch, Farseeing). Our results show that a Deep Learning model for fall detection generally outperforms more traditional models across the three datasets. This is attributed to the Deep Learning model’s ability to automatically learn subtle features from the raw accelerometer data that are not available to Naive Bayes and Support Vector Machine, which are restricted to learning from a small set of extracted features manually specified. Furthermore, the Deep Learning model exhibits a better ability to generalize to new users when predicting falls, an important quality of any model that is to be successful in the real world. We also present a three-layer open IoT system architecture used in SmartFall, which can be easily adapted for the collection and analysis of other sensor data modalities (e.g., heart rate, skin temperature, walking patterns) that enables remote monitoring of a subject’s wellbeing. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Fall detection; IoT application; IoT architecture; Recurrent neural network; Smart health; Smartwatch","Accelerometers; Classifiers; Data mining; Data privacy; Internet of things; Learning algorithms; Network architecture; Patient monitoring; Recurrent neural networks; Support vector machines; Wearable computers; Accelerometer data; Fall detection; Internet of Things (IOT); IOT applications; Iot architectures; Smartwatch; System architectures; Traditional models; Deep learning","MDPI AG","14248220","","","30304768","Article","Scopus","2-s2.0-85054727788"
"Gonzalez J.A.; Green P.D.","Gonzalez, Jose A. (57210179376); Green, Phil D. (7402935470)","57210179376; 7402935470","A real-time silent speech system for voice restoration after total laryngectomy; [Un sistema de voz silenciosa en tiempo real para la restauración de la voz después de la laringectomía total]","2018","Revista de Logopedia, Foniatria y Audiologia","4","10.1016/j.rlfa.2018.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053186958&doi=10.1016%2fj.rlfa.2018.07.004&partnerID=40&md5=b759bca389bdf5776e2f62ebbddad96a","Department of Languages and Computer Sciences, University of Malaga, Malaga, Spain; Department of Computer Science, University of Sheffield, Sheffield, United Kingdom","Gonzalez J.A., Department of Languages and Computer Sciences, University of Malaga, Malaga, Spain; Green P.D., Department of Computer Science, University of Sheffield, Sheffield, United Kingdom","Background and aim: Individuals who have lost their voice following a laryngectomy as a treatment for cancer will inevitably struggle with their daily communication. Unfortunately, the current methods for speaking after laryngectomy all have limitations, either because of the poor acoustics generated by these methods or because they are potentially harmful. The aim of this work is thus to explore an alternative method for post-laryngectomy voice restoration in which the movement of the intact articulators is captured and then converted into audible speech using machine learning techniques. Materials and methods: To demonstrate the feasibility of speech generation from captured articulator movement, 6 healthy adults were recruited. For each subject, both the speech acoustics and the subject's articulator movements were recorded simultaneously. Articulator movements were captured using a technique known as permanent magnet articulography (PMA), in which small magnets are attached to the articulators (typically tongue and lips) and the magnetic field generated by the magnets is captured with sensors located close to the mouth. Deep artificial neural networks were then used to model the mapping between the sensor data and the speech acoustics, thus, enabling the synthesis of speech from captured articulatory data. Results: The proposed silent speech system is able to generate speech that sounds natural, resembles the subject's own voice and is fairly intelligible (up to 92% intelligibility for some speakers on a phonetically-rich corpus). Conclusions: With further research, the proposed system could in future be a real option to restore lost voice after laryngectomy. © 2018 Elsevier España, S.L.U. y Asociación Española de Logopedia, Foniatría y Audiología e Iberoamericana de Fonoaudiología","Laryngectomy; Permanent magnet articulography; Silent speech interfaces; Speech rehabilitation; Speech synthesis","","Grupo Ars XXI de Comunicacion, S.L.","02144603","","","","Article","Scopus","2-s2.0-85053186958"
"Fabregat H.; Araujo L.; Martinez-Romo J.","Fabregat, Hermenegildo (57195674110); Araujo, Lourdes (57197210585); Martinez-Romo, Juan (24476245900)","57195674110; 57197210585; 24476245900","Deep neural models for extracting entities and relationships in the new RDD corpus relating disabilities and rare diseases","2018","Computer Methods and Programs in Biomedicine","17","10.1016/j.cmpb.2018.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050546187&doi=10.1016%2fj.cmpb.2018.07.007&partnerID=40&md5=538f70d64c580b422032cb71e2fb24b8","Department of Computer Science, Universidad Nacional de Educación a Distancia (UNED), Juan del Rosal 16, Madrid, 28040, Spain; IMIENS: Instituto Mixto de Investigación, Escuela Nacional de Sanidad, Monforte de Lemos 5, Madrid, 28019, Spain","Fabregat H., Department of Computer Science, Universidad Nacional de Educación a Distancia (UNED), Juan del Rosal 16, Madrid, 28040, Spain; Araujo L., Department of Computer Science, Universidad Nacional de Educación a Distancia (UNED), Juan del Rosal 16, Madrid, 28040, Spain, IMIENS: Instituto Mixto de Investigación, Escuela Nacional de Sanidad, Monforte de Lemos 5, Madrid, 28019, Spain; Martinez-Romo J., Department of Computer Science, Universidad Nacional de Educación a Distancia (UNED), Juan del Rosal 16, Madrid, 28040, Spain, IMIENS: Instituto Mixto de Investigación, Escuela Nacional de Sanidad, Monforte de Lemos 5, Madrid, 28019, Spain","Background and objective: There is a huge amount of rare diseases, many of which have associated important disabilities. It is paramount to know in advance the evolution of the disease in order to limit and prevent the appearance of disabilities and to prepare the patient to manage the future difficulties. Rare disease associations are making an effort to manually collect this information, but it is a long process. A lot of information about the consequences of rare diseases is published in scientific papers, and our goal is to automatically extract disabilities associated with diseases from them. Methods: This work presents a new corpus of abstracts from scientific papers related to rare diseases, which has been manually annotated with disabilities. This corpus allows to train machine and deep learning systems that can automatically process other papers, thus extracting new information about the relations between rare diseases and disabilities. The corpus is also annotated with negation and speculation when they appear affecting disabilities. The corpus has been made publicly accessible. Results: We have devised some experiments using deep learning techniques to show the usefulness of the developed corpus. Specifically, we have designed a long short-term memory based architecture for disabilities identification, as well as a convolutional neural network for detecting their relationships to diseases. The systems designed do not need any preprocessing of the data, but only low dimensional vectors representing the words. Conclusions: The developed corpus will allow to train systems to identify disabilities in biomedical documents, which the current annotation systems are not able to detect. The system could also be trained to detect relationships between them and diseases, as well as negation and speculation, that can change the meaning of the language. The deep learning models designed for identifying disabilities and their relationships to diseases in new documents show that the corpus allows obtaining an F-measure of around 81% for the disability recognition and 75% for relation extraction. © 2018 Elsevier B.V.","Biomedical corpora; Deep neural networks; Disabilities; Entity recognition; Rare diseases; Relationship classification","Data Mining; Databases, Factual; Deep Learning; Disabled Persons; Humans; Natural Language Processing; Neural Networks (Computer); Rare Diseases; Semantics; Deep neural networks; Neural networks; Biomedical corpora; Biomedical documents; Convolutional neural network; Disabilities; Entity recognition; Publicly accessible; Rare disease; Relation extraction; Article; artificial neural network; automation; disability; machine learning; model; rare disease; short term memory; data mining; disabled person; factual database; human; natural language processing; rare disease; semantics; statistics and numerical data; Diseases","Elsevier Ireland Ltd","01692607","","CMPBE","30195420","Article","Scopus","2-s2.0-85050546187"
"Yoon J.; Gong E.; Chatnuntawech I.; Bilgic B.; Lee J.; Jung W.; Ko J.; Jung H.; Setsompop K.; Zaharchuk G.; Kim E.Y.; Pauly J.; Lee J.","Yoon, Jaeyeon (57202549869); Gong, Enhao (56046651600); Chatnuntawech, Itthi (36815595700); Bilgic, Berkin (36469704300); Lee, Jingu (57195610282); Jung, Woojin (57195609922); Ko, Jingyu (57202549369); Jung, Hosan (57202542341); Setsompop, Kawin (15053610500); Zaharchuk, Greg (6602464023); Kim, Eung Yeop (24471039500); Pauly, John (7101724924); Lee, Jongho (57203144252)","57202549869; 56046651600; 36815595700; 36469704300; 57195610282; 57195609922; 57202549369; 57202542341; 15053610500; 6602464023; 24471039500; 7101724924; 57203144252","Quantitative susceptibility mapping using deep neural network: QSMnet","2018","NeuroImage","121","10.1016/j.neuroimage.2018.06.030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048704730&doi=10.1016%2fj.neuroimage.2018.06.030&partnerID=40&md5=23736d9b6552342940497140bbcf25ec","Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical Engineering, Stanford University, Stanford, CA, United States; Department of Radiology, Stanford University, Stanford, CA, United States; National Nanotechnology Center, Pathum Thani, Thailand; Department of Radiology, Harvard Medical School, Boston, MA, United States; Department of Radiology, Gil Medical Center, Gachon University College of Medicine, Incheon, South Korea","Yoon J., Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Gong E., Department of Electrical Engineering, Stanford University, Stanford, CA, United States, Department of Radiology, Stanford University, Stanford, CA, United States; Chatnuntawech I., National Nanotechnology Center, Pathum Thani, Thailand; Bilgic B., Department of Radiology, Harvard Medical School, Boston, MA, United States; Lee J., Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Jung W., Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Ko J., Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Jung H., Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Setsompop K., Department of Radiology, Harvard Medical School, Boston, MA, United States; Zaharchuk G., Department of Radiology, Stanford University, Stanford, CA, United States; Kim E.Y., Department of Radiology, Gil Medical Center, Gachon University College of Medicine, Incheon, South Korea; Pauly J., Department of Electrical Engineering, Stanford University, Stanford, CA, United States; Lee J., Laboratory for Imaging Science and Technology, Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea","Deep neural networks have demonstrated promising potential for the field of medical image reconstruction, successfully generating high quality images for CT, PET and MRI. In this work, an MRI reconstruction algorithm, which is referred to as quantitative susceptibility mapping (QSM), has been developed using a deep neural network in order to perform dipole deconvolution, which restores magnetic susceptibility source from an MRI field map. Previous approaches of QSM require multiple orientation data (e.g. Calculation of Susceptibility through Multiple Orientation Sampling or COSMOS) or regularization terms (e.g. Truncated K-space Division or TKD; Morphology Enabled Dipole Inversion or MEDI) to solve an ill-conditioned dipole deconvolution problem. Unfortunately, they either entail challenges in data acquisition (i.e. long scan time and multiple head orientations) or suffer from image artifacts. To overcome these shortcomings, a deep neural network, which is referred to as QSMnet, is constructed to generate a high quality susceptibility source map from single orientation data. The network has a modified U-net structure and is trained using COSMOS QSM maps, which are considered as gold standard. Five head orientation datasets from five subjects were employed for patch-wise network training after doubling the training data using a model-based data augmentation. Seven additional datasets of five head orientation images (i.e. total 35 images) were used for validation (one dataset) and test (six datasets). The QSMnet maps of the test dataset were compared with the maps from TKD and MEDI for their image quality and consistency with respect to multiple head orientations. Quantitative and qualitative image quality comparisons demonstrate that the QSMnet results have superior image quality to those of TKD or MEDI results and have comparable image quality to those of COSMOS. Additionally, QSMnet maps reveal substantially better consistency across the multiple head orientation data than those from TKD or MEDI. As a preliminary application, the network was further tested for three patients, one with microbleed, another with multiple sclerosis lesions, and the third with hemorrhage. The QSMnet maps showed similar lesion contrasts with those from MEDI, demonstrating potential for future applications. © 2018","Dipole; Machine learning; Magnetic susceptibility; MRI; QSM; Reconstruction","Adult; Aged; Algorithms; Brain; Brain Mapping; Female; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Neural Networks (Computer); adult; aged; algorithm; Article; brain hemorrhage; brain mapping; clinical article; diagnostic test accuracy study; female; gold standard; human; image quality; image reconstruction; information processing; male; middle aged; multiple sclerosis; nerve cell network; priority journal; qualitative analysis; quantitative analysis; susceptibility weighted imaging; training; algorithm; anatomy and histology; artificial neural network; brain; brain mapping; image processing; procedures","Academic Press Inc.","10538119","","NEIME","29894829","Article","Scopus","2-s2.0-85048704730"
"Liu M.; Cheng D.; Wang K.; Wang Y.","Liu, Manhua (8611675100); Cheng, Danni (57195735824); Wang, Kundong (56169541100); Wang, Yaping (57225156828)","8611675100; 57195735824; 56169541100; 57225156828","Multi-Modality Cascaded Convolutional Neural Networks for Alzheimer’s Disease Diagnosis","2018","Neuroinformatics","273","10.1007/s12021-018-9370-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044373487&doi=10.1007%2fs12021-018-9370-4&partnerID=40&md5=44e627c688934010eb764240448ca132","Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China; Shanghai Engineering Research Center for Intelligent Diagnosis and Treatment Instrument, Shanghai Jiao Tong University, Shanghai, 200240, China; School of Information Engineering, Zhengzhou University, Zhengzhou, China","Liu M., Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China, Shanghai Engineering Research Center for Intelligent Diagnosis and Treatment Instrument, Shanghai Jiao Tong University, Shanghai, 200240, China; Cheng D., Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China; Wang K., Department of Instrument Science and Engineering, School of EIEE, Shanghai Jiao Tong University, Shanghai, 200240, China; Wang Y., School of Information Engineering, Zhengzhou University, Zhengzhou, China","Accurate and early diagnosis of Alzheimer’s disease (AD) plays important role for patient care and development of future treatment. Structural and functional neuroimages, such as magnetic resonance images (MRI) and positron emission tomography (PET), are providing powerful imaging modalities to help understand the anatomical and functional neural changes related to AD. In recent years, machine learning methods have been widely studied on analysis of multi-modality neuroimages for quantitative evaluation and computer-aided-diagnosis (CAD) of AD. Most existing methods extract the hand-craft imaging features after image preprocessing such as registration and segmentation, and then train a classifier to distinguish AD subjects from other groups. This paper proposes to construct cascaded convolutional neural networks (CNNs) to learn the multi-level and multimodal features of MRI and PET brain images for AD classification. First, multiple deep 3D-CNNs are constructed on different local image patches to transform the local brain image into more compact high-level features. Then, an upper high-level 2D-CNN followed by softmax layer is cascaded to ensemble the high-level features learned from the multi-modality and generate the latent multimodal correlation features of the corresponding image patches for classification task. Finally, these learned features are combined by a fully connected layer followed by softmax layer for AD classification. The proposed method can automatically learn the generic multi-level and multimodal features from multiple imaging modalities for classification, which are robust to the scale and rotation variations to some extent. No image segmentation and rigid registration are required in pre-processing the brain images. Our method is evaluated on the baseline MRI and PET images of 397 subjects including 93 AD patients, 204 mild cognitive impairment (MCI, 76 pMCI +128 sMCI) and 100 normal controls (NC) from Alzheimer’s Disease Neuroimaging Initiative (ADNI) database. Experimental results show that the proposed method achieves an accuracy of 93.26% for classification of AD vs. NC and 82.95% for classification pMCI vs. NC, demonstrating the promising classification performance. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Alzheimer’s disease diagnosis; Cascaded CNNs; Convolutional neural networks (CNNs); Image classification; Multi-modality brain images","Aged; Aged, 80 and over; Alzheimer Disease; Databases, Factual; Female; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Multimodal Imaging; Neural Networks (Computer); Positron-Emission Tomography; aged; Alzheimer disease; artificial neural network; diagnostic imaging; factual database; female; human; machine learning; male; multimodal imaging; nuclear magnetic resonance imaging; positron emission tomography; procedures; trends; very elderly","Humana Press Inc.","15392791","","NEURK","29572601","Article","Scopus","2-s2.0-85044373487"
"Crane-Droesch A.","Crane-Droesch, Andrew (55998767800)","55998767800","Machine learning methods for crop yield prediction and climate change impact assessment in agriculture","2018","Environmental Research Letters","238","10.1088/1748-9326/aae159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056865972&doi=10.1088%2f1748-9326%2faae159&partnerID=40&md5=48a4be477e1ad82bfd4537a60ac69397","Economic Research Service, United States Department of Agriculture, Washington, 20024, DC, United States","Crane-Droesch A., Economic Research Service, United States Department of Agriculture, Washington, 20024, DC, United States","Crop yields are critically dependent on weather. A growing empirical literature models this relationship in order to project climate change impacts on the sector. We describe an approach to yield modeling that uses a semiparametric variant of a deep neural network, which can simultaneously account for complex nonlinear relationships in high-dimensional datasets, as well as known parametric structure and unobserved cross-sectional heterogeneity. Using data on corn yield from the US Midwest, we show that this approach outperforms both classical statistical methods and fully-nonparametric neural networks in predicting yields of years withheld during model training. Using scenarios from a suite of climate models, we show large negative impacts of climate change on corn yield, but less severe than impacts projected using classical statistical methods. In particular, our approach is less pessimistic in the warmest regions and the warmest scenarios. © 2018 The Author(s). Published by IOP Publishing Ltd.","agriculture; climate change impacts; machine learning","Midwest; United States; Zea mays; Agriculture; Artificial intelligence; Climate models; Crops; Deep neural networks; Learning systems; Object oriented programming; Statistical methods; Climate change impact; Climate change impact assessments; Empirical literature; High dimensional datasets; Machine learning methods; Non-linear relationships; Parametric structure; Yield modeling; agriculture; artificial neural network; assessment method; climate change; climate effect; climate modeling; crop yield; heterogeneity; machine learning; prediction; Climate change","Institute of Physics Publishing","17489318","","","","Article","Scopus","2-s2.0-85056865972"
"Nardelli P.; Jimenez-Carretero D.; Bermejo-Pelaez D.; Washko G.R.; Rahaghi F.N.; Ledesma-Carbayo M.J.; San Jose Estepar R.","Nardelli, Pietro (56647924600); Jimenez-Carretero, Daniel (54787900600); Bermejo-Pelaez, David (57194832148); Washko, George R. (12808786800); Rahaghi, Farbod N. (23489808200); Ledesma-Carbayo, Maria J. (7801546083); San Jose Estepar, Raul (6506402426)","56647924600; 54787900600; 57194832148; 12808786800; 23489808200; 7801546083; 6506402426","Pulmonary Artery-Vein Classification in CT Images Using Deep Learning","2018","IEEE Transactions on Medical Imaging","127","10.1109/TMI.2018.2833385","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046412332&doi=10.1109%2fTMI.2018.2833385&partnerID=40&md5=79304a3bacde32f233ebe90611333f57","Applied Chest Imaging Laboratory, Brigham and Women's Hospital, Harvard Medical School, Boston, 02115, MA, United States; Biomedical Image Technologies, Universidad Politécnica de Madrid, Madrid, 28040, Spain","Nardelli P., Applied Chest Imaging Laboratory, Brigham and Women's Hospital, Harvard Medical School, Boston, 02115, MA, United States; Jimenez-Carretero D., Biomedical Image Technologies, Universidad Politécnica de Madrid, Madrid, 28040, Spain; Bermejo-Pelaez D., Biomedical Image Technologies, Universidad Politécnica de Madrid, Madrid, 28040, Spain; Washko G.R., Applied Chest Imaging Laboratory, Brigham and Women's Hospital, Harvard Medical School, Boston, 02115, MA, United States; Rahaghi F.N., Applied Chest Imaging Laboratory, Brigham and Women's Hospital, Harvard Medical School, Boston, 02115, MA, United States; Ledesma-Carbayo M.J., Biomedical Image Technologies, Universidad Politécnica de Madrid, Madrid, 28040, Spain; San Jose Estepar R., Applied Chest Imaging Laboratory, Brigham and Women's Hospital, Harvard Medical School, Boston, 02115, MA, United States","Recent studies show that pulmonary vascular diseases may specifically affect arteries or veins through different physiologic mechanisms. To detect changes in the two vascular trees, physicians manually analyze the chest computed tomography (CT) image of the patients in search of abnormalities. This process is time consuming, difficult to standardize, and thus not feasible for large clinical studies or useful in real-world clinical decision making. Therefore, automatic separation of arteries and veins in CT images is becoming of great interest, as it may help physicians to accurately diagnose pathological conditions. In this paper, we present a novel, fully automatic approach to classify vessels from chest CT images into arteries and veins. The algorithm follows three main steps: first, a scale-space particles segmentation to isolate vessels; then a 3-D convolutional neural network (CNN) to obtain a first classification of vessels; finally, graph-cuts' optimization to refine the results. To justify the usage of the proposed CNN architecture, we compared different 2-D and 3-D CNNs that may use local information from bronchus- and vessel-enhanced images provided to the network with different strategies. We also compared the proposed CNN approach with a random forests (RFs) classifier. The methodology was trained and evaluated on the superior and inferior lobes of the right lung of 18 clinical cases with noncontrast chest CT scans, in comparison with manual classification. The proposed algorithm achieves an overall accuracy of 94%, which is higher than the accuracy obtained using other CNN architectures and RF. Our method was also validated with contrast-enhanced CT scans of patients with chronic thromboembolic pulmonary hypertension to demonstrate that our model generalizes well to contrast-enhanced modalities. The proposed method outperforms state-of-the-art methods, paving the way for future use of 3-D CNN for artery/vein classification in CT images. © 1982-2012 IEEE.","Artery-vein separation; automatic classification; lung; machine learning; pulmonar vascular disease; pulmonary vessels","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Pulmonary Artery; Pulmonary Disease, Chronic Obstructive; Pulmonary Veins; Tomography, X-Ray Computed; Biological organs; Computer architecture; Decision making; Decision trees; Deep learning; Graphic methods; Image classification; Image enhancement; Image segmentation; Network architecture; Neural networks; Three dimensional displays; Arteries; Clinical decision making; Convolutional Neural Networks (CNN); Lung; Pathological conditions; Pulmonary hypertension; State-of-the-art methods; Veins; algorithm; Article; artificial neural network; chronic thromboembolic pulmonary hypertension; contrast enhancement; convolutional neural network; lung lobe; pulmonary artery; pulmonary vein; x-ray computed tomography; chronic obstructive lung disease; diagnostic imaging; human; image processing; procedures; pulmonary artery; pulmonary vein; x-ray computed tomography; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29993996","Article","Scopus","2-s2.0-85046412332"
"Li F.; Wang Z.; Qu G.; Song D.; Yuan Y.; Xu Y.; Gao K.; Luo G.; Xiao Z.; Lam D.S.C.; Zhong H.; Qiao Y.; Zhang X.","Li, Fei (56297335800); Wang, Zhe (57207119211); Qu, Guoxiang (57203978259); Song, Diping (57204090778); Yuan, Ye (57204099527); Xu, Yang (57207020782); Gao, Kai (57196477927); Luo, Guangwei (7401536344); Xiao, Zegu (57204093946); Lam, Dennis S.C. (35500200200); Zhong, Hua (34573846500); Qiao, Yu (36086392600); Zhang, Xiulan (7410272138)","56297335800; 57207119211; 57203978259; 57204090778; 57204099527; 57207020782; 57196477927; 7401536344; 57204093946; 35500200200; 34573846500; 36086392600; 7410272138","Automatic differentiation of Glaucoma visual field from non-glaucoma visual filed using deep convolutional neural network","2018","BMC Medical Imaging","85","10.1186/s12880-018-0273-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054441678&doi=10.1186%2fs12880-018-0273-5&partnerID=40&md5=0133d27f98dc9b84bc9a3850b67941da","Sun Yat-sen University, Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Guangzhou, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Guangdong key lab of Computer Vision and Virtual Reality, Multimedia Research Center, Shenzhen, China; The First Affiliated Hospital of Kunming Medical University, Department of Ophthalmology, Kunming, China; SenseTime Group Limited, Hong Kong, China; C-MER Dennis Lam Eye Hospital, Shenzhen, China","Li F., Sun Yat-sen University, Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Guangzhou, China; Wang Z., SenseTime Group Limited, Hong Kong, China; Qu G., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Guangdong key lab of Computer Vision and Virtual Reality, Multimedia Research Center, Shenzhen, China; Song D., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Guangdong key lab of Computer Vision and Virtual Reality, Multimedia Research Center, Shenzhen, China; Yuan Y., Sun Yat-sen University, Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Guangzhou, China, C-MER Dennis Lam Eye Hospital, Shenzhen, China; Xu Y., The First Affiliated Hospital of Kunming Medical University, Department of Ophthalmology, Kunming, China; Gao K., Sun Yat-sen University, Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Guangzhou, China; Luo G., Sun Yat-sen University, Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Guangzhou, China; Xiao Z., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Guangdong key lab of Computer Vision and Virtual Reality, Multimedia Research Center, Shenzhen, China; Lam D.S.C., C-MER Dennis Lam Eye Hospital, Shenzhen, China; Zhong H., The First Affiliated Hospital of Kunming Medical University, Department of Ophthalmology, Kunming, China; Qiao Y., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Guangdong key lab of Computer Vision and Virtual Reality, Multimedia Research Center, Shenzhen, China; Zhang X., Sun Yat-sen University, Zhongshan Ophthalmic Center, State Key Laboratory of Ophthalmology, Guangzhou, China","Background: To develop a deep neural network able to differentiate glaucoma from non-glaucoma visual fields based on visual filed (VF) test results, we collected VF tests from 3 different ophthalmic centers in mainland China. Methods: Visual fields obtained by both Humphrey 30-2 and 24-2 tests were collected. Reliability criteria were established as fixation losses less than 2/13, false positive and false negative rates of less than 15%. Results: We split a total of 4012 PD images from 1352 patients into two sets, 3712 for training and another 300 for validation. There is no significant difference between left to right ratio (P=0.6211), while age (P=0.0022), VFI (P=0.0001), MD (P=0.0039) and PSD (P=0.0001) exhibited obvious statistical differences. On the validation set of 300 VFs, CNN achieves the accuracy of 0.876, while the specificity and sensitivity are 0.826 and 0.932, respectively. For ophthalmologists, the average accuracies are 0.607, 0.585 and 0.626 for resident ophthalmologists, attending ophthalmologists and glaucoma experts, respectively. AGIS and GSS2 achieved accuracy of 0.459 and 0.523 respectively. Three traditional machine learning algorithms, namely support vector machine (SVM), random forest (RF), and k-nearest neighbor (k-NN) were also implemented and evaluated in the experiments, which achieved accuracy of 0.670, 0.644, and 0.591 respectively. Conclusions: Our algorithm based on CNN has achieved higher accuracy compared to human ophthalmologists and traditional rules (AGIS and GSS2) in differentiation of glaucoma and non-glaucoma VFs. © 2018 The Author(s).","Deep learning; Glaucoma; Visual field","Adult; Aged; Female; Glaucoma; Humans; Machine Learning; Middle Aged; Reproducibility of Results; Visual Field Tests; adult; aged; clinical trial; female; glaucoma; human; machine learning; middle aged; multicenter study; perimetry; procedures; reproducibility","BioMed Central Ltd.","14712342","","BMIMA","30286740","Article","Scopus","2-s2.0-85054441678"
"Donner Y.; Kazmierczak S.; Fortney K.","Donner, Yoni (24829456600); Kazmierczak, Stéphane (57202951139); Fortney, Kristen (36099931500)","24829456600; 57202951139; 36099931500","Drug Repurposing Using Deep Embeddings of Gene Expression Profiles","2018","Molecular Pharmaceutics","44","10.1021/acs.molpharmaceut.8b00284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049985225&doi=10.1021%2facs.molpharmaceut.8b00284&partnerID=40&md5=35baf09c9e4cf597c5ca6a3df3d86628","Quantified Mind, United States; BioAge Labs, Richmond, 94804, CA, United States","Donner Y., Quantified Mind, United States; Kazmierczak S., BioAge Labs, Richmond, 94804, CA, United States; Fortney K., BioAge Labs, Richmond, 94804, CA, United States","Computational drug repositioning requires assessment of the functional similarities among compounds. Here, we report a new method for measuring compound functional similarity based on gene expression data. This approach takes advantage of deep neural networks to learn an embedding that substantially denoises expression data, making replicates of the same compound more similar. Our method uses unlabeled data in the sense that it only requires compounds to be labeled by identity rather than detailed pharmacological information, which is often unavailable and costly to obtain. Similarity in the learned embedding space accurately predicted pharmacological similarities despite the lack of any such labels during training and achieved substantially improved performance in comparison with previous similarity measures applied to gene expression measurements. Our method could identify drugs with shared therapeutic and biological targets even when the compounds were structurally dissimilar, thereby revealing previously unreported functional relationships between compounds. Thus, our approach provides an improved engine for drug repurposing based on expression data, which we have made available through the online tool DeepCodex (http://deepcodex.org). Copyright © 2018 American Chemical Society.","deep neural network; drug embedding; drug repositioning; L1000; metric learning","Algorithms; Computational Biology; Drug Discovery; Drug Repositioning; Neural Networks (Computer); allantoin; betazole; complementary DNA; homatropine; metformin; meticrane; metrifonate; morantel; noretynodrel; short hairpin RNA; sulfaphenazole; sulindac; todralazine; Article; chemical structure; clustered regularly interspaced short palindromic repeat; controlled study; deep neural network; drug repositioning; embedding; gene expression profiling; genetic manipulation; human; human cell; incubation time; machine learning; priority journal; receiver operating characteristic; algorithm; artificial neural network; biology; drug development; drug repositioning; procedures","American Chemical Society","15438384","","MPOHB","30001141","Article","Scopus","2-s2.0-85049985225"
"Dooraki A.R.; Lee D.-J.","Dooraki, Amir Ramezani (57189250021); Lee, Deok-Jin (55617467900)","57189250021; 55617467900","An end-to-end deep reinforcement learning-based intelligent agent capable of autonomous exploration in unknown environments","2018","Sensors (Switzerland)","34","10.3390/s18103575","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055613504&doi=10.3390%2fs18103575&partnerID=40&md5=b311694979751ea9e7dc86f6cb1e8640","Smart Autonomous Systems Lab, School of Mechanical & Automotive Engineering, Kunsan National University, Gunsan, 54150, Jeonbuk, South Korea","Dooraki A.R., Smart Autonomous Systems Lab, School of Mechanical & Automotive Engineering, Kunsan National University, Gunsan, 54150, Jeonbuk, South Korea; Lee D.-J., Smart Autonomous Systems Lab, School of Mechanical & Automotive Engineering, Kunsan National University, Gunsan, 54150, Jeonbuk, South Korea","In recent years, machine learning (and as a result artificial intelligence) has experienced considerable progress. As a result, robots in different shapes and with different purposes have found their ways into our everyday life. These robots, which have been developed with the goal of human companionship, are here to help us in our everyday and routine life. These robots are different to the previous family of robots that were used in factories and static environments. These new robots are social robots that need to be able to adapt to our environment by themselves and to learn from their own experiences. In this paper, we contribute to the creation of robots with a high degree of autonomy, which is a must for social robots. We try to create an algorithm capable of autonomous exploration in and adaptation to unknown environments and implement it in a simulated robot. We go further than a simulation and implement our algorithm in a real robot, in which our sensor fusion method is able to overcome real-world noise and perform robust exploration. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Adaptive agent; Autonomous agent; Autonomous exploration; Bio-inspired; Deep reinforcement learning; Obstacle avoidance","Artificial intelligence; Autonomous agents; Collision avoidance; Reinforcement learning; Robots; Adaptive agents; Autonomous exploration; Bio-inspired; Degree of autonomy; Different shapes; Real-world noise; Simulated robot; Static environment; Deep learning","MDPI AG","14248220","","","30360397","Article","Scopus","2-s2.0-85055613504"
"Li X.; Xu Y.; Lai L.; Pei J.","Li, Xiang (57775216900); Xu, Youjun (56927067900); Lai, Luhua (7202615995); Pei, Jianfeng (7103299043)","57775216900; 56927067900; 7202615995; 7103299043","Prediction of Human Cytochrome P450 Inhibition Using a Multitask Deep Autoencoder Neural Network","2018","Molecular Pharmaceutics","87","10.1021/acs.molpharmaceut.8b00110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047414689&doi=10.1021%2facs.molpharmaceut.8b00110&partnerID=40&md5=eb52d0bab34490402596cb8f2de3685c","Center for Life Sciences, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China; BNLMS, State Key Laboratory for Structural Chemistry of Unstable and Stable Species, College of Chemistry and Molecular Engineering, Peking University, Beijing, 100871, China; Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China","Li X., Center for Life Sciences, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China, BNLMS, State Key Laboratory for Structural Chemistry of Unstable and Stable Species, College of Chemistry and Molecular Engineering, Peking University, Beijing, 100871, China; Xu Y., Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China; Lai L., Center for Life Sciences, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China, BNLMS, State Key Laboratory for Structural Chemistry of Unstable and Stable Species, College of Chemistry and Molecular Engineering, Peking University, Beijing, 100871, China, Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China; Pei J., Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China","Adverse side effects of drug-drug interactions induced by human cytochrome P450 (CYP450) inhibition is an important consideration in drug discovery. It is highly desirable to develop computational models that can predict the inhibitive effect of a compound against a specific CYP450 isoform. In this study, we developed a multitask model for concurrent inhibition prediction of five major CYP450 isoforms, namely, 1A2, 2C9, 2C19, 2D6, and 3A4. The model was built by training a multitask autoencoder deep neural network (DNN) on a large dataset containing more than 13 000 compounds, extracted from the PubChem BioAssay Database. We demonstrate that the multitask model gave better prediction results than that of single-task models, previous reported classifiers, and traditional machine learning methods on an average of five prediction tasks. Our multitask DNN model gave average prediction accuracies of 86.4% for the 10-fold cross-validation and 88.7% for the external test datasets. In addition, we built linear regression models to quantify how the other tasks contributed to the prediction difference of a given task between single-task and multitask models, and we explained under what conditions the multitask model will outperform the single-task model, which suggested how to use multitask DNN models more effectively. We applied sensitivity analysis to extract useful knowledge about CYP450 inhibition, which may shed light on the structural features of these isoforms and give hints about how to avoid side effects during drug development. Our models are freely available at http://repharma.pku.edu.cn/deepcyp/home.php or http://www.pkumdl.cn/deepcyp/home.php. © 2018 American Chemical Society.","cytochrome P450; drug-drug interaction; multitask deep neural network; quantitative structure-activity relationship; sensitivity analysis","Algorithms; Cytochrome P-450 Enzyme Inhibitors; Cytochrome P-450 Enzyme System; Drug Interactions; Humans; Machine Learning; Neural Networks (Computer); Protein Isoforms; Quantitative Structure-Activity Relationship; cytochrome P450; cytochrome P450 1A2; cytochrome P450 1A2 inhibitor; cytochrome P450 2C19; cytochrome P450 2C19 inhibitor; cytochrome P450 2C9; cytochrome P450 2C9 inhibitor; cytochrome P450 2D6; cytochrome P450 2D6 inhibitor; cytochrome P450 inhibitor; cytochrome P450; cytochrome P450 inhibitor; isoprotein; Article; controlled study; EC50; human; machine learning; multitask deep neural network; prediction; priority journal; probability; algorithm; artificial neural network; drug interaction; metabolism; quantitative structure activity relation","American Chemical Society","15438384","","MPOHB","29775322","Article","Scopus","2-s2.0-85047414689"
"Lee J.-H.; Kim D.-H.; Jeong S.-N.; Choi S.-H.","Lee, Jae-Hong (56692047500); Kim, Do-Hyung (57203012722); Jeong, Seong-Nyum (7402425037); Choi, Seong-Ho (56132950300)","56692047500; 57203012722; 7402425037; 56132950300","Detection and diagnosis of dental caries using a deep learning-based convolutional neural network algorithm","2018","Journal of Dentistry","448","10.1016/j.jdent.2018.07.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050642974&doi=10.1016%2fj.jdent.2018.07.015&partnerID=40&md5=01b35f4c7956b50b1a3a346cc9dbd81b","Department of Periodontology, Daejeon Dental Hospital, Institute of Wonkwang Dental Research, Wonkwang University College of Dentistry, Daejeon, South Korea; Department of Periodontology, Research Institute for Periodontal Regeneration, Yonsei University College of Dentistry, Seoul, South Korea","Lee J.-H., Department of Periodontology, Daejeon Dental Hospital, Institute of Wonkwang Dental Research, Wonkwang University College of Dentistry, Daejeon, South Korea; Kim D.-H., Department of Periodontology, Daejeon Dental Hospital, Institute of Wonkwang Dental Research, Wonkwang University College of Dentistry, Daejeon, South Korea; Jeong S.-N., Department of Periodontology, Daejeon Dental Hospital, Institute of Wonkwang Dental Research, Wonkwang University College of Dentistry, Daejeon, South Korea; Choi S.-H., Department of Periodontology, Research Institute for Periodontal Regeneration, Yonsei University College of Dentistry, Seoul, South Korea","Objectives: Deep convolutional neural networks (CNNs) are a rapidly emerging new area of medical research, and have yielded impressive results in diagnosis and prediction in the fields of radiology and pathology. The aim of the current study was to evaluate the efficacy of deep CNN algorithms for detection and diagnosis of dental caries on periapical radiographs. Materials and methods: A total of 3000 periapical radiographic images were divided into a training and validation dataset (n = 2400 [80%]) and a test dataset (n = 600 [20%]). A pre-trained GoogLeNet Inception v3 CNN network was used for preprocessing and transfer learning. The diagnostic accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, and area under the curve (AUC) were calculated for detection and diagnostic performance of the deep CNN algorithm. Results: The diagnostic accuracies of premolar, molar, and both premolar and molar models were 89.0% (80.4–93.3), 88.0% (79.2–93.1), and 82.0% (75.5–87.1), respectively. The deep CNN algorithm achieved an AUC of 0.917 (95% CI 0.860–0.975) on premolar, an AUC of 0.890 (95% CI 0.819–0.961) on molar, and an AUC of 0.845 (95% CI 0.790–0.901) on both premolar and molar models. The premolar model provided the best AUC, which was significantly greater than those for other models (P < 0.001). Conclusions: This study highlighted the potential utility of deep CNN architecture for the detection and diagnosis of dental caries. A deep CNN algorithm provided considerably good performance in detecting dental caries in periapical radiographs. Clinical signiﬁcance: Deep CNN algorithms are expected to be among the most effective and efficient methods for diagnosing dental caries. © 2018 Elsevier Ltd","Artificial intelligence; Dental caries; Machine learning; Supervised machine learning","Algorithms; Deep Learning; Dental Caries; Humans; Neural Networks (Computer); ROC Curve; algorithm; artificial neural network; dental caries; human; receiver operating characteristic","Elsevier Ltd","03005712","","JDENA","30056118","Article","Scopus","2-s2.0-85050642974"
"Joopudi V.; Dandala B.; Devarakonda M.","Joopudi, Venkata (57192108870); Dandala, Bharath (55967550000); Devarakonda, Murthy (56908095700)","57192108870; 55967550000; 56908095700","A convolutional route to abbreviation disambiguation in clinical text","2018","Journal of Biomedical Informatics","32","10.1016/j.jbi.2018.07.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052861729&doi=10.1016%2fj.jbi.2018.07.025&partnerID=40&md5=78c3b7f2626c0bd4b425158f58e21544","IBM Research, Yorktown Heights, United States; Faculty of Biomedical Informatics at Arizona State University, United States","Joopudi V., IBM Research, Yorktown Heights, United States; Dandala B., IBM Research, Yorktown Heights, United States; Devarakonda M., IBM Research, Yorktown Heights, United States, Faculty of Biomedical Informatics at Arizona State University, United States","Objective: Abbreviations sense disambiguation is a special case of word sense disambiguation. Machine learning methods based on neural networks showed promising results for word sense disambiguation (Festag and Spreckelsen, 2017) [1] and, here we assess their effectiveness for abbreviation sense disambiguation. Methods: Convolutional Neural Network (CNN) models were trained, one for each abbreviation, to disambiguate abbreviation senses. A reverse substitution (of long forms with short forms) method from a previous study was used on clinical narratives from Cleveland Clinic, USA, to auto-generate training data. Accuracy of the CNN and traditional Support Vector Machine (SVM) models were studied using: (a) 5-fold cross validation on the auto-generated training data; (b) a manually created, set-aside gold standard; and (c) 10-fold cross validation on a publicly available dataset from a previous study. Results: CNN improved accuracy by 1–4 percentage points on all the three datasets compared to SVM, and the improvement was the most for the set-aside dataset. The improvement was statistically significant at p < 0.05 on the auto-generated dataset. We found that for some common abbreviations, sense distributions mismatch between the test and auto generated training data, and mitigating the mismatch significantly improved the model accuracy. Conclusion: The neural network models work well in disambiguating abbreviations in clinical narratives, and they are robust across datasets. This avoids feature-engineering for each dataset. Coupled with an enhanced auto-training data generation, neural networks can simplify development of a practical abbreviation disambiguation system. © 2018 Elsevier Inc.","","Algorithms; Automation; Cluster Analysis; Data Collection; Databases, Factual; Deep Learning; Hospitals; Language; Medical Informatics; Neural Networks (Computer); Ohio; Reproducibility of Results; Semantics; Software; Support Vector Machine; Convolution; Neural networks; Support vector machines; 10-fold cross-validation; Convolutional Neural Networks (CNN); Cross validation; Feature engineerings; Machine learning methods; Neural network model; Percentage points; Word Sense Disambiguation; article; comparative effectiveness; gold standard; narrative; nomenclature; support vector machine; validation process; algorithm; artificial neural network; automation; cluster analysis; factual database; hospital; information processing; language; medical informatics; Ohio; procedures; reproducibility; semantics; software; support vector machine; Natural language processing systems","Academic Press Inc.","15320464","","JBIOB","30118854","Article","Scopus","2-s2.0-85052861729"
"Eun H.; Kim D.; Jung C.; Kim C.","Eun, Hyunjun (57022188200); Kim, Daeyeong (56514263400); Jung, Chanho (35169804400); Kim, Changick (7409875501)","57022188200; 56514263400; 35169804400; 7409875501","Single-view 2D CNNs with fully automatic non-nodule categorization for false positive reduction in pulmonary nodule detection","2018","Computer Methods and Programs in Biomedicine","14","10.1016/j.cmpb.2018.08.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053065489&doi=10.1016%2fj.cmpb.2018.08.012&partnerID=40&md5=f0d45b1f726e083a8e1472934ff57938","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Department of Electrical Engineering, Hanbat National University, United States","Eun H., School of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Kim D., School of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Jung C., Department of Electrical Engineering, Hanbat National University, United States; Kim C., School of Electrical Engineering, Korea Advanced Institute of Science and Technology, South Korea","Background and Objective: In pulmonary nodule detection, the first stage, candidate detection, aims to detect suspicious pulmonary nodules. However, detected candidates include many false positives and thus in the following stage, false positive reduction, such false positives are reliably reduced. Note that this task is challenging due to 1) the imbalance between the numbers of nodules and non-nodules and 2) the intra-class diversity of non-nodules. Although techniques using 3D convolutional neural networks (CNNs) have shown promising performance, they suffer from high computational complexity which hinders constructing deep networks. To efficiently address these problems, we propose a novel framework using the ensemble of 2D CNNs using single views, which outperforms existing 3D CNN-based methods. Methods: Our ensemble of 2D CNNs utilizes single-view 2D patches to improve both computational and memory efficiency compared to previous techniques exploiting 3D CNNs. We first categorize non-nodules on the basis of features encoded by an autoencoder. Then, all 2D CNNs are trained by using the same nodule samples, but with different types of non-nodules. By extending the learning capability, this training scheme resolves difficulties of extracting representative features from non-nodules with large appearance variations. Note that, instead of manual categorization requiring the heavy workload of radiologists, we propose to automatically categorize non-nodules based on the autoencoder and k-means clustering. Results: We performed extensive experiments to validate the effectiveness of our framework based on the database of the lung nodule analysis 2016 challenge. The superiority of our framework is demonstrated through comparing the performance of five frameworks trained with differently constructed training sets. Our proposed framework achieved state-of-the-art performance (0.922 of the competition performance metric score) with low computational demands (789K of parameters and 1024M of floating point operations per second). Conclusion: We presented a novel false positive reduction framework, the ensemble of single-view 2D CNNs with fully automatic non-nodule categorization, for pulmonary nodule detection. Unlike previous 3D CNN-based frameworks, we utilized 2D CNNs using 2D single views to improve computational efficiency. Also, our training scheme using categorized non-nodules, extends the learning capability of representative features of different non-nodules. Our framework achieved state-of-the-art performance with low computational complexity. © 2018 Elsevier B.V.","Automatic non-nodule categorization; Computer-aided detection; Deep learning; False positive reduction; Pulmonary nodule detection","Databases, Factual; Diagnosis, Computer-Assisted; False Positive Reactions; Humans; Lung Neoplasms; Neural Networks (Computer); Radiographic Image Interpretation, Computer-Assisted; Solitary Pulmonary Nodule; Tomography, X-Ray Computed; Complex networks; Computational complexity; Computer aided instruction; Deep learning; Digital arithmetic; Efficiency; Neural networks; Positron emission tomography; Automatic non-nodule categorization; Computer aided detection; Convolutional neural network; False-positive reduction; Floating point operations per seconds; Low computational complexity; Pulmonary nodule detection; State-of-the-art performance; Article; automation; comparative study; computer assisted diagnosis; convolutional neural network; diagnostic accuracy; diagnostic radiologist; disease classification; false positive result; feature extraction; human; lung nodule; machine learning; receiver operating characteristic; three dimensional imaging; two-dimensional imaging; x-ray computed tomography; artificial neural network; classification; computer assisted diagnosis; diagnostic imaging; factual database; false positive result; lung nodule; lung tumor; procedures; statistics and numerical data; Computational efficiency","Elsevier Ireland Ltd","01692607","","CMPBE","30337076","Article","Scopus","2-s2.0-85053065489"
"Gurbani S.S.; Schreibmann E.; Maudsley A.A.; Cordova J.S.; Soher B.J.; Poptani H.; Verma G.; Barker P.B.; Shim H.; Cooper L.A.D.","Gurbani, Saumya S. (35770632100); Schreibmann, Eduard (8523608500); Maudsley, Andrew A. (7006771472); Cordova, James Scott (56205707700); Soher, Brian J. (6603733261); Poptani, Harish (57206342070); Verma, Gaurav (35796519900); Barker, Peter B. (7402080565); Shim, Hyunsuk (7202595615); Cooper, Lee A. D. (36470124000)","35770632100; 8523608500; 7006771472; 56205707700; 6603733261; 57206342070; 35796519900; 7402080565; 7202595615; 36470124000","A convolutional neural network to filter artifacts in spectroscopic MRI","2018","Magnetic Resonance in Medicine","61","10.1002/mrm.27166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043365946&doi=10.1002%2fmrm.27166&partnerID=40&md5=b146073a2c2326d04469b366c26a9c87","Department of Radiation Oncology, Emory University, Atlanta, GA, United States; Wallace H. Coulter Department of Biomedical Engineering, Emory University and Georgia Institute of Technology, Atlanta, GA, United States; Winship Cancer Institute of Emory University, Atlanta, GA, United States; Department of Radiology, University of Miami Miller School of Medicine, Miami, FL, United States; Department of Radiology, Duke University School of Medicine, Durham, NC, United States; Institute of Translational Medicine, University of Liverpool, Liverpool, United Kingdom; Department of Radiology, Icahn School of Medicine at Mt. Sinai, New York, NY, United States; Department of Radiology and Radiological Science, The Johns Hopkins University, Baltimore, MD, United States; Department of Radiology and Imaging Sciences, Emory University, Atlanta, GA, United States; Department of Biomedical Informatics, Emory University School of Medicine, Atlanta, GA, United States","Gurbani S.S., Department of Radiation Oncology, Emory University, Atlanta, GA, United States, Wallace H. Coulter Department of Biomedical Engineering, Emory University and Georgia Institute of Technology, Atlanta, GA, United States, Winship Cancer Institute of Emory University, Atlanta, GA, United States; Schreibmann E., Department of Radiation Oncology, Emory University, Atlanta, GA, United States, Winship Cancer Institute of Emory University, Atlanta, GA, United States; Maudsley A.A., Department of Radiology, University of Miami Miller School of Medicine, Miami, FL, United States; Cordova J.S., Department of Radiation Oncology, Emory University, Atlanta, GA, United States, Winship Cancer Institute of Emory University, Atlanta, GA, United States; Soher B.J., Department of Radiology, Duke University School of Medicine, Durham, NC, United States; Poptani H., Institute of Translational Medicine, University of Liverpool, Liverpool, United Kingdom; Verma G., Department of Radiology, Icahn School of Medicine at Mt. Sinai, New York, NY, United States; Barker P.B., Department of Radiology and Radiological Science, The Johns Hopkins University, Baltimore, MD, United States; Shim H., Department of Radiation Oncology, Emory University, Atlanta, GA, United States, Wallace H. Coulter Department of Biomedical Engineering, Emory University and Georgia Institute of Technology, Atlanta, GA, United States, Winship Cancer Institute of Emory University, Atlanta, GA, United States, Department of Radiology and Imaging Sciences, Emory University, Atlanta, GA, United States; Cooper L.A.D., Wallace H. Coulter Department of Biomedical Engineering, Emory University and Georgia Institute of Technology, Atlanta, GA, United States, Winship Cancer Institute of Emory University, Atlanta, GA, United States, Department of Biomedical Informatics, Emory University School of Medicine, Atlanta, GA, United States","Purpose: Proton MRSI is a noninvasive modality capable of generating volumetric maps of in vivo tissue metabolism without the need for ionizing radiation or injected contrast agent. Magnetic resonance spectroscopic imaging has been shown to be a viable imaging modality for studying several neuropathologies. However, a key hurdle in the routine clinical adoption of MRSI is the presence of spectral artifacts that can arise from a number of sources, possibly leading to false information. Methods: A deep learning model was developed that was capable of identifying and filtering out poor quality spectra. The core of the model used a tiled convolutional neural network that analyzed frequency-domain spectra to detect artifacts. Results: When compared with a panel of MRS experts, our convolutional neural network achieved high sensitivity and specificity with an area under the curve of 0.95. A visualization scheme was implemented to better understand how the convolutional neural network made its judgement on single-voxel or multivoxel MRSI, and the convolutional neural network was embedded into a pipeline capable of producing whole-brain spectroscopic MRI volumes in real time. Conclusion: The fully automated method for assessment of spectral quality provides a valuable tool to support clinical MRSI or spectroscopic MRI studies for use in fields such as adaptive radiation therapy planning. © 2018 International Society for Magnetic Resonance in Medicine","deep learning; machine learning; MR spectroscopic imaging; spectroscopic MRI","Algorithms; Artifacts; Brain; Brain Neoplasms; Deep Learning; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Convolution; Deep learning; Frequency domain analysis; Ionizing radiation; Learning systems; Magnetic resonance; Magnetic resonance imaging; Magnetic resonance spectroscopy; Metabolism; Adaptive radiation therapies; Area under the curves; Frequency domains; High sensitivity; Magnetic resonance spectroscopic imaging; Mr spectroscopic imaging; Number of sources; Spectral artifacts; area under the curve; Article; artificial neural network; Bayes theorem; classification; convolutional neural network; deep learning model; frequency modulation; glioblastoma; image quality; intermethod comparison; machine learning; neuroimaging; nuclear magnetic resonance imaging; process development; process optimization; sensitivity and specificity; spectroscopy; algorithm; artifact; brain; brain tumor; diagnostic imaging; human; image processing; nuclear magnetic resonance imaging; procedures; Convolutional neural networks","John Wiley and Sons Inc","07403194","","MRMEE","29520831","Article","Scopus","2-s2.0-85043365946"
"Kiasari M.A.; Moirangthem D.S.; Lee M.","Kiasari, Mohammad Ahangar (56527440500); Moirangthem, Dennis Singh (57195432297); Lee, Minho (57191730119)","56527440500; 57195432297; 57191730119","Joint moment-matching autoencoders","2018","Neural Networks","3","10.1016/j.neunet.2018.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050745173&doi=10.1016%2fj.neunet.2018.07.001&partnerID=40&md5=f21cebbd3fda0ab322a1fc7b2328089c","School of Electronics Engineering, IT1, Kyungpook National University, 80 Daehakro, Bukgu, Daegu, 41566, South Korea","Kiasari M.A., School of Electronics Engineering, IT1, Kyungpook National University, 80 Daehakro, Bukgu, Daegu, 41566, South Korea; Moirangthem D.S., School of Electronics Engineering, IT1, Kyungpook National University, 80 Daehakro, Bukgu, Daegu, 41566, South Korea; Lee M., School of Electronics Engineering, IT1, Kyungpook National University, 80 Daehakro, Bukgu, Daegu, 41566, South Korea","Image transformation between multiple domains has become a challenging problem in deep generative networks. This is because, in real-world applications, finding paired images in different domains is an expensive and impractical task. This paper proposes a new model named joint moment-matching autoencoders(JMA). This model learns to perform cross-domain transformation over multiple domains based on perceptual loss and maximum mean discrepancy criteria, in the absence of any paired images between the domains. Our results show that the proposed JMA framework successfully learns to transform images between domains without any paired data. We demonstrate that our model has good performance in the generative context as well as in the domain transformation tasks with better computational efficiency than conventional methods. © 2018 Elsevier Ltd","Generative models; Image transformation; Moment matching; Multiple domain transformation","Algorithms; Humans; Machine Learning; Pattern Recognition, Automated; Photic Stimulation; Computational efficiency; Conventional methods; Different domains; Domain transformation; Generative model; Image transformations; Joint moment; Moment-matching; Multiple domains; article; joint; algorithm; automated pattern recognition; human; machine learning; photostimulation; procedures; Learning systems","Elsevier Ltd","08936080","","NNETE","30075355","Article","Scopus","2-s2.0-85050745173"
"Tang W.; Chen J.; Wang Z.; Xie H.; Hong H.","Tang, Weihao (57204182132); Chen, Jingwen (7501879637); Wang, Zhongyu (56553437100); Xie, Hongbin (52864886400); Hong, Huixiao (7401521704)","57204182132; 7501879637; 56553437100; 52864886400; 7401521704","Deep learning for predicting toxicity of chemicals: a mini review","2018","Journal of Environmental Science and Health - Part C Environmental Carcinogenesis and Ecotoxicology Reviews","56","10.1080/10590501.2018.1537563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062514448&doi=10.1080%2f10590501.2018.1537563&partnerID=40&md5=bbc61dad5d8be1b33c6b339bffffd6b5","Key Laboratory of Industrial Ecology and Environmental Engineering (MOE), School of Environmental Science and Technology, Dalian University of Technology, Dalian, China; National Center for Toxicological Research, U.S. Food and Drug Administration, Jefferson, United States","Tang W., Key Laboratory of Industrial Ecology and Environmental Engineering (MOE), School of Environmental Science and Technology, Dalian University of Technology, Dalian, China; Chen J., Key Laboratory of Industrial Ecology and Environmental Engineering (MOE), School of Environmental Science and Technology, Dalian University of Technology, Dalian, China; Wang Z., Key Laboratory of Industrial Ecology and Environmental Engineering (MOE), School of Environmental Science and Technology, Dalian University of Technology, Dalian, China; Xie H., Key Laboratory of Industrial Ecology and Environmental Engineering (MOE), School of Environmental Science and Technology, Dalian University of Technology, Dalian, China; Hong H., National Center for Toxicological Research, U.S. Food and Drug Administration, Jefferson, United States","Humans and wildlife inhabit a world with panoply of natural and synthetic chemicals. Alarmingly, only a limited number of chemicals have undergone comprehensive toxicological evaluation due to limitations of traditional toxicity testing. High-throughput screening assays provide a higher-speed alternative for conventional toxicity testing. Advancement of high-throughput bioassay technology has greatly increased chemical toxicity data volumes in the past decade, pushing toxicology research into a “big data” era. However, traditional data analysis methods fail to effectively process large data volumes, presenting both a challenge and an opportunity for toxicologists. Deep learning, a machine learning method leveraging deep neural networks (DNNs), is a proven useful tool for building quantitative structure–activity relationship (QSAR) models for toxicity prediction utilizing these new large datasets. In this mini review, a brief technical background on DNNs is provided, and the current state of chemical toxicity prediction models built with DNNs is reviewed. In addition, relevant toxicity data sources are summarized, possible limitations are discussed, and perspectives on DNN utilization in chemical toxicity prediction are given. © 2019, © 2019 Taylor & Francis Group, LLC.","Chemicals toxicity; deep learning; deep neural networks; high-throughput screening assays; QSAR","Deep Learning; Environmental Pollutants; High-Throughput Screening Assays; Humans; Machine Learning; Models, Chemical; Neural Networks (Computer); Quantitative Structure-Activity Relationship; Toxicity Tests; Chemicals; Computational chemistry; Deep learning; Forecasting; Large dataset; Throughput; Toxicity; Data analysis methods; High throughput screening; Machine learning methods; QSAR; Quantitative structures; Technical background; Toxicity predictions; Toxicological evaluation; animal experiment; animal model; article; big data; bioassay; data analysis; deep learning; high throughput screening; nonhuman; prediction; quantitative structure activity relation; toxicity testing; toxicology; velocity; wildlife; artificial neural network; chemical model; high throughput screening; human; machine learning; pollutant; procedures; quantitative structure activity relation; toxicity; Deep neural networks","Taylor and Francis Inc.","10590501","","JSHRE","30821199","Article","Scopus","2-s2.0-85062514448"
"Skomrock N.D.; Schwemmer M.A.; Ting J.E.; Trivedi H.R.; Sharma G.; Bockbrader M.A.; Friedenberg D.A.","Skomrock, Nicholas D. (57192917864); Schwemmer, Michael A. (37085444100); Ting, Jordyn E. (57213194243); Trivedi, Hemang R. (57222496270); Sharma, Gaurav (57208200916); Bockbrader, Marcia A. (6507484812); Friedenberg, David A. (55961372800)","57192917864; 37085444100; 57213194243; 57222496270; 57208200916; 6507484812; 55961372800","A Characterization of Brain-Computer Interface Performance Trade-Offs Using Support Vector Machines and Deep Neural Networks to Decode Movement Intent","2018","Frontiers in Neuroscience","25","10.3389/fnins.2018.00763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074425591&doi=10.3389%2ffnins.2018.00763&partnerID=40&md5=ad6a08d8f55cbfdd2cb29c3914b75ceb","Advanced Analytics and Health Research, Battelle Memorial Institute, Columbus, OH, United States; Medical Devices and Neuromodulation, Battelle Memorial Institute, Columbus, OH, United States; Neurological Institute, The Ohio State University, Columbus, OH, United States; Department of Physical Medicine and Rehabilitation, The Ohio State University, Columbus, OH, United States","Skomrock N.D., Advanced Analytics and Health Research, Battelle Memorial Institute, Columbus, OH, United States; Schwemmer M.A., Advanced Analytics and Health Research, Battelle Memorial Institute, Columbus, OH, United States; Ting J.E., Medical Devices and Neuromodulation, Battelle Memorial Institute, Columbus, OH, United States; Trivedi H.R., Medical Devices and Neuromodulation, Battelle Memorial Institute, Columbus, OH, United States; Sharma G., Medical Devices and Neuromodulation, Battelle Memorial Institute, Columbus, OH, United States; Bockbrader M.A., Neurological Institute, The Ohio State University, Columbus, OH, United States, Department of Physical Medicine and Rehabilitation, The Ohio State University, Columbus, OH, United States; Friedenberg D.A., Advanced Analytics and Health Research, Battelle Memorial Institute, Columbus, OH, United States","Laboratory demonstrations of brain-computer interface (BCI) systems show promise for reducing disability associated with paralysis by directly linking neural activity to the control of assistive devices. Surveys of potential users have revealed several key BCI performance criteria for clinical translation of such a system. Of these criteria, high accuracy, short response latencies, and multi-functionality are three key characteristics directly impacted by the neural decoding component of the BCI system, the algorithm that translates neural activity into control signals. Building a decoder that simultaneously addresses these three criteria is complicated because optimizing for one criterion may lead to undesirable changes in the other criteria. Unfortunately, there has been little work to date to quantify how decoder design simultaneously affects these performance characteristics. Here, we systematically explore the trade-off between accuracy, response latency, and multi-functionality for discrete movement classification using two different decoding strategies–a support vector machine (SVM) classifier which represents the current state-of-the-art for discrete movement classification in laboratory demonstrations and a proposed deep neural network (DNN) framework. We utilized historical intracortical recordings from a human tetraplegic study participant, who imagined performing several different hand and finger movements. For both decoders, we found that response time increases (i.e., slower reaction) and accuracy decreases as the number of functions increases. However, we also found that both the increase of response times and the decline in accuracy with additional functions is less for the DNN than the SVM. We also show that data preprocessing steps can affect the performance characteristics of the two decoders in drastically different ways. Finally, we evaluated the performance of our tetraplegic participant using the DNN decoder in real-time to control functional electrical stimulation (FES) of his paralyzed forearm. We compared his performance to that of able-bodied participants performing the same task, establishing a quantitative target for ideal BCI-FES performance on this task. Cumulatively, these results help quantify BCI decoder performance characteristics relevant to potential users and the complex interactions between them. © Copyright © 2018 Skomrock, Schwemmer, Ting, Trivedi, Sharma, Bockbrader and Friedenberg.","brain-computer interface; decoding; deep learning; machine learning; response time; support vector machines","","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85074425591"
"Huang Q.; Sun J.; Ding H.; Wang X.; Wang G.","Huang, Qing (57034586500); Sun, Jinfeng (57203462167); Ding, Hui (26423717600); Wang, Xiaodong (56183155800); Wang, Guangzhi (57194626987)","57034586500; 57203462167; 26423717600; 56183155800; 57194626987","Robust liver vessel extraction using 3D U-Net with variant dice loss function","2018","Computers in Biology and Medicine","126","10.1016/j.compbiomed.2018.08.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051835592&doi=10.1016%2fj.compbiomed.2018.08.018&partnerID=40&md5=3015bae639932d05c7b89e0df2980522","Department of Biomedical Engineering, School of Medicine, Tsinghua University, Room C249, Beijing, 100084, China; Department of Interventional Radiology, Peking University Cancer Hospital & Institute, Key Laboratory of Carcinogenesis and Translational Research (Ministry of Education), Beijing, 100142, China","Huang Q., Department of Biomedical Engineering, School of Medicine, Tsinghua University, Room C249, Beijing, 100084, China; Sun J., Department of Biomedical Engineering, School of Medicine, Tsinghua University, Room C249, Beijing, 100084, China; Ding H., Department of Biomedical Engineering, School of Medicine, Tsinghua University, Room C249, Beijing, 100084, China; Wang X., Department of Interventional Radiology, Peking University Cancer Hospital & Institute, Key Laboratory of Carcinogenesis and Translational Research (Ministry of Education), Beijing, 100142, China; Wang G., Department of Biomedical Engineering, School of Medicine, Tsinghua University, Room C249, Beijing, 100084, China","Purpose: Liver vessel extraction from CT images is essential in liver surgical planning. Liver vessel segmentation is difficult due to the complex vessel structures, and even expert manual annotations contain unlabeled vessels. This paper presents an automatic liver vessel extraction method using deep convolutional network and studies the impact of incomplete data annotation on segmentation accuracy evaluation. Methods: We select the 3D U-Net and use data augmentation for accurate liver vessel extraction with few training samples and incomplete labeling. To deal with high imbalance between foreground (liver vessel) and background (liver) classes but also increase segmentation accuracy, a loss function based on a variant of the dice coefficient is proposed to increase the penalties for misclassified voxels. We include unlabeled liver vessels extracted by our method in the expert manual annotations, with a specialist's visual inspection for refinement, and compare the evaluations before and after the procedure. Results: Experiments were performed on the public datasets Sliver07 and 3Dircadb as well as local clinical datasets. The average dice and sensitivity for the 3Dircadb dataset were 67.5% and 74.3%, respectively, prior to annotation refinement, as compared with 75.3% and 76.7% after refinement. Conclusions: The proposed method is automatic, accurate and robust for liver vessel extraction with high noise and varied vessel structures. It can be used for liver surgery planning and rough annotation of new datasets. The evaluation difference based on some benchmarks, and their refined results, showed that the quality of annotation should be further considered for supervised learning methods. © 2018 Elsevier Ltd","3D U-Net; Annotation quality; Liver vessel extraction; Refined manual expert annotations; Variant dice loss function","Blood Vessels; Databases, Factual; Humans; Liver; Machine Learning; Tomography, X-Ray Computed; Benchmarking; Computerized tomography; Extraction; Function evaluation; Surgery; 3D U-Net; Complex vessel structures; Convolutional networks; Expert annotations; Liver vessels; Loss functions; Segmentation accuracy; Supervised learning methods; article; controlled study; diagnostic test accuracy study; extraction; human; learning; liver blood vessel; liver surgery; loss of function mutation; noise; punishment; blood vessel; diagnostic imaging; factual database; liver; machine learning; procedures; vascularization; x-ray computed tomography; Quality control","Elsevier Ltd","00104825","","CBMDA","30144657","Article","Scopus","2-s2.0-85051835592"
"Mungofa P.; Schumann A.; Waldo L.","Mungofa, Perseverança (57204097357); Schumann, Arnold (7004465049); Waldo, Laura (25959393100)","57204097357; 7004465049; 25959393100","Chemical crystal identification with deep learning machine vision","2018","BMC Research Notes","8","10.1186/s13104-018-3813-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054458681&doi=10.1186%2fs13104-018-3813-8&partnerID=40&md5=9bcb670adea3579ab1d2d538440e93ef","Soil and Water Science Department, Citrus Research and Education Center, University of Florida, 700 Experiment Station Rd, Lake Alfred, 33850, FL, United States","Mungofa P., Soil and Water Science Department, Citrus Research and Education Center, University of Florida, 700 Experiment Station Rd, Lake Alfred, 33850, FL, United States; Schumann A., Soil and Water Science Department, Citrus Research and Education Center, University of Florida, 700 Experiment Station Rd, Lake Alfred, 33850, FL, United States; Waldo L., Soil and Water Science Department, Citrus Research and Education Center, University of Florida, 700 Experiment Station Rd, Lake Alfred, 33850, FL, United States","Objective: This study was carried out with the purpose of testing the ability of deep learning machine vision to identify microscopic objects and geometries found in chemical crystal structures. Results: A database of 6994 images taken with a light microscope showing microscopic crystal details of selected chemical compounds along with 180 images of an unknown chemical was created to train and test, respectively the deep learning models. The models used were GoogLeNet (22 layers deep network) and VGG-16 (16 layers deep network), based on the Caffe framework (University of California, Berkeley, CA) of the DIGITS platform (NVIDIA Corporation, Santa Clara, CA). The two models were successfully trained with the images, having validation accuracy values of 97.38% and 99.65% respectively. Finally, both models were able to correctly identify the unknown chemical sample with a high probability score of 93.34% (GoogLeNet) and 99.41% (VGG-16). The positive results found in this study can be further applied to other unknown sample identification tasks using light microscopy coupled with deep learning machine vision. © 2018 The Author(s).","Chemical crystals; Deep learning; GoogLeNet; Image classification; Microscopic objects; VGG-16","Agrochemicals; Deep Learning; Image Processing, Computer-Assisted; Microscopy; Pattern Recognition, Automated; agricultural chemical; automated pattern recognition; image processing; microscopy","BioMed Central Ltd.","17560500","","","30290837","Article","Scopus","2-s2.0-85054458681"
"Wang Z.; Wang J.; Wang Y.","Wang, Zirui (57202218038); Wang, Jun (57224988246); Wang, Youren (8717353200)","57202218038; 57224988246; 8717353200","An intelligent diagnosis scheme based on generative adversarial learning deep neural networks and its application to planetary gearbox fault pattern recognition","2018","Neurocomputing","289","10.1016/j.neucom.2018.05.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047495975&doi=10.1016%2fj.neucom.2018.05.024&partnerID=40&md5=0b4e3daee207877a63bb254343b10d03","College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, Jiangsu, China","Wang Z., College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, Jiangsu, China; Wang J., College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, Jiangsu, China; Wang Y., College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, Jiangsu, China","Planetary gearbox has complex structures and works under various non-stationary operating conditions. The vibration signals of planetary gearbox are complicated and usually polluted by noise and interference. It is difficult to extract effective features of early faults. In addition, there are only a small number of fault samples for planetary gearbox fault diagnosis. All of these increase the difficulty of planetary gearbox fault diagnosis. Aiming at these problems, a novel fault diagnostic method is proposed which combines Generative Adversarial Networks (GAN) and Stacked Denoising Autoencoders (SDAE). The generator of GAN can generate new samples which has similar distribution with original samples from planetary gearbox vibration signals. Then, generated samples are transformed to the discriminator together with original samples which expand the sample size. SDAE is used as the discriminator of GAN which can automatically extract effective fault features from input samples and discriminate their authenticity and fault categories. Through novel adversarial machine learning mechanism, the generator and discriminator are concurrently optimized to enhance the quality of generation samples and the ability of fault mode classification. The experimental results show that the developed SDAE-GAN method for planetary gearbox has good anti-noise ability and achieve better fault diagnosis performance in the case of small samples. © 2018 Elsevier Ltd","Adversarial machine learning; Deep stacked denoising autoencoders; Fault diagnosis; Generative adversarial networks; Planetary gearbox; Small samples","Artificial intelligence; Deep neural networks; Failure analysis; Gears; Pattern recognition; Adversarial networks; Autoencoders; Diagnosis performance; Fault diagnostic methods; Intelligent diagnosis; Machine learning mechanism; Planetary gearboxes; Small samples; Article; artificial neural network; automated pattern recognition; controlled study; diagnostic value; learning algorithm; machine learning; mathematical computing; mathematical model; planetary gearbox fault; priority journal; Fault detection","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85047495975"
"Gao X.W.; Qian Y.","Gao, Xiaohong W. (36170243000); Qian, Yu (57197782929)","36170243000; 57197782929","Prediction of Multidrug-Resistant TB from CT Pulmonary Images Based on Deep Learning Techniques","2018","Molecular Pharmaceutics","39","10.1021/acs.molpharmaceut.7b00875","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051079066&doi=10.1021%2facs.molpharmaceut.7b00875&partnerID=40&md5=22be2ea2bac24ebbe2dc37a5ebab08de","Department of Computer Science, Middlesex University, London, NW4 4BT, United Kingdom; Cortexica Vision Systems, London, United Kingdom","Gao X.W., Department of Computer Science, Middlesex University, London, NW4 4BT, United Kingdom; Qian Y., Cortexica Vision Systems, London, United Kingdom","While tuberculosis (TB) disease was discovered more than a century ago, it has not been eradicated yet. Quite contrary, at present, TB constitutes one of the top 10 causes of death and has shown signs of increasing. To complement the conventional diagnostic procedure of applying microbiological culture that takes several weeks and remains expensive, high resolution computer tomography (CT) of pulmonary images has been resorted to not only for aiding clinicians to expedite the process of diagnosis but also for monitoring prognosis when administering antibiotic drugs. This research undertakes the investigation of predicting multidrug-resistant (MDR) patients from drug-sensitive (DS) ones based on CT lung images to monitor the effectiveness of treatment. To contend with smaller data sets (i.e., hundreds) and the characteristics of CT TB images with limited regions capturing abnormities, patch-based deep convolutional neural network (CNN) allied to support vector machine (SVM) classifier is implemented on a collection of data sets from 230 patients obtained from the ImageCLEF 2017 competition. As a result, the proposed architecture of CNN + SVM + patch performs the best with classification accuracy rate at 91.11% (79.80% in terms of patches). In addition, a hand-crafted SIFT based approach accomplishes 88.88% in terms of subject and 83.56% with reference to patches, the highest in this study, which can be explained away by the fact that the data sets are in small numbers. Significantly, during the Tuberculosis Competition at ImageCLEF 2017, the authors took part in the task of classification of 5 types of TB disease and achieved the top one with regard to averaged classification accuracy (i.e., ACC = 0.4067), which is also premised on the approach of CNN + SVM + patch. On the other hand, when the whole slices of 3D TB data sets are applied to train a CNN network, the best result is achieved through the application of CNN coupled with orderless pooling and SVM at 64.71% accuracy rate. © 2017 American Chemical Society.","classification; deep learning; multidrug-resistant TB; patch-based image classification; SVM; tuberculosis (TB)","Deep Learning; Humans; Neural Networks (Computer); Support Vector Machine; Tomography, X-Ray Computed; Tuberculosis, Multidrug-Resistant; Article; convolutional neural network; human; machine learning; multidrug resistant tuberculosis; prediction; priority journal; support vector machine; x-ray computed tomography; artificial neural network; diagnostic imaging; multidrug resistant tuberculosis; procedures; x-ray computed tomography","American Chemical Society","15438384","","MPOHB","29257894","Article","Scopus","2-s2.0-85051079066"
"Krauß S.D.; Roy R.; Yosef H.K.; Lechtonen T.; El-Mashtoly S.F.; Gerwert K.; Mosig A.","Krauß, Sascha D. (56150275200); Roy, Raphael (57203163074); Yosef, Hesham K. (56022642500); Lechtonen, Tatjana (57194688788); El-Mashtoly, Samir F. (14420690000); Gerwert, Klaus (7003540537); Mosig, Axel (23091372000)","56150275200; 57203163074; 56022642500; 57194688788; 14420690000; 7003540537; 23091372000","Hierarchical deep convolutional neural networks combine spectral and spatial information for highly accurate Raman-microscopy-based cytopathology","2018","Journal of Biophotonics","33","10.1002/jbio.201800022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050718226&doi=10.1002%2fjbio.201800022&partnerID=40&md5=29b9ceb587f70bd1b2b3f364dfc85b83","Department of Biophysics, Ruhr-University Bochum, Bochum, Germany","Krauß S.D., Department of Biophysics, Ruhr-University Bochum, Bochum, Germany; Roy R., Department of Biophysics, Ruhr-University Bochum, Bochum, Germany; Yosef H.K., Department of Biophysics, Ruhr-University Bochum, Bochum, Germany; Lechtonen T., Department of Biophysics, Ruhr-University Bochum, Bochum, Germany; El-Mashtoly S.F., Department of Biophysics, Ruhr-University Bochum, Bochum, Germany; Gerwert K., Department of Biophysics, Ruhr-University Bochum, Bochum, Germany; Mosig A., Department of Biophysics, Ruhr-University Bochum, Bochum, Germany","Hierarchical variants of so-called deep convolutional neural networks (DCNNs) have facilitated breakthrough results for numerous pattern recognition tasks in recent years. We assess the potential of these novel whole-image classifiers for Raman-microscopy-based cytopathology. Conceptually, DCNNs facilitate a flexible combination of spectral and spatial information for classifying cellular images as healthy or cancer-affected cells. As we demonstrate, this conceptual advantage translates into practice, where DCNNs exceed the accuracy of both conventional classifiers based on pixel spectra as well as classifiers based on morphological features extracted from Raman microscopic images. Remarkably, accuracies exceeding those of all previously proposed classifiers are obtained while using only a small fraction of the spectral information provided by the dataset. Overall, our results indicate a high potential for DCNNs in medical applications of not just Raman, but also infrared microscopy. © 2018 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","neural networks; Raman spectroscopy; supervised machine learning; urinary bladder neoplasms","Humans; Microscopy; Neural Networks (Computer); Pathology; Urinalysis; Convolution; Deep neural networks; Image classification; Medical applications; Neural networks; Raman spectroscopy; Supervised learning; Conventional classifier; Deep convolutional neural networks; Infrared microscopy; Morphological features; Spatial informations; Spectral information; Supervised machine learning; Urinary bladder; artificial neural network; human; microscopy; pathology; procedures; urinalysis; Classification (of information)","Wiley-VCH Verlag","1864063X","","","29781102","Article","Scopus","2-s2.0-85050718226"
"Urban G.; Tripathi P.; Alkayali T.; Mittal M.; Jalali F.; Karnes W.; Baldi P.","Urban, Gregor (57192234261); Tripathi, Priyam (57057134000); Alkayali, Talal (57204034977); Mittal, Mohit (57193423689); Jalali, Farid (56428856700); Karnes, William (7004068848); Baldi, Pierre (7101759672)","57192234261; 57057134000; 57204034977; 57193423689; 56428856700; 7004068848; 7101759672","Deep Learning Localizes and Identifies Polyps in Real Time With 96% Accuracy in Screening Colonoscopy","2018","Gastroenterology","471","10.1053/j.gastro.2018.06.037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053727578&doi=10.1053%2fj.gastro.2018.06.037&partnerID=40&md5=22bd6010cd48c8813e8ea4c7ca43c457","Department of Computer Science, University of California, Irvine, CA, United States; Institute for Genomics and Bioinformatics, University of California, Irvine, CA, United States; Center for Machine Learning and Intelligent Systems, University of California, Irvine, CA, United States; Department of Medicine, University of California, Irvine, CA, United States; H.H. Chao Comprehensive Digestive Disease Center, University of California, Irvine, CA, United States","Urban G., Department of Computer Science, University of California, Irvine, CA, United States, Institute for Genomics and Bioinformatics, University of California, Irvine, CA, United States; Tripathi P., Department of Medicine, University of California, Irvine, CA, United States; Alkayali T., Department of Medicine, University of California, Irvine, CA, United States, H.H. Chao Comprehensive Digestive Disease Center, University of California, Irvine, CA, United States; Mittal M., Department of Medicine, University of California, Irvine, CA, United States; Jalali F., Department of Medicine, University of California, Irvine, CA, United States, H.H. Chao Comprehensive Digestive Disease Center, University of California, Irvine, CA, United States; Karnes W., Department of Medicine, University of California, Irvine, CA, United States, H.H. Chao Comprehensive Digestive Disease Center, University of California, Irvine, CA, United States; Baldi P., Department of Computer Science, University of California, Irvine, CA, United States, Institute for Genomics and Bioinformatics, University of California, Irvine, CA, United States, Center for Machine Learning and Intelligent Systems, University of California, Irvine, CA, United States","Background & Aims: The benefit of colonoscopy for colorectal cancer prevention depends on the adenoma detection rate (ADR). The ADR should reflect the adenoma prevalence rate, which is estimated to be higher than 50% in the screening-age population. However, the ADR by colonoscopists varies from 7% to 53%. It is estimated that every 1% increase in ADR lowers the risk of interval colorectal cancers by 3%–6%. New strategies are needed to increase the ADR during colonoscopy. We tested the ability of computer-assisted image analysis using convolutional neural networks (CNNs; a deep learning model for image analysis) to improve polyp detection, a surrogate of ADR. Methods: We designed and trained deep CNNs to detect polyps using a diverse and representative set of 8,641 hand-labeled images from screening colonoscopies collected from more than 2000 patients. We tested the models on 20 colonoscopy videos with a total duration of 5 hours. Expert colonoscopists were asked to identify all polyps in 9 de-identified colonoscopy videos, which were selected from archived video studies, with or without benefit of the CNN overlay. Their findings were compared with those of the CNN using CNN-assisted expert review as the reference. Results: When tested on manually labeled images, the CNN identified polyps with an area under the receiver operating characteristic curve of 0.991 and an accuracy of 96.4%. In the analysis of colonoscopy videos in which 28 polyps were removed, 4 expert reviewers identified 8 additional polyps without CNN assistance that had not been removed and identified an additional 17 polyps with CNN assistance (45 in total). All polyps removed and identified by expert review were detected by the CNN. The CNN had a false-positive rate of 7%. Conclusion: In a set of 8,641 colonoscopy images containing 4,088 unique polyps, the CNN identified polyps with a cross-validation accuracy of 96.4% and an area under the receiver operating characteristic curve of 0.991. The CNN system detected and localized polyps well within real-time constraints using an ordinary desktop machine with a contemporary graphics processing unit. This system could increase the ADR and decrease interval colorectal cancers but requires validation in large multicenter trials. © 2018 AGA Institute","Adenoma Detection Rate Improving Technology; Colorectal Cancer Prevention; Convolutional Neural Networks; Machine Learning","Adenomatous Polyps; Area Under Curve; Colonic Polyps; Colonoscopy; Colorectal Neoplasms; Diagnosis, Computer-Assisted; Early Detection of Cancer; Feasibility Studies; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Observer Variation; Predictive Value of Tests; Prognosis; Reproducibility of Results; ROC Curve; Video Recording; Article; cancer screening; colonoscopy; colorectal adenoma; colorectal cancer; convolutional neural network; diagnostic accuracy; false positive result; human; image analysis; machine learning; polyp; priority journal; adenomatous polyp; area under the curve; artificial neural network; colon polyp; colonoscopy; colorectal tumor; computer assisted diagnosis; early cancer diagnosis; feasibility study; observer variation; pathology; predictive value; procedures; prognosis; receiver operating characteristic; reproducibility; videorecording","W.B. Saunders","00165085","","GASTA","29928897","Article","Scopus","2-s2.0-85053727578"
"Vasconcelos F.; Brandão P.; Vercauteren T.; Ourselin S.; Deprest J.; Peebles D.; Stoyanov D.","Vasconcelos, Francisco (47862298300); Brandão, Patrick (57194468794); Vercauteren, Tom (23010613000); Ourselin, Sebastien (6602233595); Deprest, Jan (7006218373); Peebles, Donald (7006889522); Stoyanov, Danail (57203105770)","47862298300; 57194468794; 23010613000; 6602233595; 7006218373; 7006889522; 57203105770","Towards computer-assisted TTTS: Laser ablation detection for workflow segmentation from fetoscopic video","2018","International Journal of Computer Assisted Radiology and Surgery","9","10.1007/s11548-018-1813-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049111060&doi=10.1007%2fs11548-018-1813-8&partnerID=40&md5=6916fe7c1a2189507d2934c778ff5d6b","Wellcome / EPSRC Centre for Interventional and Surgical Sciences Centre For Medical Image Computing, University College London, London, United Kingdom; Department of Obstetrics and Gynecology, University Hospitals Leuven, Louvain, Belgium; Department of Obstetrics and Gynecology, University College London, London, United Kingdom","Vasconcelos F., Wellcome / EPSRC Centre for Interventional and Surgical Sciences Centre For Medical Image Computing, University College London, London, United Kingdom; Brandão P., Wellcome / EPSRC Centre for Interventional and Surgical Sciences Centre For Medical Image Computing, University College London, London, United Kingdom; Vercauteren T., Wellcome / EPSRC Centre for Interventional and Surgical Sciences Centre For Medical Image Computing, University College London, London, United Kingdom; Ourselin S., Wellcome / EPSRC Centre for Interventional and Surgical Sciences Centre For Medical Image Computing, University College London, London, United Kingdom; Deprest J., Department of Obstetrics and Gynecology, University Hospitals Leuven, Louvain, Belgium; Peebles D., Department of Obstetrics and Gynecology, University College London, London, United Kingdom; Stoyanov D., Wellcome / EPSRC Centre for Interventional and Surgical Sciences Centre For Medical Image Computing, University College London, London, United Kingdom","Purpose: Intrauterine foetal surgery is the treatment option for several congenital malformations. For twin-to-twin transfusion syndrome (TTTS), interventions involve the use of laser fibre to ablate vessels in a shared placenta. The procedure presents a number of challenges for the surgeon, and computer-assisted technologies can potentially be a significant support. Vision-based sensing is the primary source of information from the intrauterine environment, and hence, vision approaches present an appealing approach for extracting higher level information from the surgical site. Methods: In this paper, we propose a framework to detect one of the key steps during TTTS interventions—ablation. We adopt a deep learning approach, specifically the ResNet101 architecture, for classification of different surgical actions performed during laser ablation therapy. Results: We perform a two-fold cross-validation using almost 50 k frames from five different TTTS ablation procedures. Our results show that deep learning methods are a promising approach for ablation detection. Conclusion: To our knowledge, this is the first attempt at automating photocoagulation detection using video and our technique can be an important component of a larger assistive framework for enhanced foetal therapies. The current implementation does not include semantic segmentation or localisation of the ablation site, and this would be a natural extension in future work. © 2018, The Author(s).","Deep learning; Endoscopy; Twin-to-twin transfusion syndrome (TTTS); Workflow segmentation","Algorithms; Diagnosis, Computer-Assisted; False Positive Reactions; Female; Fetofetal Transfusion; Fetoscopy; Humans; Image Processing, Computer-Assisted; Laser Therapy; Lasers; Placenta; Pregnancy; Pregnancy Complications; Reproducibility of Results; Support Vector Machine; Video Recording; Workflow; Article; classification; classification algorithm; computer assisted diagnosis; controlled study; false positive result; fetoscopy; fetus; human; image segmentation; jackknife test; laser surgery; network learning; priority journal; twin twin transfusion syndrome; videorecording; workflow; algorithm; diagnostic imaging; female; image processing; laser; low level laser therapy; newborn anemia; placenta; pregnancy; pregnancy complication; reproducibility; support vector machine; videorecording; workflow","Springer Verlag","18616410","","","29951938","Article","Scopus","2-s2.0-85049111060"
"Banerjee S.; Das S.","Banerjee, Samik (55702079100); Das, Sukhendu (55476994500)","55702079100; 55476994500","Mutual variation of information on transfer-CNN for face recognition with degraded probe samples","2018","Neurocomputing","36","10.1016/j.neucom.2018.05.038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048544747&doi=10.1016%2fj.neucom.2018.05.038&partnerID=40&md5=6668a43e9cfcd2f2a7fcd9dceb436d3e","Department of CS&E, IIT Madras, Chennai, India","Banerjee S., Department of CS&E, IIT Madras, Chennai, India; Das S., Department of CS&E, IIT Madras, Chennai, India","Learning based on convolutional neural networks (CNNs) or deep learning has been a major research area with applications in face recognition (FR). Under degraded conditions, performance of FR algorithms severely degrade. The work presented in this paper has three contributions. First, it proposes a transfer-CNN architecture of deep learning tailor-made for domain adaptation (DA), to overcome the difference in feature distributions between the gallery and probe samples. The proposed architecture consists of three units: base convolution (BCM), transfer (TM) and linear (LM) modules. Secondly, a novel 3-stage algorithm for Mutually Exclusive Training (3-MET) based on stochastic gradient descent, has been proposed. The initial stage of 3-MET involves updating the parameters of the BCM and LM units using samples from gallery. The second stage involves updating the parameters of TM, to bridge the disparity between the source and target distributions, based on mutual variation of information (MVI). The final stage of training in 3-MET freezes the layers of the BCM and TM, for updating (fine-tuning) only the parameters of the LM using a few probe (as target) samples. This helps the proposed transfer-CNN to provide enhanced domain-invariant representation for efficient deep-DA learning and classification. The third contribution comes from rigorous experimentations performed on three benchmark real-world degraded face datasets captured using surveillance cameras, one real-world dataset with non-uniform motion blur and three synthetically degraded benchmark face datasets. This exhibits superior performance of the proposed transfer-CNN architecture with 3-MET training, using Rank-1 recognition rates and ROC and CMC metrics, over many recent state-of-the-art techniques of CNN and DA. Experiments also include performance analysis under unbiased training with two large-scale chimeric face datasets. © 2018 Elsevier B.V.","3-MET; Deep-DA; Domain adaptation; Face recognition; KLD; Mutual variation of information; SGD; TM; Transfer-CNN","Convolution; Deep learning; Network architecture; Neural networks; Probes; Security systems; Stochastic systems; Thulium; 3-MET; Deep-DA; Domain adaptation; Transfer-CNN; Variation of informations; adaptation; Article; artificial neural network; base convolution module; benchmarking; deep domain adaptation; facial recognition; human; information processing; kernel method; learning algorithm; linear module; machine learning; mathematical computing; mutual variation of information; physical performance; priority journal; simulation training; statistical analysis; statistical significance; transfer convolutional neural network; transfer module; Face recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85048544747"
"Choi E.J.; Kim D.K.","Choi, Eun Jeong (57207765106); Kim, Dong Keun (55742977500)","57207765106; 55742977500","Arousal and valence classification model based on long short-term memory and DEAP data for mental healthcare management","2018","Healthcare Informatics Research","32","10.4258/hir.2018.24.4.309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062842482&doi=10.4258%2fhir.2018.24.4.309&partnerID=40&md5=5acce259d43c0fff7f0be8b2a0a99a73","Department of Computer Science, Graduate School, Sangmyung University, Seoul, South Korea; Department of Intelligent Engineering Informatics for Human, College of Convergence Engineering, Sangmyung University, Seoul, South Korea","Choi E.J., Department of Computer Science, Graduate School, Sangmyung University, Seoul, South Korea; Kim D.K., Department of Intelligent Engineering Informatics for Human, College of Convergence Engineering, Sangmyung University, Seoul, South Korea","Objectives: Both the valence and arousal components of affect are important considerations when managing mental healthcare because they are associated with affective and physiological responses. Research on arousal and valence analysis, which uses images, texts, and physiological signals that employ deep learning, is actively underway; research investigating how to improve the recognition rate is needed. The goal of this research was to design a deep learning framework and model to classify arousal and valence, indicating positive and negative degrees of emotion as high or low. Methods: The proposed arousal and valence classification model to analyze the affective state was tested using data from 40 channels provided by a dataset for emotion analysis using electrocardiography (EEG), physiological, and video signals (the DEAP dataset). Experiments were based on 10 selected featured central and peripheral nervous system data points, using long short-term memory (LSTM) as a deep learning method. Results: The arousal and valence were classified and visualized on a two-dimensional coordinate plane. Profiles were designed depending on the number of hidden layers, nodes, and hyperparameters according to the error rate. The experimental results show an arousal and valence classification model accuracy of 74.65 and 78%, respectively. The proposed model performed better than previous other models. Conclusions: The proposed model appears to be effective in analyzing arousal and valence; specifically, it is expected that affective analysis using physiological signals based on LSTM will be possible without manual feature extraction. In a future study, the classification model will be adopted in mental healthcare management systems. © 2018 The Korean Society of Medical Informatics.","Arousal and valence analysis; Classification; DEAP Dataset; Machine learning; Supervised machine learning","arousal; article; controlled study; deep learning; electrocardiography; feature extraction; health care management; human; human experiment; peripheral nervous system; short term memory; supervised machine learning; videorecording","Korean Society of Medical Informatics","20933681","","","","Article","Scopus","2-s2.0-85062842482"
"Arora A.; Lin J.-J.; Gasperian A.; Maldjian J.; Stein J.; Kahana M.; Lega B.","Arora, Akshay (57204666412); Lin, Jui-Jui (57194005147); Gasperian, Alec (57204674832); Maldjian, Joseph (7003284184); Stein, Joel (56415623100); Kahana, Michael (7004417058); Lega, Bradley (14066258400)","57204666412; 57194005147; 57204674832; 7003284184; 56415623100; 7004417058; 14066258400","Comparison of logistic regression, support vector machines, and deep learning classifiers for predicting memory encoding success using human intracranial EEG recordings","2018","Journal of Neural Engineering","31","10.1088/1741-2552/aae131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056641695&doi=10.1088%2f1741-2552%2faae131&partnerID=40&md5=3a4723d6f2efeb1a0815c526fd4356fe","Department of Neurological Surgery, University of Texas, Southwestern Medical Center, Dallas, 75390, TX, United States; Department of Radiology, University of Texas, Southwestern Medical Center, Dallas, 75390, TX, United States; Department of Radiology, University of Pennsylvania, Philadelphia, 19104, PA, United States; Department of Psychology, University of Pennsylvania, Philadelphia, 19104, PA, United States; UT-Southwestern, Neurological Surgery MS 8855, 5323 Harry Hines Blvd, Dallas, 75390, TX, United States","Arora A., Department of Neurological Surgery, University of Texas, Southwestern Medical Center, Dallas, 75390, TX, United States; Lin J.-J., Department of Neurological Surgery, University of Texas, Southwestern Medical Center, Dallas, 75390, TX, United States; Gasperian A., Department of Neurological Surgery, University of Texas, Southwestern Medical Center, Dallas, 75390, TX, United States; Maldjian J., Department of Radiology, University of Texas, Southwestern Medical Center, Dallas, 75390, TX, United States; Stein J., Department of Radiology, University of Pennsylvania, Philadelphia, 19104, PA, United States; Kahana M., Department of Psychology, University of Pennsylvania, Philadelphia, 19104, PA, United States; Lega B., Department of Neurological Surgery, University of Texas, Southwestern Medical Center, Dallas, 75390, TX, United States, UT-Southwestern, Neurological Surgery MS 8855, 5323 Harry Hines Blvd, Dallas, 75390, TX, United States","Objective. We sought to test the performance of three strategies for binary classification (logistic regression, support vector machines, and deep learning) for the problem of predicting successful episodic memory encoding using direct brain recordings obtained from human stereo EEG subjects. We also sought to test the impact of applying t-distributed stochastic neighbor embedding (tSNE) for unsupervised dimensionality reduction, as well as testing the effect of reducing input features to a core set of memory relevant brain areas. This work builds upon published efforts to develop a closed-loop stimulation device to improve memory performance. Approach. We used a unique data set consisting of 30 stereo EEG patients with electrodes implanted into a core set of five common brain regions (along with other areas) who performed the free recall episodic memory task as brain activity was recorded. Using three different machine learning strategies, we trained classifiers to predict successful versus unsuccessful memory encoding and compared the difference in classifier performance (as measured by the AUC) at the subject level and in aggregate across modalities. We report the impact of feature reduction on the classifiers, including reducing the number of input brain regions, frequency bands, and the impact of tSNE. Results. Deep learning classifiers outperformed both support vector machines (SVM) and logistic regression (LR). A priori selection of core brain regions also improved classifier performance for LR and SVM models, especially when combined with tSNE. Significance. We report for the first time a direct comparison among traditional and deep learning methods of binary classification to the problem of predicting successful memory encoding using human brain electrophysiological data. Our findings will inform the design of brain machine interface devices to affect memory processing. © 2018 IOP Publishing Ltd.","brain machine interface; episodic memory; oscillations; recurrent neural networks; support vector machines; tSNE","Algorithms; Computer Simulation; Deep Learning; Electrodes, Implanted; Electroencephalography; Humans; Logistic Models; Memory, Episodic; Mental Recall; Predictive Value of Tests; Stochastic Processes; Support Vector Machine; Theta Rhythm; amnesia; Article; brain electrophysiology; brain region; classifier; clinical article; deep learning; episodic memory; hemisphere; human; learning; logistic regression analysis; long term memory; machine learning; mental task; priority journal; seizure; short term memory; stereoelectroencephalography; stochastic model; support vector machine; algorithm; classification; comparative study; computer simulation; electrode implant; electroencephalography; episodic memory; Markov chain; predictive value; recall; statistical model; theta rhythm","Institute of Physics Publishing","17412560","","","30211695","Article","Scopus","2-s2.0-85056641695"
"Keshet J.","Keshet, Joseph (8671885400)","8671885400","Automatic speech recognition: A primer for speech-language pathology researchers","2018","International Journal of Speech-Language Pathology","15","10.1080/17549507.2018.1510033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059898499&doi=10.1080%2f17549507.2018.1510033&partnerID=40&md5=253311c229f22bf369bb24d395d4658d","Department of Computer Science, Bar-Ilan University, Ramat Gan, Israel","Keshet J., Department of Computer Science, Bar-Ilan University, Ramat Gan, Israel","Automatic speech recognition (ASR) is increasingly becoming an integral component of our daily lives. This trend is in large part due to recent advances in machine learning, and specifically in deep learning, that have led to accurate ASR across numerous tasks. This has led to renewed interest in providing technological support to populations whose speech patterns are atypical, including identifying the presence of a specific pathology and its severity, comparing speech characteristics before and after a surgery and enhancing the quality of life of individuals with speech pathologies. The purpose of this primer is to bring readers with relatively little technical background up to speed on fundamentals and recent advances in ASR. It presents a detailed account of the anatomy of modern ASR, with examples of how it has been used in speech-language pathology research. © 2018, The Speech Pathology Association of Australia Ltd.","assessment of speech intelligibility; automatic speech recognition; monitoring; speech pathologies","Deep Learning; Humans; Speech; Speech Recognition Software; Speech-Language Pathology; automatic speech recognition; human; procedures; speech; speech disorder","Taylor and Francis Ltd","17549515","","","31274357","Article","Scopus","2-s2.0-85059898499"
"Mitra A.; Banerjee P.S.; Roy S.; Roy S.; Setua S.K.","Mitra, Anirban (57213876003); Banerjee, Priya Shankar (57203396428); Roy, Sudipta (56406670700); Roy, Somasis (56177093700); Setua, Sanjit Kumar (6504663637)","57213876003; 57203396428; 56406670700; 56177093700; 6504663637","The region of interest localization for glaucoma analysis from retinal fundus image using deep learning","2018","Computer Methods and Programs in Biomedicine","39","10.1016/j.cmpb.2018.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051471876&doi=10.1016%2fj.cmpb.2018.08.003&partnerID=40&md5=f338f3cfa038e47a88087ed08f6ad455","Department of Computer Science & Engineering, Calcutta University Technology Campus, JD-2, Sector-III, Salt Lake, Kolkata, 700098, India; Department of Computer Science & Engineering, Academy of Technology, Adisaptagram, 712121, West Bengal, India; Mallinckrodt Institute of Radiology Department (MIR), Washington University School of Medicine, Campus Box 8225, 510 South Kingshighway Boulevard, Saint Louis, 63110-1076, MO, United States","Mitra A., Department of Computer Science & Engineering, Calcutta University Technology Campus, JD-2, Sector-III, Salt Lake, Kolkata, 700098, India, Department of Computer Science & Engineering, Academy of Technology, Adisaptagram, 712121, West Bengal, India; Banerjee P.S., Department of Computer Science & Engineering, Academy of Technology, Adisaptagram, 712121, West Bengal, India; Roy S., Department of Computer Science & Engineering, Calcutta University Technology Campus, JD-2, Sector-III, Salt Lake, Kolkata, 700098, India, Mallinckrodt Institute of Radiology Department (MIR), Washington University School of Medicine, Campus Box 8225, 510 South Kingshighway Boulevard, Saint Louis, 63110-1076, MO, United States; Roy S., Department of Computer Science & Engineering, Calcutta University Technology Campus, JD-2, Sector-III, Salt Lake, Kolkata, 700098, India; Setua S.K., Department of Computer Science & Engineering, Calcutta University Technology Campus, JD-2, Sector-III, Salt Lake, Kolkata, 700098, India","Background and objectives: Retinal fundus image analysis without manual intervention has been rising as an imperative analytical approach for early detection of eye-related diseases such as glaucoma and diabetic retinopathy. For analysis and detection of Glaucoma and some other disease from retinal image, there is a significant role of predicting the bounding box coordinates of Optic Disc (OD) that acts as a Region of Interest (ROI). Methods: We reframe ROI detection as a solitary regression predicament, from image pixel values to ROI coordinates including class probabilities. A Convolution Neural Network (CNN) has trained on full images to predict bounding boxes along with their analogous probabilities and confidence scores. The publically available MESSIDOR and Kaggle datasets have been used to train the network. We adopted various data augmentation techniques to amplify our dataset so that our network becomes less sensitive to noise. From a very high-level perspective, every image is divided into a 13 × 13 grid. Every grid cell envisages 5 bounding boxes along with the corresponding class probability and a confidence score. Before training, the network and the bounding box priors or anchors are initialized using k-means clustering on the original dataset using a distance metric based on Intersection of the Union (IOU) over ground-truth bounding boxes. During training in fact, a sum-squared loss function is used as the prediction's error function. Finally, Non-maximum suppression is applied by the proposed methodology to reach the concluding prediction. Results: The following projected method accomplish an accuracy of 99.05% and 98.78% on the Kaggle and MESSIDOR test sets for ROI detection. Results of proposed methodology indicates that proposed network is able to perceive ROI in fundus images in 0.0045 s at 25 ms of latency, which is far better than the recent-time and using no handcrafted features. Conclusions: The network predicts accurate results even on low-quality images without being biased towards any particular type of image. The network prepared to see more summed up depiction rather than past works in the field. Going by the results, our novel method has better diagnosis of eye diseases in the future in a faster and reliable way. © 2018 Elsevier B.V.","Anchor Boxes; Batch Normalization; Convolution Neural Networks; Intersection over Union; K-means clustering; Leaky ReLU, Max Pooling; Non-maximum suppression; Optic Disc Localization","Algorithms; Databases, Factual; Deep Learning; Diagnosis, Computer-Assisted; Diagnostic Techniques, Ophthalmological; Fundus Oculi; Glaucoma; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Neural Networks (Computer); Optic Disk; Convolution; Deep learning; Diagnosis; Eye protection; Forecasting; Image segmentation; Ophthalmology; Anchor-box; Batch Normalization; Convolution neural network; K - means clustering; Max-pooling; Non-maximum suppression; Optic disc localization; analytic method; Article; back propagation; deep learning; diabetic patient; diabetic retinopathy; diagnostic accuracy; eye fundus; glaucoma; grid cell; human; image analysis; latent period; learning; machine learning; optic disk; prediction; region of interest; retina image; support vector machine; algorithm; artificial neural network; computer assisted diagnosis; diagnostic imaging; evaluation study; eye fundus; factual database; glaucoma; image enhancement; pathology; procedures; visual system examination; Image analysis","Elsevier Ireland Ltd","01692607","","CMPBE","30337079","Article","Scopus","2-s2.0-85051471876"
"Rafegas I.; Vanrell M.","Rafegas, Ivet (57194188465); Vanrell, Maria (6603615441)","57194188465; 6603615441","Color encoding in biologically-inspired convolutional neural networks","2018","Vision Research","29","10.1016/j.visres.2018.03.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046870915&doi=10.1016%2fj.visres.2018.03.010&partnerID=40&md5=cced6e5c21fcdfa23caafd30129c39c9","Computer Vision Center, Universitat Autònoma de Barcelona, Edifici O, Campus UAB-Bellaterra, Barcelona, Spain","Rafegas I., Computer Vision Center, Universitat Autònoma de Barcelona, Edifici O, Campus UAB-Bellaterra, Barcelona, Spain; Vanrell M., Computer Vision Center, Universitat Autònoma de Barcelona, Edifici O, Campus UAB-Bellaterra, Barcelona, Spain","Convolutional Neural Networks have been proposed as suitable frameworks to model biological vision. Some of these artificial networks showed representational properties that rival primate performances in object recognition. In this paper we explore how color is encoded in a trained artificial network. It is performed by estimating a color selectivity index for each neuron, which allows us to describe the neuron activity to a color input stimuli. The index allows us to classify whether they are color selective or not and if they are of a single or double color. We have determined that all five convolutional layers of the network have a large number of color selective neurons. Color opponency clearly emerges in the first layer, presenting 4 main axes (Black-White, Red-Cyan, Blue-Yellow and Magenta-Green), but this is reduced and rotated as we go deeper into the network. In layer 2 we find a denser hue sampling of color neurons and opponency is reduced almost to one new main axis, the Bluish-Orangish coinciding with the dataset bias. In layers 3, 4 and 5 color neurons are similar amongst themselves, presenting different type of neurons that detect specific colored objects (e.g., orangish faces), specific surrounds (e.g., blue sky) or specific colored or contrasted object-surround configurations (e.g. blue blob in a green surround). Overall, our work concludes that color and shape representation are successively entangled through all the layers of the studied network, revealing certain parallelisms with the reported evidences in primate brains that can provide useful insight into intermediate hierarchical spatio-chromatic representations. © 2018 Elsevier Ltd","Color coding; Computer vision; Convolutional neural networks; Deep learning","Color Perception; Color Vision; Humans; Models, Biological; Neural Networks (Computer); Article; artificial neural network; brain; classifier; color; color coding; computer vision; controlled study; convolutional neural network; machine learning; nerve cell; primate; priority journal; vision; biological model; color vision; human; physiology","Elsevier Ltd","00426989","","VISRA","29730046","Article","Scopus","2-s2.0-85046870915"
"Buda M.; Maki A.; Mazurowski M.A.","Buda, Mateusz (57203226308); Maki, Atsuto (7102427653); Mazurowski, Maciej A. (21742977700)","57203226308; 7102427653; 21742977700","A systematic study of the class imbalance problem in convolutional neural networks","2018","Neural Networks","1505","10.1016/j.neunet.2018.07.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050996431&doi=10.1016%2fj.neunet.2018.07.011&partnerID=40&md5=e3a7471bdf37ac628895c6576b515135","Department of Radiology, Duke University School of Medicine, Durham, NC, United States; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States","Buda M., Department of Radiology, Duke University School of Medicine, Durham, NC, United States, School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Maki A., School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Mazurowski M.A., Department of Radiology, Duke University School of Medicine, Durham, NC, United States, Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States","In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest. © 2018 Elsevier Ltd","Class imbalance; Convolutional neural networks; Deep learning; Image classification","Humans; Machine Learning; Neural Networks (Computer); Probability; ROC Curve; Classification (of information); Convolution; Image classification; Learning algorithms; Neural networks; Class imbalance; Class imbalance problems; Class probabilities; Classification performance; Convolutional neural network; Machine learning models; Receiver operating characteristic curves; Systematic research; article; intermethod comparison; machine learning; nervous system; probability; receiver operating characteristic; artificial neural network; human; trends; Deep learning","Elsevier Ltd","08936080","","NNETE","30092410","Article","Scopus","2-s2.0-85050996431"
"Yang H.; Zhang J.; Liu Q.; Wang Y.","Yang, Hao (57207200450); Zhang, Junran (36018035200); Liu, Qihong (57212729716); Wang, Yi (58396947600)","57207200450; 36018035200; 57212729716; 58396947600","Multimodal MRI-based classification of migraine: Using deep learning convolutional neural network 08 Information and Computing Sciences 0801 Artificial Intelligence and Image Processing","2018","BioMedical Engineering Online","35","10.1186/s12938-018-0587-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054825955&doi=10.1186%2fs12938-018-0587-0&partnerID=40&md5=182fffc2cf58978ec63b442a368fed14","Department of Medical Information Engineering, School of Electrical Engineering and Information, Sichuan University, Chengdu Sichuan, China","Yang H., Department of Medical Information Engineering, School of Electrical Engineering and Information, Sichuan University, Chengdu Sichuan, China; Zhang J., Department of Medical Information Engineering, School of Electrical Engineering and Information, Sichuan University, Chengdu Sichuan, China; Liu Q., Department of Medical Information Engineering, School of Electrical Engineering and Information, Sichuan University, Chengdu Sichuan, China; Wang Y., Department of Medical Information Engineering, School of Electrical Engineering and Information, Sichuan University, Chengdu Sichuan, China","Background: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine. Methods: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls. Results: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS). Conclusions: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future. © 2018 The Author(s).","Convolutional neural networks; Deep learning; Diagnosis; Migraine; Resting-state functional MRI","Adolescent; Adult; Case-Control Studies; Deep Learning; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Migraine Disorders; Multimodal Imaging; Young Adult; Classification (of information); Convolution; Decision making; Deep learning; Deep neural networks; Diagnosis; Holmium alloys; Image classification; Magnetic resonance imaging; Neural networks; Rhenium alloys; Clinical decision making; Convolutional neural network; Functional correlation; Low Frequency Fluctuations; Migraine; Neurological disorders; Resting state functional mris; Support vector machine classifiers; adolescent; adult; case control study; diagnostic imaging; female; human; image processing; male; middle aged; migraine; multimodal imaging; nuclear magnetic resonance imaging; procedures; young adult; Functional neuroimaging","BioMed Central Ltd.","1475925X","","BEOIB","30314437","Article","Scopus","2-s2.0-85054825955"
"Park S.J.; Shin J.Y.; Kim S.; Son J.; Jung K.-H.; Park K.H.","Park, Sang Jun (56144621600); Shin, Joo Young (57964955600); Kim, Sangkeun (57203985373); Son, Jaemin (57202445375); Jung, Kyu-Hwan (14037142200); Park, Kyu Hyung (34877309000)","56144621600; 57964955600; 57203985373; 57202445375; 14037142200; 34877309000","A novel fundus image reading tool for efficient generation of a multi-dimensional categorical image database for machine learning algorithm training","2018","Journal of Korean Medical Science","15","10.3346/jkms.2018.33.e239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055075176&doi=10.3346%2fjkms.2018.33.e239&partnerID=40&md5=68c109582735544077b2b3dc9ce00f87","Department of Ophthalmology, Seoul National University Bundang Hospital, Seoul National University College of Medicine, Seongnam, South Korea; Department of Ophthalmology, Dongguk University Ilsan Hospital, Goyang, South Korea; VUNO Inc., Seoul, South Korea","Park S.J., Department of Ophthalmology, Seoul National University Bundang Hospital, Seoul National University College of Medicine, Seongnam, South Korea; Shin J.Y., Department of Ophthalmology, Dongguk University Ilsan Hospital, Goyang, South Korea; Kim S., VUNO Inc., Seoul, South Korea; Son J., VUNO Inc., Seoul, South Korea; Jung K.-H., VUNO Inc., Seoul, South Korea; Park K.H., Department of Ophthalmology, Seoul National University Bundang Hospital, Seoul National University College of Medicine, Seongnam, South Korea","Background: We described a novel multi-step retinal fundus image reading system for providing high-quality large data for machine learning algorithms, and assessed the grader variability in the large-scale dataset generated with this system. Methods: A 5-step retinal fundus image reading tool was developed that rates image quality, presence of abnormality, findings with location information, diagnoses, and clinical significance. Each image was evaluated by 3 different graders. Agreements among graders for each decision were evaluated. Results: The 234,242 readings of 79,458 images were collected from 55 licensed ophthalmologists during 6 months. The 34,364 images were graded as abnormal by at-least one rater. Of these, all three raters agreed in 46.6% in abnormality, while 69.9% of the images were rated as abnormal by two or more raters. Agreement rate of at-least two raters on a certain finding was 26.7%-65.2%, and complete agreement rate of all-three raters was 5.7%-43.3%. As for diagnoses, agreement of at-least two raters was 35.6%-65.6%, and complete agreement rate was 11.0%-40.0%. Agreement of findings and diagnoses were higher when restricted to images with prior complete agreement on abnormality. Retinal/glaucoma specialists showed higher agreements on findings and diagnoses of their corresponding subspecialties. Conclusion: This novel reading tool for retinal fundus images generated a large-scale dataset with high level of information, which can be utilized in future development of machine learning-based algorithms for automated identification of abnormal conditions and clinical decision supporting system. These results emphasize the importance of addressing grader variability in algorithm developments. © 2018 The Korean Academy of Medical Sciences.","Deep learning; Grader; Machine learning; Reading tool; Retina fundus image","Databases, Factual; Fundus Oculi; Humans; Machine Learning; Republic of Korea; Retina; diagnostic imaging; eye fundus; factual database; human; machine learning; retina; South Korea","Korean Academy of Medical Science","10118934","","JKMSE","30344460","Article","Scopus","2-s2.0-85055075176"
"Grapov D.; Fahrmann J.; Wanichthanarak K.; Khoomrung S.","Grapov, Dmitry (53870105600); Fahrmann, Johannes (56282380500); Wanichthanarak, Kwanjeera (54909246600); Khoomrung, Sakda (24437837600)","53870105600; 56282380500; 54909246600; 24437837600","Rise of deep learning for genomic, proteomic, and metabolomic data integration in precision medicine","2018","OMICS A Journal of Integrative Biology","147","10.1089/omi.2018.0097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055203338&doi=10.1089%2fomi.2018.0097&partnerID=40&md5=4561d255e3d9e244cf0f785f63b1d2d6","CDS-Creative Data Solutions LLC, Ballwin, 63021, MO, United States; Department of Clinical Cancer Prevention, University of Texas MD Anderson, Houston, TX, United States; Department of Biochemistry, Faculty of Medicine Siriraj Hospital, Mahidol University, Bangkok, Thailand; Siriraj Metabolomics and Phenomics Center, Faculty of Medicine Siriraj Hospital, Mahidol University, Bangkok, Thailand","Grapov D., CDS-Creative Data Solutions LLC, Ballwin, 63021, MO, United States; Fahrmann J., Department of Clinical Cancer Prevention, University of Texas MD Anderson, Houston, TX, United States; Wanichthanarak K., Department of Biochemistry, Faculty of Medicine Siriraj Hospital, Mahidol University, Bangkok, Thailand, Siriraj Metabolomics and Phenomics Center, Faculty of Medicine Siriraj Hospital, Mahidol University, Bangkok, Thailand; Khoomrung S., Department of Biochemistry, Faculty of Medicine Siriraj Hospital, Mahidol University, Bangkok, Thailand, Siriraj Metabolomics and Phenomics Center, Faculty of Medicine Siriraj Hospital, Mahidol University, Bangkok, Thailand","Machine learning (ML) is being ubiquitously incorporated into everyday products such as Internet search, email spam filters, product recommendations, image classification, and speech recognition. New approaches for highly integrated manufacturing and automation such as the Industry 4.0 and the Internet of things are also converging with ML methodologies. Many approaches incorporate complex artificial neural network architectures and are collectively referred to as deep learning (DL) applications. These methods have been shown capable of representing and learning predictable relationships in many diverse forms of data and hold promise for transforming the future of omics research and applications in precision medicine. Omics and electronic health record data pose considerable challenges for DL. This is due to many factors such as low signal to noise, analytical variance, and complex data integration requirements. However, DL models have already been shown capable of both improving the ease of data encoding and predictive model performance over alternative approaches. It may not be surprising that concepts encountered in DL share similarities with those observed in biological message relay systems such as gene, protein, and metabolite networks. This expert review examines the challenges and opportunities for DL at a systems and biological scale for a precision medicine readership. © 2018 Dmitry Grapov, et al. Published by Mary Ann Liebert, Inc.","Artificial intelligence; Biomarkers; Deep learning; Machine learning; Multiomics data integration; Precision medicine","Deep Learning; Genomics; Machine Learning; Metabolomics; Neural Networks (Computer); Precision Medicine; Proteomics; Article; artificial neural network; genome-wide association study; genomics; human; nonhuman; omics; personalized medicine; priority journal; proteomics; single nucleotide polymorphism; genomics; machine learning; metabolomics; personalized medicine; proteomics; trends","Mary Ann Liebert Inc.","15362310","","OMICA","30124358","Article","Scopus","2-s2.0-85055203338"
"Yasaka K.; Akai H.; Kunimatsu A.; Abe O.; Kiryu S.","Yasaka, Koichiro (41762972600); Akai, Hiroyuki (55330259700); Kunimatsu, Akira (57393819900); Abe, Osamu (7103189098); Kiryu, Shigeru (7004240410)","41762972600; 55330259700; 57393819900; 7103189098; 7004240410","Deep learning for staging liver fibrosis on CT: a pilot study","2018","European Radiology","77","10.1007/s00330-018-5499-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046906470&doi=10.1007%2fs00330-018-5499-7&partnerID=40&md5=7a25198fb91a51ce4e1ab312a22783e2","Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan; Department of Radiology, Graduate School of Medicine, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8655, Japan; Department of Radiology, Graduate School of Medical Sciences, International University of Health and Welfare, 537-3 Iguchi, Nasushiobara, Tochigi, 329-2763, Japan","Yasaka K., Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan; Akai H., Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan; Kunimatsu A., Department of Radiology, The Institute of Medical Science, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo, 108-8639, Japan; Abe O., Department of Radiology, Graduate School of Medicine, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8655, Japan; Kiryu S., Department of Radiology, Graduate School of Medical Sciences, International University of Health and Welfare, 537-3 Iguchi, Nasushiobara, Tochigi, 329-2763, Japan","                             Objectives: To investigate whether liver fibrosis can be staged by deep learning techniques based on CT images. Methods: This clinical retrospective study, approved by our institutional review board, included 496 CT examinations of 286 patients who underwent dynamic contrast-enhanced CT for evaluations of the liver and for whom histopathological information regarding liver fibrosis stage was available. The 396 portal phase images with age and sex data of patients (F0/F1/F2/F3/F4 = 113/36/56/66/125) were used for training a deep convolutional neural network (DCNN); the data for the other 100 (F0/F1/F2/F3/F4 = 29/9/14/16/32) were utilised for testing the trained network, with the histopathological fibrosis stage used as reference. To improve robustness, additional images for training data were generated by rotating or parallel shifting the images, or adding Gaussian noise. Supervised training was used to minimise the difference between the liver fibrosis stage and the fibrosis score obtained from deep learning based on CT images (F                             DLCT                              score) output by the model. Testing data were input into the trained DCNNs to evaluate their performance. Results: The F                             DLCT                              scores showed a significant correlation with liver fibrosis stage (Spearman's correlation coefficient = 0.48, p < 0.001). The areas under the receiver operating characteristic curves (with 95% confidence intervals) for diagnosing significant fibrosis (≥ F2), advanced fibrosis (≥ F3) and cirrhosis (F4) by using F                             DLCT                              scores were 0.74 (0.64–0.85), 0.76 (0.66–0.85) and 0.73 (0.62–0.84), respectively. Conclusions: Liver fibrosis can be staged by using a deep learning model based on CT images, with moderate performance. Key Points: • Liver fibrosis can be staged by a deep learning model based on magnified CT images including the liver surface, with moderate performance. • Scores from a trained deep learning model showed moderate correlation with histopathological liver fibrosis staging. • Further improvement are necessary before utilisation in clinical settings.                          © 2018, European Society of Radiology.","Artificial intelligence; Liver cirrhosis; Multidetector computed tomography; ROC curve","Aged; Deep Learning; Female; Humans; Image Interpretation, Computer-Assisted; Liver Cirrhosis; Male; Middle Aged; Pilot Projects; Retrospective Studies; ROC Curve; Tomography, X-Ray Computed; iodinated contrast medium; aged; Article; artificial neural network; computer assisted tomography; contrast enhancement; controlled study; correlation coefficient; deep convolutional neural network; diagnostic test accuracy study; female; histopathology; human; human tissue; liver cirrhosis; liver fibrosis; major clinical study; male; model; noise; normal distribution; pilot study; priority journal; retrospective study; scoring system; sensitivity and specificity; staging; supervised machine learning; computer assisted diagnosis; liver cirrhosis; middle aged; procedures; receiver operating characteristic; x-ray computed tomography","Springer Verlag","09387994","","EURAE","29761358","Article","Scopus","2-s2.0-85046906470"
"Tayeb Z.; Waniek N.; Fedjaev J.; Ghaboosi N.; Rychly L.; Widderich C.; Richter C.; Braun J.; Saveriano M.; Cheng G.; Conradt J.","Tayeb, Zied (57195526275); Waniek, Nicolai (56338432400); Fedjaev, Juri (57192818799); Ghaboosi, Nejla (16645667600); Rychly, Leonard (57204669742); Widderich, Christian (57204675361); Richter, Christoph (56646803000); Braun, Jonas (57204664263); Saveriano, Matteo (55556026600); Cheng, Gordon (10243873000); Conradt, Jörg (13005140400)","57195526275; 56338432400; 57192818799; 16645667600; 57204669742; 57204675361; 56646803000; 57204664263; 55556026600; 10243873000; 13005140400","Gumpy: A Python toolbox suitable for hybrid brain-computer interfaces","2018","Journal of Neural Engineering","29","10.1088/1741-2552/aae186","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056658695&doi=10.1088%2f1741-2552%2faae186&partnerID=40&md5=6e1cf24b641f59353e380388872edb3a","Department of Electrical and Computer Engineering, Neuroscientific System Theory, Technical University of Munich, Munich, Germany; Institute for Cognitive Systems, Technical University of Munich, Munich, Germany; Integrated Research, Sydney, Australia; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Munich, Germany","Tayeb Z., Department of Electrical and Computer Engineering, Neuroscientific System Theory, Technical University of Munich, Munich, Germany, Institute for Cognitive Systems, Technical University of Munich, Munich, Germany; Waniek N., Department of Electrical and Computer Engineering, Neuroscientific System Theory, Technical University of Munich, Munich, Germany; Fedjaev J., Department of Electrical and Computer Engineering, Neuroscientific System Theory, Technical University of Munich, Munich, Germany; Ghaboosi N., Integrated Research, Sydney, Australia; Rychly L., Department of Electrical and Computer Engineering, Neuroscientific System Theory, Technical University of Munich, Munich, Germany; Widderich C., Department of Electrical and Computer Engineering, Neuroscientific System Theory, Technical University of Munich, Munich, Germany; Richter C., Department of Electrical and Computer Engineering, Neuroscientific System Theory, Technical University of Munich, Munich, Germany; Braun J., Department of Electrical and Computer Engineering, Neuroscientific System Theory, Technical University of Munich, Munich, Germany; Saveriano M., Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Munich, Germany; Cheng G., Institute for Cognitive Systems, Technical University of Munich, Munich, Germany; Conradt J., Department of Electrical and Computer Engineering, Neuroscientific System Theory, Technical University of Munich, Munich, Germany","Objective. The objective of this work is to present gumpy, a new free and open source Python toolbox designed for hybrid brain-computer interface (BCI). Approach. Gumpy provides state-of-the-art algorithms and includes a rich selection of signal processing methods that have been employed by the BCI community over the last 20 years. In addition, a wide range of classification methods that span from classical machine learning algorithms to deep neural network models are provided. Gumpy can be used for both EEG and EMG biosignal analysis, visualization, real-time streaming and decoding. Results. The usage of the toolbox was demonstrated through two different offline example studies, namely movement prediction from EEG motor imagery, and the decoding of natural grasp movements with the applied finger forces from surface EMG (sEMG) signals. Additionally, gumpy was used for real-time control of a robot arm using steady-state visually evoked potentials (SSVEP) as well as for real-time prosthetic hand control using sEMG. Overall, obtained results with the gumpy toolbox are comparable or better than previously reported results on the same datasets. Significance. Gumpy is a free and open source software, which allows end-users to perform online hybrid BCIs and provides different techniques for processing and decoding of EEG and EMG signals. More importantly, the achieved results reveal that gumpy's deep learning toolbox can match or outperform the state-of-the-art in terms of accuracy. This can therefore enable BCI researchers to develop more robust decoding algorithms using novel techniques and hence chart a route ahead for new BCI improvements. © 2018 IOP Publishing Ltd.","deep learning; EEG; EMG; hybrid brain-computer interfaces; Python","Algorithms; Brain-Computer Interfaces; Electroencephalography; Electromyography; Hand; Humans; Imagination; Machine Learning; Movement; Programming Languages; Prostheses and Implants; Psychomotor Performance; Reproducibility of Results; Software; Article; Bayesian learning; brain computer interface; classification algorithm; classifier; computer language; data analysis software; electrocorticography; electroencephalogram; electromyogram; feature extraction; Fourier transformation; functional magnetic resonance imaging; hand movement; k nearest neighbor; machine learning; priority journal; random forest; robotics; signal processing; software; visual evoked potential; algorithm; electroencephalography; electromyography; hand; human; imagination; machine learning; movement (physiology); physiology; prostheses and orthoses; psychomotor performance; reproducibility","Institute of Physics Publishing","17412560","","","30215610","Article","Scopus","2-s2.0-85056658695"
"Van Eycke Y.-R.; Balsat C.; Verset L.; Debeir O.; Salmon I.; Decaestecker C.","Van Eycke, Yves-Rémi (56317960400); Balsat, Cédric (55229366400); Verset, Laurine (37008099500); Debeir, Olivier (55902408700); Salmon, Isabelle (7005222669); Decaestecker, Christine (7005106147)","56317960400; 55229366400; 37008099500; 55902408700; 7005222669; 7005106147","Segmentation of glandular epithelium in colorectal tumours to automatically compartmentalise IHC biomarker quantification: A deep learning approach","2018","Medical Image Analysis","47","10.1016/j.media.2018.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050876062&doi=10.1016%2fj.media.2018.07.004&partnerID=40&md5=be480a86637d0823484975e6a942ca1e","DIAPath, Center for Microscopy and Molecular Imaging, Université Libre de Bruxelles (ULB), CPI 305/1, Rue Adrienne Bolland, 8, 6041 Gosselies, Belgium; Laboratories of Image, Signal processing & Acoustics, Université Libre de Bruxelles (ULB), CPI 165/57, Avenue Franklin Roosevelt 50, Brussels, 1050, Belgium; Department of Pathology, Erasme Hospital, Université Libre de Bruxelles (ULB), Route de Lennik 808, Brussels, 1070, Belgium; MIP, Center for Microscopy and Molecular Imaging, Université Libre de Bruxelles (ULB), CPI 305/1, Rue Adrienne Bolland, 8, 6041 Gosselies, Belgium","Van Eycke Y.-R., DIAPath, Center for Microscopy and Molecular Imaging, Université Libre de Bruxelles (ULB), CPI 305/1, Rue Adrienne Bolland, 8, 6041 Gosselies, Belgium, Laboratories of Image, Signal processing & Acoustics, Université Libre de Bruxelles (ULB), CPI 165/57, Avenue Franklin Roosevelt 50, Brussels, 1050, Belgium; Balsat C., DIAPath, Center for Microscopy and Molecular Imaging, Université Libre de Bruxelles (ULB), CPI 305/1, Rue Adrienne Bolland, 8, 6041 Gosselies, Belgium; Verset L., Department of Pathology, Erasme Hospital, Université Libre de Bruxelles (ULB), Route de Lennik 808, Brussels, 1070, Belgium; Debeir O., Laboratories of Image, Signal processing & Acoustics, Université Libre de Bruxelles (ULB), CPI 165/57, Avenue Franklin Roosevelt 50, Brussels, 1050, Belgium, MIP, Center for Microscopy and Molecular Imaging, Université Libre de Bruxelles (ULB), CPI 305/1, Rue Adrienne Bolland, 8, 6041 Gosselies, Belgium; Salmon I., DIAPath, Center for Microscopy and Molecular Imaging, Université Libre de Bruxelles (ULB), CPI 305/1, Rue Adrienne Bolland, 8, 6041 Gosselies, Belgium, Department of Pathology, Erasme Hospital, Université Libre de Bruxelles (ULB), Route de Lennik 808, Brussels, 1070, Belgium; Decaestecker C., DIAPath, Center for Microscopy and Molecular Imaging, Université Libre de Bruxelles (ULB), CPI 305/1, Rue Adrienne Bolland, 8, 6041 Gosselies, Belgium, Laboratories of Image, Signal processing & Acoustics, Université Libre de Bruxelles (ULB), CPI 165/57, Avenue Franklin Roosevelt 50, Brussels, 1050, Belgium","In this paper, we propose a method for automatically annotating slide images from colorectal tissue samples. Our objective is to segment glandular epithelium in histological images from tissue slides submitted to different staining techniques, including usual haematoxylin-eosin (H&E) as well as immunohistochemistry (IHC). The proposed method makes use of Deep Learning and is based on a new convolutional network architecture. Our method achieves better performances than the state of the art on the H&E images of the GlaS challenge contest, whereas it uses only the haematoxylin colour channel extracted by colour deconvolution from the RGB images in order to extend its applicability to IHC. The network only needs to be fine-tuned on a small number of additional examples to be accurate on a new IHC dataset. Our approach also includes a new method of data augmentation to achieve good generalisation when working with different experimental conditions and different IHC markers. We show that our methodology enables to automate the compartmentalisation of the IHC biomarker analysis, results concurring highly with manual annotations. © 2018 Elsevier B.V.","Computational pathology; Data augmentation; Deep learning; Gland; Image segmentation; Immunohistochemistry","Automation; Biomarkers, Tumor; Color; Colorectal Neoplasms; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Immunohistochemistry; Staining and Labeling; Biomarkers; Image segmentation; Network architecture; Tissue; Tissue engineering; alpha smooth muscle actin; biological marker; eosin; hematoxylin; protein Bax; protein bcl 2; somatomedin binding protein 2; tumor marker; Convolutional networks; Data augmentation; Experimental conditions; Gland; Histological images; Immunohistochemistry; Learning approach; Staining techniques; Article; colon epithelium; colorectal tumor; deep learning; entropy; gland tissue; human; human tissue; image segmentation; immunohistochemistry; machine learning; priority journal; prostate tissue; protein expression; tissue microarray; automation; color; colorectal tumor; computer assisted diagnosis; diagnostic imaging; immunohistochemistry; pathology; procedures; staining; Deep learning","Elsevier B.V.","13618415","","MIAEC","30081241","Article","Scopus","2-s2.0-85050876062"
"Hong X.; Zan Y.; Weng F.; Tao W.; Peng Q.; Huang Q.","Hong, Xiang (57201735301); Zan, Yunlong (36444620400); Weng, Fenghua (56267271200); Tao, Weijie (57200531160); Peng, Qiyu (13405112200); Huang, Qiu (35435256100)","57201735301; 36444620400; 56267271200; 57200531160; 13405112200; 35435256100","Enhancing the Image Quality via Transferred Deep Residual Learning of Coarse PET Sinograms","2018","IEEE Transactions on Medical Imaging","49","10.1109/TMI.2018.2830381","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045971265&doi=10.1109%2fTMI.2018.2830381&partnerID=40&md5=ced6488c1b37aaa4c493a0d3be206018","School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; University of Michigan, Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, 200240, China; Lawrence Berkeley National Laboratory, Berkeley, 94720, CA, United States; Department of Nuclear Medicine, Ruijin Hospital, Shanghai, 200240, China","Hong X., School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Zan Y., University of Michigan, Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, 200240, China; Weng F., School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Tao W., School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Peng Q., Lawrence Berkeley National Laboratory, Berkeley, 94720, CA, United States; Huang Q., School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China, Department of Nuclear Medicine, Ruijin Hospital, Shanghai, 200240, China","Increasing the image quality of positron emission tomography (PET) is an essential topic in the PET community. For instance, thin-pixelated crystals have been used to provide high spatial resolution images but at the cost of sensitivity and manufacture expense. In this paper, we proposed an approach to enhance the PET image resolution and noise property for PET scanners with large pixelated crystals. To address the problem of coarse blurred sinograms with large parallax errors associated with large crystals, we developed a data-driven, single-image super-resolution (SISR) method for sinograms, based on the novel deep residual convolutional neural network (CNN). Unlike the CNN-based SISR on natural images, periodically padded sinogram data and dedicated network architecture were used to make it more efficient for PET imaging. Moreover, we included the transfer learning scheme in the approach to process cases with poor labeling and small training data set. The approach was validated via analytically simulated data (with and without noise), Monte Carlo simulated data, and pre-clinical data. Using the proposed method, we could achieve comparable image resolution and better noise property with large crystals of bin sizes 4 × of thin crystals with a bin size from 1 × 1 mm2 to 1.6 × 1.6 mm2. Our approach uses external PET data as the prior knowledge for training and does not require additional information during inference. Meanwhile, the method can be added into the normal PET imaging framework seamlessly, thus potentially finds its application in designing low-cost high-performance PET systems. © 2017 IEEE.","convolutional neural networks; deep residual learning; Positron emission tomography; sinogram; super resolution; transfer learning","Algorithms; Animals; Deep Learning; Image Processing, Computer-Assisted; Mice; Phantoms, Imaging; Positron-Emission Tomography; Convolution; Deep learning; Geometrical optics; Image quality; Image resolution; Medical imaging; Network architecture; Neural networks; Optical resolving power; Positron emission tomography; Positrons; fluorodeoxyglucose f 18; Convolutional neural network; deep residual learning; Sinograms; Super resolution; Transfer learning; animal experiment; Article; crystal; deep residual sinogram super resolution network; image processing; image quality; image reconstruction; machine learning; Monte Carlo method; nonhuman; positron emission tomography; signal noise ratio; whole body PET; algorithm; animal; image processing; imaging phantom; mouse; positron emission tomography; procedures; Image enhancement","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29993685","Article","Scopus","2-s2.0-85045971265"
"Wu T.; Zhao W.; Keefer E.; Yang Z.","Wu, Tong (57188746975); Zhao, Wenfeng (55953847000); Keefer, Edward (6603112633); Yang, Zhi (55746125100)","57188746975; 55953847000; 6603112633; 55746125100","Deep compressive autoencoder for action potential compression in large-scale neural recording","2018","Journal of Neural Engineering","29","10.1088/1741-2552/aae18d","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056667437&doi=10.1088%2f1741-2552%2faae18d&partnerID=40&md5=e541ff93da4215c68a96ddcfb3da964b","Biomedical Engineering, University of Minnesota, Minneapolis, 55455, MN, United States; Nerves Incorporated, Dallas, 75214, TX, United States","Wu T., Biomedical Engineering, University of Minnesota, Minneapolis, 55455, MN, United States; Zhao W., Biomedical Engineering, University of Minnesota, Minneapolis, 55455, MN, United States; Keefer E., Nerves Incorporated, Dallas, 75214, TX, United States; Yang Z., Biomedical Engineering, University of Minnesota, Minneapolis, 55455, MN, United States","Objective. Understanding the coordinated activity underlying brain computations requires large-scale, simultaneous recordings from distributed neuronal structures at a cellular-level resolution. One major hurdle to design high-bandwidth, high-precision, large-scale neural interfaces lies in the formidable data streams (tens to hundreds of Gbps) that are generated by the recorder chip and need to be online transferred to a remote computer. The data rates can require hundreds to thousands of I/O pads on the recorder chip and power consumption on the order of Watts for data streaming alone. One of the solutions is to reduce the bandwidth of neural signals before transmission. Approach. We developed a deep learning-based compression model to reduce the data rate of multichannel action potentials. The proposed compression model is built upon a deep compressive autoencoder (CAE) with discrete latent embeddings. The encoder network of CAE is equipped with residual transformations to extract representative features from spikes, which are mapped into the latent embedding space and updated via vector quantization (VQ). The indexes of VQ codebook are further entropy coded as the compressed signals. The decoder network reconstructs spike waveforms with high quality from the quantized latent embeddings through stacked deconvolution. Main results. Extensive experimental results on both synthetic and in vivo datasets show that the proposed model consistently outperforms conventional methods that utilize hand-crafted features and/or signal-agnostic transformations and compressive sensing by achieving much higher compression ratios (20-500) and better or comparable reconstruction accuracies. Testing results also indicate that CAE is robust against a diverse range of imperfections, such as waveform variation and spike misalignment, and has minor influence on spike sorting accuracy. Furthermore, we have estimated the hardware cost and real-time performance of CAE and shown that it could support thousands of recording channels simultaneously without excessive power/heat dissipation. Significance. The proposed model can reduce the required data transmission bandwidth in large-scale recording experiments and maintain good signal qualities, which will be helpful to design power-efficient and lightweight wireless neural interfaces. We have open sourced the code implementation of the work at https://github.com/tong-wu-umn/spike-compression-autoencoder. © 2018 IOP Publishing Ltd.","deep neural network; large-scale neural signal processing; on-chip data compression; vector quantization","Action Potentials; Algorithms; Brain; Data Compression; Databases, Factual; Electroencephalography; Entropy; Humans; Machine Learning; Models, Neurological; Neural Networks (Computer); Signal Processing, Computer-Assisted; Wavelet Analysis; action potential; Agnostic; article; data compression; embedding; entropy; heat; human; in vivo study; learning; signal processing; spike; waveform; action potential; algorithm; artificial neural network; biological model; brain; devices; economics; electroencephalography; factual database; information processing; machine learning; physiology; procedures; signal processing; wavelet analysis","Institute of Physics Publishing","17412560","","","30215605","Article","Scopus","2-s2.0-85056667437"
"Lee H.-C.; Yoon H.-K.; Nam K.; Cho Y.J.; Kim T.K.; Kim W.H.; Bahk J.-H.","Lee, Hyung-Chul (55578791400); Yoon, Hyun-Kyu (55909978600); Nam, Karam (55750745300); Cho, Youn Joung (55754032300); Kim, Tae Kyong (55967363000); Kim, Won Ho (55509272400); Bahk, Jae-Hyon (7005834756)","55578791400; 55909978600; 55750745300; 55754032300; 55967363000; 55509272400; 7005834756","Derivation and validation of machine learning approaches to predict acute kidney injury after cardiac surgery","2018","Journal of Clinical Medicine","130","10.3390/jcm7100322","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068332250&doi=10.3390%2fjcm7100322&partnerID=40&md5=84f2b87f249c9ed7d18914874aec8de1","Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea","Lee H.-C., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea; Yoon H.-K., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea; Nam K., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea; Cho Y.J., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea; Kim T.K., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea; Kim W.H., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea; Bahk J.-H., Department of Anesthesiology and Pain Medicine, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, 03080, South Korea","Machine learning approaches were introduced for better or comparable predictive ability than statistical analysis to predict postoperative outcomes. We sought to compare the performance of machine learning approaches with that of logistic regression analysis to predict acute kidney injury after cardiac surgery. We retrospectively reviewed 2010 patients who underwent open heart surgery and thoracic aortic surgery. Baseline medical condition, intraoperative anesthesia, and surgery-related data were obtained. The primary outcome was postoperative acute kidney injury (AKI) defined according to the Kidney Disease Improving Global Outcomes criteria. The following machine learning techniques were used: decision tree, random forest, extreme gradient boosting, support vector machine, neural network classifier, and deep learning. The performance of these techniques was compared with that of logistic regression analysis regarding the area under the receiver-operating characteristic curve (AUC). During the first postoperative week, AKI occurred in 770 patients (38.3%). The best performance regarding AUC was achieved by the gradient boosting machine to predict the AKI of all stages (0.78, 95% confidence interval (CI) 0.75–0.80) or stage 2 or 3 AKI. The AUC of logistic regression analysis was 0.69 (95% CI 0.66–0.72). Decision tree, random forest, and support vector machine showed similar performance to logistic regression. In our comprehensive comparison of machine learning approaches with logistic regression analysis, gradient boosting technique showed the best performance with the highest AUC and lower error rate. We developed an Internet–based risk estimator which could be used for real-time processing of patient data to estimate the risk of AKI at the end of surgery. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Acute kidney injury; Cardiovascular surgery; Machine learning","angiotensin receptor antagonist; calcium channel blocking agent; creatinine; acute kidney failure; adult; aged; Article; artificial neural network; comparative study; controlled study; coronary artery bypass graft; creatinine blood level; decision tree; erythrocyte concentrate; female; gradient boosting; heart surgery; hematocrit; human; hypertension; logistic regression analysis; machine learning; major clinical study; male; middle aged; observational study; outcome variable; oxygen saturation; prediction; random forest; receiver operating characteristic; retrospective study; software; support vector machine; validation process","MDPI","20770383","","","","Article","Scopus","2-s2.0-85068332250"
"Wainberg M.; Merico D.; Delong A.; Frey B.J.","Wainberg, Michael (56252818600); Merico, Daniele (18037560500); Delong, Andrew (16066810900); Frey, Brendan J. (35459307900)","56252818600; 18037560500; 16066810900; 35459307900","Deep learning in biomedicine","2018","Nature Biotechnology","371","10.1038/nbt.4233","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053083782&doi=10.1038%2fnbt.4233&partnerID=40&md5=aa4f48332c68f88ac5d718dd156be53e","Deep Genomics Inc., MaRS Discovery District, Toronto, ON, Canada; Department of Computer Science, Stanford University, Stanford, CA, United States","Wainberg M., Deep Genomics Inc., MaRS Discovery District, Toronto, ON, Canada, Department of Computer Science, Stanford University, Stanford, CA, United States; Merico D., Deep Genomics Inc., MaRS Discovery District, Toronto, ON, Canada; Delong A., Deep Genomics Inc., MaRS Discovery District, Toronto, ON, Canada; Frey B.J., Deep Genomics Inc., MaRS Discovery District, Toronto, ON, Canada","Deep learning is beginning to impact biological research and biomedical applications as a result of its ability to integrate vast datasets, learn arbitrarily complex relationships and incorporate existing knowledge. Already, deep learning models can predict, with varying degrees of success, how genetic variation alters cellular processes involved in pathogenesis, which small molecules will modulate the activity of therapeutically relevant proteins, and whether radiographic images are indicative of disease. However, the flexibility of deep learning creates new challenges in guaranteeing the performance of deployed systems and in establishing trust with stakeholders, clinicians and regulators, who require a rationale for decision making. We argue that these challenges will be overcome using the same flexibility that created them; for example, by training deep models so that they can output a rationale for their predictions. Significant research in this direction will be needed to realize the full potential of deep learning in biomedicine. © 2018, Nature Publishing Group. All rights reserved.","","Algorithms; Deep Learning; Humans; Decision making; Genes; Medical applications; Biological research; Biomedical applications; Cellular process; Complex relationships; Deployed systems; Genetic variation; Learning models; Radiographic images; Article; biomedicine; confounding variable; deep learning; human; machine learning; practice guideline; priority journal; reliability; supervised machine learning; unsupervised machine learning; algorithm; Deep learning","Nature Publishing Group","10870156","","NABIF","30188539","Article","Scopus","2-s2.0-85053083782"
"Golicz A.A.; Bhalla P.L.; Singh M.B.","Golicz, Agnieszka A. (55915014300); Bhalla, Prem L. (7004909297); Singh, Mohan B. (7406438833)","55915014300; 7004909297; 7406438833","MCRiceRepGP: a framework for the identification of genes associated with sexual reproduction in rice","2018","Plant Journal","12","10.1111/tpj.14019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053248412&doi=10.1111%2ftpj.14019&partnerID=40&md5=3a1fc976a2b4ded31aa015b4051dd2fe","Faculty of Veterinary and Agricultural Sciences, Plant Molecular Biology and Biotechnology Laboratory, University of Melbourne, Parkville, Melbourne, VIC, Australia","Golicz A.A., Faculty of Veterinary and Agricultural Sciences, Plant Molecular Biology and Biotechnology Laboratory, University of Melbourne, Parkville, Melbourne, VIC, Australia; Bhalla P.L., Faculty of Veterinary and Agricultural Sciences, Plant Molecular Biology and Biotechnology Laboratory, University of Melbourne, Parkville, Melbourne, VIC, Australia; Singh M.B., Faculty of Veterinary and Agricultural Sciences, Plant Molecular Biology and Biotechnology Laboratory, University of Melbourne, Parkville, Melbourne, VIC, Australia","Rice is an important cereal crop, being a staple food for over half of the world's population, and sexual reproduction resulting in grain formation underpins global food security. However, despite considerable research efforts, many of the genes, especially long intergenic non-coding RNA (lincRNA) genes, involved in sexual reproduction in rice remain uncharacterized. With an increasing number of public resources becoming available, information from different sources can be combined to perform gene functional annotation. We report the development of MCRiceRepGP, a machine learning framework which integrates heterogeneous evidence and employs multicriteria decision analysis and machine learning to predict coding and lincRNA genes involved in sexual reproduction in rice. The rice genome was reannotated using deep-sequencing transcriptomic data from reproduction-associated tissue/cell types identifying previously unannotated putative protein-coding genes and lincRNAs. MCRiceRepGP was used for genome-wide discovery of sexual reproduction associated coding and lincRNA genes. The protein-coding and lincRNA genes identified have distinct expression profiles, with a large proportion of lincRNAs reaching maximum expression levels in the sperm cells. Some of the genes are potentially linked to male- and female-specific fertility and heat stress tolerance during the reproductive stage. MCRiceRepGP can be used in combination with other genome-wide studies, such as genome-wide association studies, giving greater confidence that the genes identified are associated with the biological process of interest. As more data, especially about mutant plant phenotypes, become available, the power of MCRiceRepGP will grow, providing researchers with a tool to identify candidate genes for future experiments. MCRiceRepGP is available as a web application (http://mcgplannotator.com/MCRiceRepGP/). © 2018 The Authors The Plant Journal © 2018 John Wiley & Sons Ltd","function prediction; lincRNA; machine learning; Oryza sativa; reannotation; sexual reproduction","Artificial Intelligence; Coding; Data; Decision Theory; Genes; Proteins; Reproduction; Rice; Genes, Plant; Genome, Plant; Genome-Wide Association Study; Machine Learning; Oryza; Reproduction; Transcriptome; Artificial intelligence; Codes (symbols); Decision theory; Food supply; Learning systems; Proteins; transcriptome; Function prediction; lincRNA; Oryza sativa; reannotation; Sexual reproduction; genetics; genome-wide association study; machine learning; Oryza; physiology; plant gene; plant genome; reproduction; Gene expression","Blackwell Publishing Ltd","09607412","","PLJUE","29979827","Article","Scopus","2-s2.0-85053248412"
"Eo T.; Jun Y.; Kim T.; Jang J.; Lee H.-J.; Hwang D.","Eo, Taejoon (56415046300); Jun, Yohan (57191201833); Kim, Taeseong (57218356679); Jang, Jinseong (56413666600); Lee, Ho-Joon (36652691800); Hwang, Dosik (10039447700)","56415046300; 57191201833; 57218356679; 56413666600; 36652691800; 10039447700","KIKI-net: cross-domain convolutional neural networks for reconstructing undersampled magnetic resonance images","2018","Magnetic Resonance in Medicine","292","10.1002/mrm.27201","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044921256&doi=10.1002%2fmrm.27201&partnerID=40&md5=ea497ae7010b23a227d06bac836817ea","School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Department of Radiology and Research Institute of Radiological Science, Severance Hospital, Yonsei University College of Medicine, Seoul, South Korea","Eo T., School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Jun Y., School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Kim T., School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Jang J., School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Lee H.-J., Department of Radiology and Research Institute of Radiological Science, Severance Hospital, Yonsei University College of Medicine, Seoul, South Korea; Hwang D., School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea","Purpose: To demonstrate accurate MR image reconstruction from undersampled k-space data using cross-domain convolutional neural networks (CNNs). Methods: Cross-domain CNNs consist of 3 components: (1) a deep CNN operating on the k-space (KCNN), (2) a deep CNN operating on an image domain (ICNN), and (3) an interleaved data consistency operations. These components are alternately applied, and each CNN is trained to minimize the loss between the reconstructed and corresponding fully sampled k-spaces. The final reconstructed image is obtained by forward-propagating the undersampled k-space data through the entire network. Results: Performances of K-net (KCNN with inverse Fourier transform), I-net (ICNN with interleaved data consistency), and various combinations of the 2 different networks were tested. The test results indicated that K-net and I-net have different advantages/disadvantages in terms of tissue-structure restoration. Consequently, the combination of K-net and I-net is superior to single-domain CNNs. Three MR data sets, the T2 fluid-attenuated inversion recovery (T2 FLAIR) set from the Alzheimer's Disease Neuroimaging Initiative and 2 data sets acquired at our local institute (T2 FLAIR and T1 weighted), were used to evaluate the performance of 7 conventional reconstruction algorithms and the proposed cross-domain CNNs, which hereafter is referred to as KIKI-net. KIKI-net outperforms conventional algorithms with mean improvements of 2.29 dB in peak SNR and 0.031 in structure similarity. Conclusion: KIKI-net exhibits superior performance over state-of-the-art conventional algorithms in terms of restoring tissue structures and removing aliasing artifacts. The results demonstrate that KIKI-net is applicable up to a reduction factor of 3 to 4 based on variable-density Cartesian undersampling. © 2018 International Society for Magnetic Resonance in Medicine","convolutional neural networks; cross-domain deep learning; image reconstruction; k-space completion; MRI acceleration","Algorithms; Brain; Databases, Factual; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks (Computer); Signal-To-Noise Ratio; Convolution; Deep learning; Deep neural networks; Image reconstruction; Magnetic domains; Magnetic resonance; Magnetic resonance imaging; Neurodegenerative diseases; Neuroimaging; Tissue; Conventional algorithms; Cross-domain; Fluid attenuated inversion recoveries; Inverse Fourier transforms; K space; Reconstructed image; Reconstruction algorithms; Structure similarity; algorithm; Alzheimer disease; Article; artificial neural network; cross domain convolutional neural network; deep learning; image reconstruction; intermethod comparison; KIKI neural network; machine learning; neuroimaging; nuclear magnetic resonance imaging; process development; radiological parameters; structural homology; T2 fluid attenuated inversion recovery; tissue repair; tissue structure; brain; diagnostic imaging; factual database; human; image processing; nuclear magnetic resonance imaging; procedures; signal noise ratio; Convolutional neural networks","John Wiley and Sons Inc","07403194","","MRMEE","29624729","Article","Scopus","2-s2.0-85044921256"
"Elfwing S.; Uchibe E.; Doya K.","Elfwing, Stefan (16199609700); Uchibe, Eiji (6603720332); Doya, Kenji (7004163287)","16199609700; 6603720332; 7004163287","Sigmoid-weighted linear units for neural network function approximation in reinforcement learning","2018","Neural Networks","665","10.1016/j.neunet.2017.12.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041102918&doi=10.1016%2fj.neunet.2017.12.012&partnerID=40&md5=8690759e12d252297958342bb352438b","Department of Brain Robot Interface, ATR Computational Neuroscience Laboratories, 2-2-2 Hikaridai, Seikacho, Soraku-gun, Kyoto, 619-0288, Japan; Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa, 904-0495, Japan","Elfwing S., Department of Brain Robot Interface, ATR Computational Neuroscience Laboratories, 2-2-2 Hikaridai, Seikacho, Soraku-gun, Kyoto, 619-0288, Japan; Uchibe E., Department of Brain Robot Interface, ATR Computational Neuroscience Laboratories, 2-2-2 Hikaridai, Seikacho, Soraku-gun, Kyoto, 619-0288, Japan, Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa, 904-0495, Japan; Doya K., Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa, 904-0495, Japan","In recent years, neural networks have enjoyed a renaissance as function approximators in reinforcement learning. Two decades after Tesauro's TD-Gammon achieved near top-level human performance in backgammon, the deep reinforcement learning algorithm DQN achieved human-level performance in many Atari 2600 games. The purpose of this study is twofold. First, we propose two activation functions for neural network function approximation in reinforcement learning: the sigmoid-weighted linear unit (SiLU) and its derivative function (dSiLU). The activation of the SiLU is computed by the sigmoid function multiplied by its input. Second, we suggest that the more traditional approach of using on-policy learning with eligibility traces, instead of experience replay, and softmax action selection can be competitive with DQN, without the need for a separate target network. We validate our proposed approach by, first, achieving new state-of-the-art results in both stochastic SZ-Tetris and Tetris with a small 10 × 10 board, using TD(λ) learning and shallow dSiLU network agents, and, then, by outperforming DQN in the Atari 2600 domain by using a deep Sarsa(λ) agent with SiLU and dSiLU hidden units. © 2017 The Author(s)","Atari 2600; Deep learning; Function approximation; Reinforcement learning; Sigmoid-weighted linear unit; Tetris","Deep Learning; Neural Networks (Computer); Chemical activation; Deep learning; Learning algorithms; Stochastic systems; Transfer functions; Activation functions; Atari 2600; Function approximation; Function approximators; Human-level performance; Linear units; Tetris; Traditional approaches; Article; artificial neural network; brain function; controlled study; man machine interaction; mathematical computing; mathematical parameters; priority journal; reinforcement; sigmoid weighted linear unit; stochastic model; video game; Reinforcement learning","Elsevier Ltd","08936080","","NNETE","29395652","Article","Scopus","2-s2.0-85041102918"
"Idakwo G.; Luttrell J.; Chen M.; Hong H.; Zhou Z.; Gong P.; Zhang C.","Idakwo, Gabriel (57204818134); Luttrell, Joseph (57191906569); Chen, Minjun (55733264000); Hong, Huixiao (7401521704); Zhou, Zhaoxian (56141233100); Gong, Ping (55982343800); Zhang, Chaoyang (7405496346)","57204818134; 57191906569; 55733264000; 7401521704; 56141233100; 55982343800; 7405496346","A review on machine learning methods for in silico toxicity prediction","2018","Journal of Environmental Science and Health - Part C Environmental Carcinogenesis and Ecotoxicology Reviews","90","10.1080/10590501.2018.1537118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057302451&doi=10.1080%2f10590501.2018.1537118&partnerID=40&md5=7a40c1a1007509fb5c0747750c70e2b2","School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Hattiesburg, MS, United States; Division of Bioinformatics and Biostatistics, National Center for Toxicological Science, US Food and Drug Administration, Jefferson, AR, United States; Environmental Laboratory, US Army Engineer Research and Development Center, Vicksburg, MS, United States","Idakwo G., School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Hattiesburg, MS, United States; Luttrell J., School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Hattiesburg, MS, United States; Chen M., Division of Bioinformatics and Biostatistics, National Center for Toxicological Science, US Food and Drug Administration, Jefferson, AR, United States; Hong H., Division of Bioinformatics and Biostatistics, National Center for Toxicological Science, US Food and Drug Administration, Jefferson, AR, United States; Zhou Z., School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Hattiesburg, MS, United States; Gong P., Environmental Laboratory, US Army Engineer Research and Development Center, Vicksburg, MS, United States; Zhang C., School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Hattiesburg, MS, United States","In silico toxicity prediction plays an important role in the regulatory decision making and selection of leads in drug design as in vitro/vivo methods are often limited by ethics, time, budget, and other resources. Many computational methods have been employed in predicting the toxicity profile of chemicals. This review provides a detailed end-to-end overview of the application of machine learning algorithms to Structure-Activity Relationship (SAR)-based predictive toxicology. From raw data to model validation, the importance of data quality is stressed as it greatly affects the predictive power of derived models. Commonly overlooked challenges such as data imbalance, activity cliff, model evaluation, and definition of applicability domain are highlighted, and plausible solutions for alleviating these challenges are discussed. © 2018, © 2018 Taylor & Francis Group, LLC.","machine learning; model reliability; molecular descriptors; prediction accuracy; structure-activity relationship; Toxicity prediction","Algorithms; Computer Simulation; Environmental Pollutants; Machine Learning; Quantitative Structure-Activity Relationship; Support Vector Machine; Toxicity Tests; Artificial intelligence; Budget control; Decision making; Forecasting; Learning algorithms; Structures (built objects); Toxicity; Model reliability; Molecular descriptors; Prediction accuracy; Structure activity relationships; Toxicity predictions; Article; artificial neural network; chemical structure; computer model; deep learning; information processing; machine learning; quantitative structure activity relation; random forest; reliability; structure activity relation; support vector machine; toxicity testing; algorithm; computer simulation; machine learning; pollutant; procedures; toxicity; toxicity testing; Learning systems","Taylor and Francis Inc.","10590501","","JSHRE","30628866","Article","Scopus","2-s2.0-85057302451"
"Feng J.; Dong N.; Siping C.; Yuan Y.; Tianfu W.; Baiying L.","Feng, Jiang (57205378606); Dong, Ni (57191364158); Siping, Chen (13606526600); Yuan, Yao (56424499600); Tianfu, Wang (55602702200); Baiying, Lei (57191360337)","57205378606; 57191364158; 13606526600; 56424499600; 55602702200; 57191360337","Placental maturity grading via hybrid descriptors and fisher vector","2018","Chinese Journal of Biomedical Engineering","0","10.3969/j.issn.0258-8021.2018.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059805849&doi=10.3969%2fj.issn.0258-8021.2018.05.002&partnerID=40&md5=748b3d534fe618a93850545fede7cd60","School of Biomedical Engineering, Health Science Center, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China; Department of Ultrasound, Affiliated Shenzhen Maternal and Child Healthcare, Hospital of Nanfang Medical University, Shenzhen, Guangdong, 518060, China","Feng J., School of Biomedical Engineering, Health Science Center, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China; Dong N., School of Biomedical Engineering, Health Science Center, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China; Siping C., School of Biomedical Engineering, Health Science Center, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China; Yuan Y., Department of Ultrasound, Affiliated Shenzhen Maternal and Child Healthcare, Hospital of Nanfang Medical University, Shenzhen, Guangdong, 518060, China; Tianfu W., School of Biomedical Engineering, Health Science Center, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China; Baiying L., School of Biomedical Engineering, Health Science Center, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China","Placental maturity grading (PMG) is very essential to assess fetal growth and maternal health. However, PMG has mostly relied on the clinician' s subjective judgment, which is time-consuming and subjective. A dditionally it may cause wrong estimation because of redundancy and repeatability of the process. Traditional machine learning-based methods capitalize on handcrafted features, but such features may be essentially insufficient for PMG. In order to tackle it, we proposed an automatic method to stage placental maturity via deep hybrid descriptors extracted from B-mode ultrasound (BUS) and color Doppler energy (CDE) images. Specifically, convolutional descriptors extracted from a deep convolutional neural network (CNN) and hand-crafted features were combined to form hybrid descriptors to boost the performance of the proposed method. Firstly, different models with various feature layers were combined to obtain hybrid descriptors from images. Meanwhile, the transfer learning strategy was utilized to enhance the grading performance based on the deep representation features. Then, extracted descriptors were encoded by Fisher vector (FV). Finally, we used support vector machine (SVM) as the classifier to grade placental maturity. We used placental data labeled by doctors to test models. The accuracy of the model with hybrid descriptors based on the 19-layer network was 94. 15%, which was 3. 01% higher than that of the model with hand-crafted features and 7. 35% higher than the CNN feature model. The experimental results demonstrated that the proposed method could be applied to the automatic PMG effectively. © 2018 Chinese Academy of Medical Sciences. All rights reserved.","Deep convolutional network; Fisher vector; Hybrid descriptors; Placental maturity grading; Ultrasound image","article; clinician; color Doppler flowmetry; decision making; female; fetus growth; human; maternal welfare; maturity; placenta; support vector machine; transfer of learning","Chinese Academy of Medical Sciences","02588021","","ZSYXE","","Article","Scopus","2-s2.0-85059805849"
"Chong T.-W.; Lee B.-G.","Chong, Teak-Wei (57192554931); Lee, Boon-Giin (25927191200)","57192554931; 25927191200","American sign language recognition using leap motion controller with machine learning approach","2018","Sensors (Switzerland)","89","10.3390/s18103554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055199517&doi=10.3390%2fs18103554&partnerID=40&md5=91f355b0f74b823ee58088c979a72684","Department of Electronics Engineering, Keimyung University, Daegu, 42601, South Korea","Chong T.-W., Department of Electronics Engineering, Keimyung University, Daegu, 42601, South Korea; Lee B.-G., Department of Electronics Engineering, Keimyung University, Daegu, 42601, South Korea","Sign language is intentionally designed to allow deaf and dumb communities to convey messages and to connect with society. Unfortunately, learning and practicing sign language is not common among society; hence, this study developed a sign language recognition prototype using the Leap Motion Controller (LMC). Many existing studies have proposed methods for incomplete sign language recognition, whereas this study aimed for full American Sign Language (ASL) recognition, which consists of 26 letters and 10 digits. Most of the ASL letters are static (no movement), but certain ASL letters are dynamic (they require certain movements). Thus, this study also aimed to extract features from finger and hand motions to differentiate between the static and dynamic gestures. The experimental results revealed that the sign language recognition rates for the 26 letters using a support vector machine (SVM) and a deep neural network (DNN) are 80.30% and 93.81%, respectively. Meanwhile, the recognition rates for a combination of 26 letters and 10 digits are slightly lower, approximately 72.79% for the SVM and 88.79% for the DNN. As a result, the sign language recognition system has great potential for reducing the gap between deaf and dumb communities and others. The proposed prototype could also serve as an interpreter for the deaf and dumb in everyday life in service sectors, such as at the bank or post office. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","American sign language; Deep neural network; Human-computer interaction; Leap motion controller; Machine learning; Multi-class classification; Sign language recognition; Support vector machine","Deafness; Electromyography; Gestures; Hand; Humans; Machine Learning; Motion; Movement; Neural Networks (Computer); Pattern Recognition, Automated; Sign Language; United States; Artificial intelligence; Controllers; Human computer interaction; Image retrieval; Learning systems; Motion control; Support vector machines; American sign language; American sign language recognition; Leap motions; Machine learning approaches; Multi-class classification; Recognition rates; Sign language; Sign Language recognition; artificial neural network; automated pattern recognition; electromyography; gesture; hand; hearing impairment; human; machine learning; motion; movement (physiology); pathophysiology; physiology; procedures; sign language; United States; Deep neural networks","MDPI AG","14248220","","","30347776","Article","Scopus","2-s2.0-85055199517"
"Long D.; Zhang R.; Mao Y.","Long, Dingkun (57202378954); Zhang, Richong (23669861200); Mao, Yongyi (12241673700)","57202378954; 23669861200; 12241673700","Prototypical recurrent unit","2018","Neurocomputing","3","10.1016/j.neucom.2018.05.048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048142690&doi=10.1016%2fj.neucom.2018.05.048&partnerID=40&md5=53851d0d4151bf3941d6666f9ca04140","BDBC and SKLSDE, School of Computer Science and Engineering, Beihang University, 37 Xueyuan Road, Beijing, 100191, China; School of Electrical Engineering and Computer Science, University of Ottawa, 800 King Edward Avenue, K1N 6N5, ON, Canada","Long D., BDBC and SKLSDE, School of Computer Science and Engineering, Beihang University, 37 Xueyuan Road, Beijing, 100191, China; Zhang R., BDBC and SKLSDE, School of Computer Science and Engineering, Beihang University, 37 Xueyuan Road, Beijing, 100191, China; Mao Y., School of Electrical Engineering and Computer Science, University of Ottawa, 800 King Edward Avenue, K1N 6N5, ON, Canada","Despite the great successes of deep learning, the effectiveness of deep neural networks, such as LSTM/GRU-like recurrent networks, has not been well understood. Not only attributed to their nonlinear dynamics, the difficulty in understanding LSTM/GRU-like recurrent networks also resides in the highly complex recurrence structure in these networks. This work aims at constructing an alternative recurrent unit that is as simple as possible and yet also captures the key components of LSTM/GRU recurrent units. Such a unit, if available, can then be used as a prototype for the study of LSTM/GRU-like networks and potentially enable easier analysis. Towards that goal, we take a system-theoretic perspective to design a new recurrent unit, which we call the prototypical recurrent unit (PRU). Not only having minimal complexity, PRU is demonstrated experimentally to have comparable performance to GRU and LSTM over a range of modelling tasks. This establishes PRU networks as a prototypical example for future study of LSTM/GRU-like recurrent networks. The complexity advantage of PRU may also make it a favourable alternative to LSTM and GRU in practice. © 2018 Elsevier B.V.","Recurrent network; Recurrent unit; State space","Complex networks; Deep neural networks; State space methods; Recurrent networks; Recurrent unit; Article; artificial neural network; computer aided design; image analysis; LSTM GRU like recurrent network; machine learning; prediction; priority journal; process optimization; prototypical recurrent unit; Long short-term memory","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85048142690"
"Zhang L.; Lv C.; Jin Y.; Cheng G.; Fu Y.; Yuan D.; Tao Y.; Guo Y.; Ni X.; Shi T.","Zhang, Li (57196128241); Lv, Chenkai (57220675353); Jin, Yaqiong (56050843700); Cheng, Ganqi (57204362145); Fu, Yibao (57204363363); Yuan, Dongsheng (57204364190); Tao, Yiran (57204361249); Guo, Yongli (57054281200); Ni, Xin (35201774900); Shi, Tieliu (7202756564)","57196128241; 57220675353; 56050843700; 57204362145; 57204363363; 57204364190; 57204361249; 57054281200; 35201774900; 7202756564","Deep learning-based multi-omics data integration reveals two prognostic subtypes in high-risk neuroblastoma","2018","Frontiers in Genetics","124","10.3389/fgene.2018.00477","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055322501&doi=10.3389%2ffgene.2018.00477&partnerID=40&md5=c8a05e50b1bcf9ab6673c99586c06122","Center for Bioinformatics and Computational Biology, Institute of Biomedical Sciences, School of Life Sciences, East China Normal University, Shanghai, China; Beijing Key Laboratory for Pediatric Diseases of Otolaryngology, Head and Neck Surgery, MOE Key Laboratory of Major Diseases in Children, Beijing Children's Hospital, National Center for Children's Health, Beijing Pediatric Research Institute, Capital Medical University, Beijing, China; Biobank for Clinical Data and Samples in Pediatrics, Beijing Children's Hospital, National Center for Children's Health, Beijing Pediatric Research Institute, Capital Medical University, Beijing, China; Department of Otolaryngology, Head and Neck Surgery, Beijing Children's Hospital, National Center for Children's Health, Capital Medical University, Beijing, China","Zhang L., Center for Bioinformatics and Computational Biology, Institute of Biomedical Sciences, School of Life Sciences, East China Normal University, Shanghai, China; Lv C., Center for Bioinformatics and Computational Biology, Institute of Biomedical Sciences, School of Life Sciences, East China Normal University, Shanghai, China; Jin Y., Beijing Key Laboratory for Pediatric Diseases of Otolaryngology, Head and Neck Surgery, MOE Key Laboratory of Major Diseases in Children, Beijing Children's Hospital, National Center for Children's Health, Beijing Pediatric Research Institute, Capital Medical University, Beijing, China, Biobank for Clinical Data and Samples in Pediatrics, Beijing Children's Hospital, National Center for Children's Health, Beijing Pediatric Research Institute, Capital Medical University, Beijing, China; Cheng G., Center for Bioinformatics and Computational Biology, Institute of Biomedical Sciences, School of Life Sciences, East China Normal University, Shanghai, China; Fu Y., Center for Bioinformatics and Computational Biology, Institute of Biomedical Sciences, School of Life Sciences, East China Normal University, Shanghai, China; Yuan D., Center for Bioinformatics and Computational Biology, Institute of Biomedical Sciences, School of Life Sciences, East China Normal University, Shanghai, China; Tao Y., Center for Bioinformatics and Computational Biology, Institute of Biomedical Sciences, School of Life Sciences, East China Normal University, Shanghai, China; Guo Y., Beijing Key Laboratory for Pediatric Diseases of Otolaryngology, Head and Neck Surgery, MOE Key Laboratory of Major Diseases in Children, Beijing Children's Hospital, National Center for Children's Health, Beijing Pediatric Research Institute, Capital Medical University, Beijing, China, Biobank for Clinical Data and Samples in Pediatrics, Beijing Children's Hospital, National Center for Children's Health, Beijing Pediatric Research Institute, Capital Medical University, Beijing, China; Ni X., Beijing Key Laboratory for Pediatric Diseases of Otolaryngology, Head and Neck Surgery, MOE Key Laboratory of Major Diseases in Children, Beijing Children's Hospital, National Center for Children's Health, Beijing Pediatric Research Institute, Capital Medical University, Beijing, China, Biobank for Clinical Data and Samples in Pediatrics, Beijing Children's Hospital, National Center for Children's Health, Beijing Pediatric Research Institute, Capital Medical University, Beijing, China, Department of Otolaryngology, Head and Neck Surgery, Beijing Children's Hospital, National Center for Children's Health, Capital Medical University, Beijing, China; Shi T., Center for Bioinformatics and Computational Biology, Institute of Biomedical Sciences, School of Life Sciences, East China Normal University, Shanghai, China, Department of Otolaryngology, Head and Neck Surgery, Beijing Children's Hospital, National Center for Children's Health, Capital Medical University, Beijing, China","High-risk neuroblastoma is a very aggressive disease, with excessive tumor growth and poor outcomes. A proper stratification of the high-risk patients by prognostic outcome is important for treatment. However, there is still a lack of survival stratification for the high-risk neuroblastoma. To fill the gap, we adopt a deep learning algorithm, Autoencoder, to integrate multi-omics data, and combine it with K-means clustering to identify two subtypes with significant survival differences. By comparing the Autoencoder with PCA, iCluster, and DGscore about the classification based on multi-omics data integration, Autoencoder-based classification outperforms the alternative approaches. Furthermore, we also validated the classification in two independent datasets by training machine-learning classification models, and confirmed its robustness. Functional analysis revealed that MYCN amplification was more frequently occurred in the ultra-high-risk subtype, in accordance with the overexpression of MYC/MYCN targets in this subtype. In summary, prognostic subtypes identified by deep learning-based multi-omics integration could not only improve our understanding of molecular mechanism, but also help the clinicians make decisions. Copyright © 2018 Zhang, Lv, Jin, Cheng, Fu, Yuan, Tao, Guo, Ni and Shi. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.","Deep learning; High-risk neuroblastoma; Machine learning; Multi-omics data integration; MYCN amplification","Myc protein; Article; cancer patient; cancer prognosis; gene amplification; gene overexpression; high risk patient; human; learning algorithm; major clinical study; neuroblastoma; omics","Frontiers Media S.A.","16648021","","","","Article","Scopus","2-s2.0-85055322501"
"Yang W.; Si Y.; Wang D.; Guo B.","Yang, Weiyi (57203280709); Si, Yujuan (8417025100); Wang, Di (57008490800); Guo, Buhao (57203285691)","57203280709; 8417025100; 57008490800; 57203285691","Automatic recognition of arrhythmia based on principal component analysis network and linear support vector machine","2018","Computers in Biology and Medicine","123","10.1016/j.compbiomed.2018.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051109727&doi=10.1016%2fj.compbiomed.2018.08.003&partnerID=40&md5=e976fcf45a8181012849239afb408166","College of Communication Engineering, Jilin University, Changchun, 130012, China; Zhuhai College of Jilin University, Zhuhai, 519041, China","Yang W., College of Communication Engineering, Jilin University, Changchun, 130012, China; Si Y., College of Communication Engineering, Jilin University, Changchun, 130012, China, Zhuhai College of Jilin University, Zhuhai, 519041, China; Wang D., College of Communication Engineering, Jilin University, Changchun, 130012, China; Guo B., College of Communication Engineering, Jilin University, Changchun, 130012, China","Electrocardiogram (ECG) classification is an important process in identifying arrhythmia, and neural network models have been widely used in this field. However, these models are often disrupted by heartbeat noise and are negatively affected by skewed data. To address these problems, a novel heartbeat recognition method is presented. The aim of this study is to apply a principal component analysis network (PCANet) for feature extraction based on a noisy ECG signal. To improve the classification speed, a linear support vector machine (SVM) was applied. In our experiments, we identified five types of imbalanced original and noise-free ECGs in the MIT-BIH arrhythmia database to verify the effectiveness of our algorithm and achieved 97.77% and 97.08% accuracy, respectively. The results show that our method has high recognition accuracy in the classification of skewed and noisy heartbeats, indicating that our method is a practical ECG recognition method with suitable noise robustness and skewed data applicability. © 2018 Elsevier Ltd","Arrhythmia recognition; Cardiovascular diseases; Deep learning; Noise robustness; Principal component analysis network","Arrhythmias, Cardiac; Databases, Factual; Electrocardiography; Humans; Neural Networks (Computer); Signal Processing, Computer-Assisted; Support Vector Machine; Deep learning; Diseases; Electrocardiography; Linear networks; Support vector machines; Arrhythmia recognition; Automatic recognition; Cardio-vascular disease; Linear Support Vector Machines; Neural network model; Noise robustness; Recognition accuracy; Recognition methods; Article; automation; back propagation neural network; diagnostic accuracy; electrocardiogram; feature extraction; heart arrhythmia; k nearest neighbor; linear support vector machine; nerve cell network; pattern recognition; principal component analysis; priority journal; random forest; reliability; sensitivity and specificity; support vector machine; waveform; artificial neural network; electrocardiography; factual database; human; pathophysiology; signal processing; Principal component analysis","Elsevier Ltd","00104825","","CBMDA","30098452","Article","Scopus","2-s2.0-85051109727"
"Rendall R.; Castillo I.; Lu B.; Colegrove B.; Broadway M.; Chiang L.H.; Reis M.S.","Rendall, Ricardo (56385910400); Castillo, Ivan (35174380700); Lu, Bo (51562120800); Colegrove, Brenda (57200004415); Broadway, Michael (57202816315); Chiang, Leo H. (7101715303); Reis, Marco S. (9273948800)","56385910400; 35174380700; 51562120800; 57200004415; 57202816315; 7101715303; 9273948800","Image-based manufacturing analytics: Improving the accuracy of an industrial pellet classification system using deep neural networks","2018","Chemometrics and Intelligent Laboratory Systems","20","10.1016/j.chemolab.2018.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049470015&doi=10.1016%2fj.chemolab.2018.07.001&partnerID=40&md5=f75a4d0e2c214de584959804c1f4ad33","CIEPQPF, Department of Chemical Engineering, University of Coimbra, Rua Sílvio Lima, Coimbra, 3030-790, Portugal; Dow Chemical Company, Freeport, TX, United States","Rendall R., CIEPQPF, Department of Chemical Engineering, University of Coimbra, Rua Sílvio Lima, Coimbra, 3030-790, Portugal; Castillo I., Dow Chemical Company, Freeport, TX, United States; Lu B., Dow Chemical Company, Freeport, TX, United States; Colegrove B., Dow Chemical Company, Freeport, TX, United States; Broadway M., Dow Chemical Company, Freeport, TX, United States; Chiang L.H., Dow Chemical Company, Freeport, TX, United States; Reis M.S., CIEPQPF, Department of Chemical Engineering, University of Coimbra, Rua Sílvio Lima, Coimbra, 3030-790, Portugal","Manufacturing analytics is of paramount importance in many plants today, and its relevance increases in the current big data context of Industry 4.0. The fields of statistics, chemometrics, and machine learning are expected to provide tools that effectively handle many of the characteristics of industrial data. In this paper, the task of image-based product classification is considered. This is a supervised learning problem where the input is an image and the output is a unique label attributed to the image from a finite set of labels corresponding to the available product classes. This is a prevalent and highly relevant industrial challenge and recent developments in deep learning have proven to be successful in increasing the image classification accuracy, providing state-of-the-art results. Thus, in this work, we leverage deep neural networks’ (DNN) ability to automatically learn features from images and test their performance in a real industrial context for predicting the pellet shape. In order to accelerate the training of DNN, transfer learning is employed and a network previously developed for one task is adapted to predict pellet shape. Furthermore, other less complex techniques such as partial least squares discriminant analysis (PLS-DA) and random forests (RF) are also explored in order to assess the benefits of adopting DNN as opposed to current classifiers. An industrial image classification case study was utilized to compare PLS-DA, RF, and DNN models. Compared to the in situ classification system currently in use, increasingly complex models (PLS-DA and RF) were able to better utilize the same pre-defined features and improve prediction accuracy significantly. DNN obtained the highest accuracy on the independent test set, with the advantages of not requiring the a priori computation of image features since they are directly extracted from the raw images. Moreover, by visualizing the output of some layers of the DNN, it is possible to verify that activations occurred in regions that are indeed meaningful for the classification tasks, further supporting that DNN were effectively modelling the relevant features of the pellet. © 2018 Elsevier B.V.","Deep learning; Manufacturing analytics; Pellet shape classification; Transfer learning","analytic method; Article; artificial neural network; classifier; comparative study; discriminant analysis; image analysis; manufacturing industry; measurement accuracy; priority journal; random forest; receiver operating characteristic; transfer of learning","Elsevier B.V.","01697439","","CILSE","","Article","Scopus","2-s2.0-85049470015"
"Haenssle H.A.; Fink C.; Schneiderbauer R.; Toberer F.; Buhl T.; Blum A.; Kalloo A.; Ben Hadj Hassen A.; Thomas L.; Enk A.; Uhlmann L.; Alt C.; Arenbergerova M.; Bakos R.; Baltzer A.; Bertlich I.; Blum A.; Bokor-Billmann T.; Bowling J.; Braghiroli N.; Braun R.; Buder-Bakhaya K.; Cabo H.; Cabrijan L.; Cevic N.; Classen A.; Deltgen D.; Georgieva I.; Hakim-Meibodi L.-E.; Hanner S.; Hartmann F.; Hartmann J.; Haus G.; Hoxha E.; Karls R.; Koga H.; Kreusch J.; Lallas A.; Majenka P.; Marghoob A.; Massone C.; Mekokishvili L.; Mestel D.; Meyer V.; Neuberger A.; Nielsen K.; Oliviero M.; Pampena R.; Paoli J.; Pawlik Erika.; Rao B.; Rendon A.; Russo T.; Sadek A.; Samhaber K.; Schweizer A.; Trennheuser L.; Vlahova L.; Wald A.; Winkler J.; Wo¨lbing P.; Zalaudek I.","Haenssle, H.A. (6603657821); Fink, C. (56844769800); Schneiderbauer, R. (37018809400); Toberer, F. (37262045600); Buhl, T. (24463656700); Blum, A. (55644610100); Kalloo, A. (57213031962); Ben Hadj Hassen, A. (57204418301); Thomas, L. (7403526957); Enk, A. (55094698000); Uhlmann, L. (55536615700); Alt, Christina (57192176855); Arenbergerova, Monika (24330974800); Bakos, Renato (57195428961); Baltzer, Anne (57190674203); Bertlich, Ines (57193013968); Blum, Andreas (7402675019); Bokor-Billmann, Therezia (55507231200); Bowling, Jonathan (15019045500); Braghiroli, Naira (55801404500); Braun, Ralph (7402220663); Buder-Bakhaya, Kristina (36489136200); Cabo, Horacio (6603505616); Cabrijan, Leo (6507569489); Cevic, Naciye (57211306123); Classen, Anna (56517810700); Deltgen, David (57211306096); Georgieva, Ivelina (57508446400); Hakim-Meibodi, Lara-Elena (57200074786); Hanner, Susanne (57196464440); Hartmann, Franziska (57190577225); Hartmann, Julia (57205638806); Haus, Georg (12806372600); Hoxha, Elti (57195604799); Karls, Raimonds (57192648627); Koga, Hiroshi (56583488800); Kreusch, Ju¨rgen (7004223015); Lallas, Aimilios (23482399900); Majenka, Pawel (57195969615); Marghoob, Ash (57211306206); Massone, Cesare (55401556200); Mekokishvili, Lali (55544227200); Mestel, Dominik (24464261900); Meyer, Volker (57211306133); Neuberger, Anna (57195053073); Nielsen, Kari (8791360200); Oliviero, Margaret (7004025692); Pampena, Riccardo (55821950800); Paoli, John (14631010100); Pawlik, Erika (57211306205); Rao, Barbar (57211306201); Rendon, Adriana (57192066619); Russo, Teresa (56247908400); Sadek, Ahmed (57198232067); Samhaber, Kinga (56072647800); Schweizer, Anissa (57202898971); Trennheuser, Lukas (55795873900); Vlahova, Lyobomira (57216586101); Wald, Alexander (57207937061); Winkler, Julia (57191580858); Wo¨lbing, Priscila (57194173016); Zalaudek, Iris (6701737036)","6603657821; 56844769800; 37018809400; 37262045600; 24463656700; 55644610100; 57213031962; 57204418301; 7403526957; 55094698000; 55536615700; 57192176855; 24330974800; 57195428961; 57190674203; 57193013968; 7402675019; 55507231200; 15019045500; 55801404500; 7402220663; 36489136200; 6603505616; 6507569489; 57211306123; 56517810700; 57211306096; 57508446400; 57200074786; 57196464440; 57190577225; 57205638806; 12806372600; 57195604799; 57192648627; 56583488800; 7004223015; 23482399900; 57195969615; 57211306206; 55401556200; 55544227200; 24464261900; 57211306133; 57195053073; 8791360200; 7004025692; 55821950800; 14631010100; 57211306205; 57211306201; 57192066619; 56247908400; 57198232067; 56072647800; 57202898971; 55795873900; 57216586101; 57207937061; 57191580858; 57194173016; 6701737036","Man against Machine: Diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists","2018","Annals of Oncology","892","10.1093/annonc/mdy166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054158054&doi=10.1093%2fannonc%2fmdy166&partnerID=40&md5=bb5b77701696a7a4343562a96ae0b60e","Department of Dermatology, University of Heidelberg, Heidelberg, Germany; Department of Dermatology, University of GÃ¶ttingen, GÃ¶ttingen, Germany; Office Based Clinic of Dermatology, Konstanz, Germany; Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, United States; Faculty of Computer Science and Mathematics, University of Passau, Passau, Germany; Department of Dermatology, Lyons Cancer Research Center, Lyon 1 University, Lyon, France; Institute of Medical Biometry and Informatics, University of Heidelberg, Heidelberg, Germany","Haenssle H.A., Department of Dermatology, University of Heidelberg, Heidelberg, Germany; Fink C., Department of Dermatology, University of Heidelberg, Heidelberg, Germany; Schneiderbauer R., Department of Dermatology, University of Heidelberg, Heidelberg, Germany; Toberer F., Department of Dermatology, University of Heidelberg, Heidelberg, Germany; Buhl T., Department of Dermatology, University of GÃ¶ttingen, GÃ¶ttingen, Germany; Blum A., Office Based Clinic of Dermatology, Konstanz, Germany; Kalloo A., Dermatology Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, United States; Ben Hadj Hassen A., Faculty of Computer Science and Mathematics, University of Passau, Passau, Germany; Thomas L., Department of Dermatology, Lyons Cancer Research Center, Lyon 1 University, Lyon, France; Enk A., Department of Dermatology, University of Heidelberg, Heidelberg, Germany; Uhlmann L., Institute of Medical Biometry and Informatics, University of Heidelberg, Heidelberg, Germany; Alt C.; Arenbergerova M.; Bakos R.; Baltzer A.; Bertlich I.; Blum A.; Bokor-Billmann T.; Bowling J.; Braghiroli N.; Braun R.; Buder-Bakhaya K.; Cabo H.; Cabrijan L.; Cevic N.; Classen A.; Deltgen D.; Georgieva I.; Hakim-Meibodi L.-E.; Hanner S.; Hartmann F.; Hartmann J.; Haus G.; Hoxha E.; Karls R.; Koga H.; Kreusch J.; Lallas A.; Majenka P.; Marghoob A.; Massone C.; Mekokishvili L.; Mestel D.; Meyer V.; Neuberger A.; Nielsen K.; Oliviero M.; Pampena R.; Paoli J.; Pawlik Erika.; Rao B.; Rendon A.; Russo T.; Sadek A.; Samhaber K.; Schweizer A.; Trennheuser L.; Vlahova L.; Wald A.; Winkler J.; Wo¨lbing P.; Zalaudek I.","Background: Deep learning convolutional neural networks (CNN) May facilitate melanoma detection, but data comparing a CNN’s diagnostic performance to larger groups of dermatologists are lacking. Methods: Google’s Inception v4 CNN architecture was trained and validated using dermoscopic images and corresponding diagnoses. In a comparative cross-sectional reader study a 100-image test-set was used (level-I: dermoscopy only; level-II: dermoscopy plus clinical information and images). Main outcome measures were sensitivity, specificity and area under the curve (AUC) of receiver operating characteristics (ROC) for diagnostic classification (dichotomous) of lesions by the CNN versus an international group of 58 dermatologists during level-I or -II of the reader study. Secondary end points included the dermatologists’ diagnostic performance in their management decisions and differences in the diagnostic performance of dermatologists during level-I and -II of the reader study. Additionally, the CNN’s performance was compared with the top-five algorithms of the 2016 International Symposium on Biomedical Imaging (ISBI) challenge. Results: In level-I dermatologists achieved a mean (6standard deviation) sensitivity and specificity for lesion classification of 86.6% (69.3%) and 71.3% (611.2%), respectively. More clinical information (level-II) improved the sensitivity to 88.9% (69.6%, P ¼ 0.19) and specificity to 75.7% (611.7%, P < 0.05). The CNN ROC curve revealed a higher specificity of 82.5% when compared with dermatologists in level-I (71.3%, P < 0.01) and level-II (75.7%, P < 0.01) at their sensitivities of 86.6% and 88.9%, respectively. The CNN ROC AUC was greater than the mean ROC area of dermatologists (0.86 versus 0.79, P < 0.01). The CNN scored results close to the top three algorithms of the ISBI 2016 challenge. Conclusions: For the first time we compared a CNN’s diagnostic performance with a large international group of 58 dermatologists, including 30 experts. Most dermatologists were outperformed by the CNN. Irrespective of any physicians’ experience, they May benefit from assistance by a CNN’s image classification. © The Author(s) 2018.","Automated melanoma detection; Computer algorithm; Deep learning convolutional neural network; Dermoscopy; Melanocytic nevi; Melanoma","Clinical Competence; Cross-Sectional Studies; Deep Learning; Dermatologists; Dermoscopy; Humans; Image Processing, Computer-Assisted; International Cooperation; Melanoma; Retrospective Studies; ROC Curve; Skin; Skin Neoplasms; area under the curve; Article; artificial neural network; cancer classification; cancer diagnosis; comparative study; cross-sectional study; deep learning convolutional neural network; dermatologist; diagnostic accuracy; diagnostic test accuracy study; epiluminescence microscopy; human; melanoma; outcome assessment; priority journal; receiver operating characteristic; sensitivity and specificity; clinical competence; diagnostic imaging; epiluminescence microscopy; image processing; international cooperation; melanoma; procedures; retrospective study; skin; skin tumor","Oxford University Press","09237534","","ANONE","29846502","Article","Scopus","2-s2.0-85054158054"
"Wangshow W.; Chen B.; Xia P.; Hu J.; Peng Y.","Wangshow, Weiming (57204139799); Chen, Biao (57202312927); Xia, Peng (55786581200); Hu, Jie (56239213600); Peng, Yinghong (55754470800)","57204139799; 57202312927; 55786581200; 56239213600; 55754470800","Sensor Fusion for Myoelectric Control Based on Deep Learning With Recurrent Convolutional Neural Networks","2018","Artificial Organs","30","10.1111/aor.13153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050601142&doi=10.1111%2faor.13153&partnerID=40&md5=85d9341f90c73cbbcd2d354e56fd1fda","School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China","Wangshow W., School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Chen B., School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Xia P., School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Hu J., School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Peng Y., School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China","Electromyogram (EMG) signal decoding is the essential part of myoelectric control. However, traditional machine learning methods lack the capability of learning and expressing the information contained in EMG signals, and the robustness of the myoelectric control system is not sufficient for real life applications. In this article, a novel model based on recurrent convolutional neural networks (RCNNs) is proposed for hand movement classification and tested on the noninvasive EMG dataset. The proposed model uses deep architecture, which has advantages of dealing with complex time-series data, such as EMG signals. Transfer learning is used in the training of multimodal model. The classification performance is compared with support vector machine (SVM) and convolutional neural networks (CNNs) on the same dataset. To improve the adaptability to the effect of arm movements, we fused the EMG signals and acceleration data that are the multimodal input of the model. The parameter transferring of deep neural networks is used to accelerate the training process and avoid over-fitting. The experimental results show that time domain input and 1-dimensional convolution have higher accuracy in the RCNN model. Compared with SVM and CNNs, the proposed model has higher classification accuracy. Sensor fusion can improve the model performance in the condition of arm movements. The RCNN model is a promising decoder of EMG and the sensor fusion can increase the accuracy and robustness of the myoelectric control system. © 2018 International Center for Artificial Organs and Transplantation and Wiley Periodicals, Inc.","Deep learning; Electromyogram; Recurrent convolutional neural networks; Sensor fusion; Transfer learning","Adult; Algorithms; Deep Learning; Electromyography; Female; Humans; Male; Muscle, Skeletal; Neural Networks (Computer); Support Vector Machine; Transfer (Psychology); Classification (of information); Convolution; Decoding; Deep neural networks; Robust control; Robustness (control systems); Support vector machines; Arm movements; Convolutional neural network; Deep learning; Electromyo grams; Electromyogram signals; Myoelectric control; Neural network model; Sensor fusion; Support vectors machine; Transfer learning; arm movement; Article; artificial neural network; controlled study; convolutional neural network; electromyography; hand movement; human; human experiment; intermethod comparison; machine learning; myoelectric control; priority journal; recurrent convolutional neural network; support vector machine; time series analysis; transfer of learning; adult; algorithm; electromyography; female; male; physiology; skeletal muscle; Recurrent neural networks","John Wiley and Sons Inc","0160564X","","ARORD","30003559","Article","Scopus","2-s2.0-85050601142"
"Qiao K.; Zhang C.; Wang L.; Chen J.; Zeng L.; Tong L.; Yan B.","Qiao, Kai (57188641013); Zhang, Chi (57757799500); Wang, Linyuan (36667643700); Chen, Jian (56016202000); Zeng, Lei (56061534900); Tong, Li (37062047500); Yan, Bin (57222731250)","57188641013; 57757799500; 36667643700; 56016202000; 56061534900; 37062047500; 57222731250","Accurate Reconstruction of Image Stimuli From Human Functional Magnetic Resonance Imaging Based on the Decoding Model With Capsule Network Architecture","2018","Frontiers in Neuroinformatics","18","10.3389/fninf.2018.00062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054878153&doi=10.3389%2ffninf.2018.00062&partnerID=40&md5=bec3409af4fd46e49a4d11791dea43bb","National Digital Switching System Engineering and Technological Research Center, Zhengzhou, China","Qiao K., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, China; Zhang C., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, China; Wang L., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, China; Chen J., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, China; Zeng L., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, China; Tong L., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, China; Yan B., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, China","In neuroscience, all kinds of computation models were designed to answer the open question of how sensory stimuli are encoded by neurons and conversely, how sensory stimuli can be decoded from neuronal activities. Especially, functional Magnetic Resonance Imaging (fMRI) studies have made many great achievements with the rapid development of deep network computation. However, comparing with the goal of decoding orientation, position and object category from human fMRI in visual cortex, accurate reconstruction of image stimuli is a still challenging work. Current prevailing methods were composed of two independent steps, (1) decoding intermediate features from human fMRI and (2) reconstruction using the decoded intermediate features. The new concept of ‘capsule’ and ‘capsule’ based neural network were proposed recently. The ‘capsule’ represented a kind of structure containing a group of neurons to perform better feature representation. Especially, the high-level capsule’s features in the capsule network (CapsNet) contains various features of image stimuli such as semantic class, orientation, location, scale and so on, and these features can better represent the processed information inherited in the fMRI data collected in visual cortex. In this paper, a novel CapsNet architecture based visual reconstruction (CNAVR) computation model is developed to reconstruct image stimuli from human fMRI. The CNAVR is composed of linear encoding computation from capsule’s features to fMRI data and inverse reconstruction computation. In the first part, we trained the CapsNet model to obtain the non-linear mappings from images to high-level capsule’s features, and from high-level capsule’s features to images again in an end-to-end manner. In the second part, we trained the non-linear mapping from fMRI data of selected voxels to high-level capsule’s features. For a new image stimulus, we can use the method to predict the corresponding high-level capsule’s features using fMRI data, and reconstruct image stimuli with the trained reconstruction part in the CapsNet. We evaluated the proposed CNAVR method on the open dataset of handwritten digital images, and exceeded about 10% than the accuracy of all existing state-of-the-art methods on the structural similarity index (SSIM). In addition, we explained the selected voxels in specific interpretable image features to prove the effectivity and generalization of the CNAVR method. © 2018 Qiao, Zhang, Wang, Chen, Zeng, Tong and Yan.","Brain decoding; Capsule network (CapsNet); Functional magnetic resonance imaging (fMRI); Machine learning; Visual reconstruction","article; controlled study; functional magnetic resonance imaging; human; human experiment; machine learning; nerve cell; stimulus; visual cortex","Frontiers Media S.A.","16625196","","","","Article","Scopus","2-s2.0-85054878153"
"Xie Y.; Luo X.; Li Y.; Chen L.; Ma W.; Huang J.; Cui J.; Zhao Y.; Xue Y.; Zuo Z.; Ren J.","Xie, Yubin (56292146900); Luo, Xiaotong (56970096500); Li, Yupeng (57897114700); Chen, Li (56115476300); Ma, Wenbin (56446085800); Huang, Junjiu (25629545800); Cui, Jun (55233269400); Zhao, Yong (47761797600); Xue, Yu (7402270422); Zuo, Zhixiang (55613958200); Ren, Jian (35073089500)","56292146900; 56970096500; 57897114700; 56115476300; 56446085800; 25629545800; 55233269400; 47761797600; 7402270422; 55613958200; 35073089500","DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning","2018","Genomics, Proteomics and Bioinformatics","83","10.1016/j.gpb.2018.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054469492&doi=10.1016%2fj.gpb.2018.04.007&partnerID=40&md5=a4c07d1c56a8a75bee8ac4a0752ddd8f","State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Department of Bioinformatics & Systems Biology, MOE Key Laboratory of Molecular Biophysics, College of Life Science and Technology and the Collaborative Innovation Center for Biomedical Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China","Xie Y., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Luo X., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Li Y., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Chen L., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Ma W., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Huang J., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Cui J., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Zhao Y., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Xue Y., Department of Bioinformatics & Systems Biology, MOE Key Laboratory of Molecular Biophysics, College of Life Science and Technology and the Collaborative Innovation Center for Biomedical Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China; Zuo Z., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China; Ren J., State Key Laboratory of Oncology in South China, Cancer Center, Collaborative Innovation Center for Cancer Medicine, School of Life Sciences, Sun Yat-sen University, Guangzhou, 510060, China","Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%−42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org. © 2018","Deep learning; Feature extraction; Functional site prediction; Protein nitration and nitrosylation; Web service","Amino Acid Sequence; Amino Acids; Deep Learning; Humans; Internet; Neural Networks (Computer); Nitrosation; Proteins; Reproducibility of Results; Software; amino acid; cysteine; protein; tryptophan; tyrosine; protein; amino acid sequence; Article; deep learning; machine learning; nitration; nitrosylation; physical chemistry; prediction; protein processing; reliability; validation process; artificial neural network; chemistry; human; Internet; metabolism; nitrosation; reproducibility; software","Beijing Genomics Institute","16720229","","","30268931","Article","Scopus","2-s2.0-85054469492"
"Chen Y.P.; Li Y.; Wang G.","Chen, Yu Peng (57194063495); Li, Ying (55924880500); Wang, Gang (56589199200)","57194063495; 55924880500; 56589199200","An enhanced region proposal network for object detection using deep learning method","2018","PLoS ONE","25","10.1371/journal.pone.0203897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053594993&doi=10.1371%2fjournal.pone.0203897&partnerID=40&md5=ee10c15e1d932887c6556107b01ce813","College of Computer Science and Technology, Jilin University, Changchun, China; Key Laboratory of Symbolic Computation, Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China","Chen Y.P., College of Computer Science and Technology, Jilin University, Changchun, China, Key Laboratory of Symbolic Computation, Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China; Li Y., College of Computer Science and Technology, Jilin University, Changchun, China, Key Laboratory of Symbolic Computation, Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China; Wang G., College of Computer Science and Technology, Jilin University, Changchun, China, Key Laboratory of Symbolic Computation, Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China","Faster Region-based Convolutional Network (Faster R-CNN) is a state-of-the-art object detection method. However, the object detection effect of Faster R-CNN is not good based on the Region Proposal Network (RPN). Inspired by RPN of Faster R-CNN, we propose a novel proposal generation method called Enhanced Region Proposal Network (ERPN). Four improvements are presented in ERPN. Firstly, our proposed deconvolutional feature pyramid network (DFPN) is introduced to improve the quality of region proposals. Secondly, novel anchor boxes are designed with interspersed scales and adaptive aspect ratios. Thereafter, the capability of object localization is increased. Thirdly, a particle swarm optimization (PSO) based support vector machine (SVM), termed PSO-SVM, is developed to distinguish the positive and negative anchor boxes. Fourthly, the classification part of multitask loss function in RPN is improved. Consequently, the effect of classification loss is strengthened. In this study, our proposed ERPN is compared with five object detection methods on both PASCAL VOC and COCO data sets. For the VGG-16 model, our ERPN obtains 78.6% mAP on VOC 2007 data set, 74.4% mAP on VOC 2012 data set and 31.7% on COCO data set. The performance of ERPN is the best among the comparison object detection methods. Furthermore, the detection speed of ERPN is 5.8 fps. Additionally, ERPN obtains good effect on small object detection. © 2018 Chen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Deep Learning; Neural Networks (Computer); Support Vector Machine; article; intermethod comparison; learning; loss of function mutation; support vector machine; velocity; algorithm; artificial neural network; support vector machine","Public Library of Science","19326203","","POLNC","30235238","Article","Scopus","2-s2.0-85053594993"
"Tran D.T.; Iosifidis A.; Gabbouj M.","Tran, Dat Thanh (57208873207); Iosifidis, Alexandros (36720841400); Gabbouj, Moncef (7005332419)","57208873207; 36720841400; 7005332419","Improving efficiency in convolutional neural networks with multilinear filters","2018","Neural Networks","28","10.1016/j.neunet.2018.05.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048580936&doi=10.1016%2fj.neunet.2018.05.017&partnerID=40&md5=8e6476b4f45c82d650c2cf8e7e3cf8c8","Laboratory of Signal Processing, Tampere University of Technology, Finland; Department of Engineering, Electrical and Computer Engineering, Aarhus University, Denmark","Tran D.T., Laboratory of Signal Processing, Tampere University of Technology, Finland; Iosifidis A., Department of Engineering, Electrical and Computer Engineering, Aarhus University, Denmark; Gabbouj M., Laboratory of Signal Processing, Tampere University of Technology, Finland","The excellent performance of deep neural networks has enabled us to solve several automatization problems, opening an era of autonomous devices. However, current deep net architectures are heavy with millions of parameters and require billions of floating point operations. Several works have been developed to compress a pre-trained deep network to reduce memory footprint and, possibly, computation. Instead of compressing a pre-trained network, in this work, we propose a generic neural network layer structure employing multilinear projection as the primary feature extractor. The proposed architecture requires several times less memory as compared to the traditional Convolutional Neural Networks (CNN), while inherits the similar design principles of a CNN. In addition, the proposed architecture is equipped with two computation schemes that enable computation reduction or scalability. Experimental results show the effectiveness of our compact projection that outperforms traditional CNN, while requiring far fewer parameters. © 2018 Elsevier Ltd","Convolutional neural networks; Multilinear projection; Network compression","Data Compression; Machine Learning; Neural Networks (Computer); Bandpass filters; Convolution; Deep neural networks; Digital arithmetic; Memory architecture; Network layers; Neural networks; Computation reduction; Convolutional neural network; Convolutional Neural Networks (CNN); Floating point operations; Improving efficiency; Multilinear projection; Network compression; Proposed architectures; Article; artificial neural network; classifier; controlled study; convolutional neural network; information processing; machine learning; multilinear filter; priority journal; statistical analysis; information processing; procedures; standards; Network architecture","Elsevier Ltd","08936080","","NNETE","29920430","Article","Scopus","2-s2.0-85048580936"
"Liu M.-Q.; Lan J.; Chen X.; Yu G.-J.; Yang X.-J.","Liu, Ming-Qian (57203868472); Lan, Jun (57212018357); Chen, Xu (57203872426); Yu, Guang-Jun (56303901900); Yang, Xiu-Jun (37006151300)","57203868472; 57212018357; 57203872426; 56303901900; 37006151300","Bone age assessment model based on multi-dimensional feature fusion using deep learning","2018","Academic Journal of Second Military Medical University","8","10.16781/j.0258-879x.2018.08.0909","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053294452&doi=10.16781%2fj.0258-879x.2018.08.0909&partnerID=40&md5=3b24257933d503f0a6fbfbadeffec232","Winning Artificial Intelligence Research, Winning Health Technology Group Co. Ltd, Shanghai, 200072, China; Big Data Eengineering and Technology Research Center for Pediatric Precision Medicine, Children’s Hospital of Shanghai Jiao Tong University, Shanghai, 200040, China","Liu M.-Q., Winning Artificial Intelligence Research, Winning Health Technology Group Co. Ltd, Shanghai, 200072, China; Lan J., Winning Artificial Intelligence Research, Winning Health Technology Group Co. Ltd, Shanghai, 200072, China; Chen X., Winning Artificial Intelligence Research, Winning Health Technology Group Co. Ltd, Shanghai, 200072, China; Yu G.-J., Big Data Eengineering and Technology Research Center for Pediatric Precision Medicine, Children’s Hospital of Shanghai Jiao Tong University, Shanghai, 200040, China; Yang X.-J., Big Data Eengineering and Technology Research Center for Pediatric Precision Medicine, Children’s Hospital of Shanghai Jiao Tong University, Shanghai, 200040, China","Objective To evaluate the bone age of children using deep convolutional neural network based on feature extraction combined with key features and demographic information. Methods Left hand X-ray images were automatically recognized and preprocessed, and then the 17 key region features of bone age in the left hand joint were automatically extracted by X-ray image analysis method based on deep convolutional neural network. The image features of bone age were combined with clinical data (population statistics and gender) to train and test the bone age assessment model. Results The feature region extraction method based on deep learning had better efficiency in extracting feature information than traditional image analysis method, and the feature information combined with clinical information supplemented the information of bone age from another dimension. The average absolute error measured by bone age assessment model based on multidimensional data feature fusion was 0.455, which was better than traditional methods and only end-to-end deep learning method. Conclusion Compared with traditional machine learning methods, the deep convolutional neural network based on feature extraction has better performance, and can improve the predicting accuracy of image-based bone age by combining with population information such as gender and age. © 2018, Second Military Medical University Press. All rights reserved.","Age determination by skeleton; Artificial intelligence; Data analysis; Deep learning; Medical imaging","article; artificial intelligence; bone age determination; controlled study; data analysis; diagnostic imaging; feature extraction; female; gender; human; image analysis; machine learning; male","Second Military Medical University Press","0258879X","","DJXUE","","Article","Scopus","2-s2.0-85053294452"
"Shi S.; Xu G.","Shi, Shuai (56263545700); Xu, Guoren (8974168600)","56263545700; 8974168600","Novel performance prediction model of a biofilm system treating domestic wastewater based on stacked denoising auto-encoders deep learning network","2018","Chemical Engineering Journal","71","10.1016/j.cej.2018.04.087","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046374441&doi=10.1016%2fj.cej.2018.04.087&partnerID=40&md5=da02b5fbb0f0612c8456958b8c355bd5","National Engineering Laboratory for Sustainable Sludge Management & Resourcelization Technology, Harbin Institute of Technology, Harbin, 150090, China; State Key Laboratory of Urban Water Resource and Environment, Harbin Institute of Technology, Harbin, 150090, China","Shi S., National Engineering Laboratory for Sustainable Sludge Management & Resourcelization Technology, Harbin Institute of Technology, Harbin, 150090, China, State Key Laboratory of Urban Water Resource and Environment, Harbin Institute of Technology, Harbin, 150090, China; Xu G., National Engineering Laboratory for Sustainable Sludge Management & Resourcelization Technology, Harbin Institute of Technology, Harbin, 150090, China, State Key Laboratory of Urban Water Resource and Environment, Harbin Institute of Technology, Harbin, 150090, China","Stacked denoising auto-encoders (SDAE) deep learning network was used to predict the performance of a two-stage biofilm system, which was constructed based on traditional anaerobic/oxic process. Eight input variables were adopted for performance predicting, including concentrations of chemical oxygen demand (COD), ammonia (NH4+-N) and total nitrogen (TN) of biofilm system influent, concentrations of COD, NH4+-N and TN of anoxic biofilm reactor effluent, influent flow and reflux ratio of biofilm system. While concentrations of COD, NH4+-N and TN of biofilm system effluent were employed as output variables for COD, NH4+-N and TN prediction model, respectively. Root mean square error, mean absolute error, mean relative error and residuals were adopted for evaluating the fitness of the SDAE deep learning network model. Backpropagation neural network, support vector regression, extreme learning machine, gradient boosting decision tree and stacked auto-encoders were adopted for comparison to further demonstrate the effectiveness of the proposed method. Compared with the five contrast models, SDAE deep learning network model showed the best results, suggesting the possible application of performance prediction of the biofilm process with SDAE deep learning network model. © 2018 Elsevier B.V.","Artificial neural network; Biofilm process; Prediction; Stacked denoising auto-encoders; Wastewater treatment","Backpropagation; Biofilms; Chemical oxygen demand; Decision trees; Effluents; Errors; Forecasting; Mean square error; Network coding; Neural networks; Wastewater treatment; Auto encoders; Back propagation neural networks; Biofilm process; Extreme learning machine; Performance prediction; Performance prediction models; Root mean square errors; Support vector regression (SVR); Deep learning","Elsevier B.V.","13858947","","CMEJA","","Article","Scopus","2-s2.0-85046374441"
"Han Z.; Wei B.; Leung S.; Nachum I.B.; Laidley D.; Li S.","Han, Zhongyi (57194624171); Wei, Benzheng (25925572100); Leung, Stephanie (57194460168); Nachum, Ilanit Ben (23974715900); Laidley, David (9943780400); Li, Shuo (57189925356)","57194624171; 25925572100; 57194460168; 23974715900; 9943780400; 57189925356","Automated Pathogenesis-Based Diagnosis of Lumbar Neural Foraminal Stenosis via Deep Multiscale Multitask Learning","2018","Neuroinformatics","26","10.1007/s12021-018-9365-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042093398&doi=10.1007%2fs12021-018-9365-1&partnerID=40&md5=67b99653d0ebb7b19be81e354c4144fd","College of Science and Technology, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China; Computational Medicine Lab, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China; Department of Medical Imaging, Western University, London, N6A 4V2, Canada; Digital Image Group (DIG), London, N6A 4V2, ON, Canada","Han Z., College of Science and Technology, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China, Computational Medicine Lab, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China, Department of Medical Imaging, Western University, London, N6A 4V2, Canada, Digital Image Group (DIG), London, N6A 4V2, ON, Canada; Wei B., College of Science and Technology, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China, Computational Medicine Lab, Shandong University of Traditional Chinese Medicine, Jinan, 250355, China; Leung S., Digital Image Group (DIG), London, N6A 4V2, ON, Canada; Nachum I.B., Digital Image Group (DIG), London, N6A 4V2, ON, Canada; Laidley D., Digital Image Group (DIG), London, N6A 4V2, ON, Canada; Li S., Department of Medical Imaging, Western University, London, N6A 4V2, Canada, Digital Image Group (DIG), London, N6A 4V2, ON, Canada","Pathogenesis-based diagnosis is a key step to prevent and control lumbar neural foraminal stenosis (LNFS). It conducts both early diagnosis and comprehensive assessment by drawing crucial pathological links between pathogenic factors and LNFS. Automated pathogenesis-based diagnosis would simultaneously localize and grade multiple spinal organs (neural foramina, vertebrae, intervertebral discs) to diagnose LNFS and discover pathogenic factors. The automated way facilitates planning optimal therapeutic schedules and relieving clinicians from laborious workloads. However, no successful work has been achieved yet due to its extreme challenges since 1) multiple targets: each lumbar spine has at least 17 target organs, 2) multiple scales: each type of target organ has structural complexity and various scales across subjects, and 3) multiple tasks, i.e., simultaneous localization and diagnosis of all lumbar organs, are extremely difficult than individual tasks. To address these huge challenges, we propose a deep multiscale multitask learning network (DMML-Net) integrating a multiscale multi-output learning and a multitask regression learning into a fully convolutional network. 1) DMML-Net merges semantic representations to reinforce the salience of numerous target organs. 2) DMML-Net extends multiscale convolutional layers as multiple output layers to boost the scale-invariance for various organs. 3) DMML-Net joins a multitask regression module and a multitask loss module to prompt the mutual benefit between tasks. Extensive experimental results demonstrate that DMML-Net achieves high performance (0.845 mean average precision) on T1/T2-weighted MRI scans from 200 subjects. This endows our method an efficient tool for clinical LNFS diagnosis. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Deep learning; Multiscale learning; Multitask learning; Neural foraminal stenosis","Aged; Female; Humans; Intervertebral Disc Degeneration; Lumbar Vertebrae; Machine Learning; Male; Middle Aged; Multitasking Behavior; Neural Networks (Computer); Spinal Nerve Roots; Spinal Stenosis; aged; artificial neural network; behavior; clinical trial; diagnostic imaging; female; human; intervertebral disk degeneration; lumbar vertebra; machine learning; male; middle aged; multicenter study; spinal root; vertebral canal stenosis","Humana Press Inc.","15392791","","NEURK","29450848","Article","Scopus","2-s2.0-85042093398"
"Shaham U.; Yamada Y.; Negahban S.","Shaham, Uri (55662339300); Yamada, Yutaro (57202232507); Negahban, Sahand (36470927300)","55662339300; 57202232507; 36470927300","Understanding adversarial training: Increasing local stability of supervised models through robust optimization","2018","Neurocomputing","163","10.1016/j.neucom.2018.04.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047515976&doi=10.1016%2fj.neucom.2018.04.027&partnerID=40&md5=c8b27ed05118590fb453407e684ea2b0","Center for Outcome Research, Yale University, 200 Church st., New Haven, 06510, CT, United States; Department of Statistics, Yale University, 24 Hillhouse st., New Haven, 06511, CT, United States","Shaham U., Center for Outcome Research, Yale University, 200 Church st., New Haven, 06510, CT, United States; Yamada Y., Department of Statistics, Yale University, 24 Hillhouse st., New Haven, 06511, CT, United States; Negahban S., Department of Statistics, Yale University, 24 Hillhouse st., New Haven, 06511, CT, United States","We show that adversarial training of supervised learning models is in fact a robust optimization procedure. To do this, we establish a general framework for increasing local stability of supervised learning models using robust optimization. The framework is general and broadly applicable to differentiable non-parametric models, e.g., Artificial Neural Networks (ANNs). Using an alternating minimization-maximization procedure, the loss of the model is minimized with respect to perturbed examples that are generated at each parameter update, rather than with respect to the original training data. Our proposed framework generalizes adversarial training, as well as previous approaches for increasing local stability of ANNs. Experimental results reveal that our approach increases the robustness of the network to existing adversarial examples, while making it harder to generate new ones. Furthermore, our algorithm improves the accuracy of the networks also on the original test data. © 2018 Elsevier B.V.","Adversarial examples; Deep learning; Non-parametric supervised models; Robust optimization","Deep learning; Neural networks; Supervised learning; Adversarial examples; Alternating minimization; Local stability; Non-parametric; Non-parametric model; Robust optimization; Test data; Training data; accuracy; adversarial training; algorithm; Article; artificial neural network; data processing; machine learning; model; priority journal; process optimization; Optimization","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85047515976"
"Mostafa H.; Ramesh V.; Cauwenberghs G.","Mostafa, Hesham (56007793000); Ramesh, Vishwajith (57200246427); Cauwenberghs, Gert (7006056098)","56007793000; 57200246427; 7006056098","Deep supervised learning using local errors","2018","Frontiers in Neuroscience","64","10.3389/fnins.2018.00608","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052902057&doi=10.3389%2ffnins.2018.00608&partnerID=40&md5=c976a86cbb581b0a6bd3385b12634324","Institute for Neural Computation, University of California, San Diego, San Diego, CA, United States; Department of Bioengineering, University of California, San Diego, San Diego, CA, United States","Mostafa H., Institute for Neural Computation, University of California, San Diego, San Diego, CA, United States; Ramesh V., Department of Bioengineering, University of California, San Diego, San Diego, CA, United States; Cauwenberghs G., Institute for Neural Computation, University of California, San Diego, San Diego, CA, United States, Department of Bioengineering, University of California, San Diego, San Diego, CA, United States","Error backpropagation is a highly effective mechanism for learning high-quality hierarchical features in deep networks. Updating the features or weights in one layer, however, requires waiting for the propagation of error signals from higher layers. Learning using delayed and non-local errors makes it hard to reconcile backpropagation with the learning mechanisms observed in biological neural networks as it requires the neurons to maintain a memory of the input long enough until the higher-layer errors arrive. In this paper, we propose an alternative learning mechanism where errors are generated locally in each layer using fixed, random auxiliary classifiers. Lower layers could thus be trained independently of higher layers and training could either proceed layer by layer, or simultaneously in all layers using local error information. We address biological plausibility concerns such as weight symmetry requirements and show that the proposed learning mechanism based on fixed, broad, and random tuning of each neuron to the classification categories outperforms the biologically-motivated feedback alignment learning technique on the CIFAR10 dataset, approaching the performance of standard backpropagation. Our approach highlights a potential biological mechanism for the supervised, or task-dependent, learning of feature hierarchies. In addition, we show that it is well suited for learning deep networks in custom hardware where it can drastically reduce memory traffic and data communication overheads. Code used to run all learning experiments is available under https://gitlab.com/hesham-mostafa/learning-using-local-erros.git. © 2018 Mostafa, Ramesh and Cauwenberghs.","Backpropagation; Biological learning; Hardware accelerators; Local errors; Supervised learning","Article; artificial neural network; back propagation; backpropagation through time; classifier; controlled study; convolutional network; feedback system; information processing; kernel method; local error; machine learning; measurement accuracy; supervised learning","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85052902057"
"Acharya U.R.; Oh S.L.; Hagiwara Y.; Tan J.H.; Adeli H.","Acharya, U. Rajendra (7004510847); Oh, Shu Lih (57185991600); Hagiwara, Yuki (57057106000); Tan, Jen Hong (26644487800); Adeli, Hojjat (35612773100)","7004510847; 57185991600; 57057106000; 26644487800; 35612773100","Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals","2018","Computers in Biology and Medicine","1143","10.1016/j.compbiomed.2017.09.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030172410&doi=10.1016%2fj.compbiomed.2017.09.017&partnerID=40&md5=204e849c340ad030994c947b6c9e440d","Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Department of Biomedical Engineering, School of Science and Technology, SUSS University, Singapore; Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Malaysia; Departments of Neuroscience, Neurology, Biomedical Engineering, Biomedical Informatics, and Civil, Environmental, and Geodetic Engineering, The Ohio State University, 470 Hitchcock Hall, 2070 Neil Avenue, Columbus, 43210, OH, United States","Acharya U.R., Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore, Department of Biomedical Engineering, School of Science and Technology, SUSS University, Singapore, Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Malaysia; Oh S.L., Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Hagiwara Y., Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Tan J.H., Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, Singapore; Adeli H., Departments of Neuroscience, Neurology, Biomedical Engineering, Biomedical Informatics, and Civil, Environmental, and Geodetic Engineering, The Ohio State University, 470 Hitchcock Hall, 2070 Neil Avenue, Columbus, 43210, OH, United States","An encephalogram (EEG) is a commonly used ancillary test to aide in the diagnosis of epilepsy. The EEG signal contains information about the electrical activity of the brain. Traditionally, neurologists employ direct visual inspection to identify epileptiform abnormalities. This technique can be time-consuming, limited by technical artifact, provides variable results secondary to reader expertise level, and is limited in identifying abnormalities. Therefore, it is essential to develop a computer-aided diagnosis (CAD) system to automatically distinguish the class of these EEG signals using machine learning techniques. This is the first study to employ the convolutional neural network (CNN) for analysis of EEG signals. In this work, a 13-layer deep convolutional neural network (CNN) algorithm is implemented to detect normal, preictal, and seizure classes. The proposed technique achieved an accuracy, specificity, and sensitivity of 88.67%, 90.00% and 95.00%, respectively. © 2017 Elsevier Ltd","Convolutional neural network; Deep learning; Encephalogram signals; Epilepsy; Seizure","Diagnosis, Computer-Assisted; Electroencephalography; Epilepsy; Female; Humans; Machine Learning; Male; Neural Networks (Computer); Seizures; Signal Processing, Computer-Assisted; Brain; Computer aided diagnosis; Computer aided instruction; Convolution; Deep learning; Neural networks; Neurology; Signal analysis; Computer Aided Diagnosis(CAD); Convolutional neural network; Convolutional Neural Networks (CNN); Deep convolutional neural networks; Electrical activities; Epilepsy; Machine learning techniques; Seizure; Article; artificial neural network; automation; computer aided design; convolutional neural network; diagnostic accuracy; electroencephalography; epilepsy; human; machine learning; priority journal; sensitivity and specificity; artificial neural network; computer assisted diagnosis; epilepsy; female; male; pathophysiology; seizure; signal processing; Deep neural networks","Elsevier Ltd","00104825","","CBMDA","28974302","Article","Scopus","2-s2.0-85030172410"
"Winzeck S.; Hakim A.; McKinley R.; Pinto J.A.A.D.S.R.; Alves V.; Silva C.; Pisov M.; Krivov E.; Belyaev M.; Monteiro M.; Oliveira A.; Choi Y.; Paik M.C.; Kwon Y.; Lee H.; Kim B.J.; Won J.-H.; Islam M.; Ren H.; Robben D.; Suetens P.; Gong E.; Niu Y.; Xu J.; Pauly J.M.; Lucas C.; Heinrich M.P.; Rivera L.C.; Castillo L.S.; Daza L.A.; Beers A.L.; Arbelaezs P.; Maier O.; Chang K.; Brown J.M.; Kalpathy-Cramer J.; Zaharchuk G.; Wiest R.; Reyes M.","Winzeck, Stefan (56613478800); Hakim, Arsany (56024069300); McKinley, Richard (24178652500); Pinto, José A.A.D.S.R. (57204327833); Alves, Victor (7006627528); Silva, Carlos (56325790600); Pisov, Maxim (57200856660); Krivov, Egor (57189328531); Belyaev, Mikhail (57196947665); Monteiro, Miguel (57216931096); Oliveira, Arlindo (7201929537); Choi, Youngwon (57194089667); Paik, Myunghee Cho (7005745962); Kwon, Yongchan (57189761007); Lee, Hanbyul (57196309447); Kim, Beom Joon (56415337700); Won, Joong-Ho (23974997400); Islam, Mobarakol (57200950445); Ren, Hongliang (14030501000); Robben, David (55888315900); Suetens, Paul (23006621700); Gong, Enhao (56046651600); Niu, Yilin (58465420700); Xu, Junshen (57212010605); Pauly, John M. (7101724924); Lucas, Christian (55579267900); Heinrich, Mattias P. (52363917500); Rivera, Luis C. (57200856839); Castillo, Laura S. (57200853498); Daza, Laura A. (57200854916); Beers, Andrew L. (57194495725); Arbelaezs, Pablo (57204320671); Maier, Oskar (55489069300); Chang, Ken (57193440834); Brown, James M. (57202154768); Kalpathy-Cramer, Jayashree (6504761279); Zaharchuk, Greg (6602464023); Wiest, Roland (6603714583); Reyes, Mauricio (16550617900)","56613478800; 56024069300; 24178652500; 57204327833; 7006627528; 56325790600; 57200856660; 57189328531; 57196947665; 57216931096; 7201929537; 57194089667; 7005745962; 57189761007; 57196309447; 56415337700; 23974997400; 57200950445; 14030501000; 55888315900; 23006621700; 56046651600; 58465420700; 57212010605; 7101724924; 55579267900; 52363917500; 57200856839; 57200853498; 57200854916; 57194495725; 57204320671; 55489069300; 57193440834; 57202154768; 6504761279; 6602464023; 6603714583; 16550617900","ISLES 2016 and 2017-benchmarking ischemic stroke lesion outcome prediction based on multispectral MRI","2018","Frontiers in Neurology","118","10.3389/fneur.2018.00679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055195176&doi=10.3389%2ffneur.2018.00679&partnerID=40&md5=c48ea9eb336a4188d868023b3cb46be8","University Division of Anaesthesia, Department of Medicine, University of Cambridge, Cambridge, United Kingdom; Support Center of Advanced Neuroimaging (SCAN), Institute of Diagnostic and Interventional Neuroradiology, University of Bern, Inselspital, Bern University Hospital, Bern, Switzerland; CMEMS-UMinho Research Unit, University of Minho, Braga, Portugal; Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation; Institute for Information Transmission Problems (RAS), Moscow, Russian Federation; Instituto de Engenharia de Sostemas e Computadores Investigacã e Desenvolvimento, Lisbon, Portugal; Department of Statistics, Seoul National University, Seoul, South Korea; Department of Neurology and Cerebrovascular Center, Seoul National University Bundang Hospital, Seongnam, South Korea; Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore; ESAT-PSI, KU Leuven, Leuven, Belgium; Electrical Engineering and Radiology, Stanford University, Stanford, CA, United States; Computer Science, Tsinghua University, Beijing, China; Institute of Medical Informatics, Universität zu Lübeck, Lübeck, Germany; Biomedical Engineering, University of Los Andes, Bogotá, Colombia; Athinoula A. Martinos Center for Biomedical Imaging, Harvard, MA, United States; Department of Radiology, Stanford University, Stanford, CA, United States; Medical Image Analysis, Institute for Surgical Technology and Biomechanics, University of Bern, Bern, Switzerland","Winzeck S., University Division of Anaesthesia, Department of Medicine, University of Cambridge, Cambridge, United Kingdom; Hakim A., Support Center of Advanced Neuroimaging (SCAN), Institute of Diagnostic and Interventional Neuroradiology, University of Bern, Inselspital, Bern University Hospital, Bern, Switzerland; McKinley R., Support Center of Advanced Neuroimaging (SCAN), Institute of Diagnostic and Interventional Neuroradiology, University of Bern, Inselspital, Bern University Hospital, Bern, Switzerland; Pinto J.A.A.D.S.R., CMEMS-UMinho Research Unit, University of Minho, Braga, Portugal; Alves V., CMEMS-UMinho Research Unit, University of Minho, Braga, Portugal; Silva C., CMEMS-UMinho Research Unit, University of Minho, Braga, Portugal; Pisov M., Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation, Institute for Information Transmission Problems (RAS), Moscow, Russian Federation; Krivov E., Institute for Information Transmission Problems (RAS), Moscow, Russian Federation; Belyaev M., Institute for Information Transmission Problems (RAS), Moscow, Russian Federation; Monteiro M., Instituto de Engenharia de Sostemas e Computadores Investigacã e Desenvolvimento, Lisbon, Portugal; Oliveira A., Instituto de Engenharia de Sostemas e Computadores Investigacã e Desenvolvimento, Lisbon, Portugal; Choi Y., Department of Statistics, Seoul National University, Seoul, South Korea; Paik M.C., Department of Statistics, Seoul National University, Seoul, South Korea; Kwon Y., Department of Statistics, Seoul National University, Seoul, South Korea; Lee H., Department of Statistics, Seoul National University, Seoul, South Korea; Kim B.J., Department of Neurology and Cerebrovascular Center, Seoul National University Bundang Hospital, Seongnam, South Korea; Won J.-H., Department of Statistics, Seoul National University, Seoul, South Korea; Islam M., Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore; Ren H., Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore; Robben D., ESAT-PSI, KU Leuven, Leuven, Belgium; Suetens P., ESAT-PSI, KU Leuven, Leuven, Belgium; Gong E., Electrical Engineering and Radiology, Stanford University, Stanford, CA, United States; Niu Y., Computer Science, Tsinghua University, Beijing, China; Xu J., Electrical Engineering and Radiology, Stanford University, Stanford, CA, United States; Pauly J.M., Electrical Engineering and Radiology, Stanford University, Stanford, CA, United States; Lucas C., Institute of Medical Informatics, Universität zu Lübeck, Lübeck, Germany; Heinrich M.P., Institute of Medical Informatics, Universität zu Lübeck, Lübeck, Germany; Rivera L.C., Biomedical Engineering, University of Los Andes, Bogotá, Colombia; Castillo L.S., Biomedical Engineering, University of Los Andes, Bogotá, Colombia; Daza L.A., Biomedical Engineering, University of Los Andes, Bogotá, Colombia; Beers A.L., Athinoula A. Martinos Center for Biomedical Imaging, Harvard, MA, United States; Arbelaezs P., Biomedical Engineering, University of Los Andes, Bogotá, Colombia; Maier O., Institute of Medical Informatics, Universität zu Lübeck, Lübeck, Germany; Chang K., Athinoula A. Martinos Center for Biomedical Imaging, Harvard, MA, United States; Brown J.M., Athinoula A. Martinos Center for Biomedical Imaging, Harvard, MA, United States; Kalpathy-Cramer J., Athinoula A. Martinos Center for Biomedical Imaging, Harvard, MA, United States; Zaharchuk G., Department of Radiology, Stanford University, Stanford, CA, United States; Wiest R., Support Center of Advanced Neuroimaging (SCAN), Institute of Diagnostic and Interventional Neuroradiology, University of Bern, Inselspital, Bern University Hospital, Bern, Switzerland; Reyes M., Medical Image Analysis, Institute for Surgical Technology and Biomechanics, University of Bern, Bern, Switzerland","Performance of models highly depend not only on the used algorithm but also the data set it was applied to. This makes the comparison of newly developed tools to previously published approaches difficult. Either researchers need to implement others' algorithms first, to establish an adequate benchmark on their data, or a direct comparison of new and old techniques is infeasible. The Ischemic Stroke Lesion Segmentation (ISLES) challenge, which has ran now consecutively for 3 years, aims to address this problem of comparability. ISLES 2016 and 2017 focused on lesion outcome prediction after ischemic stroke: By providing a uniformly pre-processed data set, researchers from all over the world could apply their algorithm directly. A total of nine teams participated in ISLES 2015, and 15 teams participated in ISLES 2016. Their performance was evaluated in a fair and transparent way to identify the state-of-the-art among all submissions. Top ranked teams almost always employed deep learning tools, which were predominately convolutional neural networks (CNNs). Despite the great efforts, lesion outcome prediction persists challenging. The annotated data set remains publicly available and new approaches can be compared directly via the online evaluation system, serving as a continuing benchmark (www.isles-challenge.org). © 2007-2018 Frontiers Media S.A. All Rights Reserved.","Benchmarking; Datasets; Deep learning; Machine learning; MRI; Prediction models; Stroke; Stroke outcome","adult; Article; artificial neural network; benchmarking; brain ischemia; clinical decision making; cohort analysis; human; image analysis; learning algorithm; major clinical study; measurement accuracy; neuroimaging; nuclear magnetic resonance imaging; online system; outcome assessment; prediction; young adult","Frontiers Media S.A.","16642295","","","","Article","Scopus","2-s2.0-85055195176"
"Burbrink F.T.; Gehara M.","Burbrink, Frank T. (6603392663); Gehara, Marcelo (55653482800)","6603392663; 55653482800","The biogeography of deep time phylogenetic reticulation","2018","Systematic Biology","47","10.1093/sysbio/syy019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053003403&doi=10.1093%2fsysbio%2fsyy019&partnerID=40&md5=948645d987f9c66fca2db03abaede7d0","Department of Herpetology, American Museum of Natural History, 79th Street at Central Park West, New York, 10024, NY, United States","Burbrink F.T., Department of Herpetology, American Museum of Natural History, 79th Street at Central Park West, New York, 10024, NY, United States; Gehara M., Department of Herpetology, American Museum of Natural History, 79th Street at Central Park West, New York, 10024, NY, United States","Most phylogenies are typically represented as purely bifurcating. However, as genomic data have become more common in phylogenetic studies, it is not unusual to find reticulation among terminal lineages or among internal nodes (deep time reticulation; DTR). In these situations, gene flow must have happened in the same or adjacent geographic areas for these DTRs to have occurred and therefore biogeographic reconstruction should provide similar area estimates for parental nodes, provided extinction or dispersal has not eroded these patterns. We examine the phylogeny of the widely distributed New World kingsnakes (Lampropeltis), determine if DTR is present in this group, and estimate the ancestral area for reticulation. Importantly, we develop a new method that uses coalescent simulations in a machine learning framework to show conclusively that this phylogeny is best represented as reticulating at deeper time. Using joint probabilities of ancestral area reconstructions on the bifurcating parental lineages from the reticulating node, we show that this reticulation likely occurred in northwestern Mexico/southwestern US, and subsequently, led to the diversification of the Mexican kingsnakes. This region has been previously identified as an area important for understanding speciation and secondary contact with gene flow in snakes and other squamates. This research shows that phylogenetic reticulation is common, even in well-studied groups, and that the geographic scope of ancient hybridization is recoverable. © The Author(s) 2018. Published by Oxford University Press, on behalf of the Society of Systematic Biologists. All rights reserved.","Hybridization; Kingsnakes; Mexico; Neural networks","Animals; Colubridae; Evolution, Molecular; Hybridization, Genetic; Mexico; Models, Genetic; Neural Networks (Computer); Phylogeny; Southwestern United States; animal; artificial neural network; biological model; classification; Colubridae; genetics; hybridization; Mexico; molecular evolution; phylogeny; United States","Oxford University Press","10635157","","","29534232","Article","Scopus","2-s2.0-85053003403"
"He Z.; Lyu W.; Qin G.; Liao X.; Xu W.; Wen C.; Zeng H.; Chen W.","He, Zilong (57054536200); Lyu, Wenbing (57188844649); Qin, Genggeng (35785080200); Liao, Xin (35956630300); Xu, Weimin (56451969100); Wen, Chanjuan (56563474200); Zeng, Hui (57193255233); Chen, Weiguo (55568522646)","57054536200; 57188844649; 35785080200; 35956630300; 56451969100; 56563474200; 57193255233; 55568522646","A feasibility study of building up deep learning classification model based on breast digital breast tomosynthesis image texture feature extraction of the simple mass lesions; [基于数字乳腺断层摄影图像纹理特征提取的单纯肿块型病变的深度学习分类模型构建的可行性]","2018","Chinese Journal of Radiology (China)","1","10.3760/cma.j.issn.1005-1201.2018.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063163494&doi=10.3760%2fcma.j.issn.1005-1201.2018.09.004&partnerID=40&md5=3d236dd8f829812553ef4b1d7c83fc77","Department of Radiology, Nanfang Hospital, the Southern Medical University, Guangzhou, 510515, China","He Z., Department of Radiology, Nanfang Hospital, the Southern Medical University, Guangzhou, 510515, China; Lyu W., Department of Radiology, Nanfang Hospital, the Southern Medical University, Guangzhou, 510515, China; Qin G., Department of Radiology, Nanfang Hospital, the Southern Medical University, Guangzhou, 510515, China; Liao X., Department of Radiology, Nanfang Hospital, the Southern Medical University, Guangzhou, 510515, China; Xu W., Department of Radiology, Nanfang Hospital, the Southern Medical University, Guangzhou, 510515, China; Wen C., Department of Radiology, Nanfang Hospital, the Southern Medical University, Guangzhou, 510515, China; Zeng H., Department of Radiology, Nanfang Hospital, the Southern Medical University, Guangzhou, 510515, China; Chen W., Department of Radiology, Nanfang Hospital, the Southern Medical University, Guangzhou, 510515, China","Objective: To evaluate the diagnostic performance of digital breast tomosynthesis (DBT) breast X-ray photography image texture characteristics based deep learning classification model on differentiating malignant masses. Methods: Retrospectively collected 132 cases with simplex breast lesions (89 benign lesions and 43 malignant lesions) which were confirmed by pathology and DBT during January 2016 to December 2016 in Nanfang Hospital. DBT was performed before biopsy and surgery. Image of cranio-caudal view (CC) and medio-lateral oblique (MLO) were captured. The lesion area was segmented to acquire ROI by ITK-SNAP software. Then the processed images were input into MATLAB R2015b to establish a feature model for extracting texture features. The characteristics with high correlation was analyzed from Fisher score and one sample t test. We built up support vector machine (SVM) classification model based on extracted texture and added neural network model (CNN) for deep learning classification model. We randomly assigned collected cases into training group and validation group. The diagnosis of benign and malignant lesions were served as the reference. The efficiency was evaluated by ROC classification model. Result: We extracted 82 texture characteristics from 132 images of leisure (132 images of CC and 132 images of MLO) by establishing deep learning classification model of breast lesions. We randomly chose and combined characteristics from 15 texture characteristics with statistical significance, then differentiated benign and malignant by SVM classification model. After 50 iterations on each combination of characteristics, the average diagnostic efficacy was compared to obtained the one with higher efficacy. Nine of CC and 8 of MLO was selected. The result showed that the sensitivity, specificity, accuracy and area under curve (AUC) of the model to differentiate simplex breast lesions for CC were 0.68, 0.77, 0.74 and 0.74, for MLO were 0.71, 0.71, 0.71 and 0.76. Conclusions: MLO has better diagnostic performance for the diagnosis than CC. The deep learning classification model on breast lesions which was built upon DBT image texture characteristics on MLO could differentiate malignant masses effectively. Copyright © 2018 by the Chinese Medical Association.","Breast neoplasms; Deep learning; Neural network model; Texture feature","Article; breast biopsy; breast lesion; breast surgery; deep learning; digital breast tomosynthesis; feasibility study; feature extraction; human; image segmentation; major clinical study; medical photography; retrospective study; support vector machine; task performance","Chinese Medical Association","10051201","","","","Article","Scopus","2-s2.0-85063163494"
"Li C.; Ren J.; Huang H.; Wang B.; Zhu Y.; Hu H.","Li, Chuanjiang (57204189336); Ren, Jian (57195672184); Huang, Huaiqi (56469929400); Wang, Bin (57190194507); Zhu, Yanfei (56953672800); Hu, Huosheng (7404096825)","57204189336; 57195672184; 56469929400; 57190194507; 56953672800; 7404096825","PCA and deep learning based myoelectric grasping control of a prosthetic hand","2018","BioMedical Engineering Online","51","10.1186/s12938-018-0539-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054930874&doi=10.1186%2fs12938-018-0539-8&partnerID=40&md5=2298955ba43a94449bdd02dbe6c2263c","Shanghai Normal University, The College of Information, Mechanical and Electrical Engineering, Shanghai, 201418, China; EPFL, Neuchâtel, 2002, Switzerland; BFH, Biel, 2502, Switzerland; University of Essex, School of Computer Science and Electronic Engineering, Colchester, CO4 3SQ, United Kingdom","Li C., Shanghai Normal University, The College of Information, Mechanical and Electrical Engineering, Shanghai, 201418, China; Ren J., Shanghai Normal University, The College of Information, Mechanical and Electrical Engineering, Shanghai, 201418, China; Huang H., EPFL, Neuchâtel, 2002, Switzerland, BFH, Biel, 2502, Switzerland; Wang B., Shanghai Normal University, The College of Information, Mechanical and Electrical Engineering, Shanghai, 201418, China; Zhu Y., Shanghai Normal University, The College of Information, Mechanical and Electrical Engineering, Shanghai, 201418, China; Hu H., University of Essex, School of Computer Science and Electronic Engineering, Colchester, CO4 3SQ, United Kingdom","Background: For the functional control of prosthetic hand, it is insufficient to obtain only the motion pattern information. As far as practicality is concerned, the control of the prosthetic hand force is indispensable. The application value of prosthetic hand will be greatly improved if the stable grip of prosthetic hand can be achieved. To address this problem, in this study, a bio-signal control method for grasping control of a prosthetic hand is proposed to improve patient's sense of using prosthetic hand and the thus improving the quality of life. Methods: A MYO gesture control armband is used to collect the surface electromyographic (sEMG) signals from the upper limb. The overlapping sliding window scheme are applied for data segmentation and the correlated features are extracted from each segmented data. Principal component analysis (PCA) methods are then deployed for dimension reduction. Deep neural network is used to generate sEMG-force regression model for force prediction at different levels. The predicted force values are input to a fuzzy controller for the grasping control of a prosthetic hand. A vibration feedback device is used to feed grasping force value back to patient's arm to improve patient's sense of using prosthetic hand and realize accurate grasping. To test the effectiveness of the scheme, 15 able-bodied subjects participated in the experiments. Results: The classification results indicated that 8-channel sEMG applying all four time-domain features, with PCA reduction from 32 to 8 dimensions results in the highest classification accuracy. Based on the experimental results from 15 participants, the average recognition rate is over 95%. On the other hand, from the statistical results of standard deviation, the between-subject variations ranges from 3.58 to 1.25%, proving that the robustness and stability of the proposed approach. Conclusions: The method proposed hereto control grasping power through the patient's own sEMG signal, which achieves a high recognition rate to improve the success rate of grip and increases the sense of operation and also brings the gospel for upper extremity amputation patients. © 2018 The Author(s).","DNN; Fuzzy controller; Grasp control; PCA; Prosthetic hand; SEMG-force; Vibration feedback device","Artificial Limbs; Electromyography; Feasibility Studies; Female; Hand; Hand Strength; Humans; Machine Learning; Male; Muscles; Principal Component Analysis; Biomedical signal processing; Controllers; Deep neural networks; Feedback; Principal component analysis; Prosthetics; Regression analysis; Time domain analysis; Fuzzy controllers; Grasp controls; Prosthetic hands; SEMG-force; Vibration feedback; adult; arm amputation; article; clinical article; comparative effectiveness; controlled study; female; gesture; human; learning; male; nervous system; prediction; principal component analysis; quality of life; vibration; electromyography; feasibility study; hand; hand strength; limb prosthesis; machine learning; muscle; physiology; Quality control","BioMed Central Ltd.","1475925X","","BEOIB","30081927","Article","Scopus","2-s2.0-85054930874"
"Wang W.; Li Y.; Zhang W.-J.; Tian Y.; Qian A.-R.","Wang, Wei (56937562500); Li, Yu (55949866900); Zhang, Wen-Juan (57203869658); Tian, Ye (57201242167); Qian, Ai-Rong (35337620600)","56937562500; 55949866900; 57203869658; 57201242167; 35337620600","Application of deep learning technology in disease diagnosis","2018","Academic Journal of Second Military Medical University","3","10.16781/j.0258-879x.2018.08.0852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053294040&doi=10.16781%2fj.0258-879x.2018.08.0852&partnerID=40&md5=6db0d901d4acb4153fba5938fddf97b8","School of Life Sciences, Northwestern Polytechnical University, Xi’an, 710072, Shaanxi, China","Wang W., School of Life Sciences, Northwestern Polytechnical University, Xi’an, 710072, Shaanxi, China; Li Y., School of Life Sciences, Northwestern Polytechnical University, Xi’an, 710072, Shaanxi, China; Zhang W.-J., School of Life Sciences, Northwestern Polytechnical University, Xi’an, 710072, Shaanxi, China; Tian Y., School of Life Sciences, Northwestern Polytechnical University, Xi’an, 710072, Shaanxi, China; Qian A.-R.","The rapid development of deep learning technology provides new methods and ideas for achieving the goal of assisting doctors in high-precision diagnosis. In this paper, we summarized the principles and characteristics of deep learning models that are commonly used in disease diagnosis, including convolutional neural networks, deep belief network, restricted Boltzmann machine and circulation neural network model. Then we introduced the application of deep learning technology in disease diagnosis of several typical diseases, such as lung cancer, breast cancer, and diabetic retinopathy. Finally, we proposed the future of deep learning considering the limitations of deep learning technology in disease diagnosis. © 2018, Second Military Medical University Press. All rights reserved.","Artificial intelligence; Deep learning; Disease diagnosis; Neural networks","Article; artificial neural network; breast cancer; deep learning technology; diabetic retinopathy; diagnostic procedure; learning; lung cancer","Second Military Medical University Press","0258879X","","DJXUE","","Article","Scopus","2-s2.0-85053294040"
"Kim S.; Choi B.; Lim M.; Kim Y.; Kim H.-D.; Choi S.-J.","Kim, Sungho (57422935100); Choi, Bongsik (56044201500); Lim, Meehyun (57213831448); Kim, Yeamin (57196321651); Kim, Hee-Dong (57218466782); Choi, Sung-Jin (7408120164)","57422935100; 56044201500; 57213831448; 57196321651; 57218466782; 7408120164","Synaptic Device Network Architecture with Feature Extraction for Unsupervised Image Classification","2018","Small","16","10.1002/smll.201800521","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050809585&doi=10.1002%2fsmll.201800521&partnerID=40&md5=9507f6d94abf1ed287b52a1e0019e63a","Department of Electrical Engineering, Sejong University, Seoul, 05006, South Korea; School of Electrical Engineering, Kookmin University, Seoul, 02707, South Korea; Mechatronics R&D Center, Samsung Electronics, Gyonggi-do, 18448, South Korea","Kim S., Department of Electrical Engineering, Sejong University, Seoul, 05006, South Korea; Choi B., School of Electrical Engineering, Kookmin University, Seoul, 02707, South Korea; Lim M., Mechatronics R&D Center, Samsung Electronics, Gyonggi-do, 18448, South Korea; Kim Y., School of Electrical Engineering, Kookmin University, Seoul, 02707, South Korea; Kim H.-D., Department of Electrical Engineering, Sejong University, Seoul, 05006, South Korea; Choi S.-J., School of Electrical Engineering, Kookmin University, Seoul, 02707, South Korea","For the efficient recognition and classification of numerous images, neuroinspired deep learning algorithms have demonstrated their substantial performance. Nevertheless, current deep learning algorithms that are performed on von Neumann machines face significant limitations due to their inherent inefficient energy consumption. Thus, alternative approaches (i.e., neuromorphic systems) are expected to provide more energy-efficient computing units. However, the implementation of the neuromorphic system is still challenging due to the uncertain impacts of synaptic device specifications on system performance. Moreover, only few studies are reported how to implement feature extraction algorithms on the neuromorphic system. Here, a synaptic device network architecture with a feature extraction algorithm inspired by the convolutional neural network is demonstrated. Its pattern recognition efficacy is validated using a device-to-system level simulation. The network can classify handwritten digits at up to a 90% recognition rate despite using fewer synaptic devices than the architecture without feature extraction. © 2018 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","carbon nanotubes; feature extraction; image classification; neuromorphic systems; recognition rates","Carbon nanotubes; Character recognition; Classification (of information); Deep learning; Energy efficiency; Energy utilization; Extraction; Feature extraction; Image classification; Learning algorithms; Neural networks; Pattern recognition systems; Yarn; Convolutional neural network; Device specification; Energy efficient computing; Feature extraction algorithms; Neuromorphic systems; Recognition rates; System level simulation; Unsupervised image classification; Network architecture","Wiley-VCH Verlag","16136810","","SMALB","30009414","Article","Scopus","2-s2.0-85050809585"
"Im H.; Pathania D.; McFarland P.J.; Sohani A.R.; Degani I.; Allen M.; Coble B.; Kilcoyne A.; Hong S.; Rohrer L.; Abramson J.S.; Dryden-Peterson S.; Fexon L.; Pivovarov M.; Chabner B.; Lee H.; Castro C.M.; Weissleder R.","Im, Hyungsoon (57209766429); Pathania, Divya (35485241400); McFarland, Philip J. (57203116010); Sohani, Aliyah R. (26322034700); Degani, Ismail (57203112285); Allen, Matthew (57203112139); Coble, Benjamin (57201730073); Kilcoyne, Aoife (57078300000); Hong, Seonki (37461264400); Rohrer, Lucas (57203116979); Abramson, Jeremy S. (8693159800); Dryden-Peterson, Scott (36116458100); Fexon, Lioubov (30467516500); Pivovarov, Misha (57218590730); Chabner, Bruce (7102637524); Lee, Hakho (35725732800); Castro, Cesar M. (37086975700); Weissleder, Ralph (35452687500)","57209766429; 35485241400; 57203116010; 26322034700; 57203112285; 57203112139; 57201730073; 57078300000; 37461264400; 57203116979; 8693159800; 36116458100; 30467516500; 57218590730; 7102637524; 35725732800; 37086975700; 35452687500","Design and clinical validation of a point-of-care device for the diagnosis of lymphoma via contrast-enhanced microholography and machine learning","2018","Nature Biomedical Engineering","47","10.1038/s41551-018-0265-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050530041&doi=10.1038%2fs41551-018-0265-3&partnerID=40&md5=e9c19f5d047fc559b4a03826e214f15b","Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States; Department of Radiology, Massachusetts General Hospital, Boston, MA, United States; Department of Pathology, Massachusetts General Hospital, Boston, MA, United States; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Engineering and Management, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Health Sciences, Northeastern University, Boston, MA, United States; Massachusetts General Hospital Cancer Center, Boston, MA, United States; Botswana Harvard AIDS Institute, Gaborone, Botswana; Division of Infectious Diseases, Brigham and Women’s Hospital, Boston, MA, United States; Harvard T.H. Chan School of Public Health, Boston, MA, United States; Department of Systems Biology, Harvard Medical School, Boston, MA, United States","Im H., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States, Department of Radiology, Massachusetts General Hospital, Boston, MA, United States; Pathania D., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States; McFarland P.J., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States; Sohani A.R., Department of Pathology, Massachusetts General Hospital, Boston, MA, United States; Degani I., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, United States; Allen M., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States; Coble B., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States, Department of Engineering and Management, Massachusetts Institute of Technology, Cambridge, MA, United States; Kilcoyne A., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States, Department of Radiology, Massachusetts General Hospital, Boston, MA, United States; Hong S., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States; Rohrer L., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States, Department of Health Sciences, Northeastern University, Boston, MA, United States; Abramson J.S., Massachusetts General Hospital Cancer Center, Boston, MA, United States; Dryden-Peterson S., Botswana Harvard AIDS Institute, Gaborone, Botswana, Division of Infectious Diseases, Brigham and Women’s Hospital, Boston, MA, United States, Harvard T.H. Chan School of Public Health, Boston, MA, United States; Fexon L., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States; Pivovarov M., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States, Department of Radiology, Massachusetts General Hospital, Boston, MA, United States; Chabner B., Massachusetts General Hospital Cancer Center, Boston, MA, United States; Lee H., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States, Department of Radiology, Massachusetts General Hospital, Boston, MA, United States; Castro C.M., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States, Massachusetts General Hospital Cancer Center, Boston, MA, United States; Weissleder R., Center for Systems Biology, Massachusetts General Hospital, Boston, MA, United States, Department of Radiology, Massachusetts General Hospital, Boston, MA, United States, Department of Systems Biology, Harvard Medical School, Boston, MA, United States","The identification of patients with aggressive cancer who require immediate therapy is a health challenge in low- and middle-income countries. Limited pathology resources, high healthcare costs and large caseloads call for the development of advanced stand-alone diagnostics. Here, we report and validate an automated, low-cost point-of-care device for the molecular diagnosis of aggressive lymphomas. The device uses contrast-enhanced microholography and a deep learning algorithm to directly analyse percutaneously obtained fine-needle aspirates. We show the feasibility and high accuracy of the device in cells, as well as the prospective validation of the results in 40 patients clinically referred for image-guided aspiration of nodal mass lesions suspicious of lymphoma. Automated analysis of human samples with the portable device should allow for the accurate classification of patients with benign and malignant adenopathy. © 2018, The Author(s).","","Deep learning; Learning algorithms; Molecular biology; Oncology; Patient treatment; Automated analysis; Clinical validations; Contrast-enhanced; Health care costs; High-accuracy; Low and middle income countries; Molecular diagnosis; Portable device; Article; B cell lymphoma; cancer diagnosis; cell sizing (measurement); clinical article; contrast enhanced micrography; contrast enhancement; controlled study; diagnostic accuracy; diagnostic test accuracy study; equipment design; false negative result; feasibility study; flow cytometry; follicular lymphoma; freeze drying; histopathology; holography; human; image reconstruction; learning algorithm; lymphoma; mantle cell lymphoma; medical photography; point of care testing; priority journal; prospective study; reproducibility; sensitivity and specificity; validation process; validation study; whole body imaging; Diagnosis","Nature Publishing Group","2157846X","","","","Article","Scopus","2-s2.0-85050530041"
"Chen G.; Tsoi A.; Xu H.; Zheng W.J.","Chen, Guocai (22033875500); Tsoi, Alex (57203411180); Xu, Hua (55493876700); Zheng, W. Jim (18036326600)","22033875500; 57203411180; 55493876700; 18036326600","Predict effective drug combination by deep belief network and ontology fingerprints","2018","Journal of Biomedical Informatics","51","10.1016/j.jbi.2018.07.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051631748&doi=10.1016%2fj.jbi.2018.07.024&partnerID=40&md5=d50ed9b0a5ce83a43371cd7093d89beb","School of Biomedical Informatics, University of Texas Health Science Center, Houston, TX, United States; Department of Dermatology and Biostatistics, University of Michigan, Ann Arbor, MI, United States","Chen G., School of Biomedical Informatics, University of Texas Health Science Center, Houston, TX, United States; Tsoi A., Department of Dermatology and Biostatistics, University of Michigan, Ann Arbor, MI, United States; Xu H., School of Biomedical Informatics, University of Texas Health Science Center, Houston, TX, United States; Zheng W.J., School of Biomedical Informatics, University of Texas Health Science Center, Houston, TX, United States","The synergistic effect of drug combination is one of the most desirable properties for treating cancer. However, systematically predicting effective drug combination is a significant challenge. We report here a novel method based on deep belief network to predict drug synergy from gene expression, pathway and the Ontology Fingerprints—a literature derived ontological profile of genes. Using data sets provided by 2015 DREAM competition, our analysis shows that this integrative method outperforms published results from the DREAM website for 4999 drug pairs, demonstrating the feasibility of predicting drug synergy from literature and the –omics data using advanced artificial intelligence approach. © 2018 Elsevier Inc.","Deep belief network; Drug combination; Ontology fingerprint","Antineoplastic Combined Chemotherapy Protocols; Cell Line, Tumor; Computational Biology; Databases, Pharmaceutical; Deep Learning; Drug Combinations; Drug Synergism; Gene Expression Profiling; Gene Ontology; Gene Regulatory Networks; Humans; Neoplasms; Forecasting; Gene expression; antineoplastic agent; Deep belief networks; Drug combinations; Ontological profiles; Synergistic effect; Article; artificial neural network; cell line; controlled study; deep belief network; drug potentiation; gene expression; ontology; ontology fingerprint; prediction; priority journal; restricted Boltzmann machine; biology; drug combination; drug database; drug potentiation; gene expression profiling; gene ontology; gene regulatory network; genetics; human; neoplasm; tumor cell line; Ontology","Academic Press Inc.","15320464","","JBIOB","30081101","Article","Scopus","2-s2.0-85051631748"
"Preuer K.; Renz P.; Unterthiner T.; Hochreiter S.; Klambauer G.","Preuer, Kristina (57202071945); Renz, Philipp (57203762289); Unterthiner, Thomas (37078167900); Hochreiter, Sepp (6602873810); Klambauer, Günter (6507603426)","57202071945; 57203762289; 37078167900; 6602873810; 6507603426","Fréchet ChemNet Distance: A Metric for Generative Models for Molecules in Drug Discovery","2018","Journal of Chemical Information and Modeling","169","10.1021/acs.jcim.8b00234","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052894544&doi=10.1021%2facs.jcim.8b00234&partnerID=40&md5=5bc9ec715a73cddd4b3f7728c0e09b49","LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria","Preuer K., LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria; Renz P., LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria; Unterthiner T., LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria; Hochreiter S., LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria; Klambauer G., LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria","The new wave of successful generative models in machine learning has increased the interest in deep learning driven de novo drug design. However, method comparison is difficult because of various flaws of the currently employed evaluation metrics. We propose an evaluation metric for generative models called Fréchet ChemNet distance (FCD). The advantage of the FCD over previous metrics is that it can detect whether generated molecules are diverse and have similar chemical and biological properties as real molecules. © 2018 American Chemical Society.","","Computer Simulation; Databases, Factual; Deep Learning; Drug Discovery; Models, Molecular; Software; Deep learning; Outsourcing; Chemical and biologicals; Drug Design; Drug discovery; Evaluation metrics; Generative model; Method comparison; computer simulation; drug development; factual database; molecular model; software; Molecules","American Chemical Society","15499596","","JCISD","30118593","Article","Scopus","2-s2.0-85052894544"
"Peñaranda F.; Naranjo V.; Lloyd G.R.; Kastl L.; Kemper B.; Schnekenburger J.; Nallala J.; Stone N.","Peñaranda, Francisco (57192912843); Naranjo, Valery (55208614400); Lloyd, Gavin R. (8981281100); Kastl, Lena (57192078011); Kemper, Björn (7102821674); Schnekenburger, Jürgen (7004687491); Nallala, Jayakrupakar (54682099200); Stone, Nicholas (7202511172)","57192912843; 55208614400; 8981281100; 57192078011; 7102821674; 7004687491; 54682099200; 7202511172","Discrimination of skin cancer cells using Fourier transform infrared spectroscopy","2018","Computers in Biology and Medicine","10","10.1016/j.compbiomed.2018.06.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049300674&doi=10.1016%2fj.compbiomed.2018.06.023&partnerID=40&md5=9a93df310c3c7d7722fd978c5f698e15","Instituto de Investigación e Innovación en Bioingeniería (I3B), Universitat Politècnica de València, Camino de Vera s/n, Valencia, 46022, Spain; Biophotonics Research Unit, Gloucestershire Hospitals NHS Foundation Trust, Gloucester, United Kingdom; Biomedical Technology Center, University of Münster, Münster, Germany; Biomedical Physics, School of Physics, University of Exeter, Exeter, United Kingdom; Phenome Centre Birmingham, School of Biosciences, University of Birmingham, Birmingham, United Kingdom","Peñaranda F., Instituto de Investigación e Innovación en Bioingeniería (I3B), Universitat Politècnica de València, Camino de Vera s/n, Valencia, 46022, Spain; Naranjo V., Instituto de Investigación e Innovación en Bioingeniería (I3B), Universitat Politècnica de València, Camino de Vera s/n, Valencia, 46022, Spain; Lloyd G.R., Biophotonics Research Unit, Gloucestershire Hospitals NHS Foundation Trust, Gloucester, United Kingdom, Phenome Centre Birmingham, School of Biosciences, University of Birmingham, Birmingham, United Kingdom; Kastl L., Biomedical Technology Center, University of Münster, Münster, Germany; Kemper B., Biomedical Technology Center, University of Münster, Münster, Germany; Schnekenburger J., Biomedical Technology Center, University of Münster, Münster, Germany; Nallala J., Biomedical Physics, School of Physics, University of Exeter, Exeter, United Kingdom; Stone N., Biomedical Physics, School of Physics, University of Exeter, Exeter, United Kingdom","Fourier transform infrared (FTIR) spectroscopy is a highly versatile tool for cell and tissue analysis. Modern commercial FTIR microspectroscopes allow the acquisition of good-quality hyperspectral images from cytopathological samples within relatively short times. This study aims at assessing the abilities of FTIR spectra to discriminate different types of cultured skin cell lines by different computer analysis technologies. In particular, 22700 single skin cells, belonging to two non-tumoral and two tumoral cell lines, were analysed. These cells were prepared in three different batches that included each cell type. Different spectral preprocessing and classification strategies were considered, including the current standard approaches to reduce Mie scattering artefacts. Special care was taken for the optimisation, training and evaluation of the learning models in order to avoid possible overfitting. Excellent classification performance (balanced accuracy between 0.85 and 0.95) was achieved when the algorithms were trained and tested with the cells from the same batch. When cells from different batches were used for training and testing the balanced accuracy reached values between 0.35 and 0.6, demonstrating the strong influence of sample preparation on the results and comparability of cell FTIR spectra. A deep study of the most optimistic results was performed in order to identify perturbations that influenced the final classification. © 2018 Elsevier Ltd","Cancer diagnosis; Cytopathology; Fourier transform infrared spectroscopy; Machine learning; Multivariate analysis","Algorithms; Animals; Cell Line, Tumor; Humans; Mice; NIH 3T3 Cells; Signal Processing, Computer-Assisted; Skin; Skin Neoplasms; Spectroscopy, Fourier Transform Infrared; Cell culture; Cells; Diagnosis; Diseases; Learning systems; Multivariant analysis; Spectrum analysis; Cancer diagnosis; Classification performance; Computer analysis; Cytopathology; Multi variate analysis; Sample preparation; Spectral preprocessing; Training and testing; A-375 cell line; animal cell; Article; cell structure; computer analysis; data analysis; Fourier transform infrared spectroscopy; HaCat cell line; human; human cell; mouse; NIH 3T3 cell line; nonhuman; principal component analysis; priority journal; SK-MEL-28 cell line; skin cancer cell line; statistics; algorithm; animal; classification; infrared spectroscopy; pathology; signal processing; skin; skin tumor; tumor cell line; Fourier transform infrared spectroscopy","Elsevier Ltd","00104825","","CBMDA","29975855","Article","Scopus","2-s2.0-85049300674"
"Zhang K.; Wu J.; Chen H.; Lyu P.","Zhang, Kailai (57203098345); Wu, Ji (55714034400); Chen, Hu (55976396000); Lyu, Peijun (56657293600)","57203098345; 55714034400; 55976396000; 56657293600","An effective teeth recognition method using label tree with cascade network structure","2018","Computerized Medical Imaging and Graphics","71","10.1016/j.compmedimag.2018.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050509806&doi=10.1016%2fj.compmedimag.2018.07.001&partnerID=40&md5=1c9961f058fb1fd9db09f4b87f5e4019","Department of Electronic Engineering, Tsinghua University, Beijing, China; Center of Digital Dentistry, Peking University School and Hospital of Stomatology & National Engineering Laboratory for Digital and Material Technology of Stomatology, Beijing, China","Zhang K., Department of Electronic Engineering, Tsinghua University, Beijing, China; Wu J., Department of Electronic Engineering, Tsinghua University, Beijing, China; Chen H., Center of Digital Dentistry, Peking University School and Hospital of Stomatology & National Engineering Laboratory for Digital and Material Technology of Stomatology, Beijing, China; Lyu P., Center of Digital Dentistry, Peking University School and Hospital of Stomatology & National Engineering Laboratory for Digital and Material Technology of Stomatology, Beijing, China","In this article, we apply the deep learning technique to medical field for the teeth detection and classification of dental periapical radiographs, which is important for the medical curing and postmortem identification. We detect teeth in an input X-ray image and distinguish them from different position. An adult usually has 32 teeth, and some of them are similar while others have very different shape. So there are 32 teeth position for us to recognize, which is a challenging task. Convolutional neural network is a popular method to do multi-class detection and classification, but it needs a lot of training data to get a good result if used directly. The lack of data is a common case in medical field due to patients’ privacy. In this work, limited to the available data, we propose a new method using label tree to give each tooth several labels and decompose the task, which can deal with the lack of data. Then use cascade network structure to do automatic identification on 32 teeth position, which uses several convolutional neural network as its basic module. Meanwhile, several key strategies are utilized to improve the detection and classification performance. Our method can deal with many complex cases such as X-ray images with tooth loss, decayed tooth and filled tooth, which frequently appear on patients. The experiments on our dataset show: for small training dataset, compared to the precision and recall by training a 33-classes (32 teeth and background) state-of-the-art convolutional neural network directly, the proposed approach reaches a high precision and recall of 95.8% and 96.1% in total, which is a big improvement in such a complex task. © 2018 Elsevier Ltd","Cascade structure; Convolutional neural network; Label tree; Teeth recognition","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Radiography, Dental; Tooth; Automation; Complex networks; Convolution; Deep learning; Forestry; Neural networks; Trees (mathematics); Automatic identification; Cascade structures; Classification performance; Convolutional neural network; Different shapes; Learning techniques; Precision and recall; Teeth recognition; anodontia; Article; automation; controlled study; convolutional neural network; human; image processing; intermethod comparison; machine learning; molar tooth; premolar tooth; priority journal; tooth; tooth radiography; algorithm; artificial neural network; diagnostic imaging; tooth; Classification (of information)","Elsevier Ltd","08956111","","CMIGE","30056291","Article","Scopus","2-s2.0-85050509806"
"Ramraj S.; Saranya S.; Yashwant K.","Ramraj, S. (57204395934); Saranya, S. (57218605812); Yashwant, K. (57204396284)","57204395934; 57218605812; 57204396284","Comparative study of bagging, boosting and convolutional neural network for text classification","2018","Indian Journal of Public Health Research and Development","2","10.5958/0976-5506.2018.01138.5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055434965&doi=10.5958%2f0976-5506.2018.01138.5&partnerID=40&md5=7a37ed01d12e5f303c86344f71a6d653","Dept. of Software Engineering, SRM Institute Of Technology, Chennai, India","Ramraj S., Dept. of Software Engineering, SRM Institute Of Technology, Chennai, India; Saranya S., Dept. of Software Engineering, SRM Institute Of Technology, Chennai, India; Yashwant K., Dept. of Software Engineering, SRM Institute Of Technology, Chennai, India","Text classification is applied in various domains such as identifying malicious comments in a public forum, classifying documents according to its category, etc. Application of machine learning for the purpose of text classification is very successful in recent years, especially the algorithms based on bagging and boosting. Convolutional neural network (CNN), is one of the successful deep learning algorithm applied in many image classification problems. In this paper we evaluated the performance of tree based machine learning algorithms such as Random Forest, XGBoost along with SVM and CNN for text classification. Upon training we found that in terms of F1 score XGBoost was giving the best accuracy in long text classification while CNN were giving the best accuracy in short text classification. © 2018, Indian Journal of Public Health Research and Development. All rights reserved.","Convolutional neural networks; Decision tree ensemble; Deep learning; Ensemble; Feature extraction; Machine learning; Support vector machines; XGBoost","article; comparative study; controlled study; decision tree; feature extraction; machine learning; random forest; support vector machine","Institute of Medico-Legal Publications","09760245","","","","Article","Scopus","2-s2.0-85055434965"
"Yates E.J.; Yates L.C.; Harvey H.","Yates, E.J. (57202404170); Yates, L.C. (57202406360); Harvey, H. (57193520215)","57202404170; 57202406360; 57193520215","Machine learning “red dot”: open-source, cloud, deep convolutional neural networks in chest radiograph binary normality classification","2018","Clinical Radiology","44","10.1016/j.crad.2018.05.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048220227&doi=10.1016%2fj.crad.2018.05.015&partnerID=40&md5=88fed5ef751ad1e1e8b36b136d7c1fb9","Foundation Doctor, West Midlands, England, United Kingdom; Kheiron Medical Technologies, Rocketspace, 40 Islington High St, London, N1 8EQ, United Kingdom","Yates E.J., Foundation Doctor, West Midlands, England, United Kingdom; Yates L.C., Foundation Doctor, West Midlands, England, United Kingdom; Harvey H., Kheiron Medical Technologies, Rocketspace, 40 Islington High St, London, N1 8EQ, United Kingdom","Aim: To develop a machine learning-based model for the binary classification of chest radiography abnormalities, to serve as a retrospective tool in guiding clinician reporting prioritisation. Materials and methods: The open-source machine learning library, Tensorflow, was used to retrain a final layer of the deep convolutional neural network, Inception, to perform binary normality classification on two, anonymised, public image datasets. Re-training was performed on 47,644 images using commodity hardware, with validation testing on 5,505 previously unseen radiographs. Confusion matrix analysis was performed to derive diagnostic utility metrics. Results: A final model accuracy of 94.6% (95% confidence interval [CI]: 94.3–94.7%) based on an unseen testing subset (n=5,505) was obtained, yielding a sensitivity of 94.6% (95% CI: 94.4–94.7%) and a specificity of 93.4% (95% CI: 87.2–96.9%) with a positive predictive value (PPV) of 99.8% (95% CI: 99.7–99.9%) and area under the curve (AUC) of 0.98 (95% CI: 0.97–0.99). Conclusion: This study demonstrates the application of a machine learning-based approach to classify chest radiographs as normal or abnormal. Its application to real-world datasets may be warranted in optimising clinician workload. © 2018 The Royal College of Radiologists","","Cloud Computing; Datasets as Topic; Diagnosis, Differential; Humans; Machine Learning; Neural Networks (Computer); Radiography, Thoracic; Sensitivity and Specificity; Article; binary normality classification; classification algorithm; cloud computing; deep convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; human; image analysis; image processing; machine learning; metadata; predictive value; priority journal; receiver operating characteristic; sensitivity and specificity; thorax radiography; transfer of learning; artificial neural network; classification; differential diagnosis; information processing; thorax radiography","W.B. Saunders Ltd","00099260","","CLRAA","29898829","Article","Scopus","2-s2.0-85048220227"
"Tomori S.; Kadoya N.; Takayama Y.; Kajikawa T.; Shima K.; Narazaki K.; Jingu K.","Tomori, Seiji (57203523959); Kadoya, Noriyuki (34876892300); Takayama, Yoshiki (57194561018); Kajikawa, Tomohiro (57201979572); Shima, Katsumi (35460976200); Narazaki, Kakutarou (14008718800); Jingu, Keiichi (8834066000)","57203523959; 34876892300; 57194561018; 57201979572; 35460976200; 14008718800; 8834066000","A deep learning-based prediction model for gamma evaluation in patient-specific quality assurance","2018","Medical Physics","86","10.1002/mp.13112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052382284&doi=10.1002%2fmp.13112&partnerID=40&md5=35ea919e151445c4b211caebbaed0533","Department of Radiology, National Hospital Organization Sendai Medical Center, Sendai, 983-8520, Miyagi, Japan; Department of Radiation Oncology, Tohoku University Graduate School of Medicine, Sendai, 980-8574, Miyagi, Japan; Department of Radiology, National Hospital Organization Hakodate National Hospital, Hakodate, 041-8512, Hokkaido, Japan","Tomori S., Department of Radiology, National Hospital Organization Sendai Medical Center, Sendai, 983-8520, Miyagi, Japan, Department of Radiation Oncology, Tohoku University Graduate School of Medicine, Sendai, 980-8574, Miyagi, Japan; Kadoya N., Department of Radiation Oncology, Tohoku University Graduate School of Medicine, Sendai, 980-8574, Miyagi, Japan; Takayama Y., Department of Radiation Oncology, Tohoku University Graduate School of Medicine, Sendai, 980-8574, Miyagi, Japan; Kajikawa T., Department of Radiation Oncology, Tohoku University Graduate School of Medicine, Sendai, 980-8574, Miyagi, Japan; Shima K., Department of Radiology, National Hospital Organization Hakodate National Hospital, Hakodate, 041-8512, Hokkaido, Japan; Narazaki K., Department of Radiology, National Hospital Organization Sendai Medical Center, Sendai, 983-8520, Miyagi, Japan; Jingu K., Department of Radiation Oncology, Tohoku University Graduate School of Medicine, Sendai, 980-8574, Miyagi, Japan","Purpose: Patient-specific quality assurance (QA) measurement is conducted to confirm the accuracy of dose delivery. However, measurement is time-consuming and places a heavy workload on the medical physicists and radiological technologists. In this study, we proposed a prediction model for gamma evaluation, based on deep learning. We applied the model to a QA measurement dataset of prostate cancer cases to evaluate its practicality. Methods: Sixty pretreatment verification plans from prostate cancer patients treated using intensity modulated radiation therapy were collected. Fifteen-layer convolutional neural networks (CNN) were developed to learn the sagittal planar dose distributions from a RT-3000 QA phantom (R-TECH.INC., Tokyo, Japan). The percentage gamma passing rate (GPR) was measured using GAFCHROMIC EBT3 film (Ashland Specialty Ingredients, Covington, USA). The input training data also included the volume of the PTV (planning target volume), rectum, and overlapping region, measured in cm3, and the monitor unit values for each field. The network produced predicted GPR values at four criteria: 2%(global)/2 mm, 3%(global)/2 mm, 2%(global)/3 mm, and 3%(global)/3 mm. Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, was used for learning and for optimizing the CNN-based model. Fivefold cross-validation was applied to validate the performance of the proposed method. Forty cases were used for training and validation set in fivefold cross-validation, and the remaining 20 cases were used for the test set. The predicted and measured GPR values were compared. Results: A linear relationship was found between the measured and predicted values, for each of the four criteria. Spearman rank correlation coefficients in validation set between measured and predicted GPR values at four criteria were 0.73 at 2%/2 mm, 0.72 at 3%/2 mm, 0.74 at 2%/3 mm, and 0.65 at 3%/3 mm, respectively (P < 0.01). The Spearman rank correlation coefficients in the test set were 0.62 (P < 0.01) at 2%/2 mm, 0.56 (P < 0.01) at 3%/2 mm, 0.51 (P = 0.02) at 2%/3 mm, and 0.32 (P = 0.16) at 3%/3 mm. These results demonstrated a strong or moderate correlation between the predicted and measured values. Conclusions: We developed a CNN-based prediction model for patient-specific QA of dose distribution in prostate treatment. Our results suggest that deep learning may provide a useful prediction model for gamma evaluation of patient-specific QA in prostate treatment planning. © 2018 American Association of Physicists in Medicine","convolutional neural network; deep learning; gamma evaluation; patient QA; radiotherapy","Convolution; Deep learning; Diseases; Multilayer neural networks; Network layers; Patient monitoring; Quality control; Radiotherapy; Stochastic models; Stochastic systems; Urology; Convolutional neural network; Cross validation; Deep learning; Dose distributions; Gamma evaluation; Patient quality assurance; Patient specific; Prediction modelling; Prostate cancers; Validation sets; Article; cancer patient; cancer radiotherapy; comparative study; convolutional neural network; deep learning; feasibility study; film dosimetry; gamma passing rate; gamma radiation; human; intensity modulated radiation therapy; machine learning; major clinical study; male; measurement accuracy; planning target volume; prostate cancer; quality control; radiation dose distribution; radiological parameters; treatment planning; Quality assurance","John Wiley and Sons Ltd","00942405","","MPHYA","","Article","Scopus","2-s2.0-85052382284"
"Ahmed H.M.; Mahmoud H.H.","Ahmed, Hanaa Mohsin (57203240193); Mahmoud, Halah Hasan (57216248938)","57203240193; 57216248938","Effect of successive convolution layers to detect gender","2018","Iraqi Journal of Science","4","10.24996/IJS.2018.59.3C.17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086278706&doi=10.24996%2fIJS.2018.59.3C.17&partnerID=40&md5=d96d2c1385d9f46a6c3a21c53f54d0b5","Department of Computers Science, University of Technology, Baghdad, Iraq; Computer Center, University of Baghdad, Baghdad, Iraq","Ahmed H.M., Department of Computers Science, University of Technology, Baghdad, Iraq; Mahmoud H.H., Computer Center, University of Baghdad, Baghdad, Iraq","Image classification can be defined as one of the most important tasks in the area of machine learning. Recently, deep neural networks, especially deep convolution networks, have participated greatly in end-to-end learning which reduce need for human designed features in the image recognition like Convolution Neural Network. It is offers the computation models which are made up of several processing layers for learning data representations with several abstraction levels. In this work, a pre-trained deep CNN is utilized according to some parameters like filter size, no of convolution, pooling, fully connected and type of activation function which includes 300 images for training and predict 100 image gender using probability measures. Results in Classification and precision accuracy equal to 0.68 and 0.3225 respectively. © 2018 University of Baghdad-College of Science. All rights reserved.","Convolution Neural Network; Deep Learning; Detection; Models; Probability","","University of Baghdad-College of Science","00672904","","","","Article","Scopus","2-s2.0-85086278706"
"Doucette W.T.; Dwiel L.; Boyce J.E.; Simon A.A.; Khokhar J.Y.; Green A.I.","Doucette, Wilder T. (25822476100); Dwiel, Lucas (56096054800); Boyce, Jared E. (57204201352); Simon, Amanda A. (57204201118); Khokhar, Jibran Y. (26423044500); Green, Alan I. (56680142600)","25822476100; 56096054800; 57204201352; 57204201118; 26423044500; 56680142600","Machine learning based classification of deep brain stimulation outcomes in a rat model of binge eating using ventral striatal oscillations","2018","Frontiers in Psychiatry","7","10.3389/fpsyt.2018.00336","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054930986&doi=10.3389%2ffpsyt.2018.00336&partnerID=40&md5=2ae2c59abc8e55d124dce1e3128f687a","Department of Psychiatry, Geisel School of Medicine at Dartmouth, Hanover, NH, United States; The Dartmouth Clinical and Translational Science Institute, Dartmouth College, Hanover, NH, United States; Department of Psychological and Brain Sciences, Hanover, NH, United States; Department of Molecular and Systems Biology, Geisel School of Medicine at Dartmouth, Hanover, NH, United States; Department of Biomedical Sciences, University of Guelph, Guelph, ON, Canada","Doucette W.T., Department of Psychiatry, Geisel School of Medicine at Dartmouth, Hanover, NH, United States, The Dartmouth Clinical and Translational Science Institute, Dartmouth College, Hanover, NH, United States; Dwiel L., Department of Psychiatry, Geisel School of Medicine at Dartmouth, Hanover, NH, United States; Boyce J.E., Department of Psychological and Brain Sciences, Hanover, NH, United States; Simon A.A., Department of Psychological and Brain Sciences, Hanover, NH, United States; Khokhar J.Y., Department of Psychiatry, Geisel School of Medicine at Dartmouth, Hanover, NH, United States, Department of Molecular and Systems Biology, Geisel School of Medicine at Dartmouth, Hanover, NH, United States, Department of Biomedical Sciences, University of Guelph, Guelph, ON, Canada; Green A.I., Department of Psychiatry, Geisel School of Medicine at Dartmouth, Hanover, NH, United States, The Dartmouth Clinical and Translational Science Institute, Dartmouth College, Hanover, NH, United States, Department of Molecular and Systems Biology, Geisel School of Medicine at Dartmouth, Hanover, NH, United States","Neuromodulation-based interventions continue to be evaluated across an array of appetitive disorders but broader implementation of these approaches remains limited due to variable treatment outcomes. We hypothesize that individual variation in treatment outcomes may be linked to differences in the networks underlying these disorders. Here, Sprague-Dawley rats received deep brain stimulation separately within each nucleus accumbens (NAc) sub-region (core and shell) using a within-animal crossover design in a rat model of binge eating. Significant reductions in binge size were observed with stimulation of either target but with significant variation in effectiveness across individuals. When features of local field potentials (LFPs) recorded from the NAc were used to classify the pre-defined stimulation outcomes (response or non-response) from each rat using a machine-learning approach (lasso), stimulation outcomes could be classified with greater accuracy than expected by chance (effect sizes: core = 1.13, shell = 1.05). Further, these LFP features could be used to identify the best stimulation target for each animal (core vs. shell) with an effect size = 0.96. These data suggest that individual differences in underlying network activity may relate to the variable outcomes of circuit based interventions, and measures of network activity could have the potential to individually guide the selection of an optimal stimulation target to improve overall treatment response rates. © 2018 Doucette, Dwiel, Boyce, Simon, Khokhar and Green.","Binge eating; Deep brain stimulation (DBS); Local field potential (LFP); Machine learning applied to neuroscience; Nucleus accumbens","accuracy; animal experiment; animal model; animal tissue; Article; binge eating disorder; brain depth stimulation; brain region; controlled study; delta rhythm; effect size; local field potential; machine learning; male; measurement accuracy; nerve cell network; neuromodulation; nonhuman; nucleus accumbens core; nucleus accumbens shell; oscillation; outcome assessment; place preference; rat; Sprague Dawley rat; therapy effect; treatment outcome; treatment response; ventral striatum","Frontiers Media S.A.","16640640","","","","Article","Scopus","2-s2.0-85054930986"
"Zhao L.","Zhao, Liang (57211351625)","57211351625","Application of deep learning in medical imaging: Hope or trap?","2018","Academic Journal of Second Military Medical University","1","10.16781/j.0258-879x.2018.08.0859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053318107&doi=10.16781%2fj.0258-879x.2018.08.0859&partnerID=40&md5=cea25ef9eb6298b29a8084091f699605","Digital Medicine Research Center of Fudan University, Shanghai Medical Image Processing and Digital Diagnosis Key Laboratory, Shanghai, 201203, China","Zhao L., Digital Medicine Research Center of Fudan University, Shanghai Medical Image Processing and Digital Diagnosis Key Laboratory, Shanghai, 201203, China","Medical imaging technology plays an important role in the detection, diagnosis and treatment of diseases. Due to the instability of human expert experience, machine learning technology is expected to assist researchers and doctors to improve the accuracy of imaging diagnosis and treatment and reduce the imbalance of medical resources. In this paper, we systematically summarized the methods of deep learning technology, introduced the application of deep learning in medical imaging, and discussed the limitations of deep learning technology in medical imaging. © 2018, Second Military Medical University Press. All rights reserved.","Artificial intelligence; Big data; Deep learning; Medical imaging","Article; artificial intelligence; diagnostic accuracy; diagnostic imaging; diagnostic procedure; human; learning; machine learning","Second Military Medical University Press","0258879X","","DJXUE","","Article","Scopus","2-s2.0-85053318107"
"Islam M.M.; Tian Y.; Cheng Y.; Wang Y.; Hu P.","Islam, Md. Mohaiminul (57214493835); Tian, Ye (57198239600); Cheng, Yan (57188871718); Wang, Yang (56233737200); Hu, Pingzhao (8957120500)","57214493835; 57198239600; 57188871718; 56233737200; 8957120500","A deep neural network based regression model for triglyceride concentrations prediction using epigenome-wide DNA methylation profiles 06 Biological Sciences 0604 Genetics","2018","BMC Proceedings","6","10.1186/s12919-018-0121-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053418331&doi=10.1186%2fs12919-018-0121-1&partnerID=40&md5=2a6c79e28442d881801307799e72d983","Department of Biochemistry and Medical Genetics, University of Manitoba, 745 Bannatyne Avenue, Winnipeg, R3E 0J9, MB, Canada; Department of Electrical and Computer Engineering, University of Manitoba, 66 Chancellors Cir, Winnipeg, R3T 2N2, MB, Canada; Department of Computer Science, University of Manitoba, 66 Chancellors Cir, Winnipeg, R3T 2N2, MB, Canada; George and Fay Yee Centre for Healthcare Innovation, University of Manitoba, 753 McDermot Avenue, Winnipeg, R3E 0T6, MB, Canada; Experimental Center, Northwest University for Nationalities, Chenggua, Lanzhou, Gansu, 730030, China","Islam M.M., Department of Biochemistry and Medical Genetics, University of Manitoba, 745 Bannatyne Avenue, Winnipeg, R3E 0J9, MB, Canada, Department of Computer Science, University of Manitoba, 66 Chancellors Cir, Winnipeg, R3T 2N2, MB, Canada; Tian Y., Department of Biochemistry and Medical Genetics, University of Manitoba, 745 Bannatyne Avenue, Winnipeg, R3E 0J9, MB, Canada, Department of Electrical and Computer Engineering, University of Manitoba, 66 Chancellors Cir, Winnipeg, R3T 2N2, MB, Canada; Cheng Y., Department of Biochemistry and Medical Genetics, University of Manitoba, 745 Bannatyne Avenue, Winnipeg, R3E 0J9, MB, Canada, Experimental Center, Northwest University for Nationalities, Chenggua, Lanzhou, Gansu, 730030, China; Wang Y., Department of Computer Science, University of Manitoba, 66 Chancellors Cir, Winnipeg, R3T 2N2, MB, Canada; Hu P., Department of Biochemistry and Medical Genetics, University of Manitoba, 745 Bannatyne Avenue, Winnipeg, R3E 0J9, MB, Canada, Department of Electrical and Computer Engineering, University of Manitoba, 66 Chancellors Cir, Winnipeg, R3T 2N2, MB, Canada, Department of Computer Science, University of Manitoba, 66 Chancellors Cir, Winnipeg, R3T 2N2, MB, Canada, George and Fay Yee Centre for Healthcare Innovation, University of Manitoba, 753 McDermot Avenue, Winnipeg, R3E 0T6, MB, Canada","Background: Epigenetic modification has an effect on gene expression under the environmental alteration, but it does not change corresponding genome sequence. DNA methylation (DNAm) is one of the important epigenetic mechanisms. DNAm variations could be used as epigenetic markers to predict and account for the change of many human phenotypic traits, such as cancer, diabetes, and high blood pressure. In this study, we built deep neural network (DNN) regression models to account for interindividual variation in triglyceride concentrations measured at different visits of peripheral blood samples using epigenome-wide DNAm profiles. Results: We used epigenome-wide DNAm profiles of before and after medication interventions (called pretreatment and posttreatment, respectively) to predict triglyceride concentrations for peripheral blood draws at visit 2 (using pretreatment data) and at visit 4 (using both pretreatment and posttreatment data). Our experimental results showed that DNN models can predict triglyceride concentrations for blood draws at visit 4 using pretreatment and posttreatment DNAm data more accurately than for blood draws at visit 2 using pretreatment DNAm data. Furthermore, we got the best prediction results when we used pretreatment DNAm data to predict triglyceride concentrations for blood draws at visit 4, which suggests a long-term epigenetic effect on phenotypic traits. We compared the prediction performances of our proposed DNN models with that of support vector machine (SVM). This comparison showed that our DNN models achieved better prediction performance than did SVM. Conclusions: We demonstrated the superiority of our proposed DNN models over the SVM model for predicting triglyceride concentrations. This study also suggests that the DNN approach has advantages over other traditional machine-learning methods to model high-dimensional epigenome-wide DNAm data and other genomic data. © 2018 The Author(s).","","triacylglycerol; Article; biological variation; blood sampling; controlled study; deep neural network; DNA methylation; epigenetics; genetic analysis; human; intermethod comparison; machine learning; phenotype; prediction; priority journal; regression analysis; support vector machine; triacylglycerol blood level","BioMed Central Ltd.","17536561","","","","Article","Scopus","2-s2.0-85053418331"
"Song Z.; Liu Y.; Song R.; Chen Z.; Yang J.; Zhang C.; Jiang Q.","Song, Zhenhua (35086977700); Liu, Yan (57202590425); Song, Rong (26431599600); Chen, Zhenguang (25927035000); Yang, Jianyong (10044292400); Zhang, Chao (56518414800); Jiang, Qing (56461905800)","35086977700; 57202590425; 26431599600; 25927035000; 10044292400; 56518414800; 56461905800","A sparsity-based stochastic pooling mechanism for deep convolutional neural networks","2018","Neural Networks","30","10.1016/j.neunet.2018.05.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048813008&doi=10.1016%2fj.neunet.2018.05.015&partnerID=40&md5=3ee324da5064d30aafbc4f1fb4f70076","School of Engineering, Sun Yat-sen University, Guangzhou, 510006, China; The First Affiliated Hospital of Sun Yat-sen University, Sun Yat-sen University, Guangzhou, 510080, China","Song Z., School of Engineering, Sun Yat-sen University, Guangzhou, 510006, China; Liu Y., School of Engineering, Sun Yat-sen University, Guangzhou, 510006, China; Song R., School of Engineering, Sun Yat-sen University, Guangzhou, 510006, China; Chen Z., The First Affiliated Hospital of Sun Yat-sen University, Sun Yat-sen University, Guangzhou, 510080, China; Yang J., The First Affiliated Hospital of Sun Yat-sen University, Sun Yat-sen University, Guangzhou, 510080, China; Zhang C., School of Engineering, Sun Yat-sen University, Guangzhou, 510006, China; Jiang Q., School of Engineering, Sun Yat-sen University, Guangzhou, 510006, China","A novel sparsity-based stochastic pooling which integrates the advantages of max-pooling, average-pooling and stochastic pooling is introduced. The proposed pooling is designed to balance the advantages and disadvantages of max-pooling and average-pooling by using the degree of sparsity of activations and a control function to obtain an optimized representative feature value ranging from average value to maximum value of a pooling region. The optimized representative feature value is employed for probability weights assignment of activations in normal distribution. The proposed pooling also adopts weighted random sampling with a reservoir for the sampling process to preserve the advantages of stochastic pooling. This proposed pooling is evaluated on several standard datasets in deep learning framework to compare with various classic pooling methods. Experimental results show that it has good performance on improving recognition accuracy. The influence of changes to the feature parameter on recognition accuracy is also investigated. © 2018 Elsevier Ltd","Deep learning; Degree of sparsity; Pooling mechanism; Recognition accuracy; Representative feature value","Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Probability; Chemical activation; Deep learning; Neural networks; Normal distribution; Stochastic systems; Control functions; Deep convolutional neural networks; Degree of sparsity; Feature parameters; Feature values; Learning frameworks; Recognition accuracy; Sampling process; Article; artificial neural network; convolutional neural network; image analysis; image quality; information processing; mathematical analysis; mathematical model; performance; priority journal; probability; process optimization; sampling; sparsity based stochastic pooling; stochastic model; automated pattern recognition; machine learning; procedures; standards; Deep neural networks","Elsevier Ltd","08936080","","NNETE","29929102","Article","Scopus","2-s2.0-85048813008"
"Sevillano V.; Aznarte J.L.","Sevillano, Víctor (57203869942); Aznarte, José L. (15076711700)","57203869942; 15076711700","Improving classification of pollen grain images of the POLEN23E dataset through three different applications of deep learning convolutional neural networks","2018","PLoS ONE","66","10.1371/journal.pone.0201807","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053340935&doi=10.1371%2fjournal.pone.0201807&partnerID=40&md5=f35842116f63ed5943c4c1a65813b81f","Technical Superior School of Computer Engineering, Universidad Nacional de Educación A Distancia-UNED, Madrid, Spain; Artificial Intelligence Department, Universidad Nacional de Educación A Distancia-UNED, Madrid, Spain","Sevillano V., Technical Superior School of Computer Engineering, Universidad Nacional de Educación A Distancia-UNED, Madrid, Spain; Aznarte J.L., Artificial Intelligence Department, Universidad Nacional de Educación A Distancia-UNED, Madrid, Spain","In palynology, the visual classification of pollen grains from different species is a hard task which is usually tackled by human operators using microscopes. Its complete automatization would save a high quantity of resources and provide valuable improvements especially for allergy-related information systems, but also for other application fields as paleoclimate reconstruction, quality control of honey based products, collection of evidences in criminal investigations or fabric dating and tracking. This paper presents three state-of-the-art deep learning classification methods applied to the recently published POLEN23E image dataset. The three methods make use of convolutional neural networks: The first one is strictly based on the idea of transfer learning, the second one is based on feature extraction and the third one represents a hybrid approach, combining transfer learning and feature extraction. The results from the three methods are indeed very good, reaching over 97% correct classification rates in images not previously seen by the models, where other authors reported around 70. © 2018 Sevillano, Aznarte.","","Databases, Factual; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Pollen; article; feature extraction; grain; human; transfer of learning; artificial neural network; cytology; factual database; image processing; machine learning; pollen","Public Library of Science","19326203","","POLNC","30216353","Article","Scopus","2-s2.0-85053340935"
"Shao L.; Gao H.; Liu Z.; Feng J.; Tang L.; Lin H.","Shao, Lifen (57204326038); Gao, Hui (56301683100); Liu, Zhen (57211257834); Feng, Juan (14522187100); Tang, Lixia (7402081559); Lin, Hao (35237906600)","57204326038; 56301683100; 57211257834; 14522187100; 7402081559; 35237906600","Identification of antioxidant proteins with deep learning from sequence information","2018","Frontiers in Pharmacology","13","10.3389/fphar.2018.01036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055165728&doi=10.3389%2ffphar.2018.01036&partnerID=40&md5=94bbf7a6b76fd85b69984ded2eb09a1d","Center for Informational Biology, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Key Laboratory for Neuro-Information of Ministry of Education, Center for Informational Biology, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, China","Shao L., Center for Informational Biology, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Gao H., Center for Informational Biology, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Liu Z., Center for Informational Biology, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Feng J., Key Laboratory for Neuro-Information of Ministry of Education, Center for Informational Biology, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, China; Tang L., Key Laboratory for Neuro-Information of Ministry of Education, Center for Informational Biology, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, China; Lin H., Key Laboratory for Neuro-Information of Ministry of Education, Center for Informational Biology, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, China","Antioxidant proteins have been found closely linked to disease control for its ability to eliminate excess free radicals. Because of its medicinal value, the study of identifying antioxidant proteins is on the upsurge. Many machine-learning classifiers have performed poorly owing to the nonlinear and unbalanced nature of biological data. Recently, deep learning techniques showed advantages over many state-of-the-art machine learning methods in various fields. In this study, a deep learning based classifier was proposed to identify antioxidant proteins based on mixed g-gap dipeptide composition feature vector. The classifier employed deep autoencoder to extract nonlinear representation from raw input. The t-Distributed Stochastic Neighbor Embedding (t-SNE) was used for dimensionality reduction. Support vector machine was finally performed for classification. The classifier achieved F1 score of 0.8842 and MCC of 0.7409 in 10-fold cross validation. Experimental results show that our proposed method outperformed the traditional machine learning methods and could be a promising tool for antioxidant protein identification. For the convenience of others' scientific research, we have developed a user-friendly web server called IDAod for antioxidant protein identification, which can be accessed freely at http://bigroup.uestc.edu.cn/IDAod/. © 2007-2018 Frontiers Media S.A. All Rights Reserved.","Antioxidant proteins; Deep learning; Feature selection; G-gap dipeptide; Webserver","dipeptide; g gap dipeptide; peroxiredoxin 3; unclassified drug; algorithm; analytic method; Article; deep learning; machine learning; mathematical model; multifactor dimensionality reduction; nonlinear system; protein analysis; scoring system; support vector machine; web browser","Frontiers Media S.A.","16639812","","","","Article","Scopus","2-s2.0-85055165728"
"Lee K.; Famiglietti M.L.; McMahon A.; Wei C.-H.; MacArthur J.A.L.; Poux S.; Breuza L.; Bridge A.; Cunningham F.; Xenarios I.; Lu Z.","Lee, Kyubum (54585506800); Famiglietti, Maria Livia (9436032400); McMahon, Aoife (51261314300); Wei, Chih-Hsuan (35192504800); MacArthur, Jacqueline Ann Langdon (55946587000); Poux, Sylvain (6603339222); Breuza, Lionel (6603059124); Bridge, Alan (35344606800); Cunningham, Fiona (57221545556); Xenarios, Ioannis (6602760768); Lu, Zhiyong (23474115300)","54585506800; 9436032400; 51261314300; 35192504800; 55946587000; 6603339222; 6603059124; 35344606800; 57221545556; 6602760768; 23474115300","Scaling up data curation using deep learning: An application to literature triage in genomic variation resources","2018","PLoS Computational Biology","29","10.1371/journal.pcbi.1006390","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053082493&doi=10.1371%2fjournal.pcbi.1006390&partnerID=40&md5=04c1e95aa4ff868fe3bc8d305c4336ef","National Center for Biotechnology Information (NCBI), National Library of Medicine (NLM), National Institutes of Health (NIH), Bethesda, MD, United States; Swiss-Prot Group, SIB Swiss Institute of Bioinformatics, Geneva, Switzerland; European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge, United Kingdom; Center for Integrative Genomics, University of Lausanne, Lausanne, Switzerland; Department of Chemistry and Biochemistry, University of Geneva, Geneva, Switzerland","Lee K., National Center for Biotechnology Information (NCBI), National Library of Medicine (NLM), National Institutes of Health (NIH), Bethesda, MD, United States; Famiglietti M.L., Swiss-Prot Group, SIB Swiss Institute of Bioinformatics, Geneva, Switzerland; McMahon A., European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge, United Kingdom; Wei C.-H., National Center for Biotechnology Information (NCBI), National Library of Medicine (NLM), National Institutes of Health (NIH), Bethesda, MD, United States; MacArthur J.A.L., European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge, United Kingdom; Poux S., Swiss-Prot Group, SIB Swiss Institute of Bioinformatics, Geneva, Switzerland; Breuza L., Swiss-Prot Group, SIB Swiss Institute of Bioinformatics, Geneva, Switzerland; Bridge A., Swiss-Prot Group, SIB Swiss Institute of Bioinformatics, Geneva, Switzerland; Cunningham F., European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge, United Kingdom; Xenarios I., Center for Integrative Genomics, University of Lausanne, Lausanne, Switzerland, Department of Chemistry and Biochemistry, University of Geneva, Geneva, Switzerland; Lu Z., National Center for Biotechnology Information (NCBI), National Library of Medicine (NLM), National Institutes of Health (NIH), Bethesda, MD, United States","Manually curating biomedical knowledge from publications is necessary to build a knowledge based service that provides highly precise and organized information to users. The process of retrieving relevant publications for curation, which is also known as document triage, is usually carried out by querying and reading articles in PubMed. However, this query-based method often obtains unsatisfactory precision and recall on the retrieved results, and it is difficult to manually generate optimal queries. To address this, we propose a machine-learning assisted triage method. We collect previously curated publications from two databases UniProtKB/Swiss-Prot and the NHGRI-EBI GWAS Catalog, and used them as a gold-standard dataset for training deep learning models based on convolutional neural networks. We then use the trained models to classify and rank new publications for curation. For evaluation, we apply our method to the real-world manual curation process of UniProtKB/Swiss-Prot and the GWAS Catalog. We demonstrate that our machine-assisted triage method outperforms the current query-based triage methods, improves efficiency, and enriches curated content. Our method achieves a precision 1.81 and 2.99 times higher than that obtained by the current query-based triage methods of UniProtKB/Swiss-Prot and the GWAS Catalog, respectively, without compromising recall. In fact, our method retrieves many additional relevant publications that the query-based method of UniProtKB/Swiss-Prot could not find. As these results show, our machine learning-based method can make the triage process more efficient and is being implemented in production so that human curators can focus on more challenging tasks to improve the quality of knowledge bases. © 2018, Public Library of Science. All rights reserved.","","Data Curation; Databases, Genetic; Databases, Protein; Deep Learning; Genomics; Information Storage and Retrieval; Knowledge Bases; Machine Learning; Publications; Deep learning; Genome; Knowledge based systems; Neural networks; Publishing; 'current; Curation; Data curation; Document triages; Genomics; Knowledge based; Machine-learning; Precision and recall; Scaling-up; SWISS-PROT; article; emergency health service; genome-wide association study; gold standard; human; human experiment; knowledge base; machine learning; publication; recall; scale up; SWISS-PROT; genetic database; genomics; information processing; information retrieval; machine learning; procedures; protein database; statistics and numerical data; Genes","Public Library of Science","1553734X","","","30102703","Article","Scopus","2-s2.0-85053082493"
"Kang S.K.; Seo S.; Shin S.A.; Byun M.S.; Lee D.Y.; Kim Y.K.; Lee D.S.; Lee J.S.","Kang, Seung Kwan (57193692307); Seo, Seongho (55992472900); Shin, Seong A. (56898326400); Byun, Min Soo (35721521900); Lee, Dong Young (8554284500); Kim, Yu Kyeong (55982561800); Lee, Dong Soo (56580452900); Lee, Jae Sung (56008822800)","57193692307; 55992472900; 56898326400; 35721521900; 8554284500; 55982561800; 56580452900; 56008822800","Adaptive template generation for amyloid PET using a deep learning approach","2018","Human Brain Mapping","44","10.1002/hbm.24210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046831891&doi=10.1002%2fhbm.24210&partnerID=40&md5=7cc86b3e967d535fb2c9d19ffa911257","Department of Biomedical Sciences, Seoul National University, Seoul, South Korea; Department of Nuclear Medicine, Seoul National University, Seoul, South Korea; Department of Neuroscience, College of Medicine, Gachon University, Incheon, South Korea; Department of Nuclear Medicine, Seoul National University Boramae Medical Center, Seoul, South Korea; Department of Neuropsychiatry, Seoul National University, Seoul, South Korea; Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Suwon, South Korea; Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, South Korea","Kang S.K., Department of Biomedical Sciences, Seoul National University, Seoul, South Korea, Department of Nuclear Medicine, Seoul National University, Seoul, South Korea; Seo S., Department of Neuroscience, College of Medicine, Gachon University, Incheon, South Korea; Shin S.A., Department of Biomedical Sciences, Seoul National University, Seoul, South Korea, Department of Nuclear Medicine, Seoul National University Boramae Medical Center, Seoul, South Korea; Byun M.S., Department of Neuropsychiatry, Seoul National University, Seoul, South Korea; Lee D.Y., Department of Neuropsychiatry, Seoul National University, Seoul, South Korea; Kim Y.K., Department of Nuclear Medicine, Seoul National University Boramae Medical Center, Seoul, South Korea; Lee D.S., Department of Nuclear Medicine, Seoul National University, Seoul, South Korea, Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Suwon, South Korea, Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, South Korea; Lee J.S., Department of Biomedical Sciences, Seoul National University, Seoul, South Korea, Department of Nuclear Medicine, Seoul National University, Seoul, South Korea, Institute of Radiation Medicine, Medical Research Center, Seoul National University, Seoul, South Korea","Accurate spatial normalization (SN) of amyloid positron emission tomography (PET) images for Alzheimer's disease assessment without coregistered anatomical magnetic resonance imaging (MRI) of the same individual is technically challenging. In this study, we applied deep neural networks to generate individually adaptive PET templates for robust and accurate SN of amyloid PET without using matched 3D MR images. Using 681 pairs of simultaneously acquired 11C-PIB PET and T1-weighted 3D MRI scans of AD, MCI, and cognitively normal subjects, we trained and tested two deep neural networks [convolutional auto-encoder (CAE) and generative adversarial network (GAN)] that produce adaptive best PET templates. More specifically, the networks were trained using 685,100 pieces of augmented data generated by rotating 527 randomly selected datasets and validated using 154 datasets. The input to the supervised neural networks was the 3D PET volume in native space and the label was the spatially normalized 3D PET image using the transformation parameters obtained from MRI-based SN. The proposed deep learning approach significantly enhanced the quantitative accuracy of MRI-less amyloid PET assessment by reducing the SN error observed when an average amyloid PET template is used. Given an input image, the trained deep neural networks rapidly provide individually adaptive 3D PET templates without any discontinuity between the slices (in 0.02 s). As the proposed method does not require 3D MRI for the SN of PET images, it has great potential for use in routine analysis of amyloid PET images in clinical practice and research. © 2018 Wiley Periodicals, Inc.","amyloid PET; deep learning; quantification; spatial normalization","Algorithms; Alzheimer Disease; Amyloid; Aniline Compounds; Benzothiazoles; Brain; Carbon Radioisotopes; Cognitive Dysfunction; Deep Learning; Female; Humans; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Male; Positron-Emission Tomography; Radiopharmaceuticals; Supervised Machine Learning; Thiazoles; amyloid; Pittsburgh compound B; 2-(4'-(methylamino)phenyl)-6-hydroxybenzothiazole; amyloid; aniline derivative; benzothiazole derivative; carbon; Carbon-11; N-methyl-2-(4'-methylaminophenyl)-6-hydroxybenzothiazole; radiopharmaceutical agent; thiazole derivative; accuracy; Alzheimer disease; Article; controlled study; human; learning; major clinical study; mild cognitive impairment; nuclear magnetic resonance imaging; positron emission tomography; priority journal; three dimensional imaging; algorithm; Alzheimer disease; brain; cognitive defect; comparative study; diagnostic imaging; female; male; pathology; positron emission tomography; procedures; supervised machine learning","John Wiley and Sons Inc.","10659471","","HBMAE","29752765","Article","Scopus","2-s2.0-85046831891"
"Kim S.; Kim J.; Chun H.-W.","Kim, Seonho (57210865570); Kim, Jungjoon (57203539586); Chun, Hong-Woo (16052000400)","57210865570; 57203539586; 16052000400","Wave2Vec: Vectorizing electroencephalography bio-signal for prediction of brain disease","2018","International Journal of Environmental Research and Public Health","18","10.3390/ijerph15081750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052119038&doi=10.3390%2fijerph15081750&partnerID=40&md5=baf6fafd3acf4bd6045a9f09aa719cf2","Convergence Research Center for Diagnosis, Treatment and Care System of Dementia, Korea Institute of Science and Technology (KIST), Seoul, 02792, South Korea; Korea Institute of Science and Technology Information (KISTI), Seoul, 02456, South Korea; Science and Technology Information Science, University of Science & Technology (UST), Daejeon, 34113, South Korea","Kim S., Convergence Research Center for Diagnosis, Treatment and Care System of Dementia, Korea Institute of Science and Technology (KIST), Seoul, 02792, South Korea, Korea Institute of Science and Technology Information (KISTI), Seoul, 02456, South Korea, Science and Technology Information Science, University of Science & Technology (UST), Daejeon, 34113, South Korea; Kim J., Convergence Research Center for Diagnosis, Treatment and Care System of Dementia, Korea Institute of Science and Technology (KIST), Seoul, 02792, South Korea, Korea Institute of Science and Technology Information (KISTI), Seoul, 02456, South Korea; Chun H.-W., Convergence Research Center for Diagnosis, Treatment and Care System of Dementia, Korea Institute of Science and Technology (KIST), Seoul, 02792, South Korea, Korea Institute of Science and Technology Information (KISTI), Seoul, 02456, South Korea, Science and Technology Information Science, University of Science & Technology (UST), Daejeon, 34113, South Korea","Interest in research involving health-medical information analysis based on artificial intelligence, especially for deep learning techniques, has recently been increasing. Most of the research in this field has been focused on searching for new knowledge for predicting and diagnosing disease by revealing the relation between disease and various information features of data. These features are extracted by analyzing various clinical pathology data, such as EHR (electronic health records), and academic literature using the techniques of data analysis, natural language processing, etc. However, still needed are more research and interest in applying the latest advanced artificial intelligence-based data analysis technique to bio-signal data, which are continuous physiological records, such as EEG (electroencephalography) and ECG (electrocardiogram). Unlike the other types of data, applying deep learning to bio-signal data, which is in the form of time series of real numbers, has many issues that need to be resolved in preprocessing, learning, and analysis. Such issues include leaving feature selection, learning parts that are black boxes, difficulties in recognizing and identifying effective features, high computational complexities, etc. In this paper, to solve these issues, we provide an encoding-based Wave2vec time series classifier model, which combines signal-processing and deep learning-based natural language processing techniques. To demonstrate its advantages, we provide the results of three experiments conducted with EEG data of the University of California Irvine, which are a real-world benchmark bio-signal dataset. After converting the bio-signals (in the form of waves), which are a real number time series, into a sequence of symbols or a sequence of wavelet patterns that are converted into symbols, through encoding, the proposed model vectorizes the symbols by learning the sequence using deep learning-based natural language processing. The models of each class can be constructed through learning from the vectorized wavelet patterns and training data. The implemented models can be used for prediction and diagnosis of diseases by classifying the new data. The proposed method enhanced data readability and intuition of feature selection and learning processes by converting the time series of real number data into sequences of symbols. In addition, it facilitates intuitive and easy recognition, and identification of influential patterns. Furthermore, real-time large-capacity data analysis is facilitated, which is essential in the development of real-time analysis diagnosis systems, by drastically reducing the complexity of calculation without deterioration of analysis performance by data simplification through the encoding process. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Alcoholism; Bio-signal; Deep learning; Dementia; Electroencephalography (EEG); Prediction of brain disease; Sequence classification; Wave2vec","Algorithms; Artificial Intelligence; Brain Diseases; Electroencephalography; Humans; Signal Processing, Computer-Assisted; California; United States; artificial intelligence; brain; disease vector; learning; medical geography; neurology; pathology; prediction; Article; brain disease; calculation; classifier; controlled study; data analysis; diagnostic procedure; electroencephalography; feature extraction; human; information processing; machine learning; natural language processing; prediction; sequence learning; signal processing; time series analysis; wavelet analysis; algorithm; artificial intelligence; brain disease; signal processing","MDPI AG","16617827","","","30111710","Article","Scopus","2-s2.0-85052119038"
"Liu R.; Madore M.; Glover K.P.; Feasel M.G.; Wallqvist A.","Liu, Ruifeng (55739641500); Madore, Michael (57211919127); Glover, Kyle P. (57201792961); Feasel, Michael G. (57190751776); Wallqvist, Anders (56218890000)","55739641500; 57211919127; 57201792961; 57190751776; 56218890000","Assessing deep and shallow learning methods for quantitative prediction of acute chemical toxicity","2018","Toxicological Sciences","33","10.1093/toxsci/kfy111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052119710&doi=10.1093%2ftoxsci%2fkfy111&partnerID=40&md5=d08179b97440d04272c393ee6a819197","Department of Defense Biotechnology, High Performance Computing Software Applications Institute, Telemedicine and Advanced Technology Research Center, Fort Detrick, 21702, MD, United States; Defense Threat Reduction Agency, Ft Belvoir, 22060, VA, United States; U.S. Army - Edgewood Chemical Biological Center, Operational Toxicology, Aberdeen Proving Ground, Maryland, 21010, United States","Liu R., Department of Defense Biotechnology, High Performance Computing Software Applications Institute, Telemedicine and Advanced Technology Research Center, Fort Detrick, 21702, MD, United States; Madore M., Department of Defense Biotechnology, High Performance Computing Software Applications Institute, Telemedicine and Advanced Technology Research Center, Fort Detrick, 21702, MD, United States; Glover K.P., Defense Threat Reduction Agency, Ft Belvoir, 22060, VA, United States, U.S. Army - Edgewood Chemical Biological Center, Operational Toxicology, Aberdeen Proving Ground, Maryland, 21010, United States; Feasel M.G., U.S. Army - Edgewood Chemical Biological Center, Operational Toxicology, Aberdeen Proving Ground, Maryland, 21010, United States; Wallqvist A., Department of Defense Biotechnology, High Performance Computing Software Applications Institute, Telemedicine and Advanced Technology Research Center, Fort Detrick, 21702, MD, United States","Animal-basedmethods for assessing chemical toxicity are struggling tomeet testing demands. In silico approaches, including machine-learningmethods, are promising alternatives. Recently, deep neural networks (DNNs) were evaluated and reported to outperform othermachine-learningmethods for quantitative structure-activity relationshipmodeling ofmolecular properties. However,most of the reported performance evaluations relied on global performancemetrics, such as the root mean squared error (RMSE) between the predicted and experimental values of all samples, without considering the impact of sample distribution across the activity spectrum. Here, we carried out an in-depth analysis of DNN performance for quantitative prediction of acute chemical toxicity using several datasets.We found that the overall performance of DNN models on datasets of up to 30 000 compounds was similar to that of random forest (RF)models, asmeasured by the RMSE and correlation coefficients between the predicted and experimental results. However, our detailed analyses demonstrated that global performancemetrics are inappropriate for datasets with a highly uneven sample distribution, because they show a strong bias for themost populous compounds along the toxicity spectrum. For highly toxic compounds, DNN and RFmodels trained on all samples performed much worse than the global performancemetrics indicated. Surprisingly, our variable nearest neighbormethod, which utilizes only structurally similar compounds tomake predictions, performed reasonably well, suggesting that information of close near neighbors in the training sets is a key determinant of acute toxicity predictions. © The Author(s) 2018.","acute toxicity; deep neural networks; machine learning; QSAR; random forests; variable nearest neighbor method","Animals; Computational Biology; Datasets as Topic; Deep Learning; Machine Learning; Mice; Neural Networks (Computer); Quantitative Structure-Activity Relationship; Rabbits; Rats; Toxicity Tests; chemical agent; toxic substance; acute toxicity; Article; artificial neural network; correlation coefficient; machine learning; nonhuman; quantitative analysis; random forest; animal; biology; information processing; Leporidae; machine learning; mouse; procedures; quantitative structure activity relation; rat; toxicity testing","Oxford University Press","10966080","","TOSCF","29722883","Article","Scopus","2-s2.0-85052119710"
"Patnaik S.K.; Sidhu M.S.; Gehlot Y.; Sharma B.; Muthu P.","Patnaik, Sourav Kumar (57207833008); Sidhu, Mansher Singh (57207833591); Gehlot, Yaagyanika (57207817993); Sharma, Bhairvi (57207819815); Muthu, P. (57214978457)","57207833008; 57207833591; 57207817993; 57207819815; 57214978457","Automated skin disease identification using deep learning algorithm","2018","Biomedical and Pharmacology Journal","38","10.13005/bpj/1507","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062969096&doi=10.13005%2fbpj%2f1507&partnerID=40&md5=f6900cec81007f650c01043de9bcedc3","Department of Biomedical Engineering, SRM Institute of Science and Technology, Kattankulathur, Chennai, Tamil Nadu, India","Patnaik S.K., Department of Biomedical Engineering, SRM Institute of Science and Technology, Kattankulathur, Chennai, Tamil Nadu, India; Sidhu M.S., Department of Biomedical Engineering, SRM Institute of Science and Technology, Kattankulathur, Chennai, Tamil Nadu, India; Gehlot Y., Department of Biomedical Engineering, SRM Institute of Science and Technology, Kattankulathur, Chennai, Tamil Nadu, India; Sharma B., Department of Biomedical Engineering, SRM Institute of Science and Technology, Kattankulathur, Chennai, Tamil Nadu, India; Muthu P., Department of Biomedical Engineering, SRM Institute of Science and Technology, Kattankulathur, Chennai, Tamil Nadu, India","Dermatological disorders are one of the most widespread diseases in the world. Despite being common its diagnosis is extremely difficult because of its complexities of skin tone, color, presence of hair. This paper provides an approach to use various computer vision based techniques (deep learning) to automatically predict the various kinds of skin diseases. The system uses three publicly available image recognition architectures namely InceptionV3, InceptionResnetV2, MobileNet with modifications for skin disease application and successfully predicts the skin disease based on maximum voting from the three networks. These models are pretrained to recognize images upto 1000 classes like panda, parrot etc. The architectures are published by image recognition giants for public usage for various applications. The system consists of three phases- The feature extraction phase, the training phase and the testing / validation phase. The system makes use of deep learning technology to train itself with the various skin images. The main objective of this system is to achieve maximum accuracy of skin disease prediction. © 2018 Oriental Scientific Publishing Company.","Computer vision; Deep learning; Image recognition; Learning algorithms; Skin disease","Article; artificial intelligence; automation; computer assisted diagnosis; computer model; deep learning; diagnostic accuracy; human; inception V2; inception V3; learning algorithm; machine learning; measurement precision; mobile application; MobileNet; skin disease; training; validation process","Oriental Scientific Publishing Company","09746242","","","","Article","Scopus","2-s2.0-85062969096"
"Hochuli J.; Helbling A.; Skaist T.; Ragoza M.; Koes D.R.","Hochuli, Joshua (57194064510); Helbling, Alec (57701412300); Skaist, Tamar (57192431571); Ragoza, Matthew (57190972676); Koes, David Ryan (6504625843)","57194064510; 57701412300; 57192431571; 57190972676; 6504625843","Visualizing convolutional neural network protein-ligand scoring","2018","Journal of Molecular Graphics and Modelling","67","10.1016/j.jmgm.2018.06.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048884621&doi=10.1016%2fj.jmgm.2018.06.005&partnerID=40&md5=4dd67a69e064927b1ac5f0b7848b7c57","Department of Computational and Systems Biology, University of Pittsburgh, 3501 Fifth Ave, Pittsburgh, 15260, PA, United States","Hochuli J., Department of Computational and Systems Biology, University of Pittsburgh, 3501 Fifth Ave, Pittsburgh, 15260, PA, United States; Helbling A., Department of Computational and Systems Biology, University of Pittsburgh, 3501 Fifth Ave, Pittsburgh, 15260, PA, United States; Skaist T., Department of Computational and Systems Biology, University of Pittsburgh, 3501 Fifth Ave, Pittsburgh, 15260, PA, United States; Ragoza M., Department of Computational and Systems Biology, University of Pittsburgh, 3501 Fifth Ave, Pittsburgh, 15260, PA, United States; Koes D.R., Department of Computational and Systems Biology, University of Pittsburgh, 3501 Fifth Ave, Pittsburgh, 15260, PA, United States","Protein-ligand scoring is an important step in a structure-based drug design pipeline. Selecting a correct binding pose and predicting the binding affinity of a protein-ligand complex enables effective virtual screening. Machine learning techniques can make use of the increasing amounts of structural data that are becoming publicly available. Convolutional neural network (CNN) scoring functions in particular have shown promise in pose selection and affinity prediction for protein-ligand complexes. Neural networks are known for being difficult to interpret. Understanding the decisions of a particular network can help tune parameters and training data to maximize performance. Visualization of neural networks helps decompose complex scoring functions into pictures that are more easily parsed by humans. Here we present three methods for visualizing how individual protein-ligand complexes are interpreted by 3D convolutional neural networks. We also present a visualization of the convolutional filters and their weights. We describe how the intuition provided by these visualizations aids in network design. © 2018 Elsevier Inc.","Deep learning; Molecular visualization; Protein-ligand scoring","Algorithms; Deep Learning; Ligands; Models, Molecular; Molecular Conformation; Neural Networks (Computer); Protein Binding; Proteins; ROC Curve; Binding energy; Complexation; Convolution; Deep learning; Ligands; Neural networks; Proteins; Visualization; carbonyl derivative; Human immunodeficiency virus proteinase inhibitor; oxygen; ribonuclease A; ligand; protein; protein binding; Convolutional neural network; Convolutional Neural Networks (CNN); Individual proteins; Machine learning techniques; Molecular visualization; Protein ligands; Protein-ligand complexes; Structure based drug designs; Article; atom; binding site; complex formation; conformation; convolutional neural network; hydrogen bond; intermethod comparison; ligand binding; machine learning; priority journal; probability; protein binding; algorithm; artificial neural network; chemistry; molecular model; receiver operating characteristic; Complex networks","Elsevier Inc.","10933263","","JMGMF","29940506","Article","Scopus","2-s2.0-85048884621"
"Ryan K.; Lengyel J.; Shatruk M.","Ryan, Kevin (57214267705); Lengyel, Jeff (56565026300); Shatruk, Michael (6603333408)","57214267705; 56565026300; 6603333408","Crystal Structure Prediction via Deep Learning","2018","Journal of the American Chemical Society","237","10.1021/jacs.8b03913","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048378170&doi=10.1021%2fjacs.8b03913&partnerID=40&md5=40eb7aa95ac419c2ef0840a8ab99134a","Department of Chemistry and Biochemistry, Florida State University, Tallahassee, 32306, FL, United States","Ryan K., Department of Chemistry and Biochemistry, Florida State University, Tallahassee, 32306, FL, United States; Lengyel J., Department of Chemistry and Biochemistry, Florida State University, Tallahassee, 32306, FL, United States; Shatruk M., Department of Chemistry and Biochemistry, Florida State University, Tallahassee, 32306, FL, United States","We demonstrate the application of deep neural networks as a machine-learning tool for the analysis of a large collection of crystallographic data contained in the crystal structure repositories. Using input data in the form of multiperspective atomic fingerprints, which describe coordination topology around unique crystallographic sites, we show that the neural-network model can be trained to effectively distinguish chemical elements based on the topology of their crystallographic environment. The model also identifies structurally similar atomic sites in the entire data set of ∼50000 crystal structures, essentially uncovering trends that reflect the periodic table of elements. The trained model was used to analyze templates derived from the known crystal structures in order to predict the likelihood of forming new compounds that could be generated by placing elements into these structural templates in a combinatorial fashion. Statistical analysis of predictive performance of the neural-network model, which was applied to a test set of structures never seen by the model during training, indicates its ability to predict known elemental compositions with a high likelihood of success. In ∼30% of cases, the known compositions were found among the top 10 most likely candidates proposed by the model. These results suggest that the approach developed in this work can be used to effectively guide the synthetic efforts in the discovery of new materials, especially in the case of systems composed of three or more chemical elements. © 2018 American Chemical Society.","","Chemical elements; Deep neural networks; Forecasting; Topology; Crystal structure prediction; Crystallographic data; Crystallographic sites; Elemental compositions; Neural network model; Periodic table of elements; Predictive performance; Structural templates; article; coordination; crystal structure; crystallography; machine learning; nervous system; prediction; statistical analysis; deep learning; Crystal atomic structure","American Chemical Society","00027863","","JACSA","29874459","Article","Scopus","2-s2.0-85048378170"
"Huang L.; Xiang L.-Y.","Huang, Lu (56652807900); Xiang, Lu-yang (57192179845)","56652807900; 57192179845","Method for Meteorological Early Warning of Precipitation-Induced Landslides Based on Deep Neural Network","2018","Neural Processing Letters","32","10.1007/s11063-017-9778-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040011461&doi=10.1007%2fs11063-017-9778-0&partnerID=40&md5=abac49270890461e885d53f665f8f55a","Hubei Surveying Mapping Engineering Institute, Hubei Bureau of Surveying, Mapping and Geoinformation, Wuhan, 430074, Hubei, China; Engineering Department, The 709th Research Institute of China Shipbuilding Industry Corporation, Wuhan, 430074, Hubei, China","Huang L., Hubei Surveying Mapping Engineering Institute, Hubei Bureau of Surveying, Mapping and Geoinformation, Wuhan, 430074, Hubei, China; Xiang L.-Y., Engineering Department, The 709th Research Institute of China Shipbuilding Industry Corporation, Wuhan, 430074, Hubei, China","The meteorological early warning model of precipitation-induced landslides is a significant yet challenging task, due to the complexity and uncertainty of various influence factors. Generally, the existing machine learning methods have the drawbacks of poor learning ability and weak capability of feature extraction. Inspired by deep learning technology, we propose a deep belief network (DBN) approach with Softmax classifier and Dropout mechanism for meteorological early warning of precipitation-induced landslides to overcome these problems. With the powerful nonlinear mapping ability of DBN when training a large number of sample data, we use the greedy unsupervised learning algorithm of DBN to extract the intrinsic characteristics of landslide factors. Then, to further improve prediction accuracy of landslides, the Softmax classifier is added to the top layer of DBN neural network. Moreover, the Dropout mechanism is introduced in the training process to reduce the prediction error caused by the over-fitting phenomena. Taking Wenchuan earthquake affected area for example, after analysis of the factors influencing landslide disasters, the meteorological early warning model of landslides based on Dropout DBN-Softmax is established. Compared with the existing BP neural network algorithm and BP algorithm based on Particle Swarm Optimizer (PSO-BP) algorithm, the experimental results show that the new approach proposed has the advantages of higher accuracy and better technological performances than the former algorithms. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Deep neural network; Landslide; Meteorological early warning; Softmax; Wenchuan","Earthquakes; Landslides; Learning algorithms; Neural networks; Particle swarm optimization (PSO); Deep belief network (DBN); Early warning; Intrinsic characteristics; Machine learning methods; Particle swarm optimizers; Softmax; Technological performance; Wenchuan; Deep neural networks","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-85040011461"
"Majumdar S.; Basak S.C.; Lungu C.N.; Diudea M.V.; Grunwald G.D.","Majumdar, S. (55972063800); Basak, S.C. (35599230100); Lungu, C.N. (57188837077); Diudea, M.V. (7006271534); Grunwald, G.D. (7005993106)","55972063800; 35599230100; 57188837077; 7006271534; 7005993106","Mathematical structural descriptors and mutagenicity assessment: a study with congeneric and diverse datasets$                     ","2018","SAR and QSAR in Environmental Research","11","10.1080/1062936X.2018.1496475","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050339878&doi=10.1080%2f1062936X.2018.1496475&partnerID=40&md5=15c238dc15478bd6e7f028de6529b872","University of Florida Informatics Institute, Gainesville, United States; Department of Chemistry and Biochemistry, University of Minnesota, Duluth, MN, United States; Department of Chemistry, Babes-Bolyai University, Cluj-Napoca, Romania; Natural Resources Research Institute, University of Minnesota, Duluth, United States","Majumdar S., University of Florida Informatics Institute, Gainesville, United States; Basak S.C., Department of Chemistry and Biochemistry, University of Minnesota, Duluth, MN, United States; Lungu C.N., Department of Chemistry, Babes-Bolyai University, Cluj-Napoca, Romania; Diudea M.V., Department of Chemistry, Babes-Bolyai University, Cluj-Napoca, Romania; Grunwald G.D., Natural Resources Research Institute, University of Minnesota, Duluth, United States","Quantitative bioactivity and toxicity assessment of chemical compounds plays a central role in drug discovery as it saves a substantial amount of resources. To this end, high-performance computing has enabled researchers and practitioners to leverage hundreds, or even thousands, of computed molecular descriptors for the activity prediction of candidate compounds. In this paper, we evaluate the utility of two large groups of chemical descriptors by such predictive modelling, as well as chemical structure discovery, through empirical analysis. We use a suite of commercially available and in-house software to calculate molecular descriptors for two sets of chemical mutagens–a homogeneous set of 95 amines, and a diverse set of 508 chemicals. Using calculated descriptors, we model the mutagenic activity of these compounds using a number of methods from the statistics and machine-learning literature, and use robust principal component analysis to investigate the low-dimensional subspaces that characterize these chemicals. Our results suggest that combining different sets of descriptors is likely to result in a better predictive model–but that depends on the compounds being modelled and the modelling technique being used. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","dimension reduction; machine learning; molecular descriptors; quantitative structure–activity relationship (QSAR); two-deep cross-validation; variable selection","Amines; Mutagens; Principal Component Analysis; Quantitative Structure-Activity Relationship; Software; amine; mutagenic agent; chemistry; principal component analysis; quantitative structure activity relation; software","Taylor and Francis Ltd.","1062936X","","","30025481","Article","Scopus","2-s2.0-85050339878"
"Nitta N.; Sugimura T.; Isozaki A.; Mikami H.; Hiraki K.; Sakuma S.; Iino T.; Arai F.; Endo T.; Fujiwaki Y.; Fukuzawa H.; Hase M.; Hayakawa T.; Hiramatsu K.; Hoshino Y.; Inaba M.; Ito T.; Karakawa H.; Kasai Y.; Koizumi K.; Lee S.; Lei C.; Li M.; Maeno T.; Matsusaka S.; Murakami D.; Nakagawa A.; Oguchi Y.; Oikawa M.; Ota T.; Shiba K.; Shintaku H.; Shirasaki Y.; Suga K.; Suzuki Y.; Suzuki N.; Tanaka Y.; Tezuka H.; Toyokawa C.; Yalikun Y.; Yamada M.; Yamagishi M.; Yamano T.; Yasumoto A.; Yatomi Y.; Yazawa M.; Di Carlo D.; Hosokawa Y.; Uemura S.; Ozeki Y.; Goda K.","Nitta, Nao (22433747200); Sugimura, Takeaki (57202815430); Isozaki, Akihiro (24833025700); Mikami, Hideharu (34973172900); Hiraki, Kei (7102170982); Sakuma, Shinya (24722932200); Iino, Takanori (36663610900); Arai, Fumihito (7102069340); Endo, Taichiro (57204618007); Fujiwaki, Yasuhiro (57204617355); Fukuzawa, Hideya (7006793476); Hase, Misa (57204623664); Hayakawa, Takeshi (55659912900); Hiramatsu, Kotaro (55344899800); Hoshino, Yu (12752326300); Inaba, Mary (7202428625); Ito, Takuro (55366160000); Karakawa, Hiroshi (57204628910); Kasai, Yusuke (57193408522); Koizumi, Kenichi (35781794800); Lee, SangWook (57192656949); Lei, Cheng (36246334900); Li, Ming (54410992600); Maeno, Takanori (57209162830); Matsusaka, Satoshi (36123509700); Murakami, Daichi (56340096100); Nakagawa, Atsuhiro (7202934857); Oguchi, Yusuke (12797848800); Oikawa, Minoru (42462167000); Ota, Tadataka (57204614785); Shiba, Kiyotaka (7202098413); Shintaku, Hirofumi (23767292500); Shirasaki, Yoshitaka (12242357100); Suga, Kanako (57201721993); Suzuki, Yuta (57198662465); Suzuki, Nobutake (55851278500); Tanaka, Yo (14061292500); Tezuka, Hiroshi (36795015400); Toyokawa, Chihana (57191862476); Yalikun, Yaxiaer (55822791200); Yamada, Makoto (57220849962); Yamagishi, Mai (55225413200); Yamano, Takashi (8632430900); Yasumoto, Atsushi (24339861700); Yatomi, Yutaka (7005542242); Yazawa, Masayuki (16311351000); Di Carlo, Dino (7004093204); Hosokawa, Yoichiroh (55565357200); Uemura, Sotaro (7201644842); Ozeki, Yasuyuki (7103381938); Goda, Keisuke (35227304100)","22433747200; 57202815430; 24833025700; 34973172900; 7102170982; 24722932200; 36663610900; 7102069340; 57204618007; 57204617355; 7006793476; 57204623664; 55659912900; 55344899800; 12752326300; 7202428625; 55366160000; 57204628910; 57193408522; 35781794800; 57192656949; 36246334900; 54410992600; 57209162830; 36123509700; 56340096100; 7202934857; 12797848800; 42462167000; 57204614785; 7202098413; 23767292500; 12242357100; 57201721993; 57198662465; 55851278500; 14061292500; 36795015400; 57191862476; 55822791200; 57220849962; 55225413200; 8632430900; 24339861700; 7005542242; 16311351000; 7004093204; 55565357200; 7201644842; 7103381938; 35227304100","Intelligent Image-Activated Cell Sorting","2018","Cell","366","10.1016/j.cell.2018.08.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054484004&doi=10.1016%2fj.cell.2018.08.028&partnerID=40&md5=0ee5ee616e5bd90ee02d97c860c16c30","Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Japan Science and Technology Agency, Saitama, 332-0012, Japan; Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, 464-8603, Japan; Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo, 113-8656, Japan; Center for Advanced Intelligence Project, RIKEN, Tokyo, 103-0027, Japan; ExaWizards Inc., Tokyo, 105-0013, Japan; Graduate School of Biostudies, Kyoto University, Kyoto, 606-8502, Japan; Department of Precision Mechanics, Chuo University, Tokyo, 112-8551, Japan; Department of Chemical Engineering, Kyushu University, Fukuoka, 819-0395, Japan; Department of Creative Informatics, The University of Tokyo, Tokyo, 113-0033, Japan; Department of Bioengineering, University of California, Los Angeles, Los Angeles, 90095, CA, United States; Institute of Medical Science, The University of Tokyo, Tokyo, 108-8639, Japan; Department of Gastroenterology, Cancer Institute Hospital, Japanese Foundation for Cancer Research, Tokyo, 135-8550, Japan; Department of Neurosurgery, Graduate School of Medicine, Tohoku University, Sendai, 980-8577, Japan; Department of Biological Sciences, The University of Tokyo, Tokyo, 113-0033, Japan; Science and Technology Unit, Natural Sciences Cluster, Kochi University, Kochi, 780-8520, Japan; Division of Protein Engineering, Cancer Institute, Japanese Foundation for Cancer Research, Tokyo, 135-8550, Japan; Department of Micro Engineering, Kyoto University, Kyoto, 606-8501, Japan; Center for Biosystems Dynamics Research, RIKEN, Osaka, 565-0871, Japan; Graduate School of Informatics, Kyoto University, Kyoto, 606-8501, Japan; Department of Clinical Laboratory Medicine, Graduate School of Medicine, The University of Tokyo, Tokyo, 113-0033, Japan; Department of Rehabilitation and Regenerative Medicine, Pharmacology, Columbia University, New York, 10032, NY, United States; Department of Mechanical Engineering, University of California, Los Angeles, Los Angeles, 90095, CA, United States; California NanoSystems Institute, University of California, Los Angeles, Los Angeles, 90095, CA, United States; Graduate School of Materials Science, Nara Institute of Science and Technology, Ikoma, 630-0192, Japan; Department of Electrical Engineering, University of California, Los Angeles, Los Angeles, 90095, CA, United States","Nitta N., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan, Japan Science and Technology Agency, Saitama, 332-0012, Japan; Sugimura T., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan, Japan Science and Technology Agency, Saitama, 332-0012, Japan; Isozaki A., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Mikami H., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Hiraki K., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Sakuma S., Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, 464-8603, Japan; Iino T., Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo, 113-8656, Japan; Arai F., Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, 464-8603, Japan; Endo T., Center for Advanced Intelligence Project, RIKEN, Tokyo, 103-0027, Japan, ExaWizards Inc., Tokyo, 105-0013, Japan; Fujiwaki Y., Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo, 113-8656, Japan; Fukuzawa H., Graduate School of Biostudies, Kyoto University, Kyoto, 606-8502, Japan; Hase M., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Hayakawa T., Department of Precision Mechanics, Chuo University, Tokyo, 112-8551, Japan; Hiramatsu K., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Hoshino Y., Department of Chemical Engineering, Kyushu University, Fukuoka, 819-0395, Japan; Inaba M., Department of Creative Informatics, The University of Tokyo, Tokyo, 113-0033, Japan; Ito T., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan, Japan Science and Technology Agency, Saitama, 332-0012, Japan; Karakawa H., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Kasai Y., Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, 464-8603, Japan; Koizumi K., Department of Creative Informatics, The University of Tokyo, Tokyo, 113-0033, Japan; Lee S., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Lei C., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Li M., Department of Bioengineering, University of California, Los Angeles, Los Angeles, 90095, CA, United States; Maeno T., Institute of Medical Science, The University of Tokyo, Tokyo, 108-8639, Japan; Matsusaka S., Department of Gastroenterology, Cancer Institute Hospital, Japanese Foundation for Cancer Research, Tokyo, 135-8550, Japan; Murakami D., Department of Creative Informatics, The University of Tokyo, Tokyo, 113-0033, Japan; Nakagawa A., Department of Neurosurgery, Graduate School of Medicine, Tohoku University, Sendai, 980-8577, Japan; Oguchi Y., Department of Biological Sciences, The University of Tokyo, Tokyo, 113-0033, Japan; Oikawa M., Science and Technology Unit, Natural Sciences Cluster, Kochi University, Kochi, 780-8520, Japan; Ota T., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan; Shiba K., Division of Protein Engineering, Cancer Institute, Japanese Foundation for Cancer Research, Tokyo, 135-8550, Japan; Shintaku H., Department of Micro Engineering, Kyoto University, Kyoto, 606-8501, Japan; Shirasaki Y., Department of Biological Sciences, The University of Tokyo, Tokyo, 113-0033, Japan; Suga K., Division of Protein Engineering, Cancer Institute, Japanese Foundation for Cancer Research, Tokyo, 135-8550, Japan; Suzuki Y., Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo, 113-8656, Japan; Suzuki N., Department of Biological Sciences, The University of Tokyo, Tokyo, 113-0033, Japan; Tanaka Y., Center for Biosystems Dynamics Research, RIKEN, Osaka, 565-0871, Japan; Tezuka H., Department of Creative Informatics, The University of Tokyo, Tokyo, 113-0033, Japan; Toyokawa C., Graduate School of Biostudies, Kyoto University, Kyoto, 606-8502, Japan; Yalikun Y., Center for Biosystems Dynamics Research, RIKEN, Osaka, 565-0871, Japan; Yamada M., Center for Advanced Intelligence Project, RIKEN, Tokyo, 103-0027, Japan, Graduate School of Informatics, Kyoto University, Kyoto, 606-8501, Japan; Yamagishi M., Department of Biological Sciences, The University of Tokyo, Tokyo, 113-0033, Japan; Yamano T., Graduate School of Biostudies, Kyoto University, Kyoto, 606-8502, Japan; Yasumoto A., Department of Clinical Laboratory Medicine, Graduate School of Medicine, The University of Tokyo, Tokyo, 113-0033, Japan; Yatomi Y., Department of Clinical Laboratory Medicine, Graduate School of Medicine, The University of Tokyo, Tokyo, 113-0033, Japan; Yazawa M., Department of Rehabilitation and Regenerative Medicine, Pharmacology, Columbia University, New York, 10032, NY, United States; Di Carlo D., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan, Department of Bioengineering, University of California, Los Angeles, Los Angeles, 90095, CA, United States, Department of Mechanical Engineering, University of California, Los Angeles, Los Angeles, 90095, CA, United States, California NanoSystems Institute, University of California, Los Angeles, Los Angeles, 90095, CA, United States; Hosokawa Y., Graduate School of Materials Science, Nara Institute of Science and Technology, Ikoma, 630-0192, Japan; Uemura S., Department of Biological Sciences, The University of Tokyo, Tokyo, 113-0033, Japan; Ozeki Y., Department of Electrical Engineering and Information Systems, The University of Tokyo, Tokyo, 113-8656, Japan; Goda K., Department of Chemistry, The University of Tokyo, Tokyo, 113-0033, Japan, Japan Science and Technology Agency, Saitama, 332-0012, Japan, Department of Electrical Engineering, University of California, Los Angeles, Los Angeles, 90095, CA, United States","A fundamental challenge of biology is to understand the vast heterogeneity of cells, particularly how cellular composition, structure, and morphology are linked to cellular physiology. Unfortunately, conventional technologies are limited in uncovering these relations. We present a machine-intelligence technology based on a radically different architecture that realizes real-time image-based intelligent cell sorting at an unprecedented rate. This technology, which we refer to as intelligent image-activated cell sorting, integrates high-throughput cell microscopy, focusing, and sorting on a hybrid software-hardware data-management infrastructure, enabling real-time automated operation for data acquisition, data processing, decision-making, and actuation. We use it to demonstrate real-time sorting of microalgal and blood cells based on intracellular protein localization and cell-cell interaction from large heterogeneous populations for studying photosynthesis and atherothrombosis, respectively. The technology is highly versatile and expected to enable machine-based scientific discovery in biological, pharmaceutical, and medical sciences. Artificial-intelligence-assisted, image-based flow cytometry in real-time enables rapid cell sorting based on unique chemical and morphological features. © 2018 Elsevier Inc.","cellular heterogeneity; cellular morphology; convolutional neural network; deep learning; high-throughput microscopy; high-throughput screening; image-activated cell sorting; machine intelligence","Animals; Deep Learning; Flow Cytometry; High-Throughput Screening Assays; Humans; Image Processing, Computer-Assisted; Article; automation; blood cell; cell interaction; cell selection; cell structure; Chlamydomonas reinhardtii; decision making; female; fluorescence activated cell sorting; human; human cell; image processing; intelligent image activated cell sorting; male; microalga; microscopy; molecular cloning; molecular imaging; nonhuman; normal human; photosynthesis; priority journal; protein localization; thrombocyte aggregation; animal; flow cytometry; high throughput screening; procedures","Cell Press","00928674","","CELLB","30166209","Article","Scopus","2-s2.0-85054484004"
"Al-antari M.A.; Al-masni M.A.; Choi M.-T.; Han S.-M.; Kim T.-S.","Al-antari, Mugahed A. (57189003551); Al-masni, Mohammed A. (57192575678); Choi, Mun-Taek (16229647800); Han, Seung-Moo (8564174800); Kim, Tae-Seong (36072897600)","57189003551; 57192575678; 16229647800; 8564174800; 36072897600","A fully integrated computer-aided diagnosis system for digital X-ray mammograms via deep learning detection, segmentation, and classification","2018","International Journal of Medical Informatics","287","10.1016/j.ijmedinf.2018.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048868160&doi=10.1016%2fj.ijmedinf.2018.06.003&partnerID=40&md5=336172c85fcd651de83f33323d76f57d","Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, 17104, South Korea; School of Mechanical Engineering, Sungkyunkwan University, South Korea","Al-antari M.A., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, 17104, South Korea; Al-masni M.A., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, 17104, South Korea; Choi M.-T., School of Mechanical Engineering, Sungkyunkwan University, South Korea; Han S.-M., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, 17104, South Korea; Kim T.-S., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, 17104, South Korea","A computer-aided diagnosis (CAD) system requires detection, segmentation, and classification in one framework to assist radiologists efficiently in an accurate diagnosis. In this paper, a completely integrated CAD system is proposed to screen digital X-ray mammograms involving detection, segmentation, and classification of breast masses via deep learning methodologies. In this work, to detect breast mass from entire mammograms, You-Only-Look-Once (YOLO), a regional deep learning approach, is used. To segment the mass, full resolution convolutional network (FrCN), a new deep network model, is proposed and utilized. Finally, a deep convolutional neural network (CNN) is used to recognize the mass and classify it as either benign or malignant. To evaluate the proposed integrated CAD system in terms of the accuracies of detection, segmentation, and classification, the publicly available and annotated INbreast database was utilized. The evaluation results of the proposed CAD system via four-fold cross-validation tests show that a mass detection accuracy of 98.96%, Matthews correlation coefficient (MCC) of 97.62%, and F1-score of 99.24% are achieved with the INbreast dataset. Moreover, the mass segmentation results via FrCN produced an overall accuracy of 92.97%, MCC of 85.93%, and Dice (F1-score) of 92.69% and Jaccard similarity coefficient metrics of 86.37%, respectively. The detected and segmented masses were classified via CNN and achieved an overall accuracy of 95.64%, AUC of 94.78%, MCC of 89.91%, and F1-score of 96.84%, respectively. Our results demonstrate that the proposed CAD system, through all stages of detection, segmentation, and classification, outperforms the latest conventional deep learning methodologies. Our proposed CAD system could be used to assist radiologists in all stages of detection, segmentation, and classification of breast masses. © 2018 Elsevier B.V.","Computer-aided diagnosis (CAD); Deep learning; Full resolution convolutional network (FrCN); Mass detection; Mass segmentation; You-only-look-once (YOLO)","Breast Neoplasms; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Machine Learning; Mammography; Neural Networks (Computer); Radiographic Image Enhancement; Classification (of information); Computer aided instruction; Convolution; Deep learning; Deep neural networks; Digital integrated circuits; E-learning; Image segmentation; Mammography; Neural networks; Statistical tests; X ray screens; X rays; Computer Aided Diagnosis(CAD); Convolutional networks; Mass detection; Mass segmentation; You-only-look-once (YOLO); area under the curve; Article; artificial neural network; breast cancer; breast tissue; breast tumor; cancer classification; cancer diagnosis; clinical classification; clinical evaluation; computer assisted diagnosis; controlled study; convolutional neural network; diagnostic accuracy; digital mammography; image analysis; image segmentation; outcome assessment; priority journal; transfer of learning; breast tumor; computer assisted diagnosis; female; human; image enhancement; machine learning; mammography; procedures; Computer aided diagnosis","Elsevier Ireland Ltd","13865056","","IJMIF","30032964","Article","Scopus","2-s2.0-85048868160"
"Jeong Y.; Lee S.; Park D.; Park K.H.","Jeong, Yoosoo (57193450818); Lee, Seungmin (57200005388); Park, Daejin (55463943600); Park, Kil Houm (35776805000)","57193450818; 57200005388; 55463943600; 35776805000","Accurate age estimation using multi-task Siamese network-based deep metric learning for frontal face images","2018","Symmetry","17","10.3390/sym10090385","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054356547&doi=10.3390%2fsym10090385&partnerID=40&md5=8f2524b1023874c8f045b901fe813879","School of Electronics Engineering, Kyungpook National University, Daegu, 41566, South Korea","Jeong Y., School of Electronics Engineering, Kyungpook National University, Daegu, 41566, South Korea; Lee S., School of Electronics Engineering, Kyungpook National University, Daegu, 41566, South Korea; Park D., School of Electronics Engineering, Kyungpook National University, Daegu, 41566, South Korea; Park K.H., School of Electronics Engineering, Kyungpook National University, Daegu, 41566, South Korea","Recently, there have been many studies on the automatic extraction of facial information using machine learning. Age estimation from frontal face images is becoming important, with various applications. Our proposed work is based on a binary classifier that only determines whether two input images are clustered in a similar class and trains a convolutional neural network (CNN) model using the deep metric learning method based on the Siamese network. To converge the results of the training Siamese network, two classes, for which age differences are below a certain level of distance, are considered as the same class, so the ratio of positive database images is increased. The deep metric learning method trains the CNN model to measure similarity based only on age data, but we found that the accumulated gender data can also be used to compare ages. Thus, we adopted a multi-task learning approach to consider the gender data for more accurate age estimation. In the experiment, we evaluated our approach using MORPH and MegaAge-Asian datasets, and compared gender classification accuracy only using age data from the training images. In addition, using gender classification, our proposed architecture, which is trained with only age data, performs age comparison using the self-generated gender feature. The accuracy enhancement by multi-task learning, i.e. simultaneously considering age and gender data, is discussed. Our approach results in the best accuracy among the methods based on deep metric learning on MORPH dataset. Additionally, our method has better results than the state of the art in terms of age estimation on MegaAge-Asian and MORPH datasets. © 2018 by the authors.","Age estimation; Convolutional neural network (CNN); Deep metric learning; Image classification; Multi-task learning","","MDPI AG","20738994","","","","Article","Scopus","2-s2.0-85054356547"
"Huang Y.; He N.; Chen Y.; Chen Z.; Li L.","Huang, Yu (57204608142); He, Ningning (57204516357); Chen, Yu (57204603598); Chen, Zhen (55812628400); Li, Lei (56714439800)","57204608142; 57204516357; 57204603598; 55812628400; 56714439800","                         BERMP: A cross-species classifier for predicting m                         6                         a sites by integrating a deep learning algorithm and a random forest approach                     ","2018","International Journal of Biological Sciences","80","10.7150/ijbs.27819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056315728&doi=10.7150%2fijbs.27819&partnerID=40&md5=1ca25de2e9028c0152cfd3460d6bee3f","School of Data Science and Software Engineering, Qingdao University, Qingdao, 266021, China; School of Basic Medicine, Qingdao University, Qingdao, 266021, China; Cancer institute, the Affiliated Hospital of Qingdao University, Qingdao, 266061, Shandong, China; Qingdao Cancer Institute, Qingdao, 266061, Shandong, China","Huang Y., School of Data Science and Software Engineering, Qingdao University, Qingdao, 266021, China; He N., School of Basic Medicine, Qingdao University, Qingdao, 266021, China; Chen Y., School of Data Science and Software Engineering, Qingdao University, Qingdao, 266021, China; Chen Z., School of Basic Medicine, Qingdao University, Qingdao, 266021, China; Li L., School of Data Science and Software Engineering, Qingdao University, Qingdao, 266021, China, School of Basic Medicine, Qingdao University, Qingdao, 266021, China, Cancer institute, the Affiliated Hospital of Qingdao University, Qingdao, 266061, Shandong, China, Qingdao Cancer Institute, Qingdao, 266061, Shandong, China","                             N                             6                             -methyladenosine (m                             6                             A) is a prevalent RNA methylation modification involved in several biological processes. Hundreds or thousands of m                             6                             A sites identified from different species using high-throughput experiments provides a rich resource to construct in-silico approaches for identifying m                             6                             A sites. The existing m                             6                             A predictors are developed using conventional machine-learning (ML) algorithms and most are species-centric. In this paper, we develop a novel cross-species deep-learning classifier based on bidirectional Gated Recurrent Unit (BGRU) for the prediction of m                             6                             A sites. In comparison with conventional ML approaches, BGRU achieves outstanding performance for the Mammalia dataset that contains over fifty thousand m                             6                             A sites but inferior for the Saccharomyces cerevisiae dataset that covers around a thousand positives. The accuracy of BGRU is sensitive to the data size and the sensitivity is compensated by the integration of a random forest classifier with a novel encoding of enhanced nucleic acid content. The integrated approach dubbed as BGRU-based Ensemble RNA Methylation site Predictor (BERMP) has competitive performance in both cross-validation test and independent test. BERMP also outperforms existing m                             6                             A predictors for different species. Therefore, BERMP is a novel multi-species tool for identifying m                             6                             A sites with high confidence. This classifier is freely available at http://www.bioinfogo.org/bermp.                          © Ivyspring International Publisher.","Bidirectional gated recurrent unit; Deep learning;                              N                             <sup>6</sup>                             -methyladenosine                         ; Random forest; Recurrent neural network","Adenosine; Algorithms; Computational Biology; Deep Learning; Machine Learning; Methylation; RNA; adenosine; N(6)-methyladenosine; RNA; algorithm; biology; genetics; machine learning; metabolism; methylation","Ivyspring International Publisher","14492288","","","30416381","Article","Scopus","2-s2.0-85056315728"
"Shickel B.; Tighe P.J.; Bihorac A.; Rashidi P.","Shickel, Benjamin (57192316325); Tighe, Patrick James (36198950600); Bihorac, Azra (6602479553); Rashidi, Parisa (57203185850)","57192316325; 36198950600; 6602479553; 57203185850","Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis","2018","IEEE Journal of Biomedical and Health Informatics","719","10.1109/JBHI.2017.2767063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032736236&doi=10.1109%2fJBHI.2017.2767063&partnerID=40&md5=e44a2d8fba171b1a7a4dcc2ba0f161ce","Department of Computer and Information Science, University of Florida, Gainesville, 32611, FL, United States; Department of Anesthesiology, College of Medicine, University of Florida, Gainesville, 32610, FL, United States; Department of Nephrology, College of Medicine, University of Florida, Gainesville, 32610, FL, United States; J. Crayton Pruitt Department of Biomedical Engineering, University of Florida, Gainesville, 32611, FL, United States","Shickel B., Department of Computer and Information Science, University of Florida, Gainesville, 32611, FL, United States; Tighe P.J., Department of Anesthesiology, College of Medicine, University of Florida, Gainesville, 32610, FL, United States; Bihorac A., Department of Nephrology, College of Medicine, University of Florida, Gainesville, 32610, FL, United States; Rashidi P., J. Crayton Pruitt Department of Biomedical Engineering, University of Florida, Gainesville, 32611, FL, United States","The past decade has seen an explosion in the amount of digital information stored in electronic health records (EHRs). While primarily designed for archiving patient information and performing administrative healthcare tasks like billing, many researchers have found secondary use of these records for various clinical informatics applications. Over the same period, the machine learning community has seen widespread advances in the field of deep learning. In this review, we survey the current research on applying deep learning to clinical tasks based on EHR data, where we find a variety of deep learning techniques and frameworks being applied to several types of clinical applications including information extraction, representation learning, outcome prediction, phenotyping, and deidentification. We identify several limitations of current research involving topics such as model interpretability, data heterogeneity, and lack of universal benchmarks. We conclude by summarizing the state of the field and identifying avenues of future deep EHR research. © 2013 IEEE.","Clinical informatics; deep learning; electronic health records; machine learning; survey","Deep Learning; Electronic Health Records; Humans; Clinical research; E-learning; eHealth; Learning systems; Records management; Surveying; Surveys; Clinical application; Clinical informatics; Digital information; Electronic health record; Electronic health record (EHRs); Learning techniques; Machine learning communities; Patient information; diagnostic imaging; electronic health record; electronic medical record; extraction; human; information science; machine learning; phenotype; prediction; Deep learning","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","29989977","Article","Scopus","2-s2.0-85032736236"
"Deng F.; Pu S.; Chen X.; Shi Y.; Yuan T.; Shengyan P.","Deng, Fei (57204468712); Pu, Shengliang (57203633764); Chen, Xuehong (35733584200); Shi, Yusheng (56796988900); Yuan, Ting (57203942614); Shengyan, Pu (57211721048)","57204468712; 57203633764; 35733584200; 56796988900; 57203942614; 57211721048","Hyperspectral image classification with capsule network using limited training samples","2018","Sensors (Switzerland)","120","10.3390/s18093153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053663083&doi=10.3390%2fs18093153&partnerID=40&md5=72eb65e5acb446115615d1d772e60702","School of Geodesy and Geomatics, Wuhan University, Wuhan, 430079, China; State Key Laboratory of Earth Surface Processes and Resource Ecology, Beijing Normal University, Beijing, 100875, China; State Environmental Protection Key Laboratory of Satellites Remote Sensing, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100101, China; State Key Laboratory of Geohazard Prevention and Geoenvironment Protection, Chengdu University of Technology, Chengdu, 610059, China","Deng F., School of Geodesy and Geomatics, Wuhan University, Wuhan, 430079, China; Pu S., School of Geodesy and Geomatics, Wuhan University, Wuhan, 430079, China; Chen X., State Key Laboratory of Earth Surface Processes and Resource Ecology, Beijing Normal University, Beijing, 100875, China; Shi Y., State Environmental Protection Key Laboratory of Satellites Remote Sensing, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100101, China; Yuan T., School of Geodesy and Geomatics, Wuhan University, Wuhan, 430079, China; Shengyan P., State Key Laboratory of Geohazard Prevention and Geoenvironment Protection, Chengdu University of Technology, Chengdu, 610059, China","Deep learning techniques have boosted the performance of hyperspectral image (HSI) classification. In particular, convolutional neural networks (CNNs) have shown superior performance to that of the conventional machine learning algorithms. Recently, a novel type of neural networks called capsule networks (CapsNets) was presented to improve the most advanced CNNs. In this paper, we present a modified two-layer CapsNet with limited training samples for HSI classification, which is inspired by the comparability and simplicity of the shallower deep learning models. The presented CapsNet is trained using two real HSI datasets, i.e., the PaviaU (PU) and SalinasA datasets, representing complex and simple datasets, respectively, and which are used to investigate the robustness or representation of every model or classifier. In addition, a comparable paradigm of network architecture design has been proposed for the comparison of CNN and CapsNet. Experiments demonstrate that CapsNet shows better accuracy and convergence behavior for the complex data than the state-of-the-art CNN. For CapsNet using the PU dataset, the Kappa coefficient, overall accuracy, and average accuracy are 0.9456, 95.90%, and 96.27%, respectively, compared to the corresponding values yielded by CNN of 0.9345, 95.11%, and 95.63%. Moreover, we observed that CapsNet has much higher confidence for the predicted probabilities. Subsequently, this finding was analyzed and discussed with probability maps and uncertainty analysis. In terms of the existing literature, CapsNet provides promising results and explicit merits in comparison with CNN and two baseline classifiers, i.e., random forests (RFs) and support vector machines (SVMs). © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Capsule network; Deep learning; Hyperspectral; Image classification; Possibility density","Classification (of information); Complex networks; Decision trees; Deep learning; Learning algorithms; Network architecture; Neural networks; Sampling; Spectroscopy; Support vector machines; Uncertainty analysis; Conventional machines; Convergence behaviors; Convolutional neural network; HyperSpectral; Learning techniques; Network architecture design; Possibility densities; Support vector machine (SVMs); Image classification","MDPI AG","14248220","","","30231574","Article","Scopus","2-s2.0-85053663083"
"Jiang Z.; Yu Z.; Feng S.; Huang Z.; Peng Y.; Guo J.; Ren Q.; Lu Y.","Jiang, Zhe (57203950168); Yu, Zekuan (57218290944); Feng, Shouxin (57217725187); Huang, Zhiyu (57185934800); Peng, Yahui (35085274400); Guo, Jianxin (57203950573); Ren, Qiushi (9736022400); Lu, Yanye (55542239400)","57203950168; 57218290944; 57217725187; 57185934800; 35085274400; 57203950573; 9736022400; 55542239400","A super-resolution method-based pipeline for fundus fluorescein angiography imaging 08 Information and Computing Sciences 0801 Artificial Intelligence and Image Processing Robert Koprowski","2018","BioMedical Engineering Online","13","10.1186/s12938-018-0556-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053714092&doi=10.1186%2fs12938-018-0556-7&partnerID=40&md5=412dedfabfc91817b6e57bf5af308ebb","Department of Biomedical Engineering, College of Engineering, Peking University, Beijing, 100871, China; Hospital Affiliated, Xuzhou Medical University, Xuzhou, 221006, China; School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, 100044, China; Pattern Recognition Lab, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, 91058, Germany","Jiang Z., Department of Biomedical Engineering, College of Engineering, Peking University, Beijing, 100871, China; Yu Z., Department of Biomedical Engineering, College of Engineering, Peking University, Beijing, 100871, China; Feng S., Hospital Affiliated, Xuzhou Medical University, Xuzhou, 221006, China; Huang Z., Department of Biomedical Engineering, College of Engineering, Peking University, Beijing, 100871, China; Peng Y., School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, 100044, China; Guo J., Hospital Affiliated, Xuzhou Medical University, Xuzhou, 221006, China; Ren Q., Department of Biomedical Engineering, College of Engineering, Peking University, Beijing, 100871, China; Lu Y., Pattern Recognition Lab, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, 91058, Germany","Background: Fundus fluorescein angiography (FFA) imaging is a standard diagnostic tool for many retinal diseases such as age-related macular degeneration and diabetic retinopathy. High-resolution FFA images facilitate the detection of small lesions such as microaneurysms, and other landmark changes, in the early stages; this can help an ophthalmologist improve a patient's cure rate. However, only low-resolution images are available in most clinical cases. Super-resolution (SR), which is a method to improve the resolution of an image, has been successfully employed for natural and remote sensing images. To the best of our knowledge, no one has applied SR techniques to FFA imaging so far. Methods: In this work, we propose a SR method-based pipeline for FFA imaging. The aim of this pipeline is to enhance the image quality of FFA by using SR techniques. Several SR frameworks including neighborhood embedding, sparsity-based, locally-linear regression and deep learning-based approaches are investigated. Based on a clinical FFA dataset collected from Second Affiliated Hospital to Xuzhou Medical University, each SR method is implemented and evaluated for the pipeline to improve the resolution of FFA images. Results and conclusion: As shown in our results, most SR algorithms have a positive impact on the enhancement of FFA images. Super-resolution forests (SRF), a random forest-based SR method has displayed remarkable high effectiveness and outperformed other methods. Hence, SRF should be one potential way to benefit ophthalmologists by obtaining high-resolution FFA images in a clinical setting. © 2018 The Author(s).","Convolutional network; Fundus fluorescein angiography imaging; Machine learning; Random forest; Super-resolution","Deep Learning; Eye; Fluorescein Angiography; Fundus Oculi; Humans; Image Processing, Computer-Assisted; Linear Models; Angiography; Artificial intelligence; Decision trees; Deep learning; Eye protection; Learning systems; Medical imaging; Ophthalmology; Optical resolving power; Pipelines; Remote sensing; Age-related macular degeneration; Convolutional networks; Fluorescein angiography; Learning-based approach; Low resolution images; Random forests; Super resolution; Superresolution methods; algorithm; Article; China; deep learning based approach; feasibility study; fluorescence angiography; fundus fluorescein angiography; image quality; image resolution; imaging and display; locally linear regression approach; machine learning; neighborhood embedding approach; priority journal; quantitative analysis; random forest; sparsity based approach; super resolution method; diagnostic imaging; eye; eye fundus; fluorescence angiography; human; image processing; procedures; statistical model; Image enhancement","BioMed Central Ltd.","1475925X","","BEOIB","30231879","Article","Scopus","2-s2.0-85053714092"
"Balsiger F.; Steindel C.; Arn M.; Wagner B.; Grunder L.; El-Koussy M.; Valenzuela W.; Reyes M.; Scheidegger O.","Balsiger, Fabian (57203980628); Steindel, Carolin (57204333023); Arn, Mirjam (57204309557); Wagner, Benedikt (57204309389); Grunder, Lorenz (57204330275); El-Koussy, Marwan (6602085007); Valenzuela, Waldo (57208037567); Reyes, Mauricio (16550617900); Scheidegger, Olivier (26634289200)","57203980628; 57204333023; 57204309557; 57204309389; 57204330275; 6602085007; 57208037567; 16550617900; 26634289200","Segmentation of peripheral nerves from magnetic resonance neurography: A fully-automatic, deep learning-based approach","2018","Frontiers in Neurology","30","10.3389/fneur.2018.00777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055138615&doi=10.3389%2ffneur.2018.00777&partnerID=40&md5=b97bc33db25cf0d13d0f0354f72eaa76","Institute for Surgical Technology and Biomechanics, University of Bern, Bern, Switzerland; Support Center for Advanced Neuroimaging, Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Department of Neurology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland","Balsiger F., Institute for Surgical Technology and Biomechanics, University of Bern, Bern, Switzerland; Steindel C., Support Center for Advanced Neuroimaging, Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Arn M., Support Center for Advanced Neuroimaging, Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Wagner B., Support Center for Advanced Neuroimaging, Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Grunder L., Support Center for Advanced Neuroimaging, Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; El-Koussy M., Support Center for Advanced Neuroimaging, Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Valenzuela W., Institute for Surgical Technology and Biomechanics, University of Bern, Bern, Switzerland, Support Center for Advanced Neuroimaging, Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland; Reyes M., Institute for Surgical Technology and Biomechanics, University of Bern, Bern, Switzerland; Scheidegger O., Support Center for Advanced Neuroimaging, Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland, Department of Neurology, Inselspital, Bern University Hospital, University of Bern, Bern, Switzerland","Diagnosis of peripheral neuropathies relies on neurological examinations, electrodiagnostic studies, and since recently magnetic resonance neurography (MRN). The aim of this study was to develop and evaluate a fully-automatic segmentation method of peripheral nerves of the thigh. T2-weighted sequences without fat suppression acquired on a 3 T MR scanner were retrospectively analyzed in 10 healthy volunteers and 42 patients suffering from clinically and electrophysiologically diagnosed sciatic neuropathy. A fully-convolutional neural network was developed to segment the MRN images into peripheral nerve and background tissues. The performance of the method was compared to manual inter-rater segmentation variability. The proposed method yielded Dice coefficients of 0.859 ± 0.061 and 0.719 ± 0.128, Hausdorff distances of 13.9 ± 26.6 and 12.4 ± 12.1 mm, and volumetric similarities of 0.930 ± 0.054 and 0.897 ± 0.109, for the healthy volunteer and patient cohorts, respectively. The complete segmentation process requires less than one second, which is a significant decrease to manual segmentation with an average duration of 19 ± 8 min. Considering cross-sectional area or signal intensity of the segmented nerves, focal and extended lesions might be detected. Such analyses could be used as biomarker for lesion burden, or serve as volume of interest for further quantitative MRN techniques. We demonstrated that fully-automatic segmentation of healthy and neuropathic sciatic nerves can be performed from standard MRN images with good accuracy and in a clinically feasible time. © 2007-2018 Frontiers Media S.A. All Rights Reserved.","Health; Machine learning; Magnetic resonance imaging; Magnetic resonance neurography; Peripheral nervous system diseases; Sciatic nerve; Segmentation","adult; Article; automation; clinical article; cohort analysis; controlled study; disease burden; disease marker; female; human; image analysis; image display; image processing; image segmentation; male; nerve cell network; nervous system electrophysiology; neurography; nuclear magnetic resonance imaging; peripheral neuropathy; radiological procedures; retrospective study; sciatic neuropathy; volumetry; volunteer","Frontiers Media S.A.","16642295","","","","Article","Scopus","2-s2.0-85055138615"
"Bai W.; Sinclair M.; Tarroni G.; Oktay O.; Rajchl M.; Vaillant G.; Lee A.M.; Aung N.; Lukaschuk E.; Sanghvi M.M.; Zemrak F.; Fung K.; Paiva J.M.; Carapella V.; Kim Y.J.; Suzuki H.; Kainz B.; Matthews P.M.; Petersen S.E.; Piechnik S.K.; Neubauer S.; Glocker B.; Rueckert D.","Bai, Wenjia (55570917300); Sinclair, Matthew (55785798200); Tarroni, Giacomo (37079629700); Oktay, Ozan (36782675600); Rajchl, Martin (54973905500); Vaillant, Ghislain (57193156406); Lee, Aaron M. (57193254265); Aung, Nay (55785914100); Lukaschuk, Elena (57203083063); Sanghvi, Mihir M. (57191709852); Zemrak, Filip (53865866400); Fung, Kenneth (57191706862); Paiva, Jose Miguel (57191707562); Carapella, Valentina (55785335200); Kim, Young Jin (57192961908); Suzuki, Hideaki (55704215100); Kainz, Bernhard (25937325100); Matthews, Paul M. (7202324607); Petersen, Steffen E. (35430477200); Piechnik, Stefan K. (7004664392); Neubauer, Stefan (55794522200); Glocker, Ben (23396784900); Rueckert, Daniel (7004895812)","55570917300; 55785798200; 37079629700; 36782675600; 54973905500; 57193156406; 57193254265; 55785914100; 57203083063; 57191709852; 53865866400; 57191706862; 57191707562; 55785335200; 57192961908; 55704215100; 25937325100; 7202324607; 35430477200; 7004664392; 55794522200; 23396784900; 7004895812","Automated cardiovascular magnetic resonance image analysis with fully convolutional networks 08 Information and Computing Sciences 0801 Artificial Intelligence and Image Processing","2018","Journal of Cardiovascular Magnetic Resonance","396","10.1186/s12968-018-0471-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053360253&doi=10.1186%2fs12968-018-0471-x&partnerID=40&md5=030e9f6e6b9837450f9054dea03f8ab8","Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; NIHR, Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom; Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Division of Brain Sciences, Department of Medicine, Imperial College London, London, United Kingdom","Bai W., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; Sinclair M., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; Tarroni G., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; Oktay O., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; Rajchl M., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; Vaillant G., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; Lee A.M., NIHR, Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom; Aung N., NIHR, Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom; Lukaschuk E., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Sanghvi M.M., NIHR, Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom; Zemrak F., NIHR, Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom; Fung K., NIHR, Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom; Paiva J.M., NIHR, Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom; Carapella V., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Kim Y.J., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Suzuki H., Division of Brain Sciences, Department of Medicine, Imperial College London, London, United Kingdom; Kainz B., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; Matthews P.M., Division of Brain Sciences, Department of Medicine, Imperial College London, London, United Kingdom; Petersen S.E., NIHR, Biomedical Research Centre at Barts, Queen Mary University of London, London, United Kingdom; Piechnik S.K., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Neubauer S., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Glocker B., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom; Rueckert D., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, United Kingdom","Background: Cardiovascular resonance (CMR) imaging is a standard imaging modality for assessing cardiovascular diseases (CVDs), the leading cause of death globally. CMR enables accurate quantification of the cardiac chamber volume, ejection fraction and myocardial mass, providing information for diagnosis and monitoring of CVDs. However, for years, clinicians have been relying on manual approaches for CMR image analysis, which is time consuming and prone to subjective errors. It is a major clinical challenge to automatically derive quantitative and clinically relevant information from CMR images. Methods: Deep neural networks have shown a great potential in image pattern recognition and segmentation for a variety of tasks. Here we demonstrate an automated analysis method for CMR images, which is based on a fully convolutional network (FCN). The network is trained and evaluated on a large-scale dataset from the UK Biobank, consisting of 4,875 subjects with 93,500 pixelwise annotated images. The performance of the method has been evaluated using a number of technical metrics, including the Dice metric, mean contour distance and Hausdorff distance, as well as clinically relevant measures, including left ventricle (LV) end-diastolic volume (LVEDV) and end-systolic volume (LVESV), LV mass (LVM); right ventricle (RV) end-diastolic volume (RVEDV) and end-systolic volume (RVESV). Results: By combining FCN with a large-scale annotated dataset, the proposed automated method achieves a high performance in segmenting the LV and RV on short-axis CMR images and the left atrium (LA) and right atrium (RA) on long-axis CMR images. On a short-axis image test set of 600 subjects, it achieves an average Dice metric of 0.94 for the LV cavity, 0.88 for the LV myocardium and 0.90 for the RV cavity. The mean absolute difference between automated measurement and manual measurement is 6.1 mL for LVEDV, 5.3 mL for LVESV, 6.9 gram for LVM, 8.5 mL for RVEDV and 7.2 mL for RVESV. On long-axis image test sets, the average Dice metric is 0.93 for the LA cavity (2-chamber view), 0.95 for the LA cavity (4-chamber view) and 0.96 for the RA cavity (4-chamber view). The performance is comparable to human inter-observer variability. Conclusions: We show that an automated method achieves a performance on par with human experts in analysing CMR images and deriving clinically relevant measures. © 2018 The Author(s).","CMR image analysis; Fully convolutional networks; Machine learning","Aged; Automation; Databases, Factual; Deep Learning; Female; Heart Diseases; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging, Cine; Male; Middle Aged; Myocardial Contraction; Neural Networks (Computer); Observer Variation; Predictive Value of Tests; Reproducibility of Results; Stroke Volume; Ventricular Function, Left; Ventricular Function, Right; adult; Article; artificial neural network; automation; biobank; cardiac imaging; cardiovascular magnetic resonance; controlled study; Dice metric; female; fully convolutional network; Hausdorff distance; heart left atrium; heart left ventricle; heart left ventricle enddiastolic volume; heart left ventricle endsystolic volume; heart left ventricle mass; heart right atrium; heart right ventricle; heart right ventricle enddiastolic volume; heart right ventricle endsystolic volume; human; image analysis; image segmentation; major clinical study; male; mean contour distance; observer variation; pattern recognition; priority journal; radiological parameters; United Kingdom; aged; automation; cine magnetic resonance imaging; computer assisted diagnosis; diagnostic imaging; factual database; heart contraction; heart disease; heart left ventricle function; heart right ventricle function; heart stroke volume; middle aged; pathophysiology; predictive value; procedures; reproducibility","BioMed Central Ltd.","10976647","","JCMRF","30217194","Article","Scopus","2-s2.0-85053360253"
"Liberis E.; Velickovic P.; Sormanni P.; Vendruscolo M.; Lio P.","Liberis, Edgar (57204238276); Velickovic, Petar (57190809820); Sormanni, Pietro (55159736800); Vendruscolo, Michele (7007094071); Lio, Pietro (7004223170)","57204238276; 57190809820; 55159736800; 7007094071; 7004223170","Parapred: Antibody paratope prediction using convolutional and recurrent neural networks","2018","Bioinformatics","92","10.1093/bioinformatics/bty305","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055038688&doi=10.1093%2fbioinformatics%2fbty305&partnerID=40&md5=6dac9bb333ff3639ed7bb2f6d56a172e","Department of Computer Science and Technology, University of Cambridge, CB3 0FD, United Kingdom; Department of Chemistry, University of Cambridge, CB2 1EW, United Kingdom","Liberis E., Department of Computer Science and Technology, University of Cambridge, CB3 0FD, United Kingdom; Velickovic P., Department of Computer Science and Technology, University of Cambridge, CB3 0FD, United Kingdom; Sormanni P., Department of Chemistry, University of Cambridge, CB2 1EW, United Kingdom; Vendruscolo M., Department of Chemistry, University of Cambridge, CB2 1EW, United Kingdom; Lio P., Department of Computer Science and Technology, University of Cambridge, CB3 0FD, United Kingdom","Motivation: Antibodies play essential roles in the immune system of vertebrates and are powerful tools in research and diagnostics. While hypervariable regions of antibodies, which are responsible for binding, can be readily identified from their amino acid sequence, it remains challenging to accurately pinpoint which amino acids will be in contact with the antigen (the paratope). Results: In this work, we present a sequence-based probabilistic machine learning algorithm for paratope prediction, named Parapred. Parapred uses a deep-learning architecture to leverage features from both local residue neighbourhoods and across the entire sequence. The method significantly improves on the current state-of-the-art methodology, and only requires a stretch of amino acid sequence corresponding to a hypervariable region as an input, without any information about the antigen. We further show that our predictions can be used to improve both speed and accuracy of a rigid docking algorithm. © The Author(s) 2018. Published by Oxford University Press. All rights reserved.","","Algorithms; Amino Acid Sequence; Antibodies; Binding Sites, Antibody; Deep Learning; Machine Learning; Models, Molecular; Neural Networks (Computer); antibody; algorithm; amino acid sequence; antibody combining site; artificial neural network; chemistry; immunology; machine learning; molecular model","Oxford University Press","13674803","","BOINF","29672675","Article","Scopus","2-s2.0-85055038688"
"Lynch C.J.; Liston C.","Lynch, Charles J. (55573394600); Liston, Conor (6602080355)","55573394600; 6602080355","New machine-learning technologies for computer-aided diagnosis","2018","Nature Medicine","69","10.1038/s41591-018-0178-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053393334&doi=10.1038%2fs41591-018-0178-4&partnerID=40&md5=39461cd1cece4e3b01dcf2cf15937959","Feil Family Brain and Mind Research Institute, Weill Cornell Medical College, New York, NY, United States; Department of Psychiatry, Weill Cornell Medical College, New York, NY, United States; Sackler Institute for Developmental Psychobiology, Weill Cornell Medical College, New York, NY, United States","Lynch C.J., Feil Family Brain and Mind Research Institute, Weill Cornell Medical College, New York, NY, United States; Liston C., Feil Family Brain and Mind Research Institute, Weill Cornell Medical College, New York, NY, United States, Department of Psychiatry, Weill Cornell Medical College, New York, NY, United States, Sackler Institute for Developmental Psychobiology, Weill Cornell Medical College, New York, NY, United States","[No abstract available]","","Deep Learning; Diagnosis, Computer-Assisted; Humans; Machine Learning; Referral and Consultation; Retinal Diseases; Article; artificial intelligence; artificial neural network; brain hemorrhage; cerebrovascular accident; classification algorithm; clinical outcome; computer assisted diagnosis; computer assisted tomography; deep neural network; diagnostic imaging; human; machine learning; natural language processing; optical coherence tomography; priority journal; retina disease; treatment outcome; computer assisted diagnosis; machine learning; patient referral; retina disease","Nature Publishing Group","10788956","","NAMEF","30177823","Article","Scopus","2-s2.0-85053393334"
"Qiao H.; Wang T.; Wang P.; Qiao S.; Zhang L.","Qiao, Huihui (57195062627); Wang, Taiyong (7405563562); Wang, Peng (57201553046); Qiao, Shibin (57200257368); Zhang, Lan (57203823537)","57195062627; 7405563562; 57201553046; 57200257368; 57203823537","A time-distributed spatiotemporal feature learning method for machine health monitoring with multi-sensor time series","2018","Sensors (Switzerland)","97","10.3390/s18092932","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053080643&doi=10.3390%2fs18092932&partnerID=40&md5=633b3bc1aa9c53e40c1b93fa46db7ba1","Key Laboratory of Mechanism Theory and Equipment Design of Ministry of Education, Tianjin University, Tianjin, 300350, China; School of Mechanical Engineering, Tianjin University, Tianjin, 300354, China; Institute for Special Steels, Central Iron and Steel Research Institute, Beijing, 100081, China","Qiao H., Key Laboratory of Mechanism Theory and Equipment Design of Ministry of Education, Tianjin University, Tianjin, 300350, China, School of Mechanical Engineering, Tianjin University, Tianjin, 300354, China; Wang T., Key Laboratory of Mechanism Theory and Equipment Design of Ministry of Education, Tianjin University, Tianjin, 300350, China, School of Mechanical Engineering, Tianjin University, Tianjin, 300354, China; Wang P., Key Laboratory of Mechanism Theory and Equipment Design of Ministry of Education, Tianjin University, Tianjin, 300350, China, School of Mechanical Engineering, Tianjin University, Tianjin, 300354, China; Qiao S., Institute for Special Steels, Central Iron and Steel Research Institute, Beijing, 100081, China; Zhang L., Key Laboratory of Mechanism Theory and Equipment Design of Ministry of Education, Tianjin University, Tianjin, 300350, China, School of Mechanical Engineering, Tianjin University, Tianjin, 300354, China","Data-driven methods with multi-sensor time series data are the most promising approaches for monitoring machine health. Extracting fault-sensitive features from multi-sensor time series is a daunting task for both traditional data-driven methods and current deep learning models. A novel hybrid end-to-end deep learning framework named Time-distributed ConvLSTM model (TDConvLSTM) is proposed in the paper for machine health monitoring, which works directly on raw multi-sensor time series. In TDConvLSTM, the normalized multi-sensor data is first segmented into a collection of subsequences by a sliding window along the temporal dimension. Time-distributed local feature extractors are simultaneously applied to each subsequence to extract local spatiotemporal features. Then a holistic ConvLSTM layer is designed to extract holistic spatiotemporal features between subsequences. At last, a fully-connected layer and a supervised learning layer are stacked on the top of the model to obtain the target. TDConvLSTM can extract spatiotemporal features on different time scales without any handcrafted feature engineering. The proposed model can achieve better performance in both time series classification tasks and regression prediction tasks than some state-of-the-art models, which has been verified in the gearbox fault diagnosis experiment and the tool wear prediction experiment. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Machine health monitoring; Multi-sensor time series; Spatiotemporal feature learning; Time-distributed ConvLSTM model","Deep Learning; Health; Humans; Monitoring, Physiologic; Time Factors; Computer aided diagnosis; Fault detection; Time series; Diagnosis experiments; Feature engineerings; Fully-connected layers; Machine health monitoring; Multi sensor; Regression predictions; Spatio temporal features; Time series classifications; health; human; physiologic monitoring; procedures; time factor; Deep learning","MDPI AG","14248220","","","30177670","Article","Scopus","2-s2.0-85053080643"
"Akbulut A.; Ertugrul E.; Topcu V.","Akbulut, Akhan (25960607500); Ertugrul, Egemen (57201358340); Topcu, Varol (57202455920)","25960607500; 57201358340; 57202455920","Fetal health status prediction based on maternal clinical history using machine learning techniques","2018","Computer Methods and Programs in Biomedicine","72","10.1016/j.cmpb.2018.06.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048422714&doi=10.1016%2fj.cmpb.2018.06.010&partnerID=40&md5=29d4a131c6763e07112045e83c4f824e","Department of Computer Science, North Carolina State University, Raleigh, 27606, NC, United States; Department of Computer Engineering, Istanbul Kultur University, Atakoy Campus Bakirkoy, Istanbul, 34156, Turkey","Akbulut A., Department of Computer Science, North Carolina State University, Raleigh, 27606, NC, United States, Department of Computer Engineering, Istanbul Kultur University, Atakoy Campus Bakirkoy, Istanbul, 34156, Turkey; Ertugrul E., Department of Computer Engineering, Istanbul Kultur University, Atakoy Campus Bakirkoy, Istanbul, 34156, Turkey; Topcu V., Department of Computer Engineering, Istanbul Kultur University, Atakoy Campus Bakirkoy, Istanbul, 34156, Turkey","Background and Objective: Congenital anomalies are seen at 1–3% of the population, probabilities of which are tried to be found out primarily through double, triple and quad tests during pregnancy. Also, ultrasonographical evaluations of fetuses enhance detecting and defining these abnormalities. About 60–70% of the anomalies can be diagnosed via ultrasonography, while the remaining 30–40% can be diagnosed after childbirth. Medical diagnosis and prediction is a topic that is closely related with e-Health and machine learning. e-Health applications are critically important especially for the patients unable to see a doctor or any health professional. Our objective is to help clinicians and families to better predict fetal congenital anomalies besides the traditional pregnancy tests using machine learning techniques and e-Health applications. Methods: In this work, we developed a prediction system with assistive e-Health applications which both the pregnant women and practitioners can make use of. A performance comparison (considering Accuracy, F1-Score, AUC measures) was made between 9 binary classification models (Averaged Perceptron, Boosted Decision Tree, Bayes Point Machine, Decision Forest, Decision Jungle, Locally-Deep Support Vector Machine, Logistic Regression, Neural Network, Support Vector Machine) which were trained with the clinical dataset of 96 pregnant women and used to process data to predict fetal anomaly status based on the maternal and clinical data. The dataset was obtained through maternal questionnaire and detailed evaluations of 3 clinicians from RadyoEmar radiodiagnostics center in Istanbul, Turkey. Our e-Health applications are used to get pregnant women's health status and clinical history parameters as inputs, recommend them physical activities to perform during pregnancy, and inform the practitioners and finally the patients about possible risks of fetal anomalies as the output. Results: In this paper, the highest accuracy of prediction was displayed as 89.5% during the development tests with Decision Forest model. In real life testing with 16 users, the performance was 87.5%. This estimate is sufficient to give an idea of fetal health before the patient visits the physician. Conclusions: The proposed work aims to provide assistive services to pregnant women and clinicians via an online system consisting of a mobile side for the patients, a web application side for their clinicians and a prediction system. In addition, we showed the impact of certain clinical data parameters of pregnant on the fetal health status, statistically correlated the parameters with the existence of fetal anomalies and showed guidelines for future researches. © 2018 Elsevier B.V.","Fetal health; m-Health; Machine learning; Medical diagnosis; Pregnancy; Prognosis; Risk prediction","Algorithms; Area Under Curve; Bayes Theorem; Congenital Abnormalities; Decision Trees; Diagnosis, Computer-Assisted; Female; Fetus; Health Status; Humans; Internet; Logistic Models; Machine Learning; Mobile Applications; Perception; Pregnancy; Regression Analysis; Reproducibility of Results; ROC Curve; Support Vector Machine; Telemedicine; Ultrasonography, Prenatal; Artificial intelligence; Binary trees; Classification (of information); Clinical research; Decision trees; Diagnosis; Forestry; Health risks; Learning algorithms; Learning systems; mHealth; Obstetrics; Online systems; Support vector machines; Binary classification; Boosted decision trees; e-Health applications; Machine learning techniques; Performance comparison; Pregnancy; Prognosis; Risk predictions; adult; Article; classification algorithm; clinical study; decision tree; family history; female; fetus malformation; health status; human; machine learning; major clinical study; medical history; online system; perceptron; physical activity; prediction; pregnant woman; risk factor; telehealth; Turkey (republic); algorithm; area under the curve; Bayes theorem; computer assisted diagnosis; congenital disorder; fetus; fetus echography; health status; Internet; mobile application; perception; physiology; pregnancy; procedures; receiver operating characteristic; regression analysis; reproducibility; statistical model; support vector machine; telemedicine; Forecasting","Elsevier Ireland Ltd","01692607","","CMPBE","30119860","Article","Scopus","2-s2.0-85048422714"
"Keren L.; Bosse M.; Marquez D.; Angoshtari R.; Jain S.; Varma S.; Yang S.-R.; Kurian A.; Van Valen D.; West R.; Bendall S.C.; Angelo M.","Keren, Leeat (36463856100); Bosse, Marc (57198293205); Marquez, Diana (57204345091); Angoshtari, Roshan (58697772300); Jain, Samir (57203758847); Varma, Sushama (7203029389); Yang, Soo-Ryum (57200753071); Kurian, Allison (56730290700); Van Valen, David (26327043800); West, Robert (36041739200); Bendall, Sean C. (14629875200); Angelo, Michael (57196539866)","36463856100; 57198293205; 57204345091; 58697772300; 57203758847; 7203029389; 57200753071; 56730290700; 26327043800; 36041739200; 14629875200; 57196539866","A Structured Tumor-Immune Microenvironment in Triple Negative Breast Cancer Revealed by Multiplexed Ion Beam Imaging","2018","Cell","572","10.1016/j.cell.2018.08.039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052874515&doi=10.1016%2fj.cell.2018.08.039&partnerID=40&md5=75051369393f8e997672877201a499d9","Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Department of Biology, Caltech, Pasadena, 91125, CA, United States; Department of Bioengineering, Caltech, Pasadena, 91125, CA, United States","Keren L., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Bosse M., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Marquez D., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Angoshtari R., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Jain S., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Varma S., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Yang S.-R., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Kurian A., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Van Valen D., Department of Biology, Caltech, Pasadena, 91125, CA, United States, Department of Bioengineering, Caltech, Pasadena, 91125, CA, United States; West R., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Bendall S.C., Department of Pathology, Stanford University, Stanford, 94305, CA, United States; Angelo M., Department of Pathology, Stanford University, Stanford, 94305, CA, United States","The immune system is critical in modulating cancer progression, but knowledge of immune composition, phenotype, and interactions with tumor is limited. We used multiplexed ion beam imaging by time-of-flight (MIBI-TOF) to simultaneously quantify in situ expression of 36 proteins covering identity, function, and immune regulation at sub-cellular resolution in 41 triple-negative breast cancer patients. Multi-step processing, including deep-learning-based segmentation, revealed variability in the composition of tumor-immune populations across individuals, reconciled by overall immune infiltration and enriched co-occurrence of immune subpopulations and checkpoint expression. Spatial enrichment analysis showed immune mixed and compartmentalized tumors, coinciding with expression of PD1, PD-L1, and IDO in a cell-type- and location-specific manner. Ordered immune structures along the tumor-immune border were associated with compartmentalization and linked to survival. These data demonstrate organization in the tumor-immune microenvironment that is structured in cellular composition, spatial arrangement, and regulatory-protein expression and provide a framework to apply multiplexed imaging to immune oncology. A combination of multiplexed imaging and machine learning reveals that spatial organization of immune phenotypes within triple-negative breast tumors is linked to survival. © 2018 Elsevier Inc.","Breast Cancer; Checkpoint; Imaging; Mass spectrometry; MIBI; Multiplexed Ion Beam Imaging; Proteomics; Systems Biology; Tumor Immunology; Tumor Microenvironment","Antigens, CD; B7-H1 Antigen; Cluster Analysis; Female; Humans; Indoleamine-Pyrrole 2,3,-Dioxygenase; Kaplan-Meier Estimate; Lymphocytes; Machine Learning; Mass Spectrometry; Principal Component Analysis; Programmed Cell Death 1 Receptor; Spatial Analysis; Triple Negative Breast Neoplasms; Tumor Microenvironment; indoleamine 2,3 dioxygenase; programmed death 1 ligand 1; programmed death 1 receptor; CD223 antigen; CD274 protein, human; indoleamine 2,3 dioxygenase; leukocyte antigen; PDCD1 protein, human; programmed death 1 ligand 1; programmed death 1 receptor; Article; cancer survival; cell compartmentalization; cell structure; controlled study; human; human cell; human tissue; image segmentation; imaging; immune system; immunocompetent cell; immunoregulation; multiplexed ion beam imaging; priority journal; protein expression; protein localization; time of flight mass spectrometry; triple negative breast cancer; tumor immune microenvironment; tumor microenvironment; cluster analysis; cytology; diagnostic imaging; female; immunology; Kaplan Meier method; lymphocyte; machine learning; mass spectrometry; metabolism; mortality; pathology; principal component analysis; spatial analysis; triple negative breast cancer; tumor microenvironment","Cell Press","00928674","","CELLB","30193111","Article","Scopus","2-s2.0-85052874515"
"Hassanzadeh H.; Nguyen A.; Karimi S.; Chu K.","Hassanzadeh, Hamed (35731433800); Nguyen, Anthony (36741156200); Karimi, Sarvnaz (35302172500); Chu, Kevin (7402453625)","35731433800; 36741156200; 35302172500; 7402453625","Transferability of artificial neural networks for clinical document classification across hospitals: A case study on abnormality detection from radiology reports","2018","Journal of Biomedical Informatics","16","10.1016/j.jbi.2018.07.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050820681&doi=10.1016%2fj.jbi.2018.07.017&partnerID=40&md5=6e2a74ff22d8b9b89cca1496f2c3a0e3","The Australian e-Health Research Centre, CSIRO, Brisbane, Australia; Data61, CSIRO, Sydney, Australia; Royal Brisbane and Women's Hospital, Queensland Health, Brisbane, Australia","Hassanzadeh H., The Australian e-Health Research Centre, CSIRO, Brisbane, Australia; Nguyen A., The Australian e-Health Research Centre, CSIRO, Brisbane, Australia; Karimi S., Data61, CSIRO, Sydney, Australia; Chu K., Royal Brisbane and Women's Hospital, Queensland Health, Brisbane, Australia","Objective: Application of machine learning techniques for automatic and reliable classification of clinical documents have shown promising results. However, machine learning models require abundant training data specific to each target hospital and may not be able to benefit from available labeled data from each of the hospitals due to data variations. Such training data limitations have presented one of the major obstacles for maximising potential application of machine learning approaches in the healthcare domain. We investigated transferability of artificial neural network models across hospitals from different domains representing various age demographic groups (i.e., children, adults, and mixed) in order to cope with such limitations. Materials and methods: We explored the transferability of artificial neural networks for clinical document classification. Our case study was to detect abnormalities from limb X-ray reports obtained from the emergency department (ED) of three hospitals within different domains. Different transfer learning scenarios were investigated in order to employ a source hospital's trained model for addressing a target hospital's abnormality detection problem. Results: A Convolutional Neural Network (CNN) model exhibited the best effectiveness compared to other networks when employing an embedding model trained on a large corpus of clinical documents. Furthermore, CNN models derived from a source hospital outperformed a conventional machine learning approach based on Support Vector Machines (SVM) when applied to a different (target) hospital. These models were further improved by leveraging available training data in target hospitals and outperformed the models that used only the target hospital data with F1-Score of 0.92–0.96 across three hospitals. Discussion: Our transfer learning model used only simple vector representations of documents without any task-specific feature engineering. Transferring the CNN model significantly improved (approx.10% in F1-Score) the state-of-the-art approach for clinical document classification based on a trivial transferred model. In addition, the results showed that transfer learning techniques can further improve a CNN model that is trained only on either a source or target hospital's data. Conclusion: Transferring a pre-trained CNN model generated in one hospital to another facilitates application of machine learning approaches that alleviate both hospital-specific feature engineering and training data. © 2018 Elsevier Inc.","Clinical document classification; Deep learning; Machine learning; Radiology report; Transfer learning","Algorithms; Computational Biology; Databases, Factual; Deep Learning; Humans; Machine Learning; Neural Networks (Computer); Radiographic Image Interpretation, Computer-Assisted; Radiography; Support Vector Machine; Deep learning; Information retrieval systems; Learning algorithms; Learning systems; Neural networks; Radiation; Radiology; Support vector machines; Artificial neural network models; Convolutional Neural Networks (CNN); Document Classification; Machine learning approaches; Machine learning techniques; Radiology reports; State-of-the-art approach; Transfer learning; adult; age distribution; Article; artificial neural network; bone radiography; child; classification algorithm; clinical classification; clinical effectiveness; clinical practice; convolutional neural network; emergency care; hospital; human; learning algorithm; machine learning; medical documentation; practice guideline; priority journal; radiology; algorithm; biology; computer assisted diagnosis; factual database; radiography; support vector machine; Hospitals","Academic Press Inc.","15320464","","JBIOB","30026067","Article","Scopus","2-s2.0-85050820681"
"Ishioka J.; Matsuoka Y.; Uehara S.; Yasuda Y.; Kijima T.; Yoshida S.; Yokoyama M.; Saito K.; Kihara K.; Numao N.; Kimura T.; Kudo K.; Kumazawa I.; Fujii Y.","Ishioka, Junichiro (35508319900); Matsuoka, Yoh (7402638392); Uehara, Sho (56637749100); Yasuda, Yosuke (37038739300); Kijima, Toshiki (24315028900); Yoshida, Soichiro (8900061700); Yokoyama, Minato (7403277743); Saito, Kazutaka (24796590900); Kihara, Kazunori (7102295927); Numao, Noboru (14519685000); Kimura, Tomo (57195149566); Kudo, Kosei (57203743861); Kumazawa, Itsuo (55943452700); Fujii, Yasuhisa (7403409367)","35508319900; 7402638392; 56637749100; 37038739300; 24315028900; 8900061700; 7403277743; 24796590900; 7102295927; 14519685000; 57195149566; 57203743861; 55943452700; 7403409367","Computer-aided diagnosis of prostate cancer on magnetic resonance imaging using a convolutional neural network algorithm","2018","BJU International","89","10.1111/bju.14397","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052817216&doi=10.1111%2fbju.14397&partnerID=40&md5=3e94671488b5aeff71af8d54faff9b96","Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Department of Urology, Cancer Institute Hospital, Japanese Foundation for Cancer Research, Tokyo, Japan; Department of Radiology, Ochanomizu Surugadai Clinic, Tokyo, Japan; Department of Information and Communication Engineering, Tokyo Institute of Technology, Tokyo, Japan; Laboratory for Future Interdisciplinary Research of Science and Technology, Tokyo Institute of Innovative Research, Tokyo, Japan","Ishioka J., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Matsuoka Y., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Uehara S., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Yasuda Y., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Kijima T., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Yoshida S., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Yokoyama M., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Saito K., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Kihara K., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan; Numao N., Department of Urology, Cancer Institute Hospital, Japanese Foundation for Cancer Research, Tokyo, Japan; Kimura T., Department of Radiology, Ochanomizu Surugadai Clinic, Tokyo, Japan; Kudo K., Department of Information and Communication Engineering, Tokyo Institute of Technology, Tokyo, Japan; Kumazawa I., Laboratory for Future Interdisciplinary Research of Science and Technology, Tokyo Institute of Innovative Research, Tokyo, Japan; Fujii Y., Department of Urology, Tokyo Medical and Dental University Graduate School, Tokyo, Japan","Objective: To develop a computer-aided diagnosis (CAD) algorithm with a deep learning architecture for detecting prostate cancer on magnetic resonance imaging (MRI) to promote global standardisation and diminish variation in the interpretation of prostate MRI. Patients and Methods: We retrospectively reviewed data from 335 patients with a prostate-specific antigen level of <20 ng/mL who underwent MRI and extended systematic prostate biopsy with or without MRI-targeted biopsy. The data were divided into a training data set (n = 301), which was used to develop the CAD algorithm, and two evaluation data sets (n = 34). A deep convolutional neural network (CNN) was trained using MR images labelled as ‘cancer’ or ‘no cancer’ confirmed by the above-mentioned biopsy. Using the CAD algorithm that showed the best diagnostic accuracy with the two evaluation data sets, the data set not used for evaluation was analysed, and receiver operating curve analysis was performed. Results: Graphics processing unit computing required 5.5 h to learn to analyse 2 million images. The time required for the CAD algorithm to evaluate a new image was 30 ms/image. The two algorithms showed area under the curve values of 0.645 and 0.636, respectively, in the validation data sets. The number of patients mistakenly diagnosed as having cancer was 16/17 patients and seven of 17 patients in the two validation data sets, respectively. Zero and two oversights were found in the two validation data sets, respectively. Conclusion: We developed a CAD system using a CNN algorithm for the fully automated detection of prostate cancer using MRI, which has the potential to provide reproducible interpretation and a greater level of standardisation and consistency. © 2018 The Authors BJU International © 2018 BJU International Published by John Wiley & Sons Ltd","#PCSM; #ProstateCancer; computer-aided diagnosis; deep learning; magnetic resonance imaging; neural network; prostate biopsy","Adult; Aged; Aged, 80 and over; Algorithms; Area Under Curve; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Neural Networks (Computer); Prostate; Prostatic Neoplasms; Retrospective Studies; prostate specific antigen; adult; aged; Article; artificial neural network; cancer diagnosis; cancer grading; computer assisted diagnosis; diagnostic accuracy; diagnostic error; human; human tissue; image analysis; machine learning; major clinical study; male; nuclear magnetic resonance imaging; priority journal; prostate biopsy; prostate cancer; receiver operating characteristic; retrospective study; standardization; algorithm; area under the curve; artificial neural network; computer assisted diagnosis; diagnostic imaging; middle aged; nuclear magnetic resonance imaging; pathology; procedures; prostate; prostate tumor; very elderly","Blackwell Publishing Ltd","14644096","","BJINF","29772101","Article","Scopus","2-s2.0-85052817216"
"Rodríguez-Pérez R.; Bajorath J.","Rodríguez-Pérez, Raquel (57194069554); Bajorath, Jürgen (7101742328)","57194069554; 7101742328","Prediction of Compound Profiling Matrices, Part II: Relative Performance of Multitask Deep Learning and Random Forest Classification on the Basis of Varying Amounts of Training Data","2018","ACS Omega","19","10.1021/acsomega.8b01682","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054307748&doi=10.1021%2facsomega.8b01682&partnerID=40&md5=b562c6cc2618d019820213b960d3fe6d","Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany; Department of Medicinal Chemistry, Boehringer Ingelheim Pharma GmbH and Co. KG, Birkendorfer Str. 65, Biberach/Riß, 88397, Germany","Rodríguez-Pérez R., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany, Department of Medicinal Chemistry, Boehringer Ingelheim Pharma GmbH and Co. KG, Birkendorfer Str. 65, Biberach/Riß, 88397, Germany; Bajorath J., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany","Currently, there is a high level of interest in deep learning and multitask learning in many scientific fields including the life sciences and chemistry. Herein, we investigate the performance of multitask deep neural networks (MT-DNNs) compared to random forest (RF) classification, a standard method in machine learning, in predicting compound profiling experiments. Predictions were carried out on a large profiling matrix extracted from biological screening data. For model building, submatrices with varying data density of 5-100% were generated to investigate the influence of data sparseness on prediction performance. MT-DNN models were directly compared to RF models, and control calculations were also carried out using single-task DNNs (ST-DNNs). On the basis of compound recall, the performance of ST-DNN was consistently lower than that of the other methods. Compared to RF, MT-DNN models only yielded better prediction performance for individual assays in the profiling matrix when training data were very sparse. However, when the matrix density increased to at least 25-45%, per-assay RF models met or partly exceeded the prediction performance of MT-DNN models. When the average performances of RF and MT-DNN over the grid of all targets were compared, MT-DNN was slightly superior to RF, which was a likely consequence of multitask learning. Overall, there was no consistent advantage of MT-DNN over standard RF classification in predicting the results of compound profiling assays under varying conditions. In the presence of very sparse training data, prediction performance was limited. Under these challenging conditions, MT-DNN was the preferred approach. When more training data became available and prediction performance increased, RF performance was not inferior to MT-DNN. Copyright © 2018 American Chemical Society.","","","American Chemical Society","24701343","","","","Article","Scopus","2-s2.0-85054307748"
"de Oliveira M.A.; Monteiro A.V.; Filho J.V.","de Oliveira, Mario A. (25638400800); Monteiro, Andre V. (57203823426); Filho, Jozue Vieira (36697468800)","25638400800; 57203823426; 36697468800","A new structural health monitoring strategy based on PZT sensors and convolutional neural network","2018","Sensors (Switzerland)","115","10.3390/s18092955","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053082391&doi=10.3390%2fs18092955&partnerID=40&md5=1ef0b82ae4609a99e06c58e10effe951","Department of Electrical and Electronic, Mato Grosso Federal Institute of Technology, Cuiabá, 78005-200, Brazil; São Paulo State University (UNESP), Campus of São João da Boa Vista, São Paulo, 13876-750, Brazil","de Oliveira M.A., Department of Electrical and Electronic, Mato Grosso Federal Institute of Technology, Cuiabá, 78005-200, Brazil; Monteiro A.V., Department of Electrical and Electronic, Mato Grosso Federal Institute of Technology, Cuiabá, 78005-200, Brazil; Filho J.V., São Paulo State University (UNESP), Campus of São João da Boa Vista, São Paulo, 13876-750, Brazil","Preliminaries convolutional neural network (CNN) applications have recently emerged in structural health monitoring (SHM) systems focusing mostly on vibration analysis. However, the SHM literature shows clearly that there is a lack of application regarding the combination of PZT-(lead zirconate titanate) based method and CNN. Likewise, applications using CNN along with the electromechanical impedance (EMI) technique applied to SHM systems are rare. To encourage this combination, an innovative SHM solution through the combination of the EMI-PZT and CNN is presented here. To accomplish this, the EMI signature is split into several parts followed by computing the Euclidean distances among them to form a RGB (red, green and blue) frame. As a result, we introduce a dataset formed from the EMI-PZT signals of 720 frames, encompassing a total of four types of structural conditions for each PZT. In a case study, the CNN-based method was experimentally evaluated using three PZTs glued onto an aluminum plate. The results reveal an effective pattern classification; yielding a 100% hit rate which outperforms other SHM approaches. Furthermore, the method needs only a small dataset for training the CNN, providing several advantages for industrial applications. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","CNN; Deep learning; Electromechanical impedance; Intelligent fault diagnosis; Machine learning; Piezoelectricity; SHM","Convolution; Crystallography; Deep learning; Fault detection; Ferroelectric ceramics; Green computing; Lead zirconate titanate; Learning systems; Neural networks; Piezoelectricity; Vibration analysis; Convolutional neural network; Convolutional Neural Networks (CNN); Electromechanical impedance; Electromechanical impedance techniques; Intelligent fault diagnosis; Red , green and blues; Structural condition; Structural health monitoring (SHM); Structural health monitoring","MDPI AG","14248220","","","30189639","Article","Scopus","2-s2.0-85053082391"
"Sumita M.; Yang X.; Ishihara S.; Tamura R.; Tsuda K.","Sumita, Masato (14008255900); Yang, Xiufeng (57196417567); Ishihara, Shinsuke (35069415900); Tamura, Ryo (56797641000); Tsuda, Koji (7202766502)","14008255900; 57196417567; 35069415900; 56797641000; 7202766502","Hunting for Organic Molecules with Artificial Intelligence: Molecules Optimized for Desired Excitation Energies","2018","ACS Central Science","86","10.1021/acscentsci.8b00213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052860589&doi=10.1021%2facscentsci.8b00213&partnerID=40&md5=ec72ac0096aab97c4a778780b692152e","Center for Advanced Intelligence Project, RIKEN, 1-4-1 Nihombashi, Tokyo, Chuo-ku, 103-0027, Japan; International Center for Materials Nanoarchitectonics (WPI-MANA), National Institute for Materials Science, 1-1 Namiki, Tsukuba, Ibaraki, 305-0044, Japan; Graduate School of Frontier Sciences, University of Tokyo, 5-1-5 Kashiwa-no-ha, Kashiwa, Chiba, 277-8561, Japan; Research and Services Division of Materials Data and Integrated System, National Institute for Materials Science, 1-2-1 Sengen, Tsukuba, Ibaraki, 305-0047, Japan","Sumita M., Center for Advanced Intelligence Project, RIKEN, 1-4-1 Nihombashi, Tokyo, Chuo-ku, 103-0027, Japan, International Center for Materials Nanoarchitectonics (WPI-MANA), National Institute for Materials Science, 1-1 Namiki, Tsukuba, Ibaraki, 305-0044, Japan; Yang X., Center for Advanced Intelligence Project, RIKEN, 1-4-1 Nihombashi, Tokyo, Chuo-ku, 103-0027, Japan, Graduate School of Frontier Sciences, University of Tokyo, 5-1-5 Kashiwa-no-ha, Kashiwa, Chiba, 277-8561, Japan; Ishihara S., International Center for Materials Nanoarchitectonics (WPI-MANA), National Institute for Materials Science, 1-1 Namiki, Tsukuba, Ibaraki, 305-0044, Japan; Tamura R., International Center for Materials Nanoarchitectonics (WPI-MANA), National Institute for Materials Science, 1-1 Namiki, Tsukuba, Ibaraki, 305-0044, Japan, Graduate School of Frontier Sciences, University of Tokyo, 5-1-5 Kashiwa-no-ha, Kashiwa, Chiba, 277-8561, Japan, Research and Services Division of Materials Data and Integrated System, National Institute for Materials Science, 1-2-1 Sengen, Tsukuba, Ibaraki, 305-0047, Japan; Tsuda K., Center for Advanced Intelligence Project, RIKEN, 1-4-1 Nihombashi, Tokyo, Chuo-ku, 103-0027, Japan, Graduate School of Frontier Sciences, University of Tokyo, 5-1-5 Kashiwa-no-ha, Kashiwa, Chiba, 277-8561, Japan, Research and Services Division of Materials Data and Integrated System, National Institute for Materials Science, 1-2-1 Sengen, Tsukuba, Ibaraki, 305-0047, Japan","This work presents a proof-of-concept study in artificial-intelligence-assisted (AI-assisted) chemistry where a machine-learning-based molecule generator is coupled with density functional theory (DFT) calculations, synthesis, and measurement. Although deep-learning-based molecule generators have shown promise, it is unclear to what extent they can be useful in real-world materials development. To assess the reliability of AI-assisted chemistry, we prepared a platform using a molecule generator and a DFT simulator, and attempted to generate novel photofunctional molecules whose lowest excited states lie at desired energetic levels. A 10 day run on the 12-core server discovered 86 potential photofunctional molecules around target lowest excitation levels, designated as 200, 300, 400, 500, and 600 nm. Among the molecules discovered, six were synthesized, and five were confirmed to reproduce DFT predictions in ultraviolet visible absorption measurements. This result shows the potential of AI-assisted chemistry to discover ready-to-synthesize novel molecules with modest computational resources. © 2018 American Chemical Society.","","Artificial intelligence; Computation theory; Computational chemistry; Deep learning; Density functional theory; Molecules; Computational resources; Excitation levels; Materials development; Novel molecules; Organic molecules; Proof of concept; Real-world; Ultraviolet visible absorption; Synthesis (chemical)","American Chemical Society","23747943","","","","Article","Scopus","2-s2.0-85052860589"
"Penttinen A.-M.; Parkkinen I.; Blom S.; Kopra J.; Andressoo J.-O.; Pitkänen K.; Voutilainen M.H.; Saarma M.; Airavaara M.","Penttinen, Anna-Maija (55518000200); Parkkinen, Ilmari (57202583090); Blom, Sami (56998453000); Kopra, Jaakko (56183286300); Andressoo, Jaan-Olle (6505854732); Pitkänen, Kari (57203919157); Voutilainen, Merja H. (8791886900); Saarma, Mart (7006268869); Airavaara, Mikko (6508117766)","55518000200; 57202583090; 56998453000; 56183286300; 6505854732; 57203919157; 8791886900; 7006268869; 6508117766","Implementation of deep neural networks to count dopamine neurons in substantia nigra","2018","European Journal of Neuroscience","33","10.1111/ejn.14129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053532766&doi=10.1111%2fejn.14129&partnerID=40&md5=7fd64280d4dfd4ae06df4f9bf47468a6","Institute of Biotechnology, HiLIFE Unit, University of Helsinki, Helsinki, Finland; Biomedicum, Fimmic Oy, Helsinki, Finland; Division of Pharmacology and Pharmacotherapy, Faculty of Pharmacy, University of Helsinki, Helsinki, Finland","Penttinen A.-M., Institute of Biotechnology, HiLIFE Unit, University of Helsinki, Helsinki, Finland; Parkkinen I., Institute of Biotechnology, HiLIFE Unit, University of Helsinki, Helsinki, Finland; Blom S., Biomedicum, Fimmic Oy, Helsinki, Finland; Kopra J., Division of Pharmacology and Pharmacotherapy, Faculty of Pharmacy, University of Helsinki, Helsinki, Finland; Andressoo J.-O., Institute of Biotechnology, HiLIFE Unit, University of Helsinki, Helsinki, Finland; Pitkänen K., Biomedicum, Fimmic Oy, Helsinki, Finland; Voutilainen M.H., Institute of Biotechnology, HiLIFE Unit, University of Helsinki, Helsinki, Finland; Saarma M., Institute of Biotechnology, HiLIFE Unit, University of Helsinki, Helsinki, Finland; Airavaara M., Institute of Biotechnology, HiLIFE Unit, University of Helsinki, Helsinki, Finland","Unbiased estimates of neuron numbers within substantia nigra are crucial for experimental Parkinson's disease models and gene-function studies. Unbiased stereological counting techniques with optical fractionation are successfully implemented, but are extremely laborious and time-consuming. The development of neural networks and deep learning has opened a new way to teach computers to count neurons. Implementation of a programming paradigm enables a computer to learn from the data and development of an automated cell counting method. The advantages of computerized counting are reproducibility, elimination of human error and fast high-capacity analysis. We implemented whole-slide digital imaging and deep convolutional neural networks (CNN) to count substantia nigra dopamine neurons. We compared the results of the developed method against independent manual counting by human observers and validated the CNN algorithm against previously published data in rats and mice, where tyrosine hydroxylase (TH)-immunoreactive neurons were counted using unbiased stereology. The developed CNN algorithm and fully cloud-embedded Aiforia™ platform provide robust and fast analysis of dopamine neurons in rat and mouse substantia nigra. © 2018 The Authors. European Journal of Neuroscience published by Federation of European Neuroscience Societies and John Wiley & Sons Ltd.","artificial intelligence; cloud-based analysis; digital imaging; midbrain; stereology","Animals; Dopamine; Dopaminergic Neurons; Male; Mice; Neural Networks, Computer; Parkinsonian Disorders; Rats, Wistar; Reproducibility of Results; Substantia Nigra; Tyrosine 3-Monooxygenase; tyrosine 3 monooxygenase; dopamine; tyrosine 3 monooxygenase; algorithm; animal cell; animal experiment; animal tissue; Article; cell count; controlled study; deep convolutional neural network; digital imaging; dopaminergic nerve cell; immunohistochemistry; immunoreactivity; machine learning; male; mouse; nerve cell network; nonhuman; priority journal; protein expression; rat; software; stereology; substantia nigra; validation process; animal; dopaminergic nerve cell; metabolism; parkinsonism; reproducibility; substantia nigra; Wistar rat","Blackwell Publishing Ltd","0953816X","","EJONE","30144349","Article","Scopus","2-s2.0-85053532766"
"Rodriguez-Ruiz A.; Teuwen J.; Vreemann S.; Bouwman R.W.; van Engen R.E.; Karssemeijer N.; Mann R.M.; Gubern-Merida A.; Sechopoulos I.","Rodriguez-Ruiz, Alejandro (57189389624); Teuwen, Jonas (56304766400); Vreemann, Suzan (56644971600); Bouwman, Ramona W (24764864200); van Engen, Ruben E (24173628500); Karssemeijer, Nico (24332021400); Mann, Ritse M (23397838900); Gubern-Merida, Albert (42261661300); Sechopoulos, Ioannis (14014292600)","57189389624; 56304766400; 56644971600; 24764864200; 24173628500; 24332021400; 23397838900; 42261661300; 14014292600","New reconstruction algorithm for digital breast tomosynthesis: better image quality for humans and computers","2018","Acta Radiologica","25","10.1177/0284185117748487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044256365&doi=10.1177%2f0284185117748487&partnerID=40&md5=eb20b27ba27e4a4c55044af66fa4ba15","Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Dutch Expert Centre for Screening (LRCB), Nijmegen, Netherlands","Rodriguez-Ruiz A., Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Teuwen J., Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Vreemann S., Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Bouwman R.W., Dutch Expert Centre for Screening (LRCB), Nijmegen, Netherlands; van Engen R.E., Dutch Expert Centre for Screening (LRCB), Nijmegen, Netherlands; Karssemeijer N., Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Mann R.M., Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Gubern-Merida A., Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Sechopoulos I., Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands, Dutch Expert Centre for Screening (LRCB), Nijmegen, Netherlands","Background: The image quality of digital breast tomosynthesis (DBT) volumes depends greatly on the reconstruction algorithm. Purpose: To compare two DBT reconstruction algorithms used by the Siemens Mammomat Inspiration system, filtered back projection (FBP), and FBP with iterative optimizations (EMPIRE), using qualitative analysis by human readers and detection performance of machine learning algorithms. Material and Methods: Visual grading analysis was performed by four readers specialized in breast imaging who scored 100 cases reconstructed with both algorithms (70 lesions). Scoring (5-point scale: 1 = poor to 5 = excellent quality) was performed on presence of noise and artifacts, visualization of skin-line and Cooper’s ligaments, contrast, and image quality, and, when present, lesion visibility. In parallel, a three-dimensional deep-learning convolutional neural network (3D-CNN) was trained (n = 259 patients, 51 positives with BI-RADS 3, 4, or 5 calcifications) and tested (n = 46 patients, nine positives), separately with FBP and EMPIRE volumes, to discriminate between samples with and without calcifications. The partial area under the receiver operating characteristic curve (pAUC) of each 3D-CNN was used for comparison. Results: EMPIRE reconstructions showed better contrast (3.23 vs. 3.10, P = 0.010), image quality (3.22 vs. 3.03, P < 0.001), visibility of calcifications (3.53 vs. 3.37, P = 0.053, significant for one reader), and fewer artifacts (3.26 vs. 2.97, P < 0.001). The 3D-CNN-EMPIRE had better performance than 3D-CNN-FBP (pAUC-EMPIRE = 0.880 vs. pAUC-FBP = 0.857; P < 0.001). Conclusion: The new algorithm provides DBT volumes with better contrast and image quality, fewer artifacts, and improved visibility of calcifications for human observers, as well as improved detection performance with deep-learning algorithms. © The Foundation Acta Radiologica 2017.","deep learning; Digital breast tomosynthesis; reconstruction algorithms; visual grading analysis","Algorithms; Artifacts; Breast Neoplasms; Female; Humans; Machine Learning; Mammography; Radiographic Image Enhancement; Radiographic Image Interpretation, Computer-Assisted; Biomineralization; Bone; Calcification (biochemistry); Computerized tomography; Deep learning; Grading; Image enhancement; Image quality; Image reconstruction; Iterative methods; Medical imaging; Neural networks; Visibility; Convolutional neural network; Digital breast tomosynthesis; Digital breast tomosynthesis (DBT); Filtered back projection; Iterative Optimization; Receiver operating characteristic curves; Reconstruction algorithms; Visual grading analysis; algorithm; Article; artifact; artificial neural network; breast calcification; computer analysis; controlled study; digital breast tomosynthesis; false positive result; human; image quality; image reconstruction; machine learning; major clinical study; noise; parallel design; priority journal; qualitative analysis; rating scale; receiver operating characteristic; scoring system; breast tumor; computer assisted diagnosis; diagnostic imaging; female; image enhancement; mammography; procedures; Learning algorithms","SAGE Publications Inc.","02841851","","ACRAE","29254355","Article","Scopus","2-s2.0-85044256365"
"Goto T.; Camargo C.A., Jr.; Faridi M.K.; Yun B.J.; Hasegawa K.","Goto, Tadahiro (57206624221); Camargo, Carlos A. (34567876000); Faridi, Mohammad Kamal (57191433309); Yun, Brian J. (56224363800); Hasegawa, Kohei (47061524200)","57206624221; 34567876000; 57191433309; 56224363800; 47061524200","Machine learning approaches for predicting disposition of asthma and COPD exacerbations in the ED","2018","American Journal of Emergency Medicine","94","10.1016/j.ajem.2018.06.062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049339879&doi=10.1016%2fj.ajem.2018.06.062&partnerID=40&md5=fc88470a4a914b6226f2b37cb86ec81d","Department of Emergency Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States","Goto T., Department of Emergency Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Camargo C.A., Jr., Department of Emergency Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Faridi M.K., Department of Emergency Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Yun B.J., Department of Emergency Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Hasegawa K., Department of Emergency Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States","Objective: The prediction of emergency department (ED) disposition at triage remains challenging. Machine learning approaches may enhance prediction. We compared the performance of several machine learning approaches for predicting two clinical outcomes (critical care and hospitalization) among ED patients with asthma or COPD exacerbation. Methods: Using the 2007–2015 National Hospital and Ambulatory Medical Care Survey (NHAMCS) ED data, we identified adults with asthma or COPD exacerbation. In the training set (70% random sample), using routinely-available triage data as predictors (e.g., demographics, arrival mode, vital signs, chief complaint, comorbidities), we derived four machine learning-based models: Lasso regression, random forest, boosting, and deep neural network. In the test set (the remaining 30% of sample), we compared their prediction ability against traditional logistic regression with Emergency Severity Index (ESI, reference model). Results: Of 3206 eligible ED visits, corresponding to weighted estimates of 13.9 million visits, 4% had critical care outcome and 26% had hospitalization outcome. For the critical care prediction, the best performing approach– boosting – achieved the highest discriminative ability (C-statistics 0.80 vs. 0.68), reclassification improvement (net reclassification improvement [NRI] 53%, P = 0.002), and sensitivity (0.79 vs. 0.53) over the reference model. For the hospitalization prediction, random forest provided the highest discriminative ability (C-statistics 0.83 vs. 0.64) reclassification improvement (NRI 92%, P < 0.001), and sensitivity (0.75 vs. 0.33). Results were generally consistent across the asthma and COPD subgroups. Conclusions: Based on nationally-representative ED data, machine learning approaches improved the ability to predict disposition of patients with asthma or COPD exacerbation. © 2018 Elsevier Inc.","Asthma; COPD; Disposition; Emergency department; Machine learning; Prediction","Adult; Aged; Asthma; Emergency Service, Hospital; Female; Hospitalization; Humans; Machine Learning; Male; Middle Aged; Pulmonary Disease, Chronic Obstructive; Severity of Illness Index; Treatment Outcome; Triage; adult; aged; Article; artificial neural network; asthma; chronic obstructive lung disease; clinical outcome; comorbidity; demography; disease exacerbation; emergency health service; Emergency Severity Index; emergency ward; female; health survey; hospitalization; human; intensive care; machine learning; major clinical study; male; prediction; priority journal; scoring system; sensitivity and specificity; vital sign; asthma; chronic obstructive lung disease; complication; hospital emergency service; middle aged; procedures; severity of illness index; statistics and numerical data; treatment outcome","W.B. Saunders","07356757","","AJEME","29970272","Article","Scopus","2-s2.0-85049339879"
"Wu Y.; Wang G.","Wu, Yunyi (57189852960); Wang, Guanyu (7407149382)","57189852960; 7407149382","Machine learning based toxicity prediction: From chemical structural description to transcriptome analysis","2018","International Journal of Molecular Sciences","125","10.3390/ijms19082358","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052113303&doi=10.3390%2fijms19082358&partnerID=40&md5=56e23d8434d1763a39f6d5b07f812868","Department of Biology, Guangdong Provincial Key Laboratory of Cell Microenviroment and Disease Research, Southern University of Science and Technology, Shenzhen, 518055, China","Wu Y., Department of Biology, Guangdong Provincial Key Laboratory of Cell Microenviroment and Disease Research, Southern University of Science and Technology, Shenzhen, 518055, China; Wang G., Department of Biology, Guangdong Provincial Key Laboratory of Cell Microenviroment and Disease Research, Southern University of Science and Technology, Shenzhen, 518055, China","Toxicity prediction is very important to public health. Among its many applications, toxicity prediction is essential to reduce the cost and labor of a drug’s preclinical and clinical trials, because a lot of drug evaluations (cellular, animal, and clinical) can be spared due to the predicted toxicity. In the era of Big Data and artificial intelligence, toxicity prediction can benefit from machine learning, which has been widely used in many fields such as natural language processing, speech recognition, image recognition, computational chemistry, and bioinformatics, with excellent performance. In this article, we review machine learning methods that have been applied to toxicity prediction, including deep learning, random forests, k-nearest neighbors, and support vector machines. We also discuss the input parameter to the machine learning algorithm, especially its shift from chemical structural description only to that combined with human transcriptome data analysis, which can greatly enhance prediction accuracy. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Chemical structure; Deep learning; Machine learning; Molecular fingerprint; Molecular fragment; Toxicity prediction; Transcriptome","Animals; Gene Expression Profiling; Humans; Machine Learning; Natural Language Processing; Transcriptome; sitaxsentan; sulfafurazole; transcriptome; algorithm; Article; bioinformatics; chemical structure; computer model; finger dermatoglyphics; gene expression; high throughput screening; human; k nearest neighbor; language processing; machine learning; physical chemistry; public health; random forest; speech discrimination; structure activity relation; support vector machine; toxicity testing; animal; gene expression profiling; natural language processing; procedures","MDPI AG","16616596","","","30103448","Article","Scopus","2-s2.0-85052113303"
"Moghadam S.M.; Seyyedsalehi S.A.","Moghadam, Saeed Montazeri (57194038843); Seyyedsalehi, Seyyed Ali (23052506100)","57194038843; 23052506100","Nonlinear analysis and synthesis of video images using deep dynamic bottleneck neural networks for face recognition","2018","Neural Networks","16","10.1016/j.neunet.2018.05.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048211489&doi=10.1016%2fj.neunet.2018.05.016&partnerID=40&md5=cb367a7fa20a52f5d1b19a02a9fde8f7","Department of Biomedical Engineering, Amirkabir University of Technology, 424Hafez Ave, Tehran, Iran","Moghadam S.M., Department of Biomedical Engineering, Amirkabir University of Technology, 424Hafez Ave, Tehran, Iran; Seyyedsalehi S.A., Department of Biomedical Engineering, Amirkabir University of Technology, 424Hafez Ave, Tehran, Iran","Nonlinear components extracted from deep structures of bottleneck neural networks exhibit a great ability to express input space in a low-dimensional manifold. Sharing and combining the components boost the capability of the neural networks to synthesize and interpolate new and imaginary data. This synthesis is possibly a simple model of imaginations in human brain where the components are expressed in a nonlinear low dimensional manifold. The current paper introduces a novel Dynamic Deep Bottleneck Neural Network to analyze and extract three main features of videos regarding the expression of emotions on the face. These main features are identity, emotion and expression intensity that are laid in three different sub-manifolds of one nonlinear general manifold. The proposed model enjoying the advantages of recurrent networks was used to analyze the sequence and dynamics of information in videos. It is noteworthy to mention that this model also has also the potential to synthesize new videos showing variations of one specific emotion on the face of unknown subjects. Experiments on discrimination and recognition ability of extracted components showed that the proposed model has an average of 97.77% accuracy in recognition of six prominent emotions (Fear, Surprise, Sadness, Anger, Disgust, and Happiness), and 78.17% accuracy in the recognition of intensity. The produced videos revealed variations from neutral to the apex of an emotion on the face of the unfamiliar test subject which is on average 0.8 similar to reference videos in the scale of the SSIM method. © 2018 Elsevier Ltd","Deep neural networks; Expression intensity; Facial expression; Nonlinear video analysis; Video synthesis","Biometric Identification; Emotions; Facial Expression; Humans; Machine Learning; Neural Networks (Computer); Video Recording; Deep neural networks; Nonlinear analysis; Nonlinear network synthesis; Analysis and synthesis; Expression intensities; Facial Expressions; Low-dimensional manifolds; Non-linear videos; Nonlinear components; Recognition abilities; Video synthesis; anger; Article; bottleneck neural network; disgust; emotion; facial expression; facial recognition; fear; happiness; human; image analysis; machine learning; sadness; surprise; videorecording; artificial neural network; biometry; procedures; standards; videorecording; Face recognition","Elsevier Ltd","08936080","","NNETE","29894847","Article","Scopus","2-s2.0-85048211489"
"Kim J.; Lee B.","Kim, Jongin (57203325126); Lee, Boreom (16230607300)","57203325126; 16230607300","Identification of Alzheimer's disease and mild cognitive impairment using multimodal sparse hierarchical extreme learning machine","2018","Human Brain Mapping","41","10.1002/hbm.24207","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046487564&doi=10.1002%2fhbm.24207&partnerID=40&md5=95d9f9cff2adda1f4152c38e8f3000bb","Department of Biomedical Science and Engineering (BMSE), Institute of Integrated Technology (IIT), Gwangju Institute of Science and Technology (GIST), Gwangju, 61005, South Korea","Kim J., Department of Biomedical Science and Engineering (BMSE), Institute of Integrated Technology (IIT), Gwangju Institute of Science and Technology (GIST), Gwangju, 61005, South Korea; Lee B., Department of Biomedical Science and Engineering (BMSE), Institute of Integrated Technology (IIT), Gwangju Institute of Science and Technology (GIST), Gwangju, 61005, South Korea","Different modalities such as structural MRI, FDG-PET, and CSF have complementary information, which is likely to be very useful for diagnosis of AD and MCI. Therefore, it is possible to develop a more effective and accurate AD/MCI automatic diagnosis method by integrating complementary information of different modalities. In this paper, we propose multi-modal sparse hierarchical extreme leaning machine (MSH-ELM). We used volume and mean intensity extracted from 93 regions of interest (ROIs) as features of MRI and FDG-PET, respectively, and used p-tau, t-tau, and Aβ42 as CSF features. In detail, high-level representation was individually extracted from each of MRI, FDG-PET, and CSF using a stacked sparse extreme learning machine auto-encoder (sELM-AE). Then, another stacked sELM-AE was devised to acquire a joint hierarchical feature representation by fusing the high-level representations obtained from each modality. Finally, we classified joint hierarchical feature representation using a kernel-based extreme learning machine (KELM). The results of MSH-ELM were compared with those of conventional ELM, single kernel support vector machine (SK-SVM), multiple kernel support vector machine (MK-SVM) and stacked auto-encoder (SAE). Performance was evaluated through 10-fold cross-validation. In the classification of AD vs. HC and MCI vs. HC problem, the proposed MSH-ELM method showed mean balanced accuracies of 96.10% and 86.46%, respectively, which is much better than those of competing methods. In summary, the proposed algorithm exhibits consistently better performance than SK-SVM, ELM, MK-SVM and SAE in the two binary classification problems (AD vs. HC and MCI vs. HC). © 2018 Wiley Periodicals, Inc.","Alzheimer's disease; CS; mild cognitive impairment; MRI; multimodal classification; PET; sparse hierarchical extreme learning machine","Aged; Aged, 80 and over; Algorithms; Alzheimer Disease; Cognitive Dysfunction; Databases, Factual; Deep Learning; Diagnosis, Differential; Female; Humans; Magnetic Resonance Imaging; Male; Middle Aged; Positron-Emission Tomography; Support Vector Machine; amyloid beta protein[1-42]; fluorodeoxyglucose; tau protein; adult; aged; Alzheimer disease; amygdala; angular gyrus; Article; caudate nucleus; cerebrospinal fluid; classification algorithm; computer assisted diagnosis; controlled study; feature extraction; female; fusiform gyrus; hippocampus; human; intermethod comparison; machine learning; major clinical study; male; middle temporal gyrus; mild cognitive impairment; neuroimaging; nuclear magnetic resonance imaging; occipital cortex; perirhinal cortex; positron emission tomography; primary motor cortex; priority journal; superior parietal lobule; support vector machine; temporal lobe; uncus; algorithm; Alzheimer disease; cognitive defect; diagnostic imaging; differential diagnosis; factual database; middle aged; nuclear magnetic resonance imaging; pathology; positron emission tomography; very elderly","John Wiley and Sons Inc.","10659471","","HBMAE","29736986","Article","Scopus","2-s2.0-85046487564"
"Dalins J.; Tyshetskiy Y.; Wilson C.; Carman M.J.; Boudry D.","Dalins, Janis (56671418800); Tyshetskiy, Yuriy (6506949970); Wilson, Campbell (24463026300); Carman, Mark J. (10240340400); Boudry, Douglas (57202354492)","56671418800; 6506949970; 24463026300; 10240340400; 57202354492","Laying foundations for effective machine learning in law enforcement. Majura – A labelling schema for child exploitation materials","2018","Digital Investigation","13","10.1016/j.diin.2018.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047981760&doi=10.1016%2fj.diin.2018.05.004&partnerID=40&md5=4e1073511fa64615c1dc5c2104650549","Monash University, Caulfield, VIC, Australia; Australian Federal Police, Melbourne, VIC, Australia; Australian Federal Police, Barton, ACT, Australia; Data61, CSIRO, Eveleigh, NSW, Australia","Dalins J., Monash University, Caulfield, VIC, Australia, Australian Federal Police, Melbourne, VIC, Australia; Tyshetskiy Y., Data61, CSIRO, Eveleigh, NSW, Australia; Wilson C., Monash University, Caulfield, VIC, Australia; Carman M.J., Monash University, Caulfield, VIC, Australia; Boudry D., Australian Federal Police, Barton, ACT, Australia","The health impacts of repeated exposure to distressing concepts such as child exploitation materials (CEM, aka ‘child pornography’) have become a major concern to law enforcement agencies and associated entities. Existing methods for ‘flagging’ materials largely rely upon prior knowledge, whilst predictive methods are unreliable, particularly when compared with equivalent tools used for detecting ‘lawful’ pornography. In this paper we detail the design and implementation of a deep-learning based CEM classifier, leveraging existing pornography detection methods to overcome infrastructure and corpora limitations in this field. Specifically, we further existing research through direct access to numerous contemporary, real-world, annotated cases taken from Australian Federal Police holdings, demonstrating the dangers of overfitting due to the influence of individual users’ proclivities. We quantify the performance of skin tone analysis in CEM cases, showing it to be of limited use. We assess the performance of our classifier and show it to be sufficient for use in forensic triage and ‘early warning’ of CEM, but of limited efficacy for categorising against existing scales for measuring child abuse severity. We identify limitations currently faced by researchers and practitioners in this field, whose restricted access to training material is exacerbated by inconsistent and unsuitable annotation schemas. Whilst adequate for their intended use, we show existing schemas to be unsuitable for training machine learning (ML) models, and introduce a new, flexible, objective, and tested annotation schema specifically designed for cross-jurisdictional collaborative use. This work, combined with a world-first ‘illicit data airlock’ project currently under construction, has the potential to bring a ‘ground truth’ dataset and processing facilities to researchers worldwide without compromising quality, safety, ethics and legality. © 2018 Elsevier Ltd","Annotation schema; Child exploitation; Digital forensics; Forensic triage; Neural networks","Artificial intelligence; Computational electromagnetics; Deep learning; Forensic engineering; Law enforcement; Neural networks; Annotation schema; Australian federal polices; Child exploitation; Design and implementations; Forensic triage; Law-enforcement agencies; Pornography detections; Processing facilities; Digital forensics","Elsevier Ltd","17422876","","","","Article","Scopus","2-s2.0-85047981760"
"Darst B.; Engelman C.D.; Tian Y.; Lorenzo Bermejo J.","Darst, Burcu (54905945600); Engelman, Corinne D. (6602567647); Tian, Ye (57198239600); Lorenzo Bermejo, Justo (55665790900)","54905945600; 6602567647; 57198239600; 55665790900","Data mining and machine learning approaches for the integration of genome-wide association and methylation data: Methodology and main conclusions from GAW20 01 Mathematical Sciences 0104 Statistics 08 Information and Computing Sciences 0801 Artificial Intelligence and Image Processing","2018","BMC Genetics","2","10.1186/s12863-018-0646-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053413419&doi=10.1186%2fs12863-018-0646-3&partnerID=40&md5=102a4d88b3f85e39605d0d837fdbc984","Department of Population Health Sciences, School of Medicine and Public Health, University of Wisconsin, 610 Walnut St. 1007 WARF, Madison, 53726, WI, United States; Department of Biochemistry and Medical Genetics, University of Manitoba, 745 Bannatyne Ave, Winnipeg, R3E 0J9, MB, Canada; Department of Electrical and Computer Engineering, University of Manitoba, 745 Bannatyne Ave, Winnipeg, R3E 0J9, MB, Canada; Institute of Medical Biometry and Informatics, University of Heidelberg, Im Neuenheimer Feld 130.3, Heidelberg, 69120, Germany","Darst B., Department of Population Health Sciences, School of Medicine and Public Health, University of Wisconsin, 610 Walnut St. 1007 WARF, Madison, 53726, WI, United States; Engelman C.D., Department of Population Health Sciences, School of Medicine and Public Health, University of Wisconsin, 610 Walnut St. 1007 WARF, Madison, 53726, WI, United States; Tian Y., Department of Biochemistry and Medical Genetics, University of Manitoba, 745 Bannatyne Ave, Winnipeg, R3E 0J9, MB, Canada, Department of Electrical and Computer Engineering, University of Manitoba, 745 Bannatyne Ave, Winnipeg, R3E 0J9, MB, Canada; Lorenzo Bermejo J., Institute of Medical Biometry and Informatics, University of Heidelberg, Im Neuenheimer Feld 130.3, Heidelberg, 69120, Germany","Background: Multiple layers of genetic and epigenetic variability are being simultaneously explored in an increasing number of health studies. We summarize here different approaches applied in the Data Mining and Machine Learning group at the GAW20 to integrate genome-wide genotype and methylation array data. Results: We provide a non-intimidating introduction to some frequently used methods to investigate high-dimensional molecular data and compare the different approaches tried by group members: random forest, deep learning, cluster analysis, mixed models, and gene-set enrichment analysis. Group contributions were quite heterogeneous regarding investigated data sets (real vs simulated), conducted data quality control and assessed phenotypes (eg, metabolic syndrome vs relative differences of log-transformed triglyceride concentrations before and after fenofibrate treatment). However, some common technical issues were detected, leading to practical recommendations. Conclusions: Different sources of correlation were identified by group members, including population stratification, family structure, batch effects, linkage disequilibrium and correlation of methylation values at neighboring cytosine-phosphate-guanine (CpG) sites, and the majority of applied approaches were able to take into account identified correlation structures. The ability to efficiently deal with high-dimensional omics data, and the model free nature of the approaches that did not require detailed model specifications were clearly recognized as the main strengths of applied methods. A limitation of random forest is its sensitivity to highly correlated variables. The parameter setup and the interpretation of results from deep learning methods, in particular deep neural networks, can be extremely challenging. Cluster analysis and mixed models may need some predimension reduction based on existing literature, data filtering, and supplementary statistical methods, and gene-set enrichment analysis requires biological insight. © 2018 The Author(s).","Data mining; Epigenome-wide association study; Genome-wide association study; Machine learning","Cluster Analysis; CpG Islands; Data Mining; DNA Methylation; Genome-Wide Association Study; Humans; Machine Learning; Phenotype; Article; artificial neural network; cluster analysis; controlled study; correlation analysis; CpG island; data mining; DNA methylation; family; gene linkage disequilibrium; gene-set enrichment analysis; genetic analysis; genome; genome-wide association study; genotype; human; intermethod comparison; machine learning; metabolic syndrome X; molecular genetics; phenotype; population; random forest; sensitivity analysis; statistical analysis; statistical model; statistical parameters; triacylglycerol blood level; data mining; DNA methylation","BioMed Central Ltd.","14712156","","BGMED","30255774","Article","Scopus","2-s2.0-85053413419"
"Seetha J.; Raja S.S.","Seetha, J. (54883958100); Raja, S. Selvakumar (56049538700)","54883958100; 56049538700","Brain tumor classification using Convolutional Neural Networks","2018","Biomedical and Pharmacology Journal","246","10.13005/bpj/1511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062986913&doi=10.13005%2fbpj%2f1511&partnerID=40&md5=5a55120e22e6261014718636241fee04","Department of Computer Science and Engineering, Sathyabama University, Chennai, India; Kakatiya Institute of Tech and Science for Women, Nizamabad, 503 003, Telangana State, India","Seetha J., Department of Computer Science and Engineering, Sathyabama University, Chennai, India; Raja S.S., Kakatiya Institute of Tech and Science for Women, Nizamabad, 503 003, Telangana State, India","The brain tumors, are the most common and aggressive disease, leading to a very short life expectancy in their highest grade. Thus, treatment planning is a key stage to improve the quality of life of patients. Generally, various image techniques such as Computed Tomography (CT), Magnetic Resonance Imaging (MRI)and ultrasound image are used to evaluate the tumor in a brain, lung, liver, breast, prostate⋯etc. Especially, in this work MRI images are used to diagnose tumor in the brain. However the huge amount of data generated by MRI scan thwarts manual classification of tumor vs non-tumor in a particular time. But it having some limitation (i.e) accurate quantitative measurements is provided for limited number of images. Hence trusted and automatic classification scheme are essential to prevent the death rate of human. The automatic brain tumor classification is very challenging task in large spatial and structural variability of surrounding region of brain tumor. In this work, automatic brain tumor detection is proposed by using Convolutional Neural Networks (CNN) classification. The deeper architecture design is performed by using small kernels. The weight of the neuron is given as small. Experimental results show that the CNN archives rate of 97.5% accuracy with low complexity and compared with the all other state of arts methods. © 2018 Oriental Scientific Publishing Company.","Brain image; MRI; Neural networks","accuracy; Article; artificial neural network; brain tumor; cancer diagnosis; comparative study; computer assisted tomography; deep learning; diagnostic accuracy; fuzzy c means classification; human; human tissue; k nearest neighbor classification; life expectancy; nerve cell network; nuclear magnetic resonance imaging; quality of life; support vector machine; treatment planning; tumor classification; tumor growth; tumor microenvironment","Oriental Scientific Publishing Company","09746242","","","","Article","Scopus","2-s2.0-85062986913"
"Isabekov A.; Erzin E.","Isabekov, Altynbek (35102380200); Erzin, Engin (6603621358)","35102380200; 6603621358","On the importance of hidden bias and hidden entropy in representational efficiency of the Gaussian-Bipolar Restricted Boltzmann Machines","2018","Neural Networks","1","10.1016/j.neunet.2018.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048838032&doi=10.1016%2fj.neunet.2018.06.002&partnerID=40&md5=58b3a20c10f57337ef16457d787f10e8","College of Engineering, Koç University, Rumelifeneri yolu, Istanbul, 34450, Turkey","Isabekov A., College of Engineering, Koç University, Rumelifeneri yolu, Istanbul, 34450, Turkey; Erzin E., College of Engineering, Koç University, Rumelifeneri yolu, Istanbul, 34450, Turkey","In this paper, we analyze the role of hidden bias in representational efficiency of the Gaussian-Bipolar Restricted Boltzmann Machines (GBPRBMs), which are similar to the widely used Gaussian-Bernoulli RBMs. Our experiments show that hidden bias plays an important role in shaping of the probability density function of the visible units. We define hidden entropy and propose it as a measure of representational efficiency of the model. By using this measure, we investigate the effect of hidden bias on the hidden entropy and provide a full analysis of the hidden entropy as function of the hidden bias for small models with up to three hidden units. We also provide an insight into understanding of the representational efficiency of the larger scale models. Furthermore, we introduce Normalized Empirical Hidden Entropy (NEHE) as an alternative to hidden entropy that can be computed for large models. Experiments on the MNIST, CIFAR-10 and Faces data sets show that NEHE can serve as measure of representational efficiency and gives an insight on minimum number of hidden units required to represent the data. © 2018 Elsevier Ltd","Autoencoder; Deep learning; Hidden bias; Hidden entropy; RBM; Representational efficiency","Bias; Entropy; Likelihood Functions; Machine Learning; Neural Networks (Computer); Normal Distribution; Deep learning; Efficiency; Gaussian distribution; Probability density function; Auto encoders; Bernoulli; Gaussians; Hidden bias; Hidden units; Large models; Restricted boltzmann machine; Scale models; Article; controlled study; data analysis; Gaussian Bipolar Restricted Boltzmann Machine; hidden bias; hidden entropy; machine learning; Normalized Empirical Hidden Entropy; priority journal; representational efficiency; statistical parameters; artificial neural network; entropy; normal distribution; statistical bias; statistical model; Entropy","Elsevier Ltd","08936080","","NNETE","29940489","Article","Scopus","2-s2.0-85048838032"
"Goh S.K.; Abbass H.A.; Tan K.C.; Al-Mamun A.; Thakor N.; Bezerianos A.; Li J.","Goh, Sim Kuan (56489796700); Abbass, Hussein A. (6701824380); Tan, Kay Chen (25655559700); Al-Mamun, Abdullah (55267863000); Thakor, Nitish (7102105011); Bezerianos, Anastasios (7005440300); Li, Junhua (36184673200)","56489796700; 6701824380; 25655559700; 55267863000; 7102105011; 7005440300; 36184673200","Spatio-spectral representation learning for electroencephalographic gait-pattern classification","2018","IEEE Transactions on Neural Systems and Rehabilitation Engineering","46","10.1109/TNSRE.2018.2864119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051412275&doi=10.1109%2fTNSRE.2018.2864119&partnerID=40&md5=d1e5c56c9ff3491426e426d4c3385628","Department of Electrical and Computer Engineering, Singapore Institute for Neurotechnology, National University of Singapore, Singapore, 117456, Singapore; Trusted Autonomy Group, School of Engineering and Information Technology, University of New South Wales, Canberra, 2600, ACT, Australia; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Electrical and Computer Engineering, National University of Singapore, Singapore, 117583, Singapore; Singapore Institute for Neurotechnology, National University of Singapore, Singapore, 117456, Singapore; Laboratory for Brain-Bionic Intelligence and Computational Neuroscience, Wuyi University, Jiangmen, 529020, China; Centre for Multidisciplinary Convergence Computing, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an, 710072, China","Goh S.K., Department of Electrical and Computer Engineering, Singapore Institute for Neurotechnology, National University of Singapore, Singapore, 117456, Singapore; Abbass H.A., Trusted Autonomy Group, School of Engineering and Information Technology, University of New South Wales, Canberra, 2600, ACT, Australia; Tan K.C., Department of Computer Science, City University of Hong Kong, Hong Kong; Al-Mamun A., Department of Electrical and Computer Engineering, National University of Singapore, Singapore, 117583, Singapore; Thakor N., Singapore Institute for Neurotechnology, National University of Singapore, Singapore, 117456, Singapore; Bezerianos A., Singapore Institute for Neurotechnology, National University of Singapore, Singapore, 117456, Singapore; Li J., Singapore Institute for Neurotechnology, National University of Singapore, Singapore, 117456, Singapore, Laboratory for Brain-Bionic Intelligence and Computational Neuroscience, Wuyi University, Jiangmen, 529020, China, Centre for Multidisciplinary Convergence Computing, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an, 710072, China","The brain plays a pivotal role in locomotion by coordinating muscles through interconnections that get established by the peripheral nervous system. To date, many attempts have been made to reveal the underlying mechanisms of humans' gait. However, decoding cortical processes associated with different walking conditions using EEG signals for gait-pattern classification is a less-explored research area. In this paper, we design an EEG-based experiment with four walking conditions (i.e., free walking, and exoskeleton-assisted walking at zero, low, and high assistive forces by the use of a unilateral exoskeleton to right lower limb). We proposed spatio-spectral representation learning (SSRL), a deep neural network topology with shared weights to learn the spatial and spectral representations of multi-channel EEG signals during walking. Adoption of weight sharing reduces the number of free parameters, while learning spatial and spectral equivariant features. SSRL outperformed state-of-the-art methods in decoding gait patterns, achieving a classification accuracy of 77.8%. Moreover, the features extracted in the intermediate layer of SSRL were observed to be more discriminative than the hand-crafted features. When analyzing the weights of the proposed model, we found an intriguing spatial distribution that is consistent with the distribution found in well-known motor-activated cortical regions. Our results show that SSRL advances the ability to decode human locomotion and it could have important implications for exoskeleton design, rehabilitation processes, and clinical diagnosis. © 2018 IEEE.","convolutional neural network; electroencephalogram (EEG); exoskeleton; gait pattern; Spatio-spectral representation learning","Adult; Algorithms; Biomechanical Phenomena; Brain-Computer Interfaces; Electroencephalography; Exoskeleton Device; Gait; Humans; Learning; Lower Extremity; Male; Motor Cortex; Neural Networks (Computer); Walking; Young Adult; Biomedical signal processing; Brain models; Decoding; Deep neural networks; Electrophysiology; Exoskeleton (Robotics); Feature extraction; Gait analysis; Learning systems; Neural networks; Walking aids; Biological neural networks; Convolutional neural network; Electro-encephalogram (EEG); Gait pattern; Legged locomotion; Spectral representations; adult; Article; body mass; clinical article; electroencephalography; exoskeleton; Fourier transformation; gait; human; human experiment; machine learning; male; mathematical model; measurement accuracy; multifactor dimensionality reduction; neurorehabilitation; normal human; random forest; signal processing; support vector machine; walking; young adult; algorithm; artificial neural network; biomechanics; brain computer interface; classification; electroencephalography; exoskeleton (rehabilitation); gait; learning; lower limb; motor cortex; physiology; Electroencephalography","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","30106679","Article","Scopus","2-s2.0-85051412275"
"Buccino A.P.; Kordovan M.; Ness T.V.; Merkt B.; Häfliger P.D.; Fyhn M.; Cauwenberghs G.; Rotter S.; Einevoll G.T.","Buccino, Alessio P. (57045828900); Kordovan, Michael (57203902962); Ness, Torbjørn V. (56545317500); Merkt, Benjamin (55959646100); Häfliger, Philipp D. (6601974637); Fyhn, Marianne (6603079272); Cauwenberghs, Gert (7006056098); Rotter, Stefan (7004581948); Einevoll, Gaute T. (6602592630)","57045828900; 57203902962; 56545317500; 55959646100; 6601974637; 6603079272; 7006056098; 7004581948; 6602592630","Combining biophysical modeling and deep learning for multielectrode array neuron localization and classification","2018","Journal of Neurophysiology","22","10.1152/jn.00210.2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053464601&doi=10.1152%2fjn.00210.2018&partnerID=40&md5=ed3b1919eb05dc1f75593100be442364","Center for Integrative Neuroplasticity (CINPLA), Faculty of Mathematics and Natural Sciences, University of Oslo, Oslo, Norway; Department of Bioengineering, University of California, San Diego, CA, United States; Bernstein Center Freiburg, Freiburg, Germany; Faculty of Biology, University of Freiburg, Freiburg, Germany; Faculty of Science and Technology, Norwegian University of Life Sciences, Ås, Norway","Buccino A.P., Center for Integrative Neuroplasticity (CINPLA), Faculty of Mathematics and Natural Sciences, University of Oslo, Oslo, Norway, Department of Bioengineering, University of California, San Diego, CA, United States; Kordovan M., Bernstein Center Freiburg, Freiburg, Germany, Faculty of Biology, University of Freiburg, Freiburg, Germany; Ness T.V., Faculty of Science and Technology, Norwegian University of Life Sciences, Ås, Norway; Merkt B., Bernstein Center Freiburg, Freiburg, Germany, Faculty of Biology, University of Freiburg, Freiburg, Germany; Häfliger P.D., Center for Integrative Neuroplasticity (CINPLA), Faculty of Mathematics and Natural Sciences, University of Oslo, Oslo, Norway; Fyhn M., Center for Integrative Neuroplasticity (CINPLA), Faculty of Mathematics and Natural Sciences, University of Oslo, Oslo, Norway; Cauwenberghs G., Department of Bioengineering, University of California, San Diego, CA, United States; Rotter S., Bernstein Center Freiburg, Freiburg, Germany, Faculty of Biology, University of Freiburg, Freiburg, Germany; Einevoll G.T., Center for Integrative Neuroplasticity (CINPLA), Faculty of Mathematics and Natural Sciences, University of Oslo, Oslo, Norway, Faculty of Science and Technology, Norwegian University of Life Sciences, Ås, Norway","Neural circuits typically consist of many different types of neurons, and one faces a challenge in disentangling their individual contributions in measured neural activity. Classification of cells into inhibitory and excitatory neurons and localization of neurons on the basis of extracellular recordings are frequently employed procedures. Current approaches, however, need a lot of human intervention, which makes them slow, biased, and unreliable. In light of recent advances in deep learning techniques and exploiting the availability of neuron models with quasi-realistic three-dimensional morphology and physiological properties, we present a framework for automatized and objective classification and localization of cells based on the spatiotemporal profiles of the extracellular action potentials recorded by multielectrode arrays. We train convolutional neural networks on simulated signals from a large set of cell models and show that our framework can predict the position of neurons with high accuracy, more precisely than current state-of-the-art methods. Our method is also able to classify whether a neuron is excitatory or inhibitory with very high accuracy, substantially improving on commonly used clustering techniques. Furthermore, our new method seems to have the potential to separate certain subtypes of excitatory and inhibitory neurons. The possibility of automatically localizing and classifying all neurons recorded with large high-density extracellular electrodes contributes to a more accurate and more reliable mapping of neural circuits. NEW & NOTEWORTHY We propose a novel approach to localize and classify neurons from their extracellularly recorded action potentials with a combination of biophysically detailed neuron models and deep learning techniques. Applied to simulated data, this new combination of forward modeling and machine learning yields higher performance compared with state-of-the-art localization and classification methods. © 2018 American Physiological Society. All rights reserved.","Convolutional neural networks; Deep learning; Extracellular action potentials; Multielectrode arrays; Neuron localization and classification","Action Potentials; Biophysical Phenomena; Brain; Deep Learning; Electrodes, Implanted; Models, Neurological; Neurons; action potential; animal cell; animal experiment; animal tissue; Article; artificial neural network; automation; brain mapping; cell structure; cellular distribution; comparative study; connectome; controlled study; convolutional neural network; dendrite; evoked response; firing rate; glia cell; juvenile animal; nerve cell; nerve cell excitability; nervous tissue; nonhuman; priority journal; pyramidal nerve cell; rat; somatosensory cortex; biological model; biophysics; brain; classification; cytology; electrode implant; nerve cell; physiology","American Physiological Society","00223077","","JONEA","29847231","Article","Scopus","2-s2.0-85053464601"
"Xiao Y.; Xia C.; Zhang R.-G.; Liu S.-Y.","Xiao, Yi (25622657000); Xia, Chen (57993023500); Zhang, Rong-Guo (56163990700); Liu, Shi-Yuan (9232762100)","25622657000; 57993023500; 56163990700; 9232762100","Discussion of artificial intelligence application in medical imaging","2018","Academic Journal of Second Military Medical University","0","10.16781/j.0258-879x.2018.08.0813","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053313126&doi=10.16781%2fj.0258-879x.2018.08.0813&partnerID=40&md5=0b1368db76914995e278552399730226","Department of Radiology, Changzheng Hospital, Navy Medical University (Second Military Medical University), Shanghai, 200003, China; Advanced Institute of Beijing Infervision, Beijing, 100080, China","Xiao Y., Department of Radiology, Changzheng Hospital, Navy Medical University (Second Military Medical University), Shanghai, 200003, China; Xia C., Advanced Institute of Beijing Infervision, Beijing, 100080, China; Zhang R.-G., Advanced Institute of Beijing Infervision, Beijing, 100080, China; Liu S.-Y., Department of Radiology, Changzheng Hospital, Navy Medical University (Second Military Medical University), Shanghai, 200003, China","As a new generation of artificial intelligence technology, the deep neural network takes the cognitive ability of machine to a historical high level in natural language processing, learning ability and computer vision. At present, the application of deep neural network in medical imaging can be categorized into discovery of anomalies, quantitative measurement, and differential diagnosis. Medical imaging research based on deep neural network research has involved various medical imaging domains such as radiological imaging, pathological images, ultrasound imaging, and endoscopic imaging. In several tasks, deep neural network has demonstrated physician-level or even above-physician-level performance. In the context of rapid development of artificial intelligence in imaging medicine, physicians should adopt a more objective, scientific, and proactive attitude towards artificial intelligence technology, and become the masters of artificial intelligence technology and the creators of a futuristic medical world assisted by artificial intelligence technology. © 2018, Second Military Medical University Press. All rights reserved.","Artificial intelligence; Deep neural network; Differential diagnosis; Discovery of anomalies; Medical imaging; Quantitative measurements","article; artificial intelligence; diagnostic imaging; differential diagnosis; endoscopy; human; human experiment; learning; machine; natural language processing; physician; quantitative analysis; ultrasound; vision","Second Military Medical University Press","0258879X","","DJXUE","","Article","Scopus","2-s2.0-85053313126"
"Ameri A.; Akhaee M.A.; Scheme E.; Englehart K.","Ameri, Ali (55516944900); Akhaee, Mohammad Ali (16202081400); Scheme, Erik (57202922022); Englehart, Kevin (55396192900)","55516944900; 16202081400; 57202922022; 55396192900","Real-time, simultaneous myoelectric control using a convolutional neural network","2018","PLoS ONE","58","10.1371/journal.pone.0203835","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053281723&doi=10.1371%2fjournal.pone.0203835&partnerID=40&md5=3d33f2cc78de1d97cf459c5ff988e51e","Department of Biomedical Engineering, Shahid Beheshti University of Medical Sciences, Tehran, Iran; School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran; Institute of Biomedical Engineering, University of New Brunswick, Fredericton, NB, Canada","Ameri A., Department of Biomedical Engineering, Shahid Beheshti University of Medical Sciences, Tehran, Iran; Akhaee M.A., School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran; Scheme E., Institute of Biomedical Engineering, University of New Brunswick, Fredericton, NB, Canada; Englehart K., Institute of Biomedical Engineering, University of New Brunswick, Fredericton, NB, Canada","The evolution of deep learning techniques has been transformative as they have allowed complex mappings to be trained between control inputs and outputs without the need for feature engineering. In this work, a myoelectric control system based on convolutional neural networks (CNN) is proposed as a possible alternative to traditional approaches that rely on specifically designed features. This CNN-based system is validated using a real-time Fitts’ law style target acquisition test requiring single and combined wrist motions. The performance of the proposed system is then compared to that of a standard support vector machine (SVM) based myoelectric system using a set of time-domain features. Despite the prevalence and demonstrated performance of these well-known features, no significant difference (p>0.05) was found between the two methods for any of the computed control metrics. This demonstrates the potential for automated learning approaches to extract complex and rich information from stochastic biological signals. This first evaluation of the usability of a CNN in a real-time myoelectric control environment provides a basis for further exploration. © 2018 Ameri et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Adult; Electromyography; Humans; Movement; Muscle, Skeletal; Neural Networks (Computer); Pattern Recognition, Automated; Signal Processing, Computer-Assisted; Stochastic Processes; Support Vector Machine; Wrist; adult; Article; artificial neural network; controlled study; hand function; hand movement; human; information processing; machine learning; myoelectric control; pattern recognition; prevalence; support vector machine; validation study; automated pattern recognition; comparative study; electromyography; Markov chain; movement (physiology); physiology; procedures; signal processing; skeletal muscle; wrist","Public Library of Science","19326203","","POLNC","30212573","Article","Scopus","2-s2.0-85053281723"
"Dantes R.B.; Zheng S.; Lu J.J.; Beckman M.G.; Krishnaswamy A.; Richardson L.C.; Chernetsky-Tejedor S.; Wang F.","Dantes, Raymund B. (26022242000); Zheng, Shuai (55509648900); Lu, James J. (56141782700); Beckman, Michele G. (7006540129); Krishnaswamy, Asha (57191967745); Richardson, Lisa C. (7202866773); Chernetsky-Tejedor, Sheri (55813841200); Wang, Fusheng (55740430900)","26022242000; 55509648900; 56141782700; 7006540129; 57191967745; 7202866773; 55813841200; 55740430900","Improved Identification of Venous Thromboembolism from Electronic Medical Records Using a Novel Information Extraction Software Platform","2018","Medical Care","11","10.1097/MLR.0000000000000831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032946277&doi=10.1097%2fMLR.0000000000000831&partnerID=40&md5=e6462a37e3dcb96ea8df1c823819da86","Departments of Medicine, Division of Hospital Medicine, Emory University Hospital, 1364 Clifton Road, NE, Atlanta, 30322, GA, United States; Departments of Biomedical Informatics, Emory University, School of Medicine, Atlanta, GA, United States; Department of Mathematics and Computer Science, Emory University, Atlanta, GA, United States; Division of Blood Disorders, National Center on Birth Defects and Developmental Disabilities, Centers for Disease Control and Prevention, Atlanta, GA, United States; Division of Heart Disease and Stroke Prevention, National Center for Chronic Disease Prevention and Health Promotion, Atlanta, GA, United States; Division of Cancer Prevention and Control, National Center for Chronic Disease Prevention and Health Promotion, Centers for Disease Control and Prevention, Atlanta, GA, United States","Dantes R.B., Departments of Medicine, Division of Hospital Medicine, Emory University Hospital, 1364 Clifton Road, NE, Atlanta, 30322, GA, United States; Zheng S., Departments of Biomedical Informatics, Emory University, School of Medicine, Atlanta, GA, United States; Lu J.J., Department of Mathematics and Computer Science, Emory University, Atlanta, GA, United States; Beckman M.G., Division of Blood Disorders, National Center on Birth Defects and Developmental Disabilities, Centers for Disease Control and Prevention, Atlanta, GA, United States; Krishnaswamy A., Division of Heart Disease and Stroke Prevention, National Center for Chronic Disease Prevention and Health Promotion, Atlanta, GA, United States; Richardson L.C., Division of Cancer Prevention and Control, National Center for Chronic Disease Prevention and Health Promotion, Centers for Disease Control and Prevention, Atlanta, GA, United States; Chernetsky-Tejedor S., Departments of Medicine, Division of Hospital Medicine, Emory University Hospital, 1364 Clifton Road, NE, Atlanta, 30322, GA, United States, Departments of Biomedical Informatics, Emory University, School of Medicine, Atlanta, GA, United States; Wang F., Departments of Biomedical Informatics, Emory University, School of Medicine, Atlanta, GA, United States","Introduction: The United States federally mandated reporting of venous thromboembolism (VTE), defined by Agency for Healthcare Research & Quality Patient Safety Indicator 12 (AHRQ PSI-12), is based on administrative data, the accuracy of which has not been consistently demonstrated. We used IDEAL-X, a novel information extraction software system, to identify VTE from electronic medical records and evaluated its accuracy. Methods: Medical records for 13,248 patients admitted to an orthopedic specialty hospital from 2009 to 2014 were reviewed. Patient encounters were defined as a hospital admission where both surgery (of the spine, hip, or knee) and a radiology diagnostic study that could detect VTE was performed. Radiology reports were both manually reviewed by a physician and analyzed by IDEAL-X. Results: Among 2083 radiology reports, IDEAL-X correctly identified 176/181 VTE events, achieving a sensitivity of 97.2% [95% confidence interval (CI), 93.7%-99.1%] and specificity of 99.3% (95% CI, 98.9%-99.7%) when compared with manual review. Among 422 surgical encounters with diagnostic radiographic studies for VTE, IDEAL-X correctly identified 41 of 42 VTE events, achieving a sensitivity of 97.6% (95% CI, 87.4%-99.6%) and specificity of 99.8% (95% CI, 98.7%-100.0%). The performance surpassed that of AHRQ PSI-12, which had a sensitivity of 92.9% (95% CI, 80.5%-98.4%) and specificity of 92.9% (95% CI, 89.8%-95.3%), though only the difference in specificity was statistically significant (P<0.01). Conclusion: IDEAL-X, a novel information extraction software system, identified VTE from radiology reports with high accuracy, with specificity surpassing AHRQ PSI-12. IDEAL-X could potentially improve detection and surveillance of many medical conditions from free text of electronic medical records. Copyright © 2017 Wolters Kluwer Health, Inc. All rights reserved.","machine learning; natural language processing; quality improvement; venous thromboembolism","Age Factors; Aged; Aged, 80 and over; Electronic Health Records; Female; Hospitals, Special; Humans; Information Storage and Retrieval; Length of Stay; Male; Middle Aged; Orthopedic Procedures; Sensitivity and Specificity; Sex Factors; United States; Venous Thromboembolism; acetylsalicylic acid; blood clotting factor 10a inhibitor; contrast medium; low molecular weight heparin; thrombin; warfarin; adult; aged; Article; computer assisted tomography; controlled study; controlled vocabulary; deep vein thrombosis; diagnostic accuracy; dyspnea; echography; electronic medical record; female; hip fracture; hip surgery; hospital admission; human; information retrieval; length of stay; lung embolism; machine learning; major clinical study; male; monotherapy; nuclear magnetic resonance imaging; priority journal; radiodiagnosis; sensitivity and specificity; spine surgery; thorax pain; thrombosis prevention; total knee arthroplasty; age; electronic health record; hospital; information retrieval; middle aged; organization and management; orthopedic surgery; procedures; sex factor; statistics and numerical data; United States; venous thromboembolism; very elderly","Lippincott Williams and Wilkins","00257079","","MDLCB","29087984","Article","Scopus","2-s2.0-85032946277"
"Yang J.-D.; Zhang P.","Yang, Jing-Dong (9747291400); Zhang, Peng (55547109257)","9747291400; 55547109257","Tongue image classification method based on transfer learning and fully connected neural network","2018","Academic Journal of Second Military Medical University","10","10.16781/j.0258-879x.2018.08.0897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053308654&doi=10.16781%2fj.0258-879x.2018.08.0897&partnerID=40&md5=52ff60dda8acd4c1f7a5053c42e5501d","School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China","Yang J.-D., School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China; Zhang P., School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China","Objective To propose a classification method for small sample tongue images based on transfer learning and fully connected neural network, so as to solve the problems of large amount of data, high requirement of training equipment and long training time of deep learning in the classification of tongue images. Methods Effective features such as tongue points and lines of tongue images were extracted by the convolution Inception_v3 network after training on the massive data set of ImageNet. The above features were classified by the fully connected neural network, and the image knowledge acquired by the deep learning network was transferred to the tongue image recognition task, and then the tongue data set were used to train and test the efficiency of the network. Results Compared with the typical tongue image classification method such as K-nearest neighbor (KNN) algorithm, support vector machine (SVM) algorithm and convolutional neural network (CNN) deep learning method, the two methods (Inception_v3＋2NN and Inception_v3＋3NN) in our experiment had higher classification rates for tongue images, with the accuracy rates being 90.30% and 93.98%, respectively, and had shorter training time for the sample. Conclusion Compared with KNN algorithm, SVM algorithm and CNN deep learning method, the tongue image classification method based on transfer learning and fully connected neural network can effectively improve the accuracy rate of tongue image classification and shorten the training time. © 2018, Second Military Medical University Press. All rights reserved.","Artificial intelligence; Convolutional neural network; Deep learning; Tongue presentations; Transfer learning","article; artificial intelligence; diagnostic test accuracy study; human; human experiment; k nearest neighbor; support vector machine; tongue; transfer of learning","Second Military Medical University Press","0258879X","","DJXUE","","Article","Scopus","2-s2.0-85053308654"
"Nebgen B.; Lubbers N.; Smith J.S.; Sifain A.E.; Lokhov A.; Isayev O.; Roitberg A.E.; Barros K.; Tretiak S.","Nebgen, Benjamin (25228953400); Lubbers, Nicholas (55617392500); Smith, Justin S. (57199013497); Sifain, Andrew E. (56685854400); Lokhov, Andrey (55937171900); Isayev, Olexandr (23060975100); Roitberg, Adrian E. (6701721729); Barros, Kipton (16041454700); Tretiak, Sergei (7003665075)","25228953400; 55617392500; 57199013497; 56685854400; 55937171900; 23060975100; 6701721729; 16041454700; 7003665075","Transferable Dynamic Molecular Charge Assignment Using Deep Neural Networks","2018","Journal of Chemical Theory and Computation","81","10.1021/acs.jctc.8b00524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051143067&doi=10.1021%2facs.jctc.8b00524&partnerID=40&md5=8c66c6965ae903dfef7ab7cffd069026","Theoretical Division, Los Alamos National Laboratory, Los Alamos, 87545, NM, United States; Department of Chemistry, University of Florida, Gainesville, 32611, FL, United States; Department of Physics and Astronomy, University of Southern California, Los Angeles, 90037, CA, United States; UNC Eshelman School, Pharmacy University of North Carolina Chapel Hill, Chapel Hill, 27599, NC, United States","Nebgen B., Theoretical Division, Los Alamos National Laboratory, Los Alamos, 87545, NM, United States; Lubbers N., Theoretical Division, Los Alamos National Laboratory, Los Alamos, 87545, NM, United States; Smith J.S., Theoretical Division, Los Alamos National Laboratory, Los Alamos, 87545, NM, United States, Department of Chemistry, University of Florida, Gainesville, 32611, FL, United States; Sifain A.E., Theoretical Division, Los Alamos National Laboratory, Los Alamos, 87545, NM, United States, Department of Physics and Astronomy, University of Southern California, Los Angeles, 90037, CA, United States; Lokhov A., Theoretical Division, Los Alamos National Laboratory, Los Alamos, 87545, NM, United States; Isayev O., UNC Eshelman School, Pharmacy University of North Carolina Chapel Hill, Chapel Hill, 27599, NC, United States; Roitberg A.E., Department of Chemistry, University of Florida, Gainesville, 32611, FL, United States; Barros K., Theoretical Division, Los Alamos National Laboratory, Los Alamos, 87545, NM, United States; Tretiak S., Theoretical Division, Los Alamos National Laboratory, Los Alamos, 87545, NM, United States","The ability to accurately and efficiently compute quantum-mechanical partial atomistic charges has many practical applications, such as calculations of IR spectra, analysis of chemical bonding, and classical force field parametrization. Machine learning (ML) techniques provide a possible avenue for the efficient prediction of atomic partial charges. Modern ML advances in the prediction of molecular energies [i.e., the hierarchical interacting particle neural network (HIP-NN)] has provided the necessary model framework and architecture to predict transferable, extensible, and conformationally dynamic atomic partial charges based on reference density functional theory (DFT) simulations. Utilizing HIP-NN, we show that ML charge prediction can be highly accurate over a wide range of molecules (both small and large) across a variety of charge partitioning schemes such as the Hirshfeld, CM5, MSK, and NBO methods. To demonstrate transferability and size extensibility, we compare ML results with reference DFT calculations on the COMP6 benchmark, achieving errors of 0.004e- (elementary charge). This is remarkable since this benchmark contains two proteins that are multiple times larger than the largest molecules in the training set. An application of our atomic charge predictions on nonequilibrium geometries is the generation of IR spectra for organic molecules from dynamical trajectories on a variety of organic molecules, which show good agreement with calculated IR spectra with reference method. Critically, HIP-NN charge predictions are many orders of magnitude faster than direct DFT calculations. These combined results provide further evidence that ML (specifically HIP-NN) provides a pathway to greatly increase the range of feasible simulations while retaining quantum-level accuracy. © 2018 American Chemical Society.","","Methanol; Models, Chemical; Molecular Dynamics Simulation; Neural Networks (Computer); Proteins; Spectrophotometry, Infrared; methanol; protein; artificial neural network; chemical model; chemistry; infrared spectrophotometry; molecular dynamics","American Chemical Society","15499618","","JCTCC","30064217","Article","Scopus","2-s2.0-85051143067"
"Vununu C.; Moon K.-S.; Lee S.-H.; Kwon K.-R.","Vununu, Caleb (57202463837); Moon, Kwang-Seok (9336115600); Lee, Suk-Hwan (24721765800); Kwon, Ki-Ryong (13606061300)","57202463837; 9336115600; 24721765800; 13606061300","A deep feature learning method for drill bits monitoring using the spectral analysis of the acoustic signals","2018","Sensors (Switzerland)","13","10.3390/s18082634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052060634&doi=10.3390%2fs18082634&partnerID=40&md5=da9f523e52c6a5f9652741d30d3d0808","Department of IT Convergence and Application Engineering, Pukyong National University, Busan, 48513, South Korea; Department of Electronics Engineering, Pukyong National University, Busan, 48513, South Korea; Department of Information Security, Tongmyong University, Busan, 48520, South Korea","Vununu C., Department of IT Convergence and Application Engineering, Pukyong National University, Busan, 48513, South Korea; Moon K.-S., Department of Electronics Engineering, Pukyong National University, Busan, 48513, South Korea; Lee S.-H., Department of Information Security, Tongmyong University, Busan, 48520, South Korea; Kwon K.-R., Department of IT Convergence and Application Engineering, Pukyong National University, Busan, 48513, South Korea","Machine fault diagnosis (MFD) has gained an important enthusiasm since the unfolding of the pattern recognition techniques in the last three decades. It refers to all of the studies that aim to automatically detect the faults on the machines using various kinds of signals that they can generate. The present work proposes a MFD system for the drilling machines that is based on the sounds they produce. The first key contribution of this paper is to present a system specifically designed for the drills, by attempting not only to detect the faulty drills but also to detect whether the sounds were generated during the active or the idling stage of the whole machinery system, in order to provide a complete remote control. The second key contribution of the work is to represent the power spectrum of the sounds as images and apply some transformations on them in order to reveal, expose, and emphasize the health patterns that are hidden inside them. The created images, the so-called power spectrum density (PSD)-images, are then given to a deep convolutional autoencoder (DCAE) for a high-level feature extraction process. The final step of the scheme consists of adopting the proposed PSD-images + DCAE features as the final representation of the original sounds and utilize them as the inputs of a nonlinear classifier whose outputs will represent the final diagnosis decision. The results of the experiments demonstrate the high discrimination potential afforded by the proposed PSD-images + DCAE features. They were also tested on a noisy dataset and the results show their robustness against noises. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial neural network; Deep convolutional autoencoder; Deep learning; Machine fault diagnosis; Machine learning; Pattern recognition; Smart factory; Sound and acoustic processing","Convolution; Deep learning; Drills; Failure analysis; Infill drilling; Learning systems; Machinery; Neural networks; Pattern recognition; Power spectrum; Remote control; Spectrum analysis; Auto encoders; High-level feature extractions; Machine fault diagnosis; Nonlinear classifiers; Pattern recognition techniques; Power spectrum density; Robustness against noise; Sound and acoustic; Fault detection","MDPI AG","14248220","","","30103498","Article","Scopus","2-s2.0-85052060634"
"Hill S.T.; Kuintzle R.; Teegarden A.; Merrill E., III; Danaee P.; Hendrix D.A.","Hill, Steven T. (56894649000); Kuintzle, Rachael (56815011900); Teegarden, Amy (8581387200); Merrill, Erich (57205718905); Danaee, Padideh (57194759816); Hendrix, David A. (24390320000)","56894649000; 56815011900; 8581387200; 57205718905; 57194759816; 24390320000","A deep recurrent neural network discovers complex biological rules to decipher RNA protein-coding potential","2018","Nucleic Acids Research","53","10.1093/nar/gky567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057336960&doi=10.1093%2fnar%2fgky567&partnerID=40&md5=36fdf0ff1afa664d690ef0a550242c0e","School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, 97331, OR, United States; Department of Biochemistry and Biophysics, Oregon State University, 2011 Ag & Life Sciences Bldg, Corvallis, 97331, OR, United States; New York Genome Center, 101 Avenue of the Americas, New York, 10013, NY, United States; Department of Chemistry and Chemical Engineering, California Institute of Technology, 1200 East California Blvd, Pasadena, 91125, CA, United States","Hill S.T., School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, 97331, OR, United States, New York Genome Center, 101 Avenue of the Americas, New York, 10013, NY, United States; Kuintzle R., Department of Biochemistry and Biophysics, Oregon State University, 2011 Ag & Life Sciences Bldg, Corvallis, 97331, OR, United States, Department of Chemistry and Chemical Engineering, California Institute of Technology, 1200 East California Blvd, Pasadena, 91125, CA, United States; Teegarden A., Department of Biochemistry and Biophysics, Oregon State University, 2011 Ag & Life Sciences Bldg, Corvallis, 97331, OR, United States; Merrill E., III, School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, 97331, OR, United States; Danaee P., School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, 97331, OR, United States; Hendrix D.A., School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, 97331, OR, United States, Department of Biochemistry and Biophysics, Oregon State University, 2011 Ag & Life Sciences Bldg, Corvallis, 97331, OR, United States","The current deluge of newly identified RNA transcripts presents a singular opportunity for improved assessment of coding potential, a cornerstone of genome annotation, and for machine-driven discovery of biological knowledge. While traditional, feature-based methods for RNA classification are limited by current scientific knowledge, deep learning methods can independently discover complex biological rules in the data de novo. We trained a gated recurrent neural network (RNN) on human messenger RNA (mRNA) and long noncoding RNA (lncRNA) sequences. Our model, mRNA RNN (mRNN), surpasses state-of-the-art methods at predicting protein-coding potential despite being trained with less data and with no prior concept of what features define mRNAs. To understand what mRNN learned, we probed the network and uncovered several context-sensitive codons highly predictive of coding potential. Our results suggest that gated RNNs can learn complex and long-range patterns in full-length human transcripts, making them ideal for performing a wide range of difficult classification tasks and, most importantly, for harvesting new biological insights from the rising flood of sequencing data. © The Author(s) 2018. Published by Oxford University Press on behalf of Nucleic Acids Research.","","Base Sequence; Computational Biology; Humans; Machine Learning; Neural Networks (Computer); Open Reading Frames; Protein Biosynthesis; Reproducibility of Results; RNA, Long Noncoding; RNA, Messenger; Sequence Analysis, RNA; adenine; cytosine; guanine; long untranslated RNA; messenger RNA; parathyroid hormone; protein coding RNA; RNA; transcriptome; tumor antigen; unclassified drug; uracil; long untranslated RNA; messenger RNA; 3' untranslated region; 5' untranslated region; accuracy; Article; artificial neural network; classifier; codon; controlled study; deep learning; deep recurrent neural network; diagnostic test accuracy study; gated recurrent unit network; genetic transcription; human; mouse; mutational analysis; nonhuman; point mutation; prediction; priority journal; protein analysis; RNA protein coding potential; RNA sequence; scoring system; sensitivity and specificity; start codon; stop codon; support vector machine; translation indicating codon; validation study; biology; genetics; machine learning; nucleotide sequence; open reading frame; procedures; protein synthesis; reproducibility; sequence analysis","Oxford University Press","03051048","","NARHA","29986088","Article","Scopus","2-s2.0-85057336960"
"Heinrich M.P.; Blendowski M.; Oktay O.","Heinrich, Mattias P. (52363917500); Blendowski, Max (55749899400); Oktay, Ozan (36782675600)","52363917500; 55749899400; 36782675600","TernaryNet: faster deep model inference without GPUs for medical 3D segmentation using sparse and binary convolutions","2018","International Journal of Computer Assisted Radiology and Surgery","24","10.1007/s11548-018-1797-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047816042&doi=10.1007%2fs11548-018-1797-4&partnerID=40&md5=d50bf0e5172f4c613f04e715dbc54827","Institute of Medical Informatics, University of Lübeck, Ratzeburger Allee 160, Lübeck, 23562, Germany; Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom","Heinrich M.P., Institute of Medical Informatics, University of Lübeck, Ratzeburger Allee 160, Lübeck, 23562, Germany; Blendowski M., Institute of Medical Informatics, University of Lübeck, Ratzeburger Allee 160, Lübeck, 23562, Germany; Oktay O., Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom","Purpose: Deep convolutional neural networks (DCNN) are currently ubiquitous in medical imaging. While their versatility and high-quality results for common image analysis tasks including segmentation, localisation and prediction is astonishing, the large representational power comes at the cost of highly demanding computational effort. This limits their practical applications for image-guided interventions and diagnostic (point-of-care) support using mobile devices without graphics processing units (GPU). Methods: We propose a new scheme that approximates both trainable weights and neural activations in deep networks by ternary values and tackles the open question of backpropagation when dealing with non-differentiable functions. Our solution enables the removal of the expensive floating-point matrix multiplications throughout any convolutional neural network and replaces them by energy- and time-preserving binary operators and population counts. Results: We evaluate our approach for the segmentation of the pancreas in CT. Here, our ternary approximation within a fully convolutional network leads to more than 90% memory reductions and high accuracy (without any post-processing) with a Dice overlap of 71.0% that comes close to the one obtained when using networks with high-precision weights and activations. We further provide a concept for sub-second inference without GPUs and demonstrate significant improvements in comparison with binary quantisation and without our proposed ternary hyperbolic tangent continuation. Conclusions: We present a key enabling technique for highly efficient DCNN inference without GPUs that will help to bring the advances of deep learning to practical clinical applications. It has also great promise for improving accuracies in large-scale medical data retrieval. © 2018, CARS.","Deep learning; Hamming distance; Model compression; Pancreas; Segmentation; Sparsity","Algorithms; Humans; Imaging, Three-Dimensional; Neural Networks (Computer); Pancreas; Support Vector Machine; Tomography, X-Ray Computed; Article; back propagation; computer graphics; data processing; image segmentation; nonlinear system; pancreas; priority journal; three dimensional imaging; x-ray computed tomography; algorithm; artificial neural network; diagnostic imaging; human; procedures; support vector machine; three dimensional imaging; x-ray computed tomography","Springer Verlag","18616410","","","29850978","Article","Scopus","2-s2.0-85047816042"
"Ansari A.H.; De Wel O.; Lavanga M.; Caicedo A.; Dereymaeker A.; Jansen K.; Vervisch J.; De Vos M.; Naulaers G.; Van Huffel S.","Ansari, Amir Hossein (56647537500); De Wel, Ofelie (57188869902); Lavanga, Mario (57196123235); Caicedo, Alexander (36717350200); Dereymaeker, Anneleen (57147439500); Jansen, Katrien (36655773300); Vervisch, Jan (6603500428); De Vos, Maarten (15834083300); Naulaers, Gunnar (7003953587); Van Huffel, Sabine (7004954228)","56647537500; 57188869902; 57196123235; 36717350200; 57147439500; 36655773300; 6603500428; 15834083300; 7003953587; 7004954228","Quiet sleep detection in preterm infants using deep convolutional neural networks","2018","Journal of Neural Engineering","38","10.1088/1741-2552/aadc1f","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056640275&doi=10.1088%2f1741-2552%2faadc1f&partnerID=40&md5=e8c4d90292f0be7dafb243e04340c93f","Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven, Leuven, Belgium; Imec, Leuven, Belgium; Department of Applied Mathematics and Computer Science, Faculty of Natural Sciences and Mathematics, Universidad Del Rosario, Bogotá, Colombia; Department of Development and Regeneration, University Hospitals Leuven, Neonatal Intensive Care Unit, KU Leuven, Leuven, Belgium; Department of Development and Regeneration, University Hospitals Leuven, Neonatal Intensive Care Unit and Child Neurology, KU Leuven, Leuven, Belgium; Department of Engineering Science, Institute of Biomedical Engineering (IBME), University of Oxford, Oxford, United Kingdom","Ansari A.H., Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven, Leuven, Belgium, Imec, Leuven, Belgium; De Wel O., Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven, Leuven, Belgium, Imec, Leuven, Belgium; Lavanga M., Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven, Leuven, Belgium, Imec, Leuven, Belgium; Caicedo A., Department of Applied Mathematics and Computer Science, Faculty of Natural Sciences and Mathematics, Universidad Del Rosario, Bogotá, Colombia; Dereymaeker A., Department of Development and Regeneration, University Hospitals Leuven, Neonatal Intensive Care Unit, KU Leuven, Leuven, Belgium; Jansen K., Department of Development and Regeneration, University Hospitals Leuven, Neonatal Intensive Care Unit, KU Leuven, Leuven, Belgium, Department of Development and Regeneration, University Hospitals Leuven, Neonatal Intensive Care Unit and Child Neurology, KU Leuven, Leuven, Belgium; Vervisch J., Department of Development and Regeneration, University Hospitals Leuven, Neonatal Intensive Care Unit, KU Leuven, Leuven, Belgium; De Vos M., Department of Engineering Science, Institute of Biomedical Engineering (IBME), University of Oxford, Oxford, United Kingdom; Naulaers G., Department of Development and Regeneration, University Hospitals Leuven, Neonatal Intensive Care Unit, KU Leuven, Leuven, Belgium; Van Huffel S., Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven, Leuven, Belgium, Imec, Leuven, Belgium","Objective. Neonates spend most of their time asleep. Sleep of preterm infants evolves rapidly throughout maturation and plays an important role in brain development. Since visual labelling of the sleep stages is a time consuming task, automated analysis of electroencephalography (EEG) to identify sleep stages is of great interest to clinicians. This automated sleep scoring can aid in optimizing neonatal care and assessing brain maturation. Approach. In this study, we designed and implemented an 18-layer convolutional neural network to discriminate quiet sleep from non-quiet sleep in preterm infants. The network is trained on 54 recordings from 13 preterm neonates and the performance is assessed on 43 recordings from 13 independent patients. All neonates had a normal neurodevelopmental outcome and the EEGs were recorded between 27 and 42 weeks postmenstrual age. Main results. The proposed network achieved an area under the mean and median ROC curve equal to 92% and 98%, respectively. Significance. Our findings suggest that CNN is a suitable and fast approach to classify neonatal sleep stages in preterm infants. © 2018 IOP Publishing Ltd.","convolutional neural network; EEG; preterm neonate; sleep stage classification","Algorithms; Automation; Brain; Electroencephalography; Female; Humans; Infant, Newborn; Infant, Premature; Male; Neural Networks (Computer); Sleep; Sleep Stages; Wakefulness; Article; brain development; brain maturation; classification; clinical article; convolutional neural network; correlation analysis; electroencephalogram; electroencephalography; feature extraction; human; infant; machine learning; nerve cell differentiation; newborn care; prematurity; priority journal; receiver operating characteristic; sleep; sleep stage; algorithm; artificial neural network; automation; brain; female; growth, development and aging; male; newborn; physiology; prematurity; procedures; sleep; wakefulness","Institute of Physics Publishing","17412560","","","30132438","Article","Scopus","2-s2.0-85056640275"
"Sultan M.M.; Pande V.S.","Sultan, Mohammad M. (55241174600); Pande, Vijay S. (7004966384)","55241174600; 7004966384","Automated design of collective variables using supervised machine learning","2018","Journal of Chemical Physics","94","10.1063/1.5029972","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053132306&doi=10.1063%2f1.5029972&partnerID=40&md5=6c148f63f77663884485d92a5e109e79","Department of Chemistry, Stanford University, 318 Campus Drive, Stanford, 94305, CA, United States; Department of Bioengineering, Stanford University, 318 Campus Drive, Stanford, 94305, CA, United States","Sultan M.M., Department of Chemistry, Stanford University, 318 Campus Drive, Stanford, 94305, CA, United States; Pande V.S., Department of Bioengineering, Stanford University, 318 Campus Drive, Stanford, 94305, CA, United States","Selection of appropriate collective variables (CVs) for enhancing sampling of molecular simulations remains an unsolved problem in computational modeling. In particular, picking initial CVs is particularly challenging in higher dimensions. Which atomic coordinates or transforms there of from a list of thousands should one pick for enhanced sampling runs? How does a modeler even begin to pick starting coordinates for investigation? This remains true even in the case of simple two state systems and only increases in difficulty for multi-state systems. In this work, we solve the “initial” CV problem using a data-driven approach inspired by the field of supervised machine learning (SML). In particular, we show how the decision functions in SML algorithms can be used as initial CVs (SMLcv) for accelerated sampling. Using solvated alanine dipeptide and Chignolin mini-protein as our test cases, we illustrate how the distance to the support vector machines’ decision hyperplane, the output probability estimates from logistic regression, the outputs from shallow or deep neural network classifiers, and other classifiers may be used to reversibly sample slow structural transitions. We discuss the utility of other SML algorithms that might be useful for identifying CVs for accelerating molecular simulations. © 2018 Author(s).","","Amino acids; Artificial intelligence; Deep neural networks; Molecular structure; Collective variables; Decision hyperplanes; Logistic regressions; Molecular simulations; Neural network classifier; Probability estimate; Structural transitions; Supervised machine learning; Supervised learning","American Institute of Physics Inc.","00219606","","JCPSA","30195289","Article","Scopus","2-s2.0-85053132306"
"Xie L.; He S.; Song X.; Bo X.; Zhang Z.","Xie, Lingwei (57111215600); He, Song (56770438600); Song, Xinyu (57214073161); Bo, Xiaochen (7005391024); Zhang, Zhongnan (56068760200)","57111215600; 56770438600; 57214073161; 7005391024; 56068760200","Deep learning-based transcriptome data classification for drug-target interaction prediction","2018","BMC Genomics","62","10.1186/s12864-018-5031-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053792187&doi=10.1186%2fs12864-018-5031-0&partnerID=40&md5=785075f42f57cc8d6ca9c096ac90aa65","Xiamen University, Xiamen, 361005, China; Beijing Institute of Radiation Medicine, Beijing, 100850, China","Xie L., Xiamen University, Xiamen, 361005, China; He S., Beijing Institute of Radiation Medicine, Beijing, 100850, China; Song X., Beijing Institute of Radiation Medicine, Beijing, 100850, China; Bo X., Beijing Institute of Radiation Medicine, Beijing, 100850, China; Zhang Z., Xiamen University, Xiamen, 361005, China","Background: The ability to predict the interaction of drugs with target proteins is essential to research and development of drug. However, the traditional experimental paradigm is costly, and previous in silico prediction paradigms have been impeded by the wide range of data platforms and data scarcity. Results: In this paper, we modeled the prediction of drug-target interactions as a binary classification task. Using transcriptome data from the L1000 database of the LINCS project, we developed a framework based on a deep-learning algorithm to predict potential drug target interactions. Once fully trained, the model achieved over 98% training accuracy. The results of our research demonstrated that our framework could discover more reliable DTIs than found by other methods. This conclusion was validated further across platforms with a high percentage of overlapping interactions. Conclusions: Our model's capacity of integrating transcriptome data from drugs and genes strongly suggests the strength of its potential for DTI prediction, thereby improving the drug discovery process. © 2018 The Author(s).","Deep learning; Drug-target interaction; LINCS project; Transcriptome data","Algorithms; Computer Simulation; Databases, Factual; Drug Discovery; Drug Interactions; Gene Expression Profiling; Humans; Machine Learning; Models, Theoretical; Molecular Targeted Therapy; Proteins; Transcriptome; transcriptome; protein; transcriptome; Article; artificial neural network; controlled study; decision tree; drug protein binding; learning algorithm; learning curve; linear regression analysis; measurement accuracy; nonlinear system; prediction; protein protein interaction; transcriptomics; validation process; algorithm; computer simulation; drug development; drug interaction; factual database; gene expression profiling; genetics; human; machine learning; metabolism; molecularly targeted therapy; procedures; theoretical model","BioMed Central Ltd.","14712164","","BGMEE","30255785","Article","Scopus","2-s2.0-85053792187"
"Dhoble A.S.; Lahiri P.; Bhalerao K.D.","Dhoble, Abhishek S. (57194014435); Lahiri, Pratik (56157536100); Bhalerao, Kaustubh D. (6506415397)","57194014435; 56157536100; 6506415397","Machine learning analysis of microbial flow cytometry data from nanoparticles, antibiotics and carbon sources perturbed anaerobic microbiomes","2018","Journal of Biological Engineering","11","10.1186/s13036-018-0112-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053283853&doi=10.1186%2fs13036-018-0112-9&partnerID=40&md5=b1adbcd0316e279b8c366f3727d338f8","Department of Agricultural and Biological Engineering, University of Illinois at Urbana-Champaign, 1304 W. Pennsylvania, Urbana, 61801, United States","Dhoble A.S., Department of Agricultural and Biological Engineering, University of Illinois at Urbana-Champaign, 1304 W. Pennsylvania, Urbana, 61801, United States; Lahiri P., Department of Agricultural and Biological Engineering, University of Illinois at Urbana-Champaign, 1304 W. Pennsylvania, Urbana, 61801, United States; Bhalerao K.D., Department of Agricultural and Biological Engineering, University of Illinois at Urbana-Champaign, 1304 W. Pennsylvania, Urbana, 61801, United States","Background: Flow cytometry, with its high throughput nature, combined with the ability to measure an increasing number of cell parameters at once can surpass the throughput of prevalent genomic and metagenomic approaches in the study of microbiomes. Novel computational approaches to analyze flow cytometry data will result in greater insights and actionability as compared to traditional tools used in the analysis of microbiomes. This paper is a demonstration of the fruitfulness of machine learning in analyzing microbial flow cytometry data generated in anaerobic microbiome perturbation experiments. Results: Autoencoders were found to be powerful in detecting anomalies in flow cytometry data from nanoparticles and carbon sources perturbed anaerobic microbiomes but was marginal in predicting perturbations due to antibiotics. A comparison between different algorithms based on predictive capabilities suggested that gradient boosting (GB) and deep learning, i.e. feed forward artificial neural network with three hidden layers (DL) were marginally better under tested conditions at predicting overall community structure while distributed random forests (DRF) worked better for predicting the most important putative microbial group(s) in the anaerobic digesters viz. methanogens, and it can be optimized with better parameter tuning. Predictive classification patterns with DL (feed forward artificial neural network with three hidden layers) were found to be comparable to previously demonstrated multivariate analysis. The potential applications of this approach have been demonstrated for monitoring the syntrophic resilience of the anaerobic microbiomes perturbed by synthetic nanoparticles as well as antibiotics. Conclusion: Machine learning can benefit the microbial flow cytometry research community by providing rapid screening and characterization tools to discover patterns in the dynamic response of microbiomes to several stimuli. © 2018 The Author(s).","Anaerobic digestion; Deep learning; Flow cytometry; Machine learning; Microbial community fingerprinting; Pattern recognition","antibiotic agent; carbon; fluorescent dye; nanoparticle; algorithm; anaerobe; anaerobic digestion; Article; artificial neural network; autofluorescence; carbon source; cell size; cell structure; community structure; controlled study; deep learning; distributed random forest; flow cytometry; gradient boosting; intermethod comparison; machine learning; methanogen; microbial community; microbiome; multivariate analysis; nonhuman; positive feedback; prediction; priority journal; random forest","BioMed Central Ltd.","17541611","","","","Article","Scopus","2-s2.0-85053283853"
"Gonczarek A.; Tomczak J.M.; Zaręba S.; Kaczmar J.; Dąbrowski P.; Walczak M.J.","Gonczarek, Adam (12544668700); Tomczak, Jakub M. (36471022200); Zaręba, Szymon (55701852000); Kaczmar, Joanna (57195715204); Dąbrowski, Piotr (57195717884); Walczak, Michał J. (55914912100)","12544668700; 36471022200; 55701852000; 57195715204; 57195717884; 55914912100","Interaction prediction in structure-based virtual screening using deep learning","2018","Computers in Biology and Medicine","65","10.1016/j.compbiomed.2017.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029575583&doi=10.1016%2fj.compbiomed.2017.09.007&partnerID=40&md5=0230f06b5aa230d2a8e8e989dff305aa","Department of Computer Science, Wrocław University of Science and Technology, Poland; Indata SA, Wrocław, Poland; Alphamoon, Wrocław, Poland","Gonczarek A., Department of Computer Science, Wrocław University of Science and Technology, Poland, Alphamoon, Wrocław, Poland; Tomczak J.M., Department of Computer Science, Wrocław University of Science and Technology, Poland; Zaręba S., Department of Computer Science, Wrocław University of Science and Technology, Poland, Alphamoon, Wrocław, Poland; Kaczmar J., Department of Computer Science, Wrocław University of Science and Technology, Poland; Dąbrowski P., Department of Computer Science, Wrocław University of Science and Technology, Poland, Indata SA, Wrocław, Poland; Walczak M.J., Alphamoon, Wrocław, Poland","We introduce a deep learning architecture for structure-based virtual screening that generates fixed-sized fingerprints of proteins and small molecules by applying learnable atom convolution and softmax operations to each molecule separately. These fingerprints are further non-linearly transformed, their inner product is calculated and used to predict the binding potential. Moreover, we show that widely used benchmark datasets may be insufficient for testing structure-based virtual screening methods that utilize machine learning. Therefore, we introduce a new benchmark dataset, which we constructed based on DUD-E, MUV and PDBBind databases. © 2017 Elsevier Ltd","Deep learning; DUD-E; Graph convolution; MUV; Neural fingerprint; PDBBind; Virtual screening","Databases, Protein; Deep Learning; Protein Conformation; Proteins; Convolution; E-learning; Molecules; protein; Benchmark datasets; Binding potential; Interaction prediction; Learning architectures; Neural fingerprint; PDBBind; Testing structures; Virtual Screening; Article; binding affinity; binding site; drug protein binding; machine learning; nuclear magnetic resonance; priority journal; protein database; protein structure; chemistry; protein conformation; protein database; Deep learning","Elsevier Ltd","00104825","","CBMDA","28941550","Article","Scopus","2-s2.0-85029575583"
"Hoseini F.; Shahbahrami A.; Bayat P.","Hoseini, Farnaz (56979189900); Shahbahrami, Asadollah (8865277800); Bayat, Peyman (55887561600)","56979189900; 8865277800; 55887561600","An Efficient Implementation of Deep Convolutional Neural Networks for MRI Segmentation","2018","Journal of Digital Imaging","36","10.1007/s10278-018-0062-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042619764&doi=10.1007%2fs10278-018-0062-2&partnerID=40&md5=f6b0294af7953cf8f9e0a3edb7587d4c","Department of Computer Engineering, Rasht Branch, Islamic Azad University, Rasht, Iran; Department of Computer Engineering, Faculty of Engineering, University of Guilan, Rasht, Iran","Hoseini F., Department of Computer Engineering, Rasht Branch, Islamic Azad University, Rasht, Iran; Shahbahrami A., Department of Computer Engineering, Faculty of Engineering, University of Guilan, Rasht, Iran; Bayat P., Department of Computer Engineering, Rasht Branch, Islamic Azad University, Rasht, Iran","Image segmentation is one of the most common steps in digital image processing, classifying a digital image into different segments. The main goal of this paper is to segment brain tumors in magnetic resonance images (MRI) using deep learning. Tumors having different shapes, sizes, brightness and textures can appear anywhere in the brain. These complexities are the reasons to choose a high-capacity Deep Convolutional Neural Network (DCNN) containing more than one layer. The proposed DCNN contains two parts: architecture and learning algorithms. The architecture and the learning algorithms are used to design a network model and to optimize parameters for the network training phase, respectively. The architecture contains five convolutional layers, all using 3 × 3 kernels, and one fully connected layer. Due to the advantage of using small kernels with fold, it allows making the effect of larger kernels with smaller number of parameters and fewer computations. Using the Dice Similarity Coefficient metric, we report accuracy results on the BRATS 2016, brain tumor segmentation challenge dataset, for the complete, core, and enhancing regions as 0.90, 0.85, and 0.84 respectively. The learning algorithm includes the task-level parallelism. All the pixels of an MR image are classified using a patch-based approach for segmentation. We attain a good performance and the experimental results show that the proposed DCNN increases the segmentation accuracy compared to previous techniques. © 2018, Society for Imaging Informatics in Medicine.","Deep convolutional neural networks; Deep learning; Image segmentation; Medical image; MRI; MRI segmentation","Algorithms; Brain; Brain Neoplasms; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Brain; Convolution; Deep learning; Deep neural networks; Image classification; Image segmentation; Magnetic levitation vehicles; Magnetic resonance; Magnetic resonance imaging; Medical imaging; Network architecture; Neural networks; Parameter estimation; Tumors; Brain tumor segmentation; Deep convolutional neural networks; Efficient implementation; Fully-connected layers; Magnetic resonance images (MRI); MRI segmentation; Similarity coefficients; Task level parallelisms; algorithm; artificial neural network; brain; brain tumor; computer assisted diagnosis; diagnostic imaging; human; machine learning; nuclear magnetic resonance imaging; procedures; Learning algorithms","Springer New York LLC","08971889","","JDIME","29488179","Article","Scopus","2-s2.0-85042619764"
"Sun W.; Zhao H.; Jin Z.","Sun, Wenyun (57193737107); Zhao, Haitao (58090034600); Jin, Zhong (36915349100)","57193737107; 58090034600; 36915349100","A complementary facial representation extracting method based on deep learning","2018","Neurocomputing","24","10.1016/j.neucom.2018.04.063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047087926&doi=10.1016%2fj.neucom.2018.04.063&partnerID=40&md5=3588f37f574a2a925214f439a1373fd3","School of Computer Science and Engineering, Nanjing University of Science and Technology, China; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, Nanjing University of Science and Technology, China; School of Information Science and Engineering, East China University of Science and Technology, China","Sun W., School of Computer Science and Engineering, Nanjing University of Science and Technology, China, Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, Nanjing University of Science and Technology, China; Zhao H., School of Information Science and Engineering, East China University of Science and Technology, China; Jin Z., School of Computer Science and Engineering, Nanjing University of Science and Technology, China, Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, Nanjing University of Science and Technology, China","The identification and expression are two orthogonal properties of faces. But, few studies considered the two properties together. In this paper, the two properties are modeled in a unified framework. A pair of 18-layered Convolutional Deconvolutional Networks (Conv-Deconv) is proposed to learn a bidirectional mapping between the emotional expressions and the neutral expressions. One network extracts the complementary facial representations (i.e. identification representations and emotional representations) from emotional faces. The other network reconstructs the original faces from the extracted representations. Two networks are mutually inverse functions. Based on the framework, the networks are extended for various tasks, including face generation, face interpolation, facial expression recognition, and face verification. A new facial expression dataset called Large-scale Synthesized Facial Expression Dataset (LSFED) is presented. The dataset contains 105,000 emotional faces of 15,000 subjects synthesized by computer graphics program. Its distorted version (LSFED-D) is also presented to increase the difficulty and mimic real-world conditions. Good experiment results are obtained after evaluating our method on the synthesized clean LSFED dataset, the synthesized distorted LSFED-D dataset, and the real-world RaFD dataset. © 2018 Elsevier B.V.","Complementary facial representation; Deep learning; Facial expression","Computer graphics; Deep learning; Human computer interaction; Inverse problems; Bidirectional mapping; Complementary facial representation; Emotional expressions; Emotional representations; Facial expression recognition; Facial Expressions; Orthogonal property; Unified framework; Article; artificial neural network; automated pattern recognition; computer graphics; convolutional deconvolutional network; facial expression; feature extraction; machine learning; priority journal; Face recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85047087926"
"Kyathanahally S.P.; Döring A.; Kreis R.","Kyathanahally, Sreenath P. (55981970000); Döring, André (57193846649); Kreis, Roland (7004885824)","55981970000; 57193846649; 7004885824","Deep learning approaches for detection and removal of ghosting artifacts in MR spectroscopy","2018","Magnetic Resonance in Medicine","62","10.1002/mrm.27096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041167577&doi=10.1002%2fmrm.27096&partnerID=40&md5=da45fcd40eceedb303792ac384f3ced8","Departments of Radiology and Biomedical Research, University of Bern, Bern, Switzerland; Graduate School for Cellular and Biomedical Sciences, University of Bern, Bern, Switzerland","Kyathanahally S.P., Departments of Radiology and Biomedical Research, University of Bern, Bern, Switzerland, Graduate School for Cellular and Biomedical Sciences, University of Bern, Bern, Switzerland; Döring A., Departments of Radiology and Biomedical Research, University of Bern, Bern, Switzerland, Graduate School for Cellular and Biomedical Sciences, University of Bern, Bern, Switzerland; Kreis R., Departments of Radiology and Biomedical Research, University of Bern, Bern, Switzerland","Purpose: To make use of deep learning (DL) methods to detect and remove ghosting artifacts in clinical magnetic resonance spectra of human brain. Methods: Deep learning algorithms, including fully connected neural networks, deep-convolutional neural networks, and stacked what-where auto encoders, were implemented to detect and correct MR spectra containing spurious echo ghost signals. The DL methods were trained on a huge database of simulated spectra with and without ghosting artifacts that represent complex variations of ghost-ridden spectra, transformed to time-frequency spectrograms. The trained model was tested on simulated and in vivo spectra. Results: The preliminary results for ghost detection are very promising, reaching almost 100% accuracy, and the DL ghost removal methods show potential in simulated and in vivo spectra, but need further refinement and quantitative testing. Conclusions: Ghosting artifacts in spectroscopy are problematic, as they superimpose with metabolites and lead to inaccurate quantification. Detection and removal of ghosting artifacts using traditional machine learning approaches with feature extraction/selection is difficult, as ghosts appear at different frequencies. Here, we show that DL methods perform extremely well for ghost detection if the spectra are treated as images in the form of time-frequency representations. Further optimization for in vivo spectra will hopefully confirm their “ghostbusting” capacity. Magn Reson Med 80:851–863, 2018. © 2018 International Society for Magnetic Resonance in Medicine. © 2018 International Society for Magnetic Resonance in Medicine","artifacts; deep learning; human brain; machine learning; magnetic resonance spectroscopy; quality control; time-frequency representation","Algorithms; Artifacts; Brain; Computer Simulation; Deep Learning; Gray Matter; Healthy Volunteers; Humans; Image Enhancement; Image Processing, Computer-Assisted; Magnetic Resonance Spectroscopy; Neural Networks (Computer); Normal Distribution; Signal-To-Noise Ratio; Brain; Convolutional neural networks; Deep neural networks; Feature extraction; Lead metallography; Learning algorithms; Learning systems; Magnetic resonance; Magnetic resonance spectroscopy; Magnetism; Metabolites; Quality control; artifacts; Feature extraction/selection; Fully connected neural network; Human brain; International society; Machine learning approaches; Magnetic resonance spectra; Time-frequency representations; article; artifact; brain; extraction; human; human experiment; in vivo study; learning algorithm; metabolite; nuclear magnetic resonance spectroscopy; preliminary data; quality control; simulation; algorithm; artificial neural network; brain; computer simulation; diagnostic imaging; gray matter; image enhancement; image processing; normal distribution; normal human; procedures; signal noise ratio; Deep learning","John Wiley and Sons Inc","07403194","","MRMEE","29388313","Article","Scopus","2-s2.0-85041167577"
"Fernandez M.; Ban F.; Woo G.; Hsing M.; Yamazaki T.; Leblanc E.; Rennie P.S.; Welch W.J.; Cherkasov A.","Fernandez, Michael (57199901530); Ban, Fuqiang (6601993195); Woo, Godwin (57203283037); Hsing, Michael (6602999080); Yamazaki, Takeshi (57192818079); Leblanc, Eric (57197693381); Rennie, Paul S. (7005876277); Welch, William J. (58582133100); Cherkasov, Artem (26643601100)","57199901530; 6601993195; 57203283037; 6602999080; 57192818079; 57197693381; 7005876277; 58582133100; 26643601100","Toxic Colors: The Use of Deep Learning for Predicting Toxicity of Compounds Merely from Their Graphic Images","2018","Journal of Chemical Information and Modeling","82","10.1021/acs.jcim.8b00338","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051113781&doi=10.1021%2facs.jcim.8b00338&partnerID=40&md5=0e89a00c924196fd87899613d822c69c","Vancouver Prostate Centre, Department of Urologic Sciences, Faculty of Medicine, University of British Columbia, 2660 Oak Street, Vancouver, V6H 3Z6, BC, Canada; Department of Statistics, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada","Fernandez M., Vancouver Prostate Centre, Department of Urologic Sciences, Faculty of Medicine, University of British Columbia, 2660 Oak Street, Vancouver, V6H 3Z6, BC, Canada; Ban F., Vancouver Prostate Centre, Department of Urologic Sciences, Faculty of Medicine, University of British Columbia, 2660 Oak Street, Vancouver, V6H 3Z6, BC, Canada; Woo G., Vancouver Prostate Centre, Department of Urologic Sciences, Faculty of Medicine, University of British Columbia, 2660 Oak Street, Vancouver, V6H 3Z6, BC, Canada; Hsing M., Vancouver Prostate Centre, Department of Urologic Sciences, Faculty of Medicine, University of British Columbia, 2660 Oak Street, Vancouver, V6H 3Z6, BC, Canada; Yamazaki T., Vancouver Prostate Centre, Department of Urologic Sciences, Faculty of Medicine, University of British Columbia, 2660 Oak Street, Vancouver, V6H 3Z6, BC, Canada; Leblanc E., Vancouver Prostate Centre, Department of Urologic Sciences, Faculty of Medicine, University of British Columbia, 2660 Oak Street, Vancouver, V6H 3Z6, BC, Canada; Rennie P.S., Vancouver Prostate Centre, Department of Urologic Sciences, Faculty of Medicine, University of British Columbia, 2660 Oak Street, Vancouver, V6H 3Z6, BC, Canada; Welch W.J., Department of Statistics, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Cherkasov A., Vancouver Prostate Centre, Department of Urologic Sciences, Faculty of Medicine, University of British Columbia, 2660 Oak Street, Vancouver, V6H 3Z6, BC, Canada","The majority of computational methods for predicting toxicity of chemicals are typically based on ""nonmechanistic"" cheminformatics solutions, relying on an arsenal of QSAR descriptors, often vaguely associated with chemical structures, and typically employing ""black-box"" mathematical algorithms. Nonetheless, such machine learning models, while having lower generalization capacity and interpretability, typically achieve a very high accuracy in predicting various toxicity endpoints, as unambiguously reflected by the results of the recent Tox21 competition. In the current study, we capitalize on the power of modern AI to predict Tox21 benchmark data using merely simple 2D drawings of chemicals, without employing any chemical descriptors. In particular, we have processed rather trivial 2D sketches of molecules with a supervised 2D convolutional neural network (2DConvNet) and demonstrated that the modern image recognition technology results in prediction accuracies comparable to the state-of-the-art cheminformatics tools. Furthermore, the performance of the image-based 2DConvNet model was comparatively evaluated on an external set of compounds from the Prestwick chemical library and resulted in experimental identification of significant and previously unreported antiandrogen potentials for several well-established generic drugs. © 2018 American Chemical Society.","","Algorithms; Computer Graphics; Databases, Pharmaceutical; Deep Learning; Drug Discovery; Drug-Related Side Effects and Adverse Reactions; Humans; Models, Biological; Models, Chemical; Pharmaceutical Preparations; Small Molecule Libraries; Computational chemistry; Convolutional neural networks; Forecasting; Image processing; Image recognition; Indicators (chemical); Toxicity; drug; Chemical descriptors; Chemical libraries; Experimental identification; Generalization capacity; Image recognition technology; Machine learning models; Mathematical algorithms; Prediction accuracy; adverse drug reaction; algorithm; biological model; chemical model; chemistry; computer graphics; drug database; drug development; human; molecular library; procedures; toxicity; Deep learning","American Chemical Society","15499596","","JCISD","30063345","Article","Scopus","2-s2.0-85051113781"
"He Z.; Gao S.; Xiao L.; Liu D.; He H.","He, Zhen (57679948600); Gao, Shaobing (55377029600); Xiao, Liang (57013964900); Liu, Daxue (7410098064); He, Hangen (34769709600)","57679948600; 55377029600; 57013964900; 7410098064; 34769709600","Multimedia data modelling using multidimensional recurrent neural networks","2018","Symmetry","0","10.3390/sym10090370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054421485&doi=10.3390%2fsym10090370&partnerID=40&md5=9595f15416802ed445e0c58c95bc6c70","College of Intelligence Science, National University of Defense Technology, Changsha, 410073, China; Department of Computer Science, University College London, London, WC1E 6BT, United Kingdom; Department of Computer Science, Sichuan University, Chengdu, 610065, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, 100071, China","He Z., College of Intelligence Science, National University of Defense Technology, Changsha, 410073, China, Department of Computer Science, University College London, London, WC1E 6BT, United Kingdom; Gao S., Department of Computer Science, Sichuan University, Chengdu, 610065, China; Xiao L., Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, 100071, China; Liu D., College of Intelligence Science, National University of Defense Technology, Changsha, 410073, China; He H., College of Intelligence Science, National University of Defense Technology, Changsha, 410073, China","Modelling the multimedia data such as text, images, or videos usually involves the analysis, prediction, or reconstruction of them. The recurrent neural network (RNN) is a powerful machine learning approach to modelling these data in a recursive way. As a variant, the long short-term memory (LSTM) extends the RNN with the ability to remember information for longer. Whilst one can increase the capacity of LSTM by widening or adding layers, additional parameters and runtime are usually required, which could make learning harder. We therefore propose a Tensor LSTM where the hidden states are tensorised as multidimensional arrays (tensors) and updated through a cross-layer convolution. As parameters are spatially shared within the tensor, we can efficiently widen the model without extra parameters by increasing the tensorised size; as deep computations of each time step are absorbed by temporal computations of the time series, we can implicitly deepen the model with little extra runtime by delaying the output. We show by experiments that our model is well-suited for various multimedia data modelling tasks, including text generation, text calculation, image classification, and video prediction. © 2018 by the authors.","Convolution; Deep learning; Long short-term memory (LSTM); Multimedia data modelling; Recurrent neural network (RNN); Tensor","","MDPI AG","20738994","","","","Article","Scopus","2-s2.0-85054421485"
"Veltri D.; Kamath U.; Shehu A.","Veltri, Daniel (55635790000); Kamath, Uday (36439453100); Shehu, Amarda (14420301100)","55635790000; 36439453100; 14420301100","Deep learning improves antimicrobial peptide recognition","2018","Bioinformatics","262","10.1093/bioinformatics/bty179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047572106&doi=10.1093%2fbioinformatics%2fbty179&partnerID=40&md5=fd0a7e93ea60279191560a6d3682f8e2","Bioinformatics and Computational Biosciences Branch, Office of Cyber Infrastructure and Computational Biology, National Institute of Allergy and Infectious Diseases, U.S. National Institutes of Health, Rockville, 20852, MD, United States; Medical Science and Computing, LLC, Rockville, 20852, MD, United States; Digital Reasoning, McLean, 22102, VA, United States; Department of Computer Science, United States; Department of Bioengineering, George Mason University, Fairfax, 22030, VA, United States; School of Systems Biology, George Mason University, Manassas, 20110, VA, United States","Veltri D., Bioinformatics and Computational Biosciences Branch, Office of Cyber Infrastructure and Computational Biology, National Institute of Allergy and Infectious Diseases, U.S. National Institutes of Health, Rockville, 20852, MD, United States, Medical Science and Computing, LLC, Rockville, 20852, MD, United States; Kamath U., Digital Reasoning, McLean, 22102, VA, United States; Shehu A., Department of Computer Science, United States, Department of Bioengineering, George Mason University, Fairfax, 22030, VA, United States, School of Systems Biology, George Mason University, Manassas, 20110, VA, United States","Motivation: Bacterial resistance to antibiotics is a growing concern. Antimicrobial peptides (AMPs), natural components of innate immunity, are popular targets for developing new drugs. Machine learning methods are now commonly adopted by wet-laboratory researchers to screen for promising candidates. Results: In this work, we utilize deep learning to recognize antimicrobial activity. We propose a neural network model with convolutional and recurrent layers that leverage primary sequence composition. Results show that the proposed model outperforms state-of-the-art classification models on a comprehensive dataset. By utilizing the embedding weights, we also present a reduced-alphabet representation and show that reasonable AMP recognition can be maintained using nine amino acid types. © The Author(s) 2018. Published by Oxford University Press.","","Anti-Infective Agents; Computational Biology; Deep Learning; Peptides; Sequence Analysis, Protein; antiinfective agent; peptide; biology; procedures; sequence analysis","Oxford University Press","13674803","","BOINF","29590297","Article","Scopus","2-s2.0-85047572106"
"Tang S.; Shen C.; Wang D.; Li S.; Huang W.; Zhu Z.","Tang, Shenghao (57195062455); Shen, Changqing (57215564637); Wang, Dong (56342707500); Li, Shuang (55264666000); Huang, Weiguo (55709632400); Zhu, Zhongkui (55611845900)","57195062455; 57215564637; 56342707500; 55264666000; 55709632400; 55611845900","Adaptive deep feature learning network with Nesterov momentum and its application to rotating machinery fault diagnosis","2018","Neurocomputing","87","10.1016/j.neucom.2018.04.048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046822982&doi=10.1016%2fj.neucom.2018.04.048&partnerID=40&md5=3d22eeb2800f83e732da9956b2a299b6","School of Rail Transportation, Soochow University, Suzhou, 215131, China; College of Science and Engineering, City University of Hong Kong, Hong Kong, Hong Kong","Tang S., School of Rail Transportation, Soochow University, Suzhou, 215131, China; Shen C., School of Rail Transportation, Soochow University, Suzhou, 215131, China; Wang D., College of Science and Engineering, City University of Hong Kong, Hong Kong, Hong Kong; Li S., School of Rail Transportation, Soochow University, Suzhou, 215131, China; Huang W., School of Rail Transportation, Soochow University, Suzhou, 215131, China; Zhu Z., School of Rail Transportation, Soochow University, Suzhou, 215131, China","The effective fault diagnosis of rotating machinery is critical to ensure the continuous operation of equipment and is more economical than scheduled maintenance. Traditional signal processing-based and artificial intelligence-based methods, such as wavelet packet transform and support vector machine, have been proved effective in fault diagnosis of rotating machinery, which prevents unexpected machine breakdowns due to the failure of significant components. However, these methods have several disadvantages that make them unable to automatically and effectively extract valid fault features for the effective fault diagnosis of rotating machinery. A novel adaptive learning rate deep belief network combined with Nesterov momentum is developed in this study for rotating machinery fault diagnosis. Nesterov momentum is adopted to replace traditional momentum to enable declining in advance and to improve training performance. Then, an individual adaptive learning rate method is used to select a suitable step length for accelerating descent. To confirm the utility of the proposed deep learning network architecture, two examinations are implemented on datasets from gearbox and locomotive bearing test rigs. Results indicate that the method achieves impressive performance in fault pattern recognition. Comparisons with existing methods are also conducted to demonstrate that the proposed method is more accurate and robust. © 2018","Adaptive learning rate; Deep belief network; Fault diagnosis; Feature learning; Nesterov momentum","Deep learning; Failure analysis; Learning algorithms; Machine components; Momentum; Network architecture; Pattern recognition; Rotating machinery; Signal processing; Adaptive learning rate methods; Adaptive learning rates; Deep belief networks; Deep feature learning; Fault diagnosis of rotating machineries; Feature learning; Machinery fault diagnosis; Wavelet packet transforms; adaptive deep feature learning network; Article; artificial neural network; controlled study; deep belief network; fault pattern recognition; industry and industrial phenomena; intermethod comparison; learning algorithm; machine; machine learning; mathematical computing; measurement accuracy; methodology; Nesterov momentum; parameters; priority journal; robustness; rotating machinery; rotating machinery fault diagnosis; support vector machine; Fault detection","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85046822982"
"Nguyen D.T.; Pham T.D.; Lee Y.W.; Park K.R.","Nguyen, Dat Tien (35608738000); Pham, Tuyen Danh (55808639500); Lee, Young Won (57195539045); Park, Kang Ryoung (8983316300)","35608738000; 55808639500; 57195539045; 8983316300","Deep learning-based enhanced presentation attack detection for iris recognition by combining features from local and global regions based on NIR camera sensor","2018","Sensors (Switzerland)","37","10.3390/s18082601","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051399510&doi=10.3390%2fs18082601&partnerID=40&md5=6c91ac2f8e4f7020c378227ec85e1b54","Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea","Nguyen D.T., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Pham T.D., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Lee Y.W., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Park K.R., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea","Iris recognition systems have been used in high-security-level applications because of their high recognition rate and the distinctiveness of iris patterns. However, as reported by recent studies, an iris recognition system can be fooled by the use of artificial iris patterns and lead to a reduction in its security level. The accuracies of previous presentation attack detection research are limited because they used only features extracted from global iris region image. To overcome this problem, we propose a new presentation attack detection method for iris recognition by combining features extracted from both local and global iris regions, using convolutional neural networks and support vector machines based on a near-infrared (NIR) light camera sensor. The detection results using each kind of image features are fused, based on two fusion methods of feature level and score level to enhance the detection ability of each kind of image features. Through extensive experiments using two popular public datasets (LivDet-Iris-2017 Warsaw and Notre Dame Contact Lens Detection 2015) and their fusion, we validate the efficiency of our proposed method by providing smaller detection errors than those produced by previous studies. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Iris recognition; NIR camera sensor; Presentation attack detection; Support vector machines","Deep Learning; Humans; Infrared Rays; Iris; Neural Networks (Computer); Photography; Support Vector Machine; Biometrics; Cameras; Deep learning; Image enhancement; Infrared devices; Neural networks; Pattern recognition systems; Support vector machines; Attack detection; Convolutional neural network; High security levels; Iris recognition; Iris recognition systems; Near infrared light; NIR camera; Recognition rates; anatomy and histology; artificial neural network; devices; human; infrared radiation; iris; photography; support vector machine; Feature extraction","MDPI AG","14248220","","","30096832","Article","Scopus","2-s2.0-85051399510"
"Singh J.; Hanson J.; Heffernan R.; Paliwal K.; Yang Y.; Zhou Y.","Singh, Jaswinder (57209916907); Hanson, Jack (57194425812); Heffernan, Rhys (56388539300); Paliwal, Kuldip (7005281122); Yang, Yuedong (8439078900); Zhou, Yaoqi (7405366766)","57209916907; 57194425812; 56388539300; 7005281122; 8439078900; 7405366766","Detecting Proline and Non-Proline Cis Isomers in Protein Structures from Sequences Using Deep Residual Ensemble Learning","2018","Journal of Chemical Information and Modeling","13","10.1021/acs.jcim.8b00442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052985229&doi=10.1021%2facs.jcim.8b00442&partnerID=40&md5=29aea0072eb5668dc4806d115bf4494b","Signal Processing Laboratory, Griffith University, Brisbane, 4122, QLD, Australia; Institute for Glycomics, School of Information and Communication Technology, Griffith University, Southport, 4222, QLD, Australia; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, 510006, China","Singh J., Signal Processing Laboratory, Griffith University, Brisbane, 4122, QLD, Australia; Hanson J., Signal Processing Laboratory, Griffith University, Brisbane, 4122, QLD, Australia; Heffernan R., Signal Processing Laboratory, Griffith University, Brisbane, 4122, QLD, Australia; Paliwal K., Signal Processing Laboratory, Griffith University, Brisbane, 4122, QLD, Australia; Yang Y., Institute for Glycomics, School of Information and Communication Technology, Griffith University, Southport, 4222, QLD, Australia, School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, 510006, China; Zhou Y., Institute for Glycomics, School of Information and Communication Technology, Griffith University, Southport, 4222, QLD, Australia","It has been long established that cis conformations of amino acid residues play many biologically important roles despite their rare occurrence in protein structure. Because of this rarity, few methods have been developed for predicting cis isomers from protein sequences, most of which are based on outdated datasets and lack the means for independent testing. In this work, using a database of >10000 high-resolution protein structures, we update the statistics of cis isomers and develop a sequence-based prediction technique using an ensemble of residual convolutional and long short-term memory bidirectional recurrent neural networks that allow learning from the whole protein sequence. We show that ensembling eight neural network models yields maximum Matthews correlation coefficient values of approximately 0.35 for cis-Pro isomers and 0.1 for cis-nonPro residues. The method should be useful for prioritizing functionally important residues in cis isomers for experimental validations and improving the sampling of rare protein conformations for ab initio protein structure prediction. Copyright © 2018 American Chemical Society.","","Amino Acid Sequence; Machine Learning; Proline; Proteins; Forecasting; Importance sampling; Proteins; Recurrent neural networks; proline; protein; Amino acid residues; Bidirectional recurrent neural networks; Correlation coefficient; Experimental validations; Neural network model; Prediction techniques; Protein conformation; Protein structure prediction; amino acid sequence; chemistry; machine learning; Isomers","American Chemical Society","15499596","","JCISD","30118602","Article","Scopus","2-s2.0-85052985229"
"Kavitha M.; Gayathri R.","Kavitha, M. (37077552000); Gayathri, R. (57219558920)","37077552000; 57219558920","Implications of remote sensing data analysis using deep learning techniques","2018","Journal of Computational and Theoretical Nanoscience","0","10.1166/jctn.2018.7553","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059991854&doi=10.1166%2fjctn.2018.7553&partnerID=40&md5=8f854400a20055f87797b8dc4df7ddcc","Department of Electronics and Communication Engineering, Sri Venkateshwara College of Engineering, 602117, India","Kavitha M., Department of Electronics and Communication Engineering, Sri Venkateshwara College of Engineering, 602117, India; Gayathri R., Department of Electronics and Communication Engineering, Sri Venkateshwara College of Engineering, 602117, India","The fastest growing trend in data analysis is Deep Learning Techniques (DL). Machine learning techniques are becoming increasingly important and outperforms in many situations, e.g., image or speech processing. One of the most important deep learning architecture is represented by Convolution Neural Network (CNN). The purpose of this paper is to give a overview of remote sensing image processing using deep learning and discuss the challenges in recent development of deep learning for remote sensing data, and acknowledge the information to make deep learning an implicit model to handle the large scale data processing as a advantageous challenge like analyzing urbanization, climate change, vegetation and many more. Copyright © 2018 American Scientific Publishers.","Convolution neural networks; Deep Learning; Earth observation; Remote sensing","","American Scientific Publishers","15461955","","","","Article","Scopus","2-s2.0-85059991854"
"Nelson A.J.; Hess S.T.","Nelson, A.J. (57199258591); Hess, S.T. (7102293847)","57199258591; 7102293847","Molecular imaging with neural training of identification algorithm (neural network localization identification)","2018","Microscopy Research and Technique","6","10.1002/jemt.23059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053689137&doi=10.1002%2fjemt.23059&partnerID=40&md5=d61421e45505edf2da2fd9a6fc49a1d3","Department of Physics and Astronomy, University of Maine, Orono, 04469-5709, ME, United States; Department of Biochemistry, Weill-Cornell Medicine of Cornell University, 300 York Ave. Box #63 Room A108, New York, 10065, NY, United States","Nelson A.J., Department of Physics and Astronomy, University of Maine, Orono, 04469-5709, ME, United States, Department of Biochemistry, Weill-Cornell Medicine of Cornell University, 300 York Ave. Box #63 Room A108, New York, 10065, NY, United States; Hess S.T., Department of Physics and Astronomy, University of Maine, Orono, 04469-5709, ME, United States","Superresolution localization microscopy strongly relies on robust identification algorithms for accurate reconstruction of the biological systems it is used to measure. The fields of machine learning and computer vision have provided promising solutions for automated object identification, but usually rely on well represented training sets to learn object features. However, using a static training set can result in the learned identification algorithm making mistakes on data that is not well represented by the training set. Here, we present a method for training an artificial neural network without providing a training set in advance. This method uses the data to be analyzed, and the fitting algorithm to train an artificial neural network tailored to that data set. We show that the same artificial neural network can learn to identify at least two types of molecular emissions: the regular point spread functions (PSFs), and the astigmatism PSF. Simulations indicate that this method can be extremely reliable in extracting molecular emission signatures. Additionally, we implemented the artificial neural network calculation to be performed on a graphics processing unit (GPU) for massively parallelized calculation which drastically reduces the time required for the identification process. By implementing the neural identification on a GPU, we allow this method of identification to be used in a real time analysis algorithm. Research highlights: Here, we present a machine learning algorithm for identifying point-spread functions without the need for an a priori training set. We show that this method can detect over 90% of molecules with less than 1% false positive identification in simulations. We further show that because this algorithm does not make assumptions of about the shape of molecular emission, it is compatible with models beyond the symmetric 2D Gaussian. © 2018 Wiley Periodicals, Inc.","convolutional neural network; deep learning; FPALM; machine learning; PALM; semi-supervised learning; STORM; superresolution localization microscopy","Algorithms; Image Processing, Computer-Assisted; Machine Learning; Microscopy, Fluorescence; Molecular Imaging; Neural Networks (Computer); Bioinformatics; Computer graphics; Computer graphics equipment; Deep learning; Graphics processing unit; Learning algorithms; Neural networks; Optical resolving power; Program processors; Convolutional neural network; Deep learning; FPALM; Localisation; Machine-learning; PALM; Semi-supervised learning; Superresolution; Superresolution localization microscopy; Training sets; algorithm; artificial neural network; fluorescence microscopy; image processing; machine learning; molecular imaging; procedures; Optical transfer function","Wiley-Liss Inc.","1059910X","","MRTEE","30242941","Article","Scopus","2-s2.0-85053689137"
"Jiang Z.; Zhang H.; Wang Y.; Ko S.-B.","Jiang, Zhexin (57194332662); Zhang, Hao (56962965700); Wang, Yi (57225157204); Ko, Seok-Bum (57918890700)","57194332662; 56962965700; 57225157204; 57918890700","Retinal blood vessel segmentation using fully convolutional network with transfer learning","2018","Computerized Medical Imaging and Graphics","161","10.1016/j.compmedimag.2018.04.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047258696&doi=10.1016%2fj.compmedimag.2018.04.005&partnerID=40&md5=8003f8b435b72064953f2998b4c25005","University of Saskatchewan, Department of Electrical and Computer Engineering, 57 Campus Drive, Saskatoon, S7N 5A9, Canada","Jiang Z., University of Saskatchewan, Department of Electrical and Computer Engineering, 57 Campus Drive, Saskatoon, S7N 5A9, Canada; Zhang H., University of Saskatchewan, Department of Electrical and Computer Engineering, 57 Campus Drive, Saskatoon, S7N 5A9, Canada; Wang Y., University of Saskatchewan, Department of Electrical and Computer Engineering, 57 Campus Drive, Saskatoon, S7N 5A9, Canada; Ko S.-B., University of Saskatchewan, Department of Electrical and Computer Engineering, 57 Campus Drive, Saskatoon, S7N 5A9, Canada","Since the retinal blood vessel has been acknowledged as an indispensable element in both ophthalmological and cardiovascular disease diagnosis, the accurate segmentation of the retinal vessel tree has become the prerequisite step for automated or computer-aided diagnosis systems. In this paper, a supervised method is presented based on a pre-trained fully convolutional network through transfer learning. This proposed method has simplified the typical retinal vessel segmentation problem from full-size image segmentation to regional vessel element recognition and result merging. Meanwhile, additional unsupervised image post-processing techniques are applied to this proposed method so as to refine the final result. Extensive experiments have been conducted on DRIVE, STARE, CHASE_DB1 and HRF databases, and the accuracy of the cross-database test on these four databases is state-of-the-art, which also presents the high robustness of the proposed approach. This successful result has not only contributed to the area of automated retinal blood vessel segmentation but also supports the effectiveness of transfer learning when applying deep learning technique to medical imaging. © 2018 Elsevier Ltd","Deep learning; Fully convolutional network; Pre-trained model; Retinal blood vessel segmentation; Transfer learning","Databases, Factual; Deep Learning; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Retinal Vessels; Computer aided diagnosis; Convolution; Database systems; Deep learning; Eye protection; Image segmentation; Medical imaging; Ophthalmology; Cardio-vascular disease; Computer aided diagnosis systems; Convolutional networks; Learning techniques; Post-processing techniques; Retinal blood vessels; Retinal vessel segmentations; Transfer learning; algorithm; Article; artificial neural network; convolutional neural network; data base; diagnostic imaging; human; illumination; image processing; image segmentation; priority journal; retina blood vessel; retina image; transfer of learning; unsupervised machine learning; diagnostic imaging; factual database; procedures; retina blood vessel; Blood vessels","Elsevier Ltd","08956111","","CMIGE","29775951","Article","Scopus","2-s2.0-85047258696"
"Veeramani B.; Raymond J.W.; Chanda P.","Veeramani, Balaji (6507834351); Raymond, John W. (57203401744); Chanda, Pritam (57203403031)","6507834351; 57203401744; 57203403031","DeepSort: Deep convolutional networks for sorting haploid maize seeds","2018","BMC Bioinformatics","103","10.1186/s12859-018-2267-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051600303&doi=10.1186%2fs12859-018-2267-2&partnerID=40&md5=0f9ef924a7de96743e8173d8d2ea5290","Dow AgroSciences LLC, 9330 Zionsville Rd, Indianapolis, 46268, IN, United States","Veeramani B., Dow AgroSciences LLC, 9330 Zionsville Rd, Indianapolis, 46268, IN, United States; Raymond J.W., Dow AgroSciences LLC, 9330 Zionsville Rd, Indianapolis, 46268, IN, United States; Chanda P., Dow AgroSciences LLC, 9330 Zionsville Rd, Indianapolis, 46268, IN, United States","Background: Maize is a leading crop in the modern agricultural industry that accounts for more than 40% grain production worldwide. THe double haploid technique that uses fewer breeding generations for generating a maize line has accelerated the pace of development of superior commercial seed varieties and has been transforming the agricultural industry. In this technique the chromosomes of the haploid seeds are doubled and taken forward in the process while the diploids marked for elimination. Traditionally, selective visual expression of a molecular marker within the embryo region of a maize seed has been used to manually discriminate diploids from haploids. Large scale production of inbred maize lines within the agricultural industry would benefit from the development of computer vision methods for this discriminatory task. However the variability in the phenotypic expression of the molecular marker system and the heterogeneity arising out of the maize genotypes and image acquisition have been an enduring challenge towards such efforts. Results: In this work, we propose a novel application of a deep convolutional network (DeepSort) for the sorting of haploid seeds in these realistic settings. Our proposed approach outperforms existing state-of-the-art machine learning classifiers that uses features based on color, texture and morphology. We demonstrate the network derives features that can discriminate the embryo regions using the activations of the neurons in the convolutional layers. Our experiments with different architectures show that the performance decreases with the decrease in the depth of the layers. Conclusion: Our proposed method DeepSort based on the convolutional network is robust to the variation in the phenotypic expression, shape of the corn seeds, and the embryo pose with respect to the camera. In the era of modern digital agriculture, deep learning and convolutional networks will continue to play an important role in advancing research and product development within the agricultural industry. © 2018 The Author(s).","Agriculture; Convolutional neural networks; Corn; Deep learning; Double haploid induction; Molecular markers","Algorithms; Genotype; Haploidy; Neural Networks (Computer); Phenotype; Plant Breeding; Seeds; Zea mays; Chromosomes; Convolution; Deep learning; Textures; Agricultural industries; Convolutional networks; Digital agriculture; Grain production; Large scale productions; Molecular marker systems; Novel applications; Phenotypic expression; algorithm; artificial neural network; genetics; genotype; growth, development and aging; haploidy; maize; phenotype; plant breeding; plant seed; Agriculture","BioMed Central","14712105","","BBMIC","30367590","Article","Scopus","2-s2.0-85051600303"
"de Oliveira D.C.; Wehrmeister M.A.","de Oliveira, Diulhio Candido (57202985997); Wehrmeister, Marco Aurelio (8907453600)","57202985997; 8907453600","Using deep learning and low-cost rgb and thermal cameras to detect pedestrians in aerial images captured by multirotor uav","2018","Sensors (Switzerland)","50","10.3390/s18072244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050137668&doi=10.3390%2fs18072244&partnerID=40&md5=3d1a1aaad2efcf5b688306b50688eaaf","Computing Systems Engineering Laboratory (LESC), Federal University of Technology—Parana (UTFPR), Curitiba, 80230-901, Brazil","de Oliveira D.C., Computing Systems Engineering Laboratory (LESC), Federal University of Technology—Parana (UTFPR), Curitiba, 80230-901, Brazil; Wehrmeister M.A., Computing Systems Engineering Laboratory (LESC), Federal University of Technology—Parana (UTFPR), Curitiba, 80230-901, Brazil","The use of Unmanned Aerial Vehicles (UAV) has been increasing over the last few years in many sorts of applications due mainly to the decreasing cost of this technology. One can see the use of the UAV in several civilian applications such as surveillance and search and rescue. Automatic detection of pedestrians in aerial images is a challenging task. The computing vision system must deal with many sources of variability in the aerial images captured with the UAV, e.g., low-resolution images of pedestrians, images captured at distinct angles due to the degrees of freedom that a UAV can move, the camera platform possibly experiencing some instability while the UAV flies, among others. In this work, we created and evaluated different implementations of Pattern Recognition Systems (PRS) aiming at the automatic detection of pedestrians in aerial images captured with multirotor UAV. The main goal is to assess the feasibility and suitability of distinct PRS implementations running on top of low-cost computing platforms, e.g., single-board computers such as the Raspberry Pi or regular laptops without a GPU. For that, we used four machine learning techniques in the feature extraction and classification steps, namely Haar cascade, LBP cascade, HOG + SVM and Convolutional Neural Networks (CNN). In order to improve the system performance (especially the processing time) and also to decrease the rate of false alarms, we applied the Saliency Map (SM) and Thermal Image Processing (TIP) within the segmentation and detection steps of the PRS. The classification results show the CNN to be the best technique with 99.7% accuracy, followed by HOG + SVM with 92.3%. In situations of partial occlusion, the CNN showed 71.1% sensitivity, which can be considered a good result in comparison with the current state-of-the-art, since part of the original image data is missing. As demonstrated in the experiments, by combining TIP with CNN, the PRS can process more than two frames per second (fps), whereas the PRS that combines TIP with HOG + SVM was able to process 100 fps. It is important to mention that our experiments show that a trade-off analysis must be performed during the design of a pedestrian detection PRS. The faster implementations lead to a decrease in the PRS accuracy. For instance, by using HOG + SVM with TIP, the PRS presented the best performance results, but the obtained accuracy was 35 percentage points lower than the CNN. The obtained results indicate that the best detection technique (i.e., the CNN) requires more computational resources to decrease the PRS computation time. Therefore, this work shows and discusses the pros/cons of each technique and trade-off situations, and hence, one can use such an analysis to improve and tailor the design of a PRS to detect pedestrians in aerial images. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Aerial images; Convolutional neural network; Deep learning; Pattern recognition system; Pedestrian detection; Performance assessment; Thermal camera; Unmanned Aerial Vehicle (UAV)","Aircraft detection; Cameras; Classification (of information); Convolution; Costs; Deep learning; Degrees of freedom (mechanics); Economic and social effects; Image segmentation; Infrared devices; Mobile antennas; Neural networks; Online systems; Pattern recognition systems; Pedestrian safety; Telecommunication links; Unmanned aerial vehicles (UAV); Aerial images; Convolutional neural network; Pedestrian detection; Performance assessment; Thermal camera; Image enhancement","MDPI AG","14248220","","","30002290","Article","Scopus","2-s2.0-85050137668"
"Nishio M.; Sugiyama O.; Yakami M.; Ueno S.; Kubo T.; Kuroda T.; Togashi K.","Nishio, Mizuho (36969337900); Sugiyama, Osamu (56423474300); Yakami, Masahiro (16551268900); Ueno, Syoko (57203547492); Kubo, Takeshi (55188798700); Kuroda, Tomohiro (9233475900); Togashi, Kaori (7101898163)","36969337900; 56423474300; 16551268900; 57203547492; 55188798700; 9233475900; 7101898163","Computer-aided diagnosis of lung nodule classification between benign nodule, primary lung cancer, and metastatic lung cancer at different image size using deep convolutional neural network with transfer learning","2018","PLoS ONE","122","10.1371/journal.pone.0200721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052212956&doi=10.1371%2fjournal.pone.0200721&partnerID=40&md5=f6af2001aabf79377cb94fd0fe550492","Department of Diagnostic Imaging and Nuclear Medicine, Kyoto University Graduate School of Medicine, Kyoto, Japan; Preemptive Medicine and Lifestyle-related Disease Research Center, Kyoto University Hospital, Kyoto, Japan; Department of Social Informatics, Kyoto University Graduate School of Informatics, Yoshidahonmachi, Kyoto, Japan; Division of Medical Information Technology and Administrative Planning, Kyoto University Hospital, Kyoto, Japan","Nishio M., Department of Diagnostic Imaging and Nuclear Medicine, Kyoto University Graduate School of Medicine, Kyoto, Japan, Preemptive Medicine and Lifestyle-related Disease Research Center, Kyoto University Hospital, Kyoto, Japan; Sugiyama O., Preemptive Medicine and Lifestyle-related Disease Research Center, Kyoto University Hospital, Kyoto, Japan; Yakami M., Department of Diagnostic Imaging and Nuclear Medicine, Kyoto University Graduate School of Medicine, Kyoto, Japan, Preemptive Medicine and Lifestyle-related Disease Research Center, Kyoto University Hospital, Kyoto, Japan; Ueno S., Department of Social Informatics, Kyoto University Graduate School of Informatics, Yoshidahonmachi, Kyoto, Japan; Kubo T., Department of Diagnostic Imaging and Nuclear Medicine, Kyoto University Graduate School of Medicine, Kyoto, Japan; Kuroda T., Division of Medical Information Technology and Administrative Planning, Kyoto University Hospital, Kyoto, Japan; Togashi K., Department of Diagnostic Imaging and Nuclear Medicine, Kyoto University Graduate School of Medicine, Kyoto, Japan","We developed a computer-aided diagnosis (CADx) method for classification between benign nodule, primary lung cancer, and metastatic lung cancer and evaluated the following: (i) the usefulness of the deep convolutional neural network (DCNN) for CADx of the ternary classification, compared with a conventional method (hand-crafted imaging feature plus machine learning), (ii) the effectiveness of transfer learning, and (iii) the effect of image size as the DCNN input. Among 1240 patients of previously-built database, computed tomography images and clinical information of 1236 patients were included. For the conventional method, CADx was performed by using rotation-invariant uniform-pattern local binary pattern on three orthogonal planes with a support vector machine. For the DCNN method, CADx was evaluated using the VGG-16 convolutional neural network with and without transfer learning, and hyperparameter optimization of the DCNN method was performed by random search. The best averaged validation accuracies of CADx were 55.9%, 68.0%, and 62.4% for the conventional method, the DCNN method with transfer learning, and the DCNN method without transfer learning, respectively. For image size of 56, 112, and 224, the best averaged validation accuracy for the DCNN with transfer learning were 60.7%, 64.7%, and 68.0%, respectively. DCNN was better than the conventional method for CADx, and the accuracy of DCNN improved when using transfer learning. Also, we found that larger image sizes as inputs to DCNN improved the accuracy of lung nodule classification. © 2018 Nishio et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Aged; Female; Humans; Lung; Lung Neoplasms; Machine Learning; Male; Middle Aged; Neural Networks (Computer); Radiographic Image Interpretation, Computer-Assisted; Retrospective Studies; Tomography, X-Ray Computed; adult; aged; Article; artificial neural network; computer assisted diagnosis; computer assisted tomography; controlled study; data base; deep convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; differential diagnosis; disease classification; female; human; image processing; image quality; lung cancer; lung metastasis; lung nodule; machine learning; major clinical study; male; retrospective study; support vector machine; transfer of learning; artificial neural network; comparative study; computer assisted diagnosis; diagnostic imaging; evaluation study; lung; lung tumor; machine learning; middle aged; pathology; procedures; secondary; x-ray computed tomography","Public Library of Science","19326203","","POLNC","30052644","Article","Scopus","2-s2.0-85052212956"
"Qin F.; Gao N.; Peng Y.; Wu Z.; Shen S.; Grudtsin A.","Qin, Feiwei (55485132000); Gao, Nannan (57202248296); Peng, Yong (56647218000); Wu, Zizhao (57198577833); Shen, Shuying (55911286700); Grudtsin, Artur (57202258210)","55485132000; 57202248296; 56647218000; 57198577833; 55911286700; 57202258210","Fine-grained leukocyte classification with deep residual learning for microscopic images","2018","Computer Methods and Programs in Biomedicine","107","10.1016/j.cmpb.2018.05.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047623655&doi=10.1016%2fj.cmpb.2018.05.024&partnerID=40&md5=463910bf282f48247d07509acdc9e3c5","School of Computer Science and Technology, Hangzhou Dianzi University, China; School of Media and Design, Hangzhou Dianzi University, China; Department of Orthopaedic Surgery, Sir Run Run Shaw Hospital, China","Qin F., School of Computer Science and Technology, Hangzhou Dianzi University, China; Gao N., School of Computer Science and Technology, Hangzhou Dianzi University, China; Peng Y., School of Computer Science and Technology, Hangzhou Dianzi University, China; Wu Z., School of Media and Design, Hangzhou Dianzi University, China; Shen S., Department of Orthopaedic Surgery, Sir Run Run Shaw Hospital, China; Grudtsin A., School of Computer Science and Technology, Hangzhou Dianzi University, China","Background and objective: Leukocyte classification and cytometry have wide applications in medical domain, previous researches usually exploit machine learning techniques to classify leukocytes automatically. However, constrained by the past development of machine learning techniques, for example, extracting distinctive features from raw microscopic images are difficult, the widely used SVM classifier only has relative few parameters to tune, these methods cannot efficiently handle fine-grained classification cases when the white blood cells have up to 40 categories. Methods: Based on deep learning theory, a systematic study is conducted on finer leukocyte classification in this paper. A deep residual neural network based leukocyte classifier is constructed at first, which can imitate the domain expert's cell recognition process, and extract salient features robustly and automatically. Then the deep neural network classifier's topology is adjusted according to the prior knowledge of white blood cell test. After that the microscopic image dataset with almost one hundred thousand labeled leukocytes belonging to 40 categories is built, and combined training strategies are adopted to make the designed classifier has good generalization ability. Results: The proposed deep residual neural network based classifier was tested on microscopic image dataset with 40 leukocyte categories. It achieves top-1 accuracy of 77.80%, top-5 accuracy of 98.75% during the training procedure. The average accuracy on the test set is nearly 76.84%. Conclusions: This paper presents a fine-grained leukocyte classification method for microscopic images, based on deep residual learning theory and medical domain knowledge. Experimental results validate the feasibility and effectiveness of our approach. Extended experiments support that the fine-grained leukocyte classifier could be used in real medical applications, assist doctors in diagnosing diseases, reduce human power significantly. © 2018 Elsevier B.V.","Deep learning; Image analysis; Leukocyte; Residual learning","Humans; Leukocytes; Machine Learning; Microscopy; Models, Statistical; Neural Networks (Computer); Pattern Recognition, Automated; Support Vector Machine; Artificial intelligence; Blood; Cells; Classifiers; Deep learning; Deep neural networks; Diagnosis; Image analysis; Image classification; Learning algorithms; Medical applications; Medical imaging; Classification methods; Generalization ability; Leukocyte; Machine learning techniques; Neural network classifier; Residual learning; Training procedures; White blood cells; Article; automation; basophil; cell labeling; classification algorithm; classifier; comparative study; cytometry; deep residual neural network classifier; eosinophil; erythroblast; erythrocyte; feature extraction; granulocyte; human; human cell; image analysis; image processing; learning theory; leukocyte; leukocyte differential count; lymphocyte; measurement accuracy; megakaryoblast; megakaryocyte; microscopy; monocyte; myeloblast; neutrophil; plasma cell; plasmablast; prolymphocyte; promonocytic cell; promyelocyte; artificial neural network; automated pattern recognition; cytology; leukocyte; machine learning; statistical model; support vector machine; Classification (of information)","Elsevier Ireland Ltd","01692607","","CMPBE","29903491","Article","Scopus","2-s2.0-85047623655"
"Brigham K.; Gupta S.; Brigham J.C.","Brigham, Katharine (36451900400); Gupta, Samir (55495157000); Brigham, John C. (35809956500)","36451900400; 55495157000; 35809956500","Predicting responses to mechanical ventilation for preterm infants with acute respiratory illness using artificial neural networks","2018","International Journal for Numerical Methods in Biomedical Engineering","8","10.1002/cnm.3094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046630010&doi=10.1002%2fcnm.3094&partnerID=40&md5=a459fdf969c75d7d0f2ab952dc1cea89","Department of Engineering, Durham University, Durham, United Kingdom; Neonatal Unit, University Hospital of North Tees, Stockton-on-Tees, United Kingdom","Brigham K., Department of Engineering, Durham University, Durham, United Kingdom; Gupta S., Neonatal Unit, University Hospital of North Tees, Stockton-on-Tees, United Kingdom; Brigham J.C., Department of Engineering, Durham University, Durham, United Kingdom","Infants born prematurely are particularly susceptible to respiratory illness due to underdeveloped lungs, which can often result in fatality. Preterm infants in acute stages of respiratory illness typically require mechanical ventilation assistance, and the efficacy of the type of mechanical ventilation and its delivery has been the subject of a number clinical studies. With recent advances in machine learning approaches, particularly deep learning, it may be possible to estimate future responses to mechanical ventilation in real time, based on ventilation monitoring up to the point of analysis. In this work, recurrent neural networks are proposed for predicting future ventilation parameters due to the highly nonlinear behavior of the ventilation measures of interest and the ability of recurrent neural networks to model complex nonlinear functions. The resulting application of this particular class of neural networks shows promise in its ability to predict future responses for different ventilation modes. Towards improving care and treatment of preterm newborns, further development of this prediction process for ventilation could potentially aid in important clinical decisions or studies to improve preterm infant health. Copyright © 2018 John Wiley & Sons, Ltd.","deep learning; neonatal; neural networks; prediction; time series","Deep learning; Diseases; Forecasting; Neural networks; Time series; Ventilation; Acute respiratory illness; Machine learning approaches; Mechanical ventilation; Neonatal; Nonlinear behavior; Nonlinear functions; Prediction process; Respiratory illness; Recurrent neural networks","Wiley-Blackwell","20407939","","","","Article","Scopus","2-s2.0-85046630010"
"Huang C.-J.; Kuo P.-H.","Huang, Chiou-Jye (57201619481); Kuo, Ping-Huan (25925911500)","57201619481; 25925911500","A deep cnn-lstm model for particulate matter (Pm2.5) forecasting in smart cities","2018","Sensors (Switzerland)","475","10.3390/s18072220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050087079&doi=10.3390%2fs18072220&partnerID=40&md5=a50aae05880856071822338e19ae6b0a","School of Electrical Engineering and Automation, Jiangxi University of Science and Technology, Ganzhou, 341000, China; National Pingtung University, Pingtung, 90004, Taiwan","Huang C.-J., School of Electrical Engineering and Automation, Jiangxi University of Science and Technology, Ganzhou, 341000, China; Kuo P.-H., National Pingtung University, Pingtung, 90004, Taiwan","In modern society, air pollution is an important topic as this pollution exerts a critically bad influence on human health and the environment. Among air pollutants, Particulate Matter (PM2.5) consists of suspended particles with a diameter equal to or less than 2.5 µm. Sources of PM2.5 can be coal-fired power generation, smoke, or dusts. These suspended particles in the air can damage the respiratory and cardiovascular systems of the human body, which may further lead to other diseases such as asthma, lung cancer, or cardiovascular diseases. To monitor and estimate the PM2.5 concentration, Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) are combined and applied to the PM2.5 forecasting system. To compare the overall performance of each algorithm, four measurement indexes, Mean Absolute Error (MAE), Root Mean Square Error (RMSE) Pearson correlation coefficient and Index of Agreement (IA) are applied to the experiments in this paper. Compared with other machine learning methods, the experimental results showed that the forecasting accuracy of the proposed CNN-LSTM model (APNet) is verified to be the highest in this paper. For the CNN-LSTM model, its feasibility and practicability to forecast the PM2.5 concentration are also verified in this paper. The main contribution of this paper is to develop a deep neural network model that integrates the CNN and LSTM architectures, and through historical data such as cumulated hours of rain, cumulated wind speed and PM2.5 concentration. In the future, this study can also be applied to the prevention and control of PM2.5. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Big data analytics; CNN-LSTM model; Deep learning; PM<sub>2.5</sub> forecasting","Air pollution; Big data; Cardiovascular system; Correlation methods; Deep learning; Deep neural networks; Diseases; Forecasting; Mean square error; Particles (particulate matter); Smart city; Wind effects; Big Data Analytics; Cardio-vascular disease; Coal-fired power generation; Convolutional Neural Networks (CNN); Machine learning methods; Pearson correlation coefficients; Prevention and controls; Root mean square errors; Long short-term memory","MDPI AG","14248220","","","29996546","Article","Scopus","2-s2.0-85050087079"
"Bini S.A.","Bini, Stefano A. (6701549847)","6701549847","Artificial Intelligence, Machine Learning, Deep Learning, and Cognitive Computing: What Do These Terms Mean and How Will They Impact Health Care?","2018","Journal of Arthroplasty","352","10.1016/j.arth.2018.02.067","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045344385&doi=10.1016%2fj.arth.2018.02.067&partnerID=40&md5=1b53d427a7f8fd743eaee0781b7d07eb","Department of Orthopaedics, University of California, San Francisco, San Francisco, California, United States","Bini S.A., Department of Orthopaedics, University of California, San Francisco, San Francisco, California, United States","This article was presented at the 2017 annual meeting of the American Association of Hip and Knee Surgeons to introduce the members gathered as the audience to the concepts behind artificial intelligence (AI) and the applications that AI can have in the world of health care today. We discuss the origin of AI, progress to machine learning, and then discuss how the limits of machine learning lead data scientists to develop artificial neural networks and deep learning algorithms through biomimicry. We will place all these technologies in the context of practical clinical examples and show how AI can act as a tool to support and amplify human cognitive functions for physicians delivering care to increasingly complex patients. The aim of this article is to provide the reader with a basic understanding of the fundamentals of AI. Its purpose is to demystify this technology for practicing surgeons so they can better understand how and where to apply it. © 2018 Elsevier Inc.","artificial intelligence; cognitive computing; deep learning; digital health; digital orthopedics; machine learning","Algorithms; Artificial Intelligence; Deep Learning; Humans; Machine Learning; Neural Networks (Computer); Orthopedics; Physicians; article; artificial intelligence; human; human experiment; machine learning; orthopedics; surgeon; algorithm; artificial intelligence; artificial neural network; machine learning; orthopedics; physician; trends","Churchill Livingstone Inc.","08835403","","JOARE","29656964","Article","Scopus","2-s2.0-85045344385"
"Choi H.; Kang H.; Lee D.S.","Choi, Hongyoon (45760940100); Kang, Hyejin (56525710600); Lee, Dong Soo (56580452900)","45760940100; 56525710600; 56580452900","Predicting aging of brain metabolic topography using variational autoencoder","2018","Frontiers in Aging Neuroscience","21","10.3389/fnagi.2018.00212","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050221650&doi=10.3389%2ffnagi.2018.00212&partnerID=40&md5=63d947a80f9bf5d60b02221a8b1793d7","Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, South Korea; Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea; Korea Brain Research Institute, Daegu, South Korea","Choi H., Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, South Korea; Kang H., Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, South Korea; Lee D.S., Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, South Korea, Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea, Korea Brain Research Institute, Daegu, South Korea","Predicting future brain topography can give insight into neural correlates of aging and neurodegeneration. Due to variability in the aging process, it has been challenging to precisely estimate brain topographical change according to aging. Here, we predict age-related brain metabolic change by generating future brain 18F-Fluorodeoxyglucose PET. A cross-sectional PET dataset of cognitively normal subjects with different age was used to develop a generative model. The model generated PET images using age information and characteristic individual features. Predicted regional metabolic changes were correlated with the real changes obtained by follow-up data. This model was applied to produce a brain metabolism aging movie by generating PET at different ages. Normal population distribution of brain metabolic topography at each age was estimated as well. In addition, a generative model using APOE4 status as well as age as inputs revealed a significant effect of APOE4 status on age-related metabolic changes particularly in the calcarine, lingual cortex, hippocampus, and amygdala. It suggested APOE4 could be a factor affecting individual variability in age-related metabolic degeneration in normal elderly. This predictive model may not only be extended to understanding the cognitive aging process, but apply to the development of a preclinical biomarker for various brain disorders. © 2018 Choi, Kang and Lee, for the Alzheimer's Disease Neuroimaging Initiative.","APOE4; Brain metabolism; Deep generative model; FDG PET; Variational autoencoder","apolipoprotein E4; fluorodeoxyglucose f 18; adult; age distribution; aged; aging; amygdala; Article; artificial intelligence; brain disease; brain function; brain mapping; brain metabolic topography; brain metabolism; brain region; calcarine sulcus; cognition; controlled study; hippocampus; human; lingual cortex; major clinical study; metabolic disorder; nerve cell network; neuroimaging; positron emission tomography; prediction; unsupervised machine learning; variational autoencoder; very elderly","Frontiers Media S.A.","16634365","","","","Article","Scopus","2-s2.0-85050221650"
"Seong S.-B.; Pae C.; Park H.-J.","Seong, Si-Baek (57204177560); Pae, Chongwon (57191247660); Park, Hae-Jeong (56488742100)","57204177560; 57191247660; 56488742100","Geometric Convolutional Neural Network for Analyzing Surface-Based Neuroimaging Data","2018","Frontiers in Neuroinformatics","28","10.3389/fninf.2018.00042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054469532&doi=10.3389%2ffninf.2018.00042&partnerID=40&md5=a808502e38e4c77eb5dd0cb7c74e24d8","Brain Korea 21 PLUS Project for Medical Science, College of Medicine, Yonsei University, Seoul, South Korea; Department of Nuclear Medicine, Radiology and Psychiatry, Severance Hospital, College of Medicine, Yonsei University, Seoul, South Korea; Department of Cognitive Science, Yonsei University, Seoul, South Korea; Center for Systems and Translational Brain Sciences, Institute of Human Complexity and Systems Science, Yonsei University, Seoul, South Korea","Seong S.-B., Brain Korea 21 PLUS Project for Medical Science, College of Medicine, Yonsei University, Seoul, South Korea, Department of Nuclear Medicine, Radiology and Psychiatry, Severance Hospital, College of Medicine, Yonsei University, Seoul, South Korea; Pae C., Brain Korea 21 PLUS Project for Medical Science, College of Medicine, Yonsei University, Seoul, South Korea, Department of Nuclear Medicine, Radiology and Psychiatry, Severance Hospital, College of Medicine, Yonsei University, Seoul, South Korea; Park H.-J., Brain Korea 21 PLUS Project for Medical Science, College of Medicine, Yonsei University, Seoul, South Korea, Department of Nuclear Medicine, Radiology and Psychiatry, Severance Hospital, College of Medicine, Yonsei University, Seoul, South Korea, Department of Cognitive Science, Yonsei University, Seoul, South Korea, Center for Systems and Translational Brain Sciences, Institute of Human Complexity and Systems Science, Yonsei University, Seoul, South Korea","In machine learning, one of the most popular deep learning methods is the convolutional neural network (CNN), which utilizes shared local filters and hierarchical information processing analogous to the brain’s visual system. Despite its popularity in recognizing two-dimensional (2D) images, the conventional CNN is not directly applicable to semi-regular geometric mesh surfaces, on which the cerebral cortex is often represented. In order to apply the CNN to surface-based brain research, we propose a geometric CNN (gCNN) that deals with data representation on a mesh surface and renders pattern recognition in a multi-shell mesh structure. To make it compatible with the conventional CNN toolbox, the gCNN includes data sampling over the surface, and a data reshaping method for the convolution and pooling layers. We evaluated the performance of the gCNN in sex classification using cortical thickness maps of both hemispheres from the Human Connectome Project (HCP). The classification accuracy of the gCNN was significantly higher than those of a support vector machine (SVM) and a 2D CNN for thickness maps generated by a map projection. The gCNN also demonstrated position invariance of local features, which rendered reuse of its pre-trained model for applications other than that for which the model was trained without significant distortion in the final outcome. The superior performance of the gCNN is attributable to CNN properties stemming from its brain-like architecture, and its surface-based representation of cortical information. The gCNN provides much-needed access to surface-based machine learning, which can be used in both scientific investigations and clinical applications. © 2018 Seong, Pae and Park.","Cortical thickness; Geometric convolutional neural network; Machine learning; Neuroimage; Sex differences; Surface-based analysis","article; brain cortex; connectome; human; neuroimaging; sex difference; support vector machine; thickness","Frontiers Media S.A.","16625196","","","","Article","Scopus","2-s2.0-85054469532"
"Boufenar C.; Kerboua A.; Batouche M.","Boufenar, Chaouki (57197769342); Kerboua, Adlen (57193777299); Batouche, Mohamed (9335107500)","57197769342; 57193777299; 9335107500","Investigation on deep learning for off-line handwritten Arabic character recognition","2018","Cognitive Systems Research","95","10.1016/j.cogsys.2017.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034782477&doi=10.1016%2fj.cogsys.2017.11.002&partnerID=40&md5=aa082755e8fc323606075726d72511c6","Computer Science Department, College of NTIC, University Of Constantine2, Abdelhamid Mehri, Constantine, 25000, Algeria","Boufenar C., Computer Science Department, College of NTIC, University Of Constantine2, Abdelhamid Mehri, Constantine, 25000, Algeria; Kerboua A., Computer Science Department, College of NTIC, University Of Constantine2, Abdelhamid Mehri, Constantine, 25000, Algeria; Batouche M., Computer Science Department, College of NTIC, University Of Constantine2, Abdelhamid Mehri, Constantine, 25000, Algeria","Handwritten character recognition is a system widely used in the modern world and it is still an important challenge. Traditional machine-learning techniques require careful engineering and considerable domain expertise to transform raw data into a feature vector from which the classifier could classify the input pattern. To cope with this problem, the popular Deep Convolutional Neural Networks (DCNN), introduced recently, have effectively replaced the hand-crafted descriptors with network features and have been shown to provide significantly better results than traditional methods. It is one of the fastest growing areas in machine learning, promising to reshape the future of artificial intelligence. However, the problem with deep learning is that it requires large datasets for training because of the huge number of parameters needed to be tuned by a learning algorithm. CNN model can be used in three different ways: (i) training the CNN from scratch; (ii) using the transfer learning strategy to leverage features from a pre-trained model on a larger dataset; and (iii) keeping the transfer learning strategy and fine-tune the weights of CNN architecture. In this work, we investigate the applicability of DCNN using transfer learning strategies on two datasets; a new expanded version of our recently proposed database for off-line isolated handwritten Arabic character, referred to as OIHACDB and AHCD. Our results showed satisfactory recognition accuracies and outperform all other prominent exiting methods in the field of Handwritten Arabic Character Recognition (HACR). © 2017 Elsevier B.V.","AHCD; Deep Convolutional Neural Network (DCNN); Handwritten Arabic Character Recognition (HACR); OIHACDB; Transfer learning","Convolution; Deep neural networks; Image segmentation; Learning algorithms; Neural networks; AHCD; Arabic character recognition; Deep convolutional neural networks; OIHACDB; Transfer learning; Arabic script; Article; artificial intelligence; artificial neural network; automated pattern recognition; controlled study; deep convolutional neural network; deep learning; handwriting; Handwritten Arabic Character Recognition; learning algorithm; machine learning; priority journal; transfer of learning; Character recognition","Elsevier B.V.","13890417","","CSROA","","Article","Scopus","2-s2.0-85034782477"
"Li D.; Huang M.; Li X.; Ruan Y.; Yao L.","Li, Dingcheng (55301231800); Huang, Ming (58027236000); Li, Xiaodi (57201854287); Ruan, Yaoping (35189602500); Yao, Lixia (53868570800)","55301231800; 58027236000; 57201854287; 35189602500; 53868570800","MfeCNN: Mixture feature embedding convolutional neural network for data mapping","2018","IEEE Transactions on Nanobioscience","10","10.1109/TNB.2018.2841053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047649536&doi=10.1109%2fTNB.2018.2841053&partnerID=40&md5=0c664caa496b2ead75ad0faff4979c1c","Big Data Laboratory, Baidu, Sunnyvale, 94085, CA, United States; Department of Health Sciences Research, Mayo Clinic, Rochester, 55906, MN, United States; Department of Mechatronics Engineering, Donhua University, Shanghai, 200336, China; Watson Health Cloud, IBM, Yorktown Heights, 10598, NY, United States","Li D., Big Data Laboratory, Baidu, Sunnyvale, 94085, CA, United States; Huang M., Department of Health Sciences Research, Mayo Clinic, Rochester, 55906, MN, United States; Li X., Department of Mechatronics Engineering, Donhua University, Shanghai, 200336, China; Ruan Y., Watson Health Cloud, IBM, Yorktown Heights, 10598, NY, United States; Yao L., Department of Health Sciences Research, Mayo Clinic, Rochester, 55906, MN, United States","Data mapping plays an important role in data integration and exchanges among institutions and organizations with different data standards. However, traditional rule-based approaches and machine learning methods fail to achieve satisfactory results for the data mapping problem. In this paper, we propose a novel and sophisticated deep learning framework for data mapping called mixture feature embedding convolutional neural network (MfeCNN). The MfeCNN model converts the data mapping task to a multiple classification problem. In the model, we incorporated multimodal learning and multiview embedding into a CNN for mixture feature tensor generation and classification prediction. Multimodal features were extracted from various linguistic spaces with a medical natural language processing package. Then, powerful feature embeddings were learned by using the CNN. As many as 10 classes could be simultaneously classified by a softmax prediction layer based on multiview embedding. MfeCNN achieved the best results on unbalanced data (average F1 score, 82.4%) among the traditional state-of-the-art machine learning models and CNN without mixture feature embedding. Our model also outperformed a very deep CNN with 29 layers, which took free texts as inputs. The combination of mixture feature embedding and a deep neural network can achieve high accuracy for data mapping and multiple classification. © 2002-2011 IEEE.","convolutional neural network; Data mapping; deep learning; mixture feature embedding; multimodal; multiview","Computational Biology; Data Mining; Deep Learning; Humans; Natural Language Processing; Neural Networks (Computer); Workflow; Convolution; Data integration; Deep learning; Deep neural networks; Learning algorithms; Mapping; Mixtures; Natural language processing systems; Neural networks; Convolutional neural network; Data mappings; Mixture features; Multi-modal; Multi-views; artificial neural network; biology; data mining; human; natural language processing; procedures; workflow; Classification (of information)","Institute of Electrical and Electronics Engineers Inc.","15361241","","","29993581","Article","Scopus","2-s2.0-85047649536"
"Lawhern V.J.; Solon A.J.; Waytowich N.R.; Gordon S.M.; Hung C.P.; Lance B.J.","Lawhern, Vernon J. (35795485600); Solon, Amelia J. (57193851353); Waytowich, Nicholas R. (36683457800); Gordon, Stephen M. (53868031600); Hung, Chou P. (7403166540); Lance, Brent J. (23091636200)","35795485600; 57193851353; 36683457800; 53868031600; 7403166540; 23091636200","EEGNet: A compact convolutional neural network for EEG-based brain-computer interfaces","2018","Journal of Neural Engineering","1747","10.1088/1741-2552/aace8c","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053150526&doi=10.1088%2f1741-2552%2faace8c&partnerID=40&md5=8b11925c5c2bd750d3f50a76974b78ef","Human Research and Engineering Direct., U.S. Army Research Laboratory, Aberdeen Proving Ground, MD, United States; DCS Corporation, Alexandria, VA, United States; Department of Biomedical Engineering, Columbia University, New York, NY, United States; Department of Neuroscience, Georgetown University, Washington, DC, United States","Lawhern V.J., Human Research and Engineering Direct., U.S. Army Research Laboratory, Aberdeen Proving Ground, MD, United States; Solon A.J., Human Research and Engineering Direct., U.S. Army Research Laboratory, Aberdeen Proving Ground, MD, United States, DCS Corporation, Alexandria, VA, United States; Waytowich N.R., Human Research and Engineering Direct., U.S. Army Research Laboratory, Aberdeen Proving Ground, MD, United States, Department of Biomedical Engineering, Columbia University, New York, NY, United States; Gordon S.M., Human Research and Engineering Direct., U.S. Army Research Laboratory, Aberdeen Proving Ground, MD, United States, DCS Corporation, Alexandria, VA, United States; Hung C.P., Human Research and Engineering Direct., U.S. Army Research Laboratory, Aberdeen Proving Ground, MD, United States, Department of Neuroscience, Georgetown University, Washington, DC, United States; Lance B.J., Human Research and Engineering Direct., U.S. Army Research Laboratory, Aberdeen Proving Ground, MD, United States","Objective. Brain-computer interfaces (BCI) enable direct communication with a computer, using neural activity as the control signal. This neural signal is generally chosen from a variety of well-studied electroencephalogram (EEG) signals. For a given BCI paradigm, feature extractors and classifiers are tailored to the distinct characteristics of its expected EEG control signal, limiting its application to that specific signal. Convolutional neural networks (CNNs), which have been used in computer vision and speech recognition to perform automatic feature extraction and classification, have successfully been applied to EEG-based BCIs; however, they have mainly been applied to single BCI paradigms and thus it remains unclear how these architectures generalize to other paradigms. Here, we ask if we can design a single CNN architecture to accurately classify EEG signals from different BCI paradigms, while simultaneously being as compact as possible. Approach. In this work we introduce EEGNet, a compact convolutional neural network for EEG-based BCIs. We introduce the use of depthwise and separable convolutions to construct an EEG-specific model which encapsulates well-known EEG feature extraction concepts for BCI. We compare EEGNet, both for within-subject and cross-subject classification, to current state-of-the-art approaches across four BCI paradigms: P300 visual-evoked potentials, error-related negativity responses (ERN), movement-related cortical potentials (MRCP), and sensory motor rhythms (SMR). Main results. We show that EEGNet generalizes across paradigms better than, and achieves comparably high performance to, the reference algorithms when only limited training data is available across all tested paradigms. In addition, we demonstrate three different approaches to visualize the contents of a trained EEGNet model to enable interpretation of the learned features. Significance. Our results suggest that EEGNet is robust enough to learn a wide variety of interpretable features over a range of BCI tasks. Our models can be found at: https://github.com/vlawhern/arl-eegmodels. © Not subject to copyright in the USA. Contribution of U.S. Army Research Laboratory.","brain-computer interface; convolutional neural network; deep learning; EEG; event-related potential; sensory motor rhythm","Adolescent; Adult; Algorithms; Brain-Computer Interfaces; Electroencephalography; Event-Related Potentials, P300; Evoked Potentials, Visual; Female; Humans; Male; Middle Aged; Movement; Neural Networks (Computer); Young Adult; Bioelectric potentials; Biomedical signal processing; Brain; Classification (of information); Convolution; Deep learning; Electroencephalography; Electrophysiology; Extraction; Feature extraction; Interfaces (computer); Network architecture; Neural networks; Neurons; Speech recognition; Automatic feature extraction; Convolutional neural network; Electroencephalogram signals; Event related potentials; Movement Related Cortical Potentials; Sensory motors; State-of-the-art approach; Visual evoked potential; alpha rhythm; Article; beta rhythm; brain computer interface; classification algorithm; classifier; comparative study; convolutional neural network; deep learning; electric potential; electroencephalogram; electrophysiology parameters; error related negativity potential; event related potential; feature extraction; feedback system; machine learning; motor cortex; movement (physiology); movement related cortical potential; priority journal; sensory motor rhythm; theta rhythm; visual evoked potential; adolescent; adult; algorithm; artificial neural network; devices; electroencephalography; female; human; male; middle aged; physiology; procedures; young adult; Brain computer interface","Institute of Physics Publishing","17412560","","","29932424","Article","Scopus","2-s2.0-85053150526"
"Qiao J.; Wang G.; Li W.; Li X.","Qiao, Junfei (9634105900); Wang, Gongming (57195606371); Li, Wenjing (57200498007); Li, Xiaoli (56928444700)","9634105900; 57195606371; 57200498007; 56928444700","A deep belief network with PLSR for nonlinear system modeling","2018","Neural Networks","67","10.1016/j.neunet.2017.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046777188&doi=10.1016%2fj.neunet.2017.10.006&partnerID=40&md5=4842997764080a3f557e0b6ed5699835","Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing, 100124, China","Qiao J., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing, 100124, China; Wang G., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing, 100124, China; Li W., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing, 100124, China; Li X., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China","Nonlinear system modeling plays an important role in practical engineering, and deep learning-based deep belief network (DBN) is now popular in nonlinear system modeling and identification because of the strong learning ability. However, the existing weights optimization for DBN is based on gradient, which always leads to a local optimum and a poor training result. In this paper, a DBN with partial least square regression (PLSR-DBN) is proposed for nonlinear system modeling, which focuses on the problem of weights optimization for DBN using PLSR. Firstly, unsupervised contrastive divergence (CD) algorithm is used in weights initialization. Secondly, initial weights derived from CD algorithm are optimized through layer-by-layer PLSR modeling from top layer to bottom layer. Instead of gradient method, PLSR-DBN can determine the optimal weights using several PLSR models, so that a better performance of PLSR-DBN is achieved. Then, the analysis of convergence is theoretically given to guarantee the effectiveness of the proposed PLSR-DBN model. Finally, the proposed PLSR-DBN is tested on two benchmark nonlinear systems and an actual wastewater treatment system as well as a handwritten digit recognition (nonlinear mapping and modeling) with high-dimension input data. The experiment results show that the proposed PLSR-DBN has better performances of time and accuracy on nonlinear system modeling than that of other methods. © 2017 Elsevier Ltd","Deep belief network; Nonlinear system modeling; Partial least square regression; Wastewater treatment system; Weights optimization","Least-Squares Analysis; Machine Learning; Neural Networks (Computer); Nonlinear Dynamics; Character recognition; Gradient methods; Nonlinear systems; Wastewater treatment; Contrastive divergence; Deep belief network (DBN); Deep belief networks; Handwritten digit recognition; Nonlinear system modeling; Partial least square regression; Practical engineering; Wastewater treatment system; accuracy; algorithm; Article; artificial neural network; concentration (parameters); contrastive divergence algorithm; deep belief network; mathematical model; nonlinear system; priority journal; process optimization; simulation; time; waste water management; least square analysis; machine learning; nonlinear system; Deep learning","Elsevier Ltd","08936080","","NNETE","29729561","Article","Scopus","2-s2.0-85046777188"
"Al-masni M.A.; Al-antari M.A.; Choi M.-T.; Han S.-M.; Kim T.-S.","Al-masni, Mohammed A. (57192575678); Al-antari, Mugahed A. (57189003551); Choi, Mun-Taek (16229647800); Han, Seung-Moo (8564174800); Kim, Tae-Seong (36072897600)","57192575678; 57189003551; 16229647800; 8564174800; 36072897600","Skin lesion segmentation in dermoscopy images via deep full resolution convolutional networks","2018","Computer Methods and Programs in Biomedicine","326","10.1016/j.cmpb.2018.05.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047600387&doi=10.1016%2fj.cmpb.2018.05.027&partnerID=40&md5=18812c13cc0b21ec98c5062d3b4aad2c","Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; School of Mechanical Engineering, Sungkyunkwan University, South Korea","Al-masni M.A., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Al-antari M.A., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Choi M.-T., School of Mechanical Engineering, Sungkyunkwan University, South Korea; Han S.-M., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Kim T.-S., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea","Background and objective: Automatic segmentation of skin lesions in dermoscopy images is still a challenging task due to the large shape variations and indistinct boundaries of the lesions. Accurate segmentation of skin lesions is a key prerequisite step for any computer-aided diagnostic system to recognize skin melanoma. Methods: In this paper, we propose a novel segmentation methodology via full resolution convolutional networks (FrCN). The proposed FrCN method directly learns the full resolution features of each individual pixel of the input data without the need for pre- or post-processing operations such as artifact removal, low contrast adjustment, or further enhancement of the segmented skin lesion boundaries. We evaluated the proposed method using two publicly available databases, the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 Challenge and PH2 datasets. To evaluate the proposed method, we compared the segmentation performance with the latest deep learning segmentation approaches such as the fully convolutional network (FCN), U-Net, and SegNet. Results: Our results showed that the proposed FrCN method segmented the skin lesions with an average Jaccard index of 77.11% and an overall segmentation accuracy of 94.03% for the ISBI 2017 test dataset and 84.79% and 95.08%, respectively, for the PH2 dataset. In comparison to FCN, U-Net, and SegNet, the proposed FrCN outperformed them by 4.94%, 15.47%, and 7.48% for the Jaccard index and 1.31%, 3.89%, and 2.27% for the segmentation accuracy, respectively. Furthermore, the proposed FrCN achieved a segmentation accuracy of 95.62% for some representative clinical benign cases, 90.78% for the melanoma cases, and 91.29% for the seborrheic keratosis cases in the ISBI 2017 test dataset, exhibiting better performance than those of FCN, U-Net, and SegNet. Conclusions: We conclude that using the full spatial resolutions of the input image could enable to learn better specific and prominent features, leading to an improvement in the segmentation performance. © 2018 Elsevier B.V.","Deep learning; Dermoscopy; Full resolution convolutional network (FrCN); Melanoma; Skin lesion segmentation","Algorithms; Artifacts; Dermoscopy; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Machine Learning; Melanoma; Neural Networks (Computer); Reproducibility of Results; Sensitivity and Specificity; Skin Diseases; Skin Neoplasms; Convolution; Deep learning; Dermatology; Diagnosis; Image enhancement; Medical imaging; Oncology; Statistical tests; Automatic segmentations; Computer aided diagnostics; Convolutional networks; Dermoscopy; Melanoma; Segmentation accuracy; Segmentation performance; Skin lesion; area under the curve; Article; controlled study; diagnostic test accuracy study; epiluminescence microscopy; human; image segmentation; melanoma; nevus; receiver operating characteristic; seborrheic keratosis; sensitivity and specificity; skin defect; algorithm; artifact; artificial neural network; computer assisted diagnosis; diagnostic imaging; image processing; machine learning; melanoma; reproducibility; skin disease; skin tumor; Image segmentation","Elsevier Ireland Ltd","01692607","","CMPBE","29903489","Article","Scopus","2-s2.0-85047600387"
"Mao D.; Wang F.; Hao Z.; Li H.","Mao, Dianhui (55647384200); Wang, Fan (57203340491); Hao, Zhihao (57203317096); Li, Haisheng (55707571100)","55647384200; 57203340491; 57203317096; 55707571100","Credit evaluation system based on blockchain for multiple stakeholders in the food supply chain","2018","International Journal of Environmental Research and Public Health","168","10.3390/ijerph15081627","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051243872&doi=10.3390%2fijerph15081627&partnerID=40&md5=21969e1c489cd18e00b362a7bae9c9e0","Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China","Mao D., Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China; Wang F., Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China; Hao Z., Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China; Li H., Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, 100048, China","The food supply chain is a complex system that involves a multitude of “stakeholders” such as farmers, production factories, distributors, retailers and consumers. “Information asymmetry” between stakeholders is one of the major factors that lead to food fraud. Some current researches have shown that applying blockchain can help ensure food safety. However, they tend to study the traceability of food but not its supervision. This paper provides a blockchain-based credit evaluation system to strengthen the effectiveness of supervision and management in the food supply chain. The system gathers credit evaluation text from traders by smart contracts on the blockchain. Then the gathered text is analyzed directly by a deep learning network named Long Short Term Memory (LSTM). Finally traders’ credit results are used as a reference for the supervision and management of regulators. By applying blockchain, traders can be held accountable for their actions in the process of transaction and credit evaluation. Regulators can gather more reliable, authentic and sufficient information about traders. The results of experiments show that adopting LSTM results in better performance than traditional machine learning methods such as Support Vector Machine (SVM) and Navie Bayes (NB) to analyze the credit evaluation text. The system provides a friendly interface for the convenience of users. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Blockchain; Credit evaluation system; Food supply chain; LSTM","Algorithms; Bayes Theorem; Commerce; Food Safety; Food Supply; Humans; Research; Stakeholder Participation; Support Vector Machine; credit provision; food safety; food supply; machine learning; stakeholder; valuation; article; catering service; comparative effectiveness; human; machine learning; short term memory; support vector machine; algorithm; Bayes theorem; commercial phenomena; economics; food safety; organization and management; research; stakeholder engagement","MDPI AG","16617827","","","30071695","Article","Scopus","2-s2.0-85051243872"
"Kim K.H.; Do W.-J.; Park S.-H.","Kim, Ki Hwan (56987946700); Do, Won-Joon (56989484100); Park, Sung-Hong (16686626100)","56987946700; 56989484100; 16686626100","Improving resolution of MR images with an adversarial network incorporating images with different contrast","2018","Medical Physics","73","10.1002/mp.12945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047616972&doi=10.1002%2fmp.12945&partnerID=40&md5=bd4c4f6ae0961f47781b2ee2301e361a","Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Graduate School of Medical Science and Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea","Kim K.H., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea, Graduate School of Medical Science and Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Do W.-J., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Park S.-H., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea, Graduate School of Medical Science and Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea","Purpose: The routine MRI scan protocol consists of multiple pulse sequences that acquire images of varying contrast. Since high frequency contents such as edges are not significantly affected by image contrast, down-sampled images in one contrast may be improved by high resolution (HR) images acquired in another contrast, reducing the total scan time. In this study, we propose a new deep learning framework that uses HR MR images in one contrast to generate HR MR images from highly down-sampled MR images in another contrast. Materials and Methods: The proposed convolutional neural network (CNN) framework consists of two CNNs: (a) a reconstruction CNN for generating HR images from the down-sampled images using HR images acquired with a different MRI sequence and (b) a discriminator CNN for improving the perceptual quality of the generated HR images. The proposed method was evaluated using a public brain tumor database and in vivo datasets. The performance of the proposed method was assessed in tumor and no-tumor cases separately, with perceptual image quality being judged by a radiologist. To overcome the challenge of training the network with a small number of available in vivo datasets, the network was pretrained using the public database and then fine-tuned using the small number of in vivo datasets. The performance of the proposed method was also compared to that of several compressed sensing (CS) algorithms. Results: Incorporating HR images of another contrast improved the quantitative assessments of the generated HR image in reference to ground truth. Also, incorporating a discriminator CNN yielded perceptually higher image quality. These results were verified in regions of normal tissue as well as tumors for various MRI sequences from pseudo k-space data generated from the public database. The combination of pretraining with the public database and fine-tuning with the small number of real k-space datasets enhanced the performance of CNNs in in vivo application compared to training CNNs from scratch. The proposed method outperformed the compressed sensing methods. Conclusions: The proposed method can be a good strategy for accelerating routine MRI scanning. © 2018 American Association of Physicists in Medicine","convolutional neural network; generative adversarial network; magnetic resonance imaging","Image Enhancement; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Compressed sensing; Convolution; Database systems; Deep learning; Generative adversarial networks; Image acquisition; Image enhancement; Image quality; Neural networks; Tumors; contrast medium; Adversarial networks; Compressed-Sensing; Convolutional neural network; High resolution; High-resolution images; In-vivo; MR-images; MRI sequences; Performance; Public database; algorithm; Article; contrast enhancement; convolutional neural network; factual database; feasibility study; glioma; human; image analysis; image quality; image reconstruction; in vivo study; intermethod comparison; machine learning; measurement error; neuroimaging; nuclear magnetic resonance imaging; quantitative analysis; radiologist; artificial neural network; image enhancement; procedures; Magnetic resonance imaging","John Wiley and Sons Ltd","00942405","","MPHYA","29729006","Article","Scopus","2-s2.0-85047616972"
"Altan G.; Kutlu Y.; Pekmezci A.Ö.; Nural S.","Altan, Gokhan (50360930100); Kutlu, Yakup (16230371300); Pekmezci, Adnan Özhan (57202234881); Nural, Serkan (55072636000)","50360930100; 16230371300; 57202234881; 55072636000","Deep learning with 3D-second order difference plot on respiratory sounds","2018","Biomedical Signal Processing and Control","55","10.1016/j.bspc.2018.05.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047569355&doi=10.1016%2fj.bspc.2018.05.014&partnerID=40&md5=7aa73e6730338e0823cad0beed16ab2f","Iskenderun Technical University, Turkey; Antakya State Hospital, Turkey","Altan G., Iskenderun Technical University, Turkey; Kutlu Y., Iskenderun Technical University, Turkey; Pekmezci A.Ö., Antakya State Hospital, Turkey; Nural S., Antakya State Hospital, Turkey","The second order difference plot (SODP) is a nonlinear signal analysis method that visualizes two consecutive data points for many types of biomedical signals. The proposed method is based on analysing quantization of 3D-space which is originated using three consecutive data points in signal. The obtained 3D-SODP space was segmented into 3–10 spaces using octants, spheres and cuboid polyhedrons of which centroids are at the origin. Lung sound is an indispensable tool for respiratory and cardiac diseases. The study is focused on classifying the lung sounds from at risk level and the interior level of chronic obstructive pulmonary disease (COPD). The COPD is one of the most deadliest and common respiratory diseases which come into existence as a consequence of smoking. The smokers for a few years are qualified as at risk level of COPD (COPD-0). The 12 channels of lung sounds from the RespiratoryDatabase@TR were utilized in the analysis of the proposed 3D-SODP quantization method. The lung sounds are auscultated synchronously from posterior and anterior sides of subjects using two digital stethoscopes by a pulmonologist clinician in Antakya State Hospital, Turkey. Deep Belief Networks (DBN) algorithm was preferred in the classification stage. It has a greedy layer-wise pre-training which is based on restricted Boltzmann machines and optimizes the pre-trained weights using supervised iterations. The proposed DBN model had 2 hidden layers with 270 and 580 neurons, respectively. The conjunction usage of 3D-SODP quantization features with the DBN separated the lung sounds from different levels of COPD with high classification performance rates of 95.84%, 93.34% and 93.65% for accuracy, sensitivity and specificity, respectively. The results indicate that the 3D-SODP quantization on respiratory sounds has ability to diagnose the levels of the COPD using the deep learning model. Especially, the octant-based quantization is effective on lung sounds with high generalization capability using a small number of feature set dimension. © 2018 Elsevier Ltd","3D-SODP; Chronic obstructive pulmonary disease; COPD; DBN; Deep Belief Networks; Deep learning; Lung sounds; Second order difference plot","Bioelectric phenomena; Biological organs; Biomedical signal processing; Pulmonary diseases; Quantization (signal); Smoke; 3D-SODP; Chronic obstructive pulmonary disease; COPD; Deep belief networks; Lung sounds; Second orders; abnormal respiratory sound; Article; artificial neural network; chronic obstructive lung disease; classification algorithm; classifier; data base; deep belief network algorithm; diagnostic accuracy; human; learning algorithm; lung auscultation; machine learning; priority journal; risk; sensitivity and specificity; smoking; Turkey (republic); Deep learning","Elsevier Ltd","17468094","","","","Article","Scopus","2-s2.0-85047569355"
"Athanasiadou E.; Geradts Z.; Van Eijk E.","Athanasiadou, Eleni (57206855237); Geradts, Zeno (6603940596); Van Eijk, Erwin (56092759500)","57206855237; 6603940596; 56092759500","Camera recognition with deep learning","2018","Forensic Sciences Research","9","10.1080/20961790.2018.1485198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062029928&doi=10.1080%2f20961790.2018.1485198&partnerID=40&md5=49dc5a5fc6982ddaad672ce0000cb2f0","Department of Forensic Science University of Amsterdam, Amsterdam, Netherlands; Netherlands Forensic Institute Den Haag, Den Haag, Netherlands","Athanasiadou E., Department of Forensic Science University of Amsterdam, Amsterdam, Netherlands, Netherlands Forensic Institute Den Haag, Den Haag, Netherlands; Geradts Z., Netherlands Forensic Institute Den Haag, Den Haag, Netherlands; Van Eijk E., Netherlands Forensic Institute Den Haag, Den Haag, Netherlands","In this paper, camera recognition with the use of deep learning technique is introduced. To identify the various cameras, their characteristic photo-response non-uniformity (PRNU) noise pattern was extracted. In forensic science, it is important, especially for child pornography cases, to link a photo or a set of photos to a specific camera. Deep learning is a sub-field of machine learning which trains the computer as a human brain to recognize similarities and differences by scanning it, in order to identify an object. The innovation of this research is the use of PRNU noise patterns and a deep learning technique in order to achieve camera identification. In this paper, AlexNet was modified producing an improved training procedure with high maximum accuracy of 80%–90%. DIGITS showed to have identified correctly six cameras out of 10 with a success rate higher than 75% in the database. However, many of the cameras were falsely identified indicating a fault occurring during the procedure. A possible explanation for this is that the PRNU signal is based on the quality of the sensor and the artefacts introduced during the production process of the camera. Some manufacturers may use the same or similar imaging sensors, which could result in similar PRNU noise patterns. In an attempt to form a database which contained different cameras of the same model as different categories, the accuracy rate was low. This provided further proof of the limitations of this technique, since PRNU is stochastic in nature and should be able to distinguish between different cameras from the same brand. Therefore, this study showed that current convolutional neural networks (CNNs) cannot achieve individualization with PRNU patterns. Nevertheless, the paper provided material for further research. © 2018, © 2018 The Author(s). Published by Taylor & Francis Group on behalf of the Academy of Forensic Science.","camera identification; clustering; Forensic sciences; individualization deep learning","","Taylor and Francis Ltd.","20961790","","","","Article","Scopus","2-s2.0-85062029928"
"Fu X.; Liu T.; Xiong Z.; Smaill B.H.; Stiles M.K.; Zhao J.","Fu, Xiaohang (57202131274); Liu, Tong (23568158200); Xiong, Zhaohan (57201493368); Smaill, Bruce H. (6701767071); Stiles, Martin K. (35278667100); Zhao, Jichao (14065624800)","57202131274; 23568158200; 57201493368; 6701767071; 35278667100; 14065624800","Segmentation of histological images and fibrosis identification with a convolutional neural network","2018","Computers in Biology and Medicine","36","10.1016/j.compbiomed.2018.05.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047268384&doi=10.1016%2fj.compbiomed.2018.05.015&partnerID=40&md5=1dddf884e1a1699ea89bcb76f0fdfe8d","Auckland Bioengineering Institute, The University of Auckland, Auckland, 1142, New Zealand; Department of Cardiology, Second Hospital of Tianjin Medical University, Tianjin Key Laboratory of Ionic-Molecular Function of Cardiovascular Disease, Tianjin Institute of Cardiology, Tianjin, 300201, China; Waikato Hospital, Hamilton, 3204, New Zealand","Fu X., Auckland Bioengineering Institute, The University of Auckland, Auckland, 1142, New Zealand; Liu T., Department of Cardiology, Second Hospital of Tianjin Medical University, Tianjin Key Laboratory of Ionic-Molecular Function of Cardiovascular Disease, Tianjin Institute of Cardiology, Tianjin, 300201, China; Xiong Z., Auckland Bioengineering Institute, The University of Auckland, Auckland, 1142, New Zealand; Smaill B.H., Auckland Bioengineering Institute, The University of Auckland, Auckland, 1142, New Zealand; Stiles M.K., Waikato Hospital, Hamilton, 3204, New Zealand; Zhao J., Auckland Bioengineering Institute, The University of Auckland, Auckland, 1142, New Zealand","Segmentation of histological images is one of the most crucial tasks for many biomedical analyses involving quantification of certain tissue types, such as fibrosis via Masson's trichrome staining. However, challenges are posed by the high variability and complexity of structural features in such images, in addition to imaging artifacts. Further, the conventional approach of manual thresholding is labor-intensive, and highly sensitive to inter- and intra-image intensity variations. An accurate and robust automated segmentation method is of high interest. We propose and evaluate an elegant convolutional neural network (CNN) designed for segmentation of histological images, particularly those with Masson's trichrome stain. The network comprises 11 successive convolutional – rectified linear unit – batch normalization layers. It outperformed state-of-the-art CNNs on a dataset of cardiac histological images (labeling fibrosis, myocytes, and background) with a Dice similarity coefficient of 0.947. With 100 times fewer (only 300,000) trainable parameters than the state-of-the-art, our CNN is less susceptible to overfitting, and is efficient. Additionally, it retains image resolution from input to output, captures fine-grained details, and can be trained end-to-end smoothly. To the best of our knowledge, this is the first deep CNN tailored to the problem of concern, and may potentially be extended to solve similar segmentation tasks to facilitate investigations into pathology and clinical treatment. © 2018","Convolutional neural network; Deep learning; Fibrosis; Histology; Image segmentation","Deep Learning; Fibrosis; Heart Diseases; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Neural Networks (Computer); Convolution; Deep learning; Histology; Image resolution; Neural networks; Automated segmentation method; Clinical treatments; Conventional approach; Convolutional neural network; Convolutional Neural Networks (CNN); Fibrosis; Image intensity variations; Similarity coefficients; accuracy; animal tissue; Article; artificial neural network; cardiac muscle cell; controlled study; convolutional neural network; diabetes mellitus; dice similarity coefficient; evaluation study; fibrosis; heart atrium; histology; image segmentation; machine learning; Masson trichrome staining; nonhuman; priority journal; staining; statistical model; computer assisted diagnosis; cytochemistry; diagnostic imaging; fibrosis; heart disease; human; pathology; procedures; Image segmentation","Elsevier Ltd","00104825","","CBMDA","29793096","Article","Scopus","2-s2.0-85047268384"
"Azizi S.; Van Woudenberg N.; Sojoudi S.; Li M.; Xu S.; Abu Anas E.M.; Yan P.; Tahmasebi A.; Kwak J.T.; Turkbey B.; Choyke P.; Pinto P.; Wood B.; Mousavi P.; Abolmaesumi P.","Azizi, Shekoofeh (57014719000); Van Woudenberg, Nathan (57201367076); Sojoudi, Samira (56042835100); Li, Ming (57226231506); Xu, Sheng (35868251000); Abu Anas, Emran M. (57205292745); Yan, Pingkun (8346373300); Tahmasebi, Amir (56606356800); Kwak, Jin Tae (57226305229); Turkbey, Baris (9435311800); Choyke, Peter (7102809178); Pinto, Peter (7103408914); Wood, Bradford (7401873523); Mousavi, Parvin (16176026900); Abolmaesumi, Purang (6602170125)","57014719000; 57201367076; 56042835100; 57226231506; 35868251000; 57205292745; 8346373300; 56606356800; 57226305229; 9435311800; 7102809178; 7103408914; 7401873523; 16176026900; 6602170125","Toward a real-time system for temporal enhanced ultrasound-guided prostate biopsy","2018","International Journal of Computer Assisted Radiology and Surgery","8","10.1007/s11548-018-1749-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044460539&doi=10.1007%2fs11548-018-1749-z&partnerID=40&md5=eaeee509b90f3aa7ba9a58657299e0be","The University of British Columbia, Vancouver, BC, Canada; National Institutes of Health, Bethesda, MD, United States; Johns Hopkins University, Baltimore, MD, United States; Philips Research North America, Cambridge, MA, United States; Sejong University, Gwangjin-gu, Seoul, South Korea; Queen’s University, Kingston, ON, Canada; Rensselaer Polytechnic Institute, Troy, NY, United States","Azizi S., The University of British Columbia, Vancouver, BC, Canada; Van Woudenberg N., The University of British Columbia, Vancouver, BC, Canada; Sojoudi S., The University of British Columbia, Vancouver, BC, Canada; Li M., National Institutes of Health, Bethesda, MD, United States; Xu S., National Institutes of Health, Bethesda, MD, United States; Abu Anas E.M., Johns Hopkins University, Baltimore, MD, United States; Yan P., Rensselaer Polytechnic Institute, Troy, NY, United States; Tahmasebi A., Philips Research North America, Cambridge, MA, United States; Kwak J.T., Sejong University, Gwangjin-gu, Seoul, South Korea; Turkbey B., National Institutes of Health, Bethesda, MD, United States; Choyke P., National Institutes of Health, Bethesda, MD, United States; Pinto P., National Institutes of Health, Bethesda, MD, United States; Wood B., National Institutes of Health, Bethesda, MD, United States; Mousavi P., Queen’s University, Kingston, ON, Canada; Abolmaesumi P., The University of British Columbia, Vancouver, BC, Canada","Purpose: We have previously proposed temporal enhanced ultrasound (TeUS) as a new paradigm for tissue characterization. TeUS is based on analyzing a sequence of ultrasound data with deep learning and has been demonstrated to be successful for detection of cancer in ultrasound-guided prostate biopsy. Our aim is to enable the dissemination of this technology to the community for large-scale clinical validation. Methods: In this paper, we present a unified software framework demonstrating near-real-time analysis of ultrasound data stream using a deep learning solution. The system integrates ultrasound imaging hardware, visualization and a deep learning back-end to build an accessible, flexible and robust platform. A client–server approach is used in order to run computationally expensive algorithms in parallel. We demonstrate the efficacy of the framework using two applications as case studies. First, we show that prostate cancer detection using near-real-time analysis of RF and B-mode TeUS data and deep learning is feasible. Second, we present real-time segmentation of ultrasound prostate data using an integrated deep learning solution. Results: The system is evaluated for cancer detection accuracy on ultrasound data obtained from a large clinical study with 255 biopsy cores from 157 subjects. It is further assessed with an independent dataset with 21 biopsy targets from six subjects. In the first study, we achieve area under the curve, sensitivity, specificity and accuracy of 0.94, 0.77, 0.94 and 0.92, respectively, for the detection of prostate cancer. In the second study, we achieve an AUC of 0.85. Conclusion: Our results suggest that TeUS-guided biopsy can be potentially effective for the detection of prostate cancer. © 2018, CARS.","3D slicer; Prostate cancer; Real-time biopsy guidance; Temporal enhanced ultrasound","Algorithms; Biopsy, Large-Core Needle; Computer Systems; Humans; Image-Guided Biopsy; Male; Prostatic Neoplasms; Sensitivity and Specificity; Ultrasonography, Interventional; Article; B scan; cancer diagnosis; diagnostic accuracy; Gleason score; human; human tissue; image guided biopsy; machine learning; major clinical study; male; priority journal; prostate biopsy; prostate cancer; real time echography; retrospective study; sensitivity and specificity; algorithm; computer system; image guided biopsy; interventional ultrasonography; large core needle biopsy; procedures; prostate tumor","Springer Verlag","18616410","","","29589258","Article","Scopus","2-s2.0-85044460539"
"Cai L.-H.; Ding J.-L.","Cai, Liang-Hong (57192427943); Ding, Jian-Li (13610395400)","57192427943; 13610395400","Prediction for Soil Water Content Based on Variable Preferred and Extreme Learning Machine Algorithm; [基于变量优选和ELM算法的土壤含水量预测研究]","2018","Guang Pu Xue Yu Guang Pu Fen Xi/Spectroscopy and Spectral Analysis","13","10.3964/j.issn.1000-0593(2018)07-2209-06","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055263749&doi=10.3964%2fj.issn.1000-0593%282018%2907-2209-06&partnerID=40&md5=fbcdc385a0e192a43b97d10ff6e92ea2","College of Resources & Environmental Science, Xinjiang University, Urumqi, 830046, China; Key Laboratory of Oasis Ecology, Xinjiang University, Urumqi, 830046, China","Cai L.-H., College of Resources & Environmental Science, Xinjiang University, Urumqi, 830046, China, Key Laboratory of Oasis Ecology, Xinjiang University, Urumqi, 830046, China; Ding J.-L., College of Resources & Environmental Science, Xinjiang University, Urumqi, 830046, China, Key Laboratory of Oasis Ecology, Xinjiang University, Urumqi, 830046, China","The rapid estimation of soil moisture content (SMC) is of great significance to precision agriculture in arid areas, and hyperspectral remote sensing technology had been widely used in the estimation of soil moisture content due to its non-destructive, rapid, and high spectral resolution characteristics. Meanwhile, there are many prediction models of soil moisture content, such as BP, SVM, RF and so on, but the prediction model has some shortcomings. Recently, the extreme learning machine(ELM) as a new algorithm began to emerge in the field of soil property prediction. In the present study, a total of 39 soil samples at 0~20 cm depth were collected from delta oasis in Weigan-Kuqain, Xinjiang Province. We brought back to the laboratory to dry it naturally, groundnd and passed through a 2 mm hole scree, and then the sample holders were clear black boxs in 12 cm diameter and 1.8 cm deep, which were filled and leveled at the rim with a spatula. Reflectance of soil samples were measured using ASD Fieldspec 3 Spectrometer in a dark room. We used the following steps to process soil reflectance: First, discrete wavelet transformation (DWT) was used to decompose the original spectral in 8 levels using db4 wavelet basis by MATLAB programming language. In order to select the maximum level of DWT, correlation coefficients between SMC and the spectra of each level was computed. Secondly, On the basis of wavelet transform, CARS (the adaptive variable weighting algorithm), SPA (successive projections algorithm) and CARS-SPA were used to filter the redundant variables, the wavelength variables with better correlation with SMC were screened out. Thirdly, On the basis of the preferred wavelengths, BP neural network, SVM (support vector machine), RF (random forest) and ELM (extreme learning machine) prediction models were employed to build the hyperspectral estimation models of SMC, and the advantages and disadvantages of the model were further analyzed. Statistical parameters of root mean square error of calibration (RMSEC), determination coefficient of calibration (Rc                             2), root mean square error of prediction (RMSEP), determination coefficient of predicting (Rp                             2) and relative prediction deviation (RPD) were selected as comparison criteria. The results showed that: (1) With the increase of the number of decomposed layers, the correlation between soil reflectance and SMC showed a trend of increasing first and then decreasing, and L6 was the most significant band at 0.01 level. In general, the characteristic spectrum of L6 was denoised at the same time, and the spectral detail was preserved to the maximum extent. So the maximum decomposition order of the wavelet was 6 order decomposition; (2) On the basis of L6, the CARS, SPA and CARS-SPA algorithms were used to optimize the variables, and the number of selected wavelength variables were 81, 23 and 12, respectively. The predictive models constructed by three algorithms were better than those of the whole-band model. The prediction model based on the CARS-SPA was the most accurate in the corresponding model. It can be seen that the CARS-SPA coupling algorithm not only simplified the model complexity, but also increased the robustness of the model; (3) Compared with the BP, SVM, RF and ELM, In all the SMC predicting models, there were 6 models with predictive ability, Sort by: L6-CARS-SPA-ELM>L6-CARS-SPA-RF>L6-CARS-ELM>L6-CARS-RF>L6-SPA-ELM>L6-SPA-RF. Results showed that ELM performed much better than BP, SVM and RF in predicting SMC in this study. At the same time, the L6-CARS-SPA-ELM model had the highest accuracy, and the model had RMSEC=0.015 1, Rc                             2=0.916 6, RMSEP=0.014 2, Rp                             2=0.935 4, RPD=2.323 9. It was shown that the combination of wavelet transform and CARS-SPA algorithm made it possible to remove the noise as much as possible and to remove the noise completely when the model was established. At the same time, and ELM model was a new method to predict other soil properties. © 2018, Peking University Press. All right reserved.","ELM (extreme learning machine); Soil moisture; Spectroscopy; Variable selection; WT (wavelet transformation)","Calibration; Coherent scattering; Couplings; Decision trees; Discrete wavelet transforms; Forecasting; Knowledge acquisition; MATLAB; Mean square error; Moisture determination; Neural networks; Reflection; Remote sensing; Signal reconstruction; Soil moisture; Soil surveys; Spectral resolution; Spectrometers; Spectroscopy; Speech recognition; Support vector machines; Wavelet decomposition; Discrete wavelet transformation; ELM (extreme learning machine); Hyperspectral remote sensing technology; Root mean square error of calibrations; Root-mean-square error of predictions; Successive projections algorithm; Variable selection; Wavelet transformations; Learning algorithms","Science Press","10000593","","GYGFE","","Article","Scopus","2-s2.0-85055263749"
"Mathews S.M.; Kambhamettu C.; Barner K.E.","Mathews, Sherin M. (56640862000); Kambhamettu, Chandra (6701348246); Barner, Kenneth E. (7006447386)","56640862000; 6701348246; 7006447386","A novel application of deep learning for single-lead ECG classification","2018","Computers in Biology and Medicine","233","10.1016/j.compbiomed.2018.05.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048201813&doi=10.1016%2fj.compbiomed.2018.05.013&partnerID=40&md5=db760d3ad695f811c867381f8033d2b3","Intel, 2821 Mission College, Santa Clara, 95051, CA, United States; Dept. of Electrical and Computer Engineering, University of Delaware, Newark, 19716, DE, United States; Video/Image Modeling and Synthesis (VIMS) Lab, Department of Computer and Information Sciences, University of Delaware, United States","Mathews S.M., Intel, 2821 Mission College, Santa Clara, 95051, CA, United States, Dept. of Electrical and Computer Engineering, University of Delaware, Newark, 19716, DE, United States; Kambhamettu C., Video/Image Modeling and Synthesis (VIMS) Lab, Department of Computer and Information Sciences, University of Delaware, United States; Barner K.E., Dept. of Electrical and Computer Engineering, University of Delaware, Newark, 19716, DE, United States","Detecting and classifying cardiac arrhythmias is critical to the diagnosis of patients with cardiac abnormalities. In this paper, a novel approach based on deep learning methodology is proposed for the classification of single-lead electrocardiogram (ECG) signals. We demonstrate the application of the Restricted Boltzmann Machine (RBM) and deep belief networks (DBN) for ECG classification following detection of ventricular and supraventricular heartbeats using single-lead ECG. The effectiveness of this proposed algorithm is illustrated using real ECG signals from the widely-used MIT-BIH database. Simulation results demonstrate that with a suitable choice of parameters, RBM and DBN can achieve high average recognition accuracies of ventricular ectopic beats (93.63%) and of supraventricular ectopic beats (95.57%) at a low sampling rate of 114 Hz. Experimental results indicate that classifiers built into this deep learning-based framework achieved state-of-the art performance models at lower sampling rates and simple features when compared to traditional methods. Further, employing features extracted at a sampling rate of 114 Hz when combined with deep learning provided enough discriminatory power for the classification task. This performance is comparable to that of traditional methods and uses a much lower sampling rate and simpler features. Thus, our proposed deep neural network algorithm demonstrates that deep learning-based methods offer accurate ECG classification and could potentially be extended to other physiological signal classifications, such as those in arterial blood pressure (ABP), nerve conduction (EMG), and heart rate variability (HRV) studies. © 2018","Deep belief networks (DBN); Deep learning; Heartbeat classification; MIT-BIH database; Restricted Boltzmann machine; single-lead ECG recognition","Arrhythmias, Cardiac; Databases, Factual; Deep Learning; Electrocardiography; Humans; Signal Processing, Computer-Assisted; Blood pressure; Chemical detection; Classification (of information); Deep learning; Deep neural networks; Electrocardiography; Deep belief network (DBN); Heartbeat classifications; MIT-BIH database; Restricted boltzmann machine; single-lead ECG recognition; Article; classifier; controlled study; deep learning framework; diagnostic accuracy; disease classification; electrocardiogram; false positive result; feature extraction; heart arrhythmia; heart beat; heart left bundle branch block; heart repolarization; heart right bundle branch block; heart ventricle extrasystole; human; learning algorithm; P wave; partition coefficient; pattern recognition; predictive value; priority journal; QRS complex; QRS interval; RR interval; sensitivity and specificity; supraventricular premature beat; T wave; waveform; electrocardiography; factual database; heart arrhythmia; pathophysiology; signal processing; Biomedical signal processing","Elsevier Ltd","00104825","","CBMDA","29886261","Article","Scopus","2-s2.0-85048201813"
"Zou N.; Huang X.","Zou, Na (56705724500); Huang, Xiao (57193628904)","56705724500; 57193628904","Empirical Bayes Transfer Learning for Uncertainty Characterization in Predicting Parkinson’s Disease Severity","2018","IISE Transactions on Healthcare Systems Engineering","7","10.1080/24725579.2018.1496495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057304573&doi=10.1080%2f24725579.2018.1496495&partnerID=40&md5=eb26ff007cc7035dfca1a50d23cbc4fa","Industrial and Systems Engineering, Texas A&M University, College Station, TX, United States; Computer Science and Engineering, Texas A&M University, College Station, TX, United States","Zou N., Industrial and Systems Engineering, Texas A&M University, College Station, TX, United States; Huang X., Computer Science and Engineering, Texas A&M University, College Station, TX, United States","Parkinson’s disease (PD) is a common neurodegenerative disorder disease. Identifying an accurate model to predict severity level is critical to prevent severe suffering for PD patients. However, the existing research does not consider the heterogeneity among patients, falls short for prediction uncertainty characterization and typically adopts models that involve tedious parameter tuning processes. We propose to incorporate transfer learning and sparse learning under a Hierarchical Bayesian framework for tractable estimation of parameter posterior distribution and prediction uncertainty quantification. Specifically, we develop an empirical Bayes transfer learning (ebTL) model that accounts for patient heterogeneity and meanwhile allows for knowledge transfer between the modeling processes of different patients. ebTL is also featured for automatic hyper-parameters estimation without a tedious tuning process. Finally, we present an application of predicting PD severity level by using features extracted from speech signals across PD patients. The model could achieve better prediction accuracy compared with the other two competing methods and enable reasonable quantification of prediction intervals. © 2018, © 2018 “IISE”.","","accuracy; area under the curve; Article; Bayes theorem; bayesian inference; Bayesian learning; deep learning; disease severity; empirical bayes transfer learning; genetic heterogeneity; human; learning algorithm; machine learning; Markov chain; mathematical model; Monte Carlo method; normal distribution; Parkinson disease; priority journal; simulation; transfer of learning; uncertainty","Taylor and Francis Inc.","24725579","","","","Article","Scopus","2-s2.0-85057304573"
"Cai C.-H.; Xu Y.; Ke D.; Su K.","Cai, Cheng-Hao (56424872300); Xu, Yanyan (55175447800); Ke, Dengfeng (24923197000); Su, Kaile (7101635763)","56424872300; 55175447800; 24923197000; 7101635763","Learning of human-like algebraic reasoning using deep feedforward neural networks","2018","Biologically Inspired Cognitive Architectures","6","10.1016/j.bica.2018.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050013162&doi=10.1016%2fj.bica.2018.07.004&partnerID=40&md5=dce6c2c608b5cf4fc6f4de23d38e05a4","Department of Computer Science, University of Auckland, 38 Princes Street, Auckland, 1142, New Zealand; School of Information Science and Technology, Beijing Forestry University, 35 Qing-Hua East Road, Beijing, 100083, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, 95 Zhong-Guan-Cun East Road, Beijing, 100190, China; Institute for Integrated and Intelligent Systems, Griffith University, 170 Kessels Road, Nathan, 4111, QLD, Australia","Cai C.-H., Department of Computer Science, University of Auckland, 38 Princes Street, Auckland, 1142, New Zealand; Xu Y., School of Information Science and Technology, Beijing Forestry University, 35 Qing-Hua East Road, Beijing, 100083, China; Ke D., National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, 95 Zhong-Guan-Cun East Road, Beijing, 100190, China; Su K., Institute for Integrated and Intelligent Systems, Griffith University, 170 Kessels Road, Nathan, 4111, QLD, Australia","Human-like rewriting, which is an algebraic reasoning system imitating human intelligence of problem solving, is proposed in this work. In order to imitate both learning and reasoning aspects of human cognition, a deep feedforward neural network learns from algebraic reasoning examples produced by humans and then uses learnt experiences to guide other reasoning processes. This work shows that the neural network can learn human's behaviours of solving mathematical problems, and it can indicate suitable directions of reasoning, so that intelligent and heuristic reasoning can be performed. Moreover, human-like rewriting bridges the gap between symbolic reasoning and biologically inspired machine learning. To enable the neural network to recognise patterns of symbolic expressions with non-deterministic sizes, the expressions are reduced to partial tree representations and then vectorised as numeric features. Further, the centralisation method, symbolic association vectors and rule application records are used to improve the vectorised features. With these approaches, human-like rewriting shows satisfactory performance on the tasks of solving linear equations and computing derivations and indefinite integrals. © 2018 Elsevier B.V.","Algebraic reasoning; Deep learning; Neural network reasoning; Reasoning-based learning","Algebra; Behavioral research; Deep learning; Deep neural networks; Feedforward neural networks; 00-01; 99-00; Algebraic reasoning; Association vectors; Biologically inspired; Heuristic Reasoning; Mathematical problems; Reasoning-based learning; Problem solving","Elsevier B.V.","2212683X","","","","Article","Scopus","2-s2.0-85050013162"
"Jang H.; Liu F.; Zhao G.; Bradshaw T.; McMillan A.B.","Jang, Hyungseok (55806832500); Liu, Fang (55877583300); Zhao, Gengyan (57200650684); Bradshaw, Tyler (55987286000); McMillan, Alan B. (35196501700)","55806832500; 55877583300; 57200650684; 55987286000; 35196501700","Technical Note: Deep learning based MRAC using rapid ultrashort echo time imaging","2018","Medical Physics","47","10.1002/mp.12964","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050601429&doi=10.1002%2fmp.12964&partnerID=40&md5=ca3480996abe5c0de9aebbfc65b0d824","Department of Radiology, University of California San Diego, 200 West Arbor Drive, San Diego, 92103-8226, CA, United States; Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Avenue, Madison, 53705-2275, WI, United States; Department of Medical Physics, University of Wisconsin School of Medicine and Public Health, 1111 Highland Avenue, Madison, 53705-2275, WI, United States","Jang H., Department of Radiology, University of California San Diego, 200 West Arbor Drive, San Diego, 92103-8226, CA, United States; Liu F., Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Avenue, Madison, 53705-2275, WI, United States; Zhao G., Department of Medical Physics, University of Wisconsin School of Medicine and Public Health, 1111 Highland Avenue, Madison, 53705-2275, WI, United States; Bradshaw T., Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Avenue, Madison, 53705-2275, WI, United States; McMillan A.B., Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Avenue, Madison, 53705-2275, WI, United States","Purpose: In this study, we explore the feasibility of a novel framework for MR-based attenuation correction for PET/MR imaging based on deep learning via convolutional neural networks, which enables fully automated and robust estimation of a pseudo CT image based on ultrashort echo time (UTE), fat, and water images obtained by a rapid MR acquisition. Methods: MR images for MRAC are acquired using dual echo ramped hybrid encoding (dRHE), where both UTE and out-of-phase echo images are obtained within a short single acquisition (35 s). Tissue labeling of air, soft tissue, and bone in the UTE image is accomplished via a deep learning network that was pre-trained with T1-weighted MR images. UTE images are used as input to the network, which was trained using labels derived from co-registered CT images. The tissue labels estimated by deep learning are refined by a conditional random field based correction. The soft tissue labels are further separated into fat and water components using the two-point Dixon method. The estimated bone, air, fat, and water images are then assigned appropriate Hounsfield units, resulting in a pseudo CT image for PET attenuation correction. To evaluate the proposed MRAC method, PET/MR imaging of the head was performed on eight human subjects, where Dice similarity coefficients of the estimated tissue labels and relative PET errors were evaluated through comparison to a registered CT image. Result: Dice coefficients for air (within the head), soft tissue, and bone labels were 0.76 ± 0.03, 0.96 ± 0.006, and 0.88 ± 0.01. In PET quantitation, the proposed MRAC method produced relative PET errors less than 1% within most brain regions. Conclusion: The proposed MRAC method utilizing deep learning with transfer learning and an efficient dRHE acquisition enables reliable PET quantitation with accurate and rapid pseudo CT generation. © 2018 American Association of Physicists in Medicine","deep learning; MR-based attenuation correction; transfer learning","Brain; Computerized tomography; Deep learning; Image coding; Magnetic resonance imaging; Tissue; fat; fluorodeoxyglucose f 18; water; Attenuation correction; CT Image; Deep learning; Hybrid Encoding; MR imaging; MR-based attenuation correction; MR-images; Soft tissue; Transfer learning; Ultrashort echo time; Article; artificial neural network; bone structure; bone tissue; brain region; clinical evaluation; computer assisted tomography; deep learning; diagnostic accuracy; diagnostic imaging; dual echo ramped hybrid encoding; human; human tissue; image quality; image segmentation; imaging and display; machine learning; MR-based attenuation correction; nuclear magnetic resonance imaging; positron emission tomography; radiation attenuation; soft tissue; transfer of learning; ultrashort echo time imaging; x-ray computed tomography; Neural networks","John Wiley and Sons Ltd","00942405","","MPHYA","29763997","Article","Scopus","2-s2.0-85050601429"
"Lin J.; Clancy N.T.; Qi J.; Hu Y.; Tatla T.; Stoyanov D.; Maier-Hein L.; Elson D.S.","Lin, Jianyu (56606450100); Clancy, Neil T. (34978108100); Qi, Ji (45761341500); Hu, Yang (57116675300); Tatla, Taran (57203131729); Stoyanov, Danail (57203105770); Maier-Hein, Lena (22634618600); Elson, Daniel S. (7005533698)","56606450100; 34978108100; 45761341500; 57116675300; 57203131729; 57203105770; 22634618600; 7005533698","Dual-modality endoscopic probe for tissue surface shape reconstruction and hyperspectral imaging enabled by deep neural networks","2018","Medical Image Analysis","46","10.1016/j.media.2018.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048705488&doi=10.1016%2fj.media.2018.06.004&partnerID=40&md5=48ae180c3cf428569e620ef396b95b8f","The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Wellcome/EPSRC Centre for Interventional & Surgical Sciences (WEISS), University College London, London, United Kingdom; Centre for Medical Image Computing, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom; Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Department of Otolaryngology, Northwick Park Hospital, Harrow, United Kingdom; Division of Medical and Biological Informatics, German Cancer Research Center, Heidelberg, Germany","Lin J., The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom, Department of Computing, Imperial College London, London, United Kingdom; Clancy N.T., The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom, Wellcome/EPSRC Centre for Interventional & Surgical Sciences (WEISS), University College London, London, United Kingdom, Centre for Medical Image Computing, University College London, London, United Kingdom, Department of Computer Science, University College London, London, United Kingdom, Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Qi J., The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom, Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Hu Y., The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom, Department of Computing, Imperial College London, London, United Kingdom; Tatla T., Department of Otolaryngology, Northwick Park Hospital, Harrow, United Kingdom; Stoyanov D., Wellcome/EPSRC Centre for Interventional & Surgical Sciences (WEISS), University College London, London, United Kingdom, Centre for Medical Image Computing, University College London, London, United Kingdom, Department of Computer Science, University College London, London, United Kingdom; Maier-Hein L., Division of Medical and Biological Informatics, German Cancer Research Center, Heidelberg, Germany; Elson D.S., The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom, Department of Surgery and Cancer, Imperial College London, London, United Kingdom","Surgical guidance and decision making could be improved with accurate and real-time measurement of intra-operative data including shape and spectral information of the tissue surface. In this work, a dual-modality endoscopic system has been proposed to enable tissue surface shape reconstruction and hyperspectral imaging (HSI). This system centers around a probe comprised of an incoherent fiber bundle, whose fiber arrangement is different at the two ends, and miniature imaging optics. For 3D reconstruction with structured light (SL), a light pattern formed of randomly distributed spots with different colors is projected onto the tissue surface, creating artificial texture. Pattern decoding with a Convolutional Neural Network (CNN) model and a customized feature descriptor enables real-time 3D surface reconstruction at approximately 12 frames per second (FPS). In HSI mode, spatially sparse hyperspectral signals from the tissue surface can be captured with a slit hyperspectral imager in a single snapshot. A CNN based super-resolution model, namely “super-spectral-resolution” network (SSRNet), has also been developed to estimate pixel-level dense hypercubes from the endoscope cameras standard RGB images and the sparse hyperspectral signals, at approximately 2 FPS. The probe, with a 2.1 mm diameter, enables the system to be used with endoscope working channels. Furthermore, since data acquisition in both modes can be accomplished in one snapshot, operation of this system in clinical applications is minimally affected by tissue surface movement and deformation. The whole apparatus has been validated on phantoms and tissue (ex vivo and in vivo), while initial measurements on patients during laryngeal surgery show its potential in real-world clinical applications. © 2018 Elsevier B.V.","3D reconstruction; Deep learning; Hyperspectral imaging; Intra-operative imaging; Structured light; Super-spectral-resolution","Algorithms; Endoscopes; Fiber Optic Technology; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Intraoperative Period; Neural Networks (Computer); Spatial Analysis; Spectrum Analysis; Biomedical signal processing; Convolutional neural networks; Data acquisition; Decision making; Deep learning; Deep neural networks; Endoscopy; Image reconstruction; Light; Probes; Spectral resolution; Spectroscopy; Surgery; Textures; Three dimensional computer graphics; Tissue; 3D reconstruction; 3D surface reconstruction; Hyperspectral imagers; Hyperspectral signals; Intra-operative imaging; Real time measurements; Structured Light; Super-resolution models; accuracy; Article; deep neural network; human; human tissue; hyperspectral imaging; image quality; imaging; larynx; machine learning; prediction; priority journal; three dimensional imaging; algorithm; artificial neural network; endoscope; fiber optics; image processing; intraoperative period; procedures; spatial analysis; spectroscopy; Hyperspectral imaging","Elsevier B.V.","13618415","","MIAEC","29933116","Article","Scopus","2-s2.0-85048705488"
"You R.; Huang X.; Zhu S.","You, Ronghui (56501667700); Huang, Xiaodi (57855004000); Zhu, Shanfeng (8940145500)","56501667700; 57855004000; 8940145500","DeepText2GO: Improving large-scale protein function prediction with deep semantic text representation","2018","Methods","50","10.1016/j.ymeth.2018.05.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048880771&doi=10.1016%2fj.ymeth.2018.05.026&partnerID=40&md5=ea313f3cae7b8bfc2dc1e1a64aa8fc5c","School of Computer Science and Shanghai Key Lab of Intelligent Information Processing, Fudan University, China; Center for Computational System Biology, ISTBI, Fudan University, Shanghai, 200433, China; School of Computing and Mathematics, Charles Sturt University, Albury, 2640, NSW, Australia","You R., School of Computer Science and Shanghai Key Lab of Intelligent Information Processing, Fudan University, China, Center for Computational System Biology, ISTBI, Fudan University, Shanghai, 200433, China; Huang X., School of Computing and Mathematics, Charles Sturt University, Albury, 2640, NSW, Australia; Zhu S., School of Computer Science and Shanghai Key Lab of Intelligent Information Processing, Fudan University, China, Center for Computational System Biology, ISTBI, Fudan University, Shanghai, 200433, China","As of April 2018, UniProtKB has collected more than 115 million protein sequences. Less than 0.15% of these proteins, however, have been associated with experimental GO annotations. As such, the use of automatic protein function prediction (AFP) to reduce this huge gap becomes increasingly important. The previous studies conclude that sequence homology based methods are highly effective in AFP. In addition, mining motif, domain, and functional information from protein sequences has been found very helpful for AFP. Other than sequences, alternative information sources such as text, however, may be useful for AFP as well. Instead of using BOW (bag of words) representation in traditional text-based AFP, we propose a new method called DeepText2GO that relies on deep semantic text representation, together with different kinds of available protein information such as sequence homology, families, domains, and motifs, to improve large-scale AFP. Furthermore, DeepText2GO integrates text-based methods with sequence-based ones by means of a consensus approach. Extensive experiments on the benchmark dataset extracted from UniProt/SwissProt have demonstrated that DeepText2GO significantly outperformed both text-based and sequence-based methods, validating its superiority. © 2018 Elsevier Inc.","Large-scale protein function prediction; Text classification","Animals; Computational Biology; Data Mining; Eukaryota; Gene Ontology; Humans; Machine Learning; Proteins; Semantics; Sequence Analysis, Protein; protein; amino acid sequence; Article; automation; classifier; consensus; human; information processing; nonhuman; prediction; priority journal; protein database; protein domain; protein family; protein function; protein motif; scoring system; sequence homology; animal; biology; data mining; eukaryote; gene ontology; machine learning; metabolism; physiology; procedures; semantics; sequence analysis","Academic Press Inc.","10462023","","MTHDE","29883746","Article","Scopus","2-s2.0-85048880771"
"Zhang X.; Wang S.; Liu J.; Tao C.","Zhang, Xinyuan (57195287484); Wang, Shiqi (57220912172); Liu, Jie (56038258700); Tao, Cui (8245410000)","57195287484; 57220912172; 56038258700; 8245410000","Towards improving diagnosis of skin diseases by combining deep neural network and human knowledge","2018","BMC Medical Informatics and Decision Making","89","10.1186/s12911-018-0631-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050819427&doi=10.1186%2fs12911-018-0631-9&partnerID=40&md5=e5c25156389bd81dafb75160e0feab6c","School of Biomedical Informatics, University of Texas, Health Science Center at Houston, Huston, TX, United States; Department of Dermatology, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China","Zhang X., School of Biomedical Informatics, University of Texas, Health Science Center at Houston, Huston, TX, United States; Wang S., Department of Dermatology, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China; Liu J., Department of Dermatology, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China; Tao C., School of Biomedical Informatics, University of Texas, Health Science Center at Houston, Huston, TX, United States","Background: The emergence of the deep convolutional neural network (CNN) greatly improves the quality of computer-aided supporting systems. However, due to the challenges of generating reliable and timely results, clinical adoption of computer-aided diagnosis systems is still limited. Recent informatics research indicates that machine learning algorithms need to be combined with sufficient clinical expertise in order to achieve an optimal result. Methods: In this research, we used deep learning algorithms to help diagnose four common cutaneous diseases based on dermoscopic images. In order to facilitate decision-making and improve the accuracy of our algorithm, we summarized classification/diagnosis scenarios based on domain expert knowledge and semantically represented them in a hierarchical structure. Results: Our algorithm achieved an accuracy of 87.25 ± 2.24% in our test dataset with 1067 images. The semantic summarization of diagnosis scenarios can help further improve the algorithm to facilitate future computer-aided decision support. Conclusions: In this paper, we applied deep neural network algorithm to classify dermoscopic images of four common skin diseases and archived promising results. Based on the results, we further summarized the diagnosis/classification scenarios, which reflect the importance of combining the efforts of both human expertise and computer algorithms in dermatologic diagnoses. © 2018 The Author(s).","Deep learning; Dermatology; Image classification; Semantic data analytics","Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Humans; Machine Learning; Neural Networks (Computer); Quality Improvement; Skin Diseases; algorithm; artificial neural network; computer assisted diagnosis; human; machine learning; procedures; skin disease; total quality management","BioMed Central Ltd","14726947","","","30066649","Article","Scopus","2-s2.0-85050819427"
"Fan Y.; Zhang R.","Fan, Yadan (57193355396); Zhang, Rui (55613242636)","57193355396; 55613242636","Using natural language processing methods to classify use status of dietary supplements in clinical notes","2018","BMC Medical Informatics and Decision Making","13","10.1186/s12911-018-0626-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050810293&doi=10.1186%2fs12911-018-0626-6&partnerID=40&md5=2488141c25144d9122c760fce3bf32cd","Institute for Health Informatics, University of Minnesota, Minneapolis, MN, United States; Department of Pharmaceutical Care and Health Systems, College of Pharmacy, University of Minnesota, Minneapolis, MN, United States","Fan Y., Institute for Health Informatics, University of Minnesota, Minneapolis, MN, United States; Zhang R., Institute for Health Informatics, University of Minnesota, Minneapolis, MN, United States, Department of Pharmaceutical Care and Health Systems, College of Pharmacy, University of Minnesota, Minneapolis, MN, United States","Background: Despite widespread use, the safety of dietary supplements is open to doubt due to the fact that they can interact with prescribed medications, leading to dangerous clinical outcomes. Electronic health records (EHRs) provide a potential way for active pharmacovigilance on dietary supplements since a fair amount of dietary supplement information, especially those on use status, can be found in clinical notes. Extracting such information is extremely significant for subsequent supplement safety research. Methods: In this study, we collected 2500 sentences for 25 commonly used dietary supplements and annotated into four classes: Continuing (C), Discontinued (D), Started (S) and Unclassified (U). Both rule-based and machine learning-based classifiers were developed on the same training set and evaluated using the hold-out test set. The performances of the two classifiers were also compared. Results: The rule-based classifier achieved F-measure of 0.90, 0.85, 0.90, and 0.86 in C, D, S, and U status, respectively. The optimal machine learning-based classifier (Maximum Entropy) achieved F-measure of 0.90, 0.92, 0.91 and 0.88 in C, D, S, and U status, respectively. The comparison result shows that the machine learning-based classifier has a better performance, which is more efficient and scalable especially when the sample size doubles. Conclusions: Machine learning-based classifier outperforms rule-based classifier in categorization of the use status of dietary supplements in clinical notes. Future work includes applying deep learning methods and developing a hybrid system to approach use status classification task. © 2018 The Author(s).","Clinical notes; Dietary supplements; Machine learning-based classification; Natural language processing; Rule-based method; Use status","Dietary Supplements; Documentation; Electronic Health Records; Humans; Machine Learning; Natural Language Processing; article; classifier; controlled study; dietary supplement; entropy; machine learning; natural language processing; sample size; documentation; electronic health record; human","BioMed Central Ltd","14726947","","","30066648","Article","Scopus","2-s2.0-85050810293"
"Le Tuan B.; Xiao D.; Mao Y.-C.; Song L.; He D.-K.; Liu S.-J.","Le Tuan, Ba (57204355415); Xiao, Dong (57203152313); Mao, Ya-Chun (55459013500); Song, Liang (57189853896); He, Da-Kuo (7403045822); Liu, Shan-Jun (54409091600)","57204355415; 57203152313; 55459013500; 57189853896; 7403045822; 54409091600","Coal Classification Based on Visible, Near-Infrared Spectroscopy and CNN-ELM Algorithm; [可见, 近红外光谱和深度学习CNN-ELM算法的煤炭分类]","2018","Guang Pu Xue Yu Guang Pu Fen Xi/Spectroscopy and Spectral Analysis","18","10.3964/j.issn.1000-0593(2018)07-2107-06","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055271423&doi=10.3964%2fj.issn.1000-0593%282018%2907-2107-06&partnerID=40&md5=23f39a2e5829903dfdb85d82d4158823","College of Information Science and Engineering, Northeastern University, Shenyang, 110004, China; School of Resources and Civil Engineering, Northeastern University, Shenyang, 110004, China; Control Technology College, Le Quy Don Technical University, Hanoi, 100000, Viet Nam","Le Tuan B., College of Information Science and Engineering, Northeastern University, Shenyang, 110004, China, Control Technology College, Le Quy Don Technical University, Hanoi, 100000, Viet Nam; Xiao D., College of Information Science and Engineering, Northeastern University, Shenyang, 110004, China; Mao Y.-C., School of Resources and Civil Engineering, Northeastern University, Shenyang, 110004, China; Song L., School of Resources and Civil Engineering, Northeastern University, Shenyang, 110004, China; He D.-K., College of Information Science and Engineering, Northeastern University, Shenyang, 110004, China; Liu S.-J., School of Resources and Civil Engineering, Northeastern University, Shenyang, 110004, China","Coal serves as the main energy in industrial field, the quality of which has a decisive effect on industry and environment. In the using process of coal, if the category of the coal fails to be identified correctly, it will result in great harm to production efficiency, environmental pollution and economical loss. The traditional way of classifying coal mainly depends on artificial classification as well as chemical analysis, which however entails high cost and consumes too much time. Therefore, it becomes more and more important to identify the quality of coal quickly and correctly. Hence, this essay comes up with the idea of combining deep learning, ELM arithmetic and visible, infrared spectra to construct coal classification model. Firstly, we collected different coal samples from Fushun, Yimin and Henan Jiajinkou coal mining area, and used the American Spectra Vista SVC HR-1024 spectrometer for the measurement of the spectral data. Then we used the deep learning of convolutional neural network-CNN to extract spectral characteristics, and adopted ELM arithmetic to construct classification model for spectral data. Finally, in order to further improve the classification accuracy, this article made use of particle swarm optimization algorithm by using a range of newly defined inertia weight and acceleration factor values to improve the particle swarm optimization algorithm. Then, we used the improved particle swarm optimization to optimize CNN-ELM networks. Experimental results from comparison between PCA and CNN network reveal CNN network as a better feature extraction method for the spectrum. The results also show that CNN-ELM classification model has a good classification effect. The improved ELM classification model accuracy is higher than that of the basic ELM and SVM classification model. Compared with the traditional chemical methods and artificial methods, this method has the advantage of being unparalleled in economy, speed and accuracy. © 2018, Peking University Press. All right reserved.","Coal; Convolutional neural network; Extreme learning machine; Particle swarm optimization; Visible, near-infrared spectroscopy","Chemical analysis; Coal; Coal industry; Convolution; Deep learning; Infrared devices; Near infrared spectroscopy; Neural networks; Particle swarm optimization (PSO); Spectrometers; Classification accuracy; Classification models; Convolutional neural network; Environmental pollutions; Extreme learning machine; Feature extraction methods; Particle swarm optimization algorithm; Spectral characteristics; Data mining","Science Press","10000593","","GYGFE","","Article","Scopus","2-s2.0-85055271423"
"Li H.; Parikh N.A.; He L.","Li, Hailong (56767931400); Parikh, Nehal A. (7006642541); He, Lili (55389634500)","56767931400; 7006642541; 55389634500","A novel transfer learning approach to enhance deep neural network classification of brain functional connectomes","2018","Frontiers in Neuroscience","122","10.3389/fnins.2018.00491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050382628&doi=10.3389%2ffnins.2018.00491&partnerID=40&md5=812405493e81219ba6120c03c895f3d9","Perinatal Institute, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States; Department of Pediatrics, University of Cincinnati College of Medicine, Cincinnati, OH, United States","Li H., Perinatal Institute, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States; Parikh N.A., Perinatal Institute, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States, Department of Pediatrics, University of Cincinnati College of Medicine, Cincinnati, OH, United States; He L., Perinatal Institute, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States, Department of Pediatrics, University of Cincinnati College of Medicine, Cincinnati, OH, United States","Early diagnosis remains a significant challenge for many neurological disorders, especially for rare disorders where studying large cohorts is not possible. A novel solution that investigators have undertaken is combining advanced machine learning algorithms with resting-state functional Magnetic Resonance Imaging to unveil hidden pathological brain connectome patterns to uncover diagnostic and prognostic biomarkers. Recently, state-of-the-art deep learning techniques are outperforming traditional machine learning methods and are hailed as a milestone for artificial intelligence. However, whole brain classification that combines brain connectome with deep learning has been hindered by insufficient training samples. Inspired by the transfer learning strategy employed in computer vision, we exploited previously collected resting-state functional MRI data for healthy subjects from existing databases and transferred this knowledge for new disease classification tasks. We developed a deep transfer learning neural network (DTL-NN) framework for enhancing the classification of whole brain functional connectivity patterns. Briefly, we trained a stacked sparse autoencoder (SSAE) prototype to learn healthy functional connectivity patterns in an offline learning environment. Then, the SSAE prototype was transferred to a DTL-NN model for a new classification task. To test the validity of our framework, we collected resting-state functional MRI data from the Autism Brain Imaging Data Exchange (ABIDE) repository. Using autism spectrum disorder (ASD) classification as a target task, we compared the performance of our DTL-NN approach with a traditional deep neural network and support vector machine models across four ABIDE data sites that enrolled at least 60 subjects. As compared to traditional models, our DTL-NN approach achieved an improved performance in accuracy, sensitivity, specificity and area under receiver operating characteristic curve. These findings suggest that DTL-NN approaches could enhance disease classification for neurological conditions, where accumulating large neuroimaging datasets has been challenging. © 2018 Li, Parikh and He.","Autism spectrum disorder; Deep learning; Functional connectomes; Neural networks; Resting-state functional MRI; Stacked sparse autoencoder; Transfer learning","adolescent; adult; area under the curve; Article; artificial neural network; connectome; controlled study; deep transfer learning neural network; female; functional connectivity; functional magnetic resonance imaging; human; human experiment; male; measurement accuracy; normal human; receiver operating characteristic; sensitivity and specificity; stacked sparse autoencoder; support vector machine; task performance; young adult","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85050382628"
"Sun C.; Yang Y.; Wen C.; Xie K.; Wen F.","Sun, Cunwei (57203133192); Yang, Yuxin (57203134650); Wen, Chang (56811792800); Xie, Kai (8972776100); Wen, Fangqing (55888186900)","57203133192; 57203134650; 56811792800; 8972776100; 55888186900","Voiceprint identification for limited dataset using the deep migration hybrid model based on transfer learning","2018","Sensors (Switzerland)","31","10.3390/s18072399","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050624049&doi=10.3390%2fs18072399&partnerID=40&md5=efb9fb26e0b905d005f24afa87f03148","School of Computer Science, Yangtze University, Jingzhou, 434023, China; School of Electronic and Information, Yangtze University, Jingzhou, 434023, China","Sun C., School of Computer Science, Yangtze University, Jingzhou, 434023, China; Yang Y., School of Computer Science, Yangtze University, Jingzhou, 434023, China; Wen C., School of Computer Science, Yangtze University, Jingzhou, 434023, China; Xie K., School of Electronic and Information, Yangtze University, Jingzhou, 434023, China; Wen F., School of Electronic and Information, Yangtze University, Jingzhou, 434023, China","The convolutional neural network (CNN) has made great strides in the area of voiceprint recognition; but it needs a huge number of data samples to train a deep neural network. In practice, it is too difficult to get a large number of training samples, and it cannot achieve a better convergence state due to the limited dataset. In order to solve this question, a new method using a deep migration hybrid model is put forward, which makes it easier to realize voiceprint recognition for small samples. Firstly, it uses Transfer Learning to transfer the trained network from the big sample voiceprint dataset to our limited voiceprint dataset for the further training. Fully-connected layers of a pre-training model are replaced by restricted Boltzmann machine layers. Secondly, the approach of Data Augmentation is adopted to increase the number of voiceprint datasets. Finally, we introduce fast batch normalization algorithms to improve the speed of the network convergence and shorten the training time. Our new voiceprint recognition approach uses the TLCNN-RBM (convolutional neural network mixed restricted Boltzmann machine based on transfer learning) model, which is the deep migration hybrid model that is used to achieve an average accuracy of over 97%, which is higher than that when using either CNN or the TL-CNN network (convolutional neural network based on transfer learning). Thus, an effective method for a small sample of voiceprint recognition has been provided. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural network; Data augmentation; Fast batch normalization; Restricted Boltzmann machine; Small sample; Transfer learning; Voiceprint identification","Convolution; Deep neural networks; Fisher information matrix; Neural networks; Convolutional neural network; Data augmentation; Fast batch normalization; Restricted boltzmann machine; Small samples; Transfer learning; algorithm; algorithm; article; article; convolutional neural network; convolutional neural network; transfer of learning; transfer of learning; velocity; velocity; Speech recognition","MDPI AG","14248220","","","30041500","Article","Scopus","2-s2.0-85050624049"
"Yang M.; Tu W.; Qu Q.; Zhao Z.; Chen X.; Zhu J.","Yang, Min (56349712700); Tu, Wenting (56801373600); Qu, Qiang (37102566700); Zhao, Zhou (55959624600); Chen, Xiaojun (55739099100); Zhu, Jia (55355019800)","56349712700; 56801373600; 37102566700; 55959624600; 55739099100; 55355019800","Personalized response generation by Dual-learning based domain adaptation","2018","Neural Networks","33","10.1016/j.neunet.2018.03.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045705590&doi=10.1016%2fj.neunet.2018.03.009&partnerID=40&md5=62c0e7468a872e17eeb031613314833a","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; School of Information Management and Engineering, Shanghai University of Finance and Economics, Shanghai, China; School of Computing Science, Zhejiang University, Hangzhou, China; College of Computer Science and Software, Shenzhen University, Shenzhen, China; School of Computer Science, South China Normal University, Guangzhou, China","Yang M., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Tu W., School of Information Management and Engineering, Shanghai University of Finance and Economics, Shanghai, China; Qu Q., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Zhao Z., School of Computing Science, Zhejiang University, Hangzhou, China; Chen X., College of Computer Science and Software, Shenzhen University, Shenzhen, China; Zhu J., School of Computer Science, South China Normal University, Guangzhou, China","Open-domain conversation is one of the most challenging artificial intelligence problems, which involves language understanding, reasoning, and the utilization of common sense knowledge. The goal of this paper is to further improve the response generation, using personalization criteria. We propose a novel method called PRGDDA (Personalized Response Generation by Dual-learning based Domain Adaptation) which is a personalized response generation model based on theories of domain adaptation and dual learning. During the training procedure, PRGDDA first learns the human responding style from large general data (without user-specific information), and then fine-tunes the model on a small size of personalized data to generate personalized conversations with a dual learning mechanism. We conduct experiments to verify the effectiveness of the proposed model on two real-world datasets in both English and Chinese. Experimental results show that our model can generate better personalized responses for different users. © 2018 Elsevier Ltd","Deep reinforcement learning; Domain adaptation; Dual learning; Personalized response generation","Artificial Intelligence; Databases, Factual; Humans; Language; Learning; Machine Learning; Multilingualism; Reinforcement learning; Speech recognition; Commonsense knowledge; Domain adaptation; Dual learning; Language understanding; Real-world datasets; Response generation; Specific information; Training procedures; Article; artificial neural network; controlled study; machine learning; neural machine translation; nonlinear system; Personalized Response Generation by Dual learning based Domain Adaptation; prediction; priority journal; probability; process optimization; quantitative analysis; scoring system; artificial intelligence; factual database; human; language; learning; multilingualism; trends; utilization; Deep learning","Elsevier Ltd","08936080","","NNETE","29665538","Article","Scopus","2-s2.0-85045705590"
"Lin E.; Kuo P.-H.; Liu Y.-L.; Yu Y.W.-Y.; Yang A.C.; Tsai S.-J.","Lin, Eugene (35727759300); Kuo, Po-Hsiu (14031704600); Liu, Yu-Li (57138598700); Yu, Younger W.-Y. (7406248540); Yang, Albert C. (7203072314); Tsai, Shih-Jen (7403478452)","35727759300; 14031704600; 57138598700; 7406248540; 7203072314; 7403478452","A deep learning approach for predicting antidepressant response in major depression using clinical and genetic biomarkers","2018","Frontiers in Psychiatry","116","10.3389/fpsyt.2018.00290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049845461&doi=10.3389%2ffpsyt.2018.00290&partnerID=40&md5=a7373d96df04ebfc6ad1cc948160e965","Department of Electrical Engineering, University of Washington, Seattle, WA, United States; Graduate Institute of Biomedical Sciences, China Medical University, Taichung, Taiwan; Department of Public Health, Institute of Epidemiology and Preventive Medicine, National Taiwan University, Taipei, Taiwan; Center for Neuropsychiatric Research, National Health Research Institutes, Miaoli County, Taiwan; Yu's Psychiatric Clinic, Kaohsiung, Taiwan; Department of Psychiatry, Taipei Veterans General Hospital, Taipei, Taiwan; Division of Psychiatry, National Yang-Ming University, Taipei, Taiwan; Division of Interdisciplinary Medicine and Biotechnology, Beth Israel Deaconess Medical Center/Harvard Medical School, Boston, MA, United States; Institute of Brain Science, National Yang-Ming University, Taipei, Taiwan","Lin E., Department of Electrical Engineering, University of Washington, Seattle, WA, United States, Graduate Institute of Biomedical Sciences, China Medical University, Taichung, Taiwan; Kuo P.-H., Department of Public Health, Institute of Epidemiology and Preventive Medicine, National Taiwan University, Taipei, Taiwan; Liu Y.-L., Center for Neuropsychiatric Research, National Health Research Institutes, Miaoli County, Taiwan; Yu Y.W.-Y., Yu's Psychiatric Clinic, Kaohsiung, Taiwan; Yang A.C., Department of Psychiatry, Taipei Veterans General Hospital, Taipei, Taiwan, Division of Psychiatry, National Yang-Ming University, Taipei, Taiwan, Division of Interdisciplinary Medicine and Biotechnology, Beth Israel Deaconess Medical Center/Harvard Medical School, Boston, MA, United States, Institute of Brain Science, National Yang-Ming University, Taipei, Taiwan; Tsai S.-J., Department of Psychiatry, Taipei Veterans General Hospital, Taipei, Taiwan, Division of Psychiatry, National Yang-Ming University, Taipei, Taiwan, Institute of Brain Science, National Yang-Ming University, Taipei, Taiwan","In the wake of recent advances in scientific research, personalized medicine using deep learning techniques represents a new paradigm. In this work, our goal was to establish deep learning models which distinguish responders from non-responders, and also to predict possible antidepressant treatment outcomes in major depressive disorder (MDD). To uncover relationships between the responsiveness of antidepressant treatment and biomarkers, we developed a deep learning prediction approach resulting from the analysis of genetic and clinical factors such as single nucleotide polymorphisms (SNPs), age, sex, baseline Hamilton Rating Scale for Depression score, depressive episodes, marital status, and suicide attempt status of MDD patients. The cohort consisted of 455 patients who were treated with selective serotonin reuptake inhibitors (treatment-response rate = 61.0%; remission rate = 33.0%). By using the SNP dataset that was original to a genome-wide association study, we selected 10 SNPs (including ABCA13 rs4917029, BNIP3 rs9419139, CACNA1E rs704329, EXOC4 rs6978272, GRIN2B rs7954376, LHFPL3 rs4352778, NELL1 rs2139423, NUAK1 rs2956406, PREX1 rs4810894, and SLIT3 rs139863958) which were associated with antidepressant treatment response. Furthermore, we pinpointed 10 SNPs (including ARNTL rs11022778, CAMK1D rs2724812, GABRB3 rs12904459, GRM8 rs35864549, NAALADL2 rs9878985, NCALD rs483986, PLA2G4A rs12046378, PROK2 rs73103153, RBFOX1 rs17134927, and ZNF536 rs77554113) in relation to remission. Then, we employed multilayer feedforward neural networks (MFNNs) containing 1-3 hidden layers and compared MFNN models with logistic regression models. Our analysis results revealed that the MFNN model with 2 hidden layers (area under the receiver operating characteristic curve (AUC) = 0.8228 ± 0.0571; sensitivity = 0.7546 ± 0.0619; specificity = 0.6922 ± 0.0765) performed maximally among predictive models to infer the complex relationship between antidepressant treatment response and biomarkers. In addition, the MFNN model with 3 hidden layers (AUC = 0.8060 ± 0.0722; sensitivity = 0.7732 ± 0.0583; specificity = 0.6623 ± 0.0853) achieved best among predictive models to predict remission. Our study indicates that the deep MFNN framework may provide a suitable method to establish a tool for distinguishing treatment responders from non-responders prior to antidepressant therapy. © 2018 Lin, Kuo, Liu, Yu, Yang and Tsai.","Antidepressant; Deep learning; Genome-wide association studies; Major depressive disorder; Multilayer feedforward neural networks; Personalized medicine; Single nucleotide polymorphisms","biological marker; citalopram; escitalopram; fluoxetine; paroxetine; ABCA13 gene; adult; age; ARNTL gene; Article; BNIP3 gene; CACNA1E gene; CAMK1D gene; cohort analysis; EXOC4 gene; female; GABRB3 gene; gene; gene locus; genetic susceptibility; genome-wide association study; GRIN2B gene; GRM8 gene; Hamilton Depression Rating Scale; human; LHFPL3 gene; machine learning; major clinical study; major depression; male; molecular genetics; NAALADL2 gene; NCALD gene; NELL1 gene; NUAK1 gene; PLA2G4A gene; PREX1 gene; PROK2 gene; RBFOX1 gene; remission; sex difference; single nucleotide polymorphism; SLIT3 gene; social status; suicide attempt; treatment response; ZNF536 gene","Frontiers Media S.A.","16640640","","","","Article","Scopus","2-s2.0-85049845461"
"Ghesu F.C.; Georgescu B.; Grbic S.; Maier A.; Hornegger J.; Comaniciu D.","Ghesu, Florin C. (56185916200); Georgescu, Bogdan (6603044053); Grbic, Sasa (36608106400); Maier, Andreas (23392966100); Hornegger, Joachim (6603448080); Comaniciu, Dorin (7003476440)","56185916200; 6603044053; 36608106400; 23392966100; 6603448080; 7003476440","Towards intelligent robust detection of anatomical structures in incomplete volumetric data","2018","Medical Image Analysis","33","10.1016/j.media.2018.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049348377&doi=10.1016%2fj.media.2018.06.007&partnerID=40&md5=9e2adcf8cb5f509e122ad9b17f97df7b","Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States; Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany","Ghesu F.C., Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States, Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany; Georgescu B., Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States; Grbic S., Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States; Maier A., Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany; Hornegger J., Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany; Comaniciu D., Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States","Robust and fast detection of anatomical structures represents an important component of medical image analysis technologies. Current solutions for anatomy detection are based on machine learning, and are generally driven by suboptimal and exhaustive search strategies. In particular, these techniques do not effectively address cases of incomplete data, i.e., scans acquired with a partial field-of-view. We address these challenges by following a new paradigm, which reformulates the detection task to teaching an intelligent artificial agent how to actively search for an anatomical structure. Using the principles of deep reinforcement learning with multi-scale image analysis, artificial agents are taught optimal navigation paths in the scale-space representation of an image, while accounting for structures that are missing from the field-of-view. The spatial coherence of the observed anatomical landmarks is ensured using elements from statistical shape modeling and robust estimation theory. Experiments show that our solution outperforms marginal space deep learning, a powerful deep learning method, at detecting different anatomical structures without any failure. The dataset contains 5043 3D-CT volumes from over 2000 patients, totaling over 2,500,000 image slices. In particular, our solution achieves 0% false-positive and 0% false-negative rates at detecting whether the landmarks are captured in the field-of-view of the scan (excluding all border cases), with an average detection accuracy of 2.78 mm. In terms of runtime, we reduce the detection-time of the marginal space deep learning method by 20–30 times to under 40 ms, an unmatched performance for high resolution incomplete 3D-CT data. © 2018 Elsevier B.V.","Deep learning; Deep reinforcement learning; Incomplete 3D-data; M-estimator sample consensus; Multi-scale detection; Real-time detection; Robust statistical shape-modeling; Scale-space modeling","Algorithms; Anatomic Landmarks; Deep Learning; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Tomography, X-Ray Computed; Computerized tomography; Image analysis; Medical imaging; Reinforcement learning; Volumetric analysis; 3D data; Multi-scale; Real-time detection; Sample consensus; Scale space models; Statistical shape model; anatomic landmark; anatomical concepts; aortic arch; aortic root; Article; basilar artery; carotid artery; causality; celiac artery; consensus; controlled study; false negative result; human; image analysis; learning environment; left lung; machine learning; priority journal; random forest; reinforcement; right lung; skull base; task performance; vertebral artery; volumetry; whole body CT; algorithm; image processing; procedures; three dimensional imaging; x-ray computed tomography; Deep learning","Elsevier B.V.","13618415","","MIAEC","29966940","Article","Scopus","2-s2.0-85049348377"
"Li Y.; Zhou X.; Liu Z.; Zhang L.","Li, Yibo (57195974056); Zhou, Xin (57281626900); Liu, Zhenming (7406676695); Zhang, Liangren (8833065300)","57195974056; 57281626900; 7406676695; 8833065300","Designing natural product-like virtual libraries using deep molecule generative models","2018","Journal of Chinese Pharmaceutical Sciences","6","10.5246/jcps.2018.07.046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052201283&doi=10.5246%2fjcps.2018.07.046&partnerID=40&md5=de1dd1d17b22987b28fd10e7f5703ec4","State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University Health Science Center, Beijing, 100191, China","Li Y., State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University Health Science Center, Beijing, 100191, China; Zhou X., State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University Health Science Center, Beijing, 100191, China; Liu Z., State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University Health Science Center, Beijing, 100191, China; Zhang L., State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University Health Science Center, Beijing, 100191, China","Natural products (NPs) have long been recognized as a valuable resource for drug discovery, and bringing NP-related features to virtual libraries is believed to be an effective way to increase the coverage of druggable chemical space. Here, deep learning-based molecule generative model, which is a recent technique in de novo molecule design, was applied to generate virtual libraries with NP-like properties. Results demonstrated that the model was effective in generating molecules that highly resemble NPs. Moreover, the model was also found to be capable of generating NP-like molecules that were also easy to synthesize, significantly increasing the practical value of the compound library. © 2018 Journal of Chinese Pharmaceutical Sciences, School of Pharmaceutical Sciences, Peking University.","Deep learning; Generative model; Natural product; Virtual library design","natural product; Article; chemical structure; deep molecule generative model; drug design; drug synthesis; machine learning; molecular library; molecular model; virtual library","Journal of Chinese Pharmaceutical Science","10031057","","","","Article","Scopus","2-s2.0-85052201283"
"Zhou H.; Ning S.; Yang Y.; Liu Z.; Lang C.; Lin Y.","Zhou, Huiwei (23394392300); Ning, Shixian (57196318339); Yang, Yunlong (57189440155); Liu, Zhuang (57194707710); Lang, Chengkun (57202111339); Lin, Yingyu (57196321900)","23394392300; 57196318339; 57189440155; 57194707710; 57202111339; 57196321900","Chemical-induced disease relation extraction with dependency information and prior knowledge","2018","Journal of Biomedical Informatics","16","10.1016/j.jbi.2018.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049968503&doi=10.1016%2fj.jbi.2018.07.007&partnerID=40&md5=c82aa18b283887d275dfa1b8bfb43e7c","School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, Liaoning, China","Zhou H., School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, Liaoning, China; Ning S., School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, Liaoning, China; Yang Y., School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, Liaoning, China; Liu Z., School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, Liaoning, China; Lang C., School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, Liaoning, China; Lin Y., School of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, Liaoning, China","Chemical-disease relation (CDR) extraction is significantly important to various areas of biomedical research and health care. Nowadays, many large-scale biomedical knowledge bases (KBs) containing triples about entity pairs and their relations have been built. KBs are important resources for biomedical relation extraction. However, previous research pays little attention to prior knowledge. In addition, the dependency tree contains important syntactic and semantic information, which helps to improve relation extraction. So how to effectively use it is also worth studying. In this paper, we propose a novel convolutional attention network (CAN) for CDR extraction. Firstly, we extract the shortest dependency path (SDP) between chemical and disease pairs in a sentence, which includes a sequence of words, dependency directions, and dependency relation tags. Then the convolution operations are performed on the SDP to produce deep semantic dependency features. After that, an attention mechanism is employed to learn the importance/weight of each semantic dependency vector related to knowledge representations learned from KBs. Finally, in order to combine dependency information and prior knowledge, the concatenation of weighted semantic dependency representations and knowledge representations is fed to the softmax layer for classification. Experiments on the BioCreative V CDR dataset show that our method achieves comparable performance with the state-of-the-art systems, and both dependency information and prior knowledge play important roles in CDR extraction task. © 2018","Attention mechanism; CDR extraction; Dependency information; Prior knowledge","Algorithms; Biomedical Research; Chemically-Induced Disorders; Computational Biology; Databases, Factual; False Positive Reactions; Humans; Knowledge Bases; Language; Machine Learning; Models, Statistical; Natural Language Processing; Neural Networks (Computer); Precision Medicine; Research Design; Semantics; Classification (of information); Clock and data recovery circuits (CDR circuits); Convolution; Extraction; Knowledge representation; Semantics; Attention mechanisms; Biomedical research; Dependency informations; Knowledge basis (KBs); Prior knowledge; Semantic dependency; Semantic information; State-of-the-art system; analytic method; Article; chemically induced disorder; classification; convolutional attention network; dependency information; disease association; information; intermethod comparison; knowledge base; priority journal; shortest dependency path; algorithm; artificial neural network; biology; factual database; false positive result; human; language; machine learning; medical research; methodology; natural language processing; personalized medicine; procedures; semantics; statistical model; Data reduction","Academic Press Inc.","15320464","","JBIOB","30017973","Article","Scopus","2-s2.0-85049968503"
"Mall S.; Brennan P.C.; Mello-Thoms C.","Mall, Suneeta (56694126500); Brennan, Patrick C. (7402306108); Mello-Thoms, Claudia (6701661177)","56694126500; 7402306108; 6701661177","Modeling visual search behavior of breast radiologists using a deep convolution neural network","2018","Journal of Medical Imaging","15","10.1117/1.JMI.5.3.035502","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051801598&doi=10.1117%2f1.JMI.5.3.035502&partnerID=40&md5=f92ff37e97d1a0491e92ccfcd80ab7c3","University of Sydney, Faculty of Health Sciences, Medical Image Optimisation and Perception Research Group (MIOPeG), Lidcombe, NSW, Australia","Mall S., University of Sydney, Faculty of Health Sciences, Medical Image Optimisation and Perception Research Group (MIOPeG), Lidcombe, NSW, Australia; Brennan P.C., University of Sydney, Faculty of Health Sciences, Medical Image Optimisation and Perception Research Group (MIOPeG), Lidcombe, NSW, Australia; Mello-Thoms C., University of Sydney, Faculty of Health Sciences, Medical Image Optimisation and Perception Research Group (MIOPeG), Lidcombe, NSW, Australia","Visual search, the process of detecting and identifying objects using eye movements (saccades) and foveal vision, has been studied for identification of root causes of errors in the interpretation of mammograms. The aim of this study is to model visual search behavior of radiologists and their interpretation of mammograms using deep machine learning approaches. Our model is based on a deep convolutional neural network, a biologically inspired multilayer perceptron that simulates the visual cortex and is reinforced with transfer learning techniques. Eye-tracking data were obtained from eight radiologists (of varying experience levels in reading mammograms) reviewing 120 two-view digital mammography cases (59 cancers), and it has been used to train the model, which was pretrained with the ImageNet dataset for transfer learning. Areas of the mammogram that received direct (foveally fixated), indirect (peripherally fixated), or no (never fixated) visual attention were extracted from radiologists' visual search maps (obtained by a head mounted eye-tracking device). These areas along with the radiologists' assessment (including confidence in the assessment) of the presence of suspected malignancy were used to model: (1) radiologists' decision, (2) radiologists' confidence in such decisions, and (3) the attentional level (i.e., foveal, peripheral, or none) in an area of the mammogram. Our results indicate high accuracy and low misclassification in modeling such behaviors. © 2018 Society of Photo-Optical Instrumentation Engineers (SPIE).","behavior modeling; breast cancer; deep learning; eye tracking; machine learning; mammography; visual search","Behavioral research; Convolution; Deep learning; Diseases; Eye movements; Eye tracking; Learning systems; Mammography; Neural networks; Object detection; X ray screens; Behavior model; Biologically inspired; Breast Cancer; Convolution neural network; Deep convolutional neural networks; Head-mounted eye tracking; Machine learning approaches; Visual search; Article; artificial neural network; attention; deep convolution neural network; digital mammography; eye position; eye tracking; head position; human; machine learning; perceptron; radiologist; transfer of learning; visual attention; visual cortex; visual information; Deep neural networks","SPIE","23294302","","","","Article","Scopus","2-s2.0-85051801598"
"Burdick J.; Marques O.; Weinthal J.; Furht B.","Burdick, Jack (57194161479); Marques, Oge (7003301322); Weinthal, Janet (57196076732); Furht, Borko (7004960599)","57194161479; 7003301322; 57196076732; 7004960599","Rethinking Skin Lesion Segmentation in a Convolutional Classifier","2018","Journal of Digital Imaging","50","10.1007/s10278-017-0026-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031745245&doi=10.1007%2fs10278-017-0026-y&partnerID=40&md5=730309f20f68889563c32692481eb057","Florida Atlantic University, Boca Raton, FL, United States","Burdick J., Florida Atlantic University, Boca Raton, FL, United States; Marques O., Florida Atlantic University, Boca Raton, FL, United States; Weinthal J., Florida Atlantic University, Boca Raton, FL, United States; Furht B., Florida Atlantic University, Boca Raton, FL, United States","Melanoma is a fatal form of skin cancer when left undiagnosed. Computer-aided diagnosis systems powered by convolutional neural networks (CNNs) can improve diagnostic accuracy and save lives. CNNs have been successfully used in both skin lesion segmentation and classification. For reasons heretofore unclear, previous works have found image segmentation to be, conflictingly, both detrimental and beneficial to skin lesion classification. We investigate the effect of expanding the segmentation border to include pixels surrounding the target lesion. Ostensibly, segmenting a target skin lesion will remove inessential information, non-lesion skin, and artifacts to aid in classification. Our results indicate that segmentation border enlargement produces, to a certain degree, better results across all metrics of interest when using a convolutional based classifier built using the transfer learning paradigm. Consequently, preprocessing methods which produce borders larger than the actual lesion can potentially improve classifier performance, more than both perfect segmentation, using dermatologist created ground truth masks, and no segmentation altogether. © 2017, Society for Imaging Informatics in Medicine.","Convolutional neural networks; Deep learning; Machine learning; Medical decision support systems; Medical image analysis; Skin lesions","Adult; Aged; Artifacts; Diagnosis, Computer-Assisted; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Male; Melanoma; Middle Aged; Neural Networks (Computer); Sensitivity and Specificity; Skin Neoplasms; Classification (of information); Computer aided diagnosis; Convolution; Decision support systems; Deep learning; Dermatology; Learning systems; Medical imaging; Neural networks; Classifier performance; Computer aided diagnosis systems; Convolutional neural network; Diagnostic accuracy; Medical decision support system; Pre-processing method; Skin lesion; Transfer learning; adult; aged; artifact; artificial neural network; classification; computer assisted diagnosis; diagnostic imaging; female; human; image processing; machine learning; male; melanoma; middle aged; pathology; procedures; sensitivity and specificity; skin tumor; Image segmentation","Springer New York LLC","08971889","","JDIME","29047032","Article","Scopus","2-s2.0-85031745245"
"da Silva G.L.F.; Valente T.L.A.; Silva A.C.; de Paiva A.C.; Gattass M.","da Silva, Giovanni Lucca França (57191839671); Valente, Thales Levi Azevedo (57192929996); Silva, Aristófanes Corrêa (24722153600); de Paiva, Anselmo Cardoso (57218417046); Gattass, Marcelo (6701768753)","57191839671; 57192929996; 24722153600; 57218417046; 6701768753","Convolutional neural network-based PSO for lung nodule false positive reduction on CT images","2018","Computer Methods and Programs in Biomedicine","133","10.1016/j.cmpb.2018.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047130856&doi=10.1016%2fj.cmpb.2018.05.006&partnerID=40&md5=32914ec23b77c2ee04f75f8be9a6463b","Federal University of Maranhão - UFMA, Applied Computing Group - NCA Av. dos Portugueses, SN, Bacanga, São Luís, 65085-580, MA, Brazil; Pontifical Catholic University of Rio de Janeiro - PUC - Rio R. São Vicente, 225, Gávea, Rio de Janeiro, 22453-900, RJ, Brazil","da Silva G.L.F., Federal University of Maranhão - UFMA, Applied Computing Group - NCA Av. dos Portugueses, SN, Bacanga, São Luís, 65085-580, MA, Brazil; Valente T.L.A., Pontifical Catholic University of Rio de Janeiro - PUC - Rio R. São Vicente, 225, Gávea, Rio de Janeiro, 22453-900, RJ, Brazil; Silva A.C., Federal University of Maranhão - UFMA, Applied Computing Group - NCA Av. dos Portugueses, SN, Bacanga, São Luís, 65085-580, MA, Brazil; de Paiva A.C., Federal University of Maranhão - UFMA, Applied Computing Group - NCA Av. dos Portugueses, SN, Bacanga, São Luís, 65085-580, MA, Brazil; Gattass M., Pontifical Catholic University of Rio de Janeiro - PUC - Rio R. São Vicente, 225, Gávea, Rio de Janeiro, 22453-900, RJ, Brazil","Background and objective: Detection of lung nodules is critical in CAD systems; this is because of their similar contrast with other structures and low density, which result in the generation of numerous false positives (FPs). Therefore, this study proposes a methodology to reduce the FP number using a deep learning technique in conjunction with an evolutionary technique. Method: The particle swarm optimization (PSO) algorithm was used to optimize the network hyperparameters in the convolutional neural network (CNN) in order to enhance the network performance and eliminate the requirement of manual search. Results: The methodology was tested on computed tomography (CT) scans from the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) with the highest accuracy of 97.62%, sensitivity of 92.20%, specificity of 98.64%, and area under the receiver operating characteristic (ROC) curve of 0.955. Conclusion: The results demonstrate the high performance-potential of the PSO algorithm in the identification of optimal CNN hyperparameters for lung nodule candidate classification into nodules and non-nodules, increasing the sensitivity rates in the FP reduction step of CAD systems. © 2018 Elsevier B.V.","Convolutional neural network; Deep learning; False positive reduction; Lung nodules; Medical images; Particle swarm optimization","Algorithms; Area Under Curve; Databases, Factual; False Positive Reactions; Humans; Image Processing, Computer-Assisted; Lung; Nerve Net; Radiographic Image Interpretation, Computer-Assisted; Reproducibility of Results; ROC Curve; Sensitivity and Specificity; Solitary Pulmonary Nodule; Tomography, X-Ray Computed; Biological organs; Convolution; Deep learning; Medical imaging; Neural networks; Particle swarm optimization (PSO); Computed tomography scan; Convolutional neural network; Convolutional Neural Networks (CNN); Detection of lung nodules; False-positive reduction; Lung nodule; Particle swarm optimization algorithm; Receiver Operating Characteristic (ROC) curves; algorithm; Article; artificial neural network; computer assisted tomography; convolutional neural network; data base; diagnostic accuracy; diagnostic test accuracy study; false positive result; human; image processing; lung nodule; machine learning; particle swarm optimization; sensitivity and specificity; tumor classification; algorithm; area under the curve; computer assisted diagnosis; diagnostic imaging; factual database; false positive result; lung; lung nodule; nerve cell network; receiver operating characteristic; reproducibility; x-ray computed tomography; Computerized tomography","Elsevier Ireland Ltd","01692607","","CMPBE","29903476","Article","Scopus","2-s2.0-85047130856"
"Zeng H.; Wang S.; Zhou T.; Zhao F.; Li X.; Wu Q.; Xu J.","Zeng, Hong (52164967700); Wang, Sheng (58428221300); Zhou, Tianming (57209849017); Zhao, Feifeng (57203185299); Li, Xiufeng (57221401232); Wu, Qing (57199303484); Xu, Jinbo (57203521425)","52164967700; 58428221300; 57209849017; 57203185299; 57221401232; 57199303484; 57203521425","ComplexContact: A web server for inter-protein contact prediction using deep learning","2018","Nucleic Acids Research","89","10.1093/nar/gky420","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050858312&doi=10.1093%2fnar%2fgky420&partnerID=40&md5=bb53f03cda70df5a317dafdd2e0793ac","School of Computer Science and Technology, Hangzhou Dianzi University, China; King Abdullah University of Science and Technology (KAUST), Saudi Arabia; Toyota Technological Institute at Chicago, United States; Institute for Interdisciplinary Information Sciences, Tsinghua University, China","Zeng H., School of Computer Science and Technology, Hangzhou Dianzi University, China; Wang S., King Abdullah University of Science and Technology (KAUST), Saudi Arabia, Toyota Technological Institute at Chicago, United States; Zhou T., Toyota Technological Institute at Chicago, United States, Institute for Interdisciplinary Information Sciences, Tsinghua University, China; Zhao F., School of Computer Science and Technology, Hangzhou Dianzi University, China; Li X., School of Computer Science and Technology, Hangzhou Dianzi University, China; Wu Q., School of Computer Science and Technology, Hangzhou Dianzi University, China; Xu J., Toyota Technological Institute at Chicago, United States","ComplexContact (http://raptorx2.uchicago.edu/ComplexContact/) is a web server for sequence-based interfacial residue-residue contact prediction of a putative protein complex. Interfacial residue-residue contacts are critical for understanding how proteins form complex and interact at residue level. When receiving a pair of protein sequences, ComplexContact first searches for their sequence homologs and builds two paired multiple sequence alignments (MSA), then it applies co-evolution analysis and a CASP-winning deep learning (DL) method to predict interfacial contacts from paired MSAs and visualizes the prediction as an image. The DL method was originally developed for intra-protein contact prediction and performed the best in CASP12. Our large-scale experimental test further shows that ComplexContact greatly outperforms pure co-evolution methods for inter-protein contact prediction, regardless of the species. © The Author(s) 2018. Published by Oxford University Press on behalf of Nucleic Acids Research.","","Amino Acid Sequence; Computational Biology; Databases, Factual; Deep Learning; Escherichia coli; Humans; Internet; Protein Interaction Domains and Motifs; Protein Structure, Secondary; Proteins; Sequence Alignment; Sequence Homology, Amino Acid; Software; Structural Homology, Protein; protein; amino acid sequence; Article; client server application; deep learning; information retrieval; intermethod comparison; machine learning; prediction; priority journal; protein protein interaction; sequence alignment; sequence homology; biology; chemistry; Escherichia coli; factual database; genetics; human; Internet; procedures; protein domain; protein secondary structure; software; statistics and numerical data; structural homology","Oxford University Press","03051048","","NARHA","29790960","Article","Scopus","2-s2.0-85050858312"
"Mamoshina P.; Volosnikova M.; Ozerov I.V.; Putin E.; Skibina E.; Cortese F.; Zhavoronkov A.","Mamoshina, Polina (56893719500); Volosnikova, Marina (57199275802); Ozerov, Ivan V. (36462835900); Putin, Evgeny (57189310406); Skibina, Ekaterina (57203015217); Cortese, Franco (56295145600); Zhavoronkov, Alex (39862415800)","56893719500; 57199275802; 36462835900; 57189310406; 57203015217; 56295145600; 39862415800","Machine learning on human muscle transcriptomic data for biomarker discovery and tissue-specific drug target identification","2018","Frontiers in Genetics","125","10.3389/fgene.2018.00242","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050319594&doi=10.3389%2ffgene.2018.00242&partnerID=40&md5=5130ecadd4c32a53d3e3e246a10f113d","Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States; Department of Computer Science, University of Oxford, Oxford, United Kingdom; Computer Technologies Lab, Saint Petersburg State University of Information Technologies, Mechanics and Optics, Saint Petersburg, Russian Federation; Biogerontology Research Foundation, London, United Kingdom; Buck Institute for Research on Aging, Novato, CA, United States","Mamoshina P., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States, Department of Computer Science, University of Oxford, Oxford, United Kingdom; Volosnikova M., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States; Ozerov I.V., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States; Putin E., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States, Computer Technologies Lab, Saint Petersburg State University of Information Technologies, Mechanics and Optics, Saint Petersburg, Russian Federation; Skibina E., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States; Cortese F., Biogerontology Research Foundation, London, United Kingdom; Zhavoronkov A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Baltimore, MD, United States, Biogerontology Research Foundation, London, United Kingdom, Buck Institute for Research on Aging, Novato, CA, United States","For the past several decades, research in understanding the molecular basis of human muscle aging has progressed significantly. However, the development of accessible tissue-specific biomarkers of human muscle aging that may be measured to evaluate the effectiveness of therapeutic interventions is still a major challenge. Here we present a method for tracking age-related changes of human skeletal muscle. We analyzed publicly available gene expression profiles of young and old tissue from healthy donors. Differential gene expression and pathway analysis were performed to compare signatures of young and old muscle tissue and to preprocess the resulting data for a set of machine learning algorithms. Our study confirms the established mechanisms of human skeletal muscle aging, including dysregulation of cytosolic Ca2+ homeostasis, PPAR signaling and neurotransmitter recycling along with IGFR and PI3K-Akt-mTOR signaling. Applying several supervised machine learning techniques, including neural networks, we built a panel of tissue-specific biomarkers of aging. Our predictive model achieved 0.91 Pearson correlation with respect to the actual age values of the muscle tissue samples, and a mean absolute error of 6.19 years on the test set. The performance of models was also evaluated on gene expression samples of the skeletal muscles from the Gene expression Genotype-Tissue Expression (GTEx) project. The best model achieved the accuracy of 0.80 with respect to the actual age bin prediction on the external validation set. Furthermore, we demonstrated that aging biomarkers can be used to identify new molecular targets for tissue-specific anti-aging therapies. © 2018 Mamoshina, Volosnikova, Ozerov, Putin, Skibina, Cortese and Zhavoronkov.","Aging; Biomarkers of aging; Deep learning; Machine learning; Pathway analysis; Target identification","biological marker; calcineurin; phosphatase; transcriptome; aging; apoptosis; Article; calcium homeostasis; cell proliferation; female; gene expression; human; immune response; inflammation; machine learning; male; muscle tissue; myofibrosis; sarcomere; signal transduction","Frontiers Media S.A.","16648021","","","","Article","Scopus","2-s2.0-85050319594"
"Longo L.","Longo, Luca (24314788200)","24314788200","Experienced mental workload, perception of usability, their interaction and impact on task performance","2018","PLoS ONE","66","10.1371/journal.pone.0199661","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050997831&doi=10.1371%2fjournal.pone.0199661&partnerID=40&md5=eedf13c2b650be9337f85898946ede9c","School of Computing, College of health and sciences, Dublin Institute of Technology, Dublin, Ireland; ADAPT, global centre of excellence for digital content and media innovation, Dublin, Ireland","Longo L., School of Computing, College of health and sciences, Dublin Institute of Technology, Dublin, Ireland, ADAPT, global centre of excellence for digital content and media innovation, Dublin, Ireland","Past research in HCI has generated a number of procedures for assessing the usability of interacting systems. In these procedures there is a tendency to omit characteristics of the users, aspects of the context and peculiarities of the tasks. Building a cohesive model that incorporates these features is not obvious. A construct greatly invoked in Human Factors is human Mental Workload. Its assessment is fundamental for predicting human performance. Despite the several uses of Usability and Mental Workload, not much has been done to explore their relationship. This empirical research focused on I) the investigation of such a relationship and II) the investigation of the impact of the two constructs on human performance. A user study was carried out with participants executing a set of information-seeking tasks over three popular web-sites. A deep correlation analysis of usability and mental workload, by task, by user and by classes of objective task performance was done (I). A number of Supervised Machine Learning techniques based upon different learning strategy were employed for building models aimed at predicting classes of task performance (II). Findings strongly suggests that usability and mental workload are two non overlapping constructs and they can be jointly employed to greatly improve the prediction of human performance. © 2018 Luca Longo. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Humans; Machine Learning; Perception; Task Performance and Analysis; User-Computer Interface; Workload; adult; article; correlation analysis; empirical research; female; human; human experiment; information seeking; male; perception; prediction; supervised machine learning; task performance; workload; computer interface; machine learning; perception; psychology; workload","Public Library of Science","19326203","","POLNC","30067747","Article","Scopus","2-s2.0-85050997831"
"Pla A.; Zhong X.; Rayner S.","Pla, Albert (24832476000); Zhong, Xiangfu (57203219405); Rayner, Simon (16550833000)","24832476000; 57203219405; 16550833000","miRAW: A deep learning-based approach to predict microRNA targets by analyzing whole microRNA transcripts","2018","PLoS Computational Biology","61","10.1371/journal.pcbi.1006185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050967361&doi=10.1371%2fjournal.pcbi.1006185&partnerID=40&md5=fd7efad5e27ad880569dabae7b2ea9b6","Department of Medical Genetics, University of Oslo, Oslo, Norway; Department of Medical Genetics, Oslo University Hospital, Oslo, Norway","Pla A., Department of Medical Genetics, University of Oslo, Oslo, Norway; Zhong X., Department of Medical Genetics, University of Oslo, Oslo, Norway, Department of Medical Genetics, Oslo University Hospital, Oslo, Norway; Rayner S., Department of Medical Genetics, University of Oslo, Oslo, Norway, Department of Medical Genetics, Oslo University Hospital, Oslo, Norway","MicroRNAs (miRNAs) are small non-coding RNAs that regulate gene expression by binding to partially complementary regions within the 3’UTR of their target genes. Computational methods play an important role in target prediction and assume that the miRNA “seed region” (nt 2 to 8) is required for functional targeting, but typically only identify ∼80% of known bindings. Recent studies have highlighted a role for the entire miRNA, suggesting that a more flexible methodology is needed. We present a novel approach for miRNA target prediction based on Deep Learning (DL) which, rather than incorporating any knowledge (such as seed regions), investigates the entire miRNA and 3’TR mRNA nucleotides to learn a uninhibited set of feature descriptors related to the targeting process. We collected more than 150,000 experimentally validated homo sapiens miRNA:gene targets and cross referenced them with different CLIP-Seq, CLASH and iPAR-CLIP datasets to obtain ∼20,000 validated miRNA:gene exact target sites. Using this data, we implemented and trained a deep neural network—composed of autoencoders and a feed-forward network—able to automatically learn features describing miRNA-mRNA interactions and assess functionality. Predictions were then refined using information such as site location or site accessibility energy. In a comparison using independent datasets, our DL approach consistently outperformed existing prediction methods, recognizing the seed region as a common feature in the targeting process, but also identifying the role of pairings outside this region. Thermodynamic analysis also suggests that site accessibility plays a role in targeting but that it cannot be used as a sole indicator for functionality. Data and source code available at: https://bitbucket.org/account/user/bipous/projects/MIRAW. © 2018 Pla et al. http://creativecommons.org/licenses/by/4.0/.","","3' Untranslated Regions; Binding Sites; Computer Simulation; Datasets as Topic; Deep Learning; Gene Expression Regulation; Gene Targeting; Humans; MicroRNAs; Neural Networks (Computer); Reproducibility of Results; RNA, Messenger; Thermodynamics; Deep neural networks; Feedforward neural networks; Forecasting; Gene expression; RNA; messenger RNA; microRNA; messenger RNA; microRNA; Feature descriptors; Genes expression; Homo sapiens; Learn+; Learning-based approach; Prediction-based; Sets of features; Target genes; Target prediction; Target sites; 3' untranslated region; Article; controlled study; deep learning; gene expression; gene targeting; human; human genome; machine learning; miRAW; prediction; RNA binding; RNA transcription; software; thermodynamics; artificial neural network; binding site; computer simulation; gene expression regulation; genetics; information processing; metabolism; reproducibility; Thermoanalysis","Public Library of Science","1553734X","","","30005074","Article","Scopus","2-s2.0-85050967361"
"Magnusson E.B.; Mueller J.P.B.; Juhl M.; Mendoza C.; Leosson K.","Magnusson, Einar B. (55119067600); Mueller, J. P. Balthasar (56457396300); Juhl, Michael (57196480507); Mendoza, Carlos (55599405700); Leosson, Kristjan (6701597544)","55119067600; 56457396300; 57196480507; 55599405700; 6701597544","Neural Polarimeter and Wavemeter","2018","ACS Photonics","5","10.1021/acsphotonics.8b00295","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047078976&doi=10.1021%2facsphotonics.8b00295&partnerID=40&md5=70a379307ab808578c11be106d31b9a0","Innovation Center Iceland, Arleynir 2-8, Reykjavik, Iceland; Harvard School of Engineering and Applied Science, Cambridge, 02138, MA, United States; Science Institute, University of Iceland, Dunhagi 5, Reykjavik, Iceland","Magnusson E.B., Innovation Center Iceland, Arleynir 2-8, Reykjavik, Iceland; Mueller J.P.B., Innovation Center Iceland, Arleynir 2-8, Reykjavik, Iceland, Harvard School of Engineering and Applied Science, Cambridge, 02138, MA, United States; Juhl M., Innovation Center Iceland, Arleynir 2-8, Reykjavik, Iceland, Science Institute, University of Iceland, Dunhagi 5, Reykjavik, Iceland; Mendoza C., Innovation Center Iceland, Arleynir 2-8, Reykjavik, Iceland; Leosson K., Innovation Center Iceland, Arleynir 2-8, Reykjavik, Iceland, Science Institute, University of Iceland, Dunhagi 5, Reykjavik, Iceland","Numerous optical devices can be conveniently described in terms of a transfer function matrix formalism. An important example is the intensity-division Stokes polarimeter where four device outputs can be related to the four parameters of the Stokes vector using a linear 4 × 4 matrix transformation. In the present paper, we demonstrate how the functionality of such devices can be substantially enhanced by increasing the number of outputs and employing deep neural networks instead of the traditional linear algebra approach to establish correlations between device outputs and inputs. Specifically, we employ a neural network calibration of a metasurface-based intensity-division Stokes polarimeter with six outputs to accurately measure the four parameters of the Stokes vector of the input light across a much wider wavelength range than is afforded by a canonical linear transfer matrix model. Furthermore, the neural network model allows the device to determine the input wavelength from the measured data. We argue that nonlinear machine learning models used to fit calibration functions in this way are able to capture physical parameters that cannot be easily described using analytically derived models and that this approach is thus poised to improve the performance of a broad variety of optical sensors. © 2018 American Chemical Society.","Integrated optics devices; Metamaterials; Neural networks; Polarimetry","Calibration; Deep neural networks; Mathematical transformations; Polarimeters; Transfer matrix method; Calibration functions; Matrix transformation; Network calibration; Neural network model; Physical parameters; Stokes polarimeter; Transfer function matrix; Wavelength ranges; Linear transformations","American Chemical Society","23304022","","","","Article","Scopus","2-s2.0-85047078976"
"Brunetti A.; Buongiorno D.; Trotta G.F.; Bevilacqua V.","Brunetti, Antonio (56912970400); Buongiorno, Domenico (56401876300); Trotta, Gianpaolo Francesco (56913180700); Bevilacqua, Vitoantonio (57204703239)","56912970400; 56401876300; 56913180700; 57204703239","Computer vision and deep learning techniques for pedestrian detection and tracking: A survey","2018","Neurocomputing","356","10.1016/j.neucom.2018.01.092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044310319&doi=10.1016%2fj.neucom.2018.01.092&partnerID=40&md5=26722826706b447e8a4021e6312ce97d","Department of Electrical and Information Engineering (DEI), Polytechnic University of Bari, Italy; Department of Mechanics, Mathematics and Management (DMMM), Polytechnic University of Bari, Italy","Brunetti A., Department of Electrical and Information Engineering (DEI), Polytechnic University of Bari, Italy; Buongiorno D., Department of Electrical and Information Engineering (DEI), Polytechnic University of Bari, Italy; Trotta G.F., Department of Mechanics, Mathematics and Management (DMMM), Polytechnic University of Bari, Italy; Bevilacqua V., Department of Electrical and Information Engineering (DEI), Polytechnic University of Bari, Italy","Pedestrian detection and tracking have become an important field in the computer vision research area. This growing interest, started in the last decades, might be explained by the multitude of potential applications that could use the results of this research field, e.g. robotics, entertainment, surveillance, care for the elderly and disabled, and content-based indexing. In this survey paper, vision-based pedestrian detection systems are analysed based on their field of application, acquisition technology, computer vision techniques and classification strategies. Three main application fields have been individuated and discussed: video surveillance, human-machine interaction and analysis. Due to the large variety of acquisition technologies, this paper discusses both the differences between 2D and 3D vision systems, and indoor and outdoor systems. The authors reserved a dedicated section for the analysis of the Deep Learning methodologies, including the Convolutional Neural Networks in pedestrian detection and tracking, considering their recent exploding adoption for such a kind systems. Finally, focusing on the classification point of view, different Machine Learning techniques have been analysed, basing the discussion on the classification performances on different benchmark datasets. The reported results highlight the importance of testing pedestrian detection systems on different datasets to evaluate the robustness of the computed groups of features used as input to classifiers. © 2018 Elsevier B.V.","Artificial neural network; Convolutional neural network; Deep learning; Features extraction; Human tracking; Machine learning; Pedestrian detection","Artificial intelligence; Classification (of information); Computer vision; Convolution; Feature extraction; Learning algorithms; Learning systems; Neural networks; Online systems; Security systems; Surveys; Technology transfer; Computer vision techniques; Convolutional neural network; Features extraction; Human Tracking; Machine learning techniques; Pedestrian detection; Pedestrian detection and tracking; Pedestrian detection system; Article; artificial neural network; computer analysis; controlled study; data processing; human; information processing; learning algorithm; linear system; motion; pedestrian; priority journal; support vector machine; task performance; three dimensional imaging; visual system; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85044310319"
"Mutasa S.; Chang P.D.; Ruzal-Shapiro C.; Ayyala R.","Mutasa, Simukayi (56060604800); Chang, Peter D. (57192687394); Ruzal-Shapiro, Carrie (7004012126); Ayyala, Rama (14012552200)","56060604800; 57192687394; 7004012126; 14012552200","MABAL: a Novel Deep-Learning Architecture for Machine-Assisted Bone Age Labeling","2018","Journal of Digital Imaging","72","10.1007/s10278-018-0053-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045052300&doi=10.1007%2fs10278-018-0053-3&partnerID=40&md5=5f449a7740769df96d2c3591f8278605","Columbia University Medical Center, PB 1-301, New York, 10032, NY, United States","Mutasa S., Columbia University Medical Center, PB 1-301, New York, 10032, NY, United States; Chang P.D., Columbia University Medical Center, PB 1-301, New York, 10032, NY, United States; Ruzal-Shapiro C., Columbia University Medical Center, PB 1-301, New York, 10032, NY, United States; Ayyala R., Columbia University Medical Center, PB 1-301, New York, 10032, NY, United States","Bone age assessment (BAA) is a commonly performed diagnostic study in pediatric radiology to assess skeletal maturity. The most commonly utilized method for assessment of BAA is the Greulich and Pyle method (Pediatr Radiol 46.9:1269–1274, 2016; Arch Dis Child 81.2:172–173, 1999) atlas. The evaluation of BAA can be a tedious and time-consuming process for the radiologist. As such, several computer-assisted detection/diagnosis (CAD) methods have been proposed for automation of BAA. Classical CAD tools have traditionally relied on hard-coded algorithmic features for BAA which suffer from a variety of drawbacks. Recently, the advent and proliferation of convolutional neural networks (CNNs) has shown promise in a variety of medical imaging applications. There have been at least two published applications of using deep learning for evaluation of bone age (Med Image Anal 36:41–51, 2017; JDI 1–5, 2017). However, current implementations are limited by a combination of both architecture design and relatively small datasets. The purpose of this study is to demonstrate the benefits of a customized neural network algorithm carefully calibrated to the evaluation of bone age utilizing a relatively large institutional dataset. In doing so, this study will aim to show that advanced architectures can be successfully trained from scratch in the medical imaging domain and can generate results that outperform any existing proposed algorithm. The training data consisted of 10,289 images of different skeletal age examinations, 8909 from the hospital Picture Archiving and Communication System at our institution and 1383 from the public Digital Hand Atlas Database. The data was separated into four cohorts, one each for male and female children above the age of 8, and one each for male and female children below the age of 10. The testing set consisted of 20 radiographs of each 1-year-age cohort from 0 to 1 years to 14–15+ years, half male and half female. The testing set included left-hand radiographs done for bone age assessment, trauma evaluation without significant findings, and skeletal surveys. A 14 hidden layer-customized neural network was designed for this study. The network included several state of the art techniques including residual-style connections, inception layers, and spatial transformer layers. Data augmentation was applied to the network inputs to prevent overfitting. A linear regression output was utilized. Mean square error was used as the network loss function and mean absolute error (MAE) was utilized as the primary performance metric. MAE accuracies on the validation and test sets for young females were 0.654 and 0.561 respectively. For older females, validation and test accuracies were 0.662 and 0.497 respectively. For young males, validation and test accuracies were 0.649 and 0.585 respectively. Finally, for older males, validation and test set accuracies were 0.581 and 0.501 respectively. The female cohorts were trained for 900 epochs each and the male cohorts were trained for 600 epochs. An eightfold cross-validation set was employed for hyperparameter tuning. Test error was obtained after training on a full data set with the selected hyperparameters. Using our proposed customized neural network architecture on our large available data, we achieved an aggregate validation and test set mean absolute errors of 0.637 and 0.536 respectively. To date, this is the best published performance on utilizing deep learning for bone age assessment. Our results support our initial hypothesis that customized, purpose-built neural networks provide improved performance over networks derived from pre-trained imaging data sets. We build on that initial work by showing that the addition of state-of-the-art techniques such as residual connections and inception architecture further improves prediction accuracy. This is important because the current assumption for use of residual and/or inception architectures is that a large pre-trained network is required for successful implementation given the relatively small datasets in medical imaging. Instead we show that a small, customized architecture incorporating advanced CNN strategies can indeed be trained from scratch, yielding significant improvements in algorithm accuracy. It should be noted that for all four cohorts, testing error outperformed validation error. One reason for this is that our ground truth for our test set was obtained by averaging two pediatric radiologist reads compared to our training data for which only a single read was used. This suggests that despite relatively noisy training data, the algorithm could successfully model the variation between observers and generate estimates that are close to the expected ground truth. © 2018, Society for Imaging Informatics in Medicine.","Convolutional neural networks; Deep learning; Endocrinology; Machine learning; Pediatric radiology; Radiology","Adolescent; Age Determination by Skeleton; Child; Child, Preschool; Cohort Studies; Databases, Factual; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Infant; Infant, Newborn; Machine Learning; Male; Neural Networks (Computer); Pediatrics; Retrospective Studies; Sensitivity and Specificity; Bone; Computer aided diagnosis; Convolution; Endocrinology; Errors; Image segmentation; Learning systems; Mean square error; Medical imaging; Network architecture; Network layers; Neural networks; Pediatrics; Picture archiving and communication systems; Radiation; Radiography; Radiology; Statistical tests; Advanced architecture; Computer assisted detection; Convolutional neural network; Learning architectures; Neural network algorithm; Pediatric radiology; Performance metrices; State-of-the-art techniques; adolescent; artificial neural network; bone age determination; child; cohort analysis; computer assisted diagnosis; factual database; female; human; infant; machine learning; male; newborn; pediatrics; preschool child; procedures; retrospective study; sensitivity and specificity; Deep learning","Springer New York LLC","08971889","","JDIME","29404850","Article","Scopus","2-s2.0-85045052300"
"Kazemifar S.; Balagopal A.; Nguyen D.; McGuire S.; Hannan R.; Jiang S.; Owrangi A.","Kazemifar, Samaneh (57193675665); Balagopal, Anjali (57205220059); Nguyen, Dan (55938445100); McGuire, Sarah (55246960500); Hannan, Raquibul (47861681700); Jiang, Steve (7404453173); Owrangi, Amir (26025665600)","57193675665; 57205220059; 55938445100; 55246960500; 47861681700; 7404453173; 26025665600","Segmentation of the prostate and organs at risk in male pelvic CT images using deep learning","2018","Biomedical Physics and Engineering Express","84","10.1088/2057-1976/aad100","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053156128&doi=10.1088%2f2057-1976%2faad100&partnerID=40&md5=0e926e5a995922d50def1e347e02251f","Medical Artificial Intelligence and Automation Laboratory, Department of Radiation Oncology, University of Texas Southwestern, Dallas, TX, United States","Kazemifar S., Medical Artificial Intelligence and Automation Laboratory, Department of Radiation Oncology, University of Texas Southwestern, Dallas, TX, United States; Balagopal A., Medical Artificial Intelligence and Automation Laboratory, Department of Radiation Oncology, University of Texas Southwestern, Dallas, TX, United States; Nguyen D., Medical Artificial Intelligence and Automation Laboratory, Department of Radiation Oncology, University of Texas Southwestern, Dallas, TX, United States; McGuire S., Medical Artificial Intelligence and Automation Laboratory, Department of Radiation Oncology, University of Texas Southwestern, Dallas, TX, United States; Hannan R., Medical Artificial Intelligence and Automation Laboratory, Department of Radiation Oncology, University of Texas Southwestern, Dallas, TX, United States; Jiang S., Medical Artificial Intelligence and Automation Laboratory, Department of Radiation Oncology, University of Texas Southwestern, Dallas, TX, United States; Owrangi A., Medical Artificial Intelligence and Automation Laboratory, Department of Radiation Oncology, University of Texas Southwestern, Dallas, TX, United States","Inter-and intra-observer variation in delineating regions of interest (ROIs) occurs because of differences in expertise level and preferences of the radiation oncologists. We evaluated the accuracy of a segmentation model using the U-Net structure to delineate the prostate, bladder, and rectum in male pelvic CT images. The dataset used for training and testing the model consisted of raw CT scan images of 85 prostate cancer patients. We designed a 2D U-Net model to directly learn a mapping function that converts a 2D CT grayscale image to its corresponding 2D OAR segmented image. Our network contains blocks of convolution 2D layers with variable kernel sizes, channel number, and activation functions. On the left side of the U-Net model, we used three 3 × 3 convolutions, each followed by a rectified linear unit (ReLu) (activation function), and one max pooling operation. On the right side of the U-Net model, we used a 2 × 2 transposed convolution and two 3 × 3 convolution networks followed by a ReLu activation function. The automatic segmentation using the U-Net generated an average dice similarity coefficient (DC) and standard deviation (SD) of the following: DC ± SD (0.88 ± 0.12), (0.95 ± 0.04), and (0.92 ± 0.06) for the prostate, bladder, and rectum, respectively. Furthermore, the mean of average surface Hausdorff distance (ASHD) and SD were 1.2 ± 0.9 mm, 1.08 ± 0.8 mm, and 0.8 ± 0.6 mm for the prostate, bladder, and rectum, respectively. Our proposed method, which employs the U-Net structure, is highly accurate and reproducible for automated ROI segmentation. This provides a foundation to improve automatic delineation of the boundaries between the target and surrounding normal soft tissues on a standard radiation therapy planning CT scan. © 2018 IOP Publishing Ltd.","artificial intelligence organ contouring; deep machine learning; male pelvic region; neural network; prostate; segmentation","Article; cancer diagnosis; cancer radiotherapy; cancer risk; controlled study; human; image segmentation; major clinical study; male; organs at risk; predictive value; prostate cancer; radiation; radiation oncologist; random error; x-ray computed tomography","Institute of Physics Publishing","20571976","","","","Article","Scopus","2-s2.0-85053156128"
"Cao W.; Czarnek N.; Shan J.; Li L.","Cao, Wen (57201853809); Czarnek, Nicholas (55585200500); Shan, Juan (57203242261); Li, Lin (56134014300)","57201853809; 55585200500; 57203242261; 56134014300","Microaneurysm detection using principal component analysis and machine learning methods","2018","IEEE Transactions on Nanobioscience","62","10.1109/TNB.2018.2840084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047616112&doi=10.1109%2fTNB.2018.2840084&partnerID=40&md5=28450d1e42d01a0af8cf7e4cbee1f7cf","Seidenberg School of Computer Science and Information Systems, Pace University, New York City, 10038, NY, United States; Pratt School of Electrical and Computer Engineering, Duke University, Durham, 27708, NC, United States; Department of Computer Science and Software Engineering, Seattle University, Seattle, 98122, WA, United States","Cao W., Seidenberg School of Computer Science and Information Systems, Pace University, New York City, 10038, NY, United States; Czarnek N., Pratt School of Electrical and Computer Engineering, Duke University, Durham, 27708, NC, United States; Shan J., Seidenberg School of Computer Science and Information Systems, Pace University, New York City, 10038, NY, United States; Li L., Department of Computer Science and Software Engineering, Seattle University, Seattle, 98122, WA, United States","Diabetic retinopathy (DR) is an eye abnormality caused by long-term diabetes and it is the most common cause of blindness before the age of 50. Microaneurysms (MAs), resulting from leakage from retinal blood vessels, are early indicators of DR. In this paper, we analyzed MA detectability using small 25 by 25 pixel patches extracted from fundus images in the DIAbetic RETinopathy DataBase - Calibration Level 1 (DIARETDB1). Raw pixel intensities of extracted patches served directly as inputs into the following classifiers: random forest (RF), neural network, and support vector machine. We also explored the use of two techniques (principal component analysis and RF feature importance) for reducing input dimensionality. With traditional machine learning methods and leave-10-patients-out cross validation, our method outperformed a deep learning-based MA detection method, with AUC performance improved from 0.962 to 0.985 and F-measure improved from 0.913 to 0.926, using the same DIARETDB1 database. Furthermore, we validated our method on a different dataset - retinopathy online challenge (ROC) data set. The performance of the three classifiers and the pattern with different percentage of principal components are consistent on the two data sets. Especially, we trained the RF on DIARETDB1 and applied it to ROC; the performance is very similar to that of the RF trained and tested using cross validation on ROC data set. This result indicates that our method has the potential to generalize to different datasets. © 2002-2011 IEEE.","automated microaneurysm detection; diabetic retinopathy; Feature representation; neural network; random forest; support vector machine","Diabetic Retinopathy; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Microaneurysm; Neural Networks (Computer); Principal Component Analysis; Support Vector Machine; Artificial intelligence; Blood vessels; Classification (of information); Decision trees; Deep learning; Diagnosis; Eye protection; Image processing; Neural networks; Ophthalmology; Pixels; Support vector machines; Automatic Detection; Diabetic retinopathy; Feature representation; Machine learning methods; Microaneurysms; Principal Components; Random forests; Retinal blood vessels; artificial neural network; computer assisted diagnosis; diabetic retinopathy; diagnostic imaging; human; machine learning; microaneurysm; principal component analysis; procedures; support vector machine; Principal component analysis","Institute of Electrical and Electronics Engineers Inc.","15361241","","","29994317","Article","Scopus","2-s2.0-85047616112"
"Praveen G.B.; Agrawal A.; Sundaram P.; Sardesai S.","Praveen, G.B. (57189330136); Agrawal, Anita (56405023200); Sundaram, Ponraj (57196927970); Sardesai, Sanjay (57202330147)","57189330136; 56405023200; 57196927970; 57202330147","Ischemic stroke lesion segmentation using stacked sparse autoencoder","2018","Computers in Biology and Medicine","50","10.1016/j.compbiomed.2018.05.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047930116&doi=10.1016%2fj.compbiomed.2018.05.027&partnerID=40&md5=edb9c821f97ec53914fbe981b8e198bf","Department of Electrical and Electronics Engineering, BITS PILANI - K.K Birla Goa Campus, Goa, India; Department of Neurosurgery, Goa Medical College, Goa, India; Department of Radiodiagnosis, Goa Medical College, Goa, India","Praveen G.B., Department of Electrical and Electronics Engineering, BITS PILANI - K.K Birla Goa Campus, Goa, India; Agrawal A., Department of Electrical and Electronics Engineering, BITS PILANI - K.K Birla Goa Campus, Goa, India; Sundaram P., Department of Neurosurgery, Goa Medical College, Goa, India; Sardesai S., Department of Radiodiagnosis, Goa Medical College, Goa, India","Automatic segmentation of ischemic stroke lesion volumes from multi-spectral Magnetic Resonance Imaging (MRI) sequences plays a vital role in quantifying and locating the lesion region. Most existing methods mainly rely on designing hand-crafted features followed by a classifier model for ischemic stroke lesion segmentation. Design of these features requires complex domain knowledge and often lacks the ability to differentiate between the stroke lesions and the normal classes. In this work, we propose an unsupervised featured learning approach based on stacked sparse autoencoder (SSAE) framework for automatically learning the features for accurate segmentation of stroke lesions from brain MR images. A deep architecture is designed using sparse autoencoder (SAE) layers, followed by support vector machine (SVM) classifier for classifying the patches into normal or lesions. We validated our approach on a publicly available Ischemic Stroke Lesion Segmentation (ISLES) 2015 dataset, with a mean precision of 0.968, mean dice coefficient (DC) of 0.943, mean recall of 0.924 and mean accuracy of 0.904. The experimental results show that our proposed approach significantly outperforms the state-of-the-art methods in terms of precision, DC, and recall. Quantitative evaluation was carried out and compared with the existing approaches, which demonstrates that the proposed method is 25.71%, 36.67%, and 16.96% higher in terms of precision, DC and recall values, respectively. The unsupervised features learned via SSAE framework performs better than the hand-crafted features and can be easily trained on large datasets. © 2018 Elsevier Ltd","Ischemic stroke lesion segmentation; Magnetic resonance imaging; Stacked sparse autoencoders; SVM; Unsupervised feature learning","Databases, Factual; Humans; Machine Learning; Magnetic Resonance Imaging; Stroke; Support Vector Machine; Magnetic levitation vehicles; Magnetic resonance imaging; Support vector machines; Autoencoders; Automatic segmentations; Deep architectures; Ischemic strokes; Magnetic Resonance Imaging (MRI); Quantitative evaluation; State-of-the-art methods; Unsupervised feature learning; Article; brain ischemia; conceptual framework; controlled study; false positive result; human; image segmentation; learning algorithm; measurement accuracy; neuroimaging; nuclear magnetic resonance imaging; priority journal; probability; qualitative analysis; quantitative analysis; stacked sparse autoencoder; support vector machine; cerebrovascular accident; diagnostic imaging; factual database; machine learning; nuclear magnetic resonance imaging; pathophysiology; support vector machine; Image segmentation","Elsevier Ltd","00104825","","CBMDA","29883752","Article","Scopus","2-s2.0-85047930116"
"Shuangyan Y.; Ying H.; Lingchun Y.; Jianqiang Z.; Weijuan L.; Changgui Q.; Ming L.; Yanmei Y.","Shuangyan, Yang (57199508054); Ying, Hou (57200114418); Lingchun, Yang (57202388690); Jianqiang, Zhang (57201462159); Weijuan, Liu (55867028700); Changgui, Qiu (57200107860); Ming, Li (57201467010); Yanmei, Yang (36018066000)","57199508054; 57200114418; 57202388690; 57201462159; 55867028700; 57200107860; 57201467010; 36018066000","Automatic identification of cigarette brand using near-infrared spectroscopy and sparse representation classification algorithm","2018","Journal of the Brazilian Chemical Society","4","10.21577/0103-5053.20180019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048172156&doi=10.21577%2f0103-5053.20180019&partnerID=40&md5=8afe069aea294e5190996f4936ee0258","Yunnan Reascend Tobacco Technology (Group) Co., Ltd., Kunming, 650000, China; Yunnan Comtestor Co., Ltd., Kunming, 650000, China; Yunnan Entry-Exit Inspection and Quarantine Bureau, Kunming, 650000, China; Faculty of Science, Kunming University of Science and Technology, Kunming, 650000, China","Shuangyan Y., Yunnan Reascend Tobacco Technology (Group) Co., Ltd., Kunming, 650000, China, Yunnan Comtestor Co., Ltd., Kunming, 650000, China; Ying H., Yunnan Comtestor Co., Ltd., Kunming, 650000, China; Lingchun Y., Yunnan Entry-Exit Inspection and Quarantine Bureau, Kunming, 650000, China; Jianqiang Z., Yunnan Reascend Tobacco Technology (Group) Co., Ltd., Kunming, 650000, China, Faculty of Science, Kunming University of Science and Technology, Kunming, 650000, China; Weijuan L., Yunnan Reascend Tobacco Technology (Group) Co., Ltd., Kunming, 650000, China; Changgui Q., Yunnan Comtestor Co., Ltd., Kunming, 650000, China; Ming L., Yunnan Reascend Tobacco Technology (Group) Co., Ltd., Kunming, 650000, China; Yanmei Y., Yunnan Reascend Tobacco Technology (Group) Co., Ltd., Kunming, 650000, China","A cigarette brand automatic classification method using near-infrared (NIR) spectroscopy and sparse representation classification (SRC) algorithm is put forward by the paper. Comparing with the traditional methods, it is more robust to redundancy because it uses non-negative least squares (NNLS) sparse coding instead of principal component analysis (PCA) for dimensionality reduction of the spectral data. The effectiveness of SRC algorithm is compared with PCA-linear discriminant analysis (LDA) and PCA-particle swarm optimization-support vector machine (PSO-SVM) algorithms. The results show that the classification accuracy of the proposed method is higher and is much more efficient. © 2018 Sociedade Brasileira de Química.","Deep learning; Near-infrared spectroscopy; Non-negative least squares; Sparse representation classification","","Sociedade Brasileira de Quimica","01035053","","JOCSE","","Article","Scopus","2-s2.0-85048172156"
"Le Q.; Boydell O.; Namee B.M.; Scanlon M.","Le, Quan (36799469900); Boydell, Oisín (14035144000); Namee, Brian Mac (33568100700); Scanlon, Mark (52264702800)","36799469900; 14035144000; 33568100700; 52264702800","Deep learning at the shallow end: Malware classification for non-domain experts","2018","Digital Investigation","94","10.1016/j.diin.2018.04.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048560151&doi=10.1016%2fj.diin.2018.04.024&partnerID=40&md5=0a807179be976339e76d70e5bf3a3c43","Centre for Applied Data Analytics Research, University College Dublin, Ireland; Forensics and Security Research Group, University College Dublin, Ireland","Le Q., Centre for Applied Data Analytics Research, University College Dublin, Ireland; Boydell O., Centre for Applied Data Analytics Research, University College Dublin, Ireland; Namee B.M., Centre for Applied Data Analytics Research, University College Dublin, Ireland; Scanlon M., Forensics and Security Research Group, University College Dublin, Ireland","Current malware detection and classification approaches generally rely on time consuming and knowledge intensive processes to extract patterns (signatures) and behaviors from malware, which are then used for identification. Moreover, these signatures are often limited to local, contiguous sequences within the data whilst ignoring their context in relation to each other and throughout the malware file as a whole. We present a Deep Learning based malware classification approach that requires no expert domain knowledge and is based on a purely data driven approach for complex pattern and feature identification. © 2018 The Author(s)","Deep learning; Machine learning; Malware analysis; Reverse engineering","Computer crime; Consumer behavior; Learning systems; Malware; Reverse engineering; Classification approach; Data-driven approach; Domain knowledge; Feature identification; Knowledge intensive process; Malware analysis; Malware classifications; Malware detection; Deep learning","Elsevier Ltd","17422876","","","","Article","Scopus","2-s2.0-85048560151"
"Klukowski P.; Augoff M.; ZieRba M.; Drwal M.; Gonczarek A.; Walczak M.J.","Klukowski, Piotr (55767524700); Augoff, Michal (57202087430); ZieRba, MacIej (57204243354); Drwal, MacIej (36647266900); Gonczarek, Adam (12544668700); Walczak, Michal J. (55914912100)","55767524700; 57202087430; 57204243354; 36647266900; 12544668700; 55914912100","NMRNet: A deep learning approach to automated peak picking of protein NMR spectra","2018","Bioinformatics","47","10.1093/bioinformatics/bty134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048248567&doi=10.1093%2fbioinformatics%2fbty134&partnerID=40&md5=5c47efef2bced6f7b5cf713ba0ba9cc7","Department of Computer Science, Faculty of Computer Science and Management, Wroclław University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclław, 50-370, Poland; Captor Therapeutics Ltd., ul. Dunska 11, Wroclław, 54-427, Poland; Alphamoon Ltd., ul. Wlodkowica 21/3, Wroclław, 50-072, Poland","Klukowski P., Department of Computer Science, Faculty of Computer Science and Management, Wroclław University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclław, 50-370, Poland; Augoff M., Department of Computer Science, Faculty of Computer Science and Management, Wroclław University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclław, 50-370, Poland; ZieRba M., Department of Computer Science, Faculty of Computer Science and Management, Wroclław University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclław, 50-370, Poland; Drwal M., Department of Computer Science, Faculty of Computer Science and Management, Wroclław University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclław, 50-370, Poland; Gonczarek A., Department of Computer Science, Faculty of Computer Science and Management, Wroclław University of Science and Technology, Wybrzeze Wyspianskiego 27, Wroclław, 50-370, Poland, Alphamoon Ltd., ul. Wlodkowica 21/3, Wroclław, 50-072, Poland; Walczak M.J., Captor Therapeutics Ltd., ul. Dunska 11, Wroclław, 54-427, Poland, Alphamoon Ltd., ul. Wlodkowica 21/3, Wroclław, 50-072, Poland","Motivation: Automated selection of signals in protein NMR spectra, known as peak picking, has been studied for over 20 years, nevertheless existing peak picking methods are still largely deficient. Accurate and precise automated peak picking would accelerate the structure calculation, and analysis of dynamics and interactions of macromolecules. Recent advancement in handling big data, together with an outburst of machine learning techniques, offer an opportunity to tackle the peak picking problem substantially faster than manual picking and on par with human accuracy. In particular, deep learning has proven to systematically achieve human-level performance in various recognition tasks, and thus emerges as an ideal tool to address automated identification of NMR signals. Results: We have applied a convolutional neural network for visual analysis of multidimensional NMR spectra. A comprehensive test on 31 manually annotated spectra has demonstrated top-tier average precision (AP) of 0.9596, 0.9058 and 0.8271 for backbone, side-chain and NOESY spectra, respectively. Furthermore, a combination of extracted peak lists with automated assignment routine, FLYA, outperformed other methods, including the manual one, and led to correct resonance assignment at the levels of 90.40%, 89.90% and 90.20% for three benchmark proteins. © The Author(s) 2018.","","Deep Learning; Macromolecular Substances; Nuclear Magnetic Resonance, Biomolecular; Proteins; Software; protein; article; human; human experiment; learning; nuclear magnetic resonance spectroscopy; nuclear Overhauser effect; chemistry; macromolecule; nuclear magnetic resonance; procedures; software","Oxford University Press","13674803","","BOINF","29547986","Article","Scopus","2-s2.0-85048248567"
"Masumoto H.; Tabuchi H.; Nakakura S.; Ishitobi N.; Miki M.; Enno H.","Masumoto, Hiroki (57201984138); Tabuchi, Hitoshi (36810783800); Nakakura, Shunsuke (9250833200); Ishitobi, Naofumi (57195472024); Miki, Masayuki (57216058316); Enno, Hiroki (57195449818)","57201984138; 36810783800; 9250833200; 57195472024; 57216058316; 57195449818","Deep-learning Classifier with an Ultrawide-field Scanning Laser Ophthalmoscope Detects Glaucoma Visual Field Severity","2018","Journal of Glaucoma","43","10.1097/IJG.0000000000000988","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049926365&doi=10.1097%2fIJG.0000000000000988&partnerID=40&md5=dc6ab87c0daca35fadb12f8580140dd6","Department of Ophthalmology, Saneikai Tsukazaki Hospital, 68-1 Aboshi Waku, Himeji, 671-1227, Japan; Rist Inc., Tokyo, Japan","Masumoto H., Department of Ophthalmology, Saneikai Tsukazaki Hospital, 68-1 Aboshi Waku, Himeji, 671-1227, Japan; Tabuchi H., Department of Ophthalmology, Saneikai Tsukazaki Hospital, 68-1 Aboshi Waku, Himeji, 671-1227, Japan; Nakakura S., Department of Ophthalmology, Saneikai Tsukazaki Hospital, 68-1 Aboshi Waku, Himeji, 671-1227, Japan; Ishitobi N., Department of Ophthalmology, Saneikai Tsukazaki Hospital, 68-1 Aboshi Waku, Himeji, 671-1227, Japan; Miki M., Department of Ophthalmology, Saneikai Tsukazaki Hospital, 68-1 Aboshi Waku, Himeji, 671-1227, Japan; Enno H., Rist Inc., Tokyo, Japan","Purpose: To evaluate the accuracy of detecting glaucoma visual field defect severity using deep-learning (DL) classifier with an ultrawidefield scanning laser ophthalmoscope. Methods: One eye of 982 open-angle glaucoma (OAG) patients and 417 healthy eyes were enrolled. We categorized glaucoma patients into 3 groups according to the glaucoma visual field damage (Humphrey Field Analyzer 24-2 program) [early; ?6 dB (mean deviation) or better, moderate; between ?6 and ?12 dB, and severe as mean deviation of ?12 dB or worse]. In total, 558 images (446 for training and 112 for grading) from early OAG patients, 203 images (162 for training and 41 for grading) from moderate OAG patients, 221 images (176 for training and 45 for grading) from severe OAG patients and 417 images (333 for training and 84 for grading) from normal subjects were analyzed using DL. The area under the receiver operating characteristic curve (AUC) was used to evaluate the accuracy after 100 trials. Results: The mean AUC between normal versus all glaucoma patients was 0.872, the sensitivity was 81.3% and the specificity was 80.2%. In normal versus early OAG, mean AUC was 0.830, the sensitivity was 83.8% and the specificity was 75.3%. In normal versus moderate OAG, mean AUC was 0.864, sensitivity was 77.5%, and specificity was 90.2%. In normal versus severe OAG glaucoma mean AUC was 0.934, sensitivity was 90.9%, and specificity was 95.8%. Conclusions: Despite using an ultrawide-field scanning laser ophthalmoscope, DL can detect glaucoma characteristics and glaucoma visual field defect severity with high reliability. Copyright © 2018 Wolters Kluwer Health, Inc. All rights reserved.","artificial intelligence; deep learning; glaucoma; machine learning; optos; ultrawide-field scanning laser ophthalmoscope; visual field defect","Adult; Aged; Cross-Sectional Studies; Deep Learning; Female; Glaucoma; Humans; Image Interpretation, Computer-Assisted; Intraocular Pressure; Male; Microscopy, Confocal; Middle Aged; Ophthalmoscopes; Reproducibility of Results; Retrospective Studies; Sensitivity and Specificity; Severity of Illness Index; Vision Disorders; Visual Field Tests; Visual Fields; adult; age distribution; Article; artificial intelligence; artificial neural network; best corrected visual acuity; controlled study; cross-sectional study; deep learning classifier; diagnostic accuracy; disease severity; female; human; machine learning; major clinical study; male; open angle glaucoma; ophthalmoscopy; perimetry; priority journal; reliability; retrospective study; scanning laser ophthalmoscopy; sensitivity and specificity; sex difference; ultrawide field scanning laser ophthalmoscopy; visual system parameters; aged; classification; computer assisted diagnosis; confocal microscopy; devices; glaucoma; intraocular pressure; middle aged; ophthalmoscope; pathology; procedures; reproducibility; severity of illness index; visual disorder; visual field","Lippincott Williams and Wilkins","10570829","","JOGLE","29781835","Article","Scopus","2-s2.0-85049926365"
"He L.; Cao C.","He, Lang (57214655836); Cao, Cui (57202419325)","57214655836; 57202419325","Automated depression analysis using convolutional neural networks from speech","2018","Journal of Biomedical Informatics","138","10.1016/j.jbi.2018.05.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048279448&doi=10.1016%2fj.jbi.2018.05.007&partnerID=40&md5=ae482b41d98a7d09dca8b2101efbe0f2","NPU-VUB joint AVSP Research Lab, School of Computer Science, Northwestern Polytechnical University (NPU), Xi'an, China; Moscow Institute of Arts, Weinan Normal University, Weinan, China","He L., NPU-VUB joint AVSP Research Lab, School of Computer Science, Northwestern Polytechnical University (NPU), Xi'an, China; Cao C., Moscow Institute of Arts, Weinan Normal University, Weinan, China","To help clinicians to efficiently diagnose the severity of a person's depression, the affective computing community and the artificial intelligence field have shown a growing interest in designing automated systems. The speech features have useful information for the diagnosis of depression. However, manually designing and domain knowledge are still important for the selection of the feature, which makes the process labor consuming and subjective. In recent years, deep-learned features based on neural networks have shown superior performance to hand-crafted features in various areas. In this paper, to overcome the difficulties mentioned above, we propose a combination of hand-crafted and deep-learned features which can effectively measure the severity of depression from speech. In the proposed method, Deep Convolutional Neural Networks (DCNN) are firstly built to learn deep-learned features from spectrograms and raw speech waveforms. Then we manually extract the state-of-the-art texture descriptors named median robust extended local binary patterns (MRELBP) from spectrograms. To capture the complementary information within the hand-crafted features and deep-learned features, we propose joint fine-tuning layers to combine the raw and spectrogram DCNN to boost the depression recognition performance. Moreover, to address the problems with small samples, a data augmentation method was proposed. Experiments conducted on AVEC2013 and AVEC2014 depression databases show that our approach is robust and effective for the diagnosis of depression when compared to state-of-the-art audio-based methods. © 2018 Elsevier Inc.","Automatic diagnosis; Depression; Median Robust extended Local Binary Patterns(MRELBP); Speech processing","Deep Learning; Depression; Diagnosis, Computer-Assisted; Humans; Neural Networks (Computer); Speech; Automation; Convolution; Neural networks; Spectrographs; Speech processing; Affective Computing; Automatic diagnosis; Convolutional neural network; Data augmentation; Deep convolutional neural networks; Depression; Extended local binary patterns; Texture descriptors; Article; artificial neural network; computer assisted diagnosis; controlled study; data base; deep convolutional neural network; depression; feature extraction; human; intermethod comparison; machine learning; psychiatric diagnosis; speech; depression; Deep neural networks","Academic Press Inc.","15320464","","JBIOB","29852317","Article","Scopus","2-s2.0-85048279448"
"Nakano Y.; Suzuki N.; Kuwata F.","Nakano, Yoshio (35414888700); Suzuki, Nao (36162617200); Kuwata, Fumiyuki (6603654658)","35414888700; 36162617200; 6603654658","Predicting oral malodour based on the microbiota in saliva samples using a deep learning approach","2018","BMC Oral Health","25","10.1186/s12903-018-0591-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050781060&doi=10.1186%2fs12903-018-0591-6&partnerID=40&md5=3df3cbd9414ae53b182bbe6657a4278e","Department of Chemistry, Nihon University School of Dentistry, Kanda-Surugadai, Tokyo, Chiyoda-ku, 101-8310, Japan; Department of Preventive and Public Health Dentistry, Fukuoka Dental College, Tamura, Sawara-ku, Fukuoka, 814-0193, Japan","Nakano Y., Department of Chemistry, Nihon University School of Dentistry, Kanda-Surugadai, Tokyo, Chiyoda-ku, 101-8310, Japan; Suzuki N., Department of Preventive and Public Health Dentistry, Fukuoka Dental College, Tamura, Sawara-ku, Fukuoka, 814-0193, Japan; Kuwata F., Department of Chemistry, Nihon University School of Dentistry, Kanda-Surugadai, Tokyo, Chiyoda-ku, 101-8310, Japan","Background: Oral malodour is mainly caused by volatile sulphur compounds produced by bacteria and bacterial interactions. It is difficult to predict the presence or absence of oral malodour based on the abundances of specific species and their combinations. This paper presents an effective way of deep learning approach to predicting the oral malodour from salivary microbiota. Methods: The 16S rRNA genes from saliva samples of 90 subjects (45 had no or weak oral malodour, and 45 had marked oral malodour) were amplified, and gene sequence analysis was carried out. Deep learning classified oral malodour and healthy breath based on the resultant abundances of operational taxonomic units (OTUs) Results: A discrimination classifier model was constructed by profiling OTUs and calculating their relative abundance in saliva samples from 90 subjects. Our deep learning model achieved a predictive accuracy of 97%, compared to the 79% obtained with a support vector machine. Conclusion: This approach is expected to be useful in screening the saliva for prediction of oral malodour before visits to specialist clinics. © 2018 The Author(s).","Deep learning; Oral malodour; Oral micorobiota","Deep Learning; Female; Halitosis; High-Throughput Nucleotide Sequencing; Humans; Male; Microbiota; Middle Aged; RNA, Ribosomal, 16S; Saliva; RNA 16S; female; genetics; halitosis; high throughput sequencing; human; male; microbiology; microflora; middle aged; saliva","BioMed Central Ltd.","14726831","","","30064419","Article","Scopus","2-s2.0-85050781060"
"Wiesner-Hanks T.; Stewart E.L.; Kaczmar N.; Dechant C.; Wu H.; Nelson R.J.; Lipson H.; Gore M.A.","Wiesner-Hanks, Tyr (56487971500); Stewart, Ethan L. (56363142300); Kaczmar, Nicholas (57202820302); Dechant, Chad (57196280974); Wu, Harvey (57202812772); Nelson, Rebecca J. (57203792660); Lipson, Hod (7006792691); Gore, Michael A. (18133454100)","56487971500; 56363142300; 57202820302; 57196280974; 57202812772; 57203792660; 7006792691; 18133454100","Image set for deep learning: Field images of maize annotated with disease symptoms","2018","BMC Research Notes","94","10.1186/s13104-018-3548-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049430423&doi=10.1186%2fs13104-018-3548-6&partnerID=40&md5=dab0892ec5acbe586d7ce9094f021760","Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, 14853, NY, United States; Department of Computer Science, Columbia University, New York, 10027, NY, United States; Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University, Ithaca, 14853, NY, United States; Department of Mechanical Engineering and Institute of Data Science, Columbia University, New York, 10027, NY, United States","Wiesner-Hanks T., Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, 14853, NY, United States; Stewart E.L., Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, 14853, NY, United States; Kaczmar N., Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, 14853, NY, United States; Dechant C., Department of Computer Science, Columbia University, New York, 10027, NY, United States; Wu H., Department of Computer Science, Columbia University, New York, 10027, NY, United States; Nelson R.J., Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant Science, Cornell University, Ithaca, 14853, NY, United States; Lipson H., Department of Mechanical Engineering and Institute of Data Science, Columbia University, New York, 10027, NY, United States; Gore M.A., Plant Breeding and Genetics Section, School of Integrative Plant Science, Cornell University, Ithaca, 14853, NY, United States","Objectives: Automated detection and quantification of plant diseases would enable more rapid gains in plant breeding and faster scouting of farmers' fields. However, it is difficult for a simple algorithm to distinguish between the target disease and other sources of dead plant tissue in a typical field, especially given the many variations in lighting and orientation. Training a machine learning algorithm to accurately detect a given disease from images taken in the field requires a massive amount of human-generated training data. Data description: This data set contains images of maize (Zea mays L.) leaves taken in three ways: by a hand-held camera, with a camera mounted on a boom, and with a camera mounted on a small unmanned aircraft system (sUAS, commonly known as a drone). Lesions of northern leaf blight (NLB), a common foliar disease of maize, were annotated in each image by one of two human experts. The three data sets together contain 18,222 images annotated with 105,705 NLB lesions, making this the largest publicly available image set annotated for a single plant disease. © 2018 The Author(s).","Convolutional neural network; Corn; Deep learning; Disease; Images; Machine learning; Maize; Phytopathology; Plant disease","Algorithms; Data Curation; Deep Learning; Humans; Plant Breeding; Plant Diseases; Zea mays; algorithm; human; information processing; maize; plant breeding; plant disease","BioMed Central Ltd.","17560500","","","29970178","Article","Scopus","2-s2.0-85049430423"
"Wang Q.; Xu W.; Zheng H.","Wang, Qili (57198901406); Xu, Wei (56582984800); Zheng, Han (57201496167)","57198901406; 56582984800; 57201496167","Combining the wisdom of crowds and technical analysis for financial market prediction using deep random subspace ensembles","2018","Neurocomputing","51","10.1016/j.neucom.2018.02.095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045111057&doi=10.1016%2fj.neucom.2018.02.095&partnerID=40&md5=95f05338e6f01e505b9272757c91b0a7","School of Information, Renmin University of China, Beijing, 100872, China; Smart City Research Center, Renmin University of China, Beijing, 100872, China","Wang Q., School of Information, Renmin University of China, Beijing, 100872, China; Xu W., School of Information, Renmin University of China, Beijing, 100872, China, Smart City Research Center, Renmin University of China, Beijing, 100872, China; Zheng H., School of Information, Renmin University of China, Beijing, 100872, China","Many researchers and practitioners have attempted to predict financial market trends for excess returns using multiple information sources including social media. Recent studies have investigated the relation between public sentiment and stock price movements and demonstrated that investment decisions are affected by public opinion. In this paper, we design a novel framework that combines the wisdom of crowds and technical analysis for financial market prediction using a new fusion strategy. A machine learning technique called deep random subspace ensembles (DRSE), which integrates deep learning algorithms and ensemble learning methods, is proposed according to the characteristics of the prediction task. Based on collected real-world datasets, the experimental results show that our proposed method outperforms the baseline models in predicting stock market by at least 14.2% in terms of AUC value, indicating the efficacy of DRSE as a viable mechanism for financial market prediction. © 2018","Deep learning; Financial market prediction; Random subspace ensembles; Sentiment analysis; Wisdom of crowds","Commerce; Financial markets; Forecasting; Investments; Learning algorithms; Sentiment analysis; Social aspects; Information sources; Investment decisions; Machine learning techniques; Market prediction; Random subspace ensembles; Real-world datasets; Stock price movements; Wisdom of crowds; article; deep learning; human; prediction; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85045111057"
"You R.; Zhang Z.; Xiong Y.; Sun F.; Mamitsuka H.; Zhu S.","You, Ronghui (56501667700); Zhang, Zihan (57204288614); Xiong, Yi (56564594900); Sun, Fengzhu (7401804190); Mamitsuka, Hiroshi (6602748450); Zhu, Shanfeng (8940145500)","56501667700; 57204288614; 56564594900; 7401804190; 6602748450; 8940145500","GOLabeler: Improving sequence-based large-scale protein function prediction by learning to rank","2018","Bioinformatics","109","10.1093/bioinformatics/bty130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049829991&doi=10.1093%2fbioinformatics%2fbty130&partnerID=40&md5=6f4e0641104960920b6c44fc6736820b","School of Computer Science, Shanghai Key Lab of Intelligent Information Processing, Fudan University, Shanghai, 200433, China; Center for Computational System Biology, ISTBI, Fudan University, Shanghai, 200433, China; Department of Bioinformatics and Biostatistics, Shanghai Jiaotong University, Shanghai, 200240, China; Molecular and Computational Biology Program, Department of Biological Sciences, University of Southern California, Los Angeles, 90089, CA, United States; Bioinformatics Center, Institute for Chemical Research, Kyoto University, Uji, Kyoto Prefecture, 611-0011, Japan; Department of Computer Science, Aalto University, Helsinki, Finland","You R., School of Computer Science, Shanghai Key Lab of Intelligent Information Processing, Fudan University, Shanghai, 200433, China, Center for Computational System Biology, ISTBI, Fudan University, Shanghai, 200433, China; Zhang Z., School of Computer Science, Shanghai Key Lab of Intelligent Information Processing, Fudan University, Shanghai, 200433, China, Center for Computational System Biology, ISTBI, Fudan University, Shanghai, 200433, China; Xiong Y., Department of Bioinformatics and Biostatistics, Shanghai Jiaotong University, Shanghai, 200240, China; Sun F., Center for Computational System Biology, ISTBI, Fudan University, Shanghai, 200433, China, Molecular and Computational Biology Program, Department of Biological Sciences, University of Southern California, Los Angeles, 90089, CA, United States; Mamitsuka H., Bioinformatics Center, Institute for Chemical Research, Kyoto University, Uji, Kyoto Prefecture, 611-0011, Japan, Department of Computer Science, Aalto University, Helsinki, Finland; Zhu S., School of Computer Science, Shanghai Key Lab of Intelligent Information Processing, Fudan University, Shanghai, 200433, China, Center for Computational System Biology, ISTBI, Fudan University, Shanghai, 200433, China","Motivation: Gene Ontology (GO) has been widely used to annotate functions of proteins and understand their biological roles. Currently only < 1% of >70 million proteins in UniProtKB have experimental GO annotations, implying the strong necessity of automated function prediction (AFP) of proteins, where AFP is a hard multilabel classification problem due to one protein with a diverse number of GO terms. Most of these proteins have only sequences as input information, indicating the importance of sequence-based AFP (SAFP: Sequences are the only input). Furthermore, homology-based SAFP tools are competitive in AFP competitions, while they do not necessarily work well for so-called difficult proteins, which have < 60% sequence identity to proteins with annotations already. Thus, the vital and challenging problem now is how to develop a method for SAFP, particularly for difficult proteins. Methods: The key of this method is to extract not only homology information but also diverse, deep-rooted information/evidence from sequence inputs and integrate them into a predictor in a both effective and efficient manner. We propose GOLabeler, which integrates five component classifiers, trained from different features, including GO term frequency, sequence alignment, amino acid trigram, domains and motifs, and biophysical properties, etc., in the framework of learning to rank (LTR), a paradigm of machine learning, especially powerful for multilabel classification. Results: The empirical results obtained by examining GOLabeler extensively and thoroughly by using large-scale datasets revealed numerous favorable aspects of GOLabeler, including significant performance advantage over state-of-the-art AFP methods. © The Author(s) 2018.","","Amino Acid Sequence; Animals; Computational Biology; Eukaryota; Gene Ontology; Humans; Machine Learning; Molecular Sequence Annotation; Protein Structural Elements; Proteins; Sequence Alignment; Sequence Analysis, Protein; Software; protein; amino acid sequence; animal; biology; eukaryote; gene ontology; human; machine learning; metabolism; molecular genetics; physiology; procedures; protein structure; sequence alignment; sequence analysis; software","Oxford University Press","13674803","","BOINF","29522145","Article","Scopus","2-s2.0-85049829991"
"Du J.; Zhang Y.; Luo J.; Jia Y.; Wei Q.; Tao C.; Xu H.","Du, Jingcheng (56463293100); Zhang, Yaoyun (56500740300); Luo, Jianhong (9335634000); Jia, Yuxi (57202283395); Wei, Qiang (57207269415); Tao, Cui (8245410000); Xu, Hua (55493876700)","56463293100; 56500740300; 9335634000; 57202283395; 57207269415; 8245410000; 55493876700","Extracting psychiatric stressors for suicide from social media using deep learning","2018","BMC Medical Informatics and Decision Making","103","10.1186/s12911-018-0632-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050815761&doi=10.1186%2fs12911-018-0632-8&partnerID=40&md5=57012e7f2733a989e9b7cee85ca4fa55","University of Texas, School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, 77030, TX, United States; Department of Management Science and Engineering, Zhejiang Sci-Tech University, Hangzhou, 310018, China; Department of Medical Informatics, School of Public Health, Jilin University, Changchun, Jilin, 130021, China","Du J., University of Texas, School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, 77030, TX, United States; Zhang Y., University of Texas, School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, 77030, TX, United States; Luo J., University of Texas, School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, 77030, TX, United States, Department of Management Science and Engineering, Zhejiang Sci-Tech University, Hangzhou, 310018, China; Jia Y., University of Texas, School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, 77030, TX, United States, Department of Medical Informatics, School of Public Health, Jilin University, Changchun, Jilin, 130021, China; Wei Q., University of Texas, School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, 77030, TX, United States; Tao C., University of Texas, School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, 77030, TX, United States; Xu H., University of Texas, School of Biomedical Informatics, 7000 Fannin St Suite 600, Houston, 77030, TX, United States","Background: Suicide has been one of the leading causes of deaths in the United States. One major cause of suicide is psychiatric stressors. The detection of psychiatric stressors in an at risk population will facilitate the early prevention of suicidal behaviors and suicide. In recent years, the widespread popularity and real-time information sharing flow of social media allow potential early intervention in a large-scale population. However, few automated approaches have been proposed to extract psychiatric stressors from Twitter. The goal of this study was to investigate techniques for recognizing suicide related psychiatric stressors from Twitter using deep learning based methods and transfer learning strategy which leverages an existing annotation dataset from clinical text. Methods: First, a dataset of suicide-related tweets was collected from Twitter streaming data with a multiple-step pipeline including keyword-based retrieving, filtering and further refining using an automated binary classifier. Specifically, a convolutional neural networks (CNN) based algorithm was used to build the binary classifier. Next, psychiatric stressors were annotated in the suicide-related tweets. The stressor recognition problem is conceptualized as a typical named entity recognition (NER) task and tackled using recurrent neural networks (RNN) based methods. Moreover, to reduce the annotation cost and improve the performance, transfer learning strategy was adopted by leveraging existing annotation from clinical text. Results & conclusions: To our best knowledge, this is the first effort to extract psychiatric stressors from Twitter data using deep learning based approaches. Comparison to traditional machine learning algorithms shows the superiority of deep learning based approaches. CNN is leading the performance at identifying suicide-related tweets with a precision of 78% and an F-1 measure of 83%, outperforming Support Vector Machine (SVM), Extra Trees (ET), etc. RNN based psychiatric stressors recognition obtains the best F-1 measure of 53.25% by exact match and 67.94% by inexact match, outperforming Conditional Random Fields (CRF). Moreover, transfer learning from clinical notes for the Twitter corpus outperforms the training with Twitter corpus only with an F-1 measure of 54.9% by exact match. The results indicate the advantages of deep learning based methods for the automated stressors recognition from social media. © 2018 The Author(s).","Deep learning; Mental health; Named entity recognition; Psychiatric stressors; Social media; Suicide","Algorithms; Deep Learning; Humans; Neural Networks (Computer); Social Media; Stress, Psychological; Suicide; algorithm; artificial neural network; human; mental stress; social media; suicide","BioMed Central Ltd","14726947","","","30066665","Article","Scopus","2-s2.0-85050815761"
"Chang P.; Zhang J.; Hu J.; Song Z.","Chang, Peiju (57196392769); Zhang, Jiangshe (9737712100); Hu, Junying (56729343000); Song, Zengjie (57193743313)","57196392769; 9737712100; 56729343000; 57193743313","A Deep Neural Network Based on ELM for Semi-supervised Learning of Image Classification","2018","Neural Processing Letters","12","10.1007/s11063-017-9709-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032805347&doi=10.1007%2fs11063-017-9709-0&partnerID=40&md5=93ab9c1d4f8fa68e7248e808ec1b0118","School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, 710049, China","Chang P., School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, 710049, China; Zhang J., School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, 710049, China; Hu J., School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, 710049, China; Song Z., School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, 710049, China","Deep learning has become one of very important machine learning methods in image classification, but most of them require a long training time to solve a non-convex optimization problem. In comparison, the training of extreme learning machine (ELM) is very simple, fast and effective. In order to combine the advantages of both methods, many researchers have tried to introduce ELM to deep architectures (Kasun et al. in IEEE Intell Syst 28:31–34, 2013; Yu et al. in Neurocomputing 149:308–315, 2015; Tissera and McDonnell in Neurocomputing 174:42–49, 2016 and in: Proceedings of ELM-2014, vol 1, Proceedings in adaptation, learning and optimization, vol 3, 2016; Junying et al. in Neurocomputing 171:63–72, 2016; Uzair et al. in Neural Comput Appl, 2015) to solve unsupervised learning and supervised learning problems. In this paper, we propose a new deep neural network based on ELM called discriminative deep ELM (DDELM) to address the semi-supervised learning problems in image classification. The proposed deep architecture consists of several stacked unsupervised ELMs and an additional label layer on the top layer of the stacked model. Experiments on three standard image data show that DDELM outperforms both representative semi-supervised learning algorithms and existing deep architectures such as DCNN in terms of accuracy and training time. © 2017, Springer Science+Business Media, LLC.","Deep learning; ELM; Image classification; Semi-supervised learning","Convex optimization; Deep learning; Image classification; Learning algorithms; Network architecture; Supervised learning; Deep architectures; Extreme learning machine; Machine learning methods; Neurocomputing; Nonconvex optimization; Semi- supervised learning; Standard images; Supervised learning problems; Deep neural networks","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-85032805347"
"Lee S.; Lee D.","Lee, Sangmok (57202711172); Lee, Donghyun (57092313500)","57202711172; 57092313500","Improved prediction of harmful algal blooms in four major South Korea’s rivers using deep learning models","2018","International Journal of Environmental Research and Public Health","106","10.3390/ijerph15071322","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049084393&doi=10.3390%2fijerph15071322&partnerID=40&md5=8615db83fda07886fe9a4283c3f109e1","Department of Business Administration, Korea Polytechnic University, 237, Sangidaehak-ro, Siheung-si, 15073, Gyeonggi-do, South Korea","Lee S., Department of Business Administration, Korea Polytechnic University, 237, Sangidaehak-ro, Siheung-si, 15073, Gyeonggi-do, South Korea; Lee D., Department of Business Administration, Korea Polytechnic University, 237, Sangidaehak-ro, Siheung-si, 15073, Gyeonggi-do, South Korea","Harmful algal blooms are an annual phenomenon that cause environmental damage, economic losses, and disease outbreaks. A fundamental solution to this problem is still lacking, thus, the best option for counteracting the effects of algal blooms is to improve advance warnings (predictions). However, existing physical prediction models have difficulties setting a clear coefficient indicating the relationship between each factor when predicting algal blooms, and many variable data sources are required for the analysis. These limitations are accompanied by high time and economic costs. Meanwhile, artificial intelligence and deep learning methods have become increasingly common in scientific research; attempts to apply the long short-term memory (LSTM) model to environmental research problems are increasing because the LSTM model exhibits good performance for time-series data prediction. However, few studies have applied deep learning models or LSTM to algal bloom prediction, especially in South Korea, where algal blooms occur annually. Therefore, we employed the LSTM model for algal bloom prediction in four major rivers of South Korea. We conducted short-term (one week) predictions by employing regression analysis and deep learning techniques on a newly constructed water quality and quantity dataset drawn from 16 dammed pools on the rivers. Three deep learning models (multilayer perceptron, MLP; recurrent neural network, RNN; and long short-term memory, LSTM) were used to predict chlorophyll-a, a recognized proxy for algal activity. The results were compared to those from OLS (ordinary least square) regression analysis and actual data based on the root mean square error (RSME). The LSTM model showed the highest prediction rate for harmful algal blooms and all deep learning models out-performed the OLS regression analysis. Our results reveal the potential for predicting algal blooms using LSTM and deep learning. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Algal blooms; Artificial intelligence; Chlorophyll-a; Deep learning; LSTM","Deep Learning; Harmful Algal Bloom; Models, Biological; Republic of Korea; Rivers; Water Quality; South Korea; algae; chlorophyll a; algal bloom; artificial intelligence; chlorophyll a; machine learning; prediction; river water; water quality; algal bloom; Article; artificial intelligence; artificial neural network; environmental impact; least square analysis; long short term memory; machine learning; perceptron; prediction; recurrent neural network; river; South Korea; time series analysis; water quality; biological model; water quality","MDPI AG","16617827","","","29937531","Article","Scopus","2-s2.0-85049084393"
"Lu Y.","Lu, Yi (57194620633)","57194620633","The association of urban greenness and walking behavior: Using google street view and deep learning techniques to estimate residents’ exposure to urban greenness","2018","International Journal of Environmental Research and Public Health","66","10.3390/ijerph15081576","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050682231&doi=10.3390%2fijerph15081576&partnerID=40&md5=85bd117111d46fb2df86e59200dd39e6","Department of Architecture and Civil Engineering, City University of Hong Kong, Hong Kong; City University of Hong Kong Shenzhen Research Institute, Shenzhen, 518057, Hong Kong","Lu Y., Department of Architecture and Civil Engineering, City University of Hong Kong, Hong Kong, City University of Hong Kong Shenzhen Research Institute, Shenzhen, 518057, Hong Kong","Many studies have established that urban greenness is associated with better health outcomes. Yet most studies assess urban greenness with overhead-view measures, such as park area or tree count, which often differs from the amount of greenness perceived by a person at eye-level on the ground. Furthermore, those studies are often criticized for the limitation of residential self-selection bias. In this study, urban greenness was extracted and assessed from profile view of streetscape images by Google Street View (GSV), in conjunction with deep learning techniques. We also explored a unique research opportunity arising in a citywide residential reallocation scheme of Hong Kong to reduce residential self-selection bias. Two multilevel regression analyses were conducted to examine the relationships between urban greenness and (1) the odds of walking for 24,773 public housing residents in Hong Kong, (2) total walking time of 1994 residents, while controlling for potential confounders. The results suggested that eye-level greenness was significantly related to higher odds of walking and longer walking time in both 400 m and 800 m buffers. Distance to the closest Mass Transit Rail (MTR) station was also associated with higher odds of walking. Number of shops was related to higher odds of walking in the 800 m buffer, but not in 400 m. Eye-level greenness, assessed by GSV images and deep learning techniques, can effectively estimate residents’ daily exposure to urban greenness, which is in turn associated with their walking behavior. Our findings apply to the entire public housing residents in Hong Kong, because of the large sample size. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Eye-level greenness; Physical activity; Street greenness; Urban greenness; Walking","Adult; Deep Learning; Environment Design; Female; Health Behavior; Hong Kong; Housing; Humans; Interviews as Topic; Male; Qualitative Research; Residence Characteristics; Surveys and Questionnaires; Urban Population; Viridiplantae; Walking; China; Hong Kong; digital map; greenspace; machine learning; physical activity; urban housing; walking; adolescent; adult; aged; Article; child; deep learning technique; environmental exposure; female; health behavior; Hong Kong; household income; housing; human; land use; male; middle aged; mobile application; physical activity; population density; residential area; statistical analysis; time; urban area; urban greenness; urban population; vegetation; walking; demography; environmental planning; growth, development and aging; interview; qualitative research; questionnaire; Viridiplantae","MDPI AG","16617827","","","30044417","Article","Scopus","2-s2.0-85050682231"
"Long F.","Long, Feixiao (56080699700)","56080699700","Deep learning-based mesoscopic fluorescence molecular tomography: An in silico study","2018","Journal of Medical Imaging","14","10.1117/1.JMI.5.3.036001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053355333&doi=10.1117%2f1.JMI.5.3.036001&partnerID=40&md5=4c61d45a68c02ab9688b8c5516db4235","Beijing QED Technique Co., Ltd., Beijing, China","Long F., Beijing QED Technique Co., Ltd., Beijing, China","Fluorescence molecular tomography (FMT), as well as mesoscopic FMT (MFMT) is widely employed to investigate molecular level processes ex vivo or in vivo. However, acquiring depth-localized and less blurry reconstruction still remains challenging, especially when fluorophore (dye) is located within large scattering coefficient media. Herein, a two-stage deep learning-based three-dimensional (3-D) reconstruction algorithm is proposed. The key point for the proposed algorithm is to employ a 3-D convolutional neural network to correctly predict the boundary of reconstructions, leading refined results. Compared with conventional algorithm, in silico experiments show that relative volume and absolute centroid error reduce over ∼50 % whereas intersection over union increases over 15% for most situations. These results preliminarily indicate the promising future of appropriately applying machine learning (deep learning)-based methods in MFMT. © 2018 Society of Photo-Optical Instrumentation Engineers (SPIE).","deep learning; image reconstruction; in silico experiments; mesoscopic fluorescence molecular tomography","Fluorescence; Image reconstruction; Neural networks; Superconducting materials; Tomography; Conventional algorithms; Convolutional neural network; Fluorescence molecular tomography; In-silico; Mesoscopic fluorescence molecular tomographies; Molecular levels; Scattering co-efficient; Three-dimensional (3-D) reconstruction; article; ex vivo study; fluorescence; human tissue; image reconstruction; in vivo study; machine learning; tomography; Deep learning","SPIE","23294302","","","","Article","Scopus","2-s2.0-85053355333"
"El Hatri C.; Boumhidi J.","El Hatri, Chaimae (57193029810); Boumhidi, Jaouad (16443952100)","57193029810; 16443952100","Fuzzy deep learning based urban traffic incident detection","2018","Cognitive Systems Research","51","10.1016/j.cogsys.2017.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038826829&doi=10.1016%2fj.cogsys.2017.12.002&partnerID=40&md5=a21ff71b4c8c6848764a73f5b17cdbe3","Computer Science Department, Sidi Mohamed Ben AbdEllah University, LIIAN Laboratory, Faculty of Sciences Dhar-Mahraz, Fez, 30000, Morocco","El Hatri C., Computer Science Department, Sidi Mohamed Ben AbdEllah University, LIIAN Laboratory, Faculty of Sciences Dhar-Mahraz, Fez, 30000, Morocco; Boumhidi J., Computer Science Department, Sidi Mohamed Ben AbdEllah University, LIIAN Laboratory, Faculty of Sciences Dhar-Mahraz, Fez, 30000, Morocco","Traffic incident detection (TID) is an important part of any modern traffic control because it offers an opportunity to maximise road system performance. For the complexity and the nonlinear characteristics of traffic incidents, this paper proposes a novel fuzzy deep learning based TID method which considers the spatial and temporal correlations of traffic flow inherently. Parameters of the deep network are initialized using a Stacked Auto-Encoder (SAE) model following a layer by layer pre-training procedure. To conduct the fine tuning step, the back-propagation algorithm is used to precisely adjust the parameters in the deep network. Fuzzy logic is employed to control the learning parameters where the objective is to reduce the possibility of overshooting during the learning process, increase the convergence speed and minimize the error. To find the best architecture of the deep network, we used a separate validation set to evaluate different architectures generated randomly based on the Mean Squared Error (MSE). Simulation results show that the proposed incident detection method has many advantages such as higher detection rate and lower false alarm rate. © 2017","Automatic traffic incident detection; Back-propagation algorithm; Deep artificial neural network; Fuzzy deep learning; Fuzzy logic controller; Stacked auto-encoder model","Backpropagation algorithms; Computer circuits; Fuzzy logic; Mean square error; Network architecture; Neural networks; Signal encoding; Traffic control; Auto encoders; Different architectures; Fuzzy logic controllers; Incident detection; Learning parameters; Nonlinear characteristics; Spatial and temporal correlation; Traffic incident detections; algorithm; Article; artificial neural network; back propagation; controlled study; fuzzy deep learning; fuzzy logic; information processing; limit of quantitation; machine learning; measurement accuracy; measurement precision; prediction; priority journal; simulation; traffic and transport; traffic incident detection; urban area; validation process; Deep learning","Elsevier B.V.","13890417","","CSROA","","Article","Scopus","2-s2.0-85038826829"
"Karimi D.; Samei G.; Kesch C.; Nir G.; Salcudean S.E.","Karimi, Davood (23569991400); Samei, Golnoosh (16231519700); Kesch, Claudia (56525275000); Nir, Guy (6506409148); Salcudean, Septimiu E. (7005922122)","23569991400; 16231519700; 56525275000; 6506409148; 7005922122","Prostate segmentation in MRI using a convolutional neural network architecture and training strategy based on statistical shape models","2018","International Journal of Computer Assisted Radiology and Surgery","67","10.1007/s11548-018-1785-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046899192&doi=10.1007%2fs11548-018-1785-8&partnerID=40&md5=f283d7ef4da5f421ff531c7a6e89b396","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; British Columbia Cancer Agency, Vancouver, BC, Canada; Department of Urologic Sciences, University of British Columbia, Vancouver, BC, Canada","Karimi D., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Samei G., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Kesch C., British Columbia Cancer Agency, Vancouver, BC, Canada; Nir G., Department of Urologic Sciences, University of British Columbia, Vancouver, BC, Canada; Salcudean S.E., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada","Purpose: Most of the existing convolutional neural network (CNN)-based medical image segmentation methods are based on methods that have originally been developed for segmentation of natural images. Therefore, they largely ignore the differences between the two domains, such as the smaller degree of variability in the shape and appearance of the target volume and the smaller amounts of training data in medical applications. We propose a CNN-based method for prostate segmentation in MRI that employs statistical shape models to address these issues. Methods: Our CNN predicts the location of the prostate center and the parameters of the shape model, which determine the position of prostate surface keypoints. To train such a large model for segmentation of 3D images using small data (1) we adopt a stage-wise training strategy by first training the network to predict the prostate center and subsequently adding modules for predicting the parameters of the shape model and prostate rotation, (2) we propose a data augmentation method whereby the training images and their prostate surface keypoints are deformed according to the displacements computed based on the shape model, and (3) we employ various regularization techniques. Results: Our proposed method achieves a Dice score of 0.88, which is obtained by using both elastic-net and spectral dropout for regularization. Compared with a standard CNN-based method, our method shows significantly better segmentation performance on the prostate base and apex. Our experiments also show that data augmentation using the shape model significantly improves the segmentation results. Conclusions: Prior knowledge about the shape of the target organ can improve the performance of CNN-based segmentation methods, especially where image features are not sufficient for a precise segmentation. Statistical shape models can also be employed to synthesize additional training data that can ease the training of large CNNs. © 2018, CARS.","Convolutional neural networks; Deep learning; Medical image segmentation; Prostate segmentation; Statistical shape models","Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Magnetic Resonance Imaging; Male; Models, Statistical; Neural Networks (Computer); Prostate; Article; convolutional neural network; human; image segmentation; machine learning; male; nuclear magnetic resonance imaging; principal component analysis; priority journal; prostate; surface property; artificial neural network; diagnostic imaging; image processing; nuclear magnetic resonance imaging; procedures; prostate; statistical model; three dimensional imaging","Springer Verlag","18616410","","","29766373","Article","Scopus","2-s2.0-85046899192"
"Prevost R.; Salehi M.; Jagoda S.; Kumar N.; Sprung J.; Ladikos A.; Bauer R.; Zettinig O.; Wein W.","Prevost, Raphael (36351109500); Salehi, Mehrdad (57014434300); Jagoda, Simon (57202590266); Kumar, Navneet (57202576243); Sprung, Julian (57195683142); Ladikos, Alexander (22234717500); Bauer, Robert (57195673711); Zettinig, Oliver (55785700900); Wein, Wolfgang (13906002800)","36351109500; 57014434300; 57202590266; 57202576243; 57195683142; 22234717500; 57195673711; 55785700900; 13906002800","3D freehand ultrasound without external tracking using deep learning","2018","Medical Image Analysis","88","10.1016/j.media.2018.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048755375&doi=10.1016%2fj.media.2018.06.003&partnerID=40&md5=29923c64a7189a6e0f95312404c2e041","ImFusion GmbH, Agnes-Pockels-Bogen 1, Munich, Germany; Computer Aided Medical Procedures (CAMP), TU Munich, Munich, Germany; Piur Imaging GmbH, Vienna, Austria","Prevost R., ImFusion GmbH, Agnes-Pockels-Bogen 1, Munich, Germany; Salehi M., ImFusion GmbH, Agnes-Pockels-Bogen 1, Munich, Germany, Computer Aided Medical Procedures (CAMP), TU Munich, Munich, Germany; Jagoda S., ImFusion GmbH, Agnes-Pockels-Bogen 1, Munich, Germany; Kumar N., ImFusion GmbH, Agnes-Pockels-Bogen 1, Munich, Germany; Sprung J., Piur Imaging GmbH, Vienna, Austria; Ladikos A., ImFusion GmbH, Agnes-Pockels-Bogen 1, Munich, Germany; Bauer R., Piur Imaging GmbH, Vienna, Austria; Zettinig O., ImFusion GmbH, Agnes-Pockels-Bogen 1, Munich, Germany; Wein W., ImFusion GmbH, Agnes-Pockels-Bogen 1, Munich, Germany","This work aims at creating 3D freehand ultrasound reconstructions from 2D probes with image-based tracking, therefore not requiring expensive or cumbersome external tracking hardware. Existing model-based approaches such as speckle decorrelation only partially capture the underlying complexity of ultrasound image formation, thus producing reconstruction accuracies incompatible with current clinical requirements. Here, we introduce an alternative approach that relies on a statistical analysis rather than physical models, and use a convolutional neural network (CNN) to directly estimate the motion of successive ultrasound frames in an end-to-end fashion. We demonstrate how this technique is related to prior approaches, and derive how to further improve its predictive capabilities by incorporating additional information such as data from inertial measurement units (IMU). This novel method is thoroughly evaluated and analyzed on a dataset of 800 in vivo ultrasound sweeps, yielding unprecedentedly accurate reconstructions with a median normalized drift of 5.2%. Even on long sweeps exceeding 20 cm with complex trajectories, this allows to obtain length measurements with median errors of 3.4%, hence paving the way toward translation into clinical routine. © 2018 Elsevier B.V.","3D freehand ultrasound; Deep learning; Inertial measurement unit; Motion estimation","Algorithms; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Ultrasonography; Complex networks; Image reconstruction; Motion estimation; Neural networks; Repair; Ultrasonic applications; 3D freehand; Convolutional Neural Networks (CNN); Inertial measurement unit; Inertial Measurement Unit (IMU); Model based approach; Predictive capabilities; Reconstruction accuracy; Speckle decorrelation; acceleration; algorithm; Article; comparative study; controlled study; human; learning; machine learning; motion; normal human; physical model; priority journal; rotation; three dimensional imaging; ultrasound; computer assisted diagnosis; echography; procedures; three dimensional imaging; Deep learning","Elsevier B.V.","13618415","","MIAEC","29936399","Article","Scopus","2-s2.0-85048755375"
"Biswas M.; Kuppili V.; Araki T.; Edla D.R.; Godia E.C.; Saba L.; Suri H.S.; Omerzu T.; Laird J.R.; Khanna N.N.; Nicolaides A.; Suri J.S.","Biswas, Mainak (57195430754); Kuppili, Venkatanareshbabu (54784668100); Araki, Tadashi (35557901200); Edla, Damodar Reddy (55180602300); Godia, Elisa Cuadrado (16063934800); Saba, Luca (16234937700); Suri, Harman S. (57189698139); Omerzu, Tomaž (57202119515); Laird, John R. (7102409727); Khanna, Narendra N. (57194207803); Nicolaides, Andrew (35419962500); Suri, Jasjit S. (7005613223)","57195430754; 54784668100; 35557901200; 55180602300; 16063934800; 16234937700; 57189698139; 57202119515; 7102409727; 57194207803; 35419962500; 7005613223","Deep learning strategy for accurate carotid intima-media thickness measurement: An ultrasound study on Japanese diabetic cohort","2018","Computers in Biology and Medicine","77","10.1016/j.compbiomed.2018.05.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047207454&doi=10.1016%2fj.compbiomed.2018.05.014&partnerID=40&md5=a3a00d74e497c8d3c0318ae292e14d89","National Institute of Technology Goa, India; Toho University Ohashi Medical Center, Tokyo, Japan; IMIM – Hospital del Mar, Passeig Marítim 25-29, Barcelona, Spain; Department of Radiology, Policlinico Universitario, Cagliari, Italy; Brown University, Providence, RI, United States; Department of Neurology, University Medical Centre Maribor, Slovenia; Cardiology Department, St. Helena Hospital, St. Helena, CA, United States; Cardiology Department, Apollo Hospitals, New Delhi, India; Vascular Screening and Diagnostic Centre, London, United Kingdom; Department of Biological Sciences, University of Cyprus, Nicosia, Cyprus; Stroke Monitoring and Diagnostic Division, AtheroPoint™, Roseville, CA, United States","Biswas M., National Institute of Technology Goa, India; Kuppili V., National Institute of Technology Goa, India; Araki T., Toho University Ohashi Medical Center, Tokyo, Japan; Edla D.R., National Institute of Technology Goa, India; Godia E.C., IMIM – Hospital del Mar, Passeig Marítim 25-29, Barcelona, Spain; Saba L., Department of Radiology, Policlinico Universitario, Cagliari, Italy; Suri H.S., Brown University, Providence, RI, United States; Omerzu T., Department of Neurology, University Medical Centre Maribor, Slovenia; Laird J.R., Cardiology Department, St. Helena Hospital, St. Helena, CA, United States; Khanna N.N., Cardiology Department, Apollo Hospitals, New Delhi, India; Nicolaides A., Vascular Screening and Diagnostic Centre, London, United Kingdom, Department of Biological Sciences, University of Cyprus, Nicosia, Cyprus; Suri J.S., Stroke Monitoring and Diagnostic Division, AtheroPoint™, Roseville, CA, United States","Motivation: The carotid intima-media thickness (cIMT) is an important biomarker for cardiovascular diseases and stroke monitoring. This study presents an intelligence-based, novel, robust, and clinically-strong strategy that uses a combination of deep-learning (DL) and machine-learning (ML) paradigms. Methodology: A two-stage DL-based system (a class of AtheroEdge™ systems) was proposed for cIMT measurements. Stage I consisted of a convolution layer-based encoder for feature extraction and a fully convolutional network-based decoder for image segmentation. This stage generated the raw inner lumen borders and raw outer interadventitial borders. To smooth these borders, the DL system used a cascaded stage II that consisted of ML-based regression. The final outputs were the far wall lumen-intima (LI) and media-adventitia (MA) borders which were used for cIMT measurements. There were two sets of gold standards during the DL design, therefore two sets of DL systems (DL1 and DL2) were derived. Results: A total of 396 B-mode ultrasound images of the right and left common carotid artery were used from 203 patients (Institutional Review Board approved, Toho University, Japan). For the test set, the cIMT error for the DL1 and DL2 systems with respect to the gold standard was 0.126 ± 0.134 and 0.124 ± 0.100 mm, respectively. The corresponding LI error for the DL1 and DL2 systems was 0.077 ± 0.057 and 0.077 ± 0.049 mm, respectively, while the corresponding MA error for DL1 and DL2 was 0.113 ± 0.105 and 0.109 ± 0.088 mm, respectively. The results showed up to 20% improvement in cIMT readings for the DL system compared to the sonographer's readings. Four statistical tests were conducted to evaluate reliability, stability, and statistical significance. Conclusion: The results showed that the performance of the DL-based approach was superior to the nonintelligence-based conventional methods that use spatial intensities alone. The DL system can be used for stroke risk assessment during routine or clinical trial modes. © 2018 Elsevier Ltd","Accurate; Cardiovascular diseases; Carotid intima-media thickness; Deep learning; Intelligence; Machine learning; Reproducible; Segmentation; Stroke; Ultrasound scans","Aged; Aged, 80 and over; Carotid Arteries; Carotid Artery Diseases; Carotid Intima-Media Thickness; Cohort Studies; Databases, Factual; Deep Learning; Diabetes Complications; Female; Humans; Image Interpretation, Computer-Assisted; Japan; Male; ROC Curve; Ultrasonography; Artificial intelligence; Cardiology; Convolution; Diseases; Errors; Image segmentation; Learning systems; Risk assessment; Thickness measurement; Ultrasonics; cholesterol; high density lipoprotein cholesterol; low density lipoprotein cholesterol; Accurate; Cardio-vascular disease; Carotid intima-media thickness; Intelligence; Reproducible; Stroke; Ultrasound scans; aged; area under the curve; arterial wall thickness; Article; benchmarking; carotid artery; cholesterol blood level; cholesterol level; clinical evaluation; cohort analysis; comparative study; deep learning; diabetes mellitus; diagnostic test accuracy study; feature extraction; female; gold standard; high risk patient; human; image segmentation; information processing; Japanese (people); left common carotid artery; lumen intima; machine learning; major clinical study; male; measurement error; media adventitia; null hypothesis; priority journal; receiver operating characteristic; right common carotid artery; smoking; ultrasound; carotid artery disease; computer assisted diagnosis; diabetic complication; diagnostic imaging; echography; factual database; Japan; procedures; very elderly; Deep learning","Elsevier Ltd","00104825","","CBMDA","29778925","Article","Scopus","2-s2.0-85047207454"
"Tsiouris Κ.Μ.; Pezoulas V.C.; Zervakis M.; Konitsiotis S.; Koutsouris D.D.; Fotiadis D.I.","Tsiouris, Κostas Μ. (56252054300); Pezoulas, Vasileios C. (57194013364); Zervakis, Michalis (55797185300); Konitsiotis, Spiros (21733777500); Koutsouris, Dimitrios D. (8349801800); Fotiadis, Dimitrios I. (55938920100)","56252054300; 57194013364; 55797185300; 21733777500; 8349801800; 55938920100","A Long Short-Term Memory deep learning network for the prediction of epileptic seizures using EEG signals","2018","Computers in Biology and Medicine","393","10.1016/j.compbiomed.2018.05.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047625904&doi=10.1016%2fj.compbiomed.2018.05.019&partnerID=40&md5=f3227757fe50948202c96236975a2268","Biomedical Engineering Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens, Athens, GR15773, Greece; Unit of Medical Technology and Intelligent Information Systems, Dept. of Material Science and Engineering, University of Ioannina, Ioannina, GR45110, Greece; Digital Image and Signal Processing Laboratory, School of Electrical and Computer Engineering Technical University of Crete, Chania, Greece; Dept. of Neurology, Medical School, University of Ioannina, Ioannina, GR45110, Greece; Dept. of Biomedical Research, Institute of Molecular Biology and Biotechnology, FORTH, Ioannina, GR45110, Greece","Tsiouris Κ.Μ., Biomedical Engineering Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens, Athens, GR15773, Greece, Unit of Medical Technology and Intelligent Information Systems, Dept. of Material Science and Engineering, University of Ioannina, Ioannina, GR45110, Greece; Pezoulas V.C., Unit of Medical Technology and Intelligent Information Systems, Dept. of Material Science and Engineering, University of Ioannina, Ioannina, GR45110, Greece; Zervakis M., Digital Image and Signal Processing Laboratory, School of Electrical and Computer Engineering Technical University of Crete, Chania, Greece; Konitsiotis S., Dept. of Neurology, Medical School, University of Ioannina, Ioannina, GR45110, Greece; Koutsouris D.D., Biomedical Engineering Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens, Athens, GR15773, Greece; Fotiadis D.I., Unit of Medical Technology and Intelligent Information Systems, Dept. of Material Science and Engineering, University of Ioannina, Ioannina, GR45110, Greece, Dept. of Biomedical Research, Institute of Molecular Biology and Biotechnology, FORTH, Ioannina, GR45110, Greece","The electroencephalogram (EEG) is the most prominent means to study epilepsy and capture changes in electrical brain activity that could declare an imminent seizure. In this work, Long Short-Term Memory (LSTM) networks are introduced in epileptic seizure prediction using EEG signals, expanding the use of deep learning algorithms with convolutional neural networks (CNN). A pre-analysis is initially performed to find the optimal architecture of the LSTM network by testing several modules and layers of memory units. Based on these results, a two-layer LSTM network is selected to evaluate seizure prediction performance using four different lengths of preictal windows, ranging from 15 min to 2 h. The LSTM model exploits a wide range of features extracted prior to classification, including time and frequency domain features, between EEG channels cross-correlation and graph theoretic features. The evaluation is performed using long-term EEG recordings from the open CHB-MIT Scalp EEG database, suggest that the proposed methodology is able to predict all 185 seizures, providing high rates of seizure prediction sensitivity and low false prediction rates (FPR) of 0.11–0.02 false alarms per hour, depending on the duration of the preictal window. The proposed LSTM-based methodology delivers a significant increase in seizure prediction performance compared to both traditional machine learning techniques and convolutional neural networks that have been previously evaluated in the literature. © 2018 Elsevier Ltd","Deep learning; EEG; Epilepsy; LSTM model; Seizure prediction","Adolescent; Adult; Algorithms; Child; Child, Preschool; Deep Learning; Electroencephalography; Female; Humans; Male; Predictive Value of Tests; Seizures; Brain; Convolution; Deep learning; Electroencephalography; Forecasting; Frequency domain analysis; Graph theory; Learning algorithms; Network layers; Neurophysiology; Convolutional neural network; Convolutional Neural Networks (CNN); Electro-encephalogram (EEG); Epilepsy; Epileptic seizure prediction; Machine learning techniques; Seizure prediction; Time and frequency domains; adolescent; adult; Article; Bayesian learning; child; classification algorithm; clinical article; comparative study; computer assisted diagnosis; convolutional neural network; decision tree; deep learning network; electroencephalogram; false negative result; false positive result; feature extraction; female; frequency domain feature; functional connectivity; human; image analysis; intractable epilepsy; learning algorithm; long term memory; machine learning; male; OneR algorithm; predictive value; preschool child; priority journal; school child; sensitivity and specificity; short term memory; signal processing; support vector machine; time domain feature; wavelet transformation; young adult; algorithm; electroencephalography; pathophysiology; seizure; Long short-term memory","Elsevier Ltd","00104825","","CBMDA","29807250","Article","Scopus","2-s2.0-85047625904"
"Passos L.A., Jr.; Papa J.P.","Passos, Leandro Aparecido (56902376500); Papa, João Paulo (23397842300)","56902376500; 23397842300","Temperature-Based Deep Boltzmann Machines","2018","Neural Processing Letters","10","10.1007/s11063-017-9707-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028973130&doi=10.1007%2fs11063-017-9707-2&partnerID=40&md5=8593f1d8075cf393e0927a5ea840d5f4","Department of Computing, Federal University of São Carlos, São Carlos, Brazil; Department of Computing, São Paulo State University, Bauru, Brazil","Passos L.A., Jr., Department of Computing, Federal University of São Carlos, São Carlos, Brazil; Papa J.P., Department of Computing, São Paulo State University, Bauru, Brazil","Deep learning techniques have been paramount in the last years, mainly due to their outstanding results in a number of applications, that range from speech recognition to face-based user identification. Despite other techniques employed for such purposes, Deep Boltzmann Machines (DBMs) are among the most used ones, which are composed of layers of Restricted Boltzmann Machines stacked on top of each other. In this work, we evaluate the concept of temperature in DBMs, which play a key role in Boltzmann-related distributions, but it has never been considered in this context up to date. Therefore, the main contribution of this paper is to take into account this information, as well as the impact of replacing a standard Sigmoid function by another one and to evaluate their influence in DBMs considering the task of binary image reconstruction. We expect this work can foster future research considering the usage of different temperatures during learning in DBMs. © 2017, Springer Science+Business Media, LLC.","Deep Boltzmann Machines; Deep Learning; Machine learning","Binary images; Image reconstruction; Learning systems; Speech recognition; Boltzmann; Deep boltzmann machines; Learning techniques; Restricted boltzmann machine; Sigmoid function; User identification; Deep learning","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-85028973130"
"Abarbanel H.D.I.; Rozdeba P.J.; Shirman S.","Abarbanel, Henry D.I. (24578431400); Rozdeba, Paul J. (35206931900); Shirman, Sasha (57195806979)","24578431400; 35206931900; 57195806979","Machine Learning: Deepest learning as statistical data assimilation problems","2018","Neural Computation","48","10.1162/neco_a_01094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050148921&doi=10.1162%2fneco_a_01094&partnerID=40&md5=cb6c5dc0abf5caeb743b27aaa34a706d","Marine Physical Laboratory, Scripps Institution of Oceanography, Department of Physics, University of California, San Diego, La Jolla, 92093-0374, CA, United States; Department of Physics, University of California, San Diego, La Jolla, 92093-0374, CA, United States","Abarbanel H.D.I., Marine Physical Laboratory, Scripps Institution of Oceanography, Department of Physics, University of California, San Diego, La Jolla, 92093-0374, CA, United States; Rozdeba P.J., Department of Physics, University of California, San Diego, La Jolla, 92093-0374, CA, United States; Shirman S., Department of Physics, University of California, San Diego, La Jolla, 92093-0374, CA, United States","We formulate an equivalence between machine learning and the formulation of statistical data assimilation as usedwidely in physical and biological sciences. The correspondence is that layer number in a feedforward artificial network setting is the analog of time in the data assimilation setting. This connection has been noted in the machine learning literature. We add a perspective that expands on how methods from statistical physics and aspects of Lagrangian andHamiltonian dynamics play a role in how networks can be trained and designed. Within the discussion of this equivalence, we show that adding more layers (making the network deeper) is analogous to adding temporal resolution in a data assimilation framework. Extending this equivalence to recurrent networks is also discussed. We explore how one can find a candidate for the global minimum of the cost functions in the machine learning context using a method from data assimilation. Calculations on simple models from both sides of the equivalence are reported. Also discussed is a framework in which the time or layer label is taken to be continuous, providing a differential equation, the Euler-Lagrange equation and its boundary conditions, as a necessary condition for aminimum of the cost function. This shows that the problem being solved is a two-point boundary value problem familiar in the discussion of variational methods. The use of continuous layers is denoted ""deepest learning."" These problems respect a symplectic symmetry in continuous layer phase space. Both Lagrangian versions andHamiltonian versions of these problems are presented. Their well-studied implementation in a discrete time/layer, while respecting the symplectic structure, is addressed. The Hamiltonian version provides a direct rationale for backpropagation as a solution method for a certain two-point boundary value problem. © 2018 Massachusetts Institute of Technology.","","Artificial intelligence; Boundary conditions; Boundary value problems; Cost functions; Equations of motion; Lagrange multipliers; Object oriented programming; Phase space methods; Statistical Physics; Statistics; Artificial networks; Biological science; Euler-Lagrange equations; Machine learning literature; Recurrent networks; Temporal resolution; Two point boundary value problems; Variational methods; Learning systems","MIT Press Journals","08997667","","","29894650","Article","Scopus","2-s2.0-85050148921"
"Esfandiari H.; Newell R.; Anglin C.; Street J.; Hodgson A.J.","Esfandiari, Hooman (56539790200); Newell, Robyn (55330373400); Anglin, Carolyn (7006857151); Street, John (35273456800); Hodgson, Antony J. (7101639293)","56539790200; 55330373400; 7006857151; 35273456800; 7101639293","A deep learning framework for segmentation and pose estimation of pedicle screw implants based on C-arm fluoroscopy","2018","International Journal of Computer Assisted Radiology and Surgery","37","10.1007/s11548-018-1776-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047659026&doi=10.1007%2fs11548-018-1776-9&partnerID=40&md5=7a702ac823c727fe483991ed5d5d227f","Biomedical Engineering, Surgical Technologies Lab, Robert H.N. Ho Research Centre, University of British Columbia, 6th Floor, 2635 Laurel St, Vancouver, V5Z 1M9, BC, Canada; Biomedical Engineering, Surgical Technologies Lab, University of British Columbia, Vancouver, Canada; Biomedical Engineering, Civil Engineering, McCaig Institute for Bone and Joint Health, University of Calgary, Calgary, Canada; Combined Neurosurgical and Orthopaedic Spine Program, University of British Columbia, Vancouver, Canada; Department of Mechanical Engineering, Biomedical Engineering, Surgical Technologies Lab, University of British Columbia, Vancouver, Canada","Esfandiari H., Biomedical Engineering, Surgical Technologies Lab, Robert H.N. Ho Research Centre, University of British Columbia, 6th Floor, 2635 Laurel St, Vancouver, V5Z 1M9, BC, Canada; Newell R., Biomedical Engineering, Surgical Technologies Lab, University of British Columbia, Vancouver, Canada; Anglin C., Biomedical Engineering, Civil Engineering, McCaig Institute for Bone and Joint Health, University of Calgary, Calgary, Canada; Street J., Combined Neurosurgical and Orthopaedic Spine Program, University of British Columbia, Vancouver, Canada; Hodgson A.J., Department of Mechanical Engineering, Biomedical Engineering, Surgical Technologies Lab, University of British Columbia, Vancouver, Canada","Purpose: Pedicle screw fixation is a challenging procedure with a concerning rates of reoperation. After insertion of the screws is completed, the most common intraoperative verification approach is to acquire anterior–posterior and lateral radiographic images, based on which the surgeons try to visually assess the correctness of insertion. Given the limited accuracy of the existing verification techniques, we identified the need for an accurate and automated pedicle screw assessment system that can verify the screw insertion intraoperatively. For doing so, this paper offers a framework for automatic segmentation and pose estimation of pedicle screws based on deep learning principles. Methods: Segmentation of pedicle screw X-ray projections was performed by a convolutional neural network. The network could isolate the input X-rays into three classes: screw head, screw shaft and background. Once all the screw shafts were segmented, knowledge about the spatial configuration of the acquired biplanar X-rays was used to identify the correspondence between the projections. Pose estimation was then performed to estimate the 6 degree-of-freedom pose of each screw. The performance of the proposed pose estimation method was tested on a porcine specimen. Results: The developed machine learning framework was capable of segmenting the screw shafts with 93% and 83% accuracy when tested on synthetic X-rays and on clinically realistic X-rays, respectively. The pose estimation accuracy of this method was shown to be 1. 93 ∘± 0. 64 ∘ and 1.92±0.55mm on clinically realistic X-rays. Conclusions: The proposed system offers an accurate and fully automatic pedicle screw segmentation and pose assessment framework. Such a system can help to provide an intraoperative pedicle screw insertion assessment protocol with minimal interference with the existing surgical routines. © 2018, CARS.","Convolutional neural networks; Deep learning; Pedicle screw; Pose estimation; Segmentation; Surgical navigation","accuracy; algorithm; anatomical concepts; Article; artificial neural network; bone radiography; calibration; contrast enhancement; fluoroscopy; image processing; image segmentation; machine learning; manual labor; priority journal; radiation exposure","Springer Verlag","18616410","","","","Article","Scopus","2-s2.0-85047659026"
"Stettler M.; Francis G.","Stettler, Michael (57201876027); Francis, Gregory (35748500900)","57201876027; 35748500900","Using a model of human visual perception to improve deep learning","2018","Neural Networks","13","10.1016/j.neunet.2018.04.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046341555&doi=10.1016%2fj.neunet.2018.04.005&partnerID=40&md5=410ef308947edbe0f41e60812e501822","École Polytechnique Fédérale de Lausanne (EPFL), Switzerland; Purdue University, Department of Psychological Sciences, 703 Third Street, West Lafayette, IN 47906, United States","Stettler M., École Polytechnique Fédérale de Lausanne (EPFL), Switzerland; Purdue University, Department of Psychological Sciences, 703 Third Street, West Lafayette, IN 47906, United States; Francis G., École Polytechnique Fédérale de Lausanne (EPFL), Switzerland; Purdue University, Department of Psychological Sciences, 703 Third Street, West Lafayette, IN 47906, United States","Deep learning algorithms achieve human-level (or better) performance on many tasks, but there still remain situations where humans learn better or faster. With regard to classification of images, we argue that some of those situations are because the human visual system represents information in a format that promotes good training and classification. To demonstrate this idea, we show how occluding objects can impair performance of a deep learning system that is trained to classify digits in the MNIST database. We describe a human inspired segmentation and interpolation algorithm that attempts to reconstruct occluded parts of an image, and we show that using this reconstruction algorithm to pre-process occluded images promotes training and classification performance. © 2018 Elsevier Ltd","Deep learning; Segmentation; Visual perception","Humans; Machine Learning; Models, Neurological; Neural Networks (Computer); Visual Perception; Classification (of information); Image classification; Image segmentation; Learning algorithms; Vision; Classification performance; Human levels; Human visual perception; Human Visual System; Interpolation algorithms; Mnist database; Reconstruction algorithms; Visual perception; Article; human; image analysis; image enhancement; image reconstruction; learning algorithm; machine learning; nerve cell network; novel object recognition test; priority journal; training; vision; visual system; artificial neural network; biological model; machine learning; Deep learning","Elsevier Ltd","08936080","","NNETE","29705669","Article","Scopus","2-s2.0-85046341555"
"Zhu H.; Chen H.; Brown R.","Zhu, Hongyi (56304013300); Chen, Hsinchun (8871373800); Brown, Randall (56088310800)","56304013300; 8871373800; 56088310800","A sequence-to-sequence model-based deep learning approach for recognizing activity of daily living for senior care","2018","Journal of Biomedical Informatics","29","10.1016/j.jbi.2018.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049609979&doi=10.1016%2fj.jbi.2018.07.006&partnerID=40&md5=bfa9014aafc5cc9fd51c8a6e2ee32959","Department of Management Information Systems, University of Arizona, Tucson, AZ, United States","Zhu H., Department of Management Information Systems, University of Arizona, Tucson, AZ, United States; Chen H., Department of Management Information Systems, University of Arizona, Tucson, AZ, United States; Brown R., Department of Management Information Systems, University of Arizona, Tucson, AZ, United States","Ensuring the health and safety of independent-living senior citizens is a growing societal concern. Researchers have developed sensor based systems to monitor senior citizens’ Activity of Daily Living (ADL), a set of daily activities that can indicate their self-caring ability. However, most ADL monitoring systems are designed for one specific sensor modality, resulting in less generalizable models that is not flexible to account variations in real-life monitoring settings. Current classic machine learning and deep learning methods do not provide a generalizable solution to recognize complex ADLs for different sensor settings. This study proposes a novel Sequence-to-Sequence model based deep-learning framework to recognize complex ADLs leveraging an activity state representation. The proposed activity state representation integrated motion and environment sensor data without labor-intense feature engineering. We evaluated our proposed framework against several state-of-the-art machine learning and deep learning benchmarks. Overall, our approach outperformed baselines in most performance metrics, accurately recognized complex ADLs from different types of sensor input. This framework can generalize to different sensor settings and provide a viable approach to understand senior citizen's daily activity patterns with smart home health monitoring systems. © 2018 Elsevier Inc.","Activity of daily living; Activity state representation; ADL recognition; Deep learning; Sequence-to-sequence model","Activities of Daily Living; Aged; Algorithms; Assisted Living Facilities; Data Mining; Deep Learning; Disease Progression; Health Services for the Aged; Humans; Monitoring, Ambulatory; Neural Networks (Computer); Pattern Recognition, Automated; Artificial intelligence; Automation; Intelligent buildings; Monitoring; Activity of daily livings; ADL recognition; Daily activity patterns; Feature engineerings; Learning frameworks; Sensor based systems; Sequence modeling; State representation; aged; Article; benchmarking; controlled study; daily life activity; deep learning; elderly care; engineering; home care; human; machine learning; priority journal; telemonitoring; algorithm; ambulatory monitoring; artificial neural network; assisted living facility; automated pattern recognition; data mining; disease exacerbation; elderly care; procedures; Deep learning","Academic Press Inc.","15320464","","JBIOB","30004019","Article","Scopus","2-s2.0-85049609979"
"Akula A.; Shah A.K.; Ghosh R.","Akula, Aparna (54402310000); Shah, Anuj K. (57201996977); Ghosh, Ripul (54402719000)","54402310000; 57201996977; 54402719000","Deep learning approach for human action recognition in infrared images","2018","Cognitive Systems Research","98","10.1016/j.cogsys.2018.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046832116&doi=10.1016%2fj.cogsys.2018.04.002&partnerID=40&md5=d93a6a3a6dd0e6639306f7c2dad4e29b","Academy of Scientific and Innovative Research (AcSIR), Rafi Marg, New Delhi, 110001, India; CSIR–Central Scientific Instruments Organisation, Chandigarh, 160030, India; School of Mechatronics and Robotics, Indian Institute of Engineering Science and Technology, Shibpur, India","Akula A., Academy of Scientific and Innovative Research (AcSIR), Rafi Marg, New Delhi, 110001, India, CSIR–Central Scientific Instruments Organisation, Chandigarh, 160030, India; Shah A.K., School of Mechatronics and Robotics, Indian Institute of Engineering Science and Technology, Shibpur, India; Ghosh R., Academy of Scientific and Innovative Research (AcSIR), Rafi Marg, New Delhi, 110001, India, CSIR–Central Scientific Instruments Organisation, Chandigarh, 160030, India","Human action recognition based Ambient assisted living (AAL) systems, targeted towards providing assistance for the elderly and persons with disabilities, have been of interest to researchers from various disciplines. The research primarily focuses on development of automatic, minimally intrusive and privacy preserving systems. Although popular in the strategic sector, thermal infrared (IR) cameras haven't been explored much in AAL. This work demonstrates the use of IR cameras in the field of AAL and discusses its performance in human action recognition (HAR). Particular attention is drawn towards one of the most critical actions - falling. In this reference, a dataset of IR images was generated comprising of 6 action classes – walking, standing, sitting on a chair, sitting on a chair with a desk in front, fallen on the desk in front and fallen/lying on the ground. The dataset comprises of 5278 image samples which have been randomly sampled from thermal videos, each of about 30 s, representing the six action classes. To achieve robust action recognition, we have designed the supervised Convolution Neural Network (CNN) architecture with two convolution layers to classify the 6 action classes. Classification accuracy of 87.44% has been achieved on the manually selected complex test data. © 2018 Elsevier B.V.","Action recognition; CNN; Convolution; Deep learning; Infrared","Assisted living; Cameras; Convolution; Data privacy; Infrared imaging; Infrared radiation; Action recognition; Ambient assisted living (AAL); Classification accuracy; Convolution neural network; Human-action recognition; Learning approach; Persons with disabilities; Privacy preserving; adult; Ambient assisted living; architecture; Article; artificial neural network; convolution neural network; deep learning method; fallen on the desk in front; falling; female; human; human action recognition; human experiment; image analysis; information processing; lying on the ground; machine learning; male; physical activity; priority journal; recognition; sample; sitting on a chair; sitting on a chair with a desk in front; standing; thermography; videorecording; walking; Deep learning","Elsevier B.V.","13890417","","CSROA","","Article","Scopus","2-s2.0-85046832116"
"Kim G.B.; Jung K.-H.; Lee Y.; Kim H.-J.; Kim N.; Jun S.; Seo J.B.; Lynch D.A.","Kim, Guk Bae (56675071100); Jung, Kyu-Hwan (14037142200); Lee, Yeha (58366458900); Kim, Hyun-Jun (57196059046); Kim, Namkug (16550058300); Jun, Sanghoon (57193380681); Seo, Joon Beom (55512425800); Lynch, David A. (26642896600)","56675071100; 14037142200; 58366458900; 57196059046; 16550058300; 57193380681; 55512425800; 26642896600","Comparison of Shallow and Deep Learning Methods on Classifying the Regional Pattern of Diffuse Lung Disease","2018","Journal of Digital Imaging","68","10.1007/s10278-017-0028-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031507028&doi=10.1007%2fs10278-017-0028-9&partnerID=40&md5=d12c96b14f74aafab34f8571b08c00a5","Biomedical Engineering Research Center, Asan Institute of Life Science, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, South Korea; VUNO, 6F, 507, Gangnamdae-ro, Seocho-gu, Seoul, South Korea; Department of Convergence Medicine, University of Ulsan College of Medicine, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, 138-736, South Korea; Department of Radiology, University of Ulsan College of Medicine, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, 138-736, South Korea; Department of Radiology, National Jewish Medical and Research Center, Denver, CO, United States","Kim G.B., Biomedical Engineering Research Center, Asan Institute of Life Science, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, South Korea; Jung K.-H., VUNO, 6F, 507, Gangnamdae-ro, Seocho-gu, Seoul, South Korea; Lee Y., VUNO, 6F, 507, Gangnamdae-ro, Seocho-gu, Seoul, South Korea; Kim H.-J., VUNO, 6F, 507, Gangnamdae-ro, Seocho-gu, Seoul, South Korea; Kim N., Department of Convergence Medicine, University of Ulsan College of Medicine, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, 138-736, South Korea; Jun S., Department of Convergence Medicine, University of Ulsan College of Medicine, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, 138-736, South Korea; Seo J.B., Department of Radiology, University of Ulsan College of Medicine, Asan Medical Center, 388-1 Pungnap2-dong, Songpa-gu, Seoul, 138-736, South Korea; Lynch D.A., Department of Radiology, National Jewish Medical and Research Center, Denver, CO, United States","This study aimed to compare shallow and deep learning of classifying the patterns of interstitial lung diseases (ILDs). Using high-resolution computed tomography images, two experienced radiologists marked 1200 regions of interest (ROIs), in which 600 ROIs were each acquired using a GE or Siemens scanner and each group of 600 ROIs consisted of 100 ROIs for subregions that included normal and five regional pulmonary disease patterns (ground-glass opacity, consolidation, reticular opacity, emphysema, and honeycombing). We employed the convolution neural network (CNN) with six learnable layers that consisted of four convolution layers and two fully connected layers. The classification results were compared with the results classified by a shallow learning of a support vector machine (SVM). The CNN classifier showed significantly better performance for accuracy compared with that of the SVM classifier by 6–9%. As the convolution layer increases, the classification accuracy of the CNN showed better performance from 81.27 to 95.12%. Especially in the cases showing pathological ambiguity such as between normal and emphysema cases or between honeycombing and reticular opacity cases, the increment of the convolution layer greatly drops the misclassification rate between each case. Conclusively, the CNN classifier showed significantly greater accuracy than the SVM classifier, and the results implied structural characteristics that are inherent to the specific ILD patterns. © 2017, Society for Imaging Informatics in Medicine.","Convolution neural network; Deep architecture; Interscanner variation; Interstitial lung disease; Support vector machine","Algorithms; Cohort Studies; Deep Learning; Female; Humans; Lung Diseases, Interstitial; Male; Neural Networks (Computer); Pattern Recognition, Automated; Retrospective Studies; Tomography, X-Ray Computed; Biological organs; Computerized tomography; Convolution; Opacity; Pulmonary diseases; Support vector machines; Classification accuracy; Convolution neural network; Deep architectures; High-resolution computed tomography; Interscanner variation; Interstitial lung disease; Misclassification rates; Structural characteristics; algorithm; artificial neural network; automated pattern recognition; classification; cohort analysis; comparative study; diagnostic imaging; female; human; interstitial lung disease; male; pathology; procedures; retrospective study; x-ray computed tomography; Deep learning","Springer New York LLC","08971889","","JDIME","29043528","Article","Scopus","2-s2.0-85031507028"
"Robinson J.R.; Wei W.-Q.; Roden D.M.; Denny J.C.","Robinson, Jamie R. (57189213780); Wei, Wei-Qi (57212895740); Roden, Dan M. (57532072500); Denny, Joshua C. (57855963200)","57189213780; 57212895740; 57532072500; 57855963200","Defining Phenotypes from Clinical Data to Drive Genomic Research","2018","Annual review of biomedical data science","27","10.1146/annurev-biodatasci-080917-013335","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083553112&doi=10.1146%2fannurev-biodatasci-080917-013335&partnerID=40&md5=2f885bbb3c5e3607b990002ef6bf3872","Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, TN, United States; Department of General Surgery, Vanderbilt University Medical Center, Nashville, TN, United States; Department of Medicine, Vanderbilt University Medical Center, Nashville, TN, United States; Department of Pharmacology, Vanderbilt University Medical Center","Robinson J.R., Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, TN, United States, Department of General Surgery, Vanderbilt University Medical Center, Nashville, TN, United States; Wei W.-Q., Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, TN, United States; Roden D.M., Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, TN, United States, Department of Medicine, Vanderbilt University Medical Center, Nashville, TN, United States, Department of Pharmacology, Vanderbilt University Medical Center; Denny J.C., Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, TN, United States, Department of Medicine, Vanderbilt University Medical Center, Nashville, TN, United States","The rise in available longitudinal patient information in electronic health records (EHRs) and their coupling to DNA biobanks has resulted in a dramatic increase in genomic research using EHR data for phenotypic information. EHRs have the benefit of providing a deep and broad data source of health-related phenotypes, including drug response traits, expanding the phenome available to researchers for discovery. The earliest efforts at repurposing EHR data for research involved manual chart review of limited numbers of patients but now typically involve applications of rule-based and machine learning algorithms operating on sometimes huge corpora for both genome-wide and phenome-wide approaches. We highlight here the current methods, impact, challenges, and opportunities for repurposing clinical data to define patient phenotypes for genomics discovery. Use of EHR data has proven a powerful method for elucidation of genomic influences on diseases, traits, and drug-response phenotypes and will continue to have increasing applications in large cohort studies.","biobank; electronic health record; genomics; GWAS; phenotyping; PheWAS","","NLM (Medline)","25743414","","","34109303","Article","Scopus","2-s2.0-85083553112"
"Toth D.; Miao S.; Kurzendorfer T.; Rinaldi C.A.; Liao R.; Mansi T.; Rhode K.; Mountney P.","Toth, Daniel (57190670121); Miao, Shun (36629063700); Kurzendorfer, Tanja (55198948300); Rinaldi, Christopher A. (57217533072); Liao, Rui (55191129300); Mansi, Tommaso (24401117700); Rhode, Kawal (9245867600); Mountney, Peter (15042513400)","57190670121; 36629063700; 55198948300; 57217533072; 55191129300; 24401117700; 9245867600; 15042513400","3D/2D model-to-image registration by imitation learning for cardiac procedures","2018","International Journal of Computer Assisted Radiology and Surgery","39","10.1007/s11548-018-1774-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046801082&doi=10.1007%2fs11548-018-1774-y&partnerID=40&md5=7809a6fda62b1a047155ebf56e6e240d","Siemens Healthineers, Frimley, United Kingdom; Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States; Department of Cardiology, Guys and St. Thomas Hospitals NHS Foundation Trust, London, United Kingdom; School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Siemens Healthineers, Forchheim, Germany","Toth D., Siemens Healthineers, Frimley, United Kingdom, School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Miao S., Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States; Kurzendorfer T., Siemens Healthineers, Forchheim, Germany; Rinaldi C.A., Department of Cardiology, Guys and St. Thomas Hospitals NHS Foundation Trust, London, United Kingdom, School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Liao R., Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States; Mansi T., Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States; Rhode K., School of Biomedical Engineering and Imaging Sciences, King’s College London, London, United Kingdom; Mountney P., Siemens Healthineers, Medical Imaging Technologies, Princeton, NJ, United States","Purpose: In cardiac interventions, such as cardiac resynchronization therapy (CRT), image guidance can be enhanced by involving preoperative models. Multimodality 3D/2D registration for image guidance, however, remains a significant research challenge for fundamentally different image data, i.e., MR to X-ray. Registration methods must account for differences in intensity, contrast levels, resolution, dimensionality, field of view. Furthermore, same anatomical structures may not be visible in both modalities. Current approaches have focused on developing modality-specific solutions for individual clinical use cases, by introducing constraints, or identifying cross-modality information manually. Machine learning approaches have the potential to create more general registration platforms. However, training image to image methods would require large multimodal datasets and ground truth for each target application. Methods: This paper proposes a model-to-image registration approach instead, because it is common in image-guided interventions to create anatomical models for diagnosis, planning or guidance prior to procedures. An imitation learning-based method, trained on 702 datasets, is used to register preoperative models to intraoperative X-ray images. Results: Accuracy is demonstrated on cardiac models and artificial X-rays generated from CTs. The registration error was 2.92±2.22mm on 1000 test cases, superior to that of manual (6.48±5.6mm) and gradient-based (6.79±4.75mm) registration. High robustness is shown in 19 clinical CRT cases. Conclusion: Besides the proposed methods feasibility in a clinical environment, evaluation has shown good accuracy and high robustness indicating that it could be applied in image-guided interventions. © 2018, The Author(s).","Cardiac registration; Cardiac resynchronization therapy; Deep learning; Image fusion; Imitation learning","Algorithms; Cardiac Resynchronization Therapy; Heart; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Models, Anatomic; Multimodal Imaging; Reproducibility of Results; Article; artificial neural network; cardiac imaging; data base; diagnostic value; human; intraoperative period; learning; measurement accuracy; preoperative period; priority journal; quantitative analysis; radiography; registration; three dimensional imaging; treatment planning; two-dimensional imaging; algorithm; anatomic model; cardiac resynchronization therapy; diagnostic imaging; heart; image processing; machine learning; multimodal imaging; procedures; reproducibility; validation study","Springer Verlag","18616410","","","29754382","Article","Scopus","2-s2.0-85046801082"
"Poernomo A.; Kang D.-K.","Poernomo, Alvin (57201883230); Kang, Dae-Ki (8866969000)","57201883230; 8866969000","Biased Dropout and Crossmap Dropout: Learning towards effective Dropout regularization in convolutional neural network","2018","Neural Networks","91","10.1016/j.neunet.2018.03.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046341033&doi=10.1016%2fj.neunet.2018.03.016&partnerID=40&md5=064b1bf161f1ffbc2b9d9ccb4e7fd5ed","Department of Ubiquitous IT, Dongseo University, Busan, South Korea","Poernomo A., Department of Ubiquitous IT, Dongseo University, Busan, South Korea; Kang D.-K., Department of Ubiquitous IT, Dongseo University, Busan, South Korea","Training a deep neural network with a large number of parameters often leads to overfitting problem. Recently, Dropout has been introduced as a simple, yet effective regularization approach to combat overfitting in such models. Although Dropout has shown remarkable results on many deep neural network cases, its actual effect on CNN has not been thoroughly explored. Moreover, training a Dropout model will significantly increase the training time as it takes longer time to converge than a non-Dropout model with the same architecture. To deal with these issues, we address Biased Dropout and Crossmap Dropout, two novel approaches of Dropout extension based on the behavior of hidden units in CNN model. Biased Dropout divides the hidden units in a certain layer into two groups based on their magnitude and applies different Dropout rate to each group appropriately. Hidden units with higher activation value, which give more contributions to the network final performance, will be retained by a lower Dropout rate, while units with lower activation value will be exposed to a higher Dropout rate to compensate the previous part. The second approach is Crossmap Dropout, which is an extension of the regular Dropout in convolution layer. Each feature map in a convolution layer has a strong correlation between each other, particularly in every identical pixel location in each feature map. Crossmap Dropout tries to maintain this important correlation yet at the same time break the correlation between each adjacent pixel with respect to all feature maps by applying the same Dropout mask to all feature maps, so that all pixels or units in equivalent positions in each feature map will be either dropped or active during training. Our experiment with various benchmark datasets shows that our approaches provide better generalization than the regular Dropout. Moreover, our Biased Dropout takes faster time to converge during training phase, suggesting that assigning noise appropriately in hidden units can lead to an effective regularization. © 2018 Elsevier Ltd","Convolutional neural network; Dropout; Regularization","Bias; Neural Networks (Computer); Supervised Machine Learning; Chemical activation; Convolution; Neural networks; Pixels; Activation value; Benchmark datasets; Convolutional neural network; Dropout; Over fitting problem; Regularization; Regularization approach; Strong correlation; accuracy; Article; artificial neural network; benchmarking; convolutional neural network; data analysis; learning algorithm; linear system; mathematical computing; mathematical model; noise; prediction; priority journal; probability; statistical bias; supervised machine learning; Deep neural networks","Elsevier Ltd","08936080","","NNETE","29715684","Article","Scopus","2-s2.0-85046341033"
"Lee H.; Mansouri M.; Tajmir S.; Lev M.H.; Do S.","Lee, Hyunkwang (57193528962); Mansouri, Mohammad (56637940100); Tajmir, Shahein (57000496000); Lev, Michael H. (35272819100); Do, Synho (24173146300)","57193528962; 56637940100; 57000496000; 35272819100; 24173146300","A Deep-Learning System for Fully-Automated Peripherally Inserted Central Catheter (PICC) Tip Detection","2018","Journal of Digital Imaging","38","10.1007/s10278-017-0025-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030710900&doi=10.1007%2fs10278-017-0025-z&partnerID=40&md5=7a2dc1dc54402cb466da72c101479330","Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States","Lee H., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Mansouri M., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Tajmir S., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Lev M.H., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Do S., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States","A peripherally inserted central catheter (PICC) is a thin catheter that is inserted via arm veins and threaded near the heart, providing intravenous access. The final catheter tip position is always confirmed on a chest radiograph (CXR) immediately after insertion since malpositioned PICCs can cause potentially life-threatening complications. Although radiologists interpret PICC tip location with high accuracy, delays in interpretation can be significant. In this study, we proposed a fully-automated, deep-learning system with a cascading segmentation AI system containing two fully convolutional neural networks for detecting a PICC line and its tip location. A preprocessing module performed image quality and dimension normalization, and a post-processing module found the PICC tip accurately by pruning false positives. Our best model, trained on 400 training cases and selectively tuned on 50 validation cases, obtained absolute distances from ground truth with a mean of 3.10 mm, a standard deviation of 2.03 mm, and a root mean squares error (RMSE) of 3.71 mm on 150 held-out test cases. This system could help speed confirmation of PICC position and further be generalized to include other types of vascular access and therapeutic support devices. © 2017, Society for Imaging Informatics in Medicine.","Chest radiograph; Computer-aided detection; Deep learning; Machine learning; PICC; Radiology workflow","Catheterization, Central Venous; Catheterization, Peripheral; Central Venous Catheters; Databases, Factual; Deep Learning; Electrocardiography; Female; Humans; Male; Neural Networks (Computer); Patient Safety; Pattern Recognition, Automated; Radiography, Thoracic; Retrospective Studies; Catheters; Computer aided instruction; Learning systems; Neural networks; Radiography; Chest radiographs; Computer aided detection; Convolutional neural network; Peripherally inserted central catheters; PICC; Preprocessing modules; Radiology workflow; Standard deviation; artificial neural network; automated pattern recognition; catheterization; central venous catheter; central venous catheterization; electrocardiography; factual database; female; human; male; patient safety; procedures; retrospective study; thorax radiography; Deep learning","Springer New York LLC","08971889","","JDIME","28983851","Article","Scopus","2-s2.0-85030710900"
"Grisoni F.; Neuhaus C.S.; Gabernet G.; Müller A.T.; Hiss J.A.; Schneider G.","Grisoni, Francesca (56020972100); Neuhaus, Claudia S. (57214564239); Gabernet, Gisela (55053581000); Müller, Alex T. (57164240800); Hiss, Jan A. (16177469500); Schneider, Gisbert (7402466014)","56020972100; 57214564239; 55053581000; 57164240800; 16177469500; 7402466014","Designing Anticancer Peptides by Constructive Machine Learning","2018","ChemMedChem","65","10.1002/cmdc.201800204","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047665893&doi=10.1002%2fcmdc.201800204&partnerID=40&md5=9aebd424c99cada7e4111dd81d30bc46","Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland; University of Milano-Bicocca, Milano Chemometrics & QSAR Research Group, Department of Earth and Environmental Sciences, Milan, 20126, Italy","Grisoni F., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland, University of Milano-Bicocca, Milano Chemometrics & QSAR Research Group, Department of Earth and Environmental Sciences, Milan, 20126, Italy; Neuhaus C.S., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland; Gabernet G., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland; Müller A.T., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland; Hiss J.A., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland; Schneider G., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, 8093, Switzerland","Constructive (generative) machine learning enables the automated generation of novel chemical structures without the need for explicit molecular design rules. This study presents the experimental application of such a deep machine learning model to design membranolytic anticancer peptides (ACPs) de novo. A recurrent neural network with long short-term memory cells was trained on α-helical cationic amphipathic peptide sequences and then fine-tuned with 26 known ACPs by transfer learning. This optimized model was used to generate unique and novel amino acid sequences. Twelve of the peptides were synthesized and tested for their activity on MCF7 human breast adenocarcinoma cells and selectivity against human erythrocytes. Ten of these peptides were active against cancer cells. Six of the active peptides killed MCF7 cancer cells without affecting human erythrocytes with at least threefold selectivity. These results advocate constructive machine learning for the automated design of peptides with desired biological activities. © 2018 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","artificial intelligence; de novo design; deep learning; drug discovery; peptide design","Amino Acid Sequence; Antineoplastic Agents; Deep Learning; Drug Design; Humans; MCF-7 Cells; Peptides; antineoplastic agent; peptide derivative; antineoplastic agent; peptide; alpha helix; amino acid sequence; antineoplastic activity; Article; biological activity; breast adenocarcinoma; cell killing; drug design; drug synthesis; erythrocyte; human; human cell; machine learning; MCF-7 cell line; priority journal; selectivity index; short term memory; synthesis","John Wiley and Sons Ltd","18607179","","CHEMG","29679519","Article","Scopus","2-s2.0-85047665893"
"Li H.; Yang M.; Chen Q.; Tang B.; Wang X.; Yan J.","Li, Haodi (55814121700); Yang, Ming (57199913759); Chen, Qingcai (34869206800); Tang, Buzhou (35115621400); Wang, Xiaolong (9276464700); Yan, Jun (57203174310)","55814121700; 57199913759; 34869206800; 35115621400; 9276464700; 57203174310","Chemical-induced disease extraction via recurrent piecewise convolutional neural networks","2018","BMC Medical Informatics and Decision Making","22","10.1186/s12911-018-0629-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050823669&doi=10.1186%2fs12911-018-0629-3&partnerID=40&md5=d64d09fbd5db520a1fa29f66c7f849f8","Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology, Shenzhen, Guangdong, China; Shenzhen Calligraphy Digital Simulation Technology Engineering Laboratory, Harbin Institute of Technology, Shenzhen, Guangdong, China; Pharmacy Department, Shenzhen Second People's Hospital, First Affiliated Hospital of Shenzhen University, Guandong, Shenzhen, China; Yidu Cloud (Beijing) Technology Co., Ltd, Beijing, China","Li H., Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology, Shenzhen, Guangdong, China, Shenzhen Calligraphy Digital Simulation Technology Engineering Laboratory, Harbin Institute of Technology, Shenzhen, Guangdong, China; Yang M., Pharmacy Department, Shenzhen Second People's Hospital, First Affiliated Hospital of Shenzhen University, Guandong, Shenzhen, China; Chen Q., Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology, Shenzhen, Guangdong, China, Shenzhen Calligraphy Digital Simulation Technology Engineering Laboratory, Harbin Institute of Technology, Shenzhen, Guangdong, China; Tang B., Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology, Shenzhen, Guangdong, China, Shenzhen Calligraphy Digital Simulation Technology Engineering Laboratory, Harbin Institute of Technology, Shenzhen, Guangdong, China; Wang X., Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology, Shenzhen, Guangdong, China, Shenzhen Calligraphy Digital Simulation Technology Engineering Laboratory, Harbin Institute of Technology, Shenzhen, Guangdong, China; Yan J., Yidu Cloud (Beijing) Technology Co., Ltd, Beijing, China","Background: Extracting relationships between chemicals and diseases from unstructured literature have attracted plenty of attention since the relationships are very useful for a large number of biomedical applications such as drug repositioning and pharmacovigilance. A number of machine learning methods have been proposed for chemical-induced disease (CID) extraction due to some publicly available annotated corpora. Most of them suffer from time-consuming feature engineering except deep learning methods. In this paper, we propose a novel document-level deep learning method, called recurrent piecewise convolutional neural networks (RPCNN), for CID extraction. Results: Experimental results on a benchmark dataset, the CDR (Chemical-induced Disease Relation) dataset of the BioCreative V challenge for CID extraction show that the highest precision, recall and F-score of our RPCNN-based CID extraction system are 65.24, 77.21 and 70.77%, which is competitive with other state-of-the-art systems. Conclusions: A novel deep learning method is proposed for document-level CID extraction, where domain knowledge, piecewise strategy, attention mechanism, and multi-instance learning are combined together. The effectiveness of the method is proved by experiments conducted on a benchmark dataset. © 2018 The Author(s).","Chemical-induced disease; Convolutional neural network; Deep learning; Relation extraction","Algorithms; Chemically-Induced Disorders; Datasets as Topic; Deep Learning; Information Storage and Retrieval; Neural Networks (Computer); algorithm; artificial neural network; chemically induced disorder; information processing; information retrieval","BioMed Central Ltd","14726947","","","30066652","Article","Scopus","2-s2.0-85050823669"
"Yang Z.; Yabansu Y.C.; Al-Bahrani R.; Liao W.-K.; Choudhary A.N.; Kalidindi S.R.; Agrawal A.","Yang, Zijiang (58429935900); Yabansu, Yuksel C. (44761651300); Al-Bahrani, Reda (56022799800); Liao, Wei-keng (7203056909); Choudhary, Alok N. (24297881400); Kalidindi, Surya R. (56929687800); Agrawal, Ankit (24604939500)","58429935900; 44761651300; 56022799800; 7203056909; 24297881400; 56929687800; 24604939500","Deep learning approaches for mining structure-property linkages in high contrast composites from simulation datasets","2018","Computational Materials Science","216","10.1016/j.commatsci.2018.05.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047246249&doi=10.1016%2fj.commatsci.2018.05.014&partnerID=40&md5=1fefc0be55f4c0b40d97648c1d2a4b58","Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, 60208, IL, United States; George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, 30332, GA, United States; School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, 30332, GA, United States","Yang Z., Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, 60208, IL, United States; Yabansu Y.C., George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, 30332, GA, United States; Al-Bahrani R., Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, 60208, IL, United States; Liao W.-K., Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, 60208, IL, United States; Choudhary A.N., Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, 60208, IL, United States; Kalidindi S.R., George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, 30332, GA, United States, School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, 30332, GA, United States; Agrawal A., Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, 60208, IL, United States","Data-driven methods are emerging as an important toolset in the studies of multiscale, multiphysics, materials phenomena. More specifically, data mining and machine learning methods offer an efficient toolset for extracting and curating the important correlations controlling these multiscale materials phenomena in high-value reduced-order forms called process-structure-property (PSP) linkages. Traditional machine learning methods usually depend on intensive feature engineering, and have enjoyed some success in establishing the desired PSP linkages. In contrast, deep learning approaches provide a feature-engineering-free framework with high learning capability. In this work, a deep learning approach is designed and implemented to model an elastic homogenization structure-property linkage in a high contrast composite material system. More specifically, the proposed deep learning model is employed to capture the nonlinear mapping between the three-dimensional material microstructure and its macroscale (effective) stiffness. It is demonstrated that this end-to-end framework can predict the effective stiffness of high contrast elastic composites with a wide of range of microstructures, while exhibiting high accuracy and low computational cost for new evaluations. © 2018 Elsevier B.V.","Convolutional neural networks; Deep learning; Homogenization; Materials informatics; Structure-property linkages","Data mining; Data reduction; Homogenization method; Microstructure; Neural networks; Stiffness; Structural properties; Composite material system; Convolutional neural network; Elastic homogenizations; Learning capabilities; Machine learning methods; Material microstructures; Materials informatics; Structure property; Deep learning","Elsevier B.V.","09270256","","CMMSE","","Article","Scopus","2-s2.0-85047246249"
"Wen H.; Shi J.; Chen W.; Liu Z.","Wen, Haiguang (56834995600); Shi, Junxing (57200619976); Chen, Wei (55056314100); Liu, Zhongming (8511950700)","56834995600; 57200619976; 55056314100; 8511950700","Transferring and generalizing deep-learning-based neural encoding models across subjects","2018","NeuroImage","17","10.1016/j.neuroimage.2018.04.053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046431235&doi=10.1016%2fj.neuroimage.2018.04.053&partnerID=40&md5=6a8c698452c6633c17c453858f6f3983","Weldon School of Biomedical Engineering, Purdue University, West Lafayette, IN, United States; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States; Purdue Institute for Integrative Neuroscience, Purdue University, West Lafayette, IN, United States; Center for Magnetic Resonance Research, Department of Radiology, University of Minnesota Medical School, Minneapolis, MN, United States","Wen H., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States, Purdue Institute for Integrative Neuroscience, Purdue University, West Lafayette, IN, United States; Shi J., School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States, Purdue Institute for Integrative Neuroscience, Purdue University, West Lafayette, IN, United States; Chen W., Center for Magnetic Resonance Research, Department of Radiology, University of Minnesota Medical School, Minneapolis, MN, United States; Liu Z., Weldon School of Biomedical Engineering, Purdue University, West Lafayette, IN, United States, School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States, Purdue Institute for Integrative Neuroscience, Purdue University, West Lafayette, IN, United States","Recent studies have shown the value of using deep learning models for mapping and characterizing how the brain represents and organizes information for natural vision. However, modeling the relationship between deep learning models and the brain (or encoding models), requires measuring cortical responses to large and diverse sets of natural visual stimuli from single subjects. This requirement limits prior studies to few subjects, making it difficult to generalize findings across subjects or for a population. In this study, we developed new methods to transfer and generalize encoding models across subjects. To train encoding models specific to a target subject, the models trained for other subjects were used as the prior models and were refined efficiently using Bayesian inference with a limited amount of data from the target subject. To train encoding models for a population, the models were progressively trained and updated with incremental data from different subjects. For the proof of principle, we applied these methods to functional magnetic resonance imaging (fMRI) data from three subjects watching tens of hours of naturalistic videos, while a deep residual neural network driven by image recognition was used to model visual cortical processing. Results demonstrate that the methods developed herein provide an efficient and effective strategy to establish both subject-specific and population-wide predictive models of cortical representations of high-dimensional and hierarchical visual features. © 2018 Elsevier Inc.","Bayesian inference; Deep learning; Incremental learning; Natural vision; Neural encoding","Adult; Bayes Theorem; Brain; Brain Mapping; Deep Learning; Female; Humans; Magnetic Resonance Imaging; Neural Pathways; Pattern Recognition, Visual; Reproducibility of Results; Young Adult; adult; Article; artificial neural network; Bayesian learning; correlation coefficient; deep neural network; female; functional magnetic resonance imaging; human; human experiment; image segmentation; learning algorithm; machine learning; natural science; normal human; priority journal; proof of concept; transfer of learning; visual stimulation; Bayes theorem; brain; brain mapping; nerve tract; nuclear magnetic resonance imaging; pattern recognition; physiology; procedures; reproducibility; young adult","Academic Press Inc.","10538119","","NEIME","29705690","Article","Scopus","2-s2.0-85046431235"
"Tang F.; Xiao C.; Wang F.; Zhou J.","Tang, Fengyi (57203285345); Xiao, Cao (57199799682); Wang, Fei (56177292700); Zhou, Jiayu (24785591700)","57203285345; 57199799682; 56177292700; 24785591700","Predictive modeling in urgent care: A comparative study of machine learning approaches","2018","JAMIA Open","34","10.1093/jamiaopen/ooy011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064856416&doi=10.1093%2fjamiaopen%2fooy011&partnerID=40&md5=87628532b541134ed3960ab8a7d6278e","Department of Computer Science and Engineering, Michigan State University College of Engineering, 428 S Shaw Ln, East Lansing, 48824, MI, United States; AI for Healthcare, IBM Research, Cambridge, MA, United States; Department of Healthcare Policy and Research, Weill Cornell Medical School Cornell University, New York, NY, United States","Tang F., Department of Computer Science and Engineering, Michigan State University College of Engineering, 428 S Shaw Ln, East Lansing, 48824, MI, United States; Xiao C., AI for Healthcare, IBM Research, Cambridge, MA, United States; Wang F., Department of Healthcare Policy and Research, Weill Cornell Medical School Cornell University, New York, NY, United States; Zhou J., Department of Computer Science and Engineering, Michigan State University College of Engineering, 428 S Shaw Ln, East Lansing, 48824, MI, United States","Objective: The growing availability of rich clinical data such as patients' electronic health records provide great opportunities to address a broad range of real-world questions in medicine. At the same time, artificial intelligence and machine learning (ML)-based approaches have shown great premise on extracting insights from those data and helping with various clinical problems. The goal of this study is to conduct a systematic comparative study of different ML algorithms for several predictive modeling problems in urgent care. Design: We assess the performance of 4 benchmark prediction tasks (eg mortality and prediction, differential diagnostics, and disease marker discovery) using medical histories, physiological time-series, and demographics data from the Medical Information Mart for Intensive Care (MIMIC-III) database. Measurements: For each given task, performance was estimated using standard measures including the area under the receiver operating characteristic (AUC) curve, F-1 score, sensitivity, and specificity. Microaveraged AUC was used for multiclass classification models. Results and Discussion: Our results suggest that recurrent neural networks show the most promise in mortality prediction where temporal patterns in physiologic features alone can capture in-hospital mortality risk (AUC>0.90). Temporal models did not provide additional benefit compared to deep models in differential diagnostics. When comparing the training-testing behaviors of readmission and mortality models, we illustrate that readmission risk may be independent of patient stability at discharge. We also introduce a multiclass prediction scheme for length of stay which preserves sensitivity and AUC with outliers of increasing duration despite decrease in sample size. © The Author(s) 2018.","Machine learning; Predictive modeling; Urgent care","creatinine; lactic acid; acute kidney failure; algorithm; Article; artificial intelligence; chronic kidney failure; clinical study; comparative study; differential diagnosis; disease marker; electronic health record; hospital mortality; hospital readmission; human; hyperlipidemia; lactate blood level; length of stay; machine learning; mortality; non insulin dependent diabetes mellitus; pneumonia; prediction; predictive value; priority journal; sensitivity and specificity; sepsis; task performance; time series analysis; urea nitrogen blood level","Oxford University Press","25742531","","","","Article","Scopus","2-s2.0-85064856416"
"Purushotham S.; Meng C.; Che Z.; Liu Y.","Purushotham, Sanjay (54882660300); Meng, Chuizheng (57202426214); Che, Zhengping (56719288000); Liu, Yan (56050964100)","54882660300; 57202426214; 56719288000; 56050964100","Benchmarking deep learning models on large healthcare datasets","2018","Journal of Biomedical Informatics","221","10.1016/j.jbi.2018.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048265375&doi=10.1016%2fj.jbi.2018.04.007&partnerID=40&md5=206ec8bb80a47c6bf335aaa07fbc62c0","University of Southern California, Los Angeles, 90089, CA, United States; Tsinghua University, Beijing, 100084, China","Purushotham S., University of Southern California, Los Angeles, 90089, CA, United States; Meng C., Tsinghua University, Beijing, 100084, China; Che Z., University of Southern California, Los Angeles, 90089, CA, United States; Liu Y., University of Southern California, Los Angeles, 90089, CA, United States","Deep learning models (aka Deep Neural Networks) have revolutionized many fields including computer vision, natural language processing, speech recognition, and is being increasingly used in clinical healthcare applications. However, few works exist which have benchmarked the performance of the deep learning models with respect to the state-of-the-art machine learning models and prognostic scoring systems on publicly available healthcare datasets. In this paper, we present the benchmarking results for several clinical prediction tasks such as mortality prediction, length of stay prediction, and ICD-9 code group prediction using Deep Learning models, ensemble of machine learning models (Super Learner algorithm), SAPS II and SOFA scores. We used the Medical Information Mart for Intensive Care III (MIMIC-III) (v1.4) publicly available dataset, which includes all patients admitted to an ICU at the Beth Israel Deaconess Medical Center from 2001 to 2012, for the benchmarking tasks. Our results show that deep learning models consistently outperform all the other approaches especially when the ‘raw’ clinical time series data is used as input features to the models. © 2018 Elsevier Inc.","Deep learning models; ICD-9 code group prediction; Length of stay; Mortality prediction; Super learner algorithm","Aged; Aged, 80 and over; Algorithms; Benchmarking; Databases, Factual; Deep Learning; Female; Forecasting; Hospital Mortality; Humans; Intensive Care Units; International Classification of Diseases; Length of Stay; Male; Middle Aged; Neural Networks (Computer); Artificial intelligence; Benchmarking; Deep neural networks; Forecasting; Health care; Intensive care units; Medical computing; Natural language processing systems; Speech recognition; Clinical time series; Health care application; Learning models; Length of stay; Machine learning models; Medical information; Prediction tasks; State of the art; adult; aged; Article; benchmarking; coding algorithm; female; health care; hospital mortality; human; ICD-9; information processing; intensive care unit; length of stay; machine learning; male; scoring system; Sequential Organ Failure Assessment Score; Simplified Acute Physiology Score; statistical model; algorithm; artificial neural network; factual database; forecasting; International Classification of Diseases; middle aged; very elderly; Learning algorithms","Academic Press Inc.","15320464","","JBIOB","29879470","Article","Scopus","2-s2.0-85048265375"
"Zheng X.; Wang M.; Ordieres-Meré J.","Zheng, Xiaochen (57202144755); Wang, Meiqing (56139177300); Ordieres-Meré, Joaquín (57196075244)","57202144755; 56139177300; 57196075244","Comparison of data preprocessing approaches for applying deep learning to human activity recognition in the context of industry 4.0","2018","Sensors (Switzerland)","101","10.3390/s18072146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049595414&doi=10.3390%2fs18072146&partnerID=40&md5=41dc330194f96232cf54ab44cba3705f","Department of Industrial Engineering, Universidad Politécnica de Madrid, Madrid, 28006, Spain; School of Mechanical Engineering and Automation, Beihang University (BUAA), Beijing, 100083, China","Zheng X., Department of Industrial Engineering, Universidad Politécnica de Madrid, Madrid, 28006, Spain; Wang M., School of Mechanical Engineering and Automation, Beihang University (BUAA), Beijing, 100083, China; Ordieres-Meré J., Department of Industrial Engineering, Universidad Politécnica de Madrid, Madrid, 28006, Spain","According to the Industry 4.0 paradigm, all objects in a factory, including people, are equipped with communication capabilities and integrated into cyber-physical systems (CPS). Human activity recognition (HAR) based on wearable sensors provides a method to connect people to CPS. Deep learning has shown surpassing performance in HAR. Data preprocessing is an important part of deep learning projects and takes up a large part of the whole analytical pipeline. Data segmentation and data transformation are two critical steps of data preprocessing. This study analyzes the impact of segmentation methods on deep learning model performance, and compares four data transformation approaches. An experiment with HAR based on acceleration data from multiple wearable devices was conducted. The multichannel method, which treats the data for the three axes as three overlapped color channels, produced the best performance. The highest overall recognition accuracy achieved was 97.20% for eight daily activities, based on the data from seven wearable sensors, which outperformed most of the other machine learning techniques. Moreover, the multichannel approach was applied to three public datasets and produced satisfying results for multi-source acceleration data. The proposed method can help better analyze workers’ activities and help to integrate people into CPS. © 2018 by the authors.","Data preprocessing; Deep learning; Human Activity Recognition (HAR); Industry 4.0; Internet of things (IoT)","Acceleration; Adult; Deep Learning; Female; Human Activities; Humans; Male; Wearable Electronic Devices; Embedded systems; Industry 4.0; Internet of things; Metadata; Pattern recognition; Wearable sensors; Communication capabilities; Cyber-Physical System (CPS); Data preprocessing; Human activity recognition; Internet of Things (IOT); Machine learning techniques; Recognition accuracy; Segmentation methods; acceleration; adult; comparative study; electronic device; female; human; human activities; male; Deep learning","MDPI AG","14248220","","","29970873","Article","Scopus","2-s2.0-85049595414"
"Kwon J.-M.; Lee Y.; Lee Y.; Lee S.; Park J.","Kwon, Joon-Myoung (57202893940); Lee, Youngnam (57202891523); Lee, Yeha (57202891529); Lee, Seungwoo (57202889359); Park, Jinsik (55328611600)","57202893940; 57202891523; 57202891529; 57202889359; 55328611600","An algorithm based on deep learning for predicting in-hospital cardiac arrest","2018","Journal of the American Heart Association","181","10.1161/JAHA.118.008678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049690743&doi=10.1161%2fJAHA.118.008678&partnerID=40&md5=9cef42f33a87f2759330a115cc8621b2","Department of Emergency Medicine, Mediplex Sejong Hospital, Incheon, South Korea; Department of Cardiology, Mediplex Sejong Hospital, Incheon, South Korea; VUNO, Seoul, South Korea","Kwon J.-M., Department of Emergency Medicine, Mediplex Sejong Hospital, Incheon, South Korea; Lee Y., VUNO, Seoul, South Korea; Lee Y., VUNO, Seoul, South Korea; Lee S., VUNO, Seoul, South Korea; Park J., Department of Cardiology, Mediplex Sejong Hospital, Incheon, South Korea","Background—In-hospital cardiac arrest is a major burden to public health, which affects patient safety. Although traditional trackand- trigger systems are used to predict cardiac arrest early, they have limitations, with low sensitivity and high false-alarm rates. We propose a deep learning–based early warning system that shows higher performance than the existing track-and-trigger systems. Methods and Results—This retrospective cohort study reviewed patients who were admitted to 2 hospitals from June 2010 to July 2017. A total of 52 131 patients were included. Specifically, a recurrent neural network was trained using data from June 2010 to January 2017. The result was tested using the data from February to July 2017. The primary outcome was cardiac arrest, and the secondary outcome was death without attempted resuscitation. As comparative measures, we used the area under the receiver operating characteristic curve (AUROC), the area under the precision–recall curve (AUPRC), and the net reclassification index. Furthermore, we evaluated sensitivity while varying the number of alarms. The deep learning–based early warning system (AUROC: 0.850; AUPRC: 0.044) significantly outperformed a modified early warning score (AUROC: 0.603; AUPRC: 0.003), a random forest algorithm (AUROC: 0.780; AUPRC: 0.014), and logistic regression (AUROC: 0.613; AUPRC: 0.007). Furthermore, the deep learning– based early warning system reduced the number of alarms by 82.2%, 13.5%, and 42.1% compared with the modified early warning system, random forest, and logistic regression, respectively, at the same sensitivity. Conclusions—An algorithm based on deep learning had high sensitivity and a low false-alarm rate for detection of patients with cardiac arrest in the multicenter study. © 2018 The Authors.","Artificial intelligence; Cardiac arrest; Deep learning; Machine learning; Rapid response system; Resuscitation","Adult; Aged; Decision Support Techniques; Deep Learning; Diagnosis, Computer-Assisted; Early Diagnosis; Female; Heart Arrest; Humans; Inpatients; Male; Middle Aged; Predictive Value of Tests; Prognosis; Reproducibility of Results; Resuscitation; Retrospective Studies; Risk Assessment; Risk Factors; Seoul; Time Factors; Vital Signs; adult; algorithm; Article; artificial intelligence; artificial neural network; blood pressure; cohort analysis; controlled study; deep learning based early warning system; female; heart arrest; heart rate; hospital admission; hospital patient; human; learning; logistic regression analysis; major clinical study; male; prediction; priority journal; random forest; rapid response team; receiver operating characteristic; resuscitation; retrospective study; sensitivity analysis; track and trigger system; vital sign; aged; clinical trial; computer assisted diagnosis; decision support system; early diagnosis; heart arrest; middle aged; mortality; multicenter study; predictive value; prognosis; reproducibility; risk assessment; risk factor; South Korea; time factor; vital sign","American Heart Association Inc.","20479980","","","29945914","Article","Scopus","2-s2.0-85049690743"
"Yamada K.D.; Kinoshita K.","Yamada, Kazunori D. (55732854700); Kinoshita, Kengo (7402901232)","55732854700; 7402901232","De novo profile generation based on sequence context specificity with the long short-term memory network","2018","BMC Bioinformatics","7","10.1186/s12859-018-2284-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050284231&doi=10.1186%2fs12859-018-2284-1&partnerID=40&md5=fad672ad8f812eb4632a38d815bd89e5","Tohoku University, Graduate School of Information Sciences, Sendai, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Artificial Intelligence Research Center, Tokyo, Japan; Tohoku University, Tohoku Medical Megabank Organization, Sendai, Japan; Tohoku University, Institute of Development, Aging, and Cancer, Sendai, Japan","Yamada K.D., Tohoku University, Graduate School of Information Sciences, Sendai, Japan, National Institute of Advanced Industrial Science and Technology (AIST), Artificial Intelligence Research Center, Tokyo, Japan; Kinoshita K., Tohoku University, Graduate School of Information Sciences, Sendai, Japan, Tohoku University, Tohoku Medical Megabank Organization, Sendai, Japan, Tohoku University, Institute of Development, Aging, and Cancer, Sendai, Japan","Background: Long short-term memory (LSTM) is one of the most attractive deep learning methods to learn time series or contexts of input data. Increasing studies, including biological sequence analyses in bioinformatics, utilize this architecture. Amino acid sequence profiles are widely used for bioinformatics studies, such as sequence similarity searches, multiple alignments, and evolutionary analyses. Currently, many biological sequences are becoming available, and the rapidly increasing amount of sequence data emphasizes the importance of scalable generators of amino acid sequence profiles. Results: We employed the LSTM network and developed a novel profile generator to construct profiles without any assumptions, except for input sequence context. Our method could generate better profiles than existing de novo profile generators, including CSBuild and RPS-BLAST, on the basis of profile-sequence similarity search performance with linear calculation costs against input sequence size. In addition, we analyzed the effects of the memory power of LSTM and found that LSTM had high potential power to detect long-range interactions between amino acids, as in the case of beta-strand formation, which has been a difficult problem in protein bioinformatics using sequence information. Conclusion: We demonstrated the importance of sequence context and the feasibility of LSTM on biological sequence analyses. Our results demonstrated the effectiveness of memories in LSTM and showed that our de novo profile generator, SPBuild, achieved higher performance than that of existing methods for profile prediction of beta-strands, where long-range interactions of amino acids are important and are known to be difficult for the existing window-based prediction methods. Our findings will be useful for the development of other prediction methods related to biological sequences by machine learning methods. © 2018 The Author(s).","Deep learning; Long short-term memory; Neural networks; Protein sequence profile; Sequence context; Similarity search","Amino Acid Sequence; Computational Biology; Databases as Topic; Deep Learning; Neural Networks (Computer); Proteins; ROC Curve; Sequence Homology, Amino Acid; Amino acids; Bioinformatics; Brain; Deep learning; Forecasting; Neural networks; Proteins; protein; Biological sequence analysis; Biological sequences; Long range interactions; Machine learning methods; Protein sequence profiles; Sequence context; Sequence informations; Similarity search; amino acid sequence; artificial neural network; biology; chemistry; data base; procedures; receiver operating characteristic; sequence homology; Long short-term memory","BioMed Central Ltd.","14712105","","BBMIC","30021530","Article","Scopus","2-s2.0-85050284231"
"Chang P.; Grinband J.; Weinberg B.D.; Bardis M.; Khy M.; Cadena G.; Su M.-Y.; Cha S.; Filippi C.G.; Bota D.; Baldi P.; Poisson X.L.M.; Jain X.R.; Chow X.D.","Chang, P. (58588240500); Grinband, J. (12647205500); Weinberg, B.D. (57194383545); Bardis, M. (57202929292); Khy, M. (57202930106); Cadena, G. (56974803600); Su, M.-Y. (7403166951); Cha, S. (7201864583); Filippi, C.G. (7006884046); Bota, D. (35236098700); Baldi, P. (7101759672); Poisson, X.L.M. (57202920869); Jain, X.R. (57202931315); Chow, X.D. (57202920552)","58588240500; 12647205500; 57194383545; 57202929292; 57202930106; 56974803600; 7403166951; 7201864583; 7006884046; 35236098700; 7101759672; 57202920869; 57202931315; 57202920552","Deep-learning convolutional neural networks accurately classify genetic mutations in gliomas","2018","American Journal of Neuroradiology","311","10.3174/ajnr.A5667","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049830790&doi=10.3174%2fajnr.A5667&partnerID=40&md5=62635d7465e928d13642cae40d2621f8","Department of Radiology, University of California, San Francisco, San Francisco, CA, United States; Department of Radiology, Columbia University, New York, NY, United States; Department of Radiology, Emory University, School of Medicine, Atlanta, Georgia; Departments of Radiology, University of California, Irvine Medical Center, Douglas Hospital, 101 The City Drive South, Orange, 92868-3201, CA, United States; Neurosurgery, France; Neuro-Oncology, France; School of Information and Computer Sciences, University of California, Irvine, United States; Department of Radiology, North Shore University Hospital, Long Island, NY, United States; Department of Public Health Sciences, Henry Ford Health System, Detroit, MI, United States; Departments of Radiology and Neurosurgery, New York University, New York, NY, United States","Chang P., Department of Radiology, University of California, San Francisco, San Francisco, CA, United States; Grinband J., Department of Radiology, Columbia University, New York, NY, United States; Weinberg B.D., Department of Radiology, Emory University, School of Medicine, Atlanta, Georgia; Bardis M., Departments of Radiology, University of California, Irvine Medical Center, Douglas Hospital, 101 The City Drive South, Orange, 92868-3201, CA, United States; Khy M., Departments of Radiology, University of California, Irvine Medical Center, Douglas Hospital, 101 The City Drive South, Orange, 92868-3201, CA, United States; Cadena G., Neurosurgery, France; Su M.-Y., Departments of Radiology, University of California, Irvine Medical Center, Douglas Hospital, 101 The City Drive South, Orange, 92868-3201, CA, United States; Cha S., Department of Radiology, University of California, San Francisco, San Francisco, CA, United States; Filippi C.G., Department of Radiology, North Shore University Hospital, Long Island, NY, United States; Bota D., Neuro-Oncology, France; Baldi P., School of Information and Computer Sciences, University of California, Irvine, United States; Poisson X.L.M., Department of Public Health Sciences, Henry Ford Health System, Detroit, MI, United States; Jain X.R., Departments of Radiology and Neurosurgery, New York University, New York, NY, United States; Chow X.D., Departments of Radiology, University of California, Irvine Medical Center, Douglas Hospital, 101 The City Drive South, Orange, 92868-3201, CA, United States","BACKGROUND AND PURPOSE: The World Health Organization has recently placed new emphasis on the integration of genetic information for gliomas. While tissue sampling remains the criterion standard, noninvasive imaging techniques may provide complimentary insight into clinically relevant genetic mutations. Our aim was to train a convolutional neural network to independently predict underlying molecular genetic mutation status in gliomas with high accuracy and identify the most predictive imaging features for each mutation. MATERIALS AND METHODS: MR imaging data and molecular information were retrospectively obtained from The Cancer Imaging Archives for 259 patients with either low- or high-grade gliomas. A convolutional neural network was trained to classify isocitrate dehydrogenase 1 (IDH1) mutation status, 1p/19q codeletion, and O6-methylguanine-DNA methyltransferase (MGMT) promotor methylation status. Principal component analysis of the final convolutional neural network layer was used to extract the key imaging features critical for successful classification. RESULTS: Classification had high accuracy: IDH1 mutation status, 94%; 1p/19q codeletion, 92%; and MGMT promotor methylation status, 83%. Each genetic category was also associated with distinctive imaging features such as definition of tumor margins, T1 and FLAIR suppression, extent of edema, extent of necrosis, and textural features. CONCLUSIONS: Our results indicate that for The Cancer Imaging Archives dataset, machine-learning approaches allow classification of individual genetic mutations of both low- and high-grade gliomas. We show that relevant MR imaging features acquired from an added dimensionality-reduction technique demonstrate that neural networks are capable of learning key imaging components without prior feature selection or human-directed training. © 2018 American Society of Neuroradiology. All Rights Reserved.","","Adult; Brain Neoplasms; Deep Learning; DNA Modification Methylases; DNA Repair Enzymes; Female; Glioma; Humans; Isocitrate Dehydrogenase; Male; Middle Aged; Mutation; Promoter Regions, Genetic; Retrospective Studies; Tumor Suppressor Proteins; isocitrate dehydrogenase 1; methylated DNA protein cysteine methyltransferase; DNA ligase; DNA methyltransferase; IDH1 protein, human; isocitrate dehydrogenase; MGMT protein, human; tumor suppressor protein; accuracy; adult; area under the curve; Article; artificial neural network; cancer grading; chromosome 19p; chromosome 1p; chromosome deletion; convolutional neural network; edema; female; gene mutation; genetic variation; glioma; human; machine learning; major clinical study; male; middle aged; nuclear magnetic resonance imaging; principal component analysis; promoter region; retrospective study; tumor necrosis; tumor volume; brain tumor; genetics; glioma; mutation","American Society of Neuroradiology","01956108","","AAJND","29748206","Article","Scopus","2-s2.0-85049830790"
"Acharya U.R.; Oh S.L.; Hagiwara Y.; Tan J.H.; Adeli H.; Subha D.P.","Acharya, U. Rajendra (7004510847); Oh, Shu Lih (57185991600); Hagiwara, Yuki (57057106000); Tan, Jen Hong (26644487800); Adeli, Hojjat (35612773100); Subha, D.P. (25823963300)","7004510847; 57185991600; 57057106000; 26644487800; 35612773100; 25823963300","Automated EEG-based screening of depression using deep convolutional neural network","2018","Computer Methods and Programs in Biomedicine","409","10.1016/j.cmpb.2018.04.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046376921&doi=10.1016%2fj.cmpb.2018.04.012&partnerID=40&md5=ed5b73eb146d216ef7c863681531b9e8","Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 535 Clementi Road, Singapore, 599489, Singapore; Department of Biomedical Engineering, School of Science and Technology, Singapore University of Social Sciences, Singapore; Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Malaysia; Departments of Neuroscience, Neurology, Biomedical Informatics, The Ohio State University, 470 Hitchcock Hall, 2070 Neil Avenue, Columbus, OH, United States; Department of Electrical Engineering, National Institute of Technology Calicut, India","Acharya U.R., Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 535 Clementi Road, Singapore, 599489, Singapore, Department of Biomedical Engineering, School of Science and Technology, Singapore University of Social Sciences, Singapore, Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Malaysia; Oh S.L., Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 535 Clementi Road, Singapore, 599489, Singapore; Hagiwara Y., Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 535 Clementi Road, Singapore, 599489, Singapore; Tan J.H., Department of Electronics and Computer Engineering, Ngee Ann Polytechnic, 535 Clementi Road, Singapore, 599489, Singapore; Adeli H., Departments of Neuroscience, Neurology, Biomedical Informatics, The Ohio State University, 470 Hitchcock Hall, 2070 Neil Avenue, Columbus, OH, United States; Subha D.P., Department of Electrical Engineering, National Institute of Technology Calicut, India","In recent years, advanced neurocomputing and machine learning techniques have been used for Electroencephalogram (EEG)-based diagnosis of various neurological disorders. In this paper, a novel computer model is presented for EEG-based screening of depression using a deep neural network machine learning approach, known as Convolutional Neural Network (CNN). The proposed technique does not require a semi-manually-selected set of features to be fed into a classifier for classification. It learns automatically and adaptively from the input EEG signals to differentiate EEGs obtained from depressive and normal subjects. The model was tested using EEGs obtained from 15 normal and 15 depressed patients. The algorithm attained accuracies of 93.5% and 96.0% using EEG signals from the left and right hemisphere, respectively. It was discovered in this research that the EEG signals from the right hemisphere are more distinctive in depression than those from the left hemisphere. This discovery is consistent with recent research and revelation that the depression is associated with a hyperactive right hemisphere. An exciting extension of this research would be diagnosis of different stages and severity of depression and development of a Depression Severity Index (DSI). © 2018 Elsevier B.V.","Convolutional neural network; Deep learning; Depression; EEG; Electroencephalogram","Algorithms; Automatic Data Processing; Computer Simulation; Depression; Diagnosis, Computer-Assisted; Electroencephalography; Humans; Machine Learning; Neural Networks (Computer); Reproducibility of Results; Signal Processing, Computer-Assisted; Biomedical signal processing; Convolution; Deep learning; Electroencephalography; Neural networks; Convolutional neural network; Convolutional Neural Networks (CNN); Deep convolutional neural networks; Depression; Electro-encephalogram (EEG); Machine learning techniques; Neurological disorders; Recent researches; adult; article; classification; classifier; clinical article; diagnosis; electroencephalogram; female; human; left hemisphere; machine learning; male; right hemisphere; algorithm; artificial neural network; computer assisted diagnosis; computer simulation; depression; diagnostic imaging; electroencephalography; information processing; machine learning; procedures; reproducibility; signal processing; Deep neural networks","Elsevier Ireland Ltd","01692607","","CMPBE","29852953","Article","Scopus","2-s2.0-85046376921"
"Reeve H.W.; Brown G.","Reeve, Henry WJ (43061497800); Brown, Gavin (7406467765)","43061497800; 7406467765","Diversity and degrees of freedom in regression ensembles","2018","Neurocomputing","21","10.1016/j.neucom.2017.12.066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042871087&doi=10.1016%2fj.neucom.2017.12.066&partnerID=40&md5=85f8cf54df8cbf23ff087ebd95cd84bf","University of Manchester - School of Computer Science Kilburn Building, University of Manchester, Oxford Rd, Manchester M13 9PL, United Kingdom","Reeve H.W., University of Manchester - School of Computer Science Kilburn Building, University of Manchester, Oxford Rd, Manchester M13 9PL, United Kingdom; Brown G., University of Manchester - School of Computer Science Kilburn Building, University of Manchester, Oxford Rd, Manchester M13 9PL, United Kingdom","Ensemble methods are a cornerstone of modern machine learning. The performance of an ensemble depends crucially upon the level of diversity between its constituent learners. This paper establishes a connection between diversity and degrees of freedom (i.e. the capacity of the model), showing that diversity may be viewed as a form of inverse regularisation. This is achieved by focusing on a previously published algorithm Negative Correlation Learning (NCL), in which model diversity is explicitly encouraged through a diversity penalty term in the loss function. We provide an exact formula for the effective degrees of freedom in an NCL ensemble with fixed basis functions, showing that it is a continuous, convex and monotonically increasing function of the diversity parameter. We demonstrate a connection to Tikhonov regularisation and show that, with an appropriately chosen diversity parameter, an NCL ensemble can always outperform the unregularised ensemble in the presence of noise. We demonstrate the practical utility of our approach by deriving a method to efficiently tune the diversity parameter. Finally, we use a Monte-Carlo estimator to extend the connection between diversity and degrees of freedom to ensembles of deep neural networks. © 2018 The Authors","Deep neural networks; Degrees of freedom; Ensembles; Negative Correlation Learning; Stein's unbiased risk estimate; Tikhonov regularisation","Deep neural networks; Inverse problems; Risk perception; Effective degrees of freedoms; Ensemble methods; Ensembles; Increasing functions; Monte Carlo Estimators; Negative correlation learning; Regularisation; Unbiased risk estimates; algorithm; Article; artificial neural network; deep neural network; ensemble method; machine learning; mathematical computing; Monte Carlo method; negative correlation learning; priority journal; Tikhonov regularization; Degrees of freedom (mechanics)","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85042871087"
"Myneni S.; Sridharan V.; Cobb N.; Cohen T.","Myneni, Sahiti (35097608700); Sridharan, Vishnupriya (57194240256); Cobb, Nathan (35106641700); Cohen, Trevor (8436258000)","35097608700; 57194240256; 35106641700; 8436258000","Content-sensitive characterization of peer interactions of highly engaged users in an online community for smoking cessation: mixed-methods approach for modeling user engagement in health promotion interventions","2018","Journal of Participatory Medicine","3","10.2196/jopm.9745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096962041&doi=10.2196%2fjopm.9745&partnerID=40&md5=4f03db5fc1f6eafe8b50a62580a3b323","School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States; Georgetown University Medical Center, Washington, DC, United States","Myneni S., School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States; Sridharan V., School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States; Cobb N., Georgetown University Medical Center, Washington, DC, United States; Cohen T., School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States","Background: Online communities provide affordable venues for behavior change. However, active user engagement holds the key to the success of these platforms. In order to enhance user engagement and in turn, health outcomes, it is essential to offer targeted interventional and informational support. Objective: In this paper, we describe a content plus frequency framework to enable the characterization of highly engaged users in online communities and study theoretical techniques employed by these users through analysis of exchanged communication. Methods: We applied the proposed methodology for analysis of peer interactions within QuitNet, an online community for smoking cessation. Firstly, we identified 144 highly engaged users based on communication frequency within QuitNet over a period of 16 years. Secondly, we used the taxonomy of behavior change techniques, text analysis methods from distributional semantics, machine learning, and sentiment analysis to assign theory-driven labels to content. Finally, we extracted content-specific insights from peer interactions (n=159,483 messages) among highly engaged QuitNet users. Results: Studying user engagement using our proposed framework led to the definition of 3 user categories—conversation initiators, conversation attractors, and frequent posters. Specific behavior change techniques employed by top tier users (threshold set at top 3) within these 3 user groups were found to be goal setting, social support, rewards and threat, and comparison of outcomes. Engagement-specific trends within sentiment manifestations were also identified. Conclusions: Use of content-inclusive analytics has offered deep insight into specific behavior change techniques employed by highly engaged users within QuitNet. Implications for personalization and active user engagement are discussed. ©Gaye Moore, Helen Wilding, Kathleen Gray, David Castle.","Smoking cessation; Text analysis; User engagement","","JMIR Publications Inc.","21527202","","","","Article","Scopus","2-s2.0-85096962041"
"Wu J.; Mazur T.R.; Ruan S.; Lian C.; Daniel N.; Lashmett H.; Ochoa L.; Zoberi I.; Anastasio M.A.; Gach H.M.; Mutic S.; Thomas M.; Li H.","Wu, Jian (56342081800); Mazur, Thomas R. (56581661900); Ruan, Su (7102191561); Lian, Chunfeng (56517715300); Daniel, Nalini (57201678557); Lashmett, Hilary (57201679873); Ochoa, Laura (57088140000); Zoberi, Imran (57193119887); Anastasio, Mark A. (7006769220); Gach, H. Michael (6602093725); Mutic, Sasa (7004029328); Thomas, Maria (57087636400); Li, Hua (57000055400)","56342081800; 56581661900; 7102191561; 56517715300; 57201678557; 57201679873; 57088140000; 57193119887; 7006769220; 6602093725; 7004029328; 57087636400; 57000055400","A deep Boltzmann machine-driven level set method for heart motion tracking using cine MRI images","2018","Medical Image Analysis","25","10.1016/j.media.2018.03.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045707967&doi=10.1016%2fj.media.2018.03.015&partnerID=40&md5=3f38ceacece5aa0d34a1b05864a1e116","Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Laboratoire LITIS (EA 4108), Equipe Quantif, University of Rouen, Rouen, 76183, France; Department of Biomedical Engineering, Washington University, St. Louis, 63110, MO, United States","Wu J., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Mazur T.R., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Ruan S., Laboratoire LITIS (EA 4108), Equipe Quantif, University of Rouen, Rouen, 76183, France; Lian C., Laboratoire LITIS (EA 4108), Equipe Quantif, University of Rouen, Rouen, 76183, France; Daniel N., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Lashmett H., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Ochoa L., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Zoberi I., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Anastasio M.A., Department of Biomedical Engineering, Washington University, St. Louis, 63110, MO, United States; Gach H.M., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Mutic S., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Thomas M., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States; Li H., Department of Radiation Oncology, Washington University, St. Louis, 63110, MO, United States","Heart motion tracking for radiation therapy treatment planning can result in effective motion management strategies to minimize radiation-induced cardiotoxicity. However, automatic heart motion tracking is challenging due to factors that include the complex spatial relationship between the heart and its neighboring structures, dynamic changes in heart shape, and limited image contrast, resolution, and volume coverage. In this study, we developed and evaluated a deep generative shape model-driven level set method to address these challenges. The proposed heart motion tracking method makes use of a heart shape model that characterizes the statistical variations in heart shapes present in a training data set. This heart shape model was established by training a three-layered deep Boltzmann machine (DBM) in order to characterize both local and global heart shape variations. During the tracking phase, a distance regularized level-set evolution (DRLSE) method was applied to delineate the heart contour on each frame of a cine MRI image sequence. The trained shape model was embedded into the DRLSE method as a shape prior term to constrain an evolutional shape to reach the desired heart boundary. Frame-by-frame heart motion tracking was achieved by iteratively mapping the obtained heart contour for each frame to the next frame as a reliable initialization, and performing a level-set evolution. The performance of the proposed motion tracking method was demonstrated using thirty-eight coronal cine MRI image sequences. © 2018 Elsevier B.V.","Deep Boltzmann machine; Distance regularized level-set evolution; Generative shape model; Heart motion tracking; MRI-guided radiation therapy","Algorithms; Head and Neck Neoplasms; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging, Cine; Markov Chains; Motion; Neural Networks (Computer); Radiation Injuries; Radiotherapy, Image-Guided; Drop breakup; Heart; Iterative methods; Level measurement; Magnetic resonance imaging; Motion analysis; Radiotherapy; Deep boltzmann machines; Distance regularized level sets; Heart motion; Mri guided; Shape model; Article; artificial neural network; cancer radiotherapy; cine magnetic resonance imaging; Deep Boltzmann machine; evolution; heart movement; human; image guided radiotherapy; machine learning; magnetic resonance imaging guided radiation therapy; Markov chain; nuclear magnetic resonance imaging; priority journal; stochastic model; treatment planning; algorithm; artificial neural network; cine magnetic resonance imaging; diagnostic imaging; head and neck tumor; heart; image processing; motion; physiology; procedures; radiation injury; radiation response; Numerical methods","Elsevier B.V.","13618415","","MIAEC","29679848","Article","Scopus","2-s2.0-85045707967"
"Gong E.; Pauly J.M.; Wintermark M.; Zaharchuk G.","Gong, Enhao (56046651600); Pauly, John M. (7101724924); Wintermark, Max (7003404861); Zaharchuk, Greg (6602464023)","56046651600; 7101724924; 7003404861; 6602464023","Deep learning enables reduced gadolinium dose for contrast-enhanced brain MRI","2018","Journal of Magnetic Resonance Imaging","214","10.1002/jmri.25970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042057795&doi=10.1002%2fjmri.25970&partnerID=40&md5=1e36dfdc370a1829d080c63bdd4d99ea","Department of Electrical Engineering, Stanford University, Stanford, CA, United States; Department of Radiology, Stanford University, Stanford, CA, United States","Gong E., Department of Electrical Engineering, Stanford University, Stanford, CA, United States, Department of Radiology, Stanford University, Stanford, CA, United States; Pauly J.M., Department of Electrical Engineering, Stanford University, Stanford, CA, United States; Wintermark M., Department of Radiology, Stanford University, Stanford, CA, United States; Zaharchuk G., Department of Radiology, Stanford University, Stanford, CA, United States","                             Background: There are concerns over gadolinium deposition from gadolinium-based contrast agents (GBCA) administration. Purpose: To reduce gadolinium dose in contrast-enhanced brain MRI using a deep learning method. Study type: Retrospective, crossover. Population: Sixty patients receiving clinically indicated contrast-enhanced brain MRI. Sequence: 3D T                             1                             -weighted inversion-recovery prepped fast-spoiled-gradient-echo (IR-FSPGR) imaging was acquired at both 1.5T and 3T. In 60 brain MRI exams, the IR-FSPGR sequence was obtained under three conditions: precontrast, postcontrast images with 10% low-dose (0.01mmol/kg) and 100% full-dose (0.1 mmol/kg) of gadobenate dimeglumine. We trained a deep learning model using the first 10 cases (with mixed indications) to approximate full-dose images from the precontrast and low-dose images. Synthesized full-dose images were created using the trained model in two test sets: 20 patients with mixed indications and 30 patients with glioma. Assessment: For both test sets, low-dose, true full-dose, and the synthesized full-dose postcontrast image sets were compared quantitatively using peak-signal-to-noise-ratios (PSNR) and structural-similarity-index (SSIM). For the test set comprised of 20 patients with mixed indications, two neuroradiologists scored blindly and independently for the three postcontrast image sets, evaluating image quality, motion-artifact suppression, and contrast enhancement compared with precontrast images. Statistical Analysis: Results were assessed using paired t-tests and noninferiority tests. Results: The proposed deep learning method yielded significant (n = 50, P < 0.001) improvements over the low-dose images (>5 dB PSNR gains and >11.0% SSIM). Ratings on image quality (n = 20, P = 0.003) and contrast enhancement (n = 20, P < 0.001) were significantly increased. Compared to true full-dose images, the synthesized full-dose images have a slight but not significant reduction in image quality (n = 20, P = 0.083) and contrast enhancement (n = 20, P = 0.068). Slightly better (n = 20, P = 0.039) motion-artifact suppression was noted in the synthesized images. The noninferiority test rejects the inferiority of the synthesized to true full-dose images for image quality (95% CI: –14–9%), artifacts suppression (95% CI: –5–20%), and contrast enhancement (95% CI: –13–6%). Data Conclusion: With the proposed deep learning method, gadolinium dose can be reduced 10-fold while preserving contrast information and avoiding significant image quality degradation. Level of Evidence: 3. Technical Efficacy: Stage 5. J. MAGN. RESON. IMAGING 2018;48:330–340.                          © 2018 International Society for Magnetic Resonance in Medicine","contrast enhanced MRI; deep learning; gadolinium deposition; image quality; low dose; machine learning","Adult; Aged; Artifacts; Brain; Brain Neoplasms; Contrast Media; Deep Learning; Female; Gadolinium; Glioma; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Middle Aged; Motion; gadobenate dimeglumine; contrast medium; gadolinium; adult; Article; artifact reduction; confidence interval; contrast enhancement; controlled study; deep learning; drug dose reduction; female; glioma; human; image quality; inversion recovery prepped fast spoiled gradient echo imaging; machine learning; major clinical study; male; neuroimaging; neuroradiologist; nuclear magnetic resonance imaging; peak signal to noise ratio; priority journal; quantitative analysis; radiological parameters; retrospective study; signal noise ratio; structural similarity index; Student t test; three dimensional imaging; aged; artifact; brain; brain tumor; chemistry; diagnostic imaging; machine learning; middle aged; motion","John Wiley and Sons Inc.","10531807","","JMRIF","29437269","Article","Scopus","2-s2.0-85042057795"
"Sudha S.; Jayanthi K.B.; Rajasekaran C.; Madian N.; Sunder T.","Sudha, S. (57197371312); Jayanthi, K.B. (57206421967); Rajasekaran, C. (55314930400); Madian, Nirmala (55516660800); Sunder, T. (58386830300)","57197371312; 57206421967; 55314930400; 55516660800; 58386830300","Convolutional Neural Network for Segmentation and Measurement of Intima Media Thickness","2018","Journal of Medical Systems","26","10.1007/s10916-018-1001-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049838323&doi=10.1007%2fs10916-018-1001-y&partnerID=40&md5=1593e1be815f854135d55d1f27958de2","Department of Electronics and Communication Engineering, K.S.Rangasamy College of Technology, Tamil Nadu, India; Department of Electronics and Communication Engineering, Sri Shakthi Institute of Engineering and Technology, Coimbatore, 641 062, India; Apollo Hospitals, Chennai, India","Sudha S., Department of Electronics and Communication Engineering, K.S.Rangasamy College of Technology, Tamil Nadu, India; Jayanthi K.B., Department of Electronics and Communication Engineering, K.S.Rangasamy College of Technology, Tamil Nadu, India; Rajasekaran C., Department of Electronics and Communication Engineering, K.S.Rangasamy College of Technology, Tamil Nadu, India; Madian N., Department of Electronics and Communication Engineering, Sri Shakthi Institute of Engineering and Technology, Coimbatore, 641 062, India; Sunder T., Apollo Hospitals, Chennai, India","The measurement of Carotid Intima Media Thickness (IMT) on Common Carotid Artery (CCA) is a principle marker of risk of cardiovascular disease. This paper presents a novel method of using deep Convolutional Neural Network (CNN) for identification and measurement of IMT on the far wall of the artery. The Region of Interest (ROI) is extracted using CNN architecture with 8 layers. 110 subjects are taken for the study. Each subject is recorded with one Right Common Carotid Artery (RCCA) and Left Common Carotid Artery (LCCA) frame resulting in 220 recordings. Patch based segmentation with 2640 patches are given to the training network for ROI localization. Intima Media Complex (IMC) is the area where IMT is measured. This region is extracted after defining the ROI. Keeping in mind the end objective of measurement of IMT values binary threshold with snake algorithm is applied to extract the lumen-intima and media-adventitia boundary. IMT values are measured for 20 cases and mean difference is found to be 0.08 mm. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Cardio vascular disease (CVD); Carotid intima media thickness (CIMT); Convolutional neural network (CNN); Deep learning","Algorithms; Carotid Arteries; Carotid Artery, Common; Carotid Intima-Media Thickness; Humans; Neural Networks (Computer); adventitia; algorithm; arterial wall thickness; artery intima; Article; cardiovascular parameters; convolutional neural network; diagnostic accuracy; false negative result; false positive result; image analysis; image processing; image segmentation; intima media complex; left common carotid artery; machine learning; measurement; predictive value; receiver operating characteristic; right common carotid artery; snake algorithm; algorithm; artificial neural network; carotid artery; common carotid artery; human","Springer New York LLC","01485598","","JMSYD","29987622","Article","Scopus","2-s2.0-85049838323"
"Emami H.; Dong M.; Nejad-Davarani S.P.; Glide-Hurst C.K.","Emami, Hajar (57203140067); Dong, Ming (55724049700); Nejad-Davarani, Siamak P. (36145518600); Glide-Hurst, Carri K. (22950635400)","57203140067; 55724049700; 36145518600; 22950635400","Generating synthetic CTs from magnetic resonance images using generative adversarial networks","2018","Medical Physics","221","10.1002/mp.13047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050670728&doi=10.1002%2fmp.13047&partnerID=40&md5=5a3435b217273b1f95ae8706ab182ab0","Department of Computer Science, Wayne State University, Detroit, 48202, MI, United States; Department of Radiation Oncology, Henry Ford Health System, Detroit, 48202, MI, United States","Emami H., Department of Computer Science, Wayne State University, Detroit, 48202, MI, United States; Dong M., Department of Computer Science, Wayne State University, Detroit, 48202, MI, United States; Nejad-Davarani S.P., Department of Radiation Oncology, Henry Ford Health System, Detroit, 48202, MI, United States; Glide-Hurst C.K., Department of Radiation Oncology, Henry Ford Health System, Detroit, 48202, MI, United States","Purpose: While MR-only treatment planning using synthetic CTs (synCTs) offers potential for streamlining clinical workflow, a need exists for an efficient and automated synCT generation in the brain to facilitate near real-time MR-only planning. This work describes a novel method for generating brain synCTs based on generative adversarial networks (GANs), a deep learning model that trains two competing networks simultaneously, and compares it to a deep convolutional neural network (CNN). Methods: Post-Gadolinium T1-Weighted and CT-SIM images from fifteen brain cancer patients were retrospectively analyzed. The GAN model was developed to generate synCTs using T1-weighted MRI images as the input using a residual network (ResNet) as the generator. The discriminator is a CNN with five convolutional layers that classified the input image as real or synthetic. Fivefold cross-validation was performed to validate our model. GAN performance was compared to CNN based on mean absolute error (MAE), structural similarity index (SSIM), and peak signal-to-noise ratio (PSNR) metrics between the synCT and CT images. Results: GAN training took ~11 h with a new case testing time of 5.7 ± 0.6 s. For GAN, MAEs between synCT and CT-SIM were 89.3 ± 10.3 Hounsfield units (HU) and 41.9 ± 8.6 HU across the entire FOV and tissues, respectively. However, MAE in the bone and air was, on average, ~240–255 HU. By comparison, the CNN model had an average full FOV MAE of 102.4 ± 11.1 HU. For GAN, the mean PSNR was 26.6 ± 1.2 and SSIM was 0.83 ± 0.03. GAN synCTs preserved details better than CNN, and regions of abnormal anatomy were well represented on GAN synCTs. Conclusions: We developed and validated a GAN model using a single T1-weighted MR image as the input that generates robust, high quality synCTs in seconds. Our method offers strong potential for supporting near real-time MR-only treatment planning in the brain. © 2018 American Association of Physicists in Medicine","generative adversarial network; radiation therapy; synthetic CTs","Computerized tomography; Convolution; Deep neural networks; Magnetic resonance; Magnetic resonance imaging; Radiotherapy; Signal to noise ratio; gadolinium; Convolutional neural network; Hounsfield units; Mean absolute error; Near-real time; Network models; Similarity indices; Structural similarity; Synthetic CT; T1-weighted; Treatment planning; aged; Article; auditory canal; brain cancer; cancer patient; clinical article; clinical evaluation; comparative study; computer assisted tomography; convolutional neural network; deep learning; feedback system; female; generative adversarial network; human; information processing; machine learning; mean absolute error; nerve cell; nuclear magnetic resonance imaging; peak signal to noise; probability; radiological parameters; receptive field; signal noise ratio; structural similarity index; synthetic computer assisted tomography; treatment planning; very elderly; workflow; Generative adversarial networks","John Wiley and Sons Ltd","00942405","","MPHYA","29901223","Article","Scopus","2-s2.0-85050670728"
"Wu K.; Zhao Z.; Wang R.; Wei G.-W.","Wu, Kedi (57196481371); Zhao, Zhixiong (36674330900); Wang, Renxiao (7405340239); Wei, Guo-Wei (7402848203)","57196481371; 36674330900; 7405340239; 7402848203","TopP–S: Persistent homology-based multi-task deep neural networks for simultaneous predictions of partition coefficient and aqueous solubility","2018","Journal of Computational Chemistry","60","10.1002/jcc.25213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045091243&doi=10.1002%2fjcc.25213&partnerID=40&md5=2ba3e623dacbe881394ea92129350573","Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States; School of Medicine, Foshan University, Foshan, 528000, Guangdong, China; State Key Laboratory of Bioorganic Chemistry, Shanghai Institute of Organic Chemistry, Chinese Academy of Sciences, Shanghai, 200032, China; Department of Electrical and Computer Engineering, Michigan State University, 48824, MI, United States; Department of Biochemistry and Molecular Biology, Michigan State University, 48824, MI, United States","Wu K., Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States; Zhao Z., School of Medicine, Foshan University, Foshan, 528000, Guangdong, China; Wang R., State Key Laboratory of Bioorganic Chemistry, Shanghai Institute of Organic Chemistry, Chinese Academy of Sciences, Shanghai, 200032, China; Wei G.-W., Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States, Department of Electrical and Computer Engineering, Michigan State University, 48824, MI, United States, Department of Biochemistry and Molecular Biology, Michigan State University, 48824, MI, United States","Aqueous solubility and partition coefficient are important physical properties of small molecules. Accurate theoretical prediction of aqueous solubility and partition coefficient plays an important role in drug design and discovery. The prediction accuracy depends crucially on molecular descriptors which are typically derived from a theoretical understanding of the chemistry and physics of small molecules. This work introduces an algebraic topology-based method, called element-specific persistent homology (ESPH), as a new representation of small molecules that is entirely different from conventional chemical and/or physical representations. ESPH describes molecular properties in terms of multiscale and multicomponent topological invariants. Such topological representation is systematical, comprehensive, and scalable with respect to molecular size and composition variations. However, it cannot be literally translated into a physical interpretation. Fortunately, it is readily suitable for machine learning methods, rendering topological learning algorithms. Due to the inherent correlation between solubility and partition coefficient, a uniform ESPH representation is developed for both properties, which facilitates multi-task deep neural networks for their simultaneous predictions. This strategy leads to a more accurate prediction of relatively small datasets. A total of six datasets is considered in this work to validate the proposed topological and multitask deep learning approaches. It is demonstrated that the proposed approaches achieve some of the most accurate predictions of aqueous solubility and partition coefficient. Our software is available online at http://weilab.math.msu.edu/TopP-S/. © 2018 Wiley Periodicals, Inc. © 2018 Wiley Periodicals, Inc.","aqueous solubility; deep neural networks; multitask learning; partition coefficient; persistent homology; topological learning","Algorithms; Molecular Dynamics Simulation; Neural Networks (Computer); Software; Solubility; Water; Algebra; Drug delivery; Forecasting; Learning algorithms; Molecules; Solubility; Topology; water; Aqueous solubility; Multitask learning; Partition coefficient; Persistent homology; Topological learning; algorithm; artificial neural network; chemistry; molecular dynamics; software; solubility; Deep neural networks","John Wiley and Sons Inc.","01928651","","JCCHD","29633287","Article","Scopus","2-s2.0-85045091243"
"Vigneault D.M.; Xie W.; Ho C.Y.; Bluemke D.A.; Noble J.A.","Vigneault, Davis M. (56611878900); Xie, Weidi (57192403839); Ho, Carolyn Y. (35299617300); Bluemke, David A. (7006047770); Noble, J. Alison (56185660000)","56611878900; 57192403839; 35299617300; 7006047770; 56185660000","Ω-Net (Omega-Net): Fully automatic, multi-view cardiac MR detection, orientation, and segmentation with deep neural networks","2018","Medical Image Analysis","112","10.1016/j.media.2018.05.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047610606&doi=10.1016%2fj.media.2018.05.008&partnerID=40&md5=1e5d602932ac3fc7473940e57a55164f","Institute of Biomedical Engineering, Department of Engineering, University of Oxford, United Kingdom; Department of Radiology and Imaging Sciences, Clinical Center, National Institutes of Health, United States; Tufts University School of Medicine, Sackler School of Graduate Biomedical Sciences, United States; Cardiovascular Division, Brigham and Women's Hospital, United States; School of Medicine and Public Health, University of Wisconsin-Madison, United States","Vigneault D.M., Institute of Biomedical Engineering, Department of Engineering, University of Oxford, United Kingdom, Department of Radiology and Imaging Sciences, Clinical Center, National Institutes of Health, United States, Tufts University School of Medicine, Sackler School of Graduate Biomedical Sciences, United States; Xie W., Institute of Biomedical Engineering, Department of Engineering, University of Oxford, United Kingdom; Ho C.Y., Cardiovascular Division, Brigham and Women's Hospital, United States; Bluemke D.A., School of Medicine and Public Health, University of Wisconsin-Madison, United States; Noble J.A., Institute of Biomedical Engineering, Department of Engineering, University of Oxford, United Kingdom","Pixelwise segmentation of the left ventricular (LV) myocardium and the four cardiac chambers in 2-D steady state free precession (SSFP) cine sequences is an essential preprocessing step for a wide range of analyses. Variability in contrast, appearance, orientation, and placement of the heart between patients, clinical views, scanners, and protocols makes fully automatic semantic segmentation a notoriously difficult problem. Here, we present Ω-Net (Omega-Net): A novel convolutional neural network (CNN) architecture for simultaneous localization, transformation into a canonical orientation, and semantic segmentation. First, an initial segmentation is performed on the input image; second, the features learned during this initial segmentation are used to predict the parameters needed to transform the input image into a canonical orientation; and third, a final segmentation is performed on the transformed image. In this work, Ω-Nets of varying depths were trained to detect five foreground classes in any of three clinical views (short axis, SA; four-chamber, 4C; two-chamber, 2C), without prior knowledge of the view being segmented. This constitutes a substantially more challenging problem compared with prior work. The architecture was trained using three-fold cross-validation on a cohort of patients with hypertrophic cardiomyopathy (HCM, N=42) and healthy control subjects (N=21). Network performance, as measured by weighted foreground intersection-over-union (IoU), was substantially improved for the best-performing Ω-Net compared with U-Net segmentation without localization or orientation (0.858 vs 0.834). In addition, to be comparable with other works, Ω-Net was retrained from scratch using five-fold cross-validation on the publicly available 2017 MICCAI Automated Cardiac Diagnosis Challenge (ACDC) dataset. The Ω-Net outperformed the state-of-the-art method in segmentation of the LV and RV bloodpools, and performed slightly worse in segmentation of the LV myocardium. We conclude that this architecture represents a substantive advancement over prior approaches, with implications for biomedical image segmentation more generally. © 2018","Cardiac magnetic resonance; Deep convolutional neural networks; Semantic segmentation; Spatial transformer networks","Algorithms; Cardiac Imaging Techniques; Cardiomyopathy, Hypertrophic; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Convolution; Deep neural networks; Diagnosis; Heart; Magnetic levitation vehicles; Magnetic resonance; Network architecture; Neural networks; Semantics; Biomedical image segmentation; Cardiac magnetic resonance; Convolutional Neural Networks (CNN); Deep convolutional neural networks; Hypertrophic cardiomyopathy; Left ventricular myocardiums; Semantic segmentation; Steady state free precessions; accuracy; Article; cardiac muscle; cardiovascular magnetic resonance; clinical article; cohort analysis; controlled study; deep neural network; heart atrioventricular valve; heart papillary muscle; human; hypertrophic cardiomyopathy; image segmentation; machine learning; orientation; priority journal; algorithm; artificial neural network; cardiac imaging; diagnostic imaging; image processing; procedures; Image segmentation","Elsevier B.V.","13618415","","MIAEC","29857330","Article","Scopus","2-s2.0-85047610606"
"Koivu A.; Korpimäki T.; Kivelä P.; Pahikkala T.; Sairanen M.","Koivu, Aki (57194457422); Korpimäki, Teemu (57224374632); Kivelä, Petri (57202006526); Pahikkala, Tapio (8930918900); Sairanen, Mikko (6506585892)","57194457422; 57224374632; 57202006526; 8930918900; 6506585892","Evaluation of machine learning algorithms for improved risk assessment for Down's syndrome","2018","Computers in Biology and Medicine","25","10.1016/j.compbiomed.2018.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046822586&doi=10.1016%2fj.compbiomed.2018.05.004&partnerID=40&md5=13746c04d3ccd85012d5f4ae29e0b823","University of Turku, Turun Yliopisto, Turku, Finland; PerkinElmer, Mustionkatu 6, Turku, 20750, Finland","Koivu A., University of Turku, Turun Yliopisto, Turku, Finland; Korpimäki T., PerkinElmer, Mustionkatu 6, Turku, 20750, Finland; Kivelä P., PerkinElmer, Mustionkatu 6, Turku, 20750, Finland; Pahikkala T., University of Turku, Turun Yliopisto, Turku, Finland; Sairanen M., PerkinElmer, Mustionkatu 6, Turku, 20750, Finland","Prenatal screening generates a great amount of data that is used for predicting risk of various disorders. Prenatal risk assessment is based on multiple clinical variables and overall performance is defined by how well the risk algorithm is optimized for the population in question. This article evaluates machine learning algorithms to improve performance of first trimester screening of Down syndrome. Machine learning algorithms pose an adaptive alternative to develop better risk assessment models using the existing clinical variables. Two real-world data sets were used to experiment with multiple classification algorithms. Implemented models were tested with a third, real-world, data set and performance was compared to a predicate method, a commercial risk assessment software. Best performing deep neural network model gave an area under the curve of 0.96 and detection rate of 78% with 1% false positive rate with the test data. Support vector machine model gave area under the curve of 0.95 and detection rate of 61% with 1% false positive rate with the same test data. When compared with the predicate method, the best support vector machine model was slightly inferior, but an optimized deep neural network model was able to give higher detection rates with same false positive rate or similar detection rate but with markedly lower false positive rate. This finding could further improve the first trimester screening for Down syndrome, by using existing clinical variables and a large training data derived from a specific population. © 2018 Elsevier Ltd","Down syndrome; Multi-layer neural network; Predictive modeling; Prenatal risk assessment; Trisomy 21","Adult; Algorithms; Down Syndrome; Female; Humans; Machine Learning; Models, Statistical; Neural Networks (Computer); Pregnancy; Prenatal Diagnosis; Risk Assessment; ROC Curve; Support Vector Machine; Artificial intelligence; Classification (of information); Deep neural networks; Network layers; Population statistics; Risk assessment; Software testing; Support vector machines; Area under the curves; Down syndrome; Multiple Classification; Neural network model; Predictive modeling; Risk assessment models; Support vector machine models; Trisomy 21; adult; algorithm; area under the curve; Article; controlled study; Down syndrome; false positive result; female; human; machine learning; major clinical study; prenatal screening; priority journal; random forest; risk assessment; support vector machine; algorithm; artificial neural network; Down syndrome; pregnancy; prenatal diagnosis; procedures; receiver operating characteristic; statistical model; Learning algorithms","Elsevier Ltd","00104825","","CBMDA","29758452","Article","Scopus","2-s2.0-85046822586"
"Hughes A.J.; Mornin J.D.; Biswas S.K.; Beck L.E.; Bauer D.P.; Raj A.; Bianco S.; Gartner Z.J.","Hughes, Alex J. (36461010100); Mornin, Joseph D. (57203396208); Biswas, Sujoy K. (57214530793); Beck, Lauren E. (57193732159); Bauer, David P. (57203400200); Raj, Arjun (9433591600); Bianco, Simone (9737903800); Gartner, Zev J. (6603150955)","36461010100; 57203396208; 57214530793; 57193732159; 57203400200; 9433591600; 9737903800; 6603150955","Quanti.us: a tool for rapid, flexible, crowd-based annotation of images","2018","Nature Methods","38","10.1038/s41592-018-0069-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051458017&doi=10.1038%2fs41592-018-0069-0&partnerID=40&md5=03cbdc4149aaee5ddaa62b581766f470","Department of Pharmaceutical Chemistry, University of California, San Francisco, San Francisco, CA, United States; NSF Center for Cellular Construction, University of California, San Francisco, San Francisco, CA, United States; Independent Researcher, Berkeley, CA, United States; Department of Industrial and Applied Genomics, IBM Accelerated Discovery Laboratory, IBM Almaden Research Center, San Jose, CA, United States; Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States; Department of Cellular and Molecular Pharmacology, University of California, San Francisco, San Francisco, CA, United States; Chan Zuckerberg Biohub, San Francisco, CA, United States; Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States","Hughes A.J., Department of Pharmaceutical Chemistry, University of California, San Francisco, San Francisco, CA, United States, NSF Center for Cellular Construction, University of California, San Francisco, San Francisco, CA, United States, Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States; Mornin J.D., Independent Researcher, Berkeley, CA, United States; Biswas S.K., NSF Center for Cellular Construction, University of California, San Francisco, San Francisco, CA, United States, Department of Industrial and Applied Genomics, IBM Accelerated Discovery Laboratory, IBM Almaden Research Center, San Jose, CA, United States; Beck L.E., Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States; Bauer D.P., NSF Center for Cellular Construction, University of California, San Francisco, San Francisco, CA, United States, Department of Cellular and Molecular Pharmacology, University of California, San Francisco, San Francisco, CA, United States; Raj A., Department of Bioengineering, University of Pennsylvania, Philadelphia, PA, United States; Bianco S., NSF Center for Cellular Construction, University of California, San Francisco, San Francisco, CA, United States, Department of Industrial and Applied Genomics, IBM Accelerated Discovery Laboratory, IBM Almaden Research Center, San Jose, CA, United States; Gartner Z.J., Department of Pharmaceutical Chemistry, University of California, San Francisco, San Francisco, CA, United States, NSF Center for Cellular Construction, University of California, San Francisco, San Francisco, CA, United States, Chan Zuckerberg Biohub, San Francisco, CA, United States","We describe Quanti.us, a crowd-based image-annotation platform that provides an accurate alternative to computational algorithms for difficult image-analysis problems. We used Quanti.us for a variety of medium-throughput image-analysis tasks and achieved 10–50× savings in analysis time compared with that required for the same task by a single expert annotator. We show equivalent deep learning performance for Quanti.us-derived and expert-derived annotations, which should allow scalable integration with tailored machine learning algorithms. © 2018, The Author(s).","","Algorithms; Animals; Computational Biology; Crowdsourcing; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Internet; Machine Learning; Software; article; human; image analysis; machine learning; algorithm; animal; biology; crowdsourcing; image processing; Internet; procedures; software; three dimensional imaging","Nature Publishing Group","15487091","","","30065368","Article","Scopus","2-s2.0-85051458017"
"Sandhu H.S.; Eltanboly A.; Shalaby A.; Keynton R.S.; Schaal S.; El-Baz A.","Sandhu, Harpal Singh (56905240200); Eltanboly, Ahmed (57189265602); Shalaby, Ahmed (57197612511); Keynton, Robert S. (7004023935); Schaal, Schlomit (9844132900); El-Baz, Ayman (6602350405)","56905240200; 57189265602; 57197612511; 7004023935; 9844132900; 6602350405","Automated diagnosis and grading of diabetic retinopathy using optical coherence tomography","2018","Investigative Ophthalmology and Visual Science","39","10.1167/iovs.17-23677","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060644276&doi=10.1167%2fiovs.17-23677&partnerID=40&md5=8fce8e4363cab96a5d7dfddb2da5ac2e","Department of Ophthalmology and Visual Sciences, University of Louisville, Louisville, KY, United States; Department of Bioengineering, University of Louisville, Louisville, KY, United States; Department of Ophthalmology and Visual Sciences, University of Massachusetts Medical School, Worchester, MA, United States","Sandhu H.S., Department of Ophthalmology and Visual Sciences, University of Louisville, Louisville, KY, United States; Eltanboly A., Department of Bioengineering, University of Louisville, Louisville, KY, United States; Shalaby A., Department of Bioengineering, University of Louisville, Louisville, KY, United States; Keynton R.S., Department of Bioengineering, University of Louisville, Louisville, KY, United States; Schaal S., Department of Ophthalmology and Visual Sciences, University of Massachusetts Medical School, Worchester, MA, United States; El-Baz A., Department of Bioengineering, University of Louisville, Louisville, KY, United States","PURPOSE. We determine the feasibility and accuracy of a computer-assisted diagnostic (CAD) system to diagnose and grade nonproliferative diabetic retinopathy (NPDR) from optical coherence tomography (OCT) images. METHODS. A cross-sectional, single-center study was done of type II diabetics who presented for routine screening and/or monitoring exams. Inclusion criteria were age 18 or older, diagnosis of diabetes mellitus type II, and clear media allowing for OCT imaging. Exclusion criteria were inability to image the macula, posterior staphylomas, proliferative diabetic retinopathy, and concurrent retinovascular disease. All patients underwent a full dilated eye exam and spectral-domain OCT of a 6 x 6 mm area of the macula in both eyes. These images then were analyzed by a novel CAD system that segments the retina into 12 layers; quantifies the reflectivity, curvature, and thickness of each layer; and ultimately uses this information to train a neural network that classifies images as either normal or having NPDR, and then further grades the level of retinopathy. A first dataset was tested by ‘‘leave-one-subject-out’’ (LOSO) methods and by 2-and 4-fold cross-validation. The system then was tested on a second, independent dataset. RESULTS. Using LOSO experiments on a dataset of images from 80 patients, the proposed CAD system distinguished normal from NPDR subjects with 93.8% accuracy (sensitivity = 92.5%, specificity = 95%) and achieved 97.4% correct classification between subclinical and mild/ moderate DR. When tested on an independent dataset of 40 patients, the proposed system distinguished between normal and NPDR subjects with 92.5% accuracy and between subclinical and mild/moderate NPDR with 95% accuracy. CONCLUSIONS. A CAD system for automated diagnosis of NPDR based on macular OCT images from type II diabetics is feasible, reliable, and accurate. Â© 2018 The Authors.","Deep fusion classification networks; DFCN; Diabetic retinopathy; Machine learning; Neural networks; NPDR; OCT; SNCAE","Adolescent; Adult; Aged; Aged, 80 and over; Cross-Sectional Studies; Diabetes Mellitus, Type 2; Diabetic Retinopathy; Diagnosis, Computer-Assisted; Female; Humans; Male; Middle Aged; Reproducibility of Results; Sensitivity and Specificity; Tomography, Optical Coherence; Young Adult; antihypertensive agent; adult; aged; Article; computer assisted diagnosis; controlled study; cross-sectional study; diabetic retinopathy; diagnostic accuracy; diagnostic test accuracy study; female; fluorescence angiography; human; hypertension; major clinical study; male; non insulin dependent diabetes mellitus; nonproliferative diabetic retinopathy; optical coherence tomography; priority journal; prospective study; receiver operating characteristic; sensitivity and specificity; spectral domain optical coherence tomography; very elderly; young adult; adolescent; complication; diabetic retinopathy; diagnostic imaging; middle aged; optical coherence tomography; procedures; reproducibility","Association for Research in Vision and Ophthalmology Inc.","01460404","","IOVSD","30029278","Article","Scopus","2-s2.0-85060644276"
"Zahia S.; Sierra-Sosa D.; Garcia-Zapirain B.; Elmaghraby A.","Zahia, Sofia (57201091335); Sierra-Sosa, Daniel (37076014100); Garcia-Zapirain, Begonya (35732954700); Elmaghraby, Adel (7004230200)","57201091335; 37076014100; 35732954700; 7004230200","Tissue classification and segmentation of pressure injuries using convolutional neural networks","2018","Computer Methods and Programs in Biomedicine","55","10.1016/j.cmpb.2018.02.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043369305&doi=10.1016%2fj.cmpb.2018.02.018&partnerID=40&md5=aab242960976e1122e2b5ddd9e25baca","Department of Computer Engineering and Computer Science, Duthie Center for Engineering, University of Louisville, Louisville, 40292, KY, United States; eVida research laboratory, University of Deusto, Bilbao, 48007, Spain","Zahia S., Department of Computer Engineering and Computer Science, Duthie Center for Engineering, University of Louisville, Louisville, 40292, KY, United States, eVida research laboratory, University of Deusto, Bilbao, 48007, Spain; Sierra-Sosa D., Department of Computer Engineering and Computer Science, Duthie Center for Engineering, University of Louisville, Louisville, 40292, KY, United States; Garcia-Zapirain B., eVida research laboratory, University of Deusto, Bilbao, 48007, Spain; Elmaghraby A., Department of Computer Engineering and Computer Science, Duthie Center for Engineering, University of Louisville, Louisville, 40292, KY, United States","Background and Objectives: This paper presents a new approach for automatic tissue classification in pressure injuries. These wounds are localized skin damages which need frequent diagnosis and treatment. Therefore, a reliable and accurate systems for segmentation and tissue type identification are needed in order to achieve better treatment results. Methods: Our proposed system is based on a Convolutional Neural Network (CNN) devoted to performing optimized segmentation of the different tissue types present in pressure injuries (granulation, slough, and necrotic tissues). A preprocessing step removes the flash light and creates a set of 5x5 sub-images which are used as input for the CNN network. The network output will classify every sub-image of the validation set into one of the three classes studied. Results: The metrics used to evaluate our approach show an overall average classification accuracy of 92.01%, an average total weighted Dice Similarity Coefficient of 91.38%, and an average precision per class of 97.31% for granulation tissue, 96.59% for necrotic tissue, and 77.90% for slough tissue. Conclusions: Our system has been proven to make recognition of complicated structures in biomedical images feasible. © 2018 Elsevier B.V.","Convolutional neural networks; Deep learning; Image segmentation; Pressure injuries; Tissue type classification","Algorithms; Databases, Factual; Humans; Image Processing, Computer-Assisted; Models, Anatomic; Models, Statistical; Necrosis; Neural Networks (Computer); Pressure Ulcer; Reproducibility of Results; Sensitivity and Specificity; Tomography, X-Ray Computed; Wound Healing; Wounds and Injuries; Convolution; Deep learning; Granulation; Image segmentation; Neural networks; Tissue engineering; Classification accuracy; Complicated structures; Convolutional neural network; Convolutional Neural Networks (CNN); Optimized segmentation; Similarity coefficients; Tissue classification; Tissue types; Article; automated pattern recognition; clinical evaluation; constants and coefficients; controlled study; convolutional neural network; decubitus; dice similarity coefficient; granulation tissue; image analysis; image processing; image segmentation; machine learning; measurement accuracy; measurement precision; pathological tissue; sensitivity and specificity; slough tissue; tissue characterization; tissue injury; tissue necrosis; validation process; algorithm; anatomic model; artificial neural network; decubitus; diagnostic imaging; factual database; human; injury; necrosis; reproducibility; statistical model; wound healing; x-ray computed tomography; Tissue","Elsevier Ireland Ltd","01692607","","CMPBE","29650318","Article","Scopus","2-s2.0-85043369305"
"Zhu Q.; Li X.; Conesa A.; Pereira C.","Zhu, Qile (57200620712); Li, Xiaolin (57203730508); Conesa, Ana (18633587000); Pereira, Cécile (57188654305)","57200620712; 57203730508; 18633587000; 57188654305","GRAM-CNN: A deep learning approach with local context for named entity recognition in biomedical text","2018","Bioinformatics","100","10.1093/bioinformatics/btx815","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047068763&doi=10.1093%2fbioinformatics%2fbtx815&partnerID=40&md5=1b172769574c8f473b42204f0167ef03","National Science Foundation Center for Big Learning, University of Florida, Gainesville, 32611, FL, United States; Department of Computer and Information Science and Engineering, University of Florida, Gainesville, 32611, FL, United States; Department of Electrical and Computer Engineering, University of Florida, Gainesville, 32611, FL, United States; Department of Microbiology and Cell Science, Institute for Food and Agricultural Sciences, University of Florida, Gainesville, 32611, FL, United States; Genomics of Gene Expression Laboratory, Centro de Investigación Príncipe Felipe, Valencia, 42012, Spain","Zhu Q., National Science Foundation Center for Big Learning, University of Florida, Gainesville, 32611, FL, United States, Department of Computer and Information Science and Engineering, University of Florida, Gainesville, 32611, FL, United States; Li X., National Science Foundation Center for Big Learning, University of Florida, Gainesville, 32611, FL, United States, Department of Electrical and Computer Engineering, University of Florida, Gainesville, 32611, FL, United States; Conesa A., Department of Microbiology and Cell Science, Institute for Food and Agricultural Sciences, University of Florida, Gainesville, 32611, FL, United States, Genomics of Gene Expression Laboratory, Centro de Investigación Príncipe Felipe, Valencia, 42012, Spain; Pereira C., Department of Microbiology and Cell Science, Institute for Food and Agricultural Sciences, University of Florida, Gainesville, 32611, FL, United States","Motivation Best performing named entity recognition (NER) methods for biomedical literature are based on hand-crafted features or task-specific rules, which are costly to produce and difficult to generalize to other corpora. End-to-end neural networks achieve state-of-the-art performance without hand-crafted features and task-specific knowledge in non-biomedical NER tasks. However, in the biomedical domain, using the same architecture does not yield competitive performance compared with conventional machine learning models. Results We propose a novel end-to-end deep learning approach for biomedical NER tasks that leverages the local contexts based on n-gram character and word embeddings via Convolutional Neural Network (CNN). We call this approach GRAM-CNN. To automatically label a word, this method uses the local information around a word. Therefore, the GRAM-CNN method does not require any specific knowledge or feature engineering and can be theoretically applied to a wide range of existing NER problems. The GRAM-CNN approach was evaluated on three well-known biomedical datasets containing different BioNER entities. It obtained an F1-score of 87.26% on the Biocreative II dataset, 87.26% on the NCBI dataset and 72.57% on the JNLPBA dataset. Those results put GRAM-CNN in the lead of the biological NER methods. To the best of our knowledge, we are the first to apply CNN based structures to BioNER problems. Availability and implementation The GRAM-CNN source code, datasets and pre-trained model are available online at: https://github.com/valdersoul/GRAM-CNN. Contact andyli@ece.ufl.edu or aconesa@ufl.edu Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author(s) 2017. Published by Oxford University Press.","","Computational Biology; Deep Learning; Software; biology; procedures; software","Oxford University Press","13674803","","BOINF","29272325","Article","Scopus","2-s2.0-85047068763"
"Takao S.; Kondo S.; Ueno J.; Kondo T.","Takao, Shoichiro (16313930600); Kondo, Sayaka (57192074965); Ueno, Junji (7003362675); Kondo, Tadashi (55450770300)","16313930600; 57192074965; 7003362675; 55450770300","Deep feedback GMDH-type neural network and its application to medical image analysis of MRI brain images","2018","Artificial Life and Robotics","5","10.1007/s10015-017-0410-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035758223&doi=10.1007%2fs10015-017-0410-1&partnerID=40&md5=598260dd37a4d98c723cdf67ab8bd84a","Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan; Tokushima Medical Informatics Laboratory, 264-5 Otubo, Hachiman-cho, Tokushima, 770-8079, Japan","Takao S., Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan; Kondo S., Tokushima Medical Informatics Laboratory, 264-5 Otubo, Hachiman-cho, Tokushima, 770-8079, Japan; Ueno J., Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan; Kondo T., Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan","The deep feedback group method of data handling (GMDH)-type neural network is applied to the medical image analysis of MRI brain images. In this algorithm, the complexity of the neural network is increased gradually using the feedback loop calculations. The deep neural network architecture is automatically organized so as to fit the complexity of the medical images using the prediction error criterion defined as Akaike’s information criterion (AIC) or prediction sum of squares (PSS). The recognition results show that the deep feedback GMDH-type neural network algorithm is useful for the medical image analysis of MRI brain images, because the optimum neural network architectures fitting the complexity of the medical images are automatically organized so as to minimize the prediction error criterion defined as AIC or PSS. © 2017, ISAROB.","Deep neural network; Evolutionary computation; GMDH; Machine learning; Medical image recognition","Brain mapping; Complex networks; Computational complexity; Data handling; Deep neural networks; Evolutionary algorithms; Forecasting; Image analysis; Image recognition; Learning systems; Magnetic resonance imaging; Medical computing; Medical imaging; Neural networks; Feedback loop calculations; GMDH; GMDH-type neural networks; Group method of data handling; Information criterion; ITS applications; Prediction errors; Sum of squares; Network architecture","Springer Tokyo","14335298","","","","Article","Scopus","2-s2.0-85035758223"
"Teng H.; Cao M.D.; Hall M.B.; Duarte T.; Wang S.; Coin L.J.M.","Teng, Haotian (57204686403); Cao, Minh Duc (18233459400); Hall, Michael B. (57216367875); Duarte, Tania (57201213200); Wang, Sheng (58428221300); Coin, Lachlan J M (55889865800)","57204686403; 18233459400; 57216367875; 57201213200; 58428221300; 55889865800","Chiron: translating nanopore raw signal directly into nucleotide sequence using deep learning","2018","GigaScience","96","10.1093/gigascience/giy037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056709264&doi=10.1093%2fgigascience%2fgiy037&partnerID=40&md5=ef24087c28fd1f7dccd602176ae49df2","Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia; Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, 23955, Saudi Arabia","Teng H., Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia; Cao M.D., Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia; Hall M.B., Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia; Duarte T., Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia; Wang S., Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, 23955, Saudi Arabia; Coin L.J.M., Institute for Molecular Bioscience, University of Queensland, St Lucia, Brisbane, QLD 4072, Australia","Sequencing by translocating DNA fragments through an array of nanopores is a rapidly maturing technology that offers faster and cheaper sequencing than other approaches. However, accurately deciphering the DNA sequence from the noisy and complex electrical signal is challenging. Here, we report Chiron, the first deep learning model to achieve end-to-end basecalling and directly translate the raw signal to DNA sequence without the error-prone segmentation step. Trained with only a small set of 4,000 reads, we show that our model provides state-of-the-art basecalling accuracy, even on previously unseen species. Chiron achieves basecalling speeds of more than 2,000 bases per second using desktop computer graphics processing units.","","Base Pairing; Base Sequence; Escherichia coli; Machine Learning; Mycobacterium tuberculosis; Nanopores; Neural Networks (Computer); Nucleotides; Probability; Reproducibility of Results; Sequence Analysis, DNA; Signal Processing, Computer-Assisted; Software; nucleotide; artificial neural network; base pairing; DNA sequence; Escherichia coli; genetics; machine learning; Mycobacterium tuberculosis; nanopore; nucleotide sequence; probability; procedures; reproducibility; signal processing; software","","2047217X","","","29648610","Article","Scopus","2-s2.0-85056709264"
"Li K.; Pan W.; Li Y.; Jiang Q.; Liu G.","Li, Kunyang (57191885879); Pan, Weifeng (57200280839); Li, Yifan (57197734614); Jiang, Qing (56461905800); Liu, Guanzheng (35117945300)","57191885879; 57200280839; 57197734614; 56461905800; 35117945300","A method to detect sleep apnea based on deep neural network and hidden Markov model using single-lead ECG signal","2018","Neurocomputing","164","10.1016/j.neucom.2018.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044284191&doi=10.1016%2fj.neucom.2018.03.011&partnerID=40&md5=5094ca9451d571761da5f6fd96459912","Biomedical Engineering, School of Engineering, Sun Yat-sen University, Guangzhou, China; Key Laboratory of Sensing Technology and Biomedical Instrument of Guangdong Province, 510275, China; Guangdong Provincial Engineering and Technology Centre of Advanced and Portable Medical Device, Guangzhou, 510275, China","Li K., Biomedical Engineering, School of Engineering, Sun Yat-sen University, Guangzhou, China, Key Laboratory of Sensing Technology and Biomedical Instrument of Guangdong Province, 510275, China, Guangdong Provincial Engineering and Technology Centre of Advanced and Portable Medical Device, Guangzhou, 510275, China; Pan W., Biomedical Engineering, School of Engineering, Sun Yat-sen University, Guangzhou, China, Key Laboratory of Sensing Technology and Biomedical Instrument of Guangdong Province, 510275, China, Guangdong Provincial Engineering and Technology Centre of Advanced and Portable Medical Device, Guangzhou, 510275, China; Li Y., Biomedical Engineering, School of Engineering, Sun Yat-sen University, Guangzhou, China, Key Laboratory of Sensing Technology and Biomedical Instrument of Guangdong Province, 510275, China, Guangdong Provincial Engineering and Technology Centre of Advanced and Portable Medical Device, Guangzhou, 510275, China; Jiang Q., Biomedical Engineering, School of Engineering, Sun Yat-sen University, Guangzhou, China, Key Laboratory of Sensing Technology and Biomedical Instrument of Guangdong Province, 510275, China, Guangdong Provincial Engineering and Technology Centre of Advanced and Portable Medical Device, Guangzhou, 510275, China; Liu G., Biomedical Engineering, School of Engineering, Sun Yat-sen University, Guangzhou, China, Key Laboratory of Sensing Technology and Biomedical Instrument of Guangdong Province, 510275, China, Guangdong Provincial Engineering and Technology Centre of Advanced and Portable Medical Device, Guangzhou, 510275, China","Obstructive sleep apnea (OSA) is the most common sleep-related breathing disorder that potentially threatened people's cardiovascular system. As an alternative to polysomnography for OSA detection, ECG-based methods have been developed for several years. However, previous work is focused on feature engineering, which is highly dependent on the prior knowledge of human experts and maybe subjective. Moreover, feature engineering also highlights the prominent shortcoming of current learning algorithms that the features are unable to extracted and organized from the data. In this study, we proposed a method to detect OSA based on deep neural network and Hidden Markov model (HMM) using single-lead ECG signal. The method utilized sparse auto-encoder to learn features, which belongs to unsupervised learning that only requires unlabeled ECG signals. Two types classifiers (SVM and ANN) are used to classify the features extracted from the sparse auto-encoder. Considering the temporal dependency, HMM was adopted to improve the classification accuracy. Finally, a decision fusion method is adopted to improve the classification performance. About 85% classification accuracy is achieved in the per-segment OSA detection, and the sensitivity is up to 88.9%. Based on the results of per-segment OSA detection, we perfectly separate the OSA recording from normal with accuracy of 100%. Experimental results demonstrated that our proposed method is reliable for OSA detection. © 2018 Elsevier B.V.","Decision fusion; Deep neural network (DNN); Electrocardiogram (ECG); Hidden Markov model (HMM); Obstructive sleep apnea (OSA)","Biomedical signal processing; Cardiovascular system; Electrocardiography; Hidden Markov models; Learning algorithms; Signal encoding; Sleep research; Classification accuracy; Classification performance; Decision fusion; Decision fusion methods; Feature engineerings; Obstructive sleep apnea; Polysomnography; Sleep-related breathing disorders; Article; artificial neural network; controlled study; deep neural network; diagnostic accuracy; disease classification; electrocardiogram; hidden Markov model; machine learning; priority journal; receiver operating characteristic; reliability; sensitivity and specificity; sleep disordered breathing; support vector machine; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85044284191"
"Cang R.; Li H.; Yao H.; Jiao Y.; Ren Y.","Cang, Ruijin (57192707277); Li, Hechao (56197338700); Yao, Hope (57192684679); Jiao, Yang (57202397134); Ren, Yi (53880459200)","57192707277; 56197338700; 57192684679; 57202397134; 53880459200","Improving direct physical properties prediction of heterogeneous materials from imaging data via convolutional neural network and a morphology-aware generative model","2018","Computational Materials Science","127","10.1016/j.commatsci.2018.03.074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045220619&doi=10.1016%2fj.commatsci.2018.03.074&partnerID=40&md5=a02b3e1781a528d90ad59daa5286b94f","Mechanical Engineering, Arizona State University, Tempe, United States; Material Science and Engineering, Arizona State University, Tempe, United States","Cang R., Mechanical Engineering, Arizona State University, Tempe, United States; Li H., Material Science and Engineering, Arizona State University, Tempe, United States; Yao H., Mechanical Engineering, Arizona State University, Tempe, United States; Jiao Y., Material Science and Engineering, Arizona State University, Tempe, United States; Ren Y., Mechanical Engineering, Arizona State University, Tempe, United States","Direct prediction of material properties from microstructures through statistical models has shown to be a potential approach to accelerating computational material design with large design spaces. However, statistical modeling of highly nonlinear mappings defined on high-dimensional microstructure spaces is known to be data-demanding. Thus, the added value of such predictive models diminishes in common cases where material samples (in forms of 2D or 3D microstructures) become costly to acquire either experimentally or computationally. To this end, we propose a generative machine learning model that creates an arbitrary amount of artificial material samples with negligible computation cost, when trained on only a limited amount of authentic samples. The key contribution of this work is the introduction of a morphology constraint to the training of the generative model, that enforces the resultant artificial material samples to have the same morphology distribution as the authentic ones. We show empirically that the proposed model creates artificial samples that better match with the authentic ones in material property distributions than those generated from a state-of-the-art Markov Random Field model, and thus is more effective at improving the prediction performance of a predictive structure-property model. © 2018 Elsevier B.V.","Deep learning; Generative models; Integrated computational material engineering; Structure-property mapping","Deep learning; Image segmentation; Mapping; Markov processes; Microstructure; Morphology; Neural networks; Computational material designs; Computational materials; Convolutional neural network; Generative model; Heterogeneous materials; Markov Random Field model; Morphology distributions; Structure property; Forecasting","Elsevier B.V.","09270256","","CMMSE","","Article","Scopus","2-s2.0-85045220619"
"Han Y.; Ye J.C.","Han, Yoseob (57056695800); Ye, Jong Chul (7403237499)","57056695800; 7403237499","Framing U-Net via Deep Convolutional Framelets: Application to Sparse-View CT","2018","IEEE Transactions on Medical Imaging","414","10.1109/TMI.2018.2823768","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045199120&doi=10.1109%2fTMI.2018.2823768&partnerID=40&md5=41dcc7ac304b90ae3adf1f3994a6fd15","Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea","Han Y., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Ye J.C., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea","X-ray computed tomography (CT) using sparse projection views is a recent approach to reduce the radiation dose. However, due to the insufficient projection views, an analytic reconstruction approach using the filtered back projection (FBP) produces severe streaking artifacts. Recently, deep learning approaches using large receptive field neural networks such as U-Net have demonstrated impressive performance for sparse-view CT reconstruction. However, theoretical justification is still lacking. Inspired by the recent theory of deep convolutional framelets, the main goal of this paper is, therefore, to reveal the limitation of U-Net and propose new multi-resolution deep learning schemes. In particular, we show that the alternative U-Net variants such as dual frame and tight frame U-Nets satisfy the so-called frame condition which makes them better for effective recovery of high frequency edges in sparse-view CT. Using extensive experiments with real patient data set, we demonstrate that the new network architectures provide better reconstruction performance. © 2018 IEEE.","convolution framelets; convolutional neural network (CNN); Deep learning; frame condition; U-Net","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Tomography, X-Ray Computed; Convolution; Deep learning; Hospital data processing; Image reconstruction; Inverse problems; Learning systems; Network architecture; Neural networks; Convolutional Neural Networks (CNN); Filtered back projection; Frame conditions; Framelets; Learning approach; Matrix decomposition; Multi resolutions; X-ray computed tomography; adult; article; computer assisted tomography; decomposition; human; image reconstruction; machine learning; nervous system; patient coding; theoretical study; algorithm; image processing; procedures; x-ray computed tomography; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870370","Article","Scopus","2-s2.0-85045199120"
"Liu J.; Gan Y.; Dong J.; Qi L.; Sun X.; Jian M.; Wang L.; Yu H.","Liu, Jun (58850507600); Gan, Yanhai (57191053431); Dong, Junyu (22634069200); Qi, Lin (36606745500); Sun, Xin (56366080900); Jian, Muwei (22634073600); Wang, Lina (57201455660); Yu, Hui (56115992300)","58850507600; 57191053431; 22634069200; 36606745500; 56366080900; 22634073600; 57201455660; 56115992300","Perception-driven procedural texture generation from examples","2018","Neurocomputing","6","10.1016/j.neucom.2018.02.061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042844876&doi=10.1016%2fj.neucom.2018.02.061&partnerID=40&md5=b9568f3ba0694d5700c4f0dd611bdb49","Science and Information College, Qingdao Agricultural University, 700 Changcheng Road, Qingdao, China; Hisense TransTech Co., Ltd, China, No.17 Donghai West Road, Qingdao, China; Department of Computer Science and Technology, Ocean University of China, 238 Songling Road, Qingdao, China; School of Computer Science and Technology, Shandong University of Finance and Economics, Jinan, China; China Unicom Institute of Software, N0.87 Huaneng Road, Jinan, China; Department of School of Creative Technologies, University of Portsmouth, Eldon Building, Winston Churchill Avenue, Portsmouth, PO1 2DJ, United Kingdom","Liu J., Science and Information College, Qingdao Agricultural University, 700 Changcheng Road, Qingdao, China; Gan Y., Hisense TransTech Co., Ltd, China, No.17 Donghai West Road, Qingdao, China; Dong J., Department of Computer Science and Technology, Ocean University of China, 238 Songling Road, Qingdao, China; Qi L., Department of Computer Science and Technology, Ocean University of China, 238 Songling Road, Qingdao, China; Sun X., Department of Computer Science and Technology, Ocean University of China, 238 Songling Road, Qingdao, China; Jian M., School of Computer Science and Technology, Shandong University of Finance and Economics, Jinan, China; Wang L., China Unicom Institute of Software, N0.87 Huaneng Road, Jinan, China; Yu H., Department of School of Creative Technologies, University of Portsmouth, Eldon Building, Winston Churchill Avenue, Portsmouth, PO1 2DJ, United Kingdom","Procedural textures are widely used in computer games and animations for efficiently rendering natural scenes. They are generated using mathematical functions, and users need to tune the model parameters to produce desired texture. However, unless one has a good knowledge of these procedural models, it is difficult to predict which model can produce what types of textures. This paper proposes a framework for generating new procedural textures from examples. The new texture can have the same perceptual attributes as those of the input example or re-defined by the users. To achieve this goal, we first introduce a PCA-based Convolutional Network (PCN) to effectively learn texture features. These PCN features can be used to accurately predict the perceptual scales of the input example and a procedural model that can generate the input. Perceptual scales of the input can be redefined by users and further mapped to a point in the perceptual texture space, which has been established in advance by using a training dataset. Finally, we determine the parameters of the procedural generation model by performing perceptual similarity measurement in the perceptual texture space. Extensive experiments show that our method has produced promising results. © 2018 Elsevier B.V.","Convolutional neural network; Deep learning; PCA-based Convolutional Network; Procedural texture; Texture generation; Texture perception","Animation; Computer games; Deep learning; Functions; Neural networks; Convolutional networks; Convolutional neural network; Procedural textures; Texture generation; Texture perception; Article; artificial neural network; computer aided design; deep learning; feature extraction; information processing; machine learning; measurement accuracy; PCA based convolutional network; perception; predictive value; priority journal; space; texture generation; Convolution","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85042844876"
"Bing D.; Ying J.; Miao J.; Lan L.; Wang D.; Zhao L.; Yin Z.; Yu L.; Guan J.; Wang Q.","Bing, D. (55242372900); Ying, J. (35228239700); Miao, J. (57205782430); Lan, L. (35077689000); Wang, D. (55713325200); Zhao, L. (55445603100); Yin, Z. (56321846200); Yu, L. (56321627400); Guan, J. (57203308900); Wang, Q. (15734255200)","55242372900; 35228239700; 57205782430; 35077689000; 55713325200; 55445603100; 56321846200; 56321627400; 57203308900; 15734255200","Predicting the hearing outcome in sudden sensorineural hearing loss via machine learning models","2018","Clinical Otolaryngology","60","10.1111/coa.13068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042194874&doi=10.1111%2fcoa.13068&partnerID=40&md5=eea5ce224aa2211f69e4bcc9c66f39ac","Department of Otolaryngology-Head and Neck Surgery, Institute of Otolaryngology, Chinese PLA General Hospital, Beijing, China; Medical Support Center, Chinese PLA General Hospital, Beijing, China; Keele campus, York University, Toronto, Canada","Bing D., Department of Otolaryngology-Head and Neck Surgery, Institute of Otolaryngology, Chinese PLA General Hospital, Beijing, China; Ying J., Medical Support Center, Chinese PLA General Hospital, Beijing, China; Miao J., Keele campus, York University, Toronto, Canada; Lan L., Department of Otolaryngology-Head and Neck Surgery, Institute of Otolaryngology, Chinese PLA General Hospital, Beijing, China; Wang D., Department of Otolaryngology-Head and Neck Surgery, Institute of Otolaryngology, Chinese PLA General Hospital, Beijing, China; Zhao L., Department of Otolaryngology-Head and Neck Surgery, Institute of Otolaryngology, Chinese PLA General Hospital, Beijing, China; Yin Z., Department of Otolaryngology-Head and Neck Surgery, Institute of Otolaryngology, Chinese PLA General Hospital, Beijing, China; Yu L., Department of Otolaryngology-Head and Neck Surgery, Institute of Otolaryngology, Chinese PLA General Hospital, Beijing, China; Guan J., Department of Otolaryngology-Head and Neck Surgery, Institute of Otolaryngology, Chinese PLA General Hospital, Beijing, China; Wang Q., Department of Otolaryngology-Head and Neck Surgery, Institute of Otolaryngology, Chinese PLA General Hospital, Beijing, China","Objective: Sudden sensorineural hearing loss (SSHL) is a multifactorial disorder with high heterogeneity, thus the outcomes vary widely. This study aimed to develop predictive models based on four machine learning methods for SSHL, identifying the best performer for clinical application. Design: Single-centre retrospective study. Setting: Chinese People's liberation army (PLA) hospital, Beijing, China. Participants: A total of 1220 in-patient SSHL patients were enrolled between June 2008 and December 2015. Main outcome measures: An advanced deep learning technique, deep belief network (DBN), together with the conventional logistic regression (LR), support vector machine (SVM) and multilayer perceptron (MLP) were developed to predict the dichotomised hearing outcome of SSHL by inputting six feature collections derived from 149 potential predictors. Accuracy, precision, recall, F-score and the area under the receiver operator characteristic curves (ROC-AUC) were exploited to compare the prediction performance of different models. Results: Overall the best predictive ability was provided by the DBN model when tested in the raw data set with 149 variables, achieving an accuracy of 77.58% and AUC of 0.84. Nevertheless, DBN yielded inferior performance after feature pruning. In contrast, the LR, SVM and MLP models demonstrated opposite trend as the greatest individual prediction powers were obtained when included merely three variables, with the ROC-AUC ranging from 0.79 to 0.81, and then decreased with the increasing size of input features combinations. Conclusions: With the input of enough features, DBN can be a robust prediction tool for SSHL. But LR is more practical for early prediction in routine clinical application using three readily available variables, that is time elapse between symptom onset and study entry, initial hearing level and audiogram. © 2018 The Authors. Clinical Otolaryngology Published by John Wiley & Sons Ltd","hearing loss; machine learning; outcome prediction; sudden","Adult; China; Female; Hearing Loss, Sensorineural; Hearing Loss, Sudden; Humans; Machine Learning; Male; Middle Aged; Predictive Value of Tests; Prognosis; Recovery of Function; Retrospective Studies; ROC Curve; adolescent; adult; aged; Article; child; China; controlled study; deep belief network; female; hearing; human; intermethod comparison; logistic regression analysis; machine learning; major clinical study; male; measurement accuracy; measurement precision; perception deafness; perceptron; predictive value; priority journal; receiver operating characteristic; retrospective study; sudden deafness; support vector machine; convalescence; middle aged; perception deafness; prognosis; sudden deafness","Blackwell Publishing Ltd","17494478","","","29356346","Article","Scopus","2-s2.0-85042194874"
"Kim K.; Wu D.; Gong K.; Dutta J.; Kim J.H.; Son Y.D.; Kim H.K.; El Fakhri G.; Li Q.","Kim, Kyungsang (44861409500); Wu, Dufan (55286668100); Gong, Kuang (57146819700); Dutta, Joyita (24832908700); Kim, Jong Hoon (56054088000); Son, Young Don (7102761583); Kim, Hang Keun (56706631800); El Fakhri, Georges (7003672447); Li, Quanzheng (7405862484)","44861409500; 55286668100; 57146819700; 24832908700; 56054088000; 7102761583; 56706631800; 7003672447; 7405862484","Penalized PET Reconstruction Using Deep Learning Prior and Local Linear Fitting","2018","IEEE Transactions on Medical Imaging","145","10.1109/TMI.2018.2832613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046471581&doi=10.1109%2fTMI.2018.2832613&partnerID=40&md5=3a63ad394f070b2e1124ee40bf6c473f","Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, 02114, MA, United States; Department of Electrical and Computer Engineering, University of Massachusetts Lowell, Lowell, 01854, MA, United States; Neuroscience Research Institute, Gachon University of Medicine and Science, Incheon, 21936, South Korea; Department of Psychiatry, Gil Medical Center, Gachon University, Seongnam, 21565, South Korea","Kim K., Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, 02114, MA, United States; Wu D., Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, 02114, MA, United States; Gong K., Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, 02114, MA, United States; Dutta J., Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, 02114, MA, United States, Department of Electrical and Computer Engineering, University of Massachusetts Lowell, Lowell, 01854, MA, United States; Kim J.H., Neuroscience Research Institute, Gachon University of Medicine and Science, Incheon, 21936, South Korea, Department of Psychiatry, Gil Medical Center, Gachon University, Seongnam, 21565, South Korea; Son Y.D., Neuroscience Research Institute, Gachon University of Medicine and Science, Incheon, 21936, South Korea; Kim H.K., Neuroscience Research Institute, Gachon University of Medicine and Science, Incheon, 21936, South Korea; El Fakhri G., Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, 02114, MA, United States; Li Q., Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, 02114, MA, United States","Motivated by the great potential of deep learning in medical imaging, we propose an iterative positron emission tomography reconstruction framework using a deep learning-based prior. We utilized the denoising convolutional neural network (DnCNN) method and trained the network using full-dose images as the ground truth and low dose images reconstructed from downsampled data by Poisson thinning as input. Since most published deep networks are trained at a predetermined noise level, the noise level disparity of training and testing data is a major problem for their applicability as a generalized prior. In particular, the noise level significantly changes in each iteration, which can potentially degrade the overall performance of iterative reconstruction. Due to insufficient existing studies, we conducted simulations and evaluated the degradation of performance at various noise conditions. Our findings indicated that DnCNN produces additional bias induced by the disparity of noise levels. To address this issue, we propose a local linear fitting function incorporated with the DnCNN prior to improve the image quality by preventing unwanted bias. We demonstrate that the resultant method is robust against noise level disparities despite the network being trained at a predetermined noise level. By means of bias and standard deviation studies via both simulations and clinical experiments, we show that the proposed method outperforms conventional methods based on total variation and non-local means penalties. We thereby confirm that the proposed method improves the reconstruction result both quantitatively and qualitatively. © 2017 IEEE.","convolutional neural network; DnCNN; local linear fitting; PET; reconstruction","Algorithms; Brain; Databases, Factual; Deep Learning; Humans; Image Processing, Computer-Assisted; Linear Models; Phantoms, Imaging; Positron-Emission Tomography; Computerized tomography; Convolution; Image denoising; Image enhancement; Image quality; Image reconstruction; Iterative methods; Learning systems; Medical imaging; Neural networks; Noise abatement; Personnel training; Polyethylene terephthalates; Positron emission tomography; Convolutional neural network; DnCNN; Iterative reconstruction; Local linear fittings; Noise levels; Non local means (NLM); Positron emission tomography (PET); Reconstruction frameworks; article; degradation; image quality; image reconstruction; machine learning; nervous system; noise reduction; positron emission tomography; punishment; simulation; algorithm; brain; diagnostic imaging; factual database; human; image processing; imaging phantom; positron emission tomography; procedures; statistical model; Deep learning","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870375","Article","Scopus","2-s2.0-85046471581"
"Siegismund D.; Tolkachev V.; Heyse S.; Sick B.; Duerr O.; Steigele S.","Siegismund, Daniel (57200315711); Tolkachev, Vasily (57200315703); Heyse, Stephan (6701749354); Sick, Beate (7003387576); Duerr, Oliver (6506753851); Steigele, Stephan (8948929400)","57200315711; 57200315703; 6701749354; 7003387576; 6506753851; 8948929400","Developing Deep Learning Applications for Life Science and Pharma Industry","2018","Drug Research","8","10.1055/s-0043-124761","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040785434&doi=10.1055%2fs-0043-124761&partnerID=40&md5=cce2d91c5fff65f67c8094d78a64b9a4","Genedata AG, Margarethenstrasse 38, Basel, CH-4053, Switzerland; Institute of Data Analysis and Process Design, Winterthur, Switzerland","Siegismund D., Genedata AG, Margarethenstrasse 38, Basel, CH-4053, Switzerland; Tolkachev V., Institute of Data Analysis and Process Design, Winterthur, Switzerland; Heyse S., Genedata AG, Margarethenstrasse 38, Basel, CH-4053, Switzerland; Sick B., Institute of Data Analysis and Process Design, Winterthur, Switzerland; Duerr O., Institute of Data Analysis and Process Design, Winterthur, Switzerland; Steigele S., Genedata AG, Margarethenstrasse 38, Basel, CH-4053, Switzerland","Deep Learning has boosted artificial intelligence over the past 5 years and is seen now as one of the major technological innovation areas, predicted to replace lots of repetitive, but complex tasks of human labor within the next decade. It is also expected to be 'game changing' for research activities in pharma and life sciences, where large sets of similar yet complex data samples are systematically analyzed. Deep learning is currently conquering formerly expert domains especially in areas requiring perception, previously not amenable to standard machine learning. A typical example is the automated analysis of images which are typically produced en-masse in many domains, e. g., in high-content screening or digital pathology. Deep learning enables to create competitive applications in so-far defined core domains of 'human intelligence'. Applications of artificial intelligence have been enabled in recent years by (i) the massive availability of data samples, collected in pharma driven drug programs (='big data') as well as (ii) deep learning algorithmic advancements and (iii) increase in compute power. Such applications are based on software frameworks with specific strengths and weaknesses. Here, we introduce typical applications and underlying frameworks for deep learning with a set of practical criteria for developing production ready solutions in life science and pharma research. Based on our own experience in successfully developing deep learning applications we provide suggestions and a baseline for selecting the most suited frameworks for a future-proof and cost-effective development. © Georg Thieme Verlag KG Stuttgart, New York.","drug research; imaging; screening","Biological Science Disciplines; Drug Industry; Machine Learning; Software; algorithm; Article; artificial intelligence; biomedicine; conceptual framework; drug industry; drug research; software; biomedicine; drug industry; machine learning; procedures","Georg Thieme Verlag","21949379","","DRSGA","29341027","Article","Scopus","2-s2.0-85040785434"
"Reece A.S.; Wang W.; Hulse G.K.","Reece, Albert Stuart (7005501646); Wang, Wei (37032157400); Hulse, Gary Kenneth (7006783603)","7005501646; 37032157400; 7006783603","Pathways from epigenomics and glycobiology towards novel biomarkers of addiction and its radical cure","2018","Medical Hypotheses","14","10.1016/j.mehy.2018.04.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045654024&doi=10.1016%2fj.mehy.2018.04.011&partnerID=40&md5=aef1e8e0e5680796975ab3d6078f258d","Division of Psychiatry, University of Western Australia, Crawley, 6009, Western Australia, Australia; School of Medical and Health Sciences, Edith Cowan University, Joondalup, 6027, Western Australia, Australia","Reece A.S., Division of Psychiatry, University of Western Australia, Crawley, 6009, Western Australia, Australia, School of Medical and Health Sciences, Edith Cowan University, Joondalup, 6027, Western Australia, Australia; Wang W., School of Medical and Health Sciences, Edith Cowan University, Joondalup, 6027, Western Australia, Australia; Hulse G.K., Division of Psychiatry, University of Western Australia, Crawley, 6009, Western Australia, Australia, School of Medical and Health Sciences, Edith Cowan University, Joondalup, 6027, Western Australia, Australia","The recent demonstration that addiction-relevant neuronal ensembles defined by known master transcription factors and their connectome is networked throughout mesocorticolimbic reward circuits and resonates harmonically at known frequencies implies that single-cell pan-omics techniques can improve our understanding of Substance Use Disorders (SUD's). Application of machine learning algorithms to such data could find diagnostic utility as biomarkers both to define the presence of the disorder and to quantitate its severity and find myriad applications in a developmental pipeline towards therapeutics and cure. Recent epigenomic studies have uncovered a wealth of clinically important data relating to synapse-nucleus signalling, memory storage, lineage-fate determination and cellular control and are contributing greatly to our understanding of all SUD's. Epigenetics interacts extensively with glycobiology. Glycans decorate DNA, RNA and many circulating critical proteins particularly immunoglobulins. Glycosylation is emerging as a major information-laden post-translational protein modification with documented application for biomarker development. The integration of these two emerging cutting-edge technologies provides a powerful and fertile algorithmic-bioinformatic space for the development both of SUD biomarkers and novel cutting edge therapeutics. Hypotheses: These lines of evidence provide fertile ground for hypotheses relating to both diagnosis and treatment. They suggest that biomarkers derived from epigenomics complemented by glycobiology may potentially provide a bedside diagnostic tool which could be developed into a clinically useful biomarker to gauge both the presence and the severity of SUD's. Moreover they suggest that modern information-based therapeutics acting on the epigenome, via RNA interference or by DNA antisense oligonucleotides may provide a novel 21st century therapeutic development pipeline towards the radical cure of addictive disorders. Such techniques could be focussed and potentiated by neurotrophic vectors or the application of interfering electric or magnetic fields deep in the medial temporal lobes of the brain. © 2018","Aging; Biomarker; Epigenomics; Glycobiology; Opioid; Single cell assays","Algorithms; Behavior, Addictive; Biomarkers; Brain; Cell Lineage; DNA; DNA Methylation; Epigenesis, Genetic; Epigenomics; Glycomics; Glycosylation; Humans; Immunoglobulins; Machine Learning; Magnetic Fields; Oligonucleotides, Antisense; RNA; RNA Interference; Substance-Related Disorders; Temporal Lobe; Transcription Factors; biological marker; DNA; immunoglobulin; opiate; protein; RNA; antisense oligonucleotide; biological marker; DNA; immunoglobulin; RNA; transcription factor; Article; cell fate; cell nucleus; connectome; epigenetics; glycobiology; glycosylation; human; machine learning; nerve cell; nonhuman; opiate addiction; pathogenesis; RNA interference; signal transduction; synapse; addiction; algorithm; brain; cell lineage; DNA methylation; drug dependence; genetic epigenesis; genetics; glycobiology; magnetic field; metabolism; pathology; temporal lobe","Churchill Livingstone","03069877","","MEHYD","29857889","Article","Scopus","2-s2.0-85045654024"
"Uziela K.; Menéndez Hurtado D.; Shu N.; Wallner B.; Elofsson A.","Uziela, Karolis (56674583900); Menéndez Hurtado, David (57194976314); Shu, Nanjiang (23976544500); Wallner, Björn (57207559214); Elofsson, Arne (7003471235)","56674583900; 57194976314; 23976544500; 57207559214; 7003471235","Improved protein model quality assessments by changing the target function","2018","Proteins: Structure, Function and Bioinformatics","11","10.1002/prot.25492","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045192329&doi=10.1002%2fprot.25492&partnerID=40&md5=e9a34784fb5783191b890148146d6717","Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, Sweden; Bioinformatics Short-term Support and Infrastructure (BILS), Science for Life Laboratory, Solna, Sweden; Department of Physics, Chemistry and Biology (IFM)/Bioinformatics, Linköping University, Linköping, Sweden","Uziela K., Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, Sweden; Menéndez Hurtado D., Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, Sweden; Shu N., Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, Sweden, Bioinformatics Short-term Support and Infrastructure (BILS), Science for Life Laboratory, Solna, Sweden; Wallner B., Department of Physics, Chemistry and Biology (IFM)/Bioinformatics, Linköping University, Linköping, Sweden; Elofsson A., Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, Sweden","Protein modeling quality is an important part of protein structure prediction. We have for more than a decade developed a set of methods for this problem. We have used various types of description of the protein and different machine learning methodologies. However, common to all these methods has been the target function used for training. The target function in ProQ describes the local quality of a residue in a protein model. In all versions of ProQ the target function has been the S-score. However, other quality estimation functions also exist, which can be divided into superposition- and contact-based methods. The superposition-based methods, such as S-score, are based on a rigid body superposition of a protein model and the native structure, while the contact-based methods compare the local environment of each residue. Here, we examine the effects of retraining our latest predictor, ProQ3D, using identical inputs but different target functions. We find that the contact-based methods are easier to predict and that predictors trained on these measures provide some advantages when it comes to identifying the best model. One possible reason for this is that contact based methods are better at estimating the quality of multi-domain targets. However, training on the S-score gives the best correlation with the GDT_TS score, which is commonly used in CASP to score the global model quality. To take the advantage of both of these features we provide an updated version of ProQ3D that predicts local and global model quality estimates based on different quality estimates. © 2018 Wiley Periodicals, Inc.","CASP; deep learning; estimation of model accuracy; model quality assessments; protein structure prediction","Algorithms; Databases, Protein; Machine Learning; Models, Molecular; Protein Conformation; Proteins; Software; Structure-Activity Relationship; caspase; caspase 10; caspase 11; caspase 9; protein; analytic method; Article; CAD score; IDDT score; information processing; machine learning; methodology; prediction; predictor variable; priority journal; ProQ3D; protein structure; quality control; S score; scoring system; TM score; training; algorithm; chemistry; molecular model; protein conformation; protein database; software; structure activity relation","John Wiley and Sons Inc.","08873585","","","29524250","Article","Scopus","2-s2.0-85045192329"
"Mora N.; Matrella G.; Ciampolini P.","Mora, Niccolò (55601944000); Matrella, Guido (6602382571); Ciampolini, Paolo (7004816253)","55601944000; 6602382571; 7004816253","Cloud-based behavioral monitoring in smart homes","2018","Sensors (Switzerland)","28","10.3390/s18061951","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048710942&doi=10.3390%2fs18061951&partnerID=40&md5=f8340cefe4e84d71379d7e1bb4186c46","Dipartimento di Ingegneria e Architettura, Università degli Studi di Parma, Parma, 43124, Italy","Mora N., Dipartimento di Ingegneria e Architettura, Università degli Studi di Parma, Parma, 43124, Italy; Matrella G., Dipartimento di Ingegneria e Architettura, Università degli Studi di Parma, Parma, 43124, Italy; Ciampolini P., Dipartimento di Ingegneria e Architettura, Università degli Studi di Parma, Parma, 43124, Italy","Environmental sensors are exploited in smart homes for many purposes. Sensor data inherently carries behavioral information, possibly useful to infer wellness and health-related insights in an indirect fashion. In order to exploit such features, however, powerful analytics are needed to convert raw sensor output into meaningful and accessible knowledge. In this paper, a complete monitoring architecture is presented, including home sensors and cloud-based back-end services. Unsupervised techniques for behavioral data analysis are presented, including: (i) regression and outlier detection models (also used as feature extractors for more complex models); (ii) statistical hypothesis testing frameworks for detecting changes in sensor-detected activities; and (iii) a clustering process, leveraging deep learning techniques, for extracting complex, multivariate patterns from daily sensor data. Such methods are discussed and evaluated on real-life data, collected within several EU-funded projects. Overall, the presented methods may prove very useful to build effective monitoring services, suitable for practical exploitation in caregiving activities, complementing conventional telemedicine techniques. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Active and assisted living (AAL); Behavioral analysis; Deep learning; Machine learning; Smart home","Assisted living; Automation; Clustering algorithms; Data handling; Deep learning; Intelligent buildings; Learning systems; Testing; Active and assisted living (AAL); Behavioral analysis; Environmental sensor; Monitoring architecture; Multivariate patterns; Smart homes; Statistical hypothesis testing; Unsupervised techniques; Data mining","MDPI AG","14248220","","","29914127","Article","Scopus","2-s2.0-85048710942"
"Preuer K.; Lewis R.P.I.; Hochreiter S.; Bender A.; Bulusu K.C.; Klambauer G.","Preuer, Kristina (57202071945); Lewis, Richard P I (57189306263); Hochreiter, Sepp (6602873810); Bender, Andreas (8779307500); Bulusu, Krishna C (56720433700); Klambauer, Günter (6507603426)","57202071945; 57189306263; 6602873810; 8779307500; 56720433700; 6507603426","DeepSynergy: Predicting anti-cancer drug synergy with Deep Learning","2018","Bioinformatics","284","10.1093/bioinformatics/btx806","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046787565&doi=10.1093%2fbioinformatics%2fbtx806&partnerID=40&md5=9edf35e1c482ad2b21b8f026ef15f896","Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria; Department of Chemistry, Centre for Molecular Science Informatics, University of Cambridge, Cambridge, CB2 1EW, United Kingdom; Oncology Innovative Medicines and Early Development, AstraZeneca, Hodgkin Building, Chesterford Research Campus, Saffron Walden, Cambs, CB10 1XL, United Kingdom","Preuer K., Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria; Lewis R.P.I., Department of Chemistry, Centre for Molecular Science Informatics, University of Cambridge, Cambridge, CB2 1EW, United Kingdom; Hochreiter S., Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria; Bender A., Department of Chemistry, Centre for Molecular Science Informatics, University of Cambridge, Cambridge, CB2 1EW, United Kingdom; Bulusu K.C., Department of Chemistry, Centre for Molecular Science Informatics, University of Cambridge, Cambridge, CB2 1EW, United Kingdom, Oncology Innovative Medicines and Early Development, AstraZeneca, Hodgkin Building, Chesterford Research Campus, Saffron Walden, Cambs, CB10 1XL, United Kingdom; Klambauer G., Institute of Bioinformatics, Johannes Kepler University, Linz, 4040, Austria","Motivation While drug combination therapies are a well-established concept in cancer treatment, identifying novel synergistic combinations is challenging due to the size of combinatorial space. However, computational approaches have emerged as a time- and cost-efficient way to prioritize combinations to test, based on recently available large-scale combination screening data. Recently, Deep Learning has had an impact in many research areas by achieving new state-of-the-art model performance. However, Deep Learning has not yet been applied to drug synergy prediction, which is the approach we present here, termed DeepSynergy. DeepSynergy uses chemical and genomic information as input information, a normalization strategy to account for input data heterogeneity, and conical layers to model drug synergies. Results DeepSynergy was compared to other machine learning methods such as Gradient Boosting Machines, Random Forests, Support Vector Machines and Elastic Nets on the largest publicly available synergy dataset with respect to mean squared error. DeepSynergy significantly outperformed the other methods with an improvement of 7.2% over the second best method at the prediction of novel drug combinations within the space of explored drugs and cell lines. At this task, the mean Pearson correlation coefficient between the measured and the predicted values of DeepSynergy was 0.73. Applying DeepSynergy for classification of these novel drug combinations resulted in a high predictive performance of an AUC of 0.90. Furthermore, we found that all compared methods exhibit low predictive performance when extrapolating to unexplored drugs or cell lines, which we suggest is due to limitations in the size and diversity of the dataset. We envision that DeepSynergy could be a valuable tool for selecting novel synergistic drug combinations. Availability and implementation DeepSynergy is available via www.bioinf.jku.at/software/DeepSynergy. Contact klambauer@bioinf.jku.at Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author(s) 2017. Published by Oxford University Press.","","Antineoplastic Combined Chemotherapy Protocols; Cell Line, Tumor; Computational Biology; Deep Learning; Gene Expression Profiling; Gene Expression Regulation, Neoplastic; Humans; Neoplasms; Software; Support Vector Machine; antineoplastic agent; biology; gene expression profiling; gene expression regulation; genetics; human; neoplasm; procedures; software; support vector machine; tumor cell line","Oxford University Press","13674803","","BOINF","29253077","Article","Scopus","2-s2.0-85046787565"
"Qu J.; Hiruta N.; Terai K.; Nosato H.; Murakawa M.; Sakanashi H.","Qu, Jia (55657824300); Hiruta, Nobuyuki (24478548600); Terai, Kensuke (35084449200); Nosato, Hirokazu (22433748100); Murakawa, Masahiro (55229513600); Sakanashi, Hidenori (6701820384)","55657824300; 24478548600; 35084449200; 22433748100; 55229513600; 6701820384","Gastric Pathology Image Classification Using Stepwise Fine-Tuning for Deep Neural Networks","2018","Journal of Healthcare Engineering","49","10.1155/2018/8961781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052867744&doi=10.1155%2f2018%2f8961781&partnerID=40&md5=3da2561715bcaba6fc059a19c108c337","Department of Intelligent Interaction Technologies, University of Tsukuba, Tsukuba, 305-8573, Japan; Department of Surgical Pathology, Toho University Sakura Medical Center, Sakura, 285-8741, Japan; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, 305-8560, Japan","Qu J., Department of Intelligent Interaction Technologies, University of Tsukuba, Tsukuba, 305-8573, Japan; Hiruta N., Department of Surgical Pathology, Toho University Sakura Medical Center, Sakura, 285-8741, Japan; Terai K., Department of Surgical Pathology, Toho University Sakura Medical Center, Sakura, 285-8741, Japan; Nosato H., Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, 305-8560, Japan; Murakawa M., Department of Intelligent Interaction Technologies, University of Tsukuba, Tsukuba, 305-8573, Japan, Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, 305-8560, Japan; Sakanashi H., Department of Intelligent Interaction Technologies, University of Tsukuba, Tsukuba, 305-8573, Japan, Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, 305-8560, Japan","Deep learning using convolutional neural networks (CNNs) is a distinguished tool for many image classification tasks. Due to its outstanding robustness and generalization, it is also expected to play a key role to facilitate advanced computer-aided diagnosis (CAD) for pathology images. However, the shortage of well-annotated pathology image data for training deep neural networks has become a major issue at present because of the high-cost annotation upon pathologist's professional observation. Faced with this problem, transfer learning techniques are generally used to reinforcing the capacity of deep neural networks. In order to further boost the performance of the state-of-the-art deep neural networks and alleviate insufficiency of well-annotated data, this paper presents a novel stepwise fine-tuning-based deep learning scheme for gastric pathology image classification and establishes a new type of target-correlative intermediate datasets. Our proposed scheme is deemed capable of making the deep neural network imitating the pathologist's perception manner and of acquiring pathology-related knowledge in advance, but with very limited extra cost in data annotation. The experiments are conducted with both well-annotated gastric pathology data and the proposed target-correlative intermediate data on several state-of-the-art deep neural networks. The results congruously demonstrate the feasibility and superiority of our proposed scheme for boosting the classification performance. © 2018 Jia Qu et al.","","Algorithms; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Neural Networks (Computer); Stomach; Stomach Neoplasms; Classification (of information); Computer aided diagnosis; Image classification; Neural networks; Pathology; Classification performance; Computer Aided Diagnosis(CAD); Convolutional neural network; Data annotation; Intermediate datasets; Learning schemes; State of the art; Transfer learning; Article; automation; computer assisted diagnosis; convolutional neural network; deep neural network; diagnostic accuracy; diagnostic imaging; disease classification; human; image analysis; machine learning; pathologist; receiver operating characteristic; stepwise fine tuning; stomach disease; stomach epithelium; stroma; algorithm; artificial neural network; cytochemistry; pathology; procedures; stomach; stomach tumor; Deep neural networks","Hindawi Limited","20402295","","","30034677","Article","Scopus","2-s2.0-85052867744"
"Chen Y.; Peng G.; Xie C.; Zhang W.; Li C.; Liu S.","Chen, Yuanhang (57193428392); Peng, Gaoliang (8880273800); Xie, Chaohao (57201322761); Zhang, Wei (57365568500); Li, Chuanhao (57190618142); Liu, Shaohui (7409458485)","57193428392; 8880273800; 57201322761; 57365568500; 57190618142; 7409458485","ACDIN: Bridging the gap between artificial and real bearing damages for bearing fault diagnosis","2018","Neurocomputing","93","10.1016/j.neucom.2018.03.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044327325&doi=10.1016%2fj.neucom.2018.03.014&partnerID=40&md5=6175e2510b5a1c3c335df9fd37505529","State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin, 150001, Heilongjiang Province, China; School of Computer Science and Technology, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin, 150001, Heilongjiang Province, China; Department of Mechanical Engineering, National University of Singapore, 10 Kent Ridge Crescent, Singapore, 119260, Singapore","Chen Y., State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin, 150001, Heilongjiang Province, China; Peng G., State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin, 150001, Heilongjiang Province, China; Xie C., School of Computer Science and Technology, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin, 150001, Heilongjiang Province, China; Zhang W., Department of Mechanical Engineering, National University of Singapore, 10 Kent Ridge Crescent, Singapore, 119260, Singapore; Li C., State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin, 150001, Heilongjiang Province, China; Liu S., School of Computer Science and Technology, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin, 150001, Heilongjiang Province, China","Data-driven algorithms for bearing fault diagnosis have achieved much success. However, it is difficult and even impossible to collect enough data containing real bearing damages to train the classifiers, which hinders the application of these methods in industrial environments. One feasible way to address the problem is training the classifiers with data generated from artificial bearing damages instead of real ones. In this way, the problem changes to how to extract common features shared by both kinds of data because the differences between the artificial one and the natural one always baffle the learning machine. In this paper, a novel model, deep inception net with atrous convolution (ACDIN), is proposed to cope with the problem. The contribution of this paper is threefold. First and foremost, ACDIN improves the accuracy from 75% (best results of conventional data-driven methods) to 95% on diagnosing the real bearing faults when trained with only the data generated from artificial bearing damages. Second, ACDIN takes raw temporal signals as inputs, which means that it is pre-processing free. Last, feature visualization is used to analyze the mechanism behind the high performance of the proposed model. © 2018 Elsevier B.V.","Artificial damages; Convolutional neural network; End-to-end; Intelligent fault diagnosis; Real damages","Convolution; Failure analysis; Learning systems; Neural networks; Artificial damage; Convolutional neural network; End to end; Intelligent fault diagnosis; Real damages; Article; artificial neural network; classifier; data analysis software; information processing; k nearest neighbor; machine learning; mathematical analysis; priority journal; random forest; support vector machine; Fault detection","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85044327325"
"Mao K.; Lu D.; Dazhi E.; Tan Z.","Mao, Keming (35435711500); Lu, Duo (57202434874); Dazhi, E. (24831508700); Tan, Zhenhua (24832373000)","35435711500; 57202434874; 24831508700; 24832373000","A case study on attribute recognition of heated metal mark image using deep convolutional neural networks","2018","Sensors (Switzerland)","9","10.3390/s18061871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048340759&doi=10.3390%2fs18061871&partnerID=40&md5=243df931ed4c4c52324de78250217b6d","College of Software, Northeastern University, Shenyang, 110004, China; Shenyang Fire Research Institute, Ministry of Public Security, Shenyang, 110034, China","Mao K., College of Software, Northeastern University, Shenyang, 110004, China; Lu D., College of Software, Northeastern University, Shenyang, 110004, China; Dazhi E., Shenyang Fire Research Institute, Ministry of Public Security, Shenyang, 110034, China; Tan Z., College of Software, Northeastern University, Shenyang, 110004, China","Heated metal mark is an important trace to identify the cause of fire. However, traditional methods mainly focus on the knowledge of physics and chemistry for qualitative analysis and make it still a challenging problem. This paper presents a case study on attribute recognition of the heated metal mark image using computer vision and machine learning technologies. The proposed work is composed of three parts. Material is first generated. According to national standards, actual needs and feasibility, seven attributes are selected for research. Data generation and organization are conducted, and a small size benchmark dataset is constructed. A recognition model is then implemented. Feature representation and classifier construction methods are introduced based on deep convolutional neural networks. Finally, the experimental evaluation is carried out. Multi-aspect testings are performed with various model structures, data augments, training modes, optimization methods and batch sizes. The influence of parameters, recognitio efficiency and execution time are also analyzed. The results show that with a fine-tuned model, the recognition rate of attributes metal type, heating mode, heating temperature, heating duration, cooling mode, placing duration and relative humidity are 0.925, 0.908, 0.835, 0.917, 0.928, 0.805 and 0.92, respectively. The proposed method recognizes the attribute of heated metal mark with preferable effect, and it can be used in practical application. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Attribute recognition; Convolutional neural networks; Heated metal mark","Chemical analysis; Convolution; Metals; Model structures; Neural networks; Trace elements; Attribute recognition; Convolutional neural network; Deep convolutional neural networks; Experimental evaluation; Feature representation; Heated metal mark; Heating temperatures; Machine learning technology; article; case report; classifier; clinical article; computer vision; convolutional neural network; cooling; feasibility study; heating; humidity; Deep neural networks","MDPI AG","14248220","","","29880774","Article","Scopus","2-s2.0-85048340759"
"Patanaik A.; Ong J.L.; Gooley J.J.; Ancoli-Israel S.; Chee M.W.L.","Patanaik, Amiya (36710501000); Ong, Ju Lynn (55948206700); Gooley, Joshua J (6506691564); Ancoli-Israel, Sonia (7007066759); Chee, Michael W. L (7006125649)","36710501000; 55948206700; 6506691564; 7007066759; 7006125649","An end-to-end framework for real-time automatic sleep stage classification","2018","Sleep","118","10.1093/sleep/zsy041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047207929&doi=10.1093%2fsleep%2fzsy041&partnerID=40&md5=de9efe42096913bb9eb1a582719b40e8","Centre for Cognitive Neuroscience, Neuroscience and Behavioral Disorders Program, Duke-NUS Medical School, 8 College Rd, Singapore, 169857, Singapore; University of California, San Diego School of Medicine, San Diego, CA, United States","Patanaik A., Centre for Cognitive Neuroscience, Neuroscience and Behavioral Disorders Program, Duke-NUS Medical School, 8 College Rd, Singapore, 169857, Singapore; Ong J.L., Centre for Cognitive Neuroscience, Neuroscience and Behavioral Disorders Program, Duke-NUS Medical School, 8 College Rd, Singapore, 169857, Singapore; Gooley J.J., Centre for Cognitive Neuroscience, Neuroscience and Behavioral Disorders Program, Duke-NUS Medical School, 8 College Rd, Singapore, 169857, Singapore; Ancoli-Israel S., University of California, San Diego School of Medicine, San Diego, CA, United States; Chee M.W.L., Centre for Cognitive Neuroscience, Neuroscience and Behavioral Disorders Program, Duke-NUS Medical School, 8 College Rd, Singapore, 169857, Singapore","Sleep staging is a fundamental but time consuming process in any sleep laboratory. To greatly speed up sleep staging without compromising accuracy, we developed a novel framework for performing real-time automatic sleep stage classification. The client-server architecture adopted here provides an end-to-end solution for anonymizing and efficiently transporting polysomnography data from the client to the server and for receiving sleep stages in an interoperable fashion. The framework intelligently partitions the sleep staging task between the client and server in a way that multiple low-end clients can work with one server, and can be deployed both locally as well as over the cloud. The framework was tested on four datasets comprising 1700 polysomnography records (2 000 hr of recordings) collected from adolescents, young, and old adults, involving healthy persons as well as those with medical conditions. We used two independent validation datasets: one comprising patients from a sleep disorders clinic and the other incorporating patients with Parkinson's disease. Using this system, an entire night's sleep was staged with an accuracy on par with expert human scorers but much faster 5 s compared with 30-60 min). To illustrate the utility of such realtime sleep staging, we used it to facilitate the automatic delivery of acoustic stimuli at targeted phase of slow-sleep oscillations to enhance slow-wave sleep. © Sleep Research Society 2018. Published by Oxford University Press on behalf of the Sleep Research Society. All rights reserved.","computational neuroscience; computerized analysis; deep learning; EEG spectral analysis; scoring","Adolescent; Adult; Automation, Laboratory; Computational Biology; Electroencephalography; Humans; Machine Learning; Parkinson Disease; Polysomnography; Sleep Stages; Sleep Wake Disorders; Young Adult; adolescent; adult; aged; Article; auditory stimulation; automation; case control study; classification algorithm; client server application; conceptual framework; controlled study; diagnostic accuracy; diagnostic test accuracy study; human; machine learning; major clinical study; middle aged; oscillation; parasomnia; Parkinson disease; polysomnography; priority journal; real time automatic sleep stage classification; scoring system; sleep disorder; sleep quality; sleep stage; slow wave sleep; task performance; very elderly; young adult; biology; electroencephalography; laboratory automation; machine learning; pathophysiology; physiology; procedures; sleep disorder; sleep stage","Oxford University Press","01618105","","SLEED","29590492","Article","Scopus","2-s2.0-85047207929"
"Wang S.-H.; Phillips P.; Sui Y.; Liu B.; Yang M.; Cheng H.","Wang, Shui-Hua (36544650700); Phillips, Preetha (56113640900); Sui, Yuxiu (35485722700); Liu, Bin (57212048000); Yang, Ming (56442950900); Cheng, Hong (55382235800)","36544650700; 56113640900; 35485722700; 57212048000; 56442950900; 55382235800","Classification of Alzheimer’s Disease Based on Eight-Layer Convolutional Neural Network with Leaky Rectified Linear Unit and Max Pooling","2018","Journal of Medical Systems","252","10.1007/s10916-018-0932-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050695500&doi=10.1007%2fs10916-018-0932-7&partnerID=40&md5=99ea2b4204721af792b5f9edb2f33d5f","Department of Informatics, University of Leicester, Leicester, LE1 7RH, United Kingdom; Department of Electrical Engineering, The City College of New York, CUNY, New York, 10031, NY, United States; West Virginia School of Osteopathic Medicine, 400 N Lee St, Lewisburg, 24901, WV, United States; Department of Psychiatry, Affiliated Nanjing Brain Hospital of Nanjing Medical University, Nanjing, China; Department of Radiology, Zhong-Da Hospital of Southeast University, Nanjing, 210009, China; Department of Radiology, Children’s Hospital of Nanjing Medical University, Nanjing, 210008, China; Department of Neurology, First Affiliated Hospital of Nanjing Medical University, Nanjing, 210029, China","Wang S.-H., Department of Informatics, University of Leicester, Leicester, LE1 7RH, United Kingdom, Department of Electrical Engineering, The City College of New York, CUNY, New York, 10031, NY, United States; Phillips P., West Virginia School of Osteopathic Medicine, 400 N Lee St, Lewisburg, 24901, WV, United States; Sui Y., Department of Psychiatry, Affiliated Nanjing Brain Hospital of Nanjing Medical University, Nanjing, China; Liu B., Department of Radiology, Zhong-Da Hospital of Southeast University, Nanjing, 210009, China; Yang M., Department of Radiology, Children’s Hospital of Nanjing Medical University, Nanjing, 210008, China; Cheng H., Department of Neurology, First Affiliated Hospital of Nanjing Medical University, Nanjing, 210029, China","Alzheimer’s disease (AD) is a progressive brain disease. The goal of this study is to provide a new computer-vision based technique to detect it in an efficient way. The brain-imaging data of 98 AD patients and 98 healthy controls was collected using data augmentation method. Then, convolutional neural network (CNN) was used, CNN is the most successful tool in deep learning. An 8-layer CNN was created with optimal structure obtained by experiences. Three activation functions (AFs): sigmoid, rectified linear unit (ReLU), and leaky ReLU. The three pooling-functions were also tested: average pooling, max pooling, and stochastic pooling. The numerical experiments demonstrated that leaky ReLU and max pooling gave the greatest result in terms of performance. It achieved a sensitivity of 97.96%, a specificity of 97.35%, and an accuracy of 97.65%, respectively. In addition, the proposed approach was compared with eight state-of-the-art approaches. The method increased the classification accuracy by approximately 5% compared to state-of-the-art methods. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Activation function; Alzheimer’s disease; Convolutional neural network; Data augmentation; Leaky rectified linear unit; Max pooling","Aged; Aged, 80 and over; Alzheimer Disease; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Male; Neural Networks (Computer); Sensitivity and Specificity; aged; Alzheimer disease; artificial neural network; diagnostic imaging; female; human; image processing; machine learning; male; procedures; sensitivity and specificity; very elderly","Springer","01485598","","JMSYD","29577169","Article","Scopus","2-s2.0-85050695500"
"Ravì D.; Szczotka A.B.; Shakir D.I.; Pereira S.P.; Vercauteren T.","Ravì, Daniele (57201696886); Szczotka, Agnieszka Barbara (57201697389); Shakir, Dzhoshkun Ismail (38562092100); Pereira, Stephen P. (55944100900); Vercauteren, Tom (23010613000)","57201696886; 57201697389; 38562092100; 55944100900; 23010613000","Effective deep learning training for single-image super-resolution in endomicroscopy exploiting video-registration-based reconstruction","2018","International Journal of Computer Assisted Radiology and Surgery","31","10.1007/s11548-018-1764-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045843110&doi=10.1007%2fs11548-018-1764-0&partnerID=40&md5=133a59f203c415ec1744380e0ab82540","Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom; UCL Institute for Liver and Digestive Health, University College London, London, United Kingdom","Ravì D., Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom; Szczotka A.B., Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom; Shakir D.I., Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom; Pereira S.P., UCL Institute for Liver and Digestive Health, University College London, London, United Kingdom; Vercauteren T., Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom","Purpose: Probe-based confocal laser endomicroscopy (pCLE) is a recent imaging modality that allows performing in vivo optical biopsies. The design of pCLE hardware, and its reliance on an optical fibre bundle, fundamentally limits the image quality with a few tens of thousands fibres, each acting as the equivalent of a single-pixel detector, assembled into a single fibre bundle. Video registration techniques can be used to estimate high-resolution (HR) images by exploiting the temporal information contained in a sequence of low-resolution (LR) images. However, the alignment of LR frames, required for the fusion, is computationally demanding and prone to artefacts. Methods: In this work, we propose a novel synthetic data generation approach to train exemplar-based Deep Neural Networks (DNNs). HR pCLE images with enhanced quality are recovered by the models trained on pairs of estimated HR images (generated by the video registration algorithm) and realistic synthetic LR images. Performance of three different state-of-the-art DNNs techniques were analysed on a Smart Atlas database of 8806 images from 238 pCLE video sequences. The results were validated through an extensive image quality assessment that takes into account different quality scores, including a Mean Opinion Score (MOS). Results: Results indicate that the proposed solution produces an effective improvement in the quality of the obtained reconstructed image. Conclusion: The proposed training strategy and associated DNNs allows us to perform convincing super-resolution of pCLE images. © 2018, The Author(s).","Deep learning; Example-based super-resolution; Mosaicking; Probe-based confocal laser endomicroscopy","Algorithms; Endoscopy; General Surgery; Humans; Image-Guided Biopsy; Machine Learning; Microscopy, Confocal; Microsurgery; glass fiber; Article; artifact; colon; confocal laser scanning microscopy; contrast enhancement; data base; esophagus; human; image quality; image reconstruction; priority journal; videorecording; algorithm; confocal microscopy; education; endoscopy; general surgery; image guided biopsy; machine learning; microsurgery; procedures","Springer Verlag","18616410","","","29687176","Article","Scopus","2-s2.0-85045843110"
"Cheng X.; Zhang L.; Zheng Y.","Cheng, Xi (57199778417); Zhang, Li (55709131800); Zheng, Yefeng (8062522600)","57199778417; 55709131800; 8062522600","Deep similarity learning for multimodal medical images","2018","Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization","131","10.1080/21681163.2015.1135299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006202931&doi=10.1080%2f21681163.2015.1135299&partnerID=40&md5=8d39fbad1f94b9a9dd504d6467f4d322","Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ, United States","Cheng X., Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ, United States; Zhang L., Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ, United States; Zheng Y., Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ, United States","An effective similarity measure for multi-modal images is crucial for medical image fusion in many clinical applications. The underlining correlation across modalities is usually too complex to be modelled by intensity-based statistical metrics. Therefore, approaches of learning a similarity metric are proposed in recent years. In this work, we propose a novel deep similarity learning method that trains a binary classifier to learn the correspondence of two image patches. The classification output is transformed to a continuous probability value, then used as the similarity score. Moreover, we propose to utilise multi-modal stacked denoising autoencoder to effectively pre-train the deep neural network. We train and test the proposed metric using sampled corresponding/non-corresponding computed tomography and magnetic resonance head image patches from a same subject. Comparison is made with two commonly used metrics: normalised mutual information and local cross correlation. The contributions of the multi-modal stacked denoising autoencoder and the deep structure of the neural network are also evaluated. Both the quantitative and qualitative results from the similarity ranking experiments show the advantage of the proposed metric for a highly accurate and robust similarity measure. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","deep neural network; multi-modal denoising autoencoder; Multi-modal medical images; similarity metric learning","Computerized tomography; Image denoising; Image fusion; Magnetic resonance; Medical imaging; Auto encoders; De-noising; Image patches; Multi-modal; Multi-modal denoising autoencoder; Multi-modal medical image; Similarity learning; Similarity measure; Similarity metric learning; Article; artificial neural network; coding algorithm; computer assisted tomography; diagnostic imaging; multimodal medical image; nuclear magnetic resonance imaging; priority journal; scoring system; similarity metric learning; support vector machine; Deep neural networks","Taylor and Francis Ltd.","21681163","","","","Article","Scopus","2-s2.0-85006202931"
"Chew R.F.; Amer S.; Jones K.; Unangst J.; Cajka J.; Allpress J.; Bruhn M.","Chew, Robert F. (57195240010); Amer, Safaa (57201987587); Jones, Kasey (57201981011); Unangst, Jennifer (57201977198); Cajka, James (14119601700); Allpress, Justine (24334290000); Bruhn, Mark (9337823200)","57195240010; 57201987587; 57201981011; 57201977198; 14119601700; 24334290000; 9337823200","Residential scene classification for gridded population sampling in developing countries using deep convolutional neural networks on satellite imagery","2018","International Journal of Health Geographics","23","10.1186/s12942-018-0132-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046654849&doi=10.1186%2fs12942-018-0132-1&partnerID=40&md5=20f848008d969c1db6ee2d80470927f3","RTI International, Center for Data Science, 3040 East Cornwallis Road, Research Triangle Park, NC, United States; RTI International, Division for Statistical and Data Sciences, 3040 East Cornwallis Road, Research Triangle Park, NC, United States; RTI International, Geospatial Science and Technology Program, 3040 East Cornwallis Road, Research Triangle Park, NC, United States","Chew R.F., RTI International, Center for Data Science, 3040 East Cornwallis Road, Research Triangle Park, NC, United States; Amer S., RTI International, Division for Statistical and Data Sciences, 3040 East Cornwallis Road, Research Triangle Park, NC, United States; Jones K., RTI International, Center for Data Science, 3040 East Cornwallis Road, Research Triangle Park, NC, United States; Unangst J., RTI International, Division for Statistical and Data Sciences, 3040 East Cornwallis Road, Research Triangle Park, NC, United States; Cajka J., RTI International, Geospatial Science and Technology Program, 3040 East Cornwallis Road, Research Triangle Park, NC, United States; Allpress J., RTI International, Geospatial Science and Technology Program, 3040 East Cornwallis Road, Research Triangle Park, NC, United States; Bruhn M., RTI International, Geospatial Science and Technology Program, 3040 East Cornwallis Road, Research Triangle Park, NC, United States","Background: Conducting surveys in low- and middle-income countries is often challenging because many areas lack a complete sampling frame, have outdated census information, or have limited data available for designing and selecting a representative sample. Geosampling is a probability-based, gridded population sampling method that addresses some of these issues by using geographic information system (GIS) tools to create logistically manageable area units for sampling. GIS grid cells are overlaid to partition a country's existing administrative boundaries into area units that vary in size from 50 m × 50 m to 150 m × 150 m. To avoid sending interviewers to unoccupied areas, researchers manually classify grid cells as ""residential"" or ""nonresidential"" through visual inspection of aerial images. ""Nonresidential"" units are then excluded from sampling and data collection. This process of manually classifying sampling units has drawbacks since it is labor intensive, prone to human error, and creates the need for simplifying assumptions during calculation of design-based sampling weights. In this paper, we discuss the development of a deep learning classification model to predict whether aerial images are residential or nonresidential, thus reducing manual labor and eliminating the need for simplifying assumptions. Results: On our test sets, the model performs comparable to a human-level baseline in both Nigeria (94.5% accuracy) and Guatemala (96.4% accuracy), and outperforms baseline machine learning models trained on crowdsourced or remote-sensed geospatial features. Additionally, our findings suggest that this approach can work well in new areas with relatively modest amounts of training data. Conclusions: Gridded population sampling methods like geosampling are becoming increasingly popular in countries with outdated or inaccurate census data because of their timeliness, flexibility, and cost. Using deep learning models directly on satellite images, we provide a novel method for sample frame construction that identifies residential gridded aerial units. In cases where manual classification of satellite images is used to (1) correct for errors in gridded population data sets or (2) classify grids where population estimates are unavailable, this methodology can help reduce annotation burden with comparable quality to human analysts. © 2018 The Author(s).","Clustering; Complex sample design; Deep learning; GIS; Machine learning; Probability based; Remote sensing; Scene classification","Data Collection; Demography; Developing Countries; Guatemala; Humans; Neural Networks (Computer); Nigeria; Residence Characteristics; Satellite Imagery; Guatemala [Central America]; Nigeria; artificial neural network; cluster analysis; developing world; GIS; machine learning; population estimation; probability; remote sensing; satellite imagery; article; calculation; developing country; error; geographic information system; grid cell; Guatemala; human; human cell; human experiment; machine learning; manual labor; Nigeria; probability; satellite imagery; scientist; artificial neural network; classification; demography; developing country; epidemiology; information processing; procedures; satellite imagery","BioMed Central Ltd.","1476072X","","","29743081","Article","Scopus","2-s2.0-85046654849"
"Hang L.; Zhen Y.; Dong N.; Baiying L.; Tianfu W.","Hang, Li (57203241298); Zhen, Yu (57203246873); Dong, Ni (57191364158); Baiying, Lei (57191360337); Tianfu, Wang (55602702200)","57203241298; 57203246873; 57191364158; 57191360337; 55602702200","Melanoma recognition in dermoscopy images via deep residual network","2018","Chinese Journal of Biomedical Engineering","8","10.3969/j.issn.0258-8021.2018.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051014334&doi=10.3969%2fj.issn.0258-8021.2018.03.003&partnerID=40&md5=94795ebed3e7062151ae290200100b23","Department of Biomedical Engineering, School of Medicine, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China","Hang L., Department of Biomedical Engineering, School of Medicine, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China; Zhen Y., Department of Biomedical Engineering, School of Medicine, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China; Dong N., Department of Biomedical Engineering, School of Medicine, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China; Baiying L., Department of Biomedical Engineering, School of Medicine, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China; Tianfu W., Department of Biomedical Engineering, School of Medicine, Shenzhen University, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, Guangdong, 518060, China","Malignant melanoma is one of the most common and deadly skin cancers. Clinically, dermoscopy is a routine method for early diagnosis of malignant melanoma. However, human's visual examinations are laborious, time-consuming, and highly dependent on dermatologist' s clinical experience. Therefore, it is important to design an algorithm for recognizing melanoma automatically in dermoscopy images. This study proposed a novel framework for the evaluation of dermoscopy images, using deep learning to generate more discriminative features with limited training data. Specifically, we first extracted the intermediate convolutional features of each skin lesion image using a very deep residual neural network including 152 network layers (i. e. Res-152) which was pre-trained on a large natural image dataset, and the final deep representation was obtained by averaging the spatial feature maps into single feature vector, then, the support vector machine (SVM) was used to classify the melanoma. By using the proposed method 248 melanoma images and 1031 nonmelanoma images in published ISBI 2016 challenge datasets of skin lesion images were evaluated, obtaining accuracy rate of 84.96% and AUC of 84. 18%. In addition, in order to demonstrate the effect of neural network depth on the classification results, we compared the different depth of the model framework. Our approach, which could solve large variations in melanoma and small differences between melanoma and nonmelanoma with the limited training data, can produce more discriminative representations than existing studies using hand-crafted features (i. e. the BoF models based on densely sampled SIFT (DSIFT) descriptors) or only to extract features from the fully connected layers. © 2018 Society of China University Journals in Natural Sciences. Allm rights reserved.","Deep learning; Dermoscopy image; Melanoma recognition; Residual network","Article; cancer diagnosis; controlled study; deep residual neural network; diagnostic accuracy; epiluminescence microscopy; human; intermethod comparison; machine learning; melanoma","Chinese Academy of Medical Sciences","02588021","","ZSYXE","","Article","Scopus","2-s2.0-85051014334"
"Xiaojun B.; Haibo W.","Xiaojun, Bi (58629293900); Haibo, Wang (56939177300)","58629293900; 56939177300","Contractive Slab and Spike Convolutional Deep Boltzmann Machine","2018","Neurocomputing","8","10.1016/j.neucom.2018.02.048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042871430&doi=10.1016%2fj.neucom.2018.02.048&partnerID=40&md5=862dccc28dc2bc13c9c998754473862e","College of Information and Communication Engineering, Harbin Engineering University, Nantong street, number 145, Harbin, 150000, China","Xiaojun B., College of Information and Communication Engineering, Harbin Engineering University, Nantong street, number 145, Harbin, 150000, China; Haibo W., College of Information and Communication Engineering, Harbin Engineering University, Nantong street, number 145, Harbin, 150000, China","Deep unsupervised learning for robust and effective feature extractions from high-resolution images still keeps greatly challenging. Although Deep Boltzmann Machine (DBM) has demonstrated the impressive capacity of feature extractions, there is still a lot of potential for improvement in scaling such model to full-sized images, the robustness, and the quality of the learned features. In this paper, we propose a Contractive Slab and Spike Convolutional Deep Boltzmann Machine in order to settle these issues. First, the proposed model extends convolution operation to the DBM in order to deal with real-size images. Second, we induce element-wise multiplication between real-valued slab hidden units and binary spike hidden units in order to enhance the quality of feature extraction in the receptive field. Then, we add the frobenius norm of the jacobian of the features as a regularization term to the maximum likelihood function in order to enhance the robustness of the features during training. The proposed regularization term results in a localized space contraction, which in turn obtains robust features on the hidden layer. Last, we use a new block-Contractive Slab and Spike Convolutional Restricted Boltzmann Machine in order to pretrain the proposed model. The proposed deep model shows the better capacity to extract high-level representations. The results on various visual tasks demonstrate the proposed model can achieve the improved performance over several state-of-the-art methods. © 2018 Elsevier Ltd","Deep Boltzmann Machine; Deep learning; Restricted Boltzmann Machine; Robust features","Convolution; Image enhancement; Image processing; Maximum likelihood; Vision; Deep boltzmann machines; High resolution image; Maximum likelihood function; Receptive fields; Regularization terms; Restricted boltzmann machine; Robust features; State-of-the-art methods; Article; autoencoder; controlled study; denoising autoencoder; Hybrid Monte Carlo method; kernel method; machine learning; measurement accuracy; Monte Carlo method; priority journal; receptive field; Slab Convolutional Deep Boltzmann Machine; Spike Convolutional Deep Boltzmann Machine; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85042871430"
"Coenen A.; Kim Y.-H.; Kruk M.; Tesche C.; De Geer J.; Kurata A.; Lubbers M.L.; Daemen J.; Itu L.; Rapaka S.; Sharma P.; Schwemmer C.; Persson A.; Schoepf U.J.; Kepka C.; Yang D.H.; Nieman K.","Coenen, Adriaan (55820157700); Kim, Young-Hak (36067581900); Kruk, Mariusz (7006350720); Tesche, Christian (44861977800); De Geer, Jakob (37004163700); Kurata, Akira (55725483900); Lubbers, Marisa L. (56254588400); Daemen, Joost (7004485788); Itu, Lucian (36349647600); Rapaka, Saikiran (24504009500); Sharma, Puneet (35307903500); Schwemmer, Chris (36739966100); Persson, Anders (57203075459); Schoepf, U. Joseph (7003500498); Kepka, Cezary (6603399858); Yang, Dong Hyun (16177049100); Nieman, Koen (7003743979)","55820157700; 36067581900; 7006350720; 44861977800; 37004163700; 55725483900; 56254588400; 7004485788; 36349647600; 24504009500; 35307903500; 36739966100; 57203075459; 7003500498; 6603399858; 16177049100; 7003743979","Diagnostic accuracy of a machine-learning approach to coronary computed tomographic angiography–Based fractional flow reserve result from the MACHINE Consortium","2018","Circulation: Cardiovascular Imaging","281","10.1161/CIRCIMAGING.117.007217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053913085&doi=10.1161%2fCIRCIMAGING.117.007217&partnerID=40&md5=54bf1ad940618e69aa7a2be77ce8038a","Department of Cardiology, Erasmus University Medical Center, Rotterdam, Netherlands; Department of Radiology, Erasmus University Medical Center, Rotterdam, Netherlands; Department of Cardiology, Heart Institute, University of Ulsan College of Medicine, Seoul, South Korea; Department of Radiology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, South Korea; Coronary Disease and Structural Heart Diseases Department, Institute of Cardiology, Warsaw, Poland; Division of Cardiovascular Imaging, Medical University of South Carolina, Charleston, United States; Department of Radiology, Center for Medical Image Science and Visualization, Linköping University, Sweden; Department of Radiology, Ehime University, Graduate School of Medicine, Japan; Corporate Technology, Siemens SRL, Brasov, Romania; Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ, United States; Computed Tomography-Research and Development, Siemens Healthcare GmbH, Forchheim, Germany; Stanford University School of Medicine, Cardiovascular Institute, Stanford, CA, United States","Coenen A., Department of Cardiology, Erasmus University Medical Center, Rotterdam, Netherlands, Department of Radiology, Erasmus University Medical Center, Rotterdam, Netherlands; Kim Y.-H., Department of Cardiology, Heart Institute, University of Ulsan College of Medicine, Seoul, South Korea; Kruk M., Coronary Disease and Structural Heart Diseases Department, Institute of Cardiology, Warsaw, Poland; Tesche C., Division of Cardiovascular Imaging, Medical University of South Carolina, Charleston, United States; De Geer J., Department of Radiology, Center for Medical Image Science and Visualization, Linköping University, Sweden; Kurata A., Department of Radiology, Erasmus University Medical Center, Rotterdam, Netherlands, Department of Radiology, Ehime University, Graduate School of Medicine, Japan; Lubbers M.L., Department of Cardiology, Erasmus University Medical Center, Rotterdam, Netherlands, Department of Radiology, Erasmus University Medical Center, Rotterdam, Netherlands; Daemen J., Department of Cardiology, Erasmus University Medical Center, Rotterdam, Netherlands; Itu L., Corporate Technology, Siemens SRL, Brasov, Romania; Rapaka S., Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ, United States; Sharma P., Medical Imaging Technologies, Siemens Healthcare, Princeton, NJ, United States; Schwemmer C., Computed Tomography-Research and Development, Siemens Healthcare GmbH, Forchheim, Germany; Persson A., Department of Radiology, Center for Medical Image Science and Visualization, Linköping University, Sweden; Schoepf U.J., Division of Cardiovascular Imaging, Medical University of South Carolina, Charleston, United States; Kepka C., Coronary Disease and Structural Heart Diseases Department, Institute of Cardiology, Warsaw, Poland; Yang D.H., Department of Radiology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, South Korea; Nieman K., Department of Cardiology, Erasmus University Medical Center, Rotterdam, Netherlands, Department of Radiology, Erasmus University Medical Center, Rotterdam, Netherlands, Stanford University School of Medicine, Cardiovascular Institute, Stanford, CA, United States","BACKGROUND: Coronary computed tomographic angiography (CTA) is a reliable modality to detect coronary artery disease. However, CTA generally overestimates stenosis severity compared with invasive angiography, and angiographic stenosis does not necessarily imply hemodynamic relevance when fractional flow reserve (FFR) is used as reference. CTA-based FFR (CT-FFR), using computational fluid dynamics (CFD), improves the correlation with invasive FFR results but is computationally demanding. More recently, a new machine-learning (ML) CT-FFR algorithm has been developed based on a deep learning model, which can be performed on a regular workstation. In this large multicenter cohort, the diagnostic performance ML-based CT-FFR was compared with CTA and CFD-based CT-FFR for detection of functionally obstructive coronary artery disease. METHODS AND RESULTS: At 5 centers in Europe, Asia, and the United States, 351 patients, including 525 vessels with invasive FFR comparison, were included. ML-based and CFD-based CT-FFR were performed on the CTA data, and diagnostic performance was evaluated using invasive FFR as reference. Correlation between ML-based and CFD-based CT-FFR was excellent (R=0.997). ML-based (area under curve, 0.84) and CFD-based CT-FFR (0.84) outperformed visual CTA (0.69; P<0.0001). On a per-vessel basis, diagnostic accuracy improved from 58% (95% confidence interval, 54%–63%) by CTA to 78% (75%–82%) by ML-based CT-FFR. The per-patient accuracy improved from 71% (66%–76%) by CTA to 85% (81%–89%) by adding ML-based CT-FFR as 62 of 85 (73%) false-positive CTA results could be correctly reclassified by adding ML-based CT-FFR. CONCLUSIONS: On-site CT-FFR based on ML improves the performance of CTA by correctly reclassifying hemodynamically nonsignificant stenosis and performs equally well as CFD-based CT-FFR. © 2018 American Heart Association, Inc.","Area under curve; Computed tomography angiography; Coronary artery disease; Hemodynamics; Machine learning","Aged; Asia; Computed Tomography Angiography; Coronary Angiography; Coronary Artery Disease; Coronary Stenosis; Coronary Vessels; Deep Learning; Europe; Female; Fractional Flow Reserve, Myocardial; Humans; Male; Middle Aged; Predictive Value of Tests; Prospective Studies; Radiographic Image Interpretation, Computer-Assisted; Reproducibility of Results; Retrospective Studies; Severity of Illness Index; United States; aged; Asia; clinical trial; comparative study; computed tomographic angiography; computer assisted diagnosis; coronary angiography; coronary artery disease; coronary artery obstruction; coronary blood vessel; diagnostic imaging; Europe; female; fractional flow reserve; human; male; middle aged; multicenter study; pathophysiology; predictive value; procedures; prospective study; reproducibility; retrospective study; severity of illness index; United States","Lippincott Williams and Wilkins","19419651","","","29914866","Article","Scopus","2-s2.0-85053913085"
"Schütt K.T.; Sauceda H.E.; Kindermans P.-J.; Tkatchenko A.; Müller K.-R.","Schütt, K.T. (55496060500); Sauceda, H.E. (55509212900); Kindermans, P.-J. (55173885200); Tkatchenko, A. (57203071200); Müller, K.-R. (15042362900)","55496060500; 55509212900; 55173885200; 57203071200; 15042362900","SchNet - A deep learning architecture for molecules and materials","2018","Journal of Chemical Physics","1108","10.1063/1.5019779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044731105&doi=10.1063%2f1.5019779&partnerID=40&md5=6aa902452c61b655ff4128c385980c86","Machine Learning Group, Technische Universität Berlin, Berlin, 10587, Germany; Fritz-Haber-Institut der Max-Planck-Gesellschaft, Berlin, 14195, Germany; Physics and Materials Science Research Unit, University of Luxembourg, Luxembourg, L-1511, Luxembourg; Max-Planck-Institut für Informatik, Saarbrücken, Germany; Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 136-713, South Korea","Schütt K.T., Machine Learning Group, Technische Universität Berlin, Berlin, 10587, Germany; Sauceda H.E., Fritz-Haber-Institut der Max-Planck-Gesellschaft, Berlin, 14195, Germany; Kindermans P.-J., Machine Learning Group, Technische Universität Berlin, Berlin, 10587, Germany; Tkatchenko A., Physics and Materials Science Research Unit, University of Luxembourg, Luxembourg, L-1511, Luxembourg; Müller K.-R., Machine Learning Group, Technische Universität Berlin, Berlin, 10587, Germany, Max-Planck-Institut für Informatik, Saarbrücken, Germany, Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 136-713, South Korea","Deep learning has led to a paradigm shift in artificial intelligence, including web, text, and image search, speech recognition, as well as bioinformatics, with growing impact in chemical physics. Machine learning, in general, and deep learning, in particular, are ideally suitable for representing quantum-mechanical interactions, enabling us to model nonlinear potential-energy surfaces or enhancing the exploration of chemical compound space. Here we present the deep learning architecture SchNet that is specifically designed to model atomistic systems by making use of continuous-filter convolutional layers. We demonstrate the capabilities of SchNet by accurately predicting a range of properties across chemical space for molecules and materials, where our model learns chemically plausible embeddings of atom types across the periodic table. Finally, we employ SchNet to predict potential-energy surfaces and energy-conserving force fields for molecular dynamics simulations of small molecules and perform an exemplary study on the quantum-mechanical properties of C20-fullerene that would have been infeasible with regular ab initio molecular dynamics. © 2018 Author(s).","","Artificial intelligence; Character recognition; Molecular dynamics; Molecules; Potential energy; Potential energy surfaces; Quantum chemistry; Speech recognition; Ab initio molecular dynamics; Atomistic system; Chemical physics; Energy-conserving; Learning architectures; Molecular dynamics simulations; Nonlinear potential; Quantum mechanical; Deep learning","American Institute of Physics Inc.","00219606","","JCPSA","29960322","Article","Scopus","2-s2.0-85044731105"
"Kusumoto D.; Lachmann M.; Kunihiro T.; Yuasa S.; Kishino Y.; Kimura M.; Katsuki T.; Itoh S.; Seki T.; Fukuda K.","Kusumoto, Dai (36542750800); Lachmann, Mark (57193628371); Kunihiro, Takeshi (54883639100); Yuasa, Shinsuke (9733731400); Kishino, Yoshikazu (55353341900); Kimura, Mai (56116746500); Katsuki, Toshiomi (57202004484); Itoh, Shogo (57202022149); Seki, Tomohisa (7401920130); Fukuda, Keiichi (7403522079)","36542750800; 57193628371; 54883639100; 9733731400; 55353341900; 56116746500; 57202004484; 57202022149; 7401920130; 7403522079","Automated Deep Learning-Based System to Identify Endothelial Cells Derived from Induced Pluripotent Stem Cells","2018","Stem Cell Reports","68","10.1016/j.stemcr.2018.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046781959&doi=10.1016%2fj.stemcr.2018.04.007&partnerID=40&md5=996ebfdb5680072250b5202d04a71cdf","Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan; Department of Emergency and Critical Care Medicine, Keio University School of Medicine, Tokyo, 160-8582, Japan; LE Development Department, R&D Division, Medical Business Group, Sony Imaging Products & Solutions Inc., 4-14-1 Asahi-cho, Atsugi-shi, 243-0014, Kanagawa, Japan","Kusumoto D., Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan, Department of Emergency and Critical Care Medicine, Keio University School of Medicine, Tokyo, 160-8582, Japan; Lachmann M., Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan; Kunihiro T., LE Development Department, R&D Division, Medical Business Group, Sony Imaging Products & Solutions Inc., 4-14-1 Asahi-cho, Atsugi-shi, 243-0014, Kanagawa, Japan; Yuasa S., Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan; Kishino Y., Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan; Kimura M., Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan; Katsuki T., Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan; Itoh S., Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan; Seki T., Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan, Department of Emergency and Critical Care Medicine, Keio University School of Medicine, Tokyo, 160-8582, Japan; Fukuda K., Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo, 160-8582, Japan","Deep learning technology is rapidly advancing and is now used to solve complex problems. Here, we used deep learning in convolutional neural networks to establish an automated method to identify endothelial cells derived from induced pluripotent stem cells (iPSCs), without the need for immunostaining or lineage tracing. Networks were trained to predict whether phase-contrast images contain endothelial cells based on morphology only. Predictions were validated by comparison to immunofluorescence staining for CD31, a marker of endothelial cells. Method parameters were then automatically and iteratively optimized to increase prediction accuracy. We found that prediction accuracy was correlated with network depth and pixel size of images to be analyzed. Finally, K-fold cross-validation confirmed that optimized convolutional neural networks can identify endothelial cells with high performance, based only on morphology. Kusumoto et al. developed an automated system to identify endothelial cells derived from induced pluripotent stem cells, based only on morphology. Performance, as assessed by F1 score and accuracy, was correlated with network depth and pixel size of training images. K-fold validation confirmed that endothelial cells are identified automatically with high accuracy using only generalized morphological features. © 2018 The Author(s)","artificial intelligence; deep learning; endothelial cell; induced pluripotent stem cell; machine learning","Animals; Artificial Intelligence; Cell Differentiation; Deep Learning; Endothelial Cells; Induced Pluripotent Stem Cells; Machine Learning; Mice; platelet endothelial cell adhesion molecule 1; accuracy; Article; autofluorescence; cell differentiation; controlled study; endothelium cell; flow cytometry; fluorescence; immunofluorescence test; immunohistochemistry; induced pluripotent stem cell; mesodermal cell; prediction; priority journal; animal; artificial intelligence; cell differentiation; cytology; endothelium cell; induced pluripotent stem cell; machine learning; metabolism; mouse","Cell Press","22136711","","","29754958","Article","Scopus","2-s2.0-85046781959"
"Li Y.; Shi W.; Wasserman W.W.","Li, Yifeng (8233512800); Shi, Wenqiang (56491959100); Wasserman, Wyeth W. (7003872826)","8233512800; 56491959100; 7003872826","Genome-wide prediction of cis-regulatory regions using supervised deep learning methods","2018","BMC Bioinformatics","75","10.1186/s12859-018-2187-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047942208&doi=10.1186%2fs12859-018-2187-1&partnerID=40&md5=e895081f62bbe9df6ca1269c76add71e","University of British Columbia, Centre for Molecular Medicine and Therapeutics, BC Children's Hospital Research Institute, Department of Medical Genetics, 950 West 28th Avenue, Vancouver, V5Z 4H4, Canada; Digital Technologies Research Centre, National Research Council Canada, Building M-50, 1200 Montreal Road, Ottawa, K1A 0R6, Canada","Li Y., University of British Columbia, Centre for Molecular Medicine and Therapeutics, BC Children's Hospital Research Institute, Department of Medical Genetics, 950 West 28th Avenue, Vancouver, V5Z 4H4, Canada, Digital Technologies Research Centre, National Research Council Canada, Building M-50, 1200 Montreal Road, Ottawa, K1A 0R6, Canada; Shi W., University of British Columbia, Centre for Molecular Medicine and Therapeutics, BC Children's Hospital Research Institute, Department of Medical Genetics, 950 West 28th Avenue, Vancouver, V5Z 4H4, Canada; Wasserman W.W., University of British Columbia, Centre for Molecular Medicine and Therapeutics, BC Children's Hospital Research Institute, Department of Medical Genetics, 950 West 28th Avenue, Vancouver, V5Z 4H4, Canada","Background: In the human genome, 98% of DNA sequences are non-protein-coding regions that were previously disregarded as junk DNA. In fact, non-coding regions host a variety of cis-regulatory regions which precisely control the expression of genes. Thus, Identifying active cis-regulatory regions in the human genome is critical for understanding gene regulation and assessing the impact of genetic variation on phenotype. The developments of high-throughput sequencing and machine learning technologies make it possible to predict cis-regulatory regions genome wide. Results: Based on rich data resources such as the Encyclopedia of DNA Elements (ENCODE) and the Functional Annotation of the Mammalian Genome (FANTOM) projects, we introduce DECRES based on supervised deep learning approaches for the identification of enhancer and promoter regions in the human genome. Due to their ability to discover patterns in large and complex data, the introduction of deep learning methods enables a significant advance in our knowledge of the genomic locations of cis-regulatory regions. Using models for well-characterized cell lines, we identify key experimental features that contribute to the predictive performance. Applying DECRES, we delineate locations of 300,000 candidate enhancers genome wide (6.8% of the genome, of which 40,000 are supported by bidirectional transcription data), and 26,000 candidate promoters (0.6% of the genome). Conclusion: The predicted annotations of cis-regulatory regions will provide broad utility for genome interpretation from functional genomics to clinical applications. The DECRES model demonstrates potentials of deep learning technologies when combined with high-throughput sequencing data, and inspires the development of other advanced neural network models for further improvement of genome annotations. © 2018 The Author(s).","cis-regulatory region; Deep learning; Enhancer; Promoter","Deep Learning; Gene Expression Regulation; Genomics; Humans; Machine Learning; Neural Networks (Computer); Regulatory Sequences, Nucleic Acid; Cell culture; DNA; DNA sequences; Mammals; Throughput; Transcription; Enhancer; Functional annotation; High-throughput sequencing; Machine learning technology; Predictive performance; Promoter; Protein coding regions; Regulatory regions; article; cancer model; cell line; controlled study; enhancer region; functional genomics; high throughput sequencing; human; human cell; human experiment; human genome; machine learning; mammal; nervous system; nonhuman; prediction; promoter region; artificial neural network; gene expression regulation; genetics; genomics; machine learning; procedures; regulatory sequence; standards; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","29855387","Article","Scopus","2-s2.0-85047942208"
"Mannil M.; Von Spiczak J.; Manka R.; Alkadhi H.","Mannil, Manoj (57188974822); Von Spiczak, Jochen (16311075800); Manka, Robert (8839069800); Alkadhi, Hatem (56785523600)","57188974822; 16311075800; 8839069800; 56785523600","Texture Analysis and Machine Learning for Detecting Myocardial Infarction in Noncontrast Low-Dose Computed Tomography: Unveiling the Invisible","2018","Investigative Radiology","102","10.1097/RLI.0000000000000448","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046961757&doi=10.1097%2fRLI.0000000000000448&partnerID=40&md5=54059231372446f056597782f9c81bfd","Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Raemistr. 100, Zurich, CH-8091, Switzerland; Institute for Biomedical Engineering, University and ETH Zurich, Zurich, Switzerland; Department of Cardiology, University Heart Center, University Hospital Zurich, Zurich, Switzerland","Mannil M., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Raemistr. 100, Zurich, CH-8091, Switzerland; Von Spiczak J., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Raemistr. 100, Zurich, CH-8091, Switzerland; Manka R., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Raemistr. 100, Zurich, CH-8091, Switzerland, Institute for Biomedical Engineering, University and ETH Zurich, Zurich, Switzerland, Department of Cardiology, University Heart Center, University Hospital Zurich, Zurich, Switzerland; Alkadhi H., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, University of Zurich, Raemistr. 100, Zurich, CH-8091, Switzerland","Objectives The aim of this study was to test whether texture analysis and machine learning enable the detection of myocardial infarction (MI) on non-contrast-enhanced low radiation dose cardiac computed tomography (CCT) images. Materials and Methods In this institutional review board-approved retrospective study, we included non-contrast-enhanced electrocardiography-gated low radiation dose CCT image data (effective dose, 0.5 mSv) acquired for the purpose of calcium scoring of 27 patients with acute MI (9 female patients; mean age, 60 ± 12 years), 30 patients with chronic MI (8 female patients; mean age, 68 ± 13 years), and in 30 subjects (9 female patients; mean age, 44 ± 6 years) without cardiac abnormality, hereafter termed controls. Texture analysis of the left ventricle was performed using free-hand regions of interest, and texture features were classified twice (Model I: controls versus acute MI versus chronic MI; Model II: controls versus acute and chronic MI). For both classifications, 6 commonly used machine learning classifiers were used: decision tree C4.5 (J48), k-nearest neighbors, locally weighted learning, RandomForest, sequential minimal optimization, and an artificial neural network employing deep learning. In addition, 2 blinded, independent readers visually assessed noncontrast CCT images for the presence or absence of MI. Results In Model I, best classification results were obtained using the k-nearest neighbors classifier (sensitivity, 69%; specificity, 85%; false-positive rate, 0.15). In Model II, the best classification results were found with the locally weighted learning classification (sensitivity, 86%; specificity, 81%; false-positive rate, 0.19) with an area under the curve from receiver operating characteristics analysis of 0.78. In comparison, both readers were not able to identify MI in any of the noncontrast, low radiation dose CCT images. Conclusions This study indicates the ability of texture analysis and machine learning in detecting MI on noncontrast low radiation dose CCT images being not visible for the radiologists' eye. © 2018 Wolters Kluwer Health, Inc. All rights reserved.","computed tomography; machine learning; myocardial infarction; noncontrast; texture analysis","Adult; Aged; Aged, 80 and over; Cluster Analysis; Diagnosis, Differential; Female; Heart; Humans; Machine Learning; Male; Middle Aged; Myocardial Infarction; Radiation Dosage; Reproducibility of Results; Retrospective Studies; Sensitivity and Specificity; Tomography, X-Ray Computed; contrast medium; adult; algorithm; Article; clinical article; computer assisted tomography; female; heart infarction; human; image analysis; machine learning; male; priority journal; radiation dose; receiver operating characteristic; retrospective study; sensitivity and specificity; texture analysis; aged; cluster analysis; diagnostic imaging; differential diagnosis; heart; heart infarction; middle aged; procedures; reproducibility; very elderly; x-ray computed tomography","Lippincott Williams and Wilkins","00209996","","INVRA","29420321","Article","Scopus","2-s2.0-85046961757"
"Janowczyk A.; Doyle S.; Gilmore H.; Madabhushi A.","Janowczyk, Andrew (26531344300); Doyle, Scott (15042320000); Gilmore, Hannah (16039479600); Madabhushi, Anant (6603019206)","26531344300; 15042320000; 16039479600; 6603019206","A resolution adaptive deep hierarchical (RADHicaL) learning scheme applied to nuclear segmentation of digital pathology images","2018","Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization","35","10.1080/21681163.2016.1141063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006208802&doi=10.1080%2f21681163.2016.1141063&partnerID=40&md5=6cfcebe75301701927eb897606864a36","Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Pathology & Anatomical Sciences, SUNY Buffalo, Buffalo, NY, United States; University Hospitals Case Medical Center, Surgical Pathology, Cleveland, OH, United States","Janowczyk A., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Doyle S., Pathology & Anatomical Sciences, SUNY Buffalo, Buffalo, NY, United States; Gilmore H., University Hospitals Case Medical Center, Surgical Pathology, Cleveland, OH, United States; Madabhushi A., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States","Deep learning (DL) has recently been successfully applied to a number of image analysis problems. However, DL approaches tend to be inefficient for segmentation on large image data, such as high-resolution digital pathology slide images. For example, typical breast biopsy images scanned at 40 × magnification contain billions of pixels, of which usually only a small percentage belong to the class of interest. For a typical naïve deep learning scheme, parsing through and interrogating all the image pixels would represent hundreds if not thousands of hours of compute time using high performance computing environments. In this paper, we present a resolution adaptive deep hierarchical (RADHicaL) learning scheme wherein DL networks at lower resolutions are leveraged to determine if higher levels of magnification, and thus computation, are necessary to provide precise results. We evaluate our approach on a nuclear segmentation task with a cohort of 141 ER+ breast cancer images and show we can reduce computation time on average by about 85%. Expert annotations of 12,000 nuclei across these 141 images were employed for quantitative evaluation of RADHicaL. A head-to-head comparison with a naïve DL approach, operating solely at the highest magnification, yielded the following performance metrics:.9407 vs.9854 Detection Rate,.8218 vs.8489 F-score,.8061 vs.8364 true positive rate and.8822 vs 0.8932 positive predictive value. Our performance indices compare favourably with state of the art nuclear segmentation approaches for digital pathology images. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","applications of imaging and visualisation; Data processing and analysis; deep learning; digital pathology; image processing and analysis; output generation","Biopsy; Data handling; E-learning; Image analysis; Image segmentation; Medical imaging; Pathology; Pixels; Analysis problems; Application of imaging and visualization; Data processing and analysis; Deep learning; Digital pathologies; Hierarchical learning; Image processing and analysis; Learning approach; Learning schemes; Output generation; algorithm; analytical parameters; Article; artificial neural network; estrogen receptor positive breast cancer; histology; human; image segmentation; machine learning; measurement accuracy; nuclear segmentation; patch size; predictive value; priority journal; resolution adaptive deep hierarchical learning; Deep learning","Taylor and Francis Ltd.","21681163","","","","Article","Scopus","2-s2.0-85006208802"
"Wang Y.-B.; You Z.-H.; Li L.-P.; Huang D.-S.; Zhou F.-F.; Yang S.","Wang, Yan-Bin (57194205411); You, Zhu-Hong (23062542900); Li, Li-Ping (57193827160); Huang, De-Shuang (13310398900); Zhou, Feng-Feng (55634210800); Yang, Shan (57207740488)","57194205411; 23062542900; 57193827160; 13310398900; 55634210800; 57207740488","Improving prediction of self-interacting proteins using stacked sparse auto-encoder with PSSM profiles","2018","International Journal of Biological Sciences","21","10.7150/ijbs.23817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048154223&doi=10.7150%2fijbs.23817&partnerID=40&md5=3d3a2ce21a54db7b0f5dcf3b4ccbb531","University of Chinese Academy of Sciences, Beijing, 100049, China; Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China; Institute of Machine Learning and Systems Biology, School of Electronics and Information Engineering, Tongji University, Caoan Road 4800, Shanghai, 201804, China; College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China","Wang Y.-B., University of Chinese Academy of Sciences, Beijing, 100049, China, Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China; You Z.-H., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China; Li L.-P., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China; Huang D.-S., Institute of Machine Learning and Systems Biology, School of Electronics and Information Engineering, Tongji University, Caoan Road 4800, Shanghai, 201804, China; Zhou F.-F., College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China; Yang S., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Urumqi, 830011, China","Self-interacting proteins (SIPs) play a significant role in the execution of most important molecular processes in cells, such as signal transduction, gene expression regulation, immune response and enzyme activation. Although the traditional experimental methods can be used to generate SIPs data, it is very expensive and time-consuming based only on biological technique. Therefore, it is important and urgent to develop an efficient computational method for SIPs detection. In this study, we present a novel SIPs identification method based on machine learning technology by combing the Zernike Moments (ZMs) descriptor on Position Specific Scoring Matrix (PSSM) with Probabilistic Classification Vector Machines (PCVM) and Stacked Sparse Auto-Encoder (SSAE). More specifically, an efficient feature extraction technique called ZMs is firstly utilized to generate feature vectors on Position Specific Scoring Matrix (PSSM); Then, Deep neural network is employed for reducing the feature dimensions and noise; Finally, the Probabilistic Classification Vector Machine is used to execute the classification. The prediction performance of the proposed method is evaluated on S.erevisiae and Human SIPs datasets via cross-validation. The experimental results indicate that the proposed method can achieve good accuracies of 92.55% and 97.47%, respectively. To further evaluate the advantage of our scheme for SIPs prediction, we also compared the PCVM classifier with the Support Vector Machine (SVM) and other existing techniques on the same data sets. Comparison results reveal that the proposed strategy is outperforms other methods and could be a used tool for identifying SIPs. © Ivyspring International Publisher.","Deep learning; Probabilistic classification vector machines; Zernike moments","Algorithms; Computational Biology; Deep Learning; Protein Interaction Mapping; Proteins; Support Vector Machine; protein; algorithm; biology; chemistry; procedures; protein analysis; support vector machine; validation study","Ivyspring International Publisher","14492288","","","29989064","Article","Scopus","2-s2.0-85048154223"
"Zhang Y.; Yu H.","Zhang, Yanbo (38461645700); Yu, Hengyong (20435223800)","38461645700; 20435223800","Convolutional Neural Network Based Metal Artifact Reduction in X-Ray Computed Tomography","2018","IEEE Transactions on Medical Imaging","317","10.1109/TMI.2018.2823083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048349587&doi=10.1109%2fTMI.2018.2823083&partnerID=40&md5=43c861f9cb5f2ae10855e0575daa0005","Department of Electrical and Computer Engineering, University of Massachusetts at Lowell, Lowell, 01854, MA, United States","Zhang Y., Department of Electrical and Computer Engineering, University of Massachusetts at Lowell, Lowell, 01854, MA, United States; Yu H., Department of Electrical and Computer Engineering, University of Massachusetts at Lowell, Lowell, 01854, MA, United States","In the presence of metal implants, metal artifacts are introduced to x-ray computed tomography CT images. Although a large number of metal artifact reduction (MAR) methods have been proposed in the past decades, MAR is still one of the major problems in clinical x-ray CT. In this paper, we develop a convolutional neural network (CNN)-based open MAR framework, which fuses the information from the original and corrected images to suppress artifacts. The proposed approach consists of two phases. In the CNN training phase, we build a database consisting of metal-free, metal-inserted and pre-corrected CT images, and image patches are extracted and used for CNN training. In the MAR phase, the uncorrected and pre-corrected images are used as the input of the trained CNN to generate a CNN image with reduced artifacts. To further reduce the remaining artifacts, water equivalent tissues in a CNN image are set to a uniform value to yield a CNN prior, whose forward projections are used to replace the metal-affected projections, followed by the FBP reconstruction. The effectiveness of the proposed method is validated on both simulated and real data. Experimental results demonstrate the superior MAR capability of the proposed method to its competitors in terms of artifact suppression and preservation of anatomical structures in the vicinity of metal implants. © 2018 IEEE.","convolutional neural networks; deep learning; metal artifacts; X-ray computed tomography (CT)","Artifacts; Deep Learning; Female; Humans; Image Processing, Computer-Assisted; Metals; Middle Aged; Prostheses and Implants; Tomography, X-Ray Computed; Convolution; Deep learning; Image processing; Metal implants; Metals; Neural networks; X rays; metal; Anatomical structures; Artifact suppression; Convolutional neural network; Convolutional Neural Networks (CNN); Fbp reconstruction; Metal artifact reduction; Metal artifacts; X-ray computed tomography; adult; Article; artifact reduction; basal cistern; brain artery aneurysm; computed tomographic angiography; convolutional neural network; female; human; image quality; image segmentation; intracranial hypertension; machine learning; middle aged; subarachnoid hemorrhage; Sylvian fissure; tooth filling; x-ray computed tomography; artifact; image processing; procedures; prostheses and orthoses; x-ray computed tomography; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870366","Article","Scopus","2-s2.0-85048349587"
"Jiang J.; Liu T.; Zhu W.; Koncz R.; Liu H.; Lee T.; Sachdev P.S.; Wen W.","Jiang, Jiyang (55635357700); Liu, Tao (56658127700); Zhu, Wanlin (7404232019); Koncz, Rebecca (57190954591); Liu, Hao (57200608358); Lee, Teresa (56009358300); Sachdev, Perminder S. (7102284091); Wen, Wei (7102171045)","55635357700; 56658127700; 7404232019; 57190954591; 57200608358; 56009358300; 7102284091; 7102171045","UBO Detector – A cluster-based, fully automated pipeline for extracting white matter hyperintensities","2018","NeuroImage","50","10.1016/j.neuroimage.2018.03.050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044922816&doi=10.1016%2fj.neuroimage.2018.03.050&partnerID=40&md5=b4cc8991dc274bf8f602c0116b5121ed","Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia; School of Biological Science and Medical Engineering, Beihang University, Beijing, China; Neuropsychiatric Institute, The Prince of Wales Hospital, Randwick, NSW, Australia","Jiang J., Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia; Liu T., School of Biological Science and Medical Engineering, Beihang University, Beijing, China; Zhu W., Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia, School of Biological Science and Medical Engineering, Beihang University, Beijing, China; Koncz R., Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia, Neuropsychiatric Institute, The Prince of Wales Hospital, Randwick, NSW, Australia; Liu H., School of Biological Science and Medical Engineering, Beihang University, Beijing, China; Lee T., Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia, Neuropsychiatric Institute, The Prince of Wales Hospital, Randwick, NSW, Australia; Sachdev P.S., Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia, Neuropsychiatric Institute, The Prince of Wales Hospital, Randwick, NSW, Australia; Wen W., Centre for Healthy Brain Ageing, School of Psychiatry, University of New South Wales, Australia, Neuropsychiatric Institute, The Prince of Wales Hospital, Randwick, NSW, Australia","We present ‘UBO Detector’ a cluster-based, fully automated pipeline for extracting and calculating variables for regions of white matter hyperintensities (WMH) (available for download at https://cheba.unsw.edu.au/group/neuroimaging-pipeline). It takes T1-weighted and fluid attenuated inversion recovery (FLAIR) scans as input, and SPM12 and FSL functions are utilised for pre-processing. The candidate clusters are then generated by FMRIB's Automated Segmentation Tool (FAST). A supervised machine learning algorithm, k-nearest neighbor (k-NN), is applied to determine whether the candidate clusters are WMH or non-WMH. UBO Detector generates both image and text (volumes and the number of WMH clusters) outputs for whole brain, periventricular, deep, and lobar WMH, as well as WMH in arterial territories. The computation time for each brain is approximately 15 min. We validated the performance of UBO Detector by showing a) high segmentation (similarity index (SI) = 0.848) and volumetric (intraclass correlation coefficient (ICC) = 0.985) agreement between the UBO Detector-derived and manually traced WMH; b) highly correlated (r2 > 0.9) and a steady increase of WMH volumes over time; and c) significant associations of periventricular (t = 22.591, p < 0.001) and deep (t = 14.523, p < 0.001) WMH volumes generated by UBO Detector with Fazekas rating scores. With parallel computing enabled in UBO Detector, the processing can take advantage of multi-core CPU's that are commonly available on workstations. In conclusion, UBO Detector is a reliable, efficient and fully automated WMH segmentation pipeline. © 2018 Elsevier Inc.","Automated segmentation pipeline; k-nearest neighbours; White matter hyperintensities","Aged; Algorithms; Brain; Cluster Analysis; Cross-Sectional Studies; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Pattern Recognition, Automated; Software; White Matter; aged; Article; automation; correlation coefficient; female; human; human experiment; information processing; Internet; k nearest neighbor; learning algorithm; machine learning; male; nervous system parameters; neuropsychological test; normal human; nuclear magnetic resonance imaging; outcome assessment; priority journal; quality control; scoring system; twins; UBO Detector; very elderly; white matter; white matter hyperintensity; algorithm; automated pattern recognition; brain; clinical trial; cluster analysis; cross-sectional study; diagnostic imaging; image processing; multicenter study; pathology; procedures; software; white matter","Academic Press Inc.","10538119","","NEIME","29578029","Article","Scopus","2-s2.0-85044922816"
"Putin E.; Asadulaev A.; Ivanenkov Y.; Aladinskiy V.; Sanchez-Lengeling B.; Aspuru-Guzik A.; Zhavoronkov A.","Putin, Evgeny (57189310406); Asadulaev, Arip (57202188009); Ivanenkov, Yan (6508137923); Aladinskiy, Vladimir (57185643000); Sanchez-Lengeling, Benjamin (56906946400); Aspuru-Guzik, Alán (6507007526); Zhavoronkov, Alex (39862415800)","57189310406; 57202188009; 6508137923; 57185643000; 56906946400; 6507007526; 39862415800","Reinforced Adversarial Neural Computer for de Novo Molecular Design","2018","Journal of Chemical Information and Modeling","238","10.1021/acs.jcim.7b00690","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047412990&doi=10.1021%2facs.jcim.7b00690&partnerID=40&md5=01dac182ea9392a42b3088c8e1bc9716","Pharma.AI Department, Insilico Medicine, Inc, Baltimore, 21218, MD, United States; Computer Technologies Lab, ITMO University, St.-Petersburg, 197101, Russian Federation; Moscow Institute of Physics and Technology (State University), 9 Institutskiy lane, Dolgoprudny City, Moscow Region, 141700, Russian Federation; Institute of Biochemistry and Genetics Russian Academy of Science (IBG RAS), Ufa Scientific Centre, Oktyabrya Prospekt 71, Ufa, 450054, Russian Federation; Chemistry and Chemical Biology Department, Harvard University, 12 Oxford Street, Cambridge, 02143, MA, United States; Biologically-Inspired Solar Energy Program, Canadian Institute for Advanced Research (CIFAR), Toronto, M5S 1M1, ON, Canada; Buck Institute for Research on Aging, 8001 Redwood Boulevard, Novato, 94945, CA, United States","Putin E., Pharma.AI Department, Insilico Medicine, Inc, Baltimore, 21218, MD, United States, Computer Technologies Lab, ITMO University, St.-Petersburg, 197101, Russian Federation; Asadulaev A., Computer Technologies Lab, ITMO University, St.-Petersburg, 197101, Russian Federation; Ivanenkov Y., Pharma.AI Department, Insilico Medicine, Inc, Baltimore, 21218, MD, United States, Moscow Institute of Physics and Technology (State University), 9 Institutskiy lane, Dolgoprudny City, Moscow Region, 141700, Russian Federation, Institute of Biochemistry and Genetics Russian Academy of Science (IBG RAS), Ufa Scientific Centre, Oktyabrya Prospekt 71, Ufa, 450054, Russian Federation; Aladinskiy V., Pharma.AI Department, Insilico Medicine, Inc, Baltimore, 21218, MD, United States, Moscow Institute of Physics and Technology (State University), 9 Institutskiy lane, Dolgoprudny City, Moscow Region, 141700, Russian Federation; Sanchez-Lengeling B., Chemistry and Chemical Biology Department, Harvard University, 12 Oxford Street, Cambridge, 02143, MA, United States; Aspuru-Guzik A., Chemistry and Chemical Biology Department, Harvard University, 12 Oxford Street, Cambridge, 02143, MA, United States, Biologically-Inspired Solar Energy Program, Canadian Institute for Advanced Research (CIFAR), Toronto, M5S 1M1, ON, Canada; Zhavoronkov A., Pharma.AI Department, Insilico Medicine, Inc, Baltimore, 21218, MD, United States, Buck Institute for Research on Aging, 8001 Redwood Boulevard, Novato, 94945, CA, United States","In silico modeling is a crucial milestone in modern drug design and development. Although computer-aided approaches in this field are well-studied, the application of deep learning methods in this research area is at the beginning. In this work, we present an original deep neural network (DNN) architecture named RANC (Reinforced Adversarial Neural Computer) for the de novo design of novel small-molecule organic structures based on the generative adversarial network (GAN) paradigm and reinforcement learning (RL). As a generator RANC uses a differentiable neural computer (DNC), a category of neural networks, with increased generation capabilities due to the addition of an explicit memory bank, which can mitigate common problems found in adversarial settings. The comparative results have shown that RANC trained on the SMILES string representation of the molecules outperforms its first DNN-based counterpart ORGANIC by several metrics relevant to drug discovery: the number of unique structures, passing medicinal chemistry filters (MCFs), Muegge criteria, and high QED scores. RANC is able to generate structures that match the distributions of the key chemical features/descriptors (e.g., MW, logP, TPSA) and lengths of the SMILES strings in the training data set. Therefore, RANC can be reasonably regarded as a promising starting point to develop novel molecules with activity against different biological targets or pathways. In addition, this approach allows scientists to save time and covers a broad chemical space populated with novel and diverse compounds. © 2018 American Chemical Society.","","Algorithms; Computer-Aided Design; Deep Learning; Drug Design; Drug Discovery; Equipment Design; Machine Learning; Neural Networks (Computer); Computer aided instruction; Computer networks; Deep learning; Deep neural networks; Learning systems; Molecules; Outsourcing; Reinforcement learning; Adversarial networks; Biological targets; Chemical features; Computer aided-approach; Learning methods; Medicinal chemistry; Organic structures; Training data sets; algorithm; artificial neural network; computer aided design; devices; drug design; drug development; equipment design; machine learning; procedures; Neural networks","American Chemical Society","15499596","","JCISD","29762023","Article","Scopus","2-s2.0-85047412990"
"Bandaragoda T.; Ranasinghe W.; Adikari A.; de Silva D.; Lawrentschuk N.; Alahakoon D.; Persad R.; Bolton D.","Bandaragoda, Tharindu (56717659400); Ranasinghe, Weranja (27268036300); Adikari, Achini (57200703350); de Silva, Daswin (55242193900); Lawrentschuk, Nathan (57217501609); Alahakoon, Damminda (6602546111); Persad, Raj (35467356700); Bolton, Damien (26425523100)","56717659400; 27268036300; 57200703350; 55242193900; 57217501609; 6602546111; 35467356700; 26425523100","The Patient-Reported Information Multidimensional Exploration (PRIME) Framework for Investigating Emotions and Other Factors of Prostate Cancer Patients with Low Intermediate Risk Based on Online Cancer Support Group Discussions","2018","Annals of Surgical Oncology","20","10.1245/s10434-018-6372-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042227885&doi=10.1245%2fs10434-018-6372-2&partnerID=40&md5=66cadc03b706eafe775af619c1142afc","Research Centre for Data Analytics and Cognition, La Trobe University, Melbourne, VIC, Australia; Austin Hospital, Heidelberg, VIC, Australia; North Bristol NHS Trust, Bristol, United Kingdom","Bandaragoda T., Research Centre for Data Analytics and Cognition, La Trobe University, Melbourne, VIC, Australia; Ranasinghe W., Research Centre for Data Analytics and Cognition, La Trobe University, Melbourne, VIC, Australia, Austin Hospital, Heidelberg, VIC, Australia; Adikari A., Research Centre for Data Analytics and Cognition, La Trobe University, Melbourne, VIC, Australia; de Silva D., Research Centre for Data Analytics and Cognition, La Trobe University, Melbourne, VIC, Australia; Lawrentschuk N., Austin Hospital, Heidelberg, VIC, Australia; Alahakoon D., Research Centre for Data Analytics and Cognition, La Trobe University, Melbourne, VIC, Australia; Persad R., North Bristol NHS Trust, Bristol, United Kingdom; Bolton D., Austin Hospital, Heidelberg, VIC, Australia","Background: This study aimed to use the Patient Reported Information Multidimensional Exploration (PRIME) framework, a novel ensemble of machine-learning and deep-learning algorithms, to extract, analyze, and correlate self-reported information from Online Cancer Support Groups (OCSG) by patients (and partners of patients) with low intermediate-risk prostate cancer (PCa) undergoing radical prostatectomy (RP), external beam radiotherapy (EBRT), and active surveillance (AS), and to investigate its efficacy in quality-of-life (QoL) and emotion measures. Methods: From patient-reported information on 10 OCSG, the PRIME framework automatically filtered and extracted conversations on low intermediate-risk PCa with active user participation. Side effects as well as emotional and QoL outcomes for 6084 patients were analyzed. Results: Side-effect profiles differed between the methods analyzed, with men after RP having more urinary and sexual side effects and men after EBRT having more bowel symptoms. Key findings from the analysis of emotional expressions showed that PCa patients younger than 40 years expressed significantly high positive and negative emotions compared with other age groups, that partners of patients expressed more negative emotions than the patients, and that selected cohorts (< 40 years, > 70 years, partners of patients) have frequently used the same terms to express their emotions, which is indicative of QoL issues specific to those cohorts. Conclusion: Despite recent advances in patient-centerd care, patient emotions are largely overlooked, especially in younger men with a diagnosis of PCa and their partners. The authors present a novel approach, the PRIME framework, to extract, analyze, and correlate key patient factors. This framework improves understanding of QoL and identifies low intermediate-risk PCa patients who require additional support. © 2018, Society of Surgical Oncology.","","Adult; Age Factors; Aged; Algorithms; Deep Learning; Emotions; Humans; Internet; Male; Middle Aged; Prostatectomy; Prostatic Neoplasms; Quality of Life; Radiotherapy; Risk Factors; Self Report; Self-Help Groups; Spouses; Watchful Waiting; adult; aged; Article; bladder irritation; bladder neck stenosis; cancer patient; cancer radiotherapy; cancer surgery; cohort analysis; conversation; emotion; external beam radiotherapy; gastrointestinal irritation; groups by age; human; intermediate risk population; learning algorithm; low risk population; machine learning; major clinical study; male; middle aged; patient-reported outcome; prostate cancer; prostatectomy; quality of life; rectum hemorrhage; support group; urethra stenosis; urine incontinence; age; algorithm; Internet; prostate tumor; psychology; quality of life; radiotherapy; risk factor; self help; self report; spouse; watchful waiting","Springer New York LLC","10689265","","ASONF","29468607","Article","Scopus","2-s2.0-85042227885"
"Chin-Yee B.; Upshur R.","Chin-Yee, Benjamin (47060909100); Upshur, Ross (35597915300)","47060909100; 35597915300","Clinical judgement in the era of big data and predictive analytics","2018","Journal of Evaluation in Clinical Practice","37","10.1111/jep.12852","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038030968&doi=10.1111%2fjep.12852&partnerID=40&md5=7d89a79298ebfd585994ea35bb9b9af0","Department of Medicine, University of Toronto, Toronto, Canada; Department of Family and Community Medicine and Dalla Lana School of Public Health, University of Toronto, Toronto, Canada","Chin-Yee B., Department of Medicine, University of Toronto, Toronto, Canada; Upshur R., Department of Family and Community Medicine and Dalla Lana School of Public Health, University of Toronto, Toronto, Canada","Clinical judgement is a central and longstanding issue in the philosophy of medicine which has generated significant interest over the past few decades. In this article, we explore different approaches to clinical judgement articulated in the literature, focusing in particular on data-driven, mathematical approaches which we contrast with narrative, virtue-based approaches to clinical reasoning. We discuss the tension between these different clinical epistemologies and further explore the implications of big data and machine learning for a philosophy of clinical judgement. We argue for a pluralistic, integrative approach, and demonstrate how narrative, virtue-based clinical reasoning will remain indispensable in an era of big data and predictive analytics. © 2017 John Wiley & Sons, Ltd.","artificial intelligence; big data; clinical epistemology; clinical judgement; evidence-based medicine; machine learning; medical education; narrative medicine; person-centred medicine; philosophy of medicine; predictive analytics","Clinical Decision-Making; Databases, Factual; Education, Medical; Evidence-Based Medicine; Judgment; Knowledge; Machine Learning; Narrative Medicine; Uncertainty; Article; cardiovascular disease; clinical decision making; clinical judgement; computer assisted tomography; decision making; deep learning algorithm; diabetes mellitus; diabetic retinopathy; diagnostic accuracy; human; laboratory technologist; learning algorithm; longevity; machine learning; malignant neoplasm; mathematical analysis; medical education; medical technologist; nurse; occupational therapist; pharmacist; physiotherapist; prediction; priority journal; clinical decision making; evidence based medicine; factual database; knowledge; medical education; narrative medicine; uncertainty","Blackwell Publishing Ltd","13561294","","JECPF","29237237","Article","Scopus","2-s2.0-85038030968"
"Varadarajan A.V.; Poplin R.; Blumer K.; Angermueller C.; Ledsam J.; Chopra R.; Keane P.A.; Corrado G.S.; Peng L.; Webster D.R.","Varadarajan, Avinash V. (57200692852); Poplin, Ryan (37026985800); Blumer, Katy (57200692595); Angermueller, Christof (56270539900); Ledsam, Joe (57195333840); Chopra, Reena (55553202300); Keane, Pearse A. (24480921100); Corrado, Greg S. (7006502115); Peng, Lily (57192709975); Webster, Dale R. (57192707673)","57200692852; 37026985800; 57200692595; 56270539900; 57195333840; 55553202300; 24480921100; 7006502115; 57192709975; 57192707673","Deep learning for predicting refractive error from retinal fundus images","2018","Investigative Ophthalmology and Visual Science","116","10.1167/iovs.18-23887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048032246&doi=10.1167%2fiovs.18-23887&partnerID=40&md5=f90dfd22e96a1c0d901a4b136e7f635d","Google Research, Google, Inc, Mountain View, CA, United States; Google DeepMind, Google, Inc, London, United Kingdom; NIHR Biomedical Research Centre for Ophthalmology, Moorfields Eye Hospital NHS Foundation Trust, UCL Institute of Ophthalmology, London, United Kingdom","Varadarajan A.V., Google Research, Google, Inc, Mountain View, CA, United States; Poplin R., Google Research, Google, Inc, Mountain View, CA, United States; Blumer K., Google Research, Google, Inc, Mountain View, CA, United States; Angermueller C., Google Research, Google, Inc, Mountain View, CA, United States; Ledsam J., Google DeepMind, Google, Inc, London, United Kingdom; Chopra R., NIHR Biomedical Research Centre for Ophthalmology, Moorfields Eye Hospital NHS Foundation Trust, UCL Institute of Ophthalmology, London, United Kingdom; Keane P.A., NIHR Biomedical Research Centre for Ophthalmology, Moorfields Eye Hospital NHS Foundation Trust, UCL Institute of Ophthalmology, London, United Kingdom; Corrado G.S., Google Research, Google, Inc, Mountain View, CA, United States; Peng L., Google Research, Google, Inc, Mountain View, CA, United States; Webster D.R., Google Research, Google, Inc, Mountain View, CA, United States","PURPOSE. We evaluate how deep learning can be applied to extract novel information such as refractive error from retinal fundus imaging. METHODS. Retinal fundus images used in this study were 45-and 30-degree field of view images from the UK Biobank and Age-Related Eye Disease Study (AREDS) clinical trials, respectively. Refractive error was measured by autorefraction in UK Biobank and subjective refraction in AREDS. We trained a deep learning algorithm to predict refractive error from a total of 226,870 images and validated it on 24,007 UK Biobank and 15,750 AREDS images. Our model used the ‘‘attention’’ method to identify features that are correlated with refractive error. RESULTS. The resulting algorithm had a mean absolute error (MAE) of 0.56 diopters (95% confidence interval [CI]: 0.55–0.56) for estimating spherical equivalent on the UK Biobank data set and 0.91 diopters (95% CI: 0.89–0.93) for the AREDS data set. The baseline expected MAE (obtained by simply predicting the mean of this population) was 1.81 diopters (95% CI: 1.79–1.84) for UK Biobank and 1.63 (95% CI: 1.60–1.67) for AREDS. Attention maps suggested that the foveal region was one of the most important areas used by the algorithm to make this prediction, though other regions also contribute to the prediction. CONCLUSIONS. To our knowledge, the ability to estimate refractive error with high accuracy from retinal fundus photos has not been previously known and demonstrates that deep learning can be applied to make novel predictions from medical images. © 2018 The Authors.","Deep learning; Machine learning; Refractive error; Retinal imaging","Adult; Aged; Algorithms; Datasets as Topic; Deep Learning; Female; Fundus Oculi; Humans; Male; Middle Aged; Refraction, Ocular; Refractive Errors; Retina; Vision Tests; Visual Fields; adult; aged; algorithm; Article; deep learning algorithm; diagnostic imaging; eye fundus; female; human; major clinical study; male; middle aged; nerve cell network; optical coherence tomography; priority journal; refraction error; retinal fundus imaging; algorithm; eye refraction; information processing; physiology; refraction error; retina; vision test; visual field","Association for Research in Vision and Ophthalmology Inc.","01460404","","IOVSD","30025129","Article","Scopus","2-s2.0-85048032246"
"Huang H.; Hu X.; Zhao Y.; Makkie M.; Dong Q.; Zhao S.; Guo L.; Liu T.","Huang, Heng (57202910282); Hu, Xintao (56177187200); Zhao, Yu (56352413600); Makkie, Milad (56997432100); Dong, Qinglin (57190214381); Zhao, Shijie (56014643800); Guo, Lei (56428255600); Liu, Tianming (57203377182)","57202910282; 56177187200; 56352413600; 56997432100; 57190214381; 56014643800; 56428255600; 57203377182","Modeling Task fMRI Data Via Deep Convolutional Autoencoder","2018","IEEE Transactions on Medical Imaging","142","10.1109/TMI.2017.2715285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023184030&doi=10.1109%2fTMI.2017.2715285&partnerID=40&md5=be744380924096683cb9f18516048f89","School of Automation, Northwestern Polytechnical University, Xi'an, 710072, China; Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Laboratory, University of Georgia, Athens, 30602, GA, United States","Huang H., School of Automation, Northwestern Polytechnical University, Xi'an, 710072, China; Hu X., School of Automation, Northwestern Polytechnical University, Xi'an, 710072, China; Zhao Y., Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Laboratory, University of Georgia, Athens, 30602, GA, United States; Makkie M., Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Laboratory, University of Georgia, Athens, 30602, GA, United States; Dong Q., Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Laboratory, University of Georgia, Athens, 30602, GA, United States; Zhao S., School of Automation, Northwestern Polytechnical University, Xi'an, 710072, China; Guo L., School of Automation, Northwestern Polytechnical University, Xi'an, 710072, China; Liu T., Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Laboratory, University of Georgia, Athens, 30602, GA, United States","Task-based functional magnetic resonance imaging (tfMRI) has been widely used to study functional brain networks under task performance. Modeling tfMRI data is challenging due to at least two problems: the lack of the ground truth of underlying neural activity and the highly complex intrinsic structure of tfMRI data. To better understand brain networks based on fMRI data, data-driven approaches have been proposed, for instance, independent component analysis (ICA) and sparse dictionary learning (SDL). However, both ICA and SDL only build shallow models, and they are under the strong assumption that original fMRI signal could be linearly decomposed into time series components with their corresponding spatial maps. As growing evidence shows that human brain function is hierarchically organized, new approaches that can infer and model the hierarchical structure of brain networks are widely called for. Recently, deep convolutional neural network (CNN) has drawn much attention, in that deep CNN has proven to be a powerful method for learning high-level and mid-level abstractions from low-level raw data. Inspired by the power of deep CNN, in this paper, we developed a new neural network structure based on CNN, called deep convolutional auto-encoder (DCAE), in order to take the advantages of both data-driven approach and CNN's hierarchical feature abstraction ability for the purpose of learning mid-level and high-level features from complex, large-scale tfMRI time series in an unsupervised manner. The DCAE has been applied and tested on the publicly available human connectome project tfMRI data sets, and promising results are achieved. © 1982-2012 IEEE.","CNN; deep learning; Task fMRI; unsupervised","Brain; Connectome; Deep Learning; Humans; Magnetic Resonance Imaging; Unsupervised Machine Learning; Abstracting; Brain; Brain models; Complex networks; Convolution; Data structures; Decoding; Deep learning; Deep neural networks; Hidden Markov models; Independent component analysis; Learning systems; Neural networks; Neurons; Signal systems; Time series analysis; Deep convolutional neural networks; Hierarchical features; Hierarchical structures; Human brain functions; Independent component analyses (ICA); Neural network structures; Task fMRI; unsupervised; attention; brain function; connectome; decomposition; functional magnetic resonance imaging; hidden Markov model; human; independent component analysis; machine learning; time series analysis; brain; diagnostic imaging; nuclear magnetic resonance imaging; procedures; unsupervised machine learning; Functional neuroimaging","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28641247","Article","Scopus","2-s2.0-85023184030"
"Wang H.; Song W.; Liu W.; Song N.; Wang Y.; Pan H.","Wang, Huafeng (36783787700); Song, Wenfeng (57200110246); Liu, Wanquan (7407343628); Song, Ning (57202508072); Wang, Yuehai (57194466632); Pan, Haixia (55366540700)","36783787700; 57200110246; 7407343628; 57202508072; 57194466632; 55366540700","A bayesian scene-prior-based deep network model for face verification","2018","Sensors (Switzerland)","6","10.3390/s18061906","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048553995&doi=10.3390%2fs18061906&partnerID=40&md5=8a947b2d3c688df5906210e4222f319f","Department of Electronics and Information Engineering, North China University of Technology, Beijing, 100144, China; Department of Software, Beihang University, Beijing, 100191, China; Department of Computing, Curtin University, Perth, 6102, WA, Australia","Wang H., Department of Electronics and Information Engineering, North China University of Technology, Beijing, 100144, China, Department of Software, Beihang University, Beijing, 100191, China; Song W., Department of Software, Beihang University, Beijing, 100191, China; Liu W., Department of Computing, Curtin University, Perth, 6102, WA, Australia; Song N., Department of Software, Beihang University, Beijing, 100191, China; Wang Y., Department of Electronics and Information Engineering, North China University of Technology, Beijing, 100144, China; Pan H., Department of Software, Beihang University, Beijing, 100191, China","Face recognition/verification has received great attention in both theory and application for the past two decades. Deep learning has been considered as a very powerful tool for improving the performance of face recognition/verification recently. With large labeled training datasets, the features obtained from deep learning networks can achieve higher accuracy in comparison with shallow networks. However, many reported face recognition/verification approaches rely heavily on the large size and complete representative of the training set, and most of them tend to suffer serious performance drop or even fail to work if fewer training samples per person are available. Hence, the small number of training samples may cause the deep features to vary greatly. We aim to solve this critical problem in this paper. Inspired by recent research in scene domain transfer, for a given face image, a new series of possible scenarios about this face can be deduced from the scene semantics extracted from other face individuals in a face dataset. We believe that the “scene” or background in an image, that is, samples with more different scenes for a given person, may determine the intrinsic features among the faces of the same individual. In order to validate this belief, we propose a Bayesian scene-prior-based deep learning model in this paper with the aim to extract important features from background scenes. By learning a scene model on the basis of a labeled face dataset via the Bayesian idea, the proposed method transforms a face image into new face images by referring to the given face with the learnt scene dictionary. Because the new derived faces may have similar scenes to the input face, the face-verification performance can be improved without having background variance, while the number of training samples is significantly reduced. Experiments conducted on the Labeled Faces in the Wild (LFW) dataset view #2 subset illustrated that this model can increase the verification accuracy to 99.2% by means of scenes’ transfer learning (99.12% in literature with an unsupervised protocol). Meanwhile, our model can achieve 94.3% accuracy for the YouTube Faces database (DB) (93.2% in literature with an unsupervised protocol). © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Bayesian network; Deep features; Deep learning network; Face verification; Scene transfer","Area Under Curve; Bayes Theorem; Biometric Identification; Databases, Factual; Face; Humans; Machine Learning; Pattern Recognition, Automated; ROC Curve; Bayesian networks; Deep learning; Sampling; Semantics; Background variances; Deep features; Face recognition/verification; Face Verification; Labeled faces in the wilds (LFW); Learning network; Scene transfer; Training data sets; anatomy and histology; area under the curve; automated pattern recognition; Bayes theorem; biometry; face; factual database; human; machine learning; physiology; procedures; receiver operating characteristic; Face recognition","MDPI AG","14248220","","","29891830","Article","Scopus","2-s2.0-85048553995"
"Simm J.; Klambauer G.; Arany A.; Steijaert M.; Wegner J.K.; Gustin E.; Chupakhin V.; Chong Y.T.; Vialard J.; Buijnsters P.; Velter I.; Vapirev A.; Singh S.; Carpenter A.E.; Wuyts R.; Hochreiter S.; Moreau Y.; Ceulemans H.","Simm, Jaak (36605334600); Klambauer, Günter (6507603426); Arany, Adam (54934398000); Steijaert, Marvin (56829492400); Wegner, Jörg Kurt (57216675113); Gustin, Emmanuel (6602814811); Chupakhin, Vladimir (14028059100); Chong, Yolanda T. (26533899900); Vialard, Jorge (7003539466); Buijnsters, Peter (55923449100); Velter, Ingrid (14016998100); Vapirev, Alexander (17135971300); Singh, Shantanu (24470175500); Carpenter, Anne E. (8063969900); Wuyts, Roel (23096675100); Hochreiter, Sepp (6602873810); Moreau, Yves (7006734235); Ceulemans, Hugo (6603583751)","36605334600; 6507603426; 54934398000; 56829492400; 57216675113; 6602814811; 14028059100; 26533899900; 7003539466; 55923449100; 14016998100; 17135971300; 24470175500; 8063969900; 23096675100; 6602873810; 7006734235; 6603583751","Repurposing High-Throughput Image Assays Enables Biological Activity Prediction for Drug Discovery","2018","Cell Chemical Biology","135","10.1016/j.chembiol.2018.01.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042602612&doi=10.1016%2fj.chembiol.2018.01.015&partnerID=40&md5=23deae3f5acf17aea1e17e1dfbd5ae6d","ESAT-STADIUS, KU Leuven, Kasteelpark Arenberg 10, Leuven, 3001, Belgium; Institute of Bioinformatics, Johannes Kepler University Linz, Altenbergerstrasse 69, Linz, 4040, Austria; Open Analytics NV, Jupiterstraat 20, Antwerp, 2600, Belgium; Janssen Pharmaceutica NV, Turnhoutseweg 30, Beerse, 2340, Belgium; Facilities for Research, KU Leuven, Willem de Croylaan 52c, Box 5580, Leuven, 3001, Belgium; Imaging Platform, Broad Institute of Harvard and MIT, 415 Main Street, Cambridge, 02142, MA, United States; ExaScience Life Lab, IMEC, Kapeldreef 75, Leuven, 3001, Belgium","Simm J., ESAT-STADIUS, KU Leuven, Kasteelpark Arenberg 10, Leuven, 3001, Belgium; Klambauer G., Institute of Bioinformatics, Johannes Kepler University Linz, Altenbergerstrasse 69, Linz, 4040, Austria; Arany A., ESAT-STADIUS, KU Leuven, Kasteelpark Arenberg 10, Leuven, 3001, Belgium; Steijaert M., Open Analytics NV, Jupiterstraat 20, Antwerp, 2600, Belgium; Wegner J.K., Janssen Pharmaceutica NV, Turnhoutseweg 30, Beerse, 2340, Belgium; Gustin E., Janssen Pharmaceutica NV, Turnhoutseweg 30, Beerse, 2340, Belgium; Chupakhin V., Janssen Pharmaceutica NV, Turnhoutseweg 30, Beerse, 2340, Belgium; Chong Y.T., Janssen Pharmaceutica NV, Turnhoutseweg 30, Beerse, 2340, Belgium; Vialard J., Janssen Pharmaceutica NV, Turnhoutseweg 30, Beerse, 2340, Belgium; Buijnsters P., Janssen Pharmaceutica NV, Turnhoutseweg 30, Beerse, 2340, Belgium; Velter I., Janssen Pharmaceutica NV, Turnhoutseweg 30, Beerse, 2340, Belgium; Vapirev A., Facilities for Research, KU Leuven, Willem de Croylaan 52c, Box 5580, Leuven, 3001, Belgium; Singh S., Imaging Platform, Broad Institute of Harvard and MIT, 415 Main Street, Cambridge, 02142, MA, United States; Carpenter A.E., Imaging Platform, Broad Institute of Harvard and MIT, 415 Main Street, Cambridge, 02142, MA, United States; Wuyts R., ExaScience Life Lab, IMEC, Kapeldreef 75, Leuven, 3001, Belgium; Hochreiter S., Institute of Bioinformatics, Johannes Kepler University Linz, Altenbergerstrasse 69, Linz, 4040, Austria; Moreau Y., ESAT-STADIUS, KU Leuven, Kasteelpark Arenberg 10, Leuven, 3001, Belgium; Ceulemans H., Janssen Pharmaceutica NV, Turnhoutseweg 30, Beerse, 2340, Belgium","In both academia and the pharmaceutical industry, large-scale assays for drug discovery are expensive and often impractical, particularly for the increasingly important physiologically relevant model systems that require primary cells, organoids, whole organisms, or expensive or rare reagents. We hypothesized that data from a single high-throughput imaging assay can be repurposed to predict the biological activity of compounds in other assays, even those targeting alternate pathways or biological processes. Indeed, quantitative information extracted from a three-channel microscopy-based screen for glucocorticoid receptor translocation was able to predict assay-specific biological activity in two ongoing drug discovery projects. In these projects, repurposing increased hit rates by 50- to 250-fold over that of the initial project assays while increasing the chemical structure diversity of the hits. Our results suggest that data from high-content screens are a rich source of information that can be used to predict and replace customized biological assays. Simm et al. demonstrate a computational method to predict the activities of compounds in hundreds of biological assays from a single image-based screen of half a million compounds. The resulting models boosted the identification and diversity of hit compounds for two projects, encouraging further research in this field. © 2018 Elsevier Ltd","Bayesian matrix factorization; computational chemistry; deep learning; drug discovery; high-content imaging; high-throughput screening; machine learning; matrix factorization","Antineoplastic Agents; Cell Line, Tumor; Drug Repositioning; High-Throughput Screening Assays; Humans; Image Processing, Computer-Assisted; Machine Learning; Neoplasms; Neural Networks (Computer); antineoplastic agent; Article; artificial neural network; bioassay; biological activity; computer model; drug development; drug industry; high throughput screening; human; immunofluorescence; in vitro study; machine learning; prediction; primary cell; priority journal; random forest; structure activity relation; supervised machine learning; artificial neural network; drug repositioning; high throughput screening; image processing; machine learning; neoplasm; procedures; tumor cell line","Elsevier Ltd","24519456","","","29503208","Article","Scopus","2-s2.0-85042602612"
"Hu X.; Huang H.; Peng B.; Han J.; Liu N.; Lv J.; Guo L.; Guo C.; Liu T.","Hu, Xintao (56177187200); Huang, Heng (57202910282); Peng, Bo (57208137956); Han, Junwei (24450644400); Liu, Nian (57141379200); Lv, Jinglei (58131694200); Guo, Lei (56428255600); Guo, Christine (55233468300); Liu, Tianming (57203377182)","56177187200; 57202910282; 57208137956; 24450644400; 57141379200; 58131694200; 56428255600; 55233468300; 57203377182","Latent source mining in FMRI via restricted Boltzmann machine","2018","Human Brain Mapping","54","10.1002/hbm.24005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047480476&doi=10.1002%2fhbm.24005&partnerID=40&md5=9d226fe28736d38b7336776b17d09fd2","School of Automation, Northwestern Polytechnical University, Xi'an, China; Cortical Architecture Imaging and Discovery Lab, Department of Computer Science and Bioimaging Research Center, The University of Georgia, Athens, GA, United States; QIMR Berghofer Medical Research Institute, Herston, QLD, Australia","Hu X., School of Automation, Northwestern Polytechnical University, Xi'an, China; Huang H., School of Automation, Northwestern Polytechnical University, Xi'an, China; Peng B., School of Automation, Northwestern Polytechnical University, Xi'an, China; Han J., School of Automation, Northwestern Polytechnical University, Xi'an, China; Liu N., School of Automation, Northwestern Polytechnical University, Xi'an, China; Lv J., School of Automation, Northwestern Polytechnical University, Xi'an, China, Cortical Architecture Imaging and Discovery Lab, Department of Computer Science and Bioimaging Research Center, The University of Georgia, Athens, GA, United States; Guo L., School of Automation, Northwestern Polytechnical University, Xi'an, China; Guo C., QIMR Berghofer Medical Research Institute, Herston, QLD, Australia; Liu T., Cortical Architecture Imaging and Discovery Lab, Department of Computer Science and Bioimaging Research Center, The University of Georgia, Athens, GA, United States","Blind source separation (BSS) is commonly used in functional magnetic resonance imaging (fMRI) data analysis. Recently, BSS models based on restricted Boltzmann machine (RBM), one of the building blocks of deep learning models, have been shown to improve brain network identification compared to conventional single matrix factorization models such as independent component analysis (ICA). These models, however, trained RBM on fMRI volumes, and are hence challenged by model complexity and limited training set. In this article, we propose to apply RBM to fMRI time courses instead of volumes for BSS. The proposed method not only interprets fMRI time courses explicitly to take advantages of deep learning models in latent feature learning but also substantially reduces model complexity and increases the scale of training set to improve training efficiency. Our experimental results based on Human Connectome Project (HCP) datasets demonstrated the superiority of the proposed method over ICA and the one that applied RBM to fMRI volumes in identifying task-related components, resulted in more accurate and specific representations of task-related activations. Moreover, our method separated out components representing intermixed effects between task events, which could reflect inherent interactions among functionally connected brain regions. Our study demonstrates the value of RBM in mining complex structures embedded in large-scale fMRI data and its potential as a building block for deeper models in fMRI data analysis. © 2018 Wiley Periodicals, Inc.","blind source separation; functional magnetic resonance imaging; restricted Boltzmann machine","Algorithms; Brain; Brain Mapping; Datasets as Topic; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Models, Neurological; Oxygen; Task Performance and Analysis; oxygen; Article; Boltzmann machine; brain region; comparative study; controlled study; data mining; emotion; functional magnetic resonance imaging; functional neuroimaging; gambling; gray matter; human; language; machine learning; motor control; motor cortex; priority journal; social cognition; white matter; working memory; algorithm; biological model; blood; brain; brain mapping; diagnostic imaging; image processing; information processing; nuclear magnetic resonance imaging; statistics and numerical data; task performance","John Wiley and Sons Inc.","10659471","","HBMAE","29457314","Article","Scopus","2-s2.0-85047480476"
"Wang C.-C.; Tan K.L.; Chen C.-T.; Lin Y.-H.; Keerthi S.S.; Mahajan D.; Sundararajan S.; Lin C.-J.","Wang, Chien-Chih (56130257500); Tan, Kent Loong (57202209077); Chen, Chun-Ting (57202223640); Lin, Yu-Hsiang (56169733000); Keerthi, S. Sathiya (35587002000); Mahajan, Dhruv (14035942400); Sundararajan, S. (7003389623); Lin, Chih-Jen (57154890600)","56130257500; 57202209077; 57202223640; 56169733000; 35587002000; 14035942400; 7003389623; 57154890600","Distributed Newton methods for deep neural networks","2018","Neural Computation","13","10.1162/neco_a_01088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047469561&doi=10.1162%2fneco_a_01088&partnerID=40&md5=a8abea26d691f1ca0eca066fe0d49b96","Department of Computer Science, National Taiwan University, Taipei, 10617, Taiwan; Department of Physics, National Taiwan University, Taipei, 10617, Taiwan; Criteo Research, Palo Alto, 94301, CA, United States; Facebook Research, Menlo Park, 94025, CA, United States; Microsoft Research India, Bangalore, Karnataka, 56001, India; Department of Computer Science, National Taiwan University, Taipei, 10617, Taiwan","Wang C.-C., Department of Computer Science, National Taiwan University, Taipei, 10617, Taiwan; Tan K.L., Department of Computer Science, National Taiwan University, Taipei, 10617, Taiwan; Chen C.-T., Department of Computer Science, National Taiwan University, Taipei, 10617, Taiwan; Lin Y.-H., Department of Physics, National Taiwan University, Taipei, 10617, Taiwan; Keerthi S.S., Criteo Research, Palo Alto, 94301, CA, United States; Mahajan D., Facebook Research, Menlo Park, 94025, CA, United States; Sundararajan S., Microsoft Research India, Bangalore, Karnataka, 56001, India; Lin C.-J., Department of Computer Science, National Taiwan University, Taipei, 10617, Taiwan","Deep learning involves a difficult nonconvex optimization problem with a large number of weights between any two adjacent layers of a deep structure. To handle large data sets or complicated networks, distributed training is needed, but the calculation of function, gradient, and Hessian is expensive. In particular, the communication and the synchronization cost may become a bottleneck. In this letter, we focus on situations where the model is distributedly stored and propose a novel distributed Newton method for training deep neural networks. By variable and feature-wise data partitions and some careful designs, we are able to explicitly use the Jacobian matrix for matrix-vector products in the Newton method. Some techniques are incorporated to reduce the running time as well as memory consumption. First, to reduce the communication cost, we propose a diagonalization method such that an approximate Newton direction can be obtained without communication between machines. Second, we consider subsampled Gauss-Newton matrices for reducing the running time as well as the communication cost. Third, to reduce the synchronization cost, we terminate the process of finding an approximate Newton direction even though some nodes have not finished their tasks. Details of some implementation issues in distributed environments are thoroughly investigated. Experiments demonstrate that the proposed method is effective for the distributed training of deep neural networks. Compared with stochastic gradient methods, it is more robust and may give better test accuracy. © 2018 Massachusetts Institute of Technology.","","Cost reduction; Distributed computer systems; Gradient methods; Jacobian matrices; Newton-Raphson method; Stochastic systems; Communication cost; Diagonalization method; Distributed environments; Matrix-vector products; Memory consumption; Nonconvex optimization problem; Stochastic gradient methods; Synchronization cost; Deep neural networks","MIT Press Journals","08997667","","","29652589","Article","Scopus","2-s2.0-85047469561"
"Hassan M.M.; Huda S.; Uddin M.Z.; Almogren A.; Alrubaian M.","Hassan, Mohammad Mehedi (57201949986); Huda, Shamsul (25823733700); Uddin, Md Zia (24482836700); Almogren, Ahmad (8970033500); Alrubaian, Majed (54947308800)","57201949986; 25823733700; 24482836700; 8970033500; 54947308800","Human Activity Recognition from Body Sensor Data using Deep Learning","2018","Journal of Medical Systems","78","10.1007/s10916-018-0948-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045621921&doi=10.1007%2fs10916-018-0948-z&partnerID=40&md5=d38a1a8667d076a64b1d54e560b866d7","Chia of Pervasive and Mobile Computing, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia; Information Systems Department, King Saud University, Riyadh, 11543, Saudi Arabia; School of IT, Deakin University, Melbourne, Australia; Department of Informatics, University of Oslo, Oslo, Norway","Hassan M.M., Chia of Pervasive and Mobile Computing, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia, Information Systems Department, King Saud University, Riyadh, 11543, Saudi Arabia; Huda S., School of IT, Deakin University, Melbourne, Australia; Uddin M.Z., Department of Informatics, University of Oslo, Oslo, Norway; Almogren A., Chia of Pervasive and Mobile Computing, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia; Alrubaian M., Chia of Pervasive and Mobile Computing, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia","In recent years, human activity recognition from body sensor data or wearable sensor data has become a considerable research attention from academia and health industry. This research can be useful for various e-health applications such as monitoring elderly and physical impaired people at Smart home to improve their rehabilitation processes. However, it is not easy to accurately and automatically recognize physical human activity through wearable sensors due to the complexity and variety of body activities. In this paper, we address the human activity recognition problem as a classification problem using wearable body sensor data. In particular, we propose to utilize a Deep Belief Network (DBN) model for successful human activity recognition. First, we extract the important initial features from the raw body sensor data. Then, a kernel principal component analysis (KPCA) and linear discriminant analysis (LDA) are performed to further process the features and make them more robust to be useful for fast activity recognition. Finally, the DBN is trained by these features. Various experiments were performed on a real-world wearable sensor dataset to verify the effectiveness of the deep learning algorithm. The results show that the proposed DBN outperformed other algorithms and achieves satisfactory activity recognition performance. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Body sensor data; Deep belief network; Deep learning; Human activity recognition","Algorithms; Exercise Test; Humans; Machine Learning; Monitoring, Ambulatory; Movement; Neural Networks (Computer); Remote Sensing Technology; Reproducibility of Results; accelerometry; Article; artificial neural network; deep belief network; discriminant analysis; human; human activities; learning algorithm; machine learning; physical activity; principal component analysis; sitting; standing; support vector machine; walking; algorithm; ambulatory monitoring; exercise test; machine learning; movement (physiology); physiology; procedures; remote sensing; reproducibility","Springer New York LLC","01485598","","JMSYD","29663090","Article","Scopus","2-s2.0-85045621921"
"Guo L.; Lei Y.; Li N.; Yan T.; Li N.","Guo, Liang (57216424083); Lei, Yaguo (8905846900); Li, Naipeng (55960170700); Yan, Tao (56068081500); Li, Ningbo (57194586752)","57216424083; 8905846900; 55960170700; 56068081500; 57194586752","Machinery health indicator construction based on convolutional neural networks considering trend burr","2018","Neurocomputing","223","10.1016/j.neucom.2018.02.083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043466517&doi=10.1016%2fj.neucom.2018.02.083&partnerID=40&md5=399cc94d1772b870ca8bebbcb13a5c25","Key Laboratory of Education Ministry for Modern Design and Rotor-Bearing System, Xi'an Jiaotong University, Xi'an, 710049, Shaanxi, China; Shaanxi Key Laboratory of Mechanical Product Quality Assurance and Diagnostics, Xi'an Jiaotong University, Xi'an, 710049, Shaanxi, China","Guo L., Shaanxi Key Laboratory of Mechanical Product Quality Assurance and Diagnostics, Xi'an Jiaotong University, Xi'an, 710049, Shaanxi, China; Lei Y., Key Laboratory of Education Ministry for Modern Design and Rotor-Bearing System, Xi'an Jiaotong University, Xi'an, 710049, Shaanxi, China; Li N., Shaanxi Key Laboratory of Mechanical Product Quality Assurance and Diagnostics, Xi'an Jiaotong University, Xi'an, 710049, Shaanxi, China; Yan T., Shaanxi Key Laboratory of Mechanical Product Quality Assurance and Diagnostics, Xi'an Jiaotong University, Xi'an, 710049, Shaanxi, China; Li N., Shaanxi Key Laboratory of Mechanical Product Quality Assurance and Diagnostics, Xi'an Jiaotong University, Xi'an, 710049, Shaanxi, China","In the study of data-driven prognostic methods of machinery, much attention has been paid to constructing health indicators (HIs). Most of the existing HIs, however, are manually constructed for a specific degradation process and need the prior knowledge of experts. Additionally, for the existing HIs, there are usually some outlier regions deviating to an expected degradation trend and reducing the performance of HIs. We refer to this phenomenon as trend burr. To deal with these problems, this paper proposes a convolutional neural network based HI construction method considering trend burr. The proposed method first learns features through convolution and pooling operations, and then these learned features are constructed into a HI through a nonlinear mapping operation. Furthermore, an outlier region correction technique is applied to detect and remove outlier regions existing in the HIs. Unlike traditional methods in which HIs are manually constructed, the proposed method aims to automatically construct HIs. Moreover, the outlier region correction technique enables the constructed HIs to be more effective. The effectiveness of the proposed method is verified using a bearing dataset. Through comparing with commonly used HI construction methods, it is demonstrated that the proposed method achieves better results in terms of trendability, monotonicity and scale similarity. © 2018 Elsevier B.V.","Convolutional neural network; Deep learning; Machinery health indicator; Outlier region correction; Trend burr","Convolution; Deep learning; Health; Machinery; Neural networks; Construction method; Convolutional neural network; Correction techniques; Data-driven prognostics; Degradation process; Machinery health; Nonlinear mappings; Trend burr; algorithm; Article; artificial neural network; classification; data processing; health status indicator; machine; machine learning; mathematical analysis; nonlinear system; priority journal; prognosis; remote sensing; signal processing; Statistics","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85043466517"
"Tang C.Q.; Li J.Q.; Xu D.Y.; Liu X.B.; Hou W.J.; Lyu K.Y.; Xiao S.C.; Xia Z.F.","Tang, C.Q. (57205374162); Li, J.Q. (57190445664); Xu, D.Y. (57210259732); Liu, X.B. (57205369626); Hou, W.J. (57205370984); Lyu, K.Y. (57190182438); Xiao, S.C. (56160519500); Xia, Z.F. (55546675800)","57205374162; 57190445664; 57210259732; 57205369626; 57205370984; 57190182438; 56160519500; 55546675800","Comparison of machine learning method and logistic regression model in prediction of acute kidney injury in severely burned patients","2018","Zhonghua shao shang za zhi = Zhonghua shaoshang zazhi = Chinese journal of burns","15","10.3760/cma.j.issn.1009-2587.2018.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059799187&doi=10.3760%2fcma.j.issn.1009-2587.2018.06.006&partnerID=40&md5=5192572f0b7253761b6cee68a8ccab7e","Department of Burn Surgery, First Affiliated Hospital, Naval Military Medical University, Shanghai, 200433, China","Tang C.Q., Department of Burn Surgery, First Affiliated Hospital, Naval Military Medical University, Shanghai, 200433, China; Li J.Q.; Xu D.Y.; Liu X.B.; Hou W.J.; Lyu K.Y.; Xiao S.C.; Xia Z.F.","目的： 构建严重烧伤患者发生急性肾损伤(AKI)的风险预测模型，比较机器学习和logistic回归模型的预测效能。 方法： 收集在""八二""昆山工厂铝粉尘爆炸事故中严重烧伤的符合入选标准的157例患者的临床资料。将入院90 d内发生AKI的患者纳入AKI组，其余患者纳入非AKI组。使用单因素分析筛选可能和AKI发生相关的因素，包括患者性别、年龄、入院耗时、基础伤情、入院初始评分、治疗情况以及伤后30、60、90 d病死率等指标。对数据行Mann－Whitney U检验、χ(2)检验、Fisher确切概率法检验。将单因素分析中P<0.1以及可能有临床意义的变量纳入预测模型的构建，分别采用logistic回归分析和XGBoost机器学习算法构建AKI预测模型。计算模型的受试者工作特征曲线下面积(AUC)，以及最佳阈值下的敏感度、特异度。2个预测模型AUC差异的显著性检验采用非参数的重复采样方法。 结果： (1)患者中89例(56.7%)在入院90 d内发生了AKI。与非AKI组68例患者相比，AKI组89例患者的年龄更大(Z＝－2.203，P<0.05)，烧伤总面积和Ⅲ度烧伤面积更大(Z＝－5.200、－6.297，P<0.01)，入院时的急性生理与慢性健康评估Ⅱ(APACHEⅡ)评分、简明烧伤严重程度指数评分、序贯器官衰竭评估(SOFA)评分更差(Z＝－7.485、－4.739、－4.590，P<0.01)，发生脓毒症的百分比更高(χ(2)＝33.087，P<0.01)，接受气管切开、呼吸机辅助呼吸以及连续性肾脏替代治疗的百分比更高(χ(2)＝12.373、17.201、43.763，P<0.01)，首次切痂面积更大(Z＝－2.191，P<0.05)，伤后30、60、90 d病死率更高(χ(2)＝7.483、37.259、45.533，P<0.01)。2组患者的性别、切开减张、入院耗时、入院后24 h补液量、入院后48 h补液量、第1个24 h尿量、第2个24 h尿量、首次切痂时间、吸入性损伤比较，差异无统计学意义(χ(2)＝0.529、3.318，Z＝－1.746、－0.016、－1.199、－1.824、－0.625、－1.747，P>0.05)；深静脉置管率均为100%。(2)根据单因素分析的差异结果以及变量的临床意义，筛选出20个可能的预测自变量，供模型的初步构建。(3)logistic回归预测模型的自变量为APACHEⅡ评分(比值比为1.36，95%置信区间为1.20～1.53，P<0.001)、脓毒症(比值比为2.63，95%置信区间为0.90～7.66，P>0.05)及第1个24 h尿量(比值比为0.71，95%置信区间为0.50～1.01，P>0.05)。logistic回归分析构建预测模型的AUC为0.875(95%置信区间为0.821～0.930)，最佳阈值下的特异度为84.4%、敏感度为77.7%。(4)XGBoost机器学习算法构建的模型有7个主要预测变量：APACHEⅡ评分、Ⅲ度烧伤面积、入院后24 h补液量、脓毒症、第1个24 h尿量、SOFA评分、入院后48 h补液量。机器学习算法构建预测模型的AUC为0.920(95%置信区间为0.879～0.962)，比logistic回归分析构建模型更高(P<0.001)，最佳阈值下的特异度为89.7%、敏感度为82.0%。 结论： 脓毒症和液体复苏情况是严重烧伤患者发生AKI的可干预的重要预测变量。机器学习模型预测严重烧伤患者发生AKI的性能较logistic回归预测模型更佳，能为患者提供更为精准的个体化预测，具有良好的临床应用前景。.; Objective: To build risk prediction models for acute kidney injury (AKI) in severely burned patients, and to compare the prediction performance of machine learning method and logistic regression model. Methods: The clinical data of 157 severely burned patients in August 2nd Kunshan factory aluminum dust explosion accident conforming to the inclusion criteria were collected. Patients suffering AKI within 90 days after admission were enrolled in group AKI, while the others were enrolled in non-AKI group. Single factor analysis was used to choose independent factors associated with AKI, including sex, age, admission time, features of basic injuries, initial score on admission, treatment condition, and mortality on post injury days 30, 60, and 90. Data were processed with Mann-Whitney U test, chi-square test, and Fisher's exact test. Variables with P<0.1 in single factor analysis and those with possible clinical significance were brought into the establishment of prediction model. Logistic regression and XGBoost machine learning algorithm were used to build the prediction model of AKI. The area under receiver operating characteristic curve (AUC) was calculated, and the sensitivity and specificity for optimal threshold value were also calculated for each model. Nonparametric resampling test was used to compare the significance of difference of AUC of the two models. Results: (1) Eighty-nine (56.7%) patients developed AKI within 90 days from admission. Compared with 68 patients in non-AKI group, 89 patients in group AKI were older (Z=-2.203, P<0.05), with larger total burn area and full-thickness burn area (Z=-5.200, -6.297, P<0.01), worse acute physical and chronic health evaluation (APACHE) Ⅱ score, abbreviated burn severity index score, and sequential organ failure assessment (SOFA) score on admission (Z=-7.485, -4.739, -4.590, P<0.01), higher occurrence rate of sepsis (χ(2)=33.087, P<0.01), higher rates of accepting tracheotomy, mechanical ventilation, and continuous renal replacement therapy (χ(2)=12.373, 17.201, 43.763, P<0.01), larger first excision area (Z=-2.191, P<0.05), and higher mortality on post injury days 30, 60, and 90 (χ(2)=7.483, 37.259, 45.533, P<0.01). There were no statistically significant differences in sex, open decompression, admission time, 24-hour fluid volume after admission, 48-hour fluid volume after admission, the first 24-hour urine volume, the second 24 hour urine volume, the first excision time, and inhalation injury (χ(2)=0.529, 3.318, Z=-1.746, -0.016, -1.199, -1.824, -0.625, -1.747, P>0.05). The rates of deep vein catheterization of patients in the two groups were both 100%. (2) There were twenty possible prediction variables for preliminary establishment of model according to the difference results of single factor analysis and clinical significance of variables. (3) The logistic regression prediction model had three variables: APACHE Ⅱ score [odds ratio (OR)=1.36, 95% confidence interval (CI)=1.20-1.53, P<0.001], sepsis (OR=2.63, 95% CI=0.90-7.66, P>0.05), and the first 24-hour urine volume (OR=0.71, 95% CI=0.50-1.01, P>0.05). The AUC of the logistic regression prediction model was 0.875 (95% CI=0.821-0.930), with the specificity and sensitivity of optimal threshold value 84.4% and 77.7%, respectively. (4) XGBoost machine learning model had seven main predictive variables: APACHE Ⅱ score, full-thickness burn area, 24-hour fluid volume after admission, sepsis, the first 24-hour urine volume, SOFA score, and 48-hour fluid volume after admission. The AUC of machine learning model was 0.920 (95% CI=0.879-0.962), higher than that of logistic regression model (P<0.001), with the specificity and sensitivity of optimal threshold value 89.7% and 82.0%, respectively. Conclusions: Sepsis and fluid resuscitation are two important predictive variables that can be intervened for AKI in severely burned patients. Machine learning method has a better performance and can provide more accurate prediction for individuals than logistic regression prediction model, and therefore has good clinical application prospect.","Acute kidney injury; Artificial intelligence; Burns; Fluid resuscitation; Prediction model; Sepsis","Acute Kidney Injury; Burns; Explosions; Fluid Therapy; Hospitalization; Humans; Logistic Models; Machine Learning; Organ Dysfunction Scores; ROC Curve; Sensitivity and Specificity; Sepsis; acute kidney failure; burn; complication; explosion; fluid therapy; hospitalization; human; machine learning; organ dysfunction score; pathology; receiver operating characteristic; sensitivity and specificity; sepsis; statistical model","","10092587","","","29961290","Article","Scopus","2-s2.0-85059799187"
"Suzuki S.; Shouno H.","Suzuki, Satoshi (57033228400); Shouno, Hayaru (6603238291)","57033228400; 6603238291","Support Vector Machine Histogram: New Analysis and Architecture Design Method of Deep Convolutional Neural Network","2018","Neural Processing Letters","1","10.1007/s11063-017-9652-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021818282&doi=10.1007%2fs11063-017-9652-0&partnerID=40&md5=f9330a5c66d4a2d78580b41bc8a03adb","University of Electro-Communications, Chofugaoka 1-5-1, Chofu, Japan","Suzuki S., University of Electro-Communications, Chofugaoka 1-5-1, Chofu, Japan; Shouno H., University of Electro-Communications, Chofugaoka 1-5-1, Chofu, Japan","Deep convolutional neural network (DCNN) is a kind of hierarchical neural network models and attracts attention in recent years since it has shown high classification performance. DCNN can acquire the feature representation which is a parameter indicating the feature of the input by learning. However, its internal analysis and the design of the network architecture have many unclear points and it cannot be said that it has been sufficiently elucidated. We propose the novel DCNN analysis method “Support vector machine (SVM) histogram” as a prescription to deal with these problems. This is a method that examines the spatial distribution of DCNN extracted feature representation by using the decision boundary of linear SVM. We show that we can interpret DCNN hierarchical processing using this method. In addition, by using the result of SVM histogram, DCNN architecture design becomes possible. In this study, we designed the architecture of the application to large scale natural image dataset. In the result, we succeeded in showing higher accuracy than the original DCNN. © 2017, Springer Science+Business Media, LLC.","Architecture design; CIFAR-10; Deep convolutional neural network; ImageNet; Support vector machine","Convolution; Graphic methods; Network architecture; Neural networks; Support vector machines; Architecture designs; CIFAR-10; Classification performance; Deep convolutional neural networks; Feature representation; Hierarchical neural networks; Hierarchical processing; ImageNet; Deep neural networks","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-85021818282"
"Quan T.M.; Nguyen-Duc T.; Jeong W.-K.","Quan, Tran Minh (56412510500); Nguyen-Duc, Thanh (58544752000); Jeong, Won-Ki (8268624200)","56412510500; 58544752000; 8268624200","Compressed Sensing MRI Reconstruction Using a Generative Adversarial Network With a Cyclic Loss","2018","IEEE Transactions on Medical Imaging","430","10.1109/TMI.2018.2820120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044764845&doi=10.1109%2fTMI.2018.2820120&partnerID=40&md5=b646f1d760d44ddf77523134d68eadf4","Ulsan National Institute of Science and Technology, Ulsan, 44919, South Korea","Quan T.M., Ulsan National Institute of Science and Technology, Ulsan, 44919, South Korea; Nguyen-Duc T., Ulsan National Institute of Science and Technology, Ulsan, 44919, South Korea; Jeong W.-K., Ulsan National Institute of Science and Technology, Ulsan, 44919, South Korea","Compressed sensing magnetic resonance imaging (CS-MRI) has provided theoretical foundations upon which the time-consuming MRI acquisition process can be accelerated. However, it primarily relies on iterative numerical solvers, which still hinders their adaptation in time-critical applications. In addition, recent advances in deep neural networks have shown their potential in computer vision and image processing, but their adaptation to MRI reconstruction is still in an early stage. In this paper, we propose a novel deep learning-based generative adversarial model, RefineGAN, for fast and accurate CS-MRI reconstruction. The proposed model is a variant of fully-residual convolutional autoencoder and generative adversarial networks (GANs), specifically designed for CS-MRI formulation; it employs deeper generator and discriminator networks with cyclic data consistency loss for faithful interpolation in the given under-sampled k-space data. In addition, our solution leverages a chained network to further enhance the reconstruction quality. RefineGAN is fast and accurate - the reconstruction process is extremely rapid, as low as tens of milliseconds for reconstruction of a 256×256 image, because it is one-way deployment on a feed-forward network, and the image quality is superior even for extremely low sampling rate (as low as 10%) due to the data-driven nature of the method. We demonstrate that RefineGAN outperforms the state-of-the-art CS-MRI methods by a large margin in terms of both running time and image quality via evaluation using several open-source MRI databases. © 2018 IEEE.","Compressed sensing; CycleGAN; DiscoGAN; GAN; MRI","Algorithms; Brain; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks (Computer); Compressed sensing; Database systems; Deep neural networks; Gallium nitride; III-V semiconductors; Image quality; Image reconstruction; Iterative methods; Learning systems; Magnetic levitation vehicles; Personnel training; Adversarial networks; CycleGAN; DiscoGAN; Feed-forward network; Reconstruction process; Reconstruction quality; Theoretical foundations; Time-critical applications; algorithm; Article; comparative study; compressed sensing magnetic resonance imaging; controlled study; deep learning; dictionary learning; image processing; image quality; image reconstruction; machine learning; nuclear magnetic resonance imaging; probability; signal noise ratio; time; artificial neural network; brain; diagnostic imaging; human; nuclear magnetic resonance imaging; procedures; Magnetic resonance imaging","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870376","Article","Scopus","2-s2.0-85044764845"
"Smith J.S.; Nebgen B.; Lubbers N.; Isayev O.; Roitberg A.E.","Smith, Justin S. (57199013497); Nebgen, Ben (25228953400); Lubbers, Nicholas (55617392500); Isayev, Olexandr (23060975100); Roitberg, Adrian E. (6701721729)","57199013497; 25228953400; 55617392500; 23060975100; 6701721729","Less is more: Sampling chemical space with active learning","2018","Journal of Chemical Physics","427","10.1063/1.5023802","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047462401&doi=10.1063%2f1.5023802&partnerID=40&md5=6ead685e514a356392645c3a8a786f30","Department of Chemistry, University of Florida, Gainesville, 32611, FL, United States; Los Alamos National Laboratory, Los Alamos, 87545, NM, United States; UNC Eshelman School of Pharmacy, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States","Smith J.S., Department of Chemistry, University of Florida, Gainesville, 32611, FL, United States; Nebgen B., Los Alamos National Laboratory, Los Alamos, 87545, NM, United States; Lubbers N., Los Alamos National Laboratory, Los Alamos, 87545, NM, United States; Isayev O., UNC Eshelman School of Pharmacy, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Roitberg A.E., Department of Chemistry, University of Florida, Gainesville, 32611, FL, United States","The development of accurate and transferable machine learning (ML) potentials for predicting molecular energetics is a challenging task. The process of data generation to train such ML potentials is a task neither well understood nor researched in detail. In this work, we present a fully automated approach for the generation of datasets with the intent of training universal ML potentials. It is based on the concept of active learning (AL) via Query by Committee (QBC), which uses the disagreement between an ensemble of ML potentials to infer the reliability of the ensemble's prediction. QBC allows the presented AL algorithm to automatically sample regions of chemical space where the ML potential fails to accurately predict the potential energy. AL improves the overall fitness of ANAKIN-ME (ANI) deep learning potentials in rigorous test cases by mitigating human biases in deciding what new training data to use. AL also reduces the training set size to a fraction of the data required when using naive random sampling techniques. To provide validation of our AL approach, we develop the COmprehensive Machine-learning Potential (COMP6) benchmark (publicly available on GitHub) which contains a diverse set of organic molecules. Active learning-based ANI potentials outperform the original random sampled ANI-1 potential with only 10% of the data, while the final active learning-based model vastly outperforms ANI-1 on the COMP6 benchmark after training to only 25% of the data. Finally, we show that our proposed AL technique develops a universal ANI potential (ANI-1x) that provides accurate energy and force predictions on the entire COMP6 benchmark. This universal ML potential achieves a level of accuracy on par with the best ML potentials for single molecules or materials, while remaining applicable to the general class of organic molecules composed of the elements CHNO. © 2018 Author(s).","","Artificial intelligence; Forecasting; Molecules; Potential energy; Active Learning; Data generation; Force predictions; Fully automated; Learning potential; Organic molecules; Query by committees; Single molecule; article; deep learning; human; human experiment; learning algorithm; prediction; reliability; Deep learning","American Institute of Physics Inc.","00219606","","JCPSA","29960353","Article","Scopus","2-s2.0-85047462401"
"Cui P.; Zhong T.; Wang Z.; Wang T.; Zhao H.; Liu C.; Lu H.","Cui, Peng (55925440000); Zhong, Tingyan (57200110869); Wang, Zhuo (55719636800); Wang, Tao (55369710300); Zhao, Hongyu (7404779143); Liu, Chenglin (55762420200); Lu, Hui (7404843285)","55925440000; 57200110869; 55719636800; 55369710300; 7404779143; 55762420200; 7404843285","Identification of human circadian genes based on time course gene expression profiles by using a deep learning method","2018","Biochimica et Biophysica Acta - Molecular Basis of Disease","12","10.1016/j.bbadis.2017.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039715738&doi=10.1016%2fj.bbadis.2017.12.004&partnerID=40&md5=9c23a5062a8a578fcbad449672157772","School of Life Science and Biotechnology, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China; SJTU-Yale Joint Center for Biostatistics, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China; Department of Biostatistics, Yale University, New Heaven, United States","Cui P., School of Life Science and Biotechnology, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China, SJTU-Yale Joint Center for Biostatistics, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China; Zhong T., School of Life Science and Biotechnology, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China, SJTU-Yale Joint Center for Biostatistics, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China; Wang Z., School of Life Science and Biotechnology, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China; Wang T., School of Life Science and Biotechnology, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China, SJTU-Yale Joint Center for Biostatistics, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China; Zhao H., SJTU-Yale Joint Center for Biostatistics, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China, Department of Biostatistics, Yale University, New Heaven, United States; Liu C., School of Life Science and Biotechnology, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China; Lu H., School of Life Science and Biotechnology, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China, SJTU-Yale Joint Center for Biostatistics, Shanghai Jiao Tong University, 800 Dong Chuan Road, Shanghai, 200240, China","Circadian genes express periodically in an approximate 24-h period and the identification and study of these genes can provide deep understanding of the circadian control which plays significant roles in human health. Although many circadian gene identification algorithms have been developed, large numbers of false positives and low coverage are still major problems in this field. In this study we constructed a novel computational framework for circadian gene identification using deep neural networks (DNN) – a deep learning algorithm which can represent the raw form of data patterns without imposing assumptions on the expression distribution. Firstly, we transformed time-course gene expression data into categorical-state data to denote the changing trend of gene expression. Two distinct expression patterns emerged after clustering of the state data for circadian genes from our manually created learning dataset. DNN was then applied to discriminate the aperiodic genes and the two subtypes of periodic genes. In order to assess the performance of DNN, four commonly used machine learning methods including k-nearest neighbors, logistic regression, naïve Bayes, and support vector machines were used for comparison. The results show that the DNN model achieves the best balanced precision and recall. Next, we conducted large scale circadian gene detection using the trained DNN model for the remaining transcription profiles. Comparing with JTK_CYCLE and a study performed by Möller-Levet et al. (doi: https://doi.org/10.1073/pnas.1217154110), we identified 1132 novel periodic genes. Through the functional analysis of these novel circadian genes, we found that the GTPase superfamily exhibits distinct circadian expression patterns and may provide a molecular switch of circadian control of the functioning of the immune system in human blood. Our study provides novel insights into both the circadian gene identification field and the study of complex circadian-driven biological control. This article is part of a Special Issue entitled: Accelerating Precision Medicine through Genetic and Genomic Big Data Analysis edited by Yudong Cai & Tao Huang. © 2017","Circadian genes; Classification; Deep learning; Deep neural network; Functional analysis; GTPase","Circadian Rhythm; Databases, Genetic; Gene Expression Profiling; Humans; Machine Learning; Transcriptome; guanosine triphosphatase; transcriptome; Article; artificial neural network; Bayes theorem; circadian rhythm; conceptual framework; gene expression profiling; gene identification; human; immune system; k nearest neighbor; learning algorithm; logistic regression analysis; machine learning; priority journal; protein expression; protein family; support vector machine; circadian rhythm; gene expression profiling; genetic database; machine learning; physiology; procedures","Elsevier B.V.","09254439","","BBADE","29241666","Article","Scopus","2-s2.0-85039715738"
"Pal A.; Garain U.; Chandra A.; Chatterjee R.; Senapati S.","Pal, Anabik (57190273402); Garain, Utpal (6602234041); Chandra, Aditi (56482725200); Chatterjee, Raghunath (7101918663); Senapati, Swapan (56482976600)","57190273402; 6602234041; 56482725200; 7101918663; 56482976600","Psoriasis skin biopsy image segmentation using Deep Convolutional Neural Network","2018","Computer Methods and Programs in Biomedicine","47","10.1016/j.cmpb.2018.01.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043367318&doi=10.1016%2fj.cmpb.2018.01.027&partnerID=40&md5=9292e1b1fd93f7269277470b3eff96bb","CVPR Unit, Indian Statistical Institute, Kolkata, 700108, India; Human Genetics Unit, Indian Statistical Unit, Kolkata, 700108, West Bengal, India; Consultant Dermatologist, Uttarpara, Hooghly, 712258, West Bengal, India","Pal A., CVPR Unit, Indian Statistical Institute, Kolkata, 700108, India; Garain U., CVPR Unit, Indian Statistical Institute, Kolkata, 700108, India; Chandra A., Human Genetics Unit, Indian Statistical Unit, Kolkata, 700108, West Bengal, India; Chatterjee R., Human Genetics Unit, Indian Statistical Unit, Kolkata, 700108, West Bengal, India; Senapati S., Consultant Dermatologist, Uttarpara, Hooghly, 712258, West Bengal, India","Background and objective: Development of machine assisted tools for automatic analysis of psoriasis skin biopsy image plays an important role in clinical assistance. Development of automatic approach for accurate segmentation of psoriasis skin biopsy image is the initial prerequisite for developing such system. However, the complex cellular structure, presence of imaging artifacts, uneven staining variation make the task challenging. This paper presents a pioneering attempt for automatic segmentation of psoriasis skin biopsy images. Methods: Several deep neural architectures are tried for segmenting psoriasis skin biopsy images. Deep models are used for classifying the super-pixels generated by Simple Linear Iterative Clustering (SLIC) and the segmentation performance of these architectures is compared with the traditional hand-crafted feature based classifiers built on popularly used classifiers like K-Nearest Neighbor (KNN), Support Vector Machine (SVM) and Random Forest (RF). A U-shaped Fully Convolutional Neural Network (FCN) is also used in an end to end learning fashion where input is the original color image and the output is the segmentation class map for the skin layers. Results: An annotated real psoriasis skin biopsy image data set of ninety (90) images is developed and used for this research. The segmentation performance is evaluated with two metrics namely, Jaccard's Coefficient (JC) and the Ratio of Correct Pixel Classification (RCPC) accuracy. The experimental results show that the CNN based approaches outperform the traditional hand-crafted feature based classification approaches. Conclusions: The present research shows that practical system can be developed for machine assisted analysis of psoriasis disease. © 2018 Elsevier B.V.","Data set and Evaluation; Deep Convolutional Neural Network (DCNN); Dermis-Epidermis; Fully Convolutional Neural Network (FCN); Psoriasis Biopsy image; Simple Linear Iterative Clustering (SLIC)","Algorithms; Biopsy; Cluster Analysis; Color; Databases, Factual; Dermis; Epidermis; Humans; Image Processing, Computer-Assisted; Models, Statistical; Neural Networks (Computer); Psoriasis; Reproducibility of Results; Skin; Support Vector Machine; Biopsy; Classification (of information); Convolution; Decision trees; Deep neural networks; Dermatology; Iterative methods; Nearest neighbor search; Network architecture; Neural networks; Pixels; Support vector machines; Biopsy images; Convolutional neural network; Data set; Deep convolutional neural networks; Dermis-Epidermis; Simple Linear Iterative Clustering; accuracy; Article; artifact; artificial neural network; automation; classification; human; human tissue; image segmentation; k nearest neighbor; psoriasis; random forest; skin biopsy; support vector machine; algorithm; biopsy; cluster analysis; color; comparative study; dermis; diagnostic imaging; epidermis; factual database; image processing; psoriasis; reproducibility; skin; statistical model; Image segmentation","Elsevier Ireland Ltd","01692607","","CMPBE","29650319","Article","Scopus","2-s2.0-85043367318"
"Zhang J.; Liu W.; Hou Y.; Qiu C.; Yang S.; Li C.; Nie L.","Zhang, Jianqiang (57949878800); Liu, Weijuan (55867028700); Hou, Ying (57199881700); Qiu, Changgui (55704515800); Yang, Shuangyan (57199510157); Li, Changyu (57199501513); Nie, Linru (17435044600)","57949878800; 55867028700; 57199881700; 55704515800; 57199510157; 57199501513; 17435044600","Sparse Representation Classification of Tobacco Leaves Using Near-Infrared Spectroscopy and a Deep Learning Algorithm","2018","Analytical Letters","15","10.1080/00032719.2017.1365882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038128234&doi=10.1080%2f00032719.2017.1365882&partnerID=40&md5=730b38248f3ba81e031e82668b846da2","Yunnan Reascend Tobacco Technology (Group) Company Limited, Kunming, China; Faculty of Science, Kunming University of Science and Technology, Kunming, China; Yunnan Comtestor Company, Kunming, China","Zhang J., Yunnan Reascend Tobacco Technology (Group) Company Limited, Kunming, China, Faculty of Science, Kunming University of Science and Technology, Kunming, China; Liu W., Yunnan Reascend Tobacco Technology (Group) Company Limited, Kunming, China; Hou Y., Yunnan Comtestor Company, Kunming, China; Qiu C., Yunnan Comtestor Company, Kunming, China; Yang S., Yunnan Comtestor Company, Kunming, China; Li C., Yunnan Reascend Tobacco Technology (Group) Company Limited, Kunming, China; Nie L., Faculty of Science, Kunming University of Science and Technology, Kunming, China","A spare representation classification method for tobacco leaves based on near-infrared spectroscopy and deep learning algorithm is reported in this paper. All training samples were used to make up a data dictionary of the sparse representation and the test samples were represented by the sparsest linear combinations of the dictionary by sparse coding. The regression residual of the test sample to each class was computed and finally assigned to the class with the minimum residual. The effectiveness of spare representation classification method was compared with K-nearest neighbor and particle swarm optimization–support vector machine algorithms. The results show that the classification accuracy of the proposed method is higher and it is more efficient. The results suggest that near-infrared spectroscopy with spare representation classification algorithm may be an alternative method to traditional methods for discriminating classes of tobacco leaves. © 2017 Taylor & Francis.","Deep learning algorithm; near-infrared spectroscopy; sparse representation classification","","Taylor and Francis Inc.","00032719","","ANALB","","Article","Scopus","2-s2.0-85038128234"
"Golas S.B.; Shibahara T.; Agboola S.; Otaki H.; Sato J.; Nakae T.; Hisamitsu T.; Kojima G.; Felsted J.; Kakarmath S.; Kvedar J.; Jethwani K.","Golas, Sara Bersche (57194052738); Shibahara, Takuma (57202605409); Agboola, Stephen (55470775400); Otaki, Hiroko (57202601320); Sato, Jumpei (57210792066); Nakae, Tatsuya (57202601634); Hisamitsu, Toru (57225437379); Kojima, Go (57202601181); Felsted, Jennifer (57734861700); Kakarmath, Sujay (56826027700); Kvedar, Joseph (7003789953); Jethwani, Kamal (36457624000)","57194052738; 57202605409; 55470775400; 57202601320; 57210792066; 57202601634; 57225437379; 57202601181; 57734861700; 56826027700; 7003789953; 36457624000","A machine learning model to predict the risk of 30-day readmissions in patients with heart failure: A retrospective analysis of electronic medical records data","2018","BMC Medical Informatics and Decision Making","154","10.1186/s12911-018-0620-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048861820&doi=10.1186%2fs12911-018-0620-z&partnerID=40&md5=175217dae7d4248d9bfd86b12e4d787c","Partners Connected Health Innovation, Partners HealthCare, 25 New Chardon St., Boston, 02114, MA, United States; Massachusetts General Hospital, Boston, MA, United States; Harvard Medical School, Boston, MA, United States; Research and Development Group, Hitachi, Ltd, Tokyo, Japan","Golas S.B., Partners Connected Health Innovation, Partners HealthCare, 25 New Chardon St., Boston, 02114, MA, United States; Shibahara T., Research and Development Group, Hitachi, Ltd, Tokyo, Japan; Agboola S., Partners Connected Health Innovation, Partners HealthCare, 25 New Chardon St., Boston, 02114, MA, United States, Massachusetts General Hospital, Boston, MA, United States, Harvard Medical School, Boston, MA, United States; Otaki H., Research and Development Group, Hitachi, Ltd, Tokyo, Japan; Sato J., Research and Development Group, Hitachi, Ltd, Tokyo, Japan; Nakae T., Research and Development Group, Hitachi, Ltd, Tokyo, Japan; Hisamitsu T., Research and Development Group, Hitachi, Ltd, Tokyo, Japan; Kojima G., Research and Development Group, Hitachi, Ltd, Tokyo, Japan; Felsted J., Partners Connected Health Innovation, Partners HealthCare, 25 New Chardon St., Boston, 02114, MA, United States; Kakarmath S., Partners Connected Health Innovation, Partners HealthCare, 25 New Chardon St., Boston, 02114, MA, United States, Massachusetts General Hospital, Boston, MA, United States, Harvard Medical School, Boston, MA, United States; Kvedar J., Partners Connected Health Innovation, Partners HealthCare, 25 New Chardon St., Boston, 02114, MA, United States, Massachusetts General Hospital, Boston, MA, United States, Harvard Medical School, Boston, MA, United States; Jethwani K., Partners Connected Health Innovation, Partners HealthCare, 25 New Chardon St., Boston, 02114, MA, United States, Massachusetts General Hospital, Boston, MA, United States, Harvard Medical School, Boston, MA, United States","Background: Heart failure is one of the leading causes of hospitalization in the United States. Advances in big data solutions allow for storage, management, and mining of large volumes of structured and semi-structured data, such as complex healthcare data. Applying these advances to complex healthcare data has led to the development of risk prediction models to help identify patients who would benefit most from disease management programs in an effort to reduce readmissions and healthcare cost, but the results of these efforts have been varied. The primary aim of this study was to develop a 30-day readmission risk prediction model for heart failure patients discharged from a hospital admission. Methods: We used longitudinal electronic medical record data of heart failure patients admitted within a large healthcare system. Feature vectors included structured demographic, utilization, and clinical data, as well as selected extracts of un-structured data from clinician-authored notes. The risk prediction model was developed using deep unified networks (DUNs), a new mesh-like network structure of deep learning designed to avoid over-fitting. The model was validated with 10-fold cross-validation and results compared to models based on logistic regression, gradient boosting, and maxout networks. Overall model performance was assessed using concordance statistic. We also selected a discrimination threshold based on maximum projected cost saving to the Partners Healthcare system. Results: Data from 11,510 patients with 27,334 admissions and 6369 30-day readmissions were used to train the model. After data processing, the final model included 3512 variables. The DUNs model had the best performance after 10-fold cross-validation. AUCs for prediction models were 0.664 ± 0.015, 0.650 ± 0.011, 0.695 ± 0.016 and 0.705 ± 0.015 for logistic regression, gradient boosting, maxout networks, and DUNs respectively. The DUNs model had an accuracy of 76.4% at the classification threshold that corresponded with maximum cost saving to the hospital. Conclusions: Deep learning techniques performed better than other traditional techniques in developing this EMR-based prediction model for 30-day readmissions in heart failure patients. Such models can be used to identify heart failure patients with impending hospitalization, enabling care teams to target interventions at their most high-risk patients and improving overall clinical outcomes. © 2018 The Author(s).","Deep learning; Deep unified networks; Heart failure; Machine learning; Readmission reduction; Value-based care","Aged; Aged, 80 and over; Deep Learning; Electronic Health Records; Female; Heart Failure; Humans; Male; Middle Aged; Models, Theoretical; Patient Readmission; Prognosis; Retrospective Studies; aged; electronic health record; female; heart failure; hospital readmission; human; male; middle aged; prognosis; retrospective study; statistics and numerical data; theoretical model; very elderly","BioMed Central Ltd","14726947","","","29929496","Article","Scopus","2-s2.0-85048861820"
"Aicha A.N.; Englebienne G.; van Schooten K.S.; Pijnappels M.; Kröse B.","Aicha, Ahmed Nait (55546819100); Englebienne, Gwenn (25824791100); van Schooten, Kimberley S. (36728411800); Pijnappels, Mirjam (6603091167); Kröse, Ben (7004886067)","55546819100; 25824791100; 36728411800; 6603091167; 7004886067","Deep learning to predict falls in older adults based on daily-life trunk accelerometry","2018","Sensors (Switzerland)","123","10.3390/s18051654","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053882863&doi=10.3390%2fs18051654&partnerID=40&md5=03ad6a0f7dd73247d92936337518370c","Department of Computer Science, Amsterdam University of Applied Sciences, Amsterdam, 1091 GM, Netherlands; Human Media Interaction, University of Twente, Enschede, 7522 NH, Netherlands; Neuroscience Research Australia, University of New South Wales, Sydney, 2031, Australia; Department of Human Movement Sciences, Vrije Universiteit Amsterdam, Amsterdam, 1081 HV, Netherlands; Informatics Institute, University of Amsterdam, Amsterdam, 1098 XH, Netherlands","Aicha A.N., Department of Computer Science, Amsterdam University of Applied Sciences, Amsterdam, 1091 GM, Netherlands; Englebienne G., Human Media Interaction, University of Twente, Enschede, 7522 NH, Netherlands; van Schooten K.S., Neuroscience Research Australia, University of New South Wales, Sydney, 2031, Australia; Pijnappels M., Department of Human Movement Sciences, Vrije Universiteit Amsterdam, Amsterdam, 1081 HV, Netherlands; Kröse B., Department of Computer Science, Amsterdam University of Applied Sciences, Amsterdam, 1091 GM, Netherlands, Informatics Institute, University of Amsterdam, Amsterdam, 1098 XH, Netherlands","Early detection of high fall risk is an essential component of fall prevention in older adults. Wearable sensors can provide valuable insight into daily-life activities; biomechanical features extracted from such inertial data have been shown to be of added value for the assessment of fall risk. Body-worn sensors such as accelerometers can provide valuable insight into fall risk. Currently, biomechanical features derived from accelerometer data are used for the assessment of fall risk. Here, we studied whether deep learning methods from machine learning are suited to automatically derive features from raw accelerometer data that assess fall risk. We used an existing dataset of 296 older adults. We compared the performance of three deep learning model architectures (convolutional neural network (CNN), long short-term memory (LSTM) and a combination of these two (ConvLSTM)) to each other and to a baseline model with biomechanical features on the same dataset. The results show that the deep learning models in a single-task learning mode are strong in recognition of identity of the subject, but that these models only slightly outperform the baseline method on fall risk assessment. When using multi-task learning, with gender and age as auxiliary tasks, deep learning models perform better. We also found that preprocessing of the data resulted in the best performance (AUC = 0.75). We conclude that deep learning models, and in particular multi-task learning, effectively assess fall risk on the basis of wearable sensor data. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Accelerometry; Accidental falls; Convolutional neural network; Long short-term memory; Machine learning; Neural networks; Older adults","Accelerometry; Accidental Falls; Activities of Daily Living; Aged; Aged, 80 and over; Female; Humans; Machine Learning; Male; Monitoring, Ambulatory; Neural Networks (Computer); Accelerometers; Accident prevention; Biomechanics; Brain; Convolution; Learning algorithms; Learning systems; Long short-term memory; Neural networks; Risk assessment; Wearable sensors; Accelerometer data; Accelerometry; Accidental falls; Convolutional neural network; Convolutional Neural Networks (CNN); Daily life activities; Older adults; Single task learning; accelerometry; aged; ambulatory monitoring; artificial neural network; daily life activity; falling; female; human; machine learning; male; prevention and control; procedures; very elderly; Deep learning","MDPI AG","14248220","","","29786659","Article","Scopus","2-s2.0-85053882863"
"Faust K.; Xie Q.; Han D.; Goyle K.; Volynskaya Z.; Djuric U.; Diamandis P.","Faust, Kevin (57202080185); Xie, Quin (57202077973); Han, Dominick (57202073981); Goyle, Kartikay (57202076934); Volynskaya, Zoya (58363672800); Djuric, Ugljesa (12761194300); Diamandis, Phedias (16232762600)","57202080185; 57202077973; 57202073981; 57202076934; 58363672800; 12761194300; 16232762600","Visualizing histopathologic deep learning classification and anomaly detection using nonlinear feature space dimensionality reduction","2018","BMC Bioinformatics","44","10.1186/s12859-018-2184-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047079043&doi=10.1186%2fs12859-018-2184-4&partnerID=40&md5=db79b0277bf2f96fb4570d5253f742ca","University of Toronto, Department of Computer Science, 40 St. George Street, Toronto, M5S 2E4, ON, Canada; University of Toronto, Department of Laboratory Medicine and Pathobiology, Toronto, M5S 1A8, ON, Canada; University of Toronto, The Edward S. Rogers Sr. Department of Electrical and Computer Engineering, Toronto, ON, Canada; University Health Network, Laboratory Medicine Program, Department of Pathology, 200 Elizabeth Street, Toronto, M5G 2C4, ON, Canada; Princess Margaret Cancer Centre, MacFeeters Hamilton Centre for Neuro-Oncology Research, 101 College Street, Toronto, M5G 1L7, ON, Canada","Faust K., University of Toronto, Department of Computer Science, 40 St. George Street, Toronto, M5S 2E4, ON, Canada; Xie Q., University of Toronto, Department of Laboratory Medicine and Pathobiology, Toronto, M5S 1A8, ON, Canada; Han D., University of Toronto, Department of Computer Science, 40 St. George Street, Toronto, M5S 2E4, ON, Canada; Goyle K., University of Toronto, The Edward S. Rogers Sr. Department of Electrical and Computer Engineering, Toronto, ON, Canada; Volynskaya Z., University of Toronto, Department of Laboratory Medicine and Pathobiology, Toronto, M5S 1A8, ON, Canada, University Health Network, Laboratory Medicine Program, Department of Pathology, 200 Elizabeth Street, Toronto, M5G 2C4, ON, Canada; Djuric U., University Health Network, Laboratory Medicine Program, Department of Pathology, 200 Elizabeth Street, Toronto, M5G 2C4, ON, Canada, Princess Margaret Cancer Centre, MacFeeters Hamilton Centre for Neuro-Oncology Research, 101 College Street, Toronto, M5G 1L7, ON, Canada; Diamandis P., University of Toronto, Department of Laboratory Medicine and Pathobiology, Toronto, M5S 1A8, ON, Canada, University Health Network, Laboratory Medicine Program, Department of Pathology, 200 Elizabeth Street, Toronto, M5G 2C4, ON, Canada, Princess Margaret Cancer Centre, MacFeeters Hamilton Centre for Neuro-Oncology Research, 101 College Street, Toronto, M5G 1L7, ON, Canada","Background: There is growing interest in utilizing artificial intelligence, and particularly deep learning, for computer vision in histopathology. While accumulating studies highlight expert-level performance of convolutional neural networks (CNNs) on focused classification tasks, most studies rely on probability distribution scores with empirically defined cutoff values based on post-hoc analysis. More generalizable tools that allow humans to visualize histology-based deep learning inferences and decision making are scarce. Results: Here, we leverage t-distributed Stochastic Neighbor Embedding (t-SNE) to reduce dimensionality and depict how CNNs organize histomorphologic information. Unique to our workflow, we develop a quantitative and transparent approach to visualizing classification decisions prior to softmax compression. By discretizing the relationships between classes on the t-SNE plot, we show we can super-impose randomly sampled regions of test images and use their distribution to render statistically-driven classifications. Therefore, in addition to providing intuitive outputs for human review, this visual approach can carry out automated and objective multi-class classifications similar to more traditional and less-transparent categorical probability distribution scores. Importantly, this novel classification approach is driven by a priori statistically defined cutoffs. It therefore serves as a generalizable classification and anomaly detection tool less reliant on post-hoc tuning. Conclusion: Routine incorporation of this convenient approach for quantitative visualization and error reduction in histopathology aims to accelerate early adoption of CNNs into generalized real-world applications where unanticipated and previously untrained classes are often encountered. © 2018 The Author(s).","Artificial intelligence; Cancer; Convolutional neural networks; Deep learning; Diagnostics; Digital pathology; Glioblastoma; Machine learning; Neuropathology; T-SNE","Artificial Intelligence; Deep Learning; Humans; Machine Learning; Neural Networks (Computer); Artificial intelligence; Classification (of information); Convolution; Decision making; Learning systems; Neural networks; Plasma diagnostics; Probability distributions; Stochastic systems; Cancer; Convolutional neural network; Digital pathologies; Glioblastomas; Neuropathology; T-SNE; artificial intelligence; artificial neural network; classification; human; machine learning; standards; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","29769044","Article","Scopus","2-s2.0-85047079043"
"Shen C.; Gonzalez Y.; Chen L.; Jiang S.B.; Jia X.","Shen, Chenyang (57194522368); Gonzalez, Yesenia (57200815641); Chen, Liyuan (57200760285); Jiang, Steve B. (7404453173); Jia, Xun (15132074800)","57194522368; 57200815641; 57200760285; 7404453173; 15132074800","Intelligent Parameter Tuning in Optimization-Based Iterative CT Reconstruction via Deep Reinforcement Learning","2018","IEEE Transactions on Medical Imaging","73","10.1109/TMI.2018.2823679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045201602&doi=10.1109%2fTMI.2018.2823679&partnerID=40&md5=9858b7ef48465be7f7714d8d590343e8","Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, 75390, TX, United States","Shen C., Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, 75390, TX, United States; Gonzalez Y., Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, 75390, TX, United States; Chen L., Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, 75390, TX, United States; Jiang S.B., Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, 75390, TX, United States; Jia X., Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, 75390, TX, United States","A number of image-processing problems can be formulated as optimization problems. The objective function typically contains several terms specifically designed for different purposes. Parameters in front of these terms are used to control the relative importance among them. It is of critical importance to adjust these parameters, as quality of the solution depends on their values. Tuning parameters are a relatively straight forward task for a human, as one can intuitively determine the direction of parameter adjustment based on the solution quality. Yet manual parameter tuning is not only tedious in many cases, but also becomes impractical when a number of parameters exist in a problem. Aiming at solving this problem, this paper proposes an approach that employs deep reinforcement learning to train a system that can automatically adjust parameters in a human-like manner. We demonstrate our idea in an example problem of optimization-based iterative computed tomography (CT) reconstruction with a pixel-wise total-variation regularization term. We set up a parameter-tuning policy network (PTPN), which maps a CT image patch to an output that specifies the direction and amplitude by which the parameter at the patch center is adjusted. We train the PTPN via an end-to-end reinforcement learning procedure. We demonstrate that under the guidance of the trained PTPN, reconstructed CT images attain quality similar or better than those reconstructed with manually tuned parameters. © 2018 IEEE.","computed tomography; Image reconstruction - iterative methods; inverse methods; machine learning; x-ray imaging","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Phantoms, Imaging; Tomography, X-Ray Computed; Deep learning; Image quality; Image reconstruction; Inverse problems; Iterative methods; Learning systems; Optimization; Problem solving; Reinforcement learning; Tuning; Image processing problems; Inverse methods; Objective functions; Optimization problems; Parameter adjustments; Radio frequencies; Total variation regularization; Xray imaging; article; computer assisted tomography; human; image quality; image reconstruction; machine learning; radiofrequency; radiography; reinforcement; algorithm; image processing; imaging phantom; procedures; x-ray computed tomography; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870371","Article","Scopus","2-s2.0-85045201602"
"Parreco J.P.; Hidalgo A.E.; Badilla A.D.; Ilyas O.; Rattan R.","Parreco, Joshua P. (57191663362); Hidalgo, Antonio E. (57201451484); Badilla, Alejandro D. (57201449878); Ilyas, Omar (57201451594); Rattan, Rishi (57159337600)","57191663362; 57201451484; 57201449878; 57201451594; 57159337600","Predicting central line-associated bloodstream infections and mortality using supervised machine learning","2018","Journal of Critical Care","40","10.1016/j.jcrc.2018.02.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044847275&doi=10.1016%2fj.jcrc.2018.02.010&partnerID=40&md5=4a30a6d576002cc130294578a6f46881","Department of Surgery, University of Miami Miller School of Medicine, United States; Division of Trauma Surgery and Surgical Critical Care, Department of Surgery, University of Miami Miller School of Medicine, United States; Department of Internal Medicine, University of Miami Miller School of Medicine, United States","Parreco J.P., Department of Surgery, University of Miami Miller School of Medicine, United States; Hidalgo A.E., Department of Surgery, University of Miami Miller School of Medicine, United States; Badilla A.D., Division of Trauma Surgery and Surgical Critical Care, Department of Surgery, University of Miami Miller School of Medicine, United States; Ilyas O., Department of Internal Medicine, University of Miami Miller School of Medicine, United States; Rattan R., Division of Trauma Surgery and Surgical Critical Care, Department of Surgery, University of Miami Miller School of Medicine, United States","Purpose: The purpose of this study was to compare machine learning techniques for predicting central line-associated bloodstream infection (CLABSI). Materials and methods: The Multiparameter Intelligent Monitoring in Intensive Care III database was queried for all ICU admissions. The variables included six different severities of illness scores calculated on the first day of ICU admission with their components and comorbidities. The outcomes of interest were in-hospital mortality, central line placement, and CLABSI. Predictive models were created for these outcomes using classifiers with different algorithms: logistic regression, gradient boosted trees, and deep learning. Results: There were 57,786 total hospital admissions and the mortality rate was 10.1%. There were 38.4% patients with a central line and the rate of CLABSI was 1.5%. The classifiers using deep learning performed with the highest AUC for mortality, 0.885 ± 0.010 (p < 0.01) and central line placement, 0.816 ± 0.006 (p < 0.01). The classifier using logistic regression for predicting CLABSI performed with an AUC of 0.722 ± 0.048 (p < 0.01). Conclusions: This study demonstrates models for identifying patients who will develop CLABSI. Early identification of these patients has implications for quality, cost, and outcome improvements. © 2018 Elsevier Inc.","Artificial intelligence; Central line-associated bloodstream infection; Hospital-acquired infections; Machine learning; Quality improvement; Severity of illness score","Bacteremia; Catheter-Related Infections; Central Venous Catheters; Databases, Factual; Female; Florida; Hospital Mortality; Humans; Intensive Care Units; Logistic Models; Male; Middle Aged; Predictive Value of Tests; Risk Assessment; Simplified Acute Physiology Score; Supervised Machine Learning; Article; catheter infection; central venous catheterization; classifier; comorbidity; controlled study; deep learning; disease severity; gradient boosted trees; hospital mortality; human; infection rate; intensive care unit; intermethod comparison; logistic regression analysis; major clinical study; measurement accuracy; measurement precision; mortality; mortality rate; predictive value; receiver operating characteristic; sensitivity and specificity; supervised machine learning; bacteremia; catheter infection; central venous catheter; evaluation study; factual database; female; Florida; male; middle aged; mortality; risk assessment; Simplified Acute Physiology Score; statistical model","W.B. Saunders","08839441","","JCCAE","29486341","Article","Scopus","2-s2.0-85044847275"
"Rachmadi M.F.; Valdés-Hernández M.D.C.; Agan M.L.F.; Di Perri C.; Komura T.","Rachmadi, Muhammad Febrian (54974181500); Valdés-Hernández, Maria del C. (57189602736); Agan, Maria Leonora Fatimah (57194784012); Di Perri, Carol (23492220700); Komura, Taku (57203194876)","54974181500; 57189602736; 57194784012; 23492220700; 57203194876","Segmentation of white matter hyperintensities using convolutional neural networks with global spatial information in routine clinical brain MRI with none or mild vascular pathology","2018","Computerized Medical Imaging and Graphics","58","10.1016/j.compmedimag.2018.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042766740&doi=10.1016%2fj.compmedimag.2018.02.002&partnerID=40&md5=3c5addc476890756d3e387f8f1af6a73","School of Informatics, University of Edinburgh, Edinburgh, United Kingdom; Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, United Kingdom","Rachmadi M.F., School of Informatics, University of Edinburgh, Edinburgh, United Kingdom, Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, United Kingdom; Valdés-Hernández M.D.C., Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, United Kingdom; Agan M.L.F., Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, United Kingdom; Di Perri C., Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, United Kingdom; Komura T., School of Informatics, University of Edinburgh, Edinburgh, United Kingdom","We propose an adaptation of a convolutional neural network (CNN) scheme proposed for segmenting brain lesions with considerable mass-effect, to segment white matter hyperintensities (WMH) characteristic of brains with none or mild vascular pathology in routine clinical brain magnetic resonance images (MRI). This is a rather difficult segmentation problem because of the small area (i.e., volume) of the WMH and their similarity to non-pathological brain tissue. We investigate the effectiveness of the 2D CNN scheme by comparing its performance against those obtained from another deep learning approach: Deep Boltzmann Machine (DBM), two conventional machine learning approaches: Support Vector Machine (SVM) and Random Forest (RF), and a public toolbox: Lesion Segmentation Tool (LST), all reported to be useful for segmenting WMH in MRI. We also introduce a way to incorporate spatial information in convolution level of CNN for WMH segmentation named global spatial information (GSI). Analysis of covariance corroborated known associations between WMH progression, as assessed by all methods evaluated, and demographic and clinical data. Deep learning algorithms outperform conventional machine learning algorithms by excluding MRI artefacts and pathologies that appear similar to WMH. Our proposed approach of incorporating GSI also successfully helped CNN to achieve better automatic WMH segmentation regardless of network's settings tested. The mean Dice Similarity Coefficient (DSC) values for LST-LGA, SVM, RF, DBM, CNN and CNN-GSI were 0.2963, 0.1194, 0.1633, 0.3264, 0.5359 and 5389 respectively. © 2018","Alzheimer's disease; Convolutional neural network; Deep learning; Global spatial information; Mild cognitive impairment; Segmentation; White matter hyperintensities","Algorithms; Brain; Cognitive Dysfunction; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); White Matter; Convolution; Decision trees; Deep learning; Image segmentation; Magnetic resonance; Magnetic resonance imaging; Neural networks; Neurodegenerative diseases; Pathology; Regression analysis; Support vector machines; Alzheimer's disease; Convolutional neural network; Mild cognitive impairments; Spatial informations; White matter hyperintensities; Article; brain damage; brain size; brain tissue; controlled study; convolutional neural network; deep boltzmann machine; human; human tissue; learning algorithm; machine learning; nerve cell network; neuroimaging; nuclear magnetic resonance imaging; priority journal; random forest; support vector machine; vascular disease; white matter; algorithm; artificial neural network; brain; cognitive defect; diagnostic imaging; image processing; pathophysiology; procedures; white matter; Learning algorithms","Elsevier Ltd","08956111","","CMIGE","29523002","Article","Scopus","2-s2.0-85042766740"
"Yan C.; Hu J.; Zhang C.","Yan, Chengzhe (57200671860); Hu, Jie (57214426667); Zhang, Changshui (7405490589)","57200671860; 57214426667; 7405490589","Deep transformer: A framework for 2D text image rectification from planar transformations","2018","Neurocomputing","1","10.1016/j.neucom.2018.02.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042169095&doi=10.1016%2fj.neucom.2018.02.015&partnerID=40&md5=489b224fda246e4caae82e6541205a92","Department of Automation, State Key Lab of Intelligent Technologies and Systems, Tsinghua National Laboratory for Information Science and Technology(TNList), Tsinghua University, Beijing, China","Yan C., Department of Automation, State Key Lab of Intelligent Technologies and Systems, Tsinghua National Laboratory for Information Science and Technology(TNList), Tsinghua University, Beijing, China; Hu J., Department of Automation, State Key Lab of Intelligent Technologies and Systems, Tsinghua National Laboratory for Information Science and Technology(TNList), Tsinghua University, Beijing, China; Zhang C., Department of Automation, State Key Lab of Intelligent Technologies and Systems, Tsinghua National Laboratory for Information Science and Technology(TNList), Tsinghua University, Beijing, China","In this paper, a novel neural network architecture is proposed to rectify text images with mild assumptions. A new dataset of text images is collected to verify our model. We explored the capability of deep neural network in learning geometric transformation and found the model are sensitive to the text image without explicit supervised segmentation information. Experiments show the architecture proposed can restore planar transformations with wonderful robustness and effectiveness. © 2018 Elsevier B.V.","DNN; Image rectification; Image understanding","Deep neural networks; Image understanding; Mathematical transformations; Network architecture; Neural networks; Geometric transformations; Image rectification; Novel neural network; Supervised segmentation; Text images; algorithm; Article; artificial neural network; image processing; image segmentation; imaging and display; machine learning; planar transformation; priority journal; sensitivity analysis; statistical analysis; two dimensional text image rectification; Image segmentation","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85042169095"
"Han R.; Yang Y.; Li X.; Ouyang D.","Han, Run (57201213328); Yang, Yilong (57201588421); Li, Xiaoshan (8727670000); Ouyang, Defang (35085366100)","57201213328; 57201588421; 8727670000; 35085366100","Predicting oral disintegrating tablet formulations by neural network techniques","2018","Asian Journal of Pharmaceutical Sciences","65","10.1016/j.ajps.2018.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043995177&doi=10.1016%2fj.ajps.2018.01.003&partnerID=40&md5=7fae7b93e6a52b0e0e43e0df5702e23a","State Key Laboratory of Quality Research in Chinese Medicine, Institute of Chinese Medical Sciences (ICMS), University of Macau, Macau, 999078, Macao; Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macau, 999078, Macao","Han R., State Key Laboratory of Quality Research in Chinese Medicine, Institute of Chinese Medical Sciences (ICMS), University of Macau, Macau, 999078, Macao; Yang Y., State Key Laboratory of Quality Research in Chinese Medicine, Institute of Chinese Medical Sciences (ICMS), University of Macau, Macau, 999078, Macao, Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macau, 999078, Macao; Li X., Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macau, 999078, Macao; Ouyang D., State Key Laboratory of Quality Research in Chinese Medicine, Institute of Chinese Medical Sciences (ICMS), University of Macau, Macau, 999078, Macao","Oral disintegrating tablets (ODTs) are a novel dosage form that can be dissolved on the tongue within 3 min or less especially for geriatric and pediatric patients. Current ODT formulation studies usually rely on the personal experience of pharmaceutical experts and trial-and-error in the laboratory, which is inefficient and time-consuming. The aim of current research was to establish the prediction model of ODT formulations with direct compression process by artificial neural network (ANN) and deep neural network (DNN) techniques. 145 formulation data were extracted from Web of Science. All datasets were divided into three parts: training set (105 data), validation set (20) and testing set (20). ANN and DNN were compared for the prediction of the disintegrating time. The accuracy of the ANN model have reached 85.60%, 80.00% and 75.00% on the training set, validation set and testing set respectively, whereas that of the DNN model were 85.60%, 85.00% and 80.00%, respectively. Compared with the ANN, DNN showed the better prediction for ODT formulations. It is the first time that deep neural network with the improved dataset selection algorithm is applied to formulation prediction on small data. The proposed predictive approach could evaluate the critical parameters about quality control of formulation, and guide research and process development. The implementation of this prediction model could effectively reduce drug product development timeline and material usage, and proactively facilitate the development of a robust drug product. © 2018 Shenyang Pharmaceutical University","Artificial neural network; Deep neural network; Deep-learning; Formulation prediction; Oral disintegrating tablets","accuracy; Article; artificial neural network; data extraction; deep neural network; information retrieval; machine learning; personal experience; prediction; process development; quality control; tablet compression; tablet disintegration; tablet formulation; Web of Science","Shenyang Pharmaceutical University","18180876","","","","Article","Scopus","2-s2.0-85043995177"
"Liu M.; Cheng D.; Yan W.","Liu, Manhua (8611675100); Cheng, Danni (57195735824); Yan, Weiwu (7402221606)","8611675100; 57195735824; 7402221606","Classification of alzheimer’s disease by combination of convolutional and recurrent neural networks using FDG-PET images","2018","Frontiers in Neuroinformatics","129","10.3389/fninf.2018.00035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049076594&doi=10.3389%2ffninf.2018.00035&partnerID=40&md5=3d825338b01ef153d26eb0cbbaed0281","Department of Instrument Science and Engineering, The School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Shanghai Engineering Research Center for Intelligent Diagnosis and Treatment Instrument, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, The School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","Liu M., Department of Instrument Science and Engineering, The School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China, Shanghai Engineering Research Center for Intelligent Diagnosis and Treatment Instrument, Shanghai Jiao Tong University, Shanghai, China; Cheng D., Department of Instrument Science and Engineering, The School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Yan W., Department of Automation, The School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","Alzheimer’s disease (AD) is an irreversible brain degenerative disorder affecting people aged older than 65 years. Currently, there is no effective cure for AD, but its progression can be delayed with some treatments. Accurate and early diagnosis of AD is vital for the patient care and development of future treatment. Fluorodeoxyglucose positrons emission tomography (FDG-PET) is a functional molecular imaging modality, which proves to be powerful to help understand the anatomical and neural changes of brain related to AD. Most existing methods extract the handcrafted features from images, and then design a classifier to distinguish AD from other groups. These methods highly depends on the preprocessing of brain images, including image rigid registration and segmentation. Motivated by the success of deep learning in image classification, this paper proposes a new classification framework based on combination of 2D convolutional neural networks (CNN) and recurrent neural networks (RNNs), which learns the intra-slice and inter-slice features for classification after decomposition of the 3D PET image into a sequence of 2D slices. The 2D CNNs are built to capture the features of image slices while the gated recurrent unit (GRU) of RNN is cascaded to learn and integrate the inter-slice features for image classification. No rigid registration and segmentation are required for PET images. Our method is evaluated on the baseline FDG-PET images acquired from 339 subjects including 93 AD patients, 146 mild cognitive impairments (MCI) and 100 normal controls (NC) from Alzheimer’s Disease Neuroimaging Initiative (ADNI) database. Experimental results show that the proposed method achieves an area under receiver operating characteristic curve (AUC) of 95.3% for AD vs. NC classification and 83.9% for MCI vs. NC classification, demonstrating the promising classification performance. © 2018 Liu, Cheng and Yan.","Alzheimer’s disease diagnosis; Convolutional neural networks (CNN); Deep learning; FDG-PET; Image classification; Recurrent neural network","fluorodeoxyglucose f 18; aged; Alzheimer disease; Article; artificial neural network; comparative study; controlled study; disease classification; female; human; image processing; image segmentation; machine learning; major clinical study; male; mild cognitive impairment; Mini Mental State Examination; molecular imaging; nerve cell network; positron emission tomography; three dimensional imaging; two-dimensional imaging","Frontiers Media S.A.","16625196","","","","Article","Scopus","2-s2.0-85049076594"
"Adler J.; Öktem O.","Adler, Jonas (57193711251); Öktem, Ozan (23989346800)","57193711251; 23989346800","Learned Primal-Dual Reconstruction","2018","IEEE Transactions on Medical Imaging","479","10.1109/TMI.2018.2799231","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041342868&doi=10.1109%2fTMI.2018.2799231&partnerID=40&md5=2b1d68464394e791deff71f59c4ec0f7","Department of Mathematics, KTH - Royal Institute of Technology, 100 44 Stockholm, Sweden; Elekta Instrument AB, Stockholm, SE-103 93, Sweden","Adler J., Department of Mathematics, KTH - Royal Institute of Technology, 100 44 Stockholm, Sweden, Elekta Instrument AB, Stockholm, SE-103 93, Sweden; Öktem O., Department of Mathematics, KTH - Royal Institute of Technology, 100 44 Stockholm, Sweden","We propose the Learned Primal-Dual algorithm for tomographic reconstruction. The algorithm accounts for a (possibly non-linear) forward operator in a deep neural network by unrolling a proximal primal-dual optimization method, but where the proximal operators have been replaced with convolutional neural networks. The algorithm is trained end-to-end, working directly from raw measured data and it does not depend on any initial reconstruction such as filtered back-projection (FBP). We compare performance of the proposed method on low dose computed tomography reconstruction against FBP, total variation (TV), and deep learning based post-processing of FBP. For the Shepp-Logan phantom we obtain >6 dB peak signal to noise ratio improvement against all compared methods. For human phantoms the corresponding improvement is 6.6 dB over TV and 2.2 dB over learned post-processing along with a substantial improvement in the structural similarity index. Finally, our algorithm involves only ten forward-back-projection computations, making the method feasible for time critical clinical applications. © 2018 IEEE.","deep learning; Inverse problems; optimization; primal-dual; tomography","Algorithms; Deep Learning; Humans; Phantoms, Imaging; Radiographic Image Enhancement; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Deep neural networks; Differential equations; Inverse problems; Learning systems; Neural networks; Optimization; Phantoms; Television; Tomography; Clinical application; Convolutional neural network; Filtered back projection; Primal dual algorithms; Primal-dual; Shepp-Logan phantom; Structural similarity indices; Tomographic reconstruction; algorithm; Article; computer assisted tomography; image processing; image reconstruction; machine learning; process optimization; signal noise ratio; algorithm; human; image enhancement; imaging phantom; procedures; x-ray computed tomography; Image reconstruction","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870362","Article","Scopus","2-s2.0-85041342868"
"Kang E.; Chang W.; Yoo J.; Ye J.C.","Kang, Eunhee (57196043336); Chang, Won (55623686600); Yoo, Jaejun (55823730300); Ye, Jong Chul (7403237499)","57196043336; 55623686600; 55823730300; 7403237499","Deep Convolutional Framelet Denosing for Low-Dose CT via Wavelet Residual Network","2018","IEEE Transactions on Medical Imaging","230","10.1109/TMI.2018.2823756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045190583&doi=10.1109%2fTMI.2018.2823756&partnerID=40&md5=316f2b07c8a01e8c5e9f26ca0ad84797","Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Department of Radiology, Seoul National University Bundang Hospital, Seongnam, 13620, South Korea","Kang E., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Chang W., Department of Radiology, Seoul National University Bundang Hospital, Seongnam, 13620, South Korea; Yoo J., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea; Ye J.C., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, South Korea","Model-based iterative reconstruction algorithms for low-dose X-ray computed tomography (CT) are computationally expensive. To address this problem, we recently proposed a deep convolutional neural network (CNN) for low-dose X-ray CT and won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the textures were not fully recovered. To address this problem, here we propose a novel framelet-based denoising algorithm using wavelet residual network which synergistically combines the expressive power of deep learning and the performance guarantee from the framelet-based denoising algorithms. The new algorithms were inspired by the recent interpretation of the deep CNN as a cascaded convolution framelet signal representation. Extensive experimental results confirm that the proposed networks have significantly improved performance and preserve the detail texture of the original images. © 2018 IEEE.","convolution framelets; convolutional neural network (CNN); Deep learning; framelet denoising; low-dose CT","Algorithms; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Phantoms, Imaging; Radiation Dosage; Tomography, X-Ray Computed; Convolution; Deep learning; Deep neural networks; Image denoising; Image enhancement; Image reconstruction; Iterative methods; Learning systems; Neural networks; Noise abatement; Convolutional Neural Networks (CNN); De-noising; Framelets; Low-dose CT; Xray imaging; article; computer assisted tomography; image reconstruction; low drug dose; machine learning; nervous system; noise reduction; radiography; remission; algorithm; artificial neural network; human; image processing; imaging phantom; procedures; radiation dose; x-ray computed tomography; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870365","Article","Scopus","2-s2.0-85045190583"
"Wang G.; Li W.; Zuluaga M.A.; Pratt R.; Patel P.A.; Aertsen M.; Doel T.; David A.L.; Deprest J.; Ourselin S.; Vercauteren T.","Wang, Guotai (55682589900); Li, Wenqi (55823995400); Zuluaga, Maria A. (16551520500); Pratt, Rosalind (56780998200); Patel, Premal A. (56957582400); Aertsen, Michael (55308237500); Doel, Tom (55331921900); David, Anna L. (7402605276); Deprest, Jan (7006218373); Ourselin, Sebastien (6602233595); Vercauteren, Tom (23010613000)","55682589900; 55823995400; 16551520500; 56780998200; 56957582400; 55308237500; 55331921900; 7402605276; 7006218373; 6602233595; 23010613000","Interactive Medical Image Segmentation Using Deep Learning with Image-Specific Fine Tuning","2018","IEEE Transactions on Medical Imaging","585","10.1109/TMI.2018.2791721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041343833&doi=10.1109%2fTMI.2018.2791721&partnerID=40&md5=5206e68b5e2a34a356905b498adb2d0b","Wellcome EPSRC Centre for Interventional and Surgical Sciences, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Facultad de Medicina, Universidad Nacional de Colombia, Bogotá, 111321, Colombia; Amadeus S.A.S., Sophia-Antipolis, 06560, France; Department of Radiology, University Hospitals, KU Leuven, Leuven, 3000, Belgium; Wellcome EPSRC Centre for Interventional and Surgical Sciences, Institute for Women's Health, University College London, London, WC1E 6BT, United Kingdom; Department of Obstetrics and Gynaecology, KU Leuven, Leuven, 3000, Belgium","Wang G., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Li W., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Zuluaga M.A., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom, Facultad de Medicina, Universidad Nacional de Colombia, Bogotá, 111321, Colombia, Amadeus S.A.S., Sophia-Antipolis, 06560, France; Pratt R., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Patel P.A., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Aertsen M., Department of Radiology, University Hospitals, KU Leuven, Leuven, 3000, Belgium; Doel T., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; David A.L., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Institute for Women's Health, University College London, London, WC1E 6BT, United Kingdom, Department of Obstetrics and Gynaecology, KU Leuven, Leuven, 3000, Belgium; Deprest J., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Institute for Women's Health, University College London, London, WC1E 6BT, United Kingdom, Department of Obstetrics and Gynaecology, KU Leuven, Leuven, 3000, Belgium; Ourselin S., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Vercauteren T., Wellcome EPSRC Centre for Interventional and Surgical Sciences, Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom, Department of Radiology, University Hospitals, KU Leuven, Leuven, 3000, Belgium","Convolutional neural networks (CNNs) have achieved state-of-the-art performance for automatic medical image segmentation. However, they have not demonstrated sufficiently accurate and robust results for clinical use. In addition, they are limited by the lack of image-specific adaptation and the lack of generalizability to previously unseen object classes (a.k.a. zero-shot learning). To address these problems, we propose a novel deep learning-based interactive segmentation framework by incorporating CNNs into a bounding box and scribble-based segmentation pipeline. We propose image-specific fine tuning to make a CNN model adaptive to a specific test image, which can be either unsupervised (without additional user interactions) or supervised (with additional scribbles). We also propose a weighted loss function considering network and interaction-based uncertainty for the fine tuning. We applied this framework to two applications: 2-D segmentation of multiple organs from fetal magnetic resonance (MR) slices, where only two types of these organs were annotated for training and 3-D segmentation of brain tumor core (excluding edema) and whole brain tumor (including edema) from different MR sequences, where only the tumor core in one MR sequence was annotated for training. Experimental results show that: 1) our model is more robust to segment previously unseen objects than state-of-the-art CNNs; 2) image-specific fine tuning with the proposed weighted loss function significantly improves segmentation accuracy; and 3) our method leads to accurate results with fewer user interactions and less user time than traditional interactive segmentation methods. © 1982-2012 IEEE.","brain tumor; convolutional neural network; fetal MRI; fine-tuning; Interactive image segmentation","Brain; Brain Neoplasms; Deep Learning; Female; Fetus; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Pregnancy; Prenatal Diagnosis; Brain; Convolution; Deep learning; Image enhancement; Magnetic levitation vehicles; Magnetic resonance; Magnetic resonance imaging; Medical image processing; Medical imaging; Neural networks; Personnel training; Testing; Three dimensional displays; Tumors; Adaptation models; Biomedical imaging; Brain tumors; Convolutional neural network; Fetal MRI; Fine tuning; Interactive image segmentation; Two-dimensional displays; Article; brain edema; brain tumor; computer assisted tomography; convolutional neural network; fetus; fetus brain; fetus lung; human; image segmentation; kidney; machine learning; nuclear magnetic resonance imaging; pancreas; placenta; receptive field; brain; computer assisted diagnosis; diagnostic imaging; female; pregnancy; prenatal diagnosis; procedures; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29969407","Article","Scopus","2-s2.0-85041343833"
"Adhikari B.; Hou J.; Cheng J.","Adhikari, Badri (56120455900); Hou, Jie (56673336000); Cheng, Jianlin (57203108630)","56120455900; 56673336000; 57203108630","DNCON2: Improved protein contact prediction using two-level deep convolutional neural networks","2018","Bioinformatics","126","10.1093/bioinformatics/btx781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047095484&doi=10.1093%2fbioinformatics%2fbtx781&partnerID=40&md5=eeca080b987d0d344da85f3bbcafbaaa","Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, 63121, MO, United States; Informatics Institute, University of Missouri, Columbia, 65211, MO, United States","Adhikari B., Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, 63121, MO, United States; Hou J., Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, 63121, MO, United States; Cheng J., Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, 63121, MO, United States, Informatics Institute, University of Missouri, Columbia, 65211, MO, United States","Motivation Significant improvements in the prediction of protein residue-residue contacts are observed in the recent years. These contacts, predicted using a variety of coevolution-based and machine learning methods, are the key contributors to the recent progress in ab initio protein structure prediction, as demonstrated in the recent CASP experiments. Continuing the development of new methods to reliably predict contact maps is essential to further improve ab initio structure prediction. Results In this paper we discuss DNCON2, an improved protein contact map predictor based on two-level deep convolutional neural networks. It consists of six convolutional neural networks - the first five predict contacts at 6, 7.5, 8, 8.5 and 10 Å distance thresholds, and the last one uses these five predictions as additional features to predict final contact maps. On the free-modeling datasets in CASP10, 11 and 12 experiments, DNCON2 achieves mean precisions of 35, 50 and 53.4%, respectively, higher than 30.6% by MetaPSICOV on CASP10 dataset, 34% by MetaPSICOV on CASP11 dataset and 46.3% by Raptor-X on CASP12 dataset, when top L/5 long-range contacts are evaluated. We attribute the improved performance of DNCON2 to the inclusion of short- and medium-range contacts into training, two-level approach to prediction, use of the state-of-the-art optimization and activation functions, and a novel deep learning architecture that allows each filter in a convolutional layer to access all the input features of a protein of arbitrary length. Availability and implementation The web server of DNCON2 is at http://sysbio.rnet.Missouri.edu/dncon2/ where training and testing datasets as well as the predictions for CASP10, 11 and 12 free-modeling datasets can also be downloaded. Its source code is available at https://github.com/multicom-toolbox/DNCON2/. Contact chengji@Missouri.edu Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author(s) 2017. Published by Oxford University Press.","","Caspases; Computational Biology; Machine Learning; Neural Networks (Computer); Protein Conformation; Sequence Analysis, Protein; caspase; artificial neural network; biology; chemistry; machine learning; metabolism; procedures; protein conformation; sequence analysis","Oxford University Press","13674803","","BOINF","29228185","Article","Scopus","2-s2.0-85047095484"
"Men K.; Zhang T.; Chen X.; Chen B.; Tang Y.; Wang S.; Li Y.; Dai J.","Men, Kuo (36464032300); Zhang, Tao (57211544689); Chen, Xinyuan (55585707700); Chen, Bo (56206367000); Tang, Yu (57188875628); Wang, Shulian (7410341618); Li, Yexiong (35286024200); Dai, Jianrong (7401679180)","36464032300; 57211544689; 55585707700; 56206367000; 57188875628; 7410341618; 35286024200; 7401679180","Fully automatic and robust segmentation of the clinical target volume for radiotherapy of breast cancer using big data and deep learning","2018","Physica Medica","117","10.1016/j.ejmp.2018.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047218611&doi=10.1016%2fj.ejmp.2018.05.006&partnerID=40&md5=3fce306af63f78d671f3fb17d41a2d06","National Cancer Center/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China","Men K., National Cancer Center/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China; Zhang T., National Cancer Center/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China; Chen X., National Cancer Center/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China; Chen B., National Cancer Center/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China; Tang Y., National Cancer Center/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China; Wang S., National Cancer Center/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China; Li Y., National Cancer Center/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China; Dai J., National Cancer Center/Cancer Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100021, China","Purpose: To train and evaluate a very deep dilated residual network (DD-ResNet) for fast and consistent auto-segmentation of the clinical target volume (CTV) for breast cancer (BC) radiotherapy with big data. Methods: DD-ResNet was an end-to-end model enabling fast training and testing. We used big data comprising 800 patients who underwent breast-conserving therapy for evaluation. The CTV were validated by experienced radiation oncologists. We performed a fivefold cross-validation to test the performance of the model. The segmentation accuracy was quantified by the Dice similarity coefficient (DSC) and the Hausdorff distance (HD). The performance of the proposed model was evaluated against two different deep learning models: deep dilated convolutional neural network (DDCNN) and deep deconvolutional neural network (DDNN). Results: Mean DSC values of DD-ResNet (0.91 and 0.91) were higher than the other two networks (DDCNN: 0.85 and 0.85; DDNN: 0.88 and 0.87) for both right-sided and left-sided BC. It also has smaller mean HD values of 10.5 mm and 10.7 mm compared with DDCNN (15.1 mm and 15.6 mm) and DDNN (13.5 mm and 14.1 mm). Mean segmentation time was 4 s, 21 s and 15 s per patient with DDCNN, DDNN and DD-ResNet, respectively. The DD-ResNet was also superior with regard to results in the literature. Conclusions: The proposed method could segment the CTV accurately with acceptable time consumption. It was invariant to the body size and shape of patients and could improve the consistency of target delineation and streamline radiotherapy workflows. © 2018 Associazione Italiana di Fisica Medica","Automatic segmentation; Big data; Breast cancer radiotherapy; Clinical target volume; Deep learning","Automation; Breast Neoplasms; Humans; Image Processing, Computer-Assisted; Machine Learning; Radiotherapy Planning, Computer-Assisted; Time Factors; Tomography, X-Ray Computed; Article; artificial neural network; body build; body size; breast cancer; clinical evaluation; Clinical Target Volume; comparative study; computer assisted tomography; controlled study; data analysis; deep deconvolutional neural network; deep dilated convolutional neural network; human; image segmentation; learning algorithm; major clinical study; measurement accuracy; quantitative analysis; treatment planning; automation; breast tumor; diagnostic imaging; image processing; machine learning; procedures; radiotherapy planning system; time factor; x-ray computed tomography","Associazione Italiana di Fisica Medica","11201797","","PHYME","29891089","Article","Scopus","2-s2.0-85047218611"
"Nath A.; Karthikeyan S.","Nath, Abhigyan (55365661100); Karthikeyan, S. (55763046400)","55365661100; 55763046400","Enhanced prediction of recombination hotspots using input features extracted by class specific autoencoders","2018","Journal of Theoretical Biology","9","10.1016/j.jtbi.2018.02.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042351348&doi=10.1016%2fj.jtbi.2018.02.016&partnerID=40&md5=54df3ee498e44e72b8a937703c11d4b7","Department of Computer Science, Banaras Hindu University, Varanasi, 221005, India","Nath A., Department of Computer Science, Banaras Hindu University, Varanasi, 221005, India; Karthikeyan S., Department of Computer Science, Banaras Hindu University, Varanasi, 221005, India","In yeast and in some mammals the frequencies of recombination are high in some genomic locations which are known as recombination hotspots and in the locations where the recombination is below average are consequently known as coldspots. Knowledge of the hotspot regions gives clues about understanding the meiotic process and also in understanding the possible effects of sequence variation in these regions. Moreover, accurate information about the hotspot and coldspot regions can reveal insights into the genome evolution. In the present work, we have used class specific autoencoders for feature extraction and reduction. Subsequently the deep features that are extracted from the autoencoders were used to train three different classifiers, namely: gradient boosting machines, random forest and deep learning neural networks for predicting the hotspot and coldspot regions. A comparative performance analysis was carried out by experimenting on deep features extracted from different sets of the training data using autoencoders for selecting the best set of deep features. It was observed that learning algorithms trained on features extracted from the combined class specific autoencoder out performed when compared with the performances of these learning algorithms trained with other sets of deep features. So the combined class-specific autoencoder based feature extraction can be applied to a growing range of biological problems to achieve superior prediction performance. © 2018 Elsevier Ltd","Autoencoders; Deep features; Deep learning; Recombination hotspots","Algorithms; Base Sequence; Classification; Deep Learning; Neural Networks (Computer); Recombination, Genetic; Saccharomyces cerevisiae; Mammalia; algorithm; genome; genomics; machine learning; mammal; prediction; recombination; yeast; area under the curve; Article; class specific autoencoder; classifier; controlled study; data extraction; data processing; deep learning neural network; false positive result; genetic recombination; gradient boosting machine; information processing; learning algorithm; machine learning; measurement accuracy; prediction; predictive value; priority journal; random forest; recombination hotspot; sensitivity and specificity; algorithm; artificial neural network; classification; genetics; nucleotide sequence; Saccharomyces cerevisiae","Academic Press","00225193","","JTBIA","29462625","Article","Scopus","2-s2.0-85042351348"
"Chuai G.; Ma H.; Yan J.; Chen M.; Hong N.; Xue D.; Zhou C.; Zhu C.; Chen K.; Duan B.; Gu F.; Qu S.; Huang D.; Wei J.; Liu Q.","Chuai, Guohui (57192114259); Ma, Hanhui (16744036800); Yan, Jifang (57193126731); Chen, Ming (57191289398); Hong, Nanfang (57202728073); Xue, Dongyu (57199391334); Zhou, Chi (57193120664); Zhu, Chenyu (57193123904); Chen, Ke (57196248968); Duan, Bin (56526290600); Gu, Feng (55754155800); Qu, Sheng (57202729680); Huang, Deshuang (13310398900); Wei, Jia (56054170500); Liu, Qi (57855545300)","57192114259; 16744036800; 57193126731; 57191289398; 57202728073; 57199391334; 57193120664; 57193123904; 57196248968; 56526290600; 55754155800; 57202729680; 13310398900; 56054170500; 57855545300","DeepCRISPR: Optimized CRISPR guide RNA design by deep learning","2018","Genome Biology","241","10.1186/s13059-018-1459-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049146901&doi=10.1186%2fs13059-018-1459-4&partnerID=40&md5=0bc0cb6b635af139bf459c92e64a8f8d","Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China; School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Tongji University, Machine Learning and Systems Biology Lab, School of Electronics and Information Engineering, Shanghai, 201804, China; R and D Information, Innovation Center China, AstraZeneca, 199 Liangjing Road, Shanghai, 201203, China; ShanghaiTech University, School of Life Science and Technology, Shanghai, China; School of Ophthalmology and Optometry, Eye Hospital, Wenzhou Medical University, State Key Laboratory Cultivation Base and Key Laboratory of Vision Science, Ministry of Health and Zhejiang Provincial Key Laboratory of Ophthalmology and Optometry, Wenzhou, Zhejiang, 325027, China","Chuai G., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Ma H., ShanghaiTech University, School of Life Science and Technology, Shanghai, China; Yan J., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Chen M., R and D Information, Innovation Center China, AstraZeneca, 199 Liangjing Road, Shanghai, 201203, China; Hong N., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Xue D., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Zhou C., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Zhu C., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Chen K., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Duan B., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Gu F., School of Ophthalmology and Optometry, Eye Hospital, Wenzhou Medical University, State Key Laboratory Cultivation Base and Key Laboratory of Vision Science, Ministry of Health and Zhejiang Provincial Key Laboratory of Ophthalmology and Optometry, Wenzhou, Zhejiang, 325027, China; Qu S., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China; Huang D., Tongji University, Machine Learning and Systems Biology Lab, School of Electronics and Information Engineering, Shanghai, 201804, China; Wei J., R and D Information, Innovation Center China, AstraZeneca, 199 Liangjing Road, Shanghai, 201203, China; Liu Q., Shanghai Tenth People's Hospital, Tongji University, Department of Endocrinology and Metabolism, Shanghai, 20009, China, School of Life Sciences and Technology, Tongji University, Bioinformatics Department, Shanghai, 20009, China","A major challenge for effective application of CRISPR systems is to accurately predict the single guide RNA (sgRNA) on-target knockout efficacy and off-target profile, which would facilitate the optimized design of sgRNAs with high sensitivity and specificity. Here we present DeepCRISPR, a comprehensive computational platform to unify sgRNA on-target and off-target site prediction into one framework with deep learning, surpassing available state-of-the-art in silico tools. In addition, DeepCRISPR fully automates the identification of sequence and epigenetic features that may affect sgRNA knockout efficacy in a data-driven manner. DeepCRISPR is available at http://www.deepcrispr.net/. © 2018 The Author(s).","CRISPR system; Deep learning; Gene knockout; Off-targets; On-targets","Cell Line; Cell Line, Tumor; Clustered Regularly Interspaced Short Palindromic Repeats; Computational Biology; Computer Simulation; CRISPR-Cas Systems; HCT116 Cells; HEK293 Cells; HeLa Cells; HL-60 Cells; Humans; Machine Learning; RNA Editing; RNA, Guide; RNA; single guide RNA; unclassified drug; guide RNA; Article; automation; clustered regularly interspaced short palindromic repeat; computer model; conceptual framework; epigenetics; gene knockout; gene targeting; Internet; learning style; mathematical model; prediction; process optimization; RNA sequence; biology; cell line; clustered regularly interspaced short palindromic repeat; computer simulation; CRISPR Cas system; genetics; HCT 116 cell line; HEK293 cell line; HeLa cell line; HL-60 cell line; human; machine learning; procedures; RNA editing; tumor cell line","BioMed Central Ltd.","14747596","","GNBLF","29945655","Article","Scopus","2-s2.0-85049146901"
"Fu H.; Cheng J.; Xu Y.; Wong D.W.K.; Liu J.; Cao X.","Fu, Huazhu (35317209500); Cheng, Jun (57535555300); Xu, Yanwu (55516961100); Wong, Damon Wing Kee (56903519800); Liu, Jiang (23389932700); Cao, Xiaochun (8920951000)","35317209500; 57535555300; 55516961100; 56903519800; 23389932700; 8920951000","Joint Optic Disc and Cup Segmentation Based on Multi-Label Deep Network and Polar Transformation","2018","IEEE Transactions on Medical Imaging","643","10.1109/TMI.2018.2791488","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041202159&doi=10.1109%2fTMI.2018.2791488&partnerID=40&md5=d7e6921c77bf8d414de7823f75a6916d","Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore, 138632, Singapore; Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Zhejiang, 315201, China; Guangzhou Shiyuan Electronics Co., Ltd. (CVTE), Guangzhou, 510670, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China","Fu H., Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore, 138632, Singapore; Cheng J., Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore, 138632, Singapore, Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Zhejiang, 315201, China; Xu Y., Guangzhou Shiyuan Electronics Co., Ltd. (CVTE), Guangzhou, 510670, China; Wong D.W.K., Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore, 138632, Singapore; Liu J., Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Zhejiang, 315201, China; Cao X., State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100093, China","Glaucoma is a chronic eye disease that leads to irreversible vision loss. The cup to disc ratio (CDR) plays an important role in the screening and diagnosis of glaucoma. Thus, the accurate and automatic segmentation of optic disc (OD) and optic cup (OC) from fundus images is a fundamental task. Most existing methods segment them separately, and rely on hand-crafted visual feature from fundus images. In this paper, we propose a deep learning architecture, named M-Net, which solves the OD and OC segmentation jointly in a one-stage multi-label system. The proposed M-Net mainly consists of multi-scale input layer, U-shape convolutional network, side-output layer, and multi-label loss function. The multi-scale input layer constructs an image pyramid to achieve multiple level receptive field sizes. The U-shape convolutional network is employed as the main body network structure to learn the rich hierarchical representation, while the side-output layer acts as an early classifier that produces a companion local prediction map for different scale layers. Finally, a multi-label loss function is proposed to generate the final segmentation map. For improving the segmentation performance further, we also introduce the polar transformation, which provides the representation of the original image in the polar coordinate system. The experiments show that our M-Net system achieves state-of-the-art OD and OC segmentation result on ORIGA data set. Simultaneously, the proposed method also obtains the satisfactory glaucoma screening performances with calculated CDR value on both ORIGA and SCES datasets. © 1982-2012 IEEE.","cup to disc ratio; Deep learning; glaucoma screening; optic cup segmentation; optic disc segmentation","Databases, Factual; Deep Learning; Diagnostic Techniques, Ophthalmological; Glaucoma; Humans; Image Interpretation, Computer-Assisted; Optic Disk; Clock and data recovery circuits (CDR circuits); Convolution; Deep learning; Diagnosis; Disks (machine components); Flow visualization; Image enhancement; Learning systems; Ophthalmology; Optical image storage; Optical losses; Biomedical optical imaging; Cup to disc ratios; Glaucoma screenings; Optic cups; Optic disc; Optical imaging; Article; false negative result; false positive result; glaucoma; human; image segmentation; nerve cell; optic disk; optic disk cup; optic nerve; prediction; receptive field; screening; computer assisted diagnosis; diagnostic imaging; factual database; optic disk; procedures; visual system examination; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29969410","Article","Scopus","2-s2.0-85041202159"
"Yang G.; Yu S.; Dong H.; Slabaugh G.; Dragotti P.L.; Ye X.; Liu F.; Arridge S.; Keegan J.; Guo Y.; Firmin D.","Yang, Guang (57216243504); Yu, Simiao (57197844923); Dong, Hao (56547882800); Slabaugh, Greg (8556472600); Dragotti, Pier Luigi (6701786340); Ye, Xujiong (16033536900); Liu, Fangde (57194785628); Arridge, Simon (7005759823); Keegan, Jennifer (57206370469); Guo, Yike (12765868000); Firmin, David (7007100394)","57216243504; 57197844923; 56547882800; 8556472600; 6701786340; 16033536900; 57194785628; 7005759823; 57206370469; 12765868000; 7007100394","DAGAN: Deep De-Aliasing Generative Adversarial Networks for Fast Compressed Sensing MRI Reconstruction","2018","IEEE Transactions on Medical Imaging","722","10.1109/TMI.2017.2785879","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039809280&doi=10.1109%2fTMI.2017.2785879&partnerID=40&md5=47607a8986d3e57b49c1595cd0fc128d","National Heart and Lung Institute, Imperial College London, London, SW3 6NP, United Kingdom; Data Science Institute, Imperial College London, London, SW7 2AZ, United Kingdom; Department of Computer Science, City University of London, London, EC1V 0HB, United Kingdom; EEE Department, Imperial College London, London, SW3 6NP, United Kingdom; School of Computer Science, University of Lincoln, Lincoln, LN6 7TS, United Kingdom; CMIC, University College London, London, WC1E 6BT, United Kingdom","Yang G., National Heart and Lung Institute, Imperial College London, London, SW3 6NP, United Kingdom; Yu S., Data Science Institute, Imperial College London, London, SW7 2AZ, United Kingdom; Dong H., Data Science Institute, Imperial College London, London, SW7 2AZ, United Kingdom; Slabaugh G., Department of Computer Science, City University of London, London, EC1V 0HB, United Kingdom; Dragotti P.L., EEE Department, Imperial College London, London, SW3 6NP, United Kingdom; Ye X., School of Computer Science, University of Lincoln, Lincoln, LN6 7TS, United Kingdom; Liu F., Data Science Institute, Imperial College London, London, SW7 2AZ, United Kingdom; Arridge S., CMIC, University College London, London, WC1E 6BT, United Kingdom; Keegan J., National Heart and Lung Institute, Imperial College London, London, SW3 6NP, United Kingdom; Guo Y., Data Science Institute, Imperial College London, London, SW7 2AZ, United Kingdom; Firmin D., National Heart and Lung Institute, Imperial College London, London, SW3 6NP, United Kingdom","Compressed sensing magnetic resonance imaging (CS-MRI) enables fast acquisition, which is highly desirable for numerous clinical applications. This can not only reduce the scanning cost and ease patient burden, but also potentially reduce motion artefacts and the effect of contrast washout, thus yielding better image quality. Different from parallel imaging-based fast MRI, which utilizes multiple coils to simultaneously receive MR signals, CS-MRI breaks the Nyquist-Shannon sampling barrier to reconstruct MRI images with much less required raw data. This paper provides a deep learning-based strategy for reconstruction of CS-MRI, and bridges a substantial gap between conventional non-learning methods working only on data from a single image, and prior knowledge from large training data sets. In particular, a novel conditional Generative Adversarial Networks-based model (DAGAN)-based model is proposed to reconstruct CS-MRI. In our DAGAN architecture, we have designed a refinement learning method to stabilize our U-Net based generator, which provides an end-to-end network to reduce aliasing artefacts. To better preserve texture and edges in the reconstruction, we have coupled the adversarial loss with an innovative content loss. In addition, we incorporate frequency-domain information to enforce similarity in both the image and frequency domains. We have performed comprehensive comparison studies with both conventional CS-MRI reconstruction methods and newly investigated deep learning approaches. Compared with these methods, our DAGAN method provides superior reconstruction with preserved perceptual image details. Furthermore, each image is reconstructed in about 5 ms, which is suitable for real-time processing. © 2018 IEEE.","Compressed sensing; de-aliasing; deep learning; fast MRI; generative adversarial networks (GAN); inverse problems; magnetic resonance imaging (MRI)","Algorithms; Data Compression; Deep Learning; Humans; Magnetic Resonance Imaging; Acceleration; Compressed sensing; Deep learning; Encoding (symbols); Frequency domain analysis; Image reconstruction; Inverse problems; Learning systems; Magnetic levitation vehicles; Mathematical transformations; Adversarial networks; Aliasing; Clinical application; Comprehensive comparisons; Magnetic Resonance Imaging (MRI); MRI reconstruction; Realtime processing; Reconstruction method; Article; artifact; comparative study; compressed sensing magnetic resonance imaging; deep dealiasing generative adversarial network; image quality; image reconstruction; learning algorithm; machine learning; nuclear magnetic resonance imaging; algorithm; human; information processing; nuclear magnetic resonance imaging; procedures; Magnetic resonance imaging","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870361","Article","Scopus","2-s2.0-85039809280"
"Muhammad K.; Ahmad J.; Baik S.W.","Muhammad, Khan (8942252200); Ahmad, Jamil (57202952182); Baik, Sung Wook (7102833923)","8942252200; 57202952182; 7102833923","Early fire detection using convolutional neural networks during surveillance for effective disaster management","2018","Neurocomputing","321","10.1016/j.neucom.2017.04.083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041595565&doi=10.1016%2fj.neucom.2017.04.083&partnerID=40&md5=7fcd9cfe09196e167ca9bb1b422ebd98","Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea","Muhammad K., Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Ahmad J., Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Baik S.W., Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea","Fire disasters are man-made disasters, which cause ecological, social, and economic damage. To minimize these losses, early detection of fire and an autonomous response are important and helpful to disaster management systems. Therefore, in this article, we propose an early fire detection framework using fine-tuned convolutional neural networks for CCTV surveillance cameras, which can detect fire in varying indoor and outdoor environments. To ensure the autonomous response, we propose an adaptive prioritization mechanism for cameras in the surveillance system. Finally, we propose a dynamic channel selection algorithm for cameras based on cognitive radio networks, ensuring reliable data dissemination. Experimental results verify the higher accuracy of our fire detection scheme compared to state-of-the-art methods and validate the applicability of our framework for effective fire disaster management. © 2017 Elsevier B.V.","Deep learning; Disaster management; Fire detection; Image classification; Learning vision; Machine learning; Surveillance networks","Cameras; Cognitive radio; Convolution; Deep learning; Disaster prevention; Fire detectors; Fires; Image classification; Learning systems; Monitoring; Neural networks; Security systems; Adaptive prioritization; Cognitive radio network; Convolutional neural network; Disaster management; Dynamic channel selections; Fire detection; State-of-the-art methods; Surveillance networks; accidents and accident related phenomena; algorithm; Article; artificial neural network; convolutional neural network; data processing; disaster management; fire; measurement accuracy; priority journal; radio; validation process; Disasters","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85041595565"
"Bar Y.; Diamant I.; Wolf L.; Lieberman S.; Konen E.; Greenspan H.","Bar, Yaniv (56422136900); Diamant, Idit (13409806100); Wolf, Lior (57203078732); Lieberman, Sivan (7102933678); Konen, Eli (6701640190); Greenspan, Hayit (7004965553)","56422136900; 13409806100; 57203078732; 7102933678; 6701640190; 7004965553","Chest pathology identification using deep feature selection with non-medical training","2018","Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization","42","10.1080/21681163.2016.1138324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006184186&doi=10.1080%2f21681163.2016.1138324&partnerID=40&md5=9c9a8599358a5835b07bdc74b7ffd03f","The Blavatnik School of Computer Science, Tel Aviv University, Tel-Aviv, Israel; Department of Biomedical Engineering, Tel-Aviv University, Tel Aviv, Israel; Diagnostic Imaging Department, Sheba Medical Center, Ramat Gan, Israel","Bar Y., The Blavatnik School of Computer Science, Tel Aviv University, Tel-Aviv, Israel; Diamant I., Department of Biomedical Engineering, Tel-Aviv University, Tel Aviv, Israel; Wolf L., The Blavatnik School of Computer Science, Tel Aviv University, Tel-Aviv, Israel; Lieberman S., Diagnostic Imaging Department, Sheba Medical Center, Ramat Gan, Israel; Konen E., Diagnostic Imaging Department, Sheba Medical Center, Ramat Gan, Israel; Greenspan H., Department of Biomedical Engineering, Tel-Aviv University, Tel Aviv, Israel","We demonstrate the feasibility of detecting pathology in chest X-rays using deep learning approaches based on non-medical learning. Convolutional neural networks (CNN) learn higher level image representations. In this work, we explore the features extracted from layers of the CNN along with a set of classical features, including GIST and bag-of-words. We show results of classification using each feature set as well as fusing among the features. Finally, we perform feature selection on the collection of features to show the most informative feature set for the task. Results of 0.78–0.95 AUC for various pathologies are shown on a data-set of more than 600 radiographs. This study shows the strength and robustness of the CNN features. We conclude that deep learning with large-scale non- medical image databases may be a good substitute, or addition to domain-specific representations which are yet to be available for general medical image recognition tasks. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","chest X-rays; CNN; computer-aided diagnosis; deep learning; feature selection; Radiography","Computer aided diagnosis; Computer aided instruction; Deep learning; Image recognition; Medical imaging; Neural networks; Pathology; Radiography; Chest X-ray; Convolutional neural network; Deep learning; Detecting pathologies; Features selection; Features sets; Image representations; Learn+; Learning approach; Medical training; analytical parameters; Article; artificial neural network; convolutional neural network; human; image analysis; machine learning; measurement accuracy; priority journal; receiver operating characteristic; robustness; sensitivity and specificity; support vector machine; thorax radiography; validation process; Feature extraction","Taylor and Francis Ltd.","21681163","","","","Article","Scopus","2-s2.0-85006184186"
"Yosipof A.; Guedes R.C.; García-Sosa A.T.","Yosipof, Abraham (55773547500); Guedes, Rita C. (7103388682); García-Sosa, Alfonso T. (22953501800)","55773547500; 7103388682; 22953501800","Data mining and machine learning models for predicting drug likeness and their disease or organ category","2018","Frontiers in Chemistry","40","10.3389/fchem.2018.00162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048218866&doi=10.3389%2ffchem.2018.00162&partnerID=40&md5=41b2fa4a1f7aad23847f4ee5e9d2c8a3","Department of Information Systems, Department of Business Administration, College of Law and Business, Ramat-Gan, Israel; Department of Medicinal Chemistry, Faculty of Pharmacy, Research Institute for Medicines (iMed.ULisboa), Universidade de Lisboa, Lisbon, Portugal; Department of Molecular Technology, Institute of Chemistry, University of Tartu, Tartu, Estonia","Yosipof A., Department of Information Systems, Department of Business Administration, College of Law and Business, Ramat-Gan, Israel; Guedes R.C., Department of Medicinal Chemistry, Faculty of Pharmacy, Research Institute for Medicines (iMed.ULisboa), Universidade de Lisboa, Lisbon, Portugal; García-Sosa A.T., Department of Molecular Technology, Institute of Chemistry, University of Tartu, Tartu, Estonia","Data mining approaches can uncover underlying patterns in chemical and pharmacological property space decisive for drug discovery and development. Two of the most common approaches are visualization and machine learning methods. Visualization methods use dimensionality reduction techniques in order to reduce multi-dimension data into 2D or 3D representations with a minimal loss of information. Machine learning attempts to find correlations between specific activities or classifications for a set of compounds and their features by means of recurring mathematical models. Both models take advantage of the different and deep relationships that can exist between features of compounds, and helpfully provide classification of compounds based on such features or in case of visualization methods uncover underlying patterns in the feature space. Drug-likeness has been studied from several viewpoints, but here we provide the first implementation in chemoinformatics of the t-Distributed Stochastic Neighbor Embedding (t-SNE) method for the visualization and the representation of chemical space, and the use of different machine learning methods separately and together to form a new ensemble learning method called AL Boost. The models obtained from AL Boost synergistically combine decision tree, random forests (RF), support vector machine (SVM), artificial neural network (ANN), k nearest neighbors (kNN), and logistic regression models. In this work, we show that together they form a predictive model that not only improves the predictive force but also decreases bias. This resulted in a corrected classification rate of over 0.81, as well as higher sensitivity and specificity rates for the models. In addition, separation and good models were also achieved for disease categories such as antineoplastic compounds and nervous system diseases, among others. Such models can be used to guide decision on the feature landscape of compounds and their likeness to either drugs or other characteristics, such as specific or multiple disease-category(ies) or organ(s) of action of a molecule. © 2018 Yosipof, Guedes and García-Sosa.","Data-mining; Drug; Drug design; Logistic; Machine-learning; Multi-target; Organ","","Frontiers Media S. A","22962646","","","","Article","Scopus","2-s2.0-85048218866"
"Pang S.; del Coz J.J.; Yu Z.; Luaces O.; Díez J.","Pang, Shuchao (55639762100); del Coz, Juan José (55057195300); Yu, Zhezhou (8938987700); Luaces, Oscar (6603154001); Díez, Jorge (7201552665)","55639762100; 55057195300; 8938987700; 6603154001; 7201552665","Deep Learning and Preference Learning for Object Tracking: A Combined Approach","2018","Neural Processing Letters","10","10.1007/s11063-017-9720-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031915843&doi=10.1007%2fs11063-017-9720-5&partnerID=40&md5=6ab5ac8ce99070900966acf4165ec867","College of Computer Science and Technology, Jilin University, Changchun, 130012, China; Artificial Intelligence Center, University of Oviedo at Gijón, Gijón, 33204, Spain","Pang S., College of Computer Science and Technology, Jilin University, Changchun, 130012, China; del Coz J.J., Artificial Intelligence Center, University of Oviedo at Gijón, Gijón, 33204, Spain; Yu Z., College of Computer Science and Technology, Jilin University, Changchun, 130012, China; Luaces O., Artificial Intelligence Center, University of Oviedo at Gijón, Gijón, 33204, Spain; Díez J., Artificial Intelligence Center, University of Oviedo at Gijón, Gijón, 33204, Spain","Object tracking is one of the most important processes for object recognition in the field of computer vision. The aim is to find accurately a target object in every frame of a video sequence. In this paper we propose a combination technique of two algorithms well-known among machine learning practitioners. Firstly, we propose a deep learning approach to automatically extract the features that will be used to represent the original images. Deep learning has been successfully applied in different computer vision applications. Secondly, object tracking can be seen as a ranking problem, since the regions of an image can be ranked according to their level of overlapping with the target object (ground truth in each video frame). During object tracking, the target position and size can change, so the algorithms have to propose several candidate regions in which the target can be found. We propose to use a preference learning approach to build a ranking function which will be used to select the bounding box that ranks higher, i.e., that will likely enclose the target object. The experimental results obtained by our method, called DPL2 (Deep and Preference Learning), are competitive with respect to other algorithms. © 2017, Springer Science+Business Media, LLC.","Deep learning; Object tracking; Preference learning","Computer vision; Learning algorithms; Object recognition; Target tracking; Computer vision applications; Learning approach; Object Tracking; Preference learning; Ranking functions; Ranking problems; Target position; Video sequences; Deep learning","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-85031915843"
"Zeng W.; Wu M.; Jiang R.","Zeng, Wanwen (57189046061); Wu, Mengmeng (56626590500); Jiang, Rui (57200775668)","57189046061; 56626590500; 57200775668","Prediction of enhancer-promoter interactions via natural language processing","2018","BMC Genomics","57","10.1186/s12864-018-4459-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046700344&doi=10.1186%2fs12864-018-4459-6&partnerID=40&md5=0255dc95bc726913a1d73cb4b97e72d9","MOE Key Laboratory of Bioinformatics, Bioinformatics Division and Center for Synthetic and Systems Biology, Beijing, 100084, China; Tsinghua University, Department of Automation, Beijing, 100084, China; Tsinghua University, Department of Computer Science, Beijing, 100084, China","Zeng W., MOE Key Laboratory of Bioinformatics, Bioinformatics Division and Center for Synthetic and Systems Biology, Beijing, 100084, China, Tsinghua University, Department of Automation, Beijing, 100084, China; Wu M., MOE Key Laboratory of Bioinformatics, Bioinformatics Division and Center for Synthetic and Systems Biology, Beijing, 100084, China, Tsinghua University, Department of Computer Science, Beijing, 100084, China; Jiang R., MOE Key Laboratory of Bioinformatics, Bioinformatics Division and Center for Synthetic and Systems Biology, Beijing, 100084, China, Tsinghua University, Department of Automation, Beijing, 100084, China","Background: Precise identification of three-dimensional genome organization, especially enhancer-promoter interactions (EPIs), is important to deciphering gene regulation, cell differentiation and disease mechanisms. Currently, it is a challenging task to distinguish true interactions from other nearby non-interacting ones since the power of traditional experimental methods is limited due to low resolution or low throughput. Results: We propose a novel computational framework EP2vec to assay three-dimensional genomic interactions. We first extract sequence embedding features, defined as fixed-length vector representations learned from variable-length sequences using an unsupervised deep learning method in natural language processing. Then, we train a classifier to predict EPIs using the learned representations in supervised way. Experimental results demonstrate that EP2vec obtains F1 scores ranging from 0.841~0.933 on different datasets, which outperforms existing methods. We prove the robustness of sequence embedding features by carrying out sensitivity analysis. Besides, we identify motifs that represent cell line-specific information through analysis of the learned sequence embedding features by adopting attention mechanism. Last, we show that even superior performance with F1 scores 0.889~0.940 can be achieved by combining sequence embedding features and experimental features. Conclusions: EP2vec sheds light on feature extraction for DNA sequences of arbitrary lengths and provides a powerful approach for EPIs identification. © 2018 The Author(s).","Enhancer-promoter interactions; Natural language processing; Three-dimensinal interactions; Unsupervised learning","Cell Line, Tumor; Computational Biology; Databases, Genetic; HeLa Cells; Human Umbilical Vein Endothelial Cells; Humans; K562 Cells; Natural Language Processing; Promoter Regions, Genetic; Regulatory Sequences, Nucleic Acid; Sequence Analysis, DNA; Unsupervised Machine Learning; DNA binding protein; kruppel like factor 6; protein Myb; transforming growth factor beta1; adult; Article; classifier; decision tree; DNA sequence; enhancer region; female; gene interaction; Gradient Boosted Regression Trees classifier; hematopoiesis; human; HUVEC cell line; natural language processing; prediction; promoter region; protein binding; protein expression; RNA sequence; systematic error; TGF beta signaling; validation process; biology; genetic database; HeLa cell line; K-562 cell line; natural language processing; procedures; regulatory sequence; tumor cell line; umbilical vein endothelial cell; unsupervised machine learning","BioMed Central Ltd.","14712164","","BGMEE","29764360","Article","Scopus","2-s2.0-85046700344"
"Kern A.D.; Schrider D.R.","Kern, Andrew D. (7103061601); Schrider, Daniel R. (26322784200)","7103061601; 26322784200","DiploS/HIC: An updated approach to classifying selective sweeps","2018","G3: Genes, Genomes, Genetics","71","10.1534/g3.118.200262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047871920&doi=10.1534%2fg3.118.200262&partnerID=40&md5=9af7c3f0b5997b2175f8e901be2dbede","Department of Genetics, Rutgers University, Piscataway, 08854, NJ, United States","Kern A.D., Department of Genetics, Rutgers University, Piscataway, 08854, NJ, United States; Schrider D.R., Department of Genetics, Rutgers University, Piscataway, 08854, NJ, United States","Identifying selective sweeps in populations that have complex demographic histories remains a difficult problem in population genetics. We previously introduced a supervised machine learning approach, S/HIC, for finding both hard and soft selective sweeps in genomes on the basis of patterns of genetic variation surrounding a window of the genome. While S/HIC was shown to be both powerful and precise, the utility of S/HIC was limited by the use of phased genomic data as input. In this report we describe a deep learning variant of our method, diploS/HIC, that uses unphased genotypes to accurately classify genomic windows. diploS/HIC is shown to be quite powerful even at moderate to small sample sizes. © 2018 Kern, Schrider.","Adaptation and Population; Deep learning Selective Sweeps; Genetics; Machine Learning","Animals; Anopheles; Base Sequence; Chromosomes; Genome, Insect; Genotype; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Recombination, Genetic; ROC Curve; Selection, Genetic; article; genetics; genotype; human; machine learning; sample size; selective sweep; animal; Anopheles; artificial neural network; chromosome; genetic recombination; genetic selection; genetics; image processing; insect genome; nucleotide sequence; receiver operating characteristic","Genetics Society of America","21601836","","","29626082","Article","Scopus","2-s2.0-85047871920"
"Wang C.; Elazab A.; Jia F.; Wu J.; Hu Q.","Wang, Changmiao (57226651647); Elazab, Ahmed (56523141500); Jia, Fucang (55784808100); Wu, Jianhuang (9746889000); Hu, Qingmao (7403214583)","57226651647; 56523141500; 55784808100; 9746889000; 7403214583","Automated chest screening based on a hybrid model of transfer learning and convolutional sparse denoising autoencoder","2018","BioMedical Engineering Online","20","10.1186/s12938-018-0496-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047449643&doi=10.1186%2fs12938-018-0496-2&partnerID=40&md5=1d4d46cab718b88b26997a20aab2561f","Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, 1068 Xueyuan Boulevard, Shenzhen, 518055, China; University of Chinese Academy of Sciences, 52 Sanlihe Road, Beijing, 100864, China; Shenzhen University, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen, 518060, China; Misr Higher Institute for Commerce and Computers, Department of Computer Science, Mansoura, 35516, Egypt; Key Laboratory of Human-Machine Intelligence Synergy Systems, 1068 Xueyuan Boulevard, Shenzhen, 518055, China","Wang C., Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, 1068 Xueyuan Boulevard, Shenzhen, 518055, China, University of Chinese Academy of Sciences, 52 Sanlihe Road, Beijing, 100864, China; Elazab A., Shenzhen University, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen, 518060, China, Misr Higher Institute for Commerce and Computers, Department of Computer Science, Mansoura, 35516, Egypt; Jia F., Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, 1068 Xueyuan Boulevard, Shenzhen, 518055, China; Wu J., Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, 1068 Xueyuan Boulevard, Shenzhen, 518055, China; Hu Q., Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, 1068 Xueyuan Boulevard, Shenzhen, 518055, China, Key Laboratory of Human-Machine Intelligence Synergy Systems, 1068 Xueyuan Boulevard, Shenzhen, 518055, China","Objective: In this paper, we aim to investigate the effect of computer-aided triage system, which is implemented for the health checkup of lung lesions involving tens of thousands of chest X-rays (CXRs) that are required for diagnosis. Therefore, high accuracy of diagnosis by an automated system can reduce the radiologist's workload on scrutinizing the medical images. Method: We present a deep learning model in order to efficiently detect abnormal levels or identify normal levels during mass chest screening so as to obtain the probability confidence of the CXRs. Moreover, a convolutional sparse denoising autoencoder is designed to compute the reconstruction error. We employ four publicly available radiology datasets pertaining to CXRs, analyze their reports, and utilize their images for mining the correct disease level of the CXRs that are to be submitted to a computer aided triaging system. Based on our approach, we vote for the final decision from multi-classifiers to determine which three levels of the images (i.e. normal, abnormal, and uncertain cases) that the CXRs fall into. Results: We only deal with the grade diagnosis for physical examination and propose multiple new metric indices. Combining predictors for classification by using the area under a receiver operating characteristic curve, we observe that the final decision is related to the threshold from reconstruction error and the probability value. Our method achieves promising results in terms of precision of 98.7 and 94.3% based on the normal and abnormal cases, respectively. Conclusion: The results achieved by the proposed framework show superiority in classifying the disease level with high accuracy. This can potentially save the radiologists time and effort, so as to allow them to focus on higher-level risk CXRs. © 2018 The Author(s).","Autoencoder; Chest screening; Computer aided diagnosis; Deep learning; Receiver operating characteristic","Automation; Humans; Image Processing, Computer-Assisted; Lung; Machine Learning; Radiography, Thoracic; ROC Curve; Signal-To-Noise Ratio; Triage; Automation; Computer aided instruction; Convolution; Deep learning; Medical imaging; Auto encoders; Automated systems; Denoising Autoencoder; Physical examinations; Receiver operating characteristic curves; Receiver operating characteristics; Reconstruction error; Transfer learning; area under the curve; Article; automation; controlled study; convolutional sparse denoising autoencoder; deep learning model; diagnostic accuracy; diagnostic test accuracy study; disease classification; human; image analysis; major clinical study; measurement precision; model; parameters; predictor variable; priority journal; probability value; receiver operating characteristic; reconstruction error; thorax examination; thorax radiography; transfer of learning; automation; diagnostic imaging; emergency health service; image processing; lung; machine learning; procedures; signal noise ratio; thorax radiography; Computer aided diagnosis","BioMed Central Ltd.","1475925X","","BEOIB","29792208","Article","Scopus","2-s2.0-85047449643"
"Choi H.; Jin K.H.","Choi, Hongyoon (45760940100); Jin, Kyong Hwan (55153576800)","45760940100; 55153576800","Predicting cognitive decline with deep learning of brain metabolism and amyloid imaging","2018","Behavioural Brain Research","171","10.1016/j.bbr.2018.02.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042233822&doi=10.1016%2fj.bbr.2018.02.017&partnerID=40&md5=dfbc00554135341d2fc75a39dee1d1c5","Cheonan Public Health Center, Chungnam, South Korea; Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland; Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","Choi H., Cheonan Public Health Center, Chungnam, South Korea; Jin K.H., Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland, Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","For effective treatment of Alzheimer's disease (AD), it is important to identify subjects who are most likely to exhibit rapid cognitive decline. We aimed to develop an automatic image interpretation system based on a deep convolutional neural network (CNN) which can accurately predict future cognitive decline in mild cognitive impairment (MCI) patients using flurodeoxyglucose and florbetapir positron emission tomography (PET). PET images of 139 patients with AD, 171 patients with MCI and 182 normal subjects obtained from Alzheimer's Disease Neuroimaging Initiative database were used. Deep CNN was trained using 3-dimensional PET volumes of AD and normal controls as inputs. Manually defined image feature extraction such as quantification using predefined region-of-interests was unnecessary for our approach. Furthermore, it used minimally processed images without spatial normalization which has been commonly used in conventional quantitative analyses. Cognitive outcome of MCI subjects was predicted using this network. The prediction accuracy of the conversion of mild cognitive impairment to AD was compared with the conventional feature-based quantification approach. Accuracy of prediction (84.2%) for conversion to AD in MCI patients outperformed conventional feature-based quantification approaches. ROC analyses revealed that performance of CNN-based approach was significantly higher than that of the conventional quantification methods (p < 0.05). Output scores of the network were strongly correlated with the longitudinal change in cognitive measurements (p < 0.05). These results show the feasibility of deep learning as a practical tool for developing predictive neuroimaging biomarker. © 2018 Elsevier B.V.","Alzheimer's disease; Amyloid; Brain PET; Convolutional neural network; Deep learning","Aged; Alzheimer Disease; Amyloid; Aniline Compounds; Brain; Cognitive Dysfunction; Ethylene Glycols; Female; Fluorodeoxyglucose F18; Humans; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Male; Positron-Emission Tomography; Prognosis; Radiopharmaceuticals; Sensitivity and Specificity; Support Vector Machine; amyloid protein; amyloid; aniline derivative; ethylene glycol derivative; florbetapir; fluorodeoxyglucose f 18; radiopharmaceutical agent; aged; Alzheimer disease; Article; artificial neural network; brain metabolism; Clinical Dementia Rating; cognitive defect; controlled study; convolutional neural network; female; functional assessment; human; image analysis; image processing; imaging; institutional review; major clinical study; male; mild cognitive impairment; Mini Mental State Examination; neuroimaging; neuropsychology; positron emission tomography; principal component analysis; priority journal; support vector machine; Alzheimer disease; brain; classification; cognitive defect; computer assisted diagnosis; diagnostic imaging; metabolism; positron emission tomography; procedures; prognosis; sensitivity and specificity; three dimensional imaging","Elsevier B.V.","01664328","","BBRED","29454006","Article","Scopus","2-s2.0-85042233822"
"Takao S.; Kondo S.; Ueno J.; Kondo T.","Takao, Shoichiro (16313930600); Kondo, Sayaka (57192074965); Ueno, Junji (7003362675); Kondo, Tadashi (55450770300)","16313930600; 57192074965; 7003362675; 55450770300","Medical image analysis of abdominal X-ray CT images by deep multi-layered GMDH-type neural network","2018","Artificial Life and Robotics","0","10.1007/s10015-017-0420-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038879576&doi=10.1007%2fs10015-017-0420-z&partnerID=40&md5=4b508a034cd3806fc87c2c6500b80228","Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan; Tokushima Medical Informatics Laboratory, 264-5 Otubo Hachiman-cho, Tokushima, 770-8079, Japan","Takao S., Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan; Kondo S., Tokushima Medical Informatics Laboratory, 264-5 Otubo Hachiman-cho, Tokushima, 770-8079, Japan; Ueno J., Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan; Kondo T., Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan","In this study, a deep multi-layered group method of data handling (GMDH)-type neural network is applied to the medical image analysis of the abdominal X-ray computed tomography (CT) images. The deep neural network architecture which has many hidden layers are automatically organized using the deep multi-layered GMDH-type neural network algorithm so as to minimize the prediction error criterion defined as Akaike’s information criterion (AIC) or prediction sum of squares (PSS). The characteristics of the medical images are very complex and therefore the deep neural network architecture is very useful for the medical image diagnosis and medical image recognition. In this study, it is shown that this deep multi-layered GMDH-type neural network is useful for the medical image analysis of abdominal X-ray CT images. © 2017, ISAROB.","Deep neural networks; GMDH; Machine learning; Medical image recognition","Data handling; Deep neural networks; Diagnosis; Image analysis; Image recognition; Learning systems; Medical imaging; Network architecture; Abdominal x-ray CT image; GMDH; GMDH-type neural networks; Group method of data handling; Information criterion; Medical image diagnosis; Prediction errors; X-ray computed tomography; Computerized tomography","Springer Tokyo","14335298","","","","Article","Scopus","2-s2.0-85038879576"
"Ross T.; Zimmerer D.; Vemuri A.; Isensee F.; Wiesenfarth M.; Bodenstedt S.; Both F.; Kessler P.; Wagner M.; Müller B.; Kenngott H.; Speidel S.; Kopp-Schneider A.; Maier-Hein K.; Maier-Hein L.","Ross, Tobias (56599889900); Zimmerer, David (57193016967); Vemuri, Anant (57204154167); Isensee, Fabian (57194378532); Wiesenfarth, Manuel (36444977300); Bodenstedt, Sebastian (38560976600); Both, Fabian (57190138261); Kessler, Philip (57201745502); Wagner, Martin (56720705200); Müller, Beat (14322034300); Kenngott, Hannes (23097654000); Speidel, Stefanie (22433983800); Kopp-Schneider, Annette (7004190688); Maier-Hein, Klaus (55647018100); Maier-Hein, Lena (22634618600)","56599889900; 57193016967; 57204154167; 57194378532; 36444977300; 38560976600; 57190138261; 57201745502; 56720705200; 14322034300; 23097654000; 22433983800; 7004190688; 55647018100; 22634618600","Exploiting the potential of unlabeled endoscopic video data with self-supervised learning","2018","International Journal of Computer Assisted Radiology and Surgery","93","10.1007/s11548-018-1772-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046042133&doi=10.1007%2fs11548-018-1772-0&partnerID=40&md5=9fac8eb95b6733a383ca587d8b19f4ed","Computer Assisted Medical Interventions, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Medical Image Computing, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Division of Biostatistics, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Translational Surgical Oncology, National Center for Tumor Diseases (NCT), Fetscherstrasse 74, Dresden, 01307, Germany; Department of General, Visceral and Transplant Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69210, Germany; understand.ai, Hirschstr. 71, Karlsruhe, 76133, Germany","Ross T., Computer Assisted Medical Interventions, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Zimmerer D., Medical Image Computing, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Vemuri A., Computer Assisted Medical Interventions, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Isensee F., Medical Image Computing, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Wiesenfarth M., Division of Biostatistics, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Bodenstedt S., Translational Surgical Oncology, National Center for Tumor Diseases (NCT), Fetscherstrasse 74, Dresden, 01307, Germany; Both F., understand.ai, Hirschstr. 71, Karlsruhe, 76133, Germany; Kessler P., understand.ai, Hirschstr. 71, Karlsruhe, 76133, Germany; Wagner M., Department of General, Visceral and Transplant Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69210, Germany; Müller B., Department of General, Visceral and Transplant Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69210, Germany; Kenngott H., Department of General, Visceral and Transplant Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69210, Germany; Speidel S., Translational Surgical Oncology, National Center for Tumor Diseases (NCT), Fetscherstrasse 74, Dresden, 01307, Germany; Kopp-Schneider A., Division of Biostatistics, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Maier-Hein K., Medical Image Computing, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany; Maier-Hein L., Computer Assisted Medical Interventions, German Cancer Research Center, Im Neuenheimer Feld 581, Heidelberg, 69210, Germany","Purpose: Surgical data science is a new research field that aims to observe all aspects of the patient treatment process in order to provide the right assistance at the right time. Due to the breakthrough successes of deep learning-based solutions for automatic image annotation, the availability of reference annotations for algorithm training is becoming a major bottleneck in the field. The purpose of this paper was to investigate the concept of self-supervised learning to address this issue. Methods: Our approach is guided by the hypothesis that unlabeled video data can be used to learn a representation of the target domain that boosts the performance of state-of-the-art machine learning algorithms when used for pre-training. Core of the method is an auxiliary task based on raw endoscopic video data of the target domain that is used to initialize the convolutional neural network (CNN) for the target task. In this paper, we propose the re-colorization of medical images with a conditional generative adversarial network (cGAN)-based architecture as auxiliary task. A variant of the method involves a second pre-training step based on labeled data for the target task from a related domain. We validate both variants using medical instrument segmentation as target task. Results: The proposed approach can be used to radically reduce the manual annotation effort involved in training CNNs. Compared to the baseline approach of generating annotated data from scratch, our method decreases exploratively the number of labeled images by up to 75% without sacrificing performance. Our method also outperforms alternative methods for CNN pre-training, such as pre-training on publicly available non-medical (COCO) or medical data (MICCAI EndoVis2017 challenge) using the target task (in this instance: segmentation). Conclusion: As it makes efficient use of available (non-)public and (un-)labeled data, the approach has the potential to become a valuable tool for CNN (pre-)training. © 2018, CARS.","Computer vision; Endoscopic image processing; Endoscopic instrument segmentation; Self-supervised learning; Transfer learning","Algorithms; Endoscopy; Humans; Neural Networks (Computer); Supervised Machine Learning; Video Recording; algorithm; Article; artificial neural network; conditional generative adversarial network; convolutional neural network; priority journal; self supervised learning; supervised machine learning; surgical training; videoendoscopy; algorithm; artificial neural network; education; endoscopy; human; videorecording","Springer Verlag","18616410","","","29704196","Article","Scopus","2-s2.0-85046042133"
"Lakhani P.; Gray D.L.; Pett C.R.; Nagy P.; Shih G.","Lakhani, Paras (8763051900); Gray, Daniel L. (57201900895); Pett, Carl R. (57201897147); Nagy, Paul (35253892000); Shih, George (57203077410)","8763051900; 57201900895; 57201897147; 35253892000; 57203077410","Hello World Deep Learning in Medical Imaging","2018","Journal of Digital Imaging","76","10.1007/s10278-018-0079-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046453650&doi=10.1007%2fs10278-018-0079-6&partnerID=40&md5=55d42e557273e95647f86a95fba2e10f","Department of Radiology, Sidney Kimmel Jefferson Medical College, Thomas Jefferson University Hospital, Philadelphia, 19107, PA, United States; Sidney Kimmel Jefferson Medical College, Philadelphia, PA, United States; Department of Radiology, Johns Hopkins University School of Medicine, Baltimore, MD, United States; Division of Health Science Informatics, Johns Hopkins University School of Public Health, Baltimore, MD, United States; Department of Radiology, Weill Cornell Medical College, New York, NY, United States","Lakhani P., Department of Radiology, Sidney Kimmel Jefferson Medical College, Thomas Jefferson University Hospital, Philadelphia, 19107, PA, United States; Gray D.L., Sidney Kimmel Jefferson Medical College, Philadelphia, PA, United States; Pett C.R., Sidney Kimmel Jefferson Medical College, Philadelphia, PA, United States; Nagy P., Department of Radiology, Johns Hopkins University School of Medicine, Baltimore, MD, United States, Division of Health Science Informatics, Johns Hopkins University School of Public Health, Baltimore, MD, United States; Shih G., Department of Radiology, Weill Cornell Medical College, New York, NY, United States","There is recent popularity in applying machine learning to medical imaging, notably deep learning, which has achieved state-of-the-art performance in image analysis and processing. The rapid adoption of deep learning may be attributed to the availability of machine learning frameworks and libraries to simplify their use. In this tutorial, we provide a high-level overview of how to build a deep neural network for medical image classification, and provide code that can help those new to the field begin their informatics projects. © 2018, The Author(s).","Artificial neural networks; Deep learning; Machine learning; Medical imaging","Deep Learning; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Radiology; Deep learning; Deep neural networks; Learning systems; Neural networks; Informatics; State-of-the-art performance; diagnostic imaging; education; human; image processing; procedures; radiology; Medical imaging","Springer New York LLC","08971889","","JDIME","29725961","Article","Scopus","2-s2.0-85046453650"
"Song G.; Wang Z.; Han F.; Ding S.; Iqbal M.A.","Song, Guangxiao (57196328125); Wang, Zhijie (7410042055); Han, Fang (57204461950); Ding, Shenyi (57196326823); Iqbal, Muhammad Ather (57220698470)","57196328125; 7410042055; 57204461950; 57196326823; 57220698470","Music auto-tagging using deep Recurrent Neural Networks","2018","Neurocomputing","34","10.1016/j.neucom.2018.02.076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042904204&doi=10.1016%2fj.neucom.2018.02.076&partnerID=40&md5=61bfe284c817e3192d9ca046c1465748","College of Information Science and Technology, Donghua University, Shanghai, 201620, China","Song G., College of Information Science and Technology, Donghua University, Shanghai, 201620, China; Wang Z., College of Information Science and Technology, Donghua University, Shanghai, 201620, China; Han F., College of Information Science and Technology, Donghua University, Shanghai, 201620, China; Ding S., College of Information Science and Technology, Donghua University, Shanghai, 201620, China; Iqbal M.A., College of Information Science and Technology, Donghua University, Shanghai, 201620, China","Musical tags are used to describe music and are cruxes of music information retrieval. Existing methods for music auto-tagging usually consist of preprocessing phase (feature extraction) and machine learning phase. However, the preprocessing phase of most existing method is suffered either information loss or non-sufficient features, while the machine learning phase depends on heavily the feature extracted in the preprocessing phase, lacking the ability to make use of information. To solve this problem, we propose a content-based automatic tagging algorithm using deep Recurrent Neural Network (RNN) with scattering transformed inputs in this paper. Acting as the first phase, scattering transform extracts features from the raw data, meanwhile retains much more information than traditional methods such as mel-frequency cepstral coefficient (MFCC) and mel-frequency spectrogram. Five-layer RNNs with Gated Recurrent Unit (GRU) and sigmoid output layer are used as the second phase of our algorithm, which are extremely powerful machine learning tools capable of making full use of data fed to them. To evaluate the performance of the architecture, we experiment on Magnatagatune dataset using the measurement of the area under the ROC-curve (AUC-ROC). Experimental results show that the tagging performance can be boosted by the proposed method compared with the state-of-the-art models. Additionally, our architecture results in faster training speed and less memory usage. © 2018 Elsevier B.V.","Deep learning; Music auto-tagging; Music information retrieval; Recurrent Neural Network","Artificial intelligence; Deep learning; Deep neural networks; Information retrieval; Information use; Learning systems; Network architecture; Speech recognition; Area under the ROC curve; Auto tagging; Automatic tagging; Mel frequency cepstral coefficients (MFCC); Music information retrieval; Preprocessing phase; Recurrent neural network (RNN); Scattering transforms; area under the curve; Article; artificial neural network; content analysis; information processing; information retrieval; machine learning; mathematical analysis; music; priority journal; receiver operating characteristic; wavelet analysis; Recurrent neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85042904204"
"Kilinc O.; Uysal I.","Kilinc, Ozsel (57189351699); Uysal, Ismail (18042896600)","57189351699; 18042896600","GAR: An efficient and scalable graph-based activity regularization for semi-supervised learning","2018","Neurocomputing","24","10.1016/j.neucom.2018.03.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045188203&doi=10.1016%2fj.neucom.2018.03.028&partnerID=40&md5=cdb91ffade79d2bfd62078d7c47d1436","Electrical Engineering Department, University of South Florida, Tampa, 33620, FL, United States","Kilinc O., Electrical Engineering Department, University of South Florida, Tampa, 33620, FL, United States; Uysal I., Electrical Engineering Department, University of South Florida, Tampa, 33620, FL, United States","In this paper, we propose a novel graph-based approach for semi-supervised learning problems, which considers an adaptive adjacency of the examples throughout the unsupervised portion of the training. Adjacency of the examples is inferred using the predictions of a neural network model which is first initialized by a supervised pretraining. These predictions are then updated according to a novel unsupervised objective which regularizes another adjacency, now linking the output nodes. Regularizing the adjacency of the output nodes, inferred from the predictions of the network, creates an easier optimization problem and ultimately provides that the predictions of the network turn into the optimal embedding. Ultimately, the proposed framework provides an effective and scalable graph-based solution which is natural to the operational mechanism of deep neural networks. Our results show comparable performance with state-of-the-art generative approaches for semi-supervised learning on an easier-to-train, low-cost framework. © 2018","Graph-based; Neural networks; Semi-supervised learning","Deep neural networks; Forecasting; Graphic methods; Neural networks; Graph-based; Graph-based solution; Neural network model; Operational mechanism; Optimal embedding; Optimization problems; Semi- supervised learning; State of the art; Article; artificial neural network; calculation; data analysis; data synthesis; machine learning; mathematical computing; prediction; priority journal; process optimization; Supervised learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85045188203"
"Ahn J.; Park J.; Park D.; Paek J.; Ko J.","Ahn, Jungmo (57191892826); Park, JaeYeon (57191892662); Park, Donghwan (7403245696); Paek, Jeongyeup (12789639400); Ko, JeongGil (24822444000)","57191892826; 57191892662; 7403245696; 12789639400; 24822444000","Convolutional neural network-based classification system design with compressed wireless sensor network images","2018","PLoS ONE","25","10.1371/journal.pone.0196251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046697444&doi=10.1371%2fjournal.pone.0196251&partnerID=40&md5=3e1b42379c8dae5fa8720317d50cebaa","Department of Computer Engineering, Ajou University, Suwon, South Korea; Electronics and Telecommunications Research Institute, Daejeon, South Korea; School of Computer Science & Engineering, Chung-Ang University, Seoul, South Korea","Ahn J., Department of Computer Engineering, Ajou University, Suwon, South Korea; Park J., Department of Computer Engineering, Ajou University, Suwon, South Korea; Park D., Electronics and Telecommunications Research Institute, Daejeon, South Korea; Paek J., School of Computer Science & Engineering, Chung-Ang University, Seoul, South Korea; Ko J., Department of Computer Engineering, Ajou University, Suwon, South Korea","With the introduction of various advanced deep learning algorithms, initiatives for image classification systems have transitioned over from traditional machine learning algorithms (e.g., SVM) to Convolutional Neural Networks (CNNs) using deep learning software tools. A prerequisite in applying CNN to real world applications is a system that collects meaningful and useful data. For such purposes, Wireless Image Sensor Networks (WISNs), that are capable of monitoring natural environment phenomena using tiny and low-power cameras on resource-limited embedded devices, can be considered as an effective means of data collection. However, with limited battery resources, sending high-resolution raw images to the backend server is a burdensome task that has direct impact on network lifetime. To address this problem, we propose an energy-efficient pre- and post- processing mechanism using image resizing and color quantization that can significantly reduce the amount of data transferred while maintaining the classification accuracy in the CNN at the backend server. We show that, if well designed, an image in its highly compressed form can be well-classified with a CNN model trained in advance using adequately compressed data. Our evaluation using a real image dataset shows that an embedded device can reduce the amount of transmitted data by *71% while maintaining a classification accuracy of *98%. Under the same conditions, this process naturally reduces energy consumption by *71% compared to a WISN that sends the original uncompressed images. © 2018 Ahn et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Animals; Biosensing Techniques; Birds; Data Collection; Environmental Monitoring; Humans; Machine Learning; Nesting Behavior; Neural Networks (Computer); Software; Wireless Technology; accuracy; Article; artificial neural network; classification; classifier; color; convolutional neural network; energy consumption; energy cost; image processing; information processing; wireless image sensor network; algorithm; animal; bird; devices; environmental monitoring; genetic procedures; growth, development and aging; human; machine learning; nesting; procedures; software; wireless communication","Public Library of Science","19326203","","POLNC","29738564","Article","Scopus","2-s2.0-85046697444"
"Marciano M.A.; Williamson V.R.; Adelman J.D.","Marciano, Michael A. (57192696092); Williamson, Victoria R. (57201395674); Adelman, Jonathan D. (57192692517)","57192696092; 57201395674; 57192692517","A hybrid approach to increase the informedness of CE-based data using locus-specific thresholding and machine learning","2018","Forensic Science International: Genetics","10","10.1016/j.fsigen.2018.03.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044931692&doi=10.1016%2fj.fsigen.2018.03.017&partnerID=40&md5=dae6880ab0e8da5ea13a961ebf359d9b","Forensic & National Security Sciences Institute, Syracuse University, 107 College Place 120 Life Science Building, Syracuse, 13244, NY, United States; County of Erie, Department of Central Police Services, Forensic Laboratory, 45 Elm Street, Buffalo, 14203, NY, United States","Marciano M.A., Forensic & National Security Sciences Institute, Syracuse University, 107 College Place 120 Life Science Building, Syracuse, 13244, NY, United States; Williamson V.R., Forensic & National Security Sciences Institute, Syracuse University, 107 College Place 120 Life Science Building, Syracuse, 13244, NY, United States, County of Erie, Department of Central Police Services, Forensic Laboratory, 45 Elm Street, Buffalo, 14203, NY, United States; Adelman J.D., Forensic & National Security Sciences Institute, Syracuse University, 107 College Place 120 Life Science Building, Syracuse, 13244, NY, United States","The interpretation of genetic profiles require a robust and reliable method to discriminate true allelic information from noise, regardless of the instrumentation or methods used. Traditionally, static peak detection thresholds (analytical thresholds) have been applied to capillary electrophoresis generated data to distinguish the true allelic peaks from noise. While the rigid nature of these thresholds attempts to conservatively account for baseline variability across instrument runs, samples, capillaries, dye-channels, injection times, and voltage, its static nature is unable to adapt, leading to a loss of allelic information that exists below the threshold. The method described herein is able to account for this variability by collectively minimizing the incorrect detection of non-allelic artifacts (false positives) and the threshold-induced dropout of true allelic information (false negatives). This is accomplished by using a dynamic locus and sample specific analytical threshold and a machine learning-derived probabilistic artifact detection model. The system produced an allele detection accuracy of 97.2%, an 11.4% increase from the lowest static threshold (50 RFU), with a low incidence of incorrectly identified artifacts (0.79%). This adaptive method outperformed static thresholds in the retention of allelic information content at minimal cost. © 2018 Elsevier B.V.","Analytical threshold; Artifact removal; Baseline; Capillary electrophoresis; Deep learning; Forensic DNA; Machine learning; Random forest; Support vector machine","Algorithms; Alleles; Artifacts; DNA Fingerprinting; Electrophoresis, Capillary; Humans; Machine Learning; allele; Article; artifact; capillary electrophoresis; comparative study; deep learning; DNA template; false negative result; false positive result; forensic genetics; gene amplification; human; information processing; intelligent locus sample specific threshold and noise reducer system; learning algorithm; learning curve; machine learning; measurement accuracy; measurement precision; noise reduction; predictive value; priority journal; random forest; recall bias; receiver operating characteristic; support vector machine; trimming algorithm; algorithm; allele; DNA fingerprinting","Elsevier Ireland Ltd","18724973","","","29627762","Article","Scopus","2-s2.0-85044931692"
"Hammernik K.; Klatzer T.; Kobler E.; Recht M.P.; Sodickson D.K.; Pock T.; Knoll F.","Hammernik, Kerstin (55842869200); Klatzer, Teresa (57190393374); Kobler, Erich (57195721601); Recht, Michael P. (57092040000); Sodickson, Daniel K. (6701665489); Pock, Thomas (6506341512); Knoll, Florian (57212441954)","55842869200; 57190393374; 57195721601; 57092040000; 6701665489; 6506341512; 57212441954","Learning a variational network for reconstruction of accelerated MRI data","2018","Magnetic Resonance in Medicine","973","10.1002/mrm.26977","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043388139&doi=10.1002%2fmrm.26977&partnerID=40&md5=9a09eaac783c3a747400270efc9e662e","Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Center for Biomedical Imaging, Department of Radiology, NYU School of Medicine, New York, NY, United States; R), NYU School of Medicine, New York, NY, United States; Center for Vision, Automation & Control, AIT Austrian Institute of Technology GmbH, Vienna, Austria","Hammernik K., Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Klatzer T., Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Kobler E., Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Recht M.P., Center for Biomedical Imaging, Department of Radiology, NYU School of Medicine, New York, NY, United States, R), NYU School of Medicine, New York, NY, United States; Sodickson D.K., Center for Biomedical Imaging, Department of Radiology, NYU School of Medicine, New York, NY, United States, R), NYU School of Medicine, New York, NY, United States; Pock T., Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria, Center for Vision, Automation & Control, AIT Austrian Institute of Technology GmbH, Vienna, Austria; Knoll F., Center for Biomedical Imaging, Department of Radiology, NYU School of Medicine, New York, NY, United States, R), NYU School of Medicine, New York, NY, United States","Purpose: To allow fast and high-quality reconstruction of clinical accelerated multi-coil MR data by learning a variational network that combines the mathematical structure of variational models with deep learning. Theory and Methods: Generalized compressed sensing reconstruction formulated as a variational model is embedded in an unrolled gradient descent scheme. All parameters of this formulation, including the prior model defined by filter kernels and activation functions as well as the data term weights, are learned during an offline training procedure. The learned model can then be applied online to previously unseen data. Results: The variational network approach is evaluated on a clinical knee imaging protocol for different acceleration factors and sampling patterns using retrospectively and prospectively undersampled data. The variational network reconstructions outperform standard reconstruction algorithms, verified by quantitative error measures and a clinical reader study for regular sampling and acceleration factor 4. Conclusion: Variational network reconstructions preserve the natural appearance of MR images as well as pathologies that were not included in the training data set. Due to its high computational performance, that is, reconstruction time of 193 ms on a single graphics card, and the omission of parameter tuning once the network is trained, this new approach to image reconstruction can easily be integrated into clinical workflow. Magn Reson Med 79:3055–3071, 2018. © 2017 International Society for Magnetic Resonance in Medicine. © 2017 International Society for Magnetic Resonance in Medicine","accelerated MRI; compressed sensing; deep learning; image reconstruction; parallel imaging; variational network","Adolescent; Adult; Aged; Algorithms; Computer Simulation; Data Compression; Female; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Linear Models; Machine Learning; Magnetic Resonance Imaging; Male; Middle Aged; Reproducibility of Results; Retrospective Studies; Young Adult; Compressed sensing; Computation theory; Deep learning; Gradient methods; Magnetic resonance; Magnetic resonance imaging; Medicine; Soldered joints; Activation functions; Computational performance; High quality reconstruction; International society; Mathematical structure; Network reconstruction; Parallel imaging; Reconstruction algorithms; Article; artifact reduction; controlled study; image quality; image reconstruction; mathematical computing; mathematical model; nuclear magnetic resonance imaging; signal noise ratio; adolescent; adult; aged; algorithm; computer assisted diagnosis; computer simulation; female; human; image processing; information processing; machine learning; male; middle aged; procedures; reproducibility; retrospective study; statistical model; young adult; Image reconstruction","John Wiley and Sons Inc","07403194","","MRMEE","29115689","Article","Scopus","2-s2.0-85043388139"
"Gupta S.; Pawar S.; Ramrakhiyani N.; Palshikar G.K.; Varma V.","Gupta, Shashank (57211862439); Pawar, Sachin (55654994400); Ramrakhiyani, Nitin (56023779500); Palshikar, Girish Keshav (55890466600); Varma, Vasudeva (16053729400)","57211862439; 55654994400; 56023779500; 55890466600; 16053729400","Semi-Supervised Recurrent Neural Network for Adverse Drug Reaction mention extraction","2018","BMC Bioinformatics","31","10.1186/s12859-018-2192-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048287010&doi=10.1186%2fs12859-018-2192-4&partnerID=40&md5=e4c110d504ee077af6953d581e6e69aa","Information Retrieval and Extraction Laboratory, Kohli Center for Intelligent Systems, International Institute of Information Technology, Hyderabad, India; Tata Consultancy Services (TCS) Research, 54-B, Hadapsar Industrial Area, Pune, India","Gupta S., Information Retrieval and Extraction Laboratory, Kohli Center for Intelligent Systems, International Institute of Information Technology, Hyderabad, India; Pawar S., Tata Consultancy Services (TCS) Research, 54-B, Hadapsar Industrial Area, Pune, India; Ramrakhiyani N., Information Retrieval and Extraction Laboratory, Kohli Center for Intelligent Systems, International Institute of Information Technology, Hyderabad, India, Tata Consultancy Services (TCS) Research, 54-B, Hadapsar Industrial Area, Pune, India; Palshikar G.K., Tata Consultancy Services (TCS) Research, 54-B, Hadapsar Industrial Area, Pune, India; Varma V., Information Retrieval and Extraction Laboratory, Kohli Center for Intelligent Systems, International Institute of Information Technology, Hyderabad, India","Background: Social media is a useful platform to share health-related information due to its vast reach. This makes it a good candidate for public-health monitoring tasks, specifically for pharmacovigilance. We study the problem of extraction of Adverse-Drug-Reaction (ADR) mentions from social media, particularly from Twitter. Medical information extraction from social media is challenging, mainly due to short and highly informal nature of text, as compared to more technical and formal medical reports. Methods: Current methods in ADR mention extraction rely on supervised learning methods, which suffer from labeled data scarcity problem. The state-of-the-art method uses deep neural networks, specifically a class of Recurrent Neural Network (RNN) which is Long-Short-Term-Memory network (LSTM). Deep neural networks, due to their large number of free parameters rely heavily on large annotated corpora for learning the end task. But in the real-world, it is hard to get large labeled data, mainly due to the heavy cost associated with the manual annotation. Results: To this end, we propose a novel semi-supervised learning based RNN model, which can leverage unlabeled data also present in abundance on social media. Through experiments we demonstrate the effectiveness of our method, achieving state-of-the-art performance in ADR mention extraction. Conclusion: In this study, we tackle the problem of labeled data scarcity for Adverse Drug Reaction mention extraction from social media and propose a novel semi-supervised learning based method which can leverage large unlabeled corpus available in abundance on the web. Through empirical study, we demonstrate that our proposed method outperforms fully supervised learning based baseline which relies on large manually annotated corpus for a good performance. © 2018 The Author(s).","Pharmacovigilance; Recurrent neural networks; Semi-supervised learning","Databases as Topic; Drug-Related Side Effects and Adverse Reactions; Humans; Information Storage and Retrieval; Neural Networks (Computer); Social Media; Supervised Machine Learning; Data mining; Deep neural networks; Pharmacodynamics; Recurrent neural networks; Social networking (online); Supervised learning; Adverse drug reactions; Health related informations; Pharmacovigilance; Recurrent neural network (RNN); Semi- supervised learning; State-of-the-art methods; State-of-the-art performance; Supervised learning methods; adverse drug reaction; artificial neural network; data base; human; information retrieval; pathology; social media; supervised machine learning; Long short-term memory","BioMed Central Ltd.","14712105","","BBMIC","29897321","Article","Scopus","2-s2.0-85048287010"
"Khellal A.; Ma H.; Fei Q.","Khellal, Atmane (57190980310); Ma, Hongbin (55723483600); Fei, Qing (8256742900)","57190980310; 55723483600; 8256742900","Convolutional neural network based on extreme learning machine for maritime ships recognition in infrared images","2018","Sensors (Switzerland)","56","10.3390/s18051490","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046741027&doi=10.3390%2fs18051490&partnerID=40&md5=40a5a35f5596765029d0cdb1048299ac","School of Automation, Beijing Institute of Technology, Beijing, 100081, China; State Key Laboratory of Intelligent Control and Decision of Complex Systems, Beijing Institute of Technology, Beijing, 100081, China","Khellal A., School of Automation, Beijing Institute of Technology, Beijing, 100081, China; Ma H., School of Automation, Beijing Institute of Technology, Beijing, 100081, China, State Key Laboratory of Intelligent Control and Decision of Complex Systems, Beijing Institute of Technology, Beijing, 100081, China; Fei Q., School of Automation, Beijing Institute of Technology, Beijing, 100081, China, State Key Laboratory of Intelligent Control and Decision of Complex Systems, Beijing Institute of Technology, Beijing, 100081, China","The success of Deep Learning models, notably convolutional neural networks (CNNs), makes them the favorable solution for object recognition systems in both visible and infrared domains. However, the lack of training data in the case of maritime ships research leads to poor performance due to the problem of overfitting. In addition, the back-propagation algorithm used to train CNN is very slow and requires tuning many hyperparameters. To overcome these weaknesses, we introduce a new approach fully based on Extreme Learning Machine (ELM) to learn useful CNN features and perform a fast and accurate classification, which is suitable for infrared-based recognition systems. The proposed approach combines an ELM based learning algorithm to train CNN for discriminative features extraction and an ELM based ensemble for classification. The experimental results on VAIS dataset, which is the largest dataset of maritime ships, confirm that the proposed approach outperforms the state-of-the-art models in term of generalization performance and training speed. For instance, the proposed model is up to 950 times faster than the traditional back-propagation based training of convolutional neural networks, primarily for low-level features extraction. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Classification; Convolutional neural network; Ensemble; Extreme learning machine; Features extraction; Infrared images; Maritime ships recognition; VAIS dataset","Backpropagation algorithms; Classification (of information); Convolution; Deep learning; Extraction; Infrared imaging; Knowledge acquisition; Learning algorithms; Neural networks; Object recognition; Ships; Convolutional neural network; Ensemble; Extreme learning machine; Features extraction; Maritime ships recognition; VAIS dataset; article; back propagation; convolutional neural network; extraction; infrared radiation; learning algorithm; ship; velocity; Vehicle performance","MDPI AG","14248220","","","29747439","Article","Scopus","2-s2.0-85046741027"
"Interian Y.; Rideout V.; Kearney V.P.; Gennatas E.; Morin O.; Cheung J.; Solberg T.; Valdes G.","Interian, Yannet (8876239700); Rideout, Vincent (57201691569); Kearney, Vasant P. (56449200500); Gennatas, Efstathios (36010538800); Morin, Olivier (12761697100); Cheung, Joey (55419306500); Solberg, Timothy (57204614205); Valdes, Gilmer (55875962300)","8876239700; 57201691569; 56449200500; 36010538800; 12761697100; 55419306500; 57204614205; 55875962300","Deep nets vs expert designed features in medical physics: An IMRT QA case study","2018","Medical Physics","85","10.1002/mp.12890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045763724&doi=10.1002%2fmp.12890&partnerID=40&md5=d6b3f373b680e09f6338df38bf916c2b","MS in Analytics Program, University of San Francisco, San Francisco, CA, United States; Department of Radiation Oncology, University of California San Francisco, San Francisco, CA, United States","Interian Y., MS in Analytics Program, University of San Francisco, San Francisco, CA, United States; Rideout V., MS in Analytics Program, University of San Francisco, San Francisco, CA, United States; Kearney V.P., Department of Radiation Oncology, University of California San Francisco, San Francisco, CA, United States; Gennatas E., Department of Radiation Oncology, University of California San Francisco, San Francisco, CA, United States; Morin O., Department of Radiation Oncology, University of California San Francisco, San Francisco, CA, United States; Cheung J., Department of Radiation Oncology, University of California San Francisco, San Francisco, CA, United States; Solberg T., Department of Radiation Oncology, University of California San Francisco, San Francisco, CA, United States; Valdes G., Department of Radiation Oncology, University of California San Francisco, San Francisco, CA, United States","Purpose: The purpose of this study was to compare the performance of Deep Neural Networks against a technique designed by domain experts in the prediction of gamma passing rates for Intensity Modulated Radiation Therapy Quality Assurance (IMRT QA). Method: A total of 498 IMRT plans across all treatment sites were planned in Eclipse version 11 and delivered using a dynamic sliding window technique on Clinac iX or TrueBeam Linacs. Measurements were performed using a commercial 2D diode array, and passing rates for 3%/3 mm local dose/distance-to-agreement (DTA) were recorded. Separately, fluence maps calculated for each plan were used as inputs to a convolution neural network (CNN). The CNNs were trained to predict IMRT QA gamma passing rates using TensorFlow and Keras. A set of model architectures, inspired by the convolutional blocks of the VGG-16 ImageNet model, were constructed and implemented. Synthetic data, created by rotating and translating the fluence maps during training, was created to boost the performance of the CNNs. Dropout, batch normalization, and data augmentation were utilized to help train the model. The performance of the CNNs was compared to a generalized Poisson regression model, previously developed for this application, which used 78 expert designed features. Results: Deep Neural Networks without domain knowledge achieved comparable performance to a baseline system designed by domain experts in the prediction of 3%/3 mm Local gamma passing rates. An ensemble of neural nets resulted in a mean absolute error (MAE) of 0.70 ± 0.05 and the domain expert model resulted in a 0.74 ± 0.06. Conclusions: Convolutional neural networks (CNNs) with transfer learning can predict IMRT QA passing rates by automatically designing features from the fluence maps without human expert supervision. Predictions from CNNs are comparable to a system carefully designed by physicist experts. © 2018 American Association of Physicists in Medicine","IMRT; QA; quality assurance; radiation therapy; statistical analysis","Gamma Rays; Health Physics; Humans; Neural Networks (Computer); Particle Accelerators; Quality Assurance, Health Care; Radiotherapy Planning, Computer-Assisted; Radiotherapy, Intensity-Modulated; Convolution; Deep neural networks; Forecasting; Radiotherapy; Regression analysis; Statistical Physics; Assurance case; Case-studies; Convolutional neural network; Domain experts; Fluences; IMRT; Intensity-modulated radiation therapy; Medical physics; Performance; QA; Article; artificial neural network; clinical assessment; clinical feature; controlled study; convolution neural network; deep neural network; human; intensity modulated radiation therapy; machine learning; medical expert; outcome assessment; quality control; transfer of learning; treatment planning; comparative study; devices; drug therapy; gamma radiation; health care quality; health physics; intensity modulated radiation therapy; magnetic and electromagnetic equipment; procedures; radiotherapy planning system; Quality assurance","John Wiley and Sons Ltd","00942405","","MPHYA","29603278","Article","Scopus","2-s2.0-85045763724"
"Christmann A.; Xiang D.; Zhou D.-X.","Christmann, Andreas (55879593600); Xiang, Daohong (12807742100); Zhou, Ding-Xuan (7403394636)","55879593600; 12807742100; 7403394636","Total stability of kernel methods","2018","Neurocomputing","9","10.1016/j.neucom.2018.02.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042387905&doi=10.1016%2fj.neucom.2018.02.009&partnerID=40&md5=195396b9edcc3c6a65f48e991431757c","University of Bayreuth, Germany; Zhejiang Normal University, China; City University of Hong Kong, Hong Kong","Christmann A., University of Bayreuth, Germany; Xiang D., University of Bayreuth, Germany, Zhejiang Normal University, China; Zhou D.-X., City University of Hong Kong, Hong Kong","Regularized empirical risk minimization using kernels and their corresponding reproducing kernel Hilbert spaces (RKHSs) plays an important role in machine learning. However, the actually used kernel often depends on one or on a few hyperparameters or the kernel is even data dependent in a much more complicated manner. Examples are Gaussian RBF kernels, kernel learning, and hierarchical Gaussian kernels which were recently proposed for deep learning. Therefore, the actually used kernel is often computed by a grid search or in an iterative manner and can often only be considered as an approximation to the “ideal” or “optimal” kernel. The paper gives conditions under which classical kernel based methods based on a convex Lipschitz loss function and on a bounded and smooth kernel are stable, if the probability measure P, the regularization parameter λ and the kernel K may slightly change in a simultaneous manner. Similar results are also given for pairwise learning. Therefore, the topic of this paper is somewhat more general than in classical robust statistics, where usually only the influence of small perturbations of the probability measure P on the estimated function is considered. © 2018 Elsevier B.V.","Kernel; Machine learning; Regularization; Robustness; Stability","Artificial intelligence; Convergence of numerical methods; Iterative methods; Learning algorithms; Learning systems; Robustness (control systems); Empirical risk minimization; Kernel; Kernel based methods; Probability measures; Regularization; Regularization parameters; Reproducing Kernel Hilbert spaces; Small perturbations; Article; information processing; kernel method; limit of quantitation; Lipschitz constant; Lipschitz continuous loss function; mathematical analysis; priority journal; probability; radial based function; reproducing kernel Hilbert space; support vector machine; total stability theorem; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85042387905"
"Hauptmann A.; Lucka F.; Betcke M.; Huynh N.; Adler J.; Cox B.; Beard P.; Ourselin S.; Arridge S.","Hauptmann, Andreas (56180904900); Lucka, Felix (52364146500); Betcke, Marta (18041984600); Huynh, Nam (37103938100); Adler, Jonas (57193711251); Cox, Ben (7403198742); Beard, Paul (7006238023); Ourselin, Sebastien (6602233595); Arridge, Simon (7005759823)","56180904900; 52364146500; 18041984600; 37103938100; 57193711251; 7403198742; 7006238023; 6602233595; 7005759823","Model-Based Learning for Accelerated, Limited-View 3-D Photoacoustic Tomography","2018","IEEE Transactions on Medical Imaging","224","10.1109/TMI.2018.2820382","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044733678&doi=10.1109%2fTMI.2018.2820382&partnerID=40&md5=f67ffae48133e7e6bb65c9b17f1ce1af","Department of Computer Science, University College London, London, WC1E 6BT, United Kingdom; Centrum Wiskunde and Informatica, Amsterdam, 1098 XG, Netherlands; Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Department of Mathematics, KTH Royal Institute of Technology, Stockholm, 100 44, Sweden; Elekta, Stockholm, 103 93, Sweden","Hauptmann A., Department of Computer Science, University College London, London, WC1E 6BT, United Kingdom; Lucka F., Department of Computer Science, University College London, London, WC1E 6BT, United Kingdom, Centrum Wiskunde and Informatica, Amsterdam, 1098 XG, Netherlands; Betcke M., Department of Computer Science, University College London, London, WC1E 6BT, United Kingdom; Huynh N., Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Adler J., Department of Mathematics, KTH Royal Institute of Technology, Stockholm, 100 44, Sweden, Elekta, Stockholm, 103 93, Sweden; Cox B., Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Beard P., Department of Medical Physics and Biomedical Engineering, University College London, London, WC1E 6BT, United Kingdom; Ourselin S., Department of Computer Science, University College London, London, WC1E 6BT, United Kingdom; Arridge S., Department of Computer Science, University College London, London, WC1E 6BT, United Kingdom","Recent advances in deep learning for tomographic reconstructions have shown great potential to create accurate and high quality images with a considerable speed up. In this paper, we present a deep neural network that is specifically designed to provide high resolution 3-D images from restricted photoacoustic measurements. The network is designed to represent an iterative scheme and incorporates gradient information of the data fit to compensate for limited view artifacts. Due to the high complexity of the photoacoustic forward operator, we separate training and computation of the gradient information. A suitable prior for the desired image structures is learned as part of the training. The resulting network is trained and tested on a set of segmented vessels from lung computed tomography scans and then applied to in-vivo photoacoustic measurement data. © 2018 IEEE.","convolutional neural networks; Deep learning; iterative reconstruction; photoacoustic tomography","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Phantoms, Imaging; Photoacoustic Techniques; Deep learning; Deep neural networks; Image reconstruction; Learning systems; Neural networks; Personnel training; Photoacoustic effect; Television; Three dimensional computer graphics; Three dimensional displays; Tomography; Wave propagation; Computational model; Convolutional neural network; Gradient informations; Iterative reconstruction; Modeling-based learning; Photoacoustic measurements; Photoacoustic tomography; Tomographic reconstruction; article; artifact; human; image reconstruction; in vivo study; lung; machine learning; nervous system; photoacoustic tomography; x-ray computed tomography; algorithm; image processing; imaging phantom; photoacoustics; procedures; three dimensional imaging; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870367","Article","Scopus","2-s2.0-85044733678"
"Chen H.; Zhang Y.; Chen Y.; Zhang J.; Zhang W.; Sun H.; Lv Y.; Liao P.; Zhou J.; Wang G.","Chen, Hu (57189326786); Zhang, Yi (57203829244); Chen, Yunjin (55902679100); Zhang, Junfeng (56809427500); Zhang, Weihua (56151308100); Sun, Huaiqiang (56609493200); Lv, Yang (57207925024); Liao, Peixi (57193198003); Zhou, Jiliu (21234416400); Wang, Ge (7407148134)","57189326786; 57203829244; 55902679100; 56809427500; 56151308100; 56609493200; 57207925024; 57193198003; 21234416400; 7407148134","LEARN: Learned Experts' Assessment-Based Reconstruction Network for Sparse-Data CT","2018","IEEE Transactions on Medical Imaging","267","10.1109/TMI.2018.2805692","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042088719&doi=10.1109%2fTMI.2018.2805692&partnerID=40&md5=899632f16b2d85375bf3c0660eff18af","College of Computer Science, Sichuan University, Chengdu, 610065, China; ULSee Inc., Hangzhou, 310020, China; School of Computer and Information Engineering, Henan University of Economics and Law, Zhengzhou, 450046, China; Department of Radiology, West China Hospital of Sichuan University, Chengdu, 610041, China; Shanghai United Imaging Healthcare Co., Ltd., Shanghai, 210807, China; Department of Scientific Research and Education, Sixth People's Hospital of Chengdu, Chengdu, 610065, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, 12180, NY, United States","Chen H., College of Computer Science, Sichuan University, Chengdu, 610065, China; Zhang Y., College of Computer Science, Sichuan University, Chengdu, 610065, China; Chen Y., ULSee Inc., Hangzhou, 310020, China; Zhang J., School of Computer and Information Engineering, Henan University of Economics and Law, Zhengzhou, 450046, China; Zhang W., College of Computer Science, Sichuan University, Chengdu, 610065, China; Sun H., Department of Radiology, West China Hospital of Sichuan University, Chengdu, 610041, China; Lv Y., Shanghai United Imaging Healthcare Co., Ltd., Shanghai, 210807, China; Liao P., Department of Scientific Research and Education, Sixth People's Hospital of Chengdu, Chengdu, 610065, China; Zhou J., College of Computer Science, Sichuan University, Chengdu, 610065, China; Wang G., Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, 12180, NY, United States","Compressive sensing (CS) has proved effective for tomographic reconstruction from sparsely collected data or under-sampled measurements, which are practically important for few-view computed tomography (CT), tomosynthesis, interior tomography, and so on. To perform sparse-data CT, the iterative reconstruction commonly uses regularizers in the CS framework. Currently, how to choose the parameters adaptively for regularization is a major open problem. In this paper, inspired by the idea of machine learning especially deep learning, we unfold the state-of-the-art ""fields of experts""-based iterative reconstruction scheme up to a number of iterations for data-driven training, construct a learned experts' assessment-based reconstruction network (LEARN) for sparse-data CT, and demonstrate the feasibility and merits of our LEARN network. The experimental results with our proposed LEARN network produces a superior performance with the well-known Mayo Clinic low-dose challenge data set relative to the several state-of-the-art methods, in terms of artifact reduction, feature preservation, and computational speed. This is consistent to our insight that because all the regularization terms and parameters used in the iterative reconstruction are now learned from the training data, our LEARN network utilizes application-oriented knowledge more effectively and recovers underlying images more favorably than competing algorithms. Also, the number of layers in the LEARN network is only 50, reducing the computational complexity of typical iterative algorithms by orders of magnitude. © 2018 IEEE.","compressive sensing; Computed tomography (CT); deep learning; fields of experts; iterative reconstruction; machine learning; sparse-data CT","Algorithms; Databases, Factual; Deep Learning; Humans; Image Processing, Computer-Assisted; Radiography, Abdominal; Radiography, Thoracic; Tomography, X-Ray Computed; Artificial intelligence; Compressed sensing; Deep learning; Image reconstruction; Iterative methods; Learning systems; Medical imaging; Biomedical imaging; Compressive sensing; fields of experts; Iterative reconstruction; Sparse data; article; artifact reduction; computer assisted tomography; feasibility study; human; image reconstruction; low drug dose; machine learning; velocity; abdominal radiography; algorithm; factual database; image processing; procedures; thorax radiography; x-ray computed tomography; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870363","Article","Scopus","2-s2.0-85042088719"
"Zheng Y.-J.; Zhou X.-H.; Sheng W.-G.; Xue Y.; Chen S.-Y.","Zheng, Yu-Jun (55619294936); Zhou, Xiao-Han (57194625803); Sheng, Wei-Guo (56122524000); Xue, Yu (56501123700); Chen, Sheng-Yong (24491760700)","55619294936; 57194625803; 56122524000; 56501123700; 24491760700","Generative adversarial network based telecom fraud detection at the receiving bank","2018","Neural Networks","78","10.1016/j.neunet.2018.02.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044029801&doi=10.1016%2fj.neunet.2018.02.015&partnerID=40&md5=3e3e8f4f68985f925a502bbc4eb4c20d","Institute of Service Engineering, Hangzhou Normal University, Hangzhou, 311121, China; College of Computer Science & Technology, Zhejiang University of Technology, Hangzhou, 310023, China; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, 6140, New Zealand","Zheng Y.-J., Institute of Service Engineering, Hangzhou Normal University, Hangzhou, 311121, China, College of Computer Science & Technology, Zhejiang University of Technology, Hangzhou, 310023, China; Zhou X.-H., College of Computer Science & Technology, Zhejiang University of Technology, Hangzhou, 310023, China; Sheng W.-G., Institute of Service Engineering, Hangzhou Normal University, Hangzhou, 311121, China; Xue Y., School of Engineering and Computer Science, Victoria University of Wellington, Wellington, 6140, New Zealand; Chen S.-Y., College of Computer Science & Technology, Zhejiang University of Technology, Hangzhou, 310023, China","Recently telecom fraud has become a serious problem especially in developing countries such as China. At present, it can be very difficult to coordinate different agencies to prevent fraud completely. In this paper we study how to detect large transfers that are sent from victims deceived by fraudsters at the receiving bank. We propose a new generative adversarial network (GAN) based model to calculate for each large transfer a probability that it is fraudulent, such that the bank can take appropriate measures to prevent potential fraudsters to take the money if the probability exceeds a threshold. The inference model uses a deep denoising autoencoder to effectively learn the complex probabilistic relationship among the input features, and employs adversarial training that establishes a minimax game between a discriminator and a generator to accurately discriminate between positive samples and negative samples in the data distribution. We show that the model outperforms a set of well-known classification methods in experiments, and its applications in two commercial banks have reduced losses of about 10 million RMB in twelve weeks and significantly improved their business reputation. © 2018 Elsevier Ltd","Deep learning; Denoising autoencoder; Fraud detection; Generative adversarial network (GAN); Intelligent data analysis","Computer Communication Networks; Fraud; Humans; Machine Learning; Deep learning; Developing countries; Probability distributions; Adversarial networks; Classification methods; Data distribution; Denoising Autoencoder; Fraud detection; Intelligent data analysis; ITS applications; Negative samples; Article; artificial neural network; bank account; generative adversarial network; identity theft; money; priority journal; telecommunication; victim; computer network; fraud; human; machine learning; prevention and control; standards; Crime","Elsevier Ltd","08936080","","NNETE","29558653","Article","Scopus","2-s2.0-85044029801"
"Zhang L.; Lu Y.; Wang B.; Li F.; Zhang Z.","Zhang, Li (56066249200); Lu, Yaping (55506745400); Wang, Bangjun (55552238500); Li, Fanzhang (55650932000); Zhang, Zhao (56822575600)","56066249200; 55506745400; 55552238500; 55650932000; 56822575600","Sparse Auto-encoder with Smoothed l1 Regularization","2018","Neural Processing Letters","16","10.1007/s11063-017-9668-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021893182&doi=10.1007%2fs11063-017-9668-5&partnerID=40&md5=f5863e57d25bdda5e8b236085968f82f","School of Computer Science and Technology & Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, 215006, Jiangsu, China","Zhang L., School of Computer Science and Technology & Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, 215006, Jiangsu, China; Lu Y., School of Computer Science and Technology & Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, 215006, Jiangsu, China; Wang B., School of Computer Science and Technology & Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, 215006, Jiangsu, China; Li F., School of Computer Science and Technology & Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, 215006, Jiangsu, China; Zhang Z., School of Computer Science and Technology & Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, 215006, Jiangsu, China","Improving the performance on data representation of an auto-encoder could help to obtain a satisfying deep network. One of the strategies to enhance the performance is to incorporate sparsity into an auto-encoder. Fortunately, sparsity for the auto-encoder has been achieved by adding a Kullback–Leibler (KL) divergence term to the risk functional. In compressive sensing and machine learning, it is well known that the l1 regularization is a widely used technique which can induce sparsity. Thus, this paper introduces a smoothed l1 regularization instead of the mostly used KL divergence to enforce sparsity for auto-encoders. Experimental results show that the smoothed l1 regularization works better than the KL divergence. © 2017, Springer Science+Business Media, LLC.","Auto-encoder; Data representation; KL divergence; Smoothed l<sub>1</sub> regularization; Sparsity","Signal encoding; Auto encoders; Data representations; KL-divergence; Smoothed $$l_1$$l1regularization; Sparsity; Learning systems","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-85021893182"
"Allman D.; Reiter A.; Bell M.A.L.","Allman, Derek (57200087368); Reiter, Austin (24072196400); Bell, Muyinatu A. Lediju (25936417400)","57200087368; 24072196400; 25936417400","Photoacoustic Source Detection and Reflection Artifact Removal Enabled by Deep Learning","2018","IEEE Transactions on Medical Imaging","158","10.1109/TMI.2018.2829662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045771861&doi=10.1109%2fTMI.2018.2829662&partnerID=40&md5=dcda3ebfa345732e9cb381727d871c66","Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States; Department of Computer Science, Johns Hopkins University, Baltimore, 21218, MD, United States; Department of Biomedical Engineering, Department of Computer Science, Johns Hopkins University, Baltimore, 21218, MD, United States","Allman D., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States; Reiter A., Department of Computer Science, Johns Hopkins University, Baltimore, 21218, MD, United States; Bell M.A.L., Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States, Department of Biomedical Engineering, Department of Computer Science, Johns Hopkins University, Baltimore, 21218, MD, United States","Interventional applications of photoacoustic imaging typically require visualization of point-like targets, such as the small, circular, cross-sectional tips of needles, catheters, or brachytherapy seeds. When these point-like targets are imaged in the presence of highly echogenic structures, the resulting photoacoustic wave creates a reflection artifact that may appear as a true signal. We propose to use deep learning techniques to identify these types of noise artifacts for removal in experimental photoacoustic data. To achieve this goal, a convolutional neural network (CNN) was first trained to locate and classify sources and artifacts in pre-beamformed data simulated with k-Wave. Simulations initially contained one source and one artifact with various medium sound speeds and 2-D target locations. Based on 3,468 test images, we achieved a 100% success rate in classifying both sources and artifacts. After adding noise to assess potential performance in more realistic imaging environments, we achieved at least 98% success rates for channel signal-to-noise ratios (SNRs) of -9dB or greater, with a severe decrease in performance below -21dB channel SNR. We then explored training with multiple sources and two types of acoustic receivers and achieved similar success with detecting point sources. Networks trained with simulated data were then transferred to experimental waterbath and phantom data with 100% and 96.67% source classification accuracy, respectively (particularly when networks were tested at depths that were included during training). The corresponding mean ± one standard deviation of the point source location error was 0.40 ± 0.22 mm and 0.38 ± 0.25 mm for waterbath and phantom experimental data, respectively, which provides some indication of the resolution limits of our new CNN-based imaging system. We finally show that the CNN-based information can be displayed in a novel artifact-free image format, enabling us to effectively remove reflection artifacts from photoacoustic images, which is not possible with traditional geometry-based beamforming. © 2018 IEEE.","artifact reduction; deep learning; machine learning; neural networks; Photoacoustic imaging; reflection artifacts","Artifacts; Deep Learning; Humans; Image Processing, Computer-Assisted; Photoacoustic Techniques; Acoustic noise; Biomedical signal processing; Deep learning; Image resolution; Neural networks; Phantoms; Photoacoustic effect; Convolutional Neural Networks (CNN); Learning techniques; Phantom experimental data; Photo-acoustic imaging; Photoacoustic image; Photoacoustic wave; Source classification; Standard deviation; analytical error; Article; artifact reduction; controlled study; data analysis software; human; image analysis; image processing; learning algorithm; mathematical model; photoacoustics; signal noise ratio; simulation; sound; transfer of learning; artifact; photoacoustics; procedures; Signal to noise ratio","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870374","Article","Scopus","2-s2.0-85045771861"
"Bardou D.; Zhang K.; Ahmad S.M.","Bardou, Dalal (57193067671); Zhang, Kun (56335673500); Ahmad, Sayed Mohammad (57193062190)","57193067671; 56335673500; 57193062190","Lung sounds classification using convolutional neural networks","2018","Artificial Intelligence in Medicine","154","10.1016/j.artmed.2018.04.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046346868&doi=10.1016%2fj.artmed.2018.04.008&partnerID=40&md5=c1bcd69091f5c35a45d10f512106b7e6","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Lareb Technologies, India","Bardou D., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Zhang K., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Ahmad S.M., Lareb Technologies, India","Lung sounds convey relevant information related to pulmonary disorders, and to evaluate patients with pulmonary conditions, the physician or the doctor uses the traditional auscultation technique. However, this technique suffers from limitations. For example, if the physician is not well trained, this may lead to a wrong diagnosis. Moreover, lung sounds are non-stationary, complicating the tasks of analysis, recognition, and distinction. This is why developing automatic recognition systems can help to deal with these limitations. In this paper, we compare three machine learning approaches for lung sounds classification. The first two approaches are based on the extraction of a set of handcrafted features trained by three different classifiers (support vector machines, k-nearest neighbor, and Gaussian mixture models) while the third approach is based on the design of convolutional neural networks (CNN). In the first approach, we extracted the 12 MFCC coefficients from the audio files then calculated six MFCCs statistics. We also experimented normalization using zero mean and unity variance to enhance accuracy. In the second approach, the local binary pattern (LBP) features are extracted from the visual representation of the audio files (spectrograms). The features are normalized using whitening. The dataset used in this work consists of seven classes (normal, coarse crackle, fine crackle, monophonic wheeze, polyphonic wheeze, squawk, and stridor). We have also experimentally tested dataset augmentation techniques on the spectrograms to enhance the ultimate accuracy of the CNN. The results show that CNN outperformed the handcrafted feature based classifiers. © 2018 Elsevier B.V.","Convolutional neural network; Deep learning; Handcrafted features extraction; Lung sounds classification; Models ensembling; Support vector machines","Acoustics; Adolescent; Adult; Aged; Auscultation; Child; Deep Learning; Female; Humans; Infant, Newborn; Lung; Lung Diseases; Male; Middle Aged; Pattern Recognition, Automated; Predictive Value of Tests; Prognosis; Reproducibility of Results; Respiratory Sounds; Signal Processing, Computer-Assisted; Sound Spectrography; Support Vector Machine; Biological organs; Computer aided diagnosis; Convolution; Deep learning; Extraction; Nearest neighbor search; Neural networks; Spectrographs; Support vector machines; Augmentation techniques; Automatic recognition system; Convolutional neural network; Convolutional Neural Networks (CNN); Features extraction; Local binary pattern (LBP); Lung sounds; Machine learning approaches; abnormal respiratory sound; Article; artificial neural network; classifier; comparative study; controlled study; convolutional neural network; crackle; disease classification; feature extraction; human; k nearest neighbor; lung auscultation; machine learning; measurement accuracy; normal distribution; priority journal; squawk; stridor; support vector machine; variance; wheezing; abnormal respiratory sound; acoustics; adolescent; adult; aged; auscultation; automated pattern recognition; child; classification; female; lung; lung disease; male; middle aged; newborn; pathophysiology; predictive value; prognosis; reproducibility; signal processing; sound detection; support vector machine; Classification (of information)","Elsevier B.V.","09333657","","AIMEE","29724435","Article","Scopus","2-s2.0-85046346868"
"Wu B.; Chen Z.; Wang J.; Wu H.","Wu, Bowen (57201270620); Chen, Zhangling (57196393251); Wang, Jun (57163959600); Wu, Huaming (55605704300)","57201270620; 57196393251; 57163959600; 55605704300","Exponential discriminative metric embedding in deep learning","2018","Neurocomputing","11","10.1016/j.neucom.2018.02.040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044135694&doi=10.1016%2fj.neucom.2018.02.040&partnerID=40&md5=e25ff4e766965b5035970c0c8a2c97d4","Center for Combinatorics, Nankai University, Tianjin, 300071, China; Center for Applied Mathematics, Tianjin University, Tianjin, 300072, China; School of Mathematics, Tianjin University, Tianjin, 300072, China","Wu B., Center for Combinatorics, Nankai University, Tianjin, 300071, China; Chen Z., Center for Applied Mathematics, Tianjin University, Tianjin, 300072, China; Wang J., School of Mathematics, Tianjin University, Tianjin, 300072, China; Wu H., Center for Applied Mathematics, Tianjin University, Tianjin, 300072, China","With the remarkable success achieved by the Convolutional Neural Networks (CNNs) in object recognition recently, deep learning is being widely used in the computer vision community. Deep Metric Learning (DML), integrating deep learning with conventional metric learning, has set new records in many fields, especially in classification task. In this paper, we propose a replicable DML method, called Include and Exclude (IE) loss, to force the distance between a sample and its designated class center away from the mean distance of this sample to other class centers with a large margin in the exponential feature projection space. With the supervision of IE loss, we can train CNNs to enhance the intra-class compactness and inter-class separability, leading to great improvements on several public datasets ranging from object recognition to face verification. We conduct a comparative study of our algorithm with several typical DML methods on three kinds of networks with different capacity. Extensive experiments on three object recognition datasets and two face recognition datasets demonstrate that IE loss is always superior to other mainstream DML methods and approach the state-of-the-art results. © 2018 Elsevier B.V.","Deep metric learning; Face verification; Inter-class separability; Intra-class compactness; Object recognition","Face recognition; Neural networks; Object recognition; Classification tasks; Comparative studies; Convolutional neural network; Face Verification; Inter class; Intra class; Metric learning; Vision communities; algorithm; Article; artificial neural network; Bayesian learning; classification; classifier; comparative study; deep metric learning; discrimination learning; embedding; facial recognition; information processing; machine learning; mathematical computing; priority journal; recognition index; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85044135694"
"Amoroso N.; Diacono D.; Fanizzi A.; La Rocca M.; Monaco A.; Lombardi A.; Guaragnella C.; Bellotti R.; Tangaro S.","Amoroso, Nicola (55419832300); Diacono, Domenico (6603113523); Fanizzi, Annarita (25521194200); La Rocca, Marianna (57194093154); Monaco, Alfonso (7201639219); Lombardi, Angela (56450191700); Guaragnella, Cataldo (6603235411); Bellotti, Roberto (8419904800); Tangaro, Sabina (8712490600)","55419832300; 6603113523; 25521194200; 57194093154; 7201639219; 56450191700; 6603235411; 8419904800; 8712490600","Deep learning reveals Alzheimer's disease onset in MCI subjects: Results from an international challenge","2018","Journal of Neuroscience Methods","98","10.1016/j.jneumeth.2017.12.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044855024&doi=10.1016%2fj.jneumeth.2017.12.011&partnerID=40&md5=6b3edc0116db5d3961db123ba99be672","Dipartimento Interateneo di Fisica “M. Merlin”, Università degli studi di Bari “A. Moro”, Bari, Italy; Istituto Nazionale di Fisica Nucleare, Sezione di Bari, Bari, Italy; Istituto Tumori “Giovanni Paolo II” – I.R.C.C.S., Bari, Italy; Dipartimento di Ingegneria Elettrica e dell'Informazione, Politecnico di Bari, Bari, Italy","Amoroso N., Dipartimento Interateneo di Fisica “M. Merlin”, Università degli studi di Bari “A. Moro”, Bari, Italy, Istituto Nazionale di Fisica Nucleare, Sezione di Bari, Bari, Italy; Diacono D., Istituto Nazionale di Fisica Nucleare, Sezione di Bari, Bari, Italy; Fanizzi A., Istituto Tumori “Giovanni Paolo II” – I.R.C.C.S., Bari, Italy; La Rocca M., Dipartimento Interateneo di Fisica “M. Merlin”, Università degli studi di Bari “A. Moro”, Bari, Italy, Istituto Nazionale di Fisica Nucleare, Sezione di Bari, Bari, Italy; Monaco A., Istituto Nazionale di Fisica Nucleare, Sezione di Bari, Bari, Italy; Lombardi A., Dipartimento di Ingegneria Elettrica e dell'Informazione, Politecnico di Bari, Bari, Italy; Guaragnella C., Dipartimento di Ingegneria Elettrica e dell'Informazione, Politecnico di Bari, Bari, Italy; Bellotti R., Dipartimento Interateneo di Fisica “M. Merlin”, Università degli studi di Bari “A. Moro”, Bari, Italy, Istituto Nazionale di Fisica Nucleare, Sezione di Bari, Bari, Italy; Tangaro S., Istituto Nazionale di Fisica Nucleare, Sezione di Bari, Bari, Italy","Background: Early diagnosis of Alzheimer's disease (AD) and its onset in subjects affected by mild cognitive impairment (MCI) based on structural MRI features is one of the most important open issues in neuroimaging. Accordingly, a scientific challenge has been promoted, on the international Kaggle platform, to assess the performance of different classification methods for prediction of MCI and its conversion to AD. New method: This work presents a classification strategy based on Random Forest feature selection and Deep Neural Network classification using a mixed cohort including the four classes of classification problem, that is HC, AD, MCI and cMCI, to train the model. Moreover, we compare this approach with a novel classification strategy based on fuzzy logic learned on a mixed cohort including only HC and AD. Experiments: A training set of 240 subjects and a test set including mixed cohort of 500 real and simulated subjects were used. The data included AD patients, MCI subjects converting to AD (cMCI), MCI subjects and healthy controls (HC). This work ranked third for overall accuracy (38.8%) over 19 participating teams. Comparison with existing method(s): The “International challenge for automated prediction of MCI from MRI data” hosted by the Kaggle platform has been promoted to validate different methodologies with a common set of data and evaluation procedures. Conclusion: DNNs reach a classification accuracy significantly higher than other machine learning strategies; on the other hand, fuzzy logic is particularly accurate with cMCI, suggesting a combination of these approaches could lead to interesting future perspectives. © 2017 Elsevier B.V.","Alzheimer's disease; Deep learning; Fuzzy logic; MCI; MRI","Alzheimer Disease; Brain; Cognitive Dysfunction; Deep Learning; Disease Progression; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Pattern Recognition, Automated; Alzheimer disease; Article; brain size; comparative study; controlled study; diagnostic accuracy; early diagnosis; fuzzy logic; genotype phenotype correlation; human; major clinical study; mild cognitive impairment; Mini Mental State Examination; neuroimaging; nuclear magnetic resonance imaging; prediction; priority journal; random forest; Alzheimer disease; automated pattern recognition; brain; classification; cognitive defect; computer assisted diagnosis; diagnostic imaging; disease exacerbation; nuclear magnetic resonance imaging; procedures","Elsevier B.V.","01650270","","JNMED","29287745","Article","Scopus","2-s2.0-85044855024"
"Würfl T.; Hoffmann M.; Christlein V.; Breininger K.; Huang Y.; Unberath M.; Maier A.K.","Würfl, Tobias (57191574553); Hoffmann, Mathis (57201907702); Christlein, Vincent (37017226100); Breininger, Katharina (56536987700); Huang, Yixin (57862729800); Unberath, Mathias (56893868600); Maier, Andreas K. (23392966100)","57191574553; 57201907702; 37017226100; 56536987700; 57862729800; 56893868600; 23392966100","Deep Learning Computed Tomography: Learning Projection-Domain Weights From Image Domain in Limited Angle Problems","2018","IEEE Transactions on Medical Imaging","171","10.1109/TMI.2018.2833499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046415683&doi=10.1109%2fTMI.2018.2833499&partnerID=40&md5=dfc445a10abb9a17c54e49248ac206a2","Pattern Recognition Lab, Department Informatik, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany; Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, 21218, MD, United States","Würfl T., Pattern Recognition Lab, Department Informatik, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany; Hoffmann M., Pattern Recognition Lab, Department Informatik, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany; Christlein V., Pattern Recognition Lab, Department Informatik, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany; Breininger K., Pattern Recognition Lab, Department Informatik, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany; Huang Y., Pattern Recognition Lab, Department Informatik, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany; Unberath M., Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, 21218, MD, United States; Maier A.K., Pattern Recognition Lab, Department Informatik, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany","In this paper, we present a new deep learning framework for 3-D tomographic reconstruction. To this end, we map filtered back-projection-type algorithms to neural networks. However, the back-projection cannot be implemented as a fully connected layer due to its memory requirements. To overcome this problem, we propose a new type of cone-beam back-projection layer, efficiently calculating the forward pass. We derive this layer's backward pass as a projection operation. Unlike most deep learning approaches for reconstruction, our new layer permits joint optimization of correction steps in volume and projection domain. Evaluation is performed numerically on a public data set in a limited angle setting showing a consistent improvement over analytical algorithms while keeping the same computational test-time complexity by design. In the region of interest, the peak signal-to-noise ratio has increased by 23%. In addition, we show that the learned algorithm can be interpreted using known concepts from cone beam reconstruction: the network is able to automatically learn strategies such as compensation weights and apodization windows. © 2017 IEEE.","machine learning; neural networks; Reconstruction algorithms","Algorithms; Deep Learning; Humans; Radiographic Image Interpretation, Computer-Assisted; Tomography, X-Ray Computed; Computerized tomography; Image segmentation; Signal to noise ratio; Statistical tests; Analytical algorithms; Cone beam reconstruction; Filtered back projection; Fully-connected layers; Learning frameworks; Memory requirements; Peak signal to noise ratio; Tomographic reconstruction; article; compensation; computer assisted tomography; joint; learning; memory; nervous system; signal noise ratio; algorithm; computer assisted diagnosis; human; procedures; x-ray computed tomography; Deep learning","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29870373","Article","Scopus","2-s2.0-85046415683"
"Rodríguez-Pérez R.; Miyao T.; Jasial S.; Vogt M.; Bajorath J.","Rodríguez-Pérez, Raquel (57194069554); Miyao, Tomoyuki (36703996500); Jasial, Swarit (56525185600); Vogt, Martin (35312520200); Bajorath, Jürgen (7101742328)","57194069554; 36703996500; 56525185600; 35312520200; 7101742328","Prediction of Compound Profiling Matrices Using Machine Learning","2018","ACS Omega","28","10.1021/acsomega.8b00462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046272666&doi=10.1021%2facsomega.8b00462&partnerID=40&md5=980cb9755169ab9ef742ac46f52c5028","Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany","Rodríguez-Pérez R., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany; Miyao T., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany; Jasial S., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany; Vogt M., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany; Bajorath J., Department of Life Science Informatics, B-IT, LIMES Program Unit Chemical Biology and Medicinal Chemistry, Rheinische Friedrich-Wilhelms-Universität, Endenicher Allee 19c, Bonn, D-53115, Germany","Screening of compound libraries against panels of targets yields profiling matrices. Such matrices typically contain structurally diverse screening compounds, large numbers of inactives, and small numbers of hits per assay. As such, they represent interesting and challenging test cases for computational screening and activity predictions. In this work, modeling of large compound profiling matrices was attempted that were extracted from publicly available screening data. Different machine learning methods including deep learning were compared and different prediction strategies explored. Prediction accuracy varied for assays with different numbers of active compounds, and alternative machine learning approaches often produced comparable results. Deep learning did not further increase the prediction accuracy of standard methods such as random forests or support vector machines. Target-based random forest models were prioritized and yielded successful predictions of active compounds for many assays. © 2018 American Chemical Society.","","","American Chemical Society","24701343","","","","Article","Scopus","2-s2.0-85046272666"
"Brattain L.J.; Telfer B.A.; Dhyani M.; Grajo J.R.; Samir A.E.","Brattain, Laura J. (22956899500); Telfer, Brian A. (57198005299); Dhyani, Manish (56405450500); Grajo, Joseph R. (57209779792); Samir, Anthony E. (15045556500)","22956899500; 57198005299; 56405450500; 57209779792; 15045556500","Machine learning for medical ultrasound: status, methods, and future opportunities","2018","Abdominal Radiology","154","10.1007/s00261-018-1517-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042617516&doi=10.1007%2fs00261-018-1517-0&partnerID=40&md5=7343778fddc80bfd549de02a58334b48","MIT Lincoln Laboratory, 244 Wood St, Lexington, 02420, MA, United States; Department of Internal Medicine, Steward Carney Hospital, Boston, 02124, MA, United States; Department of Radiology, Division of Abdominal Imaging, University of Florida College of Medicine, Gainesville, FL, United States; Division of Ultrasound, Department of Radiology, Center for Ultrasound Research & Translation, Massachusetts General Hospital, Boston, 02114, MA, United States","Brattain L.J., MIT Lincoln Laboratory, 244 Wood St, Lexington, 02420, MA, United States; Telfer B.A., MIT Lincoln Laboratory, 244 Wood St, Lexington, 02420, MA, United States; Dhyani M., Department of Internal Medicine, Steward Carney Hospital, Boston, 02124, MA, United States, Division of Ultrasound, Department of Radiology, Center for Ultrasound Research & Translation, Massachusetts General Hospital, Boston, 02114, MA, United States; Grajo J.R., Department of Radiology, Division of Abdominal Imaging, University of Florida College of Medicine, Gainesville, FL, United States; Samir A.E., Division of Ultrasound, Department of Radiology, Center for Ultrasound Research & Translation, Massachusetts General Hospital, Boston, 02114, MA, United States","Ultrasound (US) imaging is the most commonly performed cross-sectional diagnostic imaging modality in the practice of medicine. It is low-cost, non-ionizing, portable, and capable of real-time image acquisition and display. US is a rapidly evolving technology with significant challenges and opportunities. Challenges include high inter- and intra-operator variability and limited image quality control. Tremendous opportunities have arisen in the last decade as a result of exponential growth in available computational power coupled with progressive miniaturization of US devices. As US devices become smaller, enhanced computational capability can contribute significantly to decreasing variability through advanced image processing. In this paper, we review leading machine learning (ML) approaches and research directions in US, with an emphasis on recent ML advances. We also present our outlook on future opportunities for ML techniques to further improve clinical workflow and US-based disease diagnosis and characterization. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Deep learning; Elastography; Machine learning; Medical ultrasound; Sonography","Abdomen; Forecasting; Humans; Machine Learning; Ultrasonography; Article; B scan; contrast-enhanced ultrasound; echography; elastography; image analysis; image processing; image segmentation; machine learning; priority journal; supervised machine learning; unsupervised machine learning; abdomen; diagnostic imaging; echography; forecasting; human; procedures","Springer New York LLC","2366004X","","","29492605","Article","Scopus","2-s2.0-85042617516"
"Li Y.; Wang S.; Umarov R.; Xie B.; Fan M.; Li L.; Gao X.","Li, Yu (57221627042); Wang, Sheng (58428221300); Umarov, Ramzan (57193205804); Xie, Bingqing (55010372700); Fan, Ming (56683907900); Li, Lihua (7501447027); Gao, Xin (55712115900)","57221627042; 58428221300; 57193205804; 55010372700; 56683907900; 7501447027; 55712115900","DEEPre: Sequence-based enzyme EC number prediction by deep learning","2018","Bioinformatics","171","10.1093/bioinformatics/btx680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042918066&doi=10.1093%2fbioinformatics%2fbtx680&partnerID=40&md5=7b0f68143eaf3c967b0f1af58759735c","Electrical and Mathematical Sciences and Engineering Division (CEMSE), Computational Bioscience Research Center (CBRC) Computer, King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia; Computer Science Department, Illinois Institute of Technology, Chicago, 60616, IL, United States; Institute of Biomedical Engineering and Instrumentation, Hangzhou Dianzi University, Hangzhou, 310018, China","Li Y., Electrical and Mathematical Sciences and Engineering Division (CEMSE), Computational Bioscience Research Center (CBRC) Computer, King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia; Wang S., Electrical and Mathematical Sciences and Engineering Division (CEMSE), Computational Bioscience Research Center (CBRC) Computer, King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia; Umarov R., Electrical and Mathematical Sciences and Engineering Division (CEMSE), Computational Bioscience Research Center (CBRC) Computer, King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia; Xie B., Computer Science Department, Illinois Institute of Technology, Chicago, 60616, IL, United States; Fan M., Institute of Biomedical Engineering and Instrumentation, Hangzhou Dianzi University, Hangzhou, 310018, China; Li L., Institute of Biomedical Engineering and Instrumentation, Hangzhou Dianzi University, Hangzhou, 310018, China; Gao X., Electrical and Mathematical Sciences and Engineering Division (CEMSE), Computational Bioscience Research Center (CBRC) Computer, King Abdullah University of Science and Technology (KAUST), Thuwal, 23955-6900, Saudi Arabia","Motivation Annotation of enzyme function has a broad range of applications, such as metagenomics, industrial biotechnology, and diagnosis of enzyme deficiency-caused diseases. However, the time and resource required make it prohibitively expensive to experimentally determine the function of every enzyme. Therefore, computational enzyme function prediction has become increasingly important. In this paper, we develop such an approach, determining the enzyme function by predicting the Enzyme Commission number. Results We propose an end-to-end feature selection and classification model training approach, as well as an automatic and robust feature dimensionality uniformization method, DEEPre, in the field of enzyme function prediction. Instead of extracting manually crafted features from enzyme sequences, our model takes the raw sequence encoding as inputs, extracting convolutional and sequential features from the raw encoding based on the classification result to directly improve the prediction performance. The thorough cross-fold validation experiments conducted on two large-scale datasets show that DEEPre improves the prediction performance over the previous state-of-the-art methods. In addition, our server outperforms five other servers in determining the main class of enzymes on a separate low-homology dataset. Two case studies demonstrate DEEPre's ability to capture the functional difference of enzyme isoforms. © The Author 2017. Published by Oxford University Press.","","Computational Biology; Enzymes; Humans; Machine Learning; Molecular Sequence Annotation; Software; enzyme; biology; human; machine learning; metabolism; molecular genetics; procedures; software","Oxford University Press","13674803","","BOINF","29069344","Article","Scopus","2-s2.0-85042918066"
"Baldominos A.; Saez Y.; Isasi P.","Baldominos, Alejandro (56203599600); Saez, Yago (8848712400); Isasi, Pedro (7004613522)","56203599600; 8848712400; 7004613522","Evolutionary design of convolutional neural networks for human activity recognition in sensor-rich environments","2018","Sensors (Switzerland)","33","10.3390/s18041288","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045923896&doi=10.3390%2fs18041288&partnerID=40&md5=df38ce56dc719c77daec076e87e55e1e","Computer Science Department, Universidad Carlos III de Madrid, Leganes, 28911, Spain","Baldominos A., Computer Science Department, Universidad Carlos III de Madrid, Leganes, 28911, Spain; Saez Y., Computer Science Department, Universidad Carlos III de Madrid, Leganes, 28911, Spain; Isasi P., Computer Science Department, Universidad Carlos III de Madrid, Leganes, 28911, Spain","Human activity recognition is a challenging problem for context-aware systems and applications. It is gaining interest due to the ubiquity of different sensor sources, wearable smart objects, ambient sensors, etc. This task is usually approached as a supervised machine learning problem, where a label is to be predicted given some input data, such as the signals retrieved from different sensors. For tackling the human activity recognition problem in sensor network environments, in this paper we propose the use of deep learning (convolutional neural networks) to perform activity recognition using the publicly available OPPORTUNITY dataset. Instead of manually choosing a suitable topology, we will let an evolutionary algorithm design the optimal topology in order to maximize the classification F1 score. After that, we will also explore the performance of committees of the models resulting from the evolutionary process. Results analysis indicates that the proposed model was able to perform activity recognition within a heterogeneous sensor network environment, achieving very high accuracies when tested with new sensor data. Based on all conducted experiments, the proposed neuroevolutionary system has proved to be able to systematically find a classification model which is capable of outperforming previous results reported in the state-of-the-art, showing that this approach is useful and improves upon previously manually-designed architectures. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Deep learning; Human activity recognition; Neuroevolution","Algorithms; Biological Evolution; Human Activities; Humans; Machine Learning; Neural Networks (Computer); Convolution; Deep learning; Neural networks; Pattern recognition; Sensor networks; Supervised learning; Topology; User interfaces; Context-aware systems; Convolutional neural network; Heterogeneous sensor networks; Human activity recognition; Neuro evolutions; Neuro-evolutionary systems; Sensor network environment; Supervised machine learning; algorithm; artificial neural network; evolution; human; human activities; machine learning; Wearable sensors","MDPI AG","14248220","","","29690587","Article","Scopus","2-s2.0-85045923896"
"Tian Y.; Gelernter J.; Wang X.; Chen W.; Gao J.; Zhang Y.; Li X.","Tian, Yan (57193621959); Gelernter, Judith (23467010800); Wang, Xun (35171979500); Chen, Weigang (7409637022); Gao, Junxiang (35098678400); Zhang, Yujie (57198517675); Li, Xiaolan (54383624500)","57193621959; 23467010800; 35171979500; 7409637022; 35098678400; 57198517675; 54383624500","Lane marking detection via deep convolutional neural network","2018","Neurocomputing","95","10.1016/j.neucom.2017.09.098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036614332&doi=10.1016%2fj.neucom.2017.09.098&partnerID=40&md5=0f98b2e38432f118371a9a810543ccd3","School of Computer and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; Information Technology Laboratory, National Institute of Standards and Technology, Pittsburgh, United States; College of Science, Huazhong Agricultural University, Wuhan, China","Tian Y., School of Computer and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; Gelernter J., Information Technology Laboratory, National Institute of Standards and Technology, Pittsburgh, United States; Wang X., School of Computer and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; Chen W., School of Computer and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; Gao J., College of Science, Huazhong Agricultural University, Wuhan, China; Zhang Y., School of Computer and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; Li X., School of Computer and Information Engineering, Zhejiang Gongshang University, Hangzhou, China","Research on Faster R-CNN has recently witnessed the progress in both accuracy and execution efficiency in detecting objects such as faces, hands or pedestrians in photograph or video. However, constrained by the size of its convolution feature map output, it is unable to clearly detect small or tiny objects. Therefore, we presented a fast, deep convolutional neural network based on a modified Faster R-CNN. Multiple strategies, such as fast multi-level combination, context cues, and a new anchor generating method were employed for small object detection in this paper. We demonstrated performance of our algorithm both on the KITTI-ROAD dataset and our own traffic scene lane markings dataset. Experiments demonstrated that our algorithm obtained better accuracy than Faster R-CNN in small object detection. © 2017","Computer vision; Deep learning; Image processing; Intelligent transportation systems; Lane marking detection","Computer vision; Convolution; Deep learning; Deep neural networks; Image processing; Intelligent systems; Object detection; Object recognition; Road and street markings; Detecting objects; Generating methods; Intelligent transportation systems; Lane marking detection; Lane markings; Multiple strategy; Small object detection; Traffic scene; Article; controlled study; deep convolutional neural network; intermethod comparison; lane marking detection; machine learning; measurement accuracy; priority journal; region convolutional neural network; software; traffic; Convolutional neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85036614332"
"Oh D.Y.; Yun I.D.","Oh, Dong Yul (57207984555); Yun, Il Dong (55666861500)","57207984555; 55666861500","Residual error based anomaly detection using auto-encoder in SMD machine sound","2018","Sensors (Switzerland)","88","10.3390/s18051308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046084471&doi=10.3390%2fs18051308&partnerID=40&md5=6939cecb23d9e023a7613a938a84c313","Department of Digital Information Engineering, Hankuk University of Foreign Studies, Yongin, 17035, South Korea; Division of Computer and Electronic System Engineering, Hankuk University of Foreign Studies, Yongin, 17035, South Korea","Oh D.Y., Department of Digital Information Engineering, Hankuk University of Foreign Studies, Yongin, 17035, South Korea; Yun I.D., Division of Computer and Electronic System Engineering, Hankuk University of Foreign Studies, Yongin, 17035, South Korea","Detecting an anomaly or an abnormal situation from given noise is highly useful in an environment where constantly verifying and monitoring a machine is required. As deep learning algorithms are further developed, current studies have focused on this problem. However, there are too many variables to define anomalies, and the human annotation for a large collection of abnormal data labeled at the class-level is very labor-intensive. In this paper, we propose to detect abnormal operation sounds or outliers in a very complex machine along with reducing the data-driven annotation cost. The architecture of the proposed model is based on an auto-encoder, and it uses the residual error, which stands for its reconstruction quality, to identify the anomaly. We assess our model using Surface-Mounted Device (SMD) machine sound, which is very complex, as experimental data, and state-of-the-art performance is successfully achieved for anomaly detection. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Anomaly detection; Auto-encoder; Machine sound; SMD; Unsupervised learning","Deep learning; Learning algorithms; Surface mount technology; Unsupervised learning; Abnormal operation; Anomaly detection; Auto encoders; Complex machines; Human annotations; Labor intensive; Reconstruction quality; State-of-the-art performance; algorithm; article; autoencoder; deep learning; human; sound; unsupervised machine learning; Signal encoding","MDPI AG","14248220","","","29695084","Article","Scopus","2-s2.0-85046084471"
"Christiansen E.M.; Yang S.J.; Ando D.M.; Javaherian A.; Skibinski G.; Lipnick S.; Mount E.; O'Neil A.; Shah K.; Lee A.K.; Goyal P.; Fedus W.; Poplin R.; Esteva A.; Berndl M.; Rubin L.L.; Nelson P.; Finkbeiner S.","Christiansen, Eric M. (57201199072); Yang, Samuel J. (56709026600); Ando, D. Michael (55016305000); Javaherian, Ashkan (46060913800); Skibinski, Gaia (7006556923); Lipnick, Scott (35286011600); Mount, Elliot (57194048840); O'Neil, Alison (39863224100); Shah, Kevan (35234843800); Lee, Alicia K. (57193154903); Goyal, Piyush (57200013447); Fedus, William (36025168400); Poplin, Ryan (37026985800); Esteva, Andre (57034062100); Berndl, Marc (7801530630); Rubin, Lee L. (7201363051); Nelson, Philip (57192712992); Finkbeiner, Steven (7004508339)","57201199072; 56709026600; 55016305000; 46060913800; 7006556923; 35286011600; 57194048840; 39863224100; 35234843800; 57193154903; 57200013447; 36025168400; 37026985800; 57034062100; 7801530630; 7201363051; 57192712992; 7004508339","In Silico Labeling: Predicting Fluorescent Labels in Unlabeled Images","2018","Cell","387","10.1016/j.cell.2018.03.040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043779029&doi=10.1016%2fj.cell.2018.03.040&partnerID=40&md5=e04fb0926cfc9712d0161eed4dc60188","Google, Inc., Mountain View, 94043, CA, United States; Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone Institutes, San Francisco, 94158, CA, United States; Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, 02138, MA, United States; Department of Biomedical Informatics, Harvard Medical School, Boston, 02115, MA, United States; Departments of Neurology and Physiology, University of California, San Francisco, 94158, United States; Montreal Institute of Learning Algorithms, University of Montreal, Montreal, QC, Canada; Department of Electrical Engineering, Stanford University, Stanford, 94305, CA, United States; Center for Assessment Technology and Continuous Health, Massachusetts General Hospital, Boston, 02114, MA, United States","Christiansen E.M., Google, Inc., Mountain View, 94043, CA, United States; Yang S.J., Google, Inc., Mountain View, 94043, CA, United States; Ando D.M., Google, Inc., Mountain View, 94043, CA, United States; Javaherian A., Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone Institutes, San Francisco, 94158, CA, United States; Skibinski G., Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone Institutes, San Francisco, 94158, CA, United States; Lipnick S., Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, 02138, MA, United States, Department of Biomedical Informatics, Harvard Medical School, Boston, 02115, MA, United States, Center for Assessment Technology and Continuous Health, Massachusetts General Hospital, Boston, 02114, MA, United States; Mount E., Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone Institutes, San Francisco, 94158, CA, United States; O'Neil A., Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, 02138, MA, United States; Shah K., Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone Institutes, San Francisco, 94158, CA, United States; Lee A.K., Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone Institutes, San Francisco, 94158, CA, United States; Goyal P., Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone Institutes, San Francisco, 94158, CA, United States; Fedus W., Google, Inc., Mountain View, 94043, CA, United States, Montreal Institute of Learning Algorithms, University of Montreal, Montreal, QC, Canada; Poplin R., Google, Inc., Mountain View, 94043, CA, United States; Esteva A., Google, Inc., Mountain View, 94043, CA, United States, Department of Electrical Engineering, Stanford University, Stanford, 94305, CA, United States; Berndl M., Google, Inc., Mountain View, 94043, CA, United States; Rubin L.L., Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, 02138, MA, United States; Nelson P., Google, Inc., Mountain View, 94043, CA, United States; Finkbeiner S., Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone Institutes, San Francisco, 94158, CA, United States, Departments of Neurology and Physiology, University of California, San Francisco, 94158, United States","Microscopy is a central method in life sciences. Many popular methods, such as antibody labeling, are used to add physical fluorescent labels to specific cellular constituents. However, these approaches have significant drawbacks, including inconsistency; limitations in the number of simultaneous labels because of spectral overlap; and necessary perturbations of the experiment, such as fixing the cells, to generate the measurement. Here, we show that a computational machine-learning approach, which we call “in silico labeling” (ISL), reliably predicts some fluorescent labels from transmitted-light images of unlabeled fixed or live biological samples. ISL predicts a range of labels, such as those for nuclei, cell type (e.g., neural), and cell state (e.g., cell death). Because prediction happens in silico, the method is consistent, is not limited by spectral overlap, and does not disturb the experiment. ISL generates biological measurements that would otherwise be problematic or impossible to acquire. In silico labeling, a machine-learning approach, reliably infers fluorescent measurements from transmitted-light images of unlabeled fixed or live biological samples. © 2018 Elsevier Inc.","cancer; computer vision; deep learning; machine learning; microscopy; neuroscience; stem cells","Algorithms; Animals; Cell Line, Tumor; Cell Survival; Cerebral Cortex; Fluorescent Dyes; Humans; Image Processing, Computer-Assisted; Induced Pluripotent Stem Cells; Machine Learning; Microscopy, Fluorescence; Motor Neurons; Neural Networks (Computer); Neurosciences; Rats; Software; Stem Cells; fluorescent dye; algorithm; Article; artificial neural network; cell death; cell labeling; cell nucleus; cell viability; cells by body anatomy; chemical labeling; computer model; factual database; fluorescence analysis; fluorescence microscopy; in silico labeling; prediction; predictive value; priority journal; transfer of learning; workflow; animal; brain cortex; cell survival; chemistry; cytology; human; image processing; induced pluripotent stem cell; machine learning; motoneuron; neuroscience; procedures; rat; software; stem cell; tumor cell line","Cell Press","00928674","","CELLB","29656897","Article","Scopus","2-s2.0-85043779029"
"Fondón I.; Sarmiento A.; García A.I.; Silvestre M.; Eloy C.; Polónia A.; Aguiar P.","Fondón, Irene (6508237785); Sarmiento, Auxiliadora (23398417800); García, Ana Isabel (57194521343); Silvestre, María (57201116243); Eloy, Catarina (24821485700); Polónia, António (57052896600); Aguiar, Paulo (36842157600)","6508237785; 23398417800; 57194521343; 57201116243; 24821485700; 57052896600; 36842157600","Automatic classification of tissue malignancy for breast carcinoma diagnosis","2018","Computers in Biology and Medicine","57","10.1016/j.compbiomed.2018.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043461026&doi=10.1016%2fj.compbiomed.2018.03.003&partnerID=40&md5=e63bfbc8937fbf5b6eb59fa44dd4b3e2","Signal Processing and Communication Department, Engineering School, University of Seville, Seville, Spain; Pathology Department, Institute of Molecular Pathology and Immunology (Ipatimup), University of Porto, Porto, Portugal; Medical Faculty, University of Porto, Porto, Portugal; Institute of Biomedical Engineering (INEB), University of Porto, Porto, Portugal; Institute for Research and Innovation in Health Sciences (i3S), Porto, Portugal","Fondón I., Signal Processing and Communication Department, Engineering School, University of Seville, Seville, Spain; Sarmiento A., Signal Processing and Communication Department, Engineering School, University of Seville, Seville, Spain; García A.I., Signal Processing and Communication Department, Engineering School, University of Seville, Seville, Spain; Silvestre M., Signal Processing and Communication Department, Engineering School, University of Seville, Seville, Spain; Eloy C., Pathology Department, Institute of Molecular Pathology and Immunology (Ipatimup), University of Porto, Porto, Portugal, Medical Faculty, University of Porto, Porto, Portugal; Polónia A., Pathology Department, Institute of Molecular Pathology and Immunology (Ipatimup), University of Porto, Porto, Portugal; Aguiar P., Institute of Biomedical Engineering (INEB), University of Porto, Porto, Portugal, Institute for Research and Innovation in Health Sciences (i3S), Porto, Portugal","Breast cancer is the second leading cause of cancer death among women. Its early diagnosis is extremely important to prevent avoidable deaths. However, malignancy assessment of tissue biopsies is complex and dependent on observer subjectivity. Moreover, hematoxylin and eosin (H&E)-stained histological images exhibit a highly variable appearance, even within the same malignancy level. In this paper, we propose a computer-aided diagnosis (CAD) tool for automated malignancy assessment of breast tissue samples based on the processing of histological images. We provide four malignancy levels as the output of the system: normal, benign, in situ and invasive. The method is based on the calculation of three sets of features related to nuclei, colour regions and textures considering local characteristics and global image properties. By taking advantage of well-established image processing techniques, we build a feature vector for each image that serves as an input to an SVM (Support Vector Machine) classifier with a quadratic kernel. The method has been rigorously evaluated, first with a 5-fold cross-validation within an initial set of 120 images, second with an external set of 30 different images and third with images with artefacts included. Accuracy levels range from 75.8% when the 5-fold cross-validation was performed to 75% with the external set of new images and 61.11% when the extremely difficult images were added to the classification experiment. The experimental results indicate that the proposed method is capable of distinguishing between four malignancy levels with high accuracy. Our results are close to those obtained with recent deep learning-based methods. Moreover, it performs better than other state-of-the-art methods based on feature extraction, and it can help improve the CAD of breast cancer. © 2018 Elsevier Ltd","Breast cancer; Computer-aided diagnosis; Digital pathology; Histopathological images; Pattern recognition and classification; Tissue malignancy","Breast; Breast Neoplasms; Female; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Pattern Recognition, Automated; Support Vector Machine; Deep learning; Diseases; Image processing; Image retrieval; Medical imaging; Pattern recognition; Support vector machines; Tissue; Breast Cancer; Computer Aided Diagnosis(CAD); Digital pathologies; Histopathological images; Image processing technique; Pattern recognition and classification; State-of-the-art methods; SVM(support vector machine); Article; artifact; automation; breast biopsy; breast carcinogenesis; breast carcinoma; cancer diagnosis; cancer tissue; computer assisted diagnosis; diagnostic accuracy; disease classification; image processing; k nearest neighbor; oncological parameters; priority journal; probabilistic neural network; support vector machine; automated pattern recognition; breast; breast tumor; computer assisted diagnosis; cytochemistry; diagnostic imaging; female; human; pathology; procedures; Computer aided diagnosis","Elsevier Ltd","00104825","","CBMDA","29544146","Article","Scopus","2-s2.0-85043461026"
"Chambon S.; Galtier M.N.; Arnal P.J.; Wainrib G.; Gramfort A.","Chambon, Stanislas (57201087480); Galtier, Mathieu N. (55545675500); Arnal, Pierrick J. (55330448800); Wainrib, Gilles (35788245900); Gramfort, Alexandre (23388890700)","57201087480; 55545675500; 55330448800; 35788245900; 23388890700","A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series","2018","IEEE Transactions on Neural Systems and Rehabilitation Engineering","378","10.1109/TNSRE.2018.2813138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043388230&doi=10.1109%2fTNSRE.2018.2813138&partnerID=40&md5=f774c9d66b80ae753ccf7ce0ed9eb223","Research Amd Algorithms Team, Rythm Inc., Paris, France; Laboratoire Traitement et Communication de L'Information, Telecom ParisTech, Universite Paris-Saclay, Paris, France; DATA Team, Département D'Informatique, Ecole Normale Supérieure, Paris, 75005, France; INRIA, Université Paris-Saclay, Paris, France; CEA, Université Paris-Saclay, Paris, France","Chambon S., Research Amd Algorithms Team, Rythm Inc., Paris, France, Laboratoire Traitement et Communication de L'Information, Telecom ParisTech, Universite Paris-Saclay, Paris, France; Galtier M.N., Research Amd Algorithms Team, Rythm Inc., Paris, France; Arnal P.J., Research Amd Algorithms Team, Rythm Inc., Paris, France; Wainrib G., DATA Team, Département D'Informatique, Ecole Normale Supérieure, Paris, 75005, France; Gramfort A., Laboratoire Traitement et Communication de L'Information, Telecom ParisTech, Universite Paris-Saclay, Paris, France, INRIA, Université Paris-Saclay, Paris, France, CEA, Université Paris-Saclay, Paris, France","Sleep stage classification constitutes an important preliminary exam in the diagnosis of sleep disorders. It is traditionally performed by a sleep expert who assigns to each 30 s of the signal of a sleep stage, based on the visual inspection of signals such as electroencephalograms (EEGs), electrooculograms (EOGs), electrocardiograms, and electromyograms (EMGs). We introduce here the first deep learning approach for sleep stage classification that learns end-to-end without computing spectrograms or extracting handcrafted features, that exploits all multivariate and multimodal polysomnography (PSG) signals (EEG, EMG, and EOG), and that can exploit the temporal context of each 30-s window of data. For each modality, the first layer learns linear spatial filters that exploit the array of sensors to increase the signal-to-noise ratio, and the last layer feeds the learnt representation to a softmax classifier. Our model is compared to alternative automatic approaches based on convolutional networks or decisions trees. Results obtained on 61 publicly available PSG records with up to 20 EEG channels demonstrate that our network architecture yields the state-of-the-art performance. Our study reveals a number of insights on the spatiotemporal distribution of the signal of interest: a good tradeoff for optimal classification performance measured with balanced accuracy is to use 6 EEG with 2 EOG (left and right) and 3 EMG chin channels. Also exploiting 1 min of data before and after each data segment offers the strongest improvement when a limited number of channels are available. As sleep experts, our system exploits the multivariate and multimodal nature of PSG signals in order to deliver the state-of-the-art classification performance with a small computational cost. © 2001-2011 IEEE.","deep learning; EEG; EMG; EOG; multivariate time series; Sleep stage classification; spatiooral data; transfer learning","Algorithms; Computer Systems; Decision Trees; Deep Learning; Electroencephalography; Electromyography; Electrooculography; Expert Systems; Humans; Multivariate Analysis; Polysomnography; Signal Processing, Computer-Assisted; Sleep Stages; Bioelectric phenomena; Computer aided diagnosis; Deep learning; Economic and social effects; Electrocardiography; Electroencephalography; Electromyography; Electrooculography; Electrophysiology; Feature extraction; Learning systems; Network architecture; Signal to noise ratio; Sleep research; Time series analysis; Multivariate time series; Sleep; Sleep stage; Spatio-temporal data; Transfer learning; accuracy; Article; decision tree; electrocardiogram; electroencephalogram; electromyogram; electrooculogram; machine learning; polysomnography; sensitivity and specificity; signal noise ratio; sleep stage; training; algorithm; classification; computer system; electroencephalography; electromyography; electrooculography; expert system; human; multivariate analysis; signal processing; statistics and numerical data; Biomedical signal processing","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","29641380","Article","Scopus","2-s2.0-85043388230"
"Pang S.; Orgun M.A.; Yu Z.","Pang, Shuchao (55639762100); Orgun, Mehmet A. (6603681610); Yu, Zhezhou (8938987700)","55639762100; 6603681610; 8938987700","A novel biomedical image indexing and retrieval system via deep preference learning","2018","Computer Methods and Programs in Biomedicine","30","10.1016/j.cmpb.2018.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041721081&doi=10.1016%2fj.cmpb.2018.02.003&partnerID=40&md5=83daf49352eb3580b74fd70ba252d771","College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China; Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia","Pang S., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China, Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Orgun M.A., Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Yu Z., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China","Background and Objectives: The traditional biomedical image retrieval methods as well as content-based image retrieval (CBIR) methods originally designed for non-biomedical images either only consider using pixel and low-level features to describe an image or use deep features to describe images but still leave a lot of room for improving both accuracy and efficiency. In this work, we propose a new approach, which exploits deep learning technology to extract the high-level and compact features from biomedical images. The deep feature extraction process leverages multiple hidden layers to capture substantial feature structures of high-resolution images and represent them at different levels of abstraction, leading to an improved performance for indexing and retrieval of biomedical images. Methods: We exploit the current popular and multi-layered deep neural networks, namely, stacked denoising autoencoders (SDAE) and convolutional neural networks (CNN) to represent the discriminative features of biomedical images by transferring the feature representations and parameters of pre-trained deep neural networks from another domain. Moreover, in order to index all the images for finding the similarly referenced images, we also introduce preference learning technology to train and learn a kind of a preference model for the query image, which can output the similarity ranking list of images from a biomedical image database. To the best of our knowledge, this paper introduces preference learning technology for the first time into biomedical image retrieval. Results: We evaluate the performance of two powerful algorithms based on our proposed system and compare them with those of popular biomedical image indexing approaches and existing regular image retrieval methods with detailed experiments over several well-known public biomedical image databases. Based on different criteria for the evaluation of retrieval performance, experimental results demonstrate that our proposed algorithms outperform the state-of-the-art techniques in indexing biomedical images. Conclusions: We propose a novel and automated indexing system based on deep preference learning to characterize biomedical images for developing computer aided diagnosis (CAD) systems in healthcare. Our proposed system shows an outstanding indexing ability and high efficiency for biomedical image retrieval applications and it can be used to collect and annotate the high-resolution images in a biomedical database for further biomedical image research and applications. © 2018 Elsevier B.V.","Biomedical image retrieval; Convolutional neural network; Deep learning; Preference learning","Algorithms; Databases, Factual; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Information Storage and Retrieval; Machine Learning; Neural Networks (Computer); Radiology Information Systems; Bioinformatics; Computer aided diagnosis; Computer aided instruction; Content based retrieval; Convolution; Database systems; Deep learning; Deep neural networks; Efficiency; Image enhancement; Indexing (of information); Medical computing; Network layers; Neural networks; Query processing; Biomedical image database; Biomedical images; Computer Aided Diagnosis(CAD); Content-Based Image Retrieval; Convolutional neural network; Convolutional Neural Networks (CNN); Preference learning; State-of-the-art techniques; article; diagnosis; diagnostic test accuracy study; extraction; image retrieval; learning; nervous system; algorithm; artificial neural network; diagnostic imaging; factual database; human; image processing; information retrieval; machine learning; procedures; radiology information system; Search engines","Elsevier Ireland Ltd","01692607","","CMPBE","29544790","Article","Scopus","2-s2.0-85041721081"
"Chougrad H.; Zouaki H.; Alheyane O.","Chougrad, Hiba (57188701294); Zouaki, Hamid (6507986820); Alheyane, Omar (57188707414)","57188701294; 6507986820; 57188707414","Deep Convolutional Neural Networks for breast cancer screening","2018","Computer Methods and Programs in Biomedicine","325","10.1016/j.cmpb.2018.01.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041413978&doi=10.1016%2fj.cmpb.2018.01.011&partnerID=40&md5=2cd7703179032adb05fa3ab23fcd3a05","Laboratory of Computer Science and Mathematics and their Applications (LIMA), Faculty of science, University Chouaib Doukkali, El Jadida, 24000, Morocco; Laboratory of Fundamental Mathematics (LMF), Faculty of science, University Chouaib Doukkali, El Jadida, 24000, Morocco","Chougrad H., Laboratory of Computer Science and Mathematics and their Applications (LIMA), Faculty of science, University Chouaib Doukkali, El Jadida, 24000, Morocco; Zouaki H., Laboratory of Computer Science and Mathematics and their Applications (LIMA), Faculty of science, University Chouaib Doukkali, El Jadida, 24000, Morocco; Alheyane O., Laboratory of Fundamental Mathematics (LMF), Faculty of science, University Chouaib Doukkali, El Jadida, 24000, Morocco","Background and objective: Radiologists often have a hard time classifying mammography mass lesions which leads to unnecessary breast biopsies to remove suspicions and this ends up adding exorbitant expenses to an already burdened patient and health care system. Methods: In this paper we developed a Computer-aided Diagnosis (CAD) system based on deep Convolutional Neural Networks (CNN) that aims to help the radiologist classify mammography mass lesions. Deep learning usually requires large datasets to train networks of a certain depth from scratch. Transfer learning is an effective method to deal with relatively small datasets as in the case of medical images, although it can be tricky as we can easily start overfitting. Results: In this work, we explore the importance of transfer learning and we experimentally determine the best fine-tuning strategy to adopt when training a CNN model. We were able to successfully fine-tune some of the recent, most powerful CNNs and achieved better results compared to other state-of-the-art methods which classified the same public datasets. For instance we achieved 97.35% accuracy and 0.98 AUC on the DDSM database, 95.50% accuracy and 0.97 AUC on the INbreast database and 96.67% accuracy and 0.96 AUC on the BCDR database. Furthermore, after pre-processing and normalizing all the extracted Regions of Interest (ROIs) from the full mammograms, we merged all the datasets to build one large set of images and used it to fine-tune our CNNs. The CNN model which achieved the best results, a 98.94% accuracy, was used as a baseline to build the Breast Cancer Screening Framework. To evaluate the proposed CAD system and its efficiency to classify new images, we tested it on an independent database (MIAS) and got 98.23% accuracy and 0.99 AUC. Conclusion: The results obtained demonstrate that the proposed framework is performant and can indeed be used to predict if the mass lesions are benign or malignant. © 2018 Elsevier B.V.","Breast cancer; Breast mass lesion classification; Computer-aided Diagnosis; Convolutional Neural Network; Deep learning; Transfer learning","Breast Neoplasms; Databases, Factual; Diagnosis, Computer-Assisted; Early Detection of Cancer; Female; Humans; Machine Learning; Mammography; Neural Networks (Computer); Reproducibility of Results; Biopsy; Classification (of information); Computer aided instruction; Computer networks; Convolution; Database systems; Deep learning; Deep neural networks; Diseases; Medical imaging; Neural networks; Breast Cancer; Breast cancer screening; Breast mass; Computer Aided Diagnosis(CAD); Convolutional neural network; Deep convolutional neural networks; State-of-the-art methods; Transfer learning; Article; breast cancer; cancer screening; classifier; computer assisted diagnosis; data base; deep convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; disease classification; human; image analysis; image processing; major clinical study; mammography; nerve cell network; receptive field; transfer of learning; artificial neural network; breast tumor; classification; computer assisted diagnosis; diagnostic imaging; early cancer diagnosis; factual database; female; machine learning; pathology; procedures; reproducibility; Computer aided diagnosis","Elsevier Ireland Ltd","01692607","","CMPBE","29477427","Article","Scopus","2-s2.0-85041413978"
"Lee J.-H.; Kim D.-H.; Jeong S.-N.; Choi S.-H.","Lee, Jae-Hong (56692047500); Kim, Do-Hyung (57203012722); Jeong, Seong-Nyum (7402425037); Choi, Seong-Ho (56132950300)","56692047500; 57203012722; 7402425037; 56132950300","Diagnosis and prediction of periodontally compromised teeth using a deep learning-based convolutional neural network algorithm","2018","Journal of Periodontal and Implant Science","248","10.5051/jpis.2018.48.2.114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046764664&doi=10.5051%2fjpis.2018.48.2.114&partnerID=40&md5=2a90d3cca70b1c12c57fbb66539b1d5c","Department of Periodontology, Daejeon Dental Hospital, Institute of Wonkwang Dental Research, Wonkwang University College of Dentistry, Daejeon, South Korea; Department of Periodontology, Research Institute for Periodontal Regeneration, Yonsei University College of Dentistry, Seoul, South Korea","Lee J.-H., Department of Periodontology, Daejeon Dental Hospital, Institute of Wonkwang Dental Research, Wonkwang University College of Dentistry, Daejeon, South Korea; Kim D.-H., Department of Periodontology, Daejeon Dental Hospital, Institute of Wonkwang Dental Research, Wonkwang University College of Dentistry, Daejeon, South Korea; Jeong S.-N., Department of Periodontology, Daejeon Dental Hospital, Institute of Wonkwang Dental Research, Wonkwang University College of Dentistry, Daejeon, South Korea; Choi S.-H., Department of Periodontology, Research Institute for Periodontal Regeneration, Yonsei University College of Dentistry, Seoul, South Korea","Purpose: The aim of the current study was to develop a computer-assisted detection system based on a deep convolutional neural network (CNN) algorithm and to evaluate the potential usefulness and accuracy of this system for the diagnosis and prediction of periodontally compromised teeth (PCT). Methods: Combining pretrained deep CNN architecture and a self-trained network, periapical radiographic images were used to determine the optimal CNN algorithm and weights. The diagnostic and predictive accuracy, sensitivity, specificity, positive predictive value, negative predictive value, receiver operating characteristic (ROC) curve, area under the ROC curve, confusion matrix, and 95% confidence intervals (CIs) were calculated using our deep CNN algorithm, based on a Keras framework in Python. Results: The periapical radiographic dataset was split into training (n=1,044), validation (n=348), and test (n=348) datasets. With the deep learning algorithm, the diagnostic accuracy for PCT was 81.0% for premolars and 76.7% for molars. Using 64 premolars and 64 molars that were clinically diagnosed as severe PCT, the accuracy of predicting extraction was 82.8% (95% CI, 70.1%-91.2%) for premolars and 73.4% (95% CI, 59.9%-84.0%) for molars. Conclusions: We demonstrated that the deep CNN algorithm was useful for assessing the diagnosis and predictability of PCT. Therefore, with further optimization of the PCT dataset and improvements in the algorithm, a computer-aided detection system can be expected to become an effective and efficient method of diagnosing and predicting PCT. © 2018. Korean Academy of Periodontology.","Artificial intelligence; Machine learning; Periodontal diseases; Supervised machine learning","","Korean Academy of Periodontology","20932278","","","","Article","Scopus","2-s2.0-85046764664"
"Trivedi H.; Mesterhazy J.; Laguna B.; Vu T.; Sohn J.H.","Trivedi, Hari (54792314500); Mesterhazy, Joseph (57195633636); Laguna, Benjamin (54418788900); Vu, Thienkhai (57195713446); Sohn, Jae Ho (56985237800)","54792314500; 57195633636; 54418788900; 57195713446; 56985237800","Automatic Determination of the Need for Intravenous Contrast in Musculoskeletal MRI Examinations Using IBM Watson’s Natural Language Processing Algorithm","2018","Journal of Digital Imaging","62","10.1007/s10278-017-0021-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029578434&doi=10.1007%2fs10278-017-0021-3&partnerID=40&md5=c3a8a92de497c212c38ba88b7d031896","Radiology & Biomedical Imaging, UCSF Medical Center, 505 Parnassus Ave, San Francisco, 94158, CA, United States","Trivedi H., Radiology & Biomedical Imaging, UCSF Medical Center, 505 Parnassus Ave, San Francisco, 94158, CA, United States; Mesterhazy J., Radiology & Biomedical Imaging, UCSF Medical Center, 505 Parnassus Ave, San Francisco, 94158, CA, United States; Laguna B., Radiology & Biomedical Imaging, UCSF Medical Center, 505 Parnassus Ave, San Francisco, 94158, CA, United States; Vu T., Radiology & Biomedical Imaging, UCSF Medical Center, 505 Parnassus Ave, San Francisco, 94158, CA, United States; Sohn J.H., Radiology & Biomedical Imaging, UCSF Medical Center, 505 Parnassus Ave, San Francisco, 94158, CA, United States","Magnetic resonance imaging (MRI) protocoling can be time- and resource-intensive, and protocols can often be suboptimal dependent upon the expertise or preferences of the protocoling radiologist. Providing a best-practice recommendation for an MRI protocol has the potential to improve efficiency and decrease the likelihood of a suboptimal or erroneous study. The goal of this study was to develop and validate a machine learning-based natural language classifier that can automatically assign the use of intravenous contrast for musculoskeletal MRI protocols based upon the free-text clinical indication of the study, thereby improving efficiency of the protocoling radiologist and potentially decreasing errors. We utilized a deep learning-based natural language classification system from IBM Watson, a question-answering supercomputer that gained fame after challenging the best human players on Jeopardy! in 2011. We compared this solution to a series of traditional machine learning-based natural language processing techniques that utilize a term-document frequency matrix. Each classifier was trained with 1240 MRI protocols plus their respective clinical indications and validated with a test set of 280. Ground truth of contrast assignment was obtained from the clinical record. For evaluation of inter-reader agreement, a blinded second reader radiologist analyzed all cases and determined contrast assignment based on only the free-text clinical indication. In the test set, Watson demonstrated overall accuracy of 83.2% when compared to the original protocol. This was similar to the overall accuracy of 80.2% achieved by an ensemble of eight traditional machine learning algorithms based on a term-document matrix. When compared to the second reader’s contrast assignment, Watson achieved 88.6% agreement. When evaluating only the subset of cases where the original protocol and second reader were concordant (n = 251), agreement climbed further to 90.0%. The classifier was relatively robust to spelling and grammatical errors, which were frequent. Implementation of this automated MR contrast determination system as a clinical decision support tool may save considerable time and effort of the radiologist while potentially decreasing error rates, and require no change in order entry or workflow. © 2017, Society for Imaging Informatics in Medicine.","Artificial intelligence; Deep learning; IBM Watson; Imaging protocol; Machine learning; Natural language processing (NLP); Quality improvement; Workflow efficiency","Algorithms; Contrast Media; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Injections, Intravenous; Magnetic Resonance Imaging; Musculoskeletal Diseases; Musculoskeletal System; Natural Language Processing; Reproducibility of Results; Retrospective Studies; Artificial intelligence; Classification (of information); Decision support systems; Deep learning; Efficiency; Errors; Learning systems; Magnetic levitation vehicles; Magnetic resonance imaging; Musculoskeletal system; Natural language processing systems; Supercomputers; contrast medium; Automatic determination; Classification system; Clinical decision support; IBM Watson; Imaging protocol; Improving efficiency; Intravenous contrast; Quality improvement; algorithm; computer assisted diagnosis; diagnostic imaging; human; image enhancement; intravenous drug administration; musculoskeletal disease; musculoskeletal system; natural language processing; nuclear magnetic resonance imaging; procedures; reproducibility; retrospective study; Learning algorithms","Springer New York LLC","08971889","","JDIME","28924815","Article","Scopus","2-s2.0-85029578434"
"Wang H.; Dai L.; Cai Y.; Sun X.; Chen L.","Wang, Hai (56193358000); Dai, Lei (57129706500); Cai, Yingfeng (26423580200); Sun, Xiaoqiang (55951382300); Chen, Long (55739181700)","56193358000; 57129706500; 26423580200; 55951382300; 55739181700","Salient object detection based on multi-scale contrast","2018","Neural Networks","61","10.1016/j.neunet.2018.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042356013&doi=10.1016%2fj.neunet.2018.02.005&partnerID=40&md5=daa65eee6b40cdb79b16a6f117a3e02b","School of Automotive and Traffic Engineering, Jiangsu University, Zhenjiang, 212013, China; Automotive Engineering Research Institute, Jiangsu University, Zhenjiang, 212013, China","Wang H., School of Automotive and Traffic Engineering, Jiangsu University, Zhenjiang, 212013, China; Dai L., School of Automotive and Traffic Engineering, Jiangsu University, Zhenjiang, 212013, China; Cai Y., Automotive Engineering Research Institute, Jiangsu University, Zhenjiang, 212013, China; Sun X., Automotive Engineering Research Institute, Jiangsu University, Zhenjiang, 212013, China; Chen L., Automotive Engineering Research Institute, Jiangsu University, Zhenjiang, 212013, China","Due to the development of deep learning networks, a salient object detection based on deep learning networks, which are used to extract the features, has made a great breakthrough compared to the traditional methods. At present, the salient object detection mainly relies on very deep convolutional network, which is used to extract the features. In deep learning networks, an dramatic increase of network depth may cause more training errors instead. In this paper, we use the residual network to increase network depth and to mitigate the errors caused by depth increase simultaneously. Inspired by image simplification, we use color and texture features to obtain simplified image with multiple scales by means of region assimilation on the basis of super-pixels in order to reduce the complexity of images and to improve the accuracy of salient target detection. We refine the feature on pixel level by the multi-scale feature correction method to avoid the feature error when the image is simplified at the above-mentioned region level. The final full connection layer not only integrates features of multi-scale and multi-level but also works as classifier of salient targets. The experimental results show that proposed model achieves better results than other salient object detection models based on original deep learning networks. © 2018 Elsevier Ltd","Deep learning; Image simplification; Residual network; Saliency detection","Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Deep learning; Errors; Feature extraction; Image enhancement; Object recognition; Pixels; Color and texture features; Convolutional networks; Correction method; Image simplification; Multi-scale features; Saliency detection; Salient object detection; Salient target detections; Article; artificial neural network; color; contrast enhancement; convolutional neural network; image analysis; image processing; image quality; learning algorithm; model; priority journal; salience network; artificial neural network; automated pattern recognition; image processing; machine learning; procedures; Object detection","Elsevier Ltd","08936080","","NNETE","29486380","Article","Scopus","2-s2.0-85042356013"
"Kim J.-S.; Gao X.; Rzhetsky A.","Kim, Ji-Sung (57201879629); Gao, Xin (55712115900); Rzhetsky, Andrey (35465167600)","57201879629; 55712115900; 35465167600","RIDDLE: Race and ethnicity Imputation from Disease history with Deep LEarning","2018","PLoS Computational Biology","14","10.1371/journal.pcbi.1006106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046371334&doi=10.1371%2fjournal.pcbi.1006106&partnerID=40&md5=2508c741324a494e49f7c669084a941a","Department of Computer Science, Princeton University, Princeton, NJ, United States; King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, Saudi Arabia; Institute for Genomics and Systems Biology, Computation Institute, Departments of Medicine and Human Genetics, University of Chicago, Chicago, IL, United States","Kim J.-S., Department of Computer Science, Princeton University, Princeton, NJ, United States; Gao X., King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, Saudi Arabia; Rzhetsky A., Institute for Genomics and Systems Biology, Computation Institute, Departments of Medicine and Human Genetics, University of Chicago, Chicago, IL, United States","Anonymized electronic medical records are an increasingly popular source of research data. However, these datasets often lack race and ethnicity information. This creates problems for researchers modeling human disease, as race and ethnicity are powerful confounders for many health exposures and treatment outcomes; race and ethnicity are closely linked to population-specific genetic variation. We showed that deep neural networks generate more accurate estimates for missing racial and ethnic information than competing methods (e.g., logistic regression, random forest, support vector machines, and gradient-boosted decision trees). RIDDLE yielded significantly better classification performance across all metrics that were considered: accuracy, cross-entropy loss (error), precision, recall, and area under the curve for receiver operating characteristic plots (all p < 10−9). We made specific efforts to interpret the trained neural network models to identify, quantify, and visualize medical features which are predictive of race and ethnicity. We used these characterizations of informative features to perform a systematic comparison of differential disease patterns by race and ethnicity. The fact that clinical histories are informative for imputing race and ethnicity could reflect (1) a skewed distribution of blue- and white-collar professions across racial and ethnic groups, (2) uneven accessibility and subjective importance of prophylactic health, (3) possible variation in lifestyle, such as dietary habits, and (4) differences in background genetic variation which predispose to diseases. © 2018 Kim et al.","","Computational Biology; Continental Population Groups; Electronic Health Records; Epidemiologic Factors; Ethnic Groups; Genetic Predisposition to Disease; Genetic Variation; Genetics, Population; Humans; Neural Networks (Computer); Supervised Machine Learning; Decision trees; Deep neural networks; Medical computing; Neural network models; Support vector machines; Boosted decision trees; Confounder; Genetic variation; Human disease; Logistics regressions; Medical record; Random forests; Research data; Support vectors machine; Treatment outcomes; Article; classification algorithm; deep learning; ethnicity; false positive result; machine learning; measurement accuracy; medical history; predictive value; race; receiver operating characteristic; support vector machine; ancestry group; artificial neural network; biology; electronic health record; epidemiology; ethnic group; genetic predisposition; genetic variation; genetics; human; population genetics; statistics and numerical data; supervised machine learning; Genes","Public Library of Science","1553734X","","","29698408","Article","Scopus","2-s2.0-85046371334"
"Ma J.; Deng X.; Wang L.","Ma, Jian (57220169757); Deng, Xiaogang (55128802500); Wang, Lei (57191964952)","57220169757; 55128802500; 57191964952","Industrial process soft sensor method based on deep learning ensemble support vector machine","2018","Huagong Xuebao/CIESC Journal","6","10.11949/j.issn.0438-1157.20171050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097115669&doi=10.11949%2fj.issn.0438-1157.20171050&partnerID=40&md5=d3d70137e8c6cfdc9ed19333fa484d18","College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, Shandong, China","Ma J., College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, Shandong, China; Deng X., College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, Shandong, China; Wang L., College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, Shandong, China","The soft sensor modeling method based on support vector machine (SVM) has been widely used in the field of industrial process control. However, the traditional support vector machine directly models the original measurement variables without fully extracting the intrinsic data information to improve the prediction accuracy. Aiming at this problem, a soft sensor modeling method based on deep ensemble support vector machine (DESVM) is proposed in this paper. Firstly, this method uses the deep belief network (DBN) to carry on the deep information mining, and extracts the intrinsic data characteristic. Then the ensemble learning strategy based on the Bagging algorithm is introduced to construct the ensemble support vector machine model based on the deep data characteristic, which can enhance generalization ability of soft measurement prediction model. Finally, the applications on a numerical system and real industrial data are used to validate the proposed method. The results show that the proposed method can effectively improve the prediction accuracy of the soft vector model of support vector machine and can predict the change of process quality index better. © All Right Reserved.","Deep belief network; Ensemble learning; Prediction; Soft sensor; Support vector machine","Data mining; Forecasting; Learning systems; Numerical methods; Predictive analytics; Support vector machines; Vectors; Deep belief network (DBN); Deep belief networks; Ensemble learning; Generalization ability; Industrial process control; Process quality indices; Soft sensors; Support vector machine models; Deep learning","Materials China","04381157","","HUKHA","","Article","Scopus","2-s2.0-85097115669"
"Huang L.; Liao L.; Wu C.H.","Huang, Lei (57188698523); Liao, Li (35787422600); Wu, Cathy H. (58071565800)","57188698523; 35787422600; 58071565800","Completing sparse and disconnected protein-protein network by deep learning","2018","BMC Bioinformatics","12","10.1186/s12859-018-2112-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044263378&doi=10.1186%2fs12859-018-2112-7&partnerID=40&md5=1dddceb1da12b29d3170d3d7921b9b08","University of Delaware, Department of Computer and Information Sciences, 18 Amstel Avenue, Newark, 19716, DE, United States; University of Delaware, Center for Bioinformatics and Computational Biology, 15 Innovation Way, Newark, 19711, DE, United States","Huang L., University of Delaware, Department of Computer and Information Sciences, 18 Amstel Avenue, Newark, 19716, DE, United States; Liao L., University of Delaware, Department of Computer and Information Sciences, 18 Amstel Avenue, Newark, 19716, DE, United States; Wu C.H., University of Delaware, Department of Computer and Information Sciences, 18 Amstel Avenue, Newark, 19716, DE, United States, University of Delaware, Center for Bioinformatics and Computational Biology, 15 Innovation Way, Newark, 19711, DE, United States","Background: Protein-protein interaction (PPI) prediction remains a central task in systems biology to achieve a better and holistic understanding of cellular and intracellular processes. Recently, an increasing number of computational methods have shifted from pair-wise prediction to network level prediction. Many of the existing network level methods predict PPIs under the assumption that the training network should be connected. However, this assumption greatly affects the prediction power and limits the application area because the current golden standard PPI networks are usually very sparse and disconnected. Therefore, how to effectively predict PPIs based on a training network that is sparse and disconnected remains a challenge. Results: In this work, we developed a novel PPI prediction method based on deep learning neural network and regularized Laplacian kernel. We use a neural network with an autoencoder-like architecture to implicitly simulate the evolutionary processes of a PPI network. Neurons of the output layer correspond to proteins and are labeled with values (1 for interaction and 0 for otherwise) from the adjacency matrix of a sparse disconnected training PPI network. Unlike autoencoder, neurons at the input layer are given all zero input, reflecting an assumption of no a priori knowledge about PPIs, and hidden layers of smaller sizes mimic ancient interactome at different times during evolution. After the training step, an evolved PPI network whose rows are outputs of the neural network can be obtained. We then predict PPIs by applying the regularized Laplacian kernel to the transition matrix that is built upon the evolved PPI network. The results from cross-validation experiments show that the PPI prediction accuracies for yeast data and human data measured as AUC are increased by up to 8.4 and 14.9% respectively, as compared to the baseline. Moreover, the evolved PPI network can also help us leverage complementary information from the disconnected training network and multiple heterogeneous data sources. Tested by the yeast data with six heterogeneous feature kernels, the results show our method can further improve the prediction performance by up to 2%, which is very close to an upper bound that is obtained by an Approximate Bayesian Computation based sampling method. Conclusions: The proposed evolution deep neural network, coupled with regularized Laplacian kernel, is an effective tool in completing sparse and disconnected PPI networks and in facilitating integration of heterogeneous data sources. © 2018 The Author(s).","Disconnected protein interaction network; Interaction prediction; Network evolution; Neural network; Regularized Laplacian","Algorithms; Area Under Curve; Bayes Theorem; Humans; Machine Learning; Neural Networks (Computer); Protein Interaction Maps; Proteins; ROC Curve; Saccharomyces cerevisiae; Bayesian networks; Biology; Deep neural networks; Forecasting; Laplace transforms; Learning systems; Matrix algebra; Neural networks; Proteins; Yeast; protein; Heterogeneous data sources; Interaction prediction; Laplacians; Learning neural networks; Multiple heterogeneous data source; Network evolution; Protein interaction networks; Protein-protein interactions; article; gold standard; human; human versus nonhuman data; learning; nerve cell; nonhuman; prediction; protein protein interaction; sampling; validation process; yeast; algorithm; area under the curve; artificial neural network; Bayes theorem; machine learning; metabolism; protein analysis; receiver operating characteristic; Saccharomyces cerevisiae; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","29566671","Article","Scopus","2-s2.0-85044263378"
"Kadari R.; Zhang Y.; Zhang W.; Liu T.","Kadari, Rekia (57199843099); Zhang, Yu (55949765600); Zhang, Weinan (57221430114); Liu, Ting (35080762900)","57199843099; 55949765600; 57221430114; 35080762900","CCG supertagging via Bidirectional LSTM-CRF neural architecture","2018","Neurocomputing","30","10.1016/j.neucom.2017.12.050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044860068&doi=10.1016%2fj.neucom.2017.12.050&partnerID=40&md5=4ba7d57b095c5c7b9b2f150400e206ba","Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China","Kadari R., Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China; Zhang Y., Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China; Zhang W., Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China; Liu T., Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China","Sequence labeling is the widely used method for CCG supertagging task where a supertag (lexical category) is assigned to each word in an input sentence. In CCG supertagging the major challenging problem is due to the large number of lexical categories. To address this, machine learning and deep learning methods have been used and achieved promising results. However, these models whether use many hand-crafted features case of machine learning methods or use sentence level representation processing a sequence without any correlations between labels in neighborhoods which have great influences on predicting the current label case of deep learning models. More recently, there is a marriage of machine learning and deep learning models. In this paper, we use the combination of Conditional Random Field and Bidirectional Long Short-Term Memory models. So first the model learns sentence representation where we can gain from both past and future input features thanks to Bidirectional Long Short-Term Memory Networks architecture. Afterward, the model uses sentence level tag information thanks to Conditional Random Field model. By combining Bidirectional Long Short-Term Memory and Conditional Random Field (BLSTM-CRF) models, we evaluate our model on in-domain and out-of-domain datasets, and in both cases achieve (or close to) state-of-the-art results on CCG supertagging task. © 2017","CCG supertagging; Combinatory Categorial Grammar; Deep learning; Machine learning; Neural Network","Brain; Computational grammars; Deep learning; Learning systems; Memory architecture; Network architecture; Neural networks; Random processes; Syntactics; CCG supertagging; Combinatory categorial grammar; Conditional random field; Lexical categories; Machine learning methods; Neural architectures; Sequence Labeling; Short term memory; Article; artificial neural network; Bidirectional Long Short Term Memory and Conditional Random Field model; controlled study; data processing; machine learning; measurement accuracy; prediction; priority journal; probability; process optimization; Recurrent Neural Network; Long short-term memory","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85044860068"
"Yildirim Ö.","Yildirim, Özal (55293146500)","55293146500","A novel wavelet sequences based on deep bidirectional LSTM network model for ECG signal classification","2018","Computers in Biology and Medicine","551","10.1016/j.compbiomed.2018.03.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044597280&doi=10.1016%2fj.compbiomed.2018.03.016&partnerID=40&md5=01ac0753595263ceda5ff2c88bca3669","Computer Engineering Department, Engineering Faculty, Munzur University, Tunceli, Turkey","Yildirim Ö., Computer Engineering Department, Engineering Faculty, Munzur University, Tunceli, Turkey","Long-short term memory networks (LSTMs), which have recently emerged in sequential data analysis, are the most widely used type of recurrent neural networks (RNNs) architecture. Progress on the topic of deep learning includes successful adaptations of deep versions of these architectures. In this study, a new model for deep bidirectional LSTM network-based wavelet sequences called DBLSTM-WS was proposed for classifying electrocardiogram (ECG) signals. For this purpose, a new wavelet-based layer is implemented to generate ECG signal sequences. The ECG signals were decomposed into frequency sub-bands at different scales in this layer. These sub-bands are used as sequences for the input of LSTM networks. New network models that include unidirectional (ULSTM) and bidirectional (BLSTM) structures are designed for performance comparisons. Experimental studies have been performed for five different types of heartbeats obtained from the MIT-BIH arrhythmia database. These five types are Normal Sinus Rhythm (NSR), Ventricular Premature Contraction (VPC), Paced Beat (PB), Left Bundle Branch Block (LBBB), and Right Bundle Branch Block (RBBB). The results show that the DBLSTM-WS model gives a high recognition performance of 99.39%. It has been observed that the wavelet-based layer proposed in the study significantly improves the recognition performance of conventional networks. This proposed network structure is an important approach that can be applied to similar signal processing problems. © 2018 Elsevier Ltd","Deep learning; ECG signals; Long-short term memory; Recurrent neural networks","Arrhythmias, Cardiac; Deep Learning; Electrocardiography; Heart Rate; Humans; Signal Processing, Computer-Assisted; Brain; Deep learning; Electrocardiography; Long short-term memory; Memory architecture; Network architecture; Recurrent neural networks; ECG signals; Electrocardiogram signal; Normal sinus rhythm; Performance comparison; Recurrent neural network (RNNs); Sequential data analysis; Signal processing problems; Ventricular premature contractions; Article; electrocardiogram; electrocardiography; heart beat; heart left bundle branch block; heart pacing; heart right bundle branch block; heart ventricle extrasystole; human; long short term memory network; machine learning; priority journal; recognition; signal processing; sinus rhythm; wavelet analysis; diagnostic imaging; heart arrhythmia; heart rate; procedures; Biomedical signal processing","Elsevier Ltd","00104825","","CBMDA","29614430","Article","Scopus","2-s2.0-85044597280"
"Kim D.H.; MacKinnon T.","Kim, D.H. (57005694600); MacKinnon, T. (57199685233)","57005694600; 57199685233","Artificial intelligence in fracture detection: transfer learning from deep convolutional neural networks","2018","Clinical Radiology","291","10.1016/j.crad.2017.11.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038394587&doi=10.1016%2fj.crad.2017.11.015&partnerID=40&md5=cbf3bdf14bd40d107fca3b0777f5f671","Medical Imaging Department, Royal Devon and Exeter Hospital, Barrack Road, Exeter, EX2 5DW, United Kingdom","Kim D.H., Medical Imaging Department, Royal Devon and Exeter Hospital, Barrack Road, Exeter, EX2 5DW, United Kingdom; MacKinnon T., Medical Imaging Department, Royal Devon and Exeter Hospital, Barrack Road, Exeter, EX2 5DW, United Kingdom","Aim: To identify the extent to which transfer learning from deep convolutional neural networks (CNNs), pre-trained on non-medical images, can be used for automated fracture detection on plain radiographs. Materials and methods: The top layer of the Inception v3 network was re-trained using lateral wrist radiographs to produce a model for the classification of new studies as either “fracture” or “no fracture”. The model was trained on a total of 11,112 images, after an eightfold data augmentation technique, from an initial set of 1,389 radiographs (695 “fracture” and 694 “no fracture”). The training data set was split 80:10:10 into training, validation, and test groups, respectively. An additional 100 wrist radiographs, comprising 50 “fracture” and 50 “no fracture” images, were used for final testing and statistical analysis. Results: The area under the receiver operator characteristic curve (AUC) for this test was 0.954. Setting the diagnostic cut-off at a threshold designed to maximise both sensitivity and specificity resulted in values of 0.9 and 0.88, respectively. Conclusion: The AUC scores for this test were comparable to state-of-the-art providing proof of concept for transfer learning from CNNs in fracture detection on plain radiographs. This was achieved using only a moderate sample size. This technique is largely transferable, and therefore, has many potential applications in medical imaging, which may lead to significant improvements in workflow productivity and in clinical risk reduction. © 2017 The Royal College of Radiologists","","Artificial Intelligence; Deep Learning; Diagnosis, Differential; Fractures, Bone; Humans; Machine Learning; Neural Networks (Computer); Radiographic Image Interpretation, Computer-Assisted; Sensitivity and Specificity; area under the curve; Article; artificial intelligence; artificial neural network; automation; bone radiography; computer assisted diagnosis; deep convolutional neural network; diagnostic accuracy; human; image processing; priority journal; receiver operating characteristic; retrospective study; transfer of learning; wrist fracture; wrist radiography; artificial neural network; computer assisted diagnosis; diagnostic imaging; differential diagnosis; fracture; machine learning; sensitivity and specificity","W.B. Saunders Ltd","00099260","","CLRAA","29269036","Article","Scopus","2-s2.0-85038394587"
"Gautam D.; Ahmed M.; Meena Y.K.; Ul Haq A.","Gautam, Diwakar (56352110500); Ahmed, Mushtaq (56542297400); Meena, Yogesh Kumar (37036259000); Ul Haq, Ahtesham (57200689964)","56352110500; 56542297400; 37036259000; 57200689964","Machine learning–based diagnosis of melanoma using macro images","2018","International Journal for Numerical Methods in Biomedical Engineering","30","10.1002/cnm.2953","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042181700&doi=10.1002%2fcnm.2953&partnerID=40&md5=34d005abd4032ef2b6c53d73efe50971","Malaviya National Institute of Technology, Jaipur, India; Kota Heart Hospital, Kota, India","Gautam D., Malaviya National Institute of Technology, Jaipur, India; Ahmed M., Malaviya National Institute of Technology, Jaipur, India; Meena Y.K., Malaviya National Institute of Technology, Jaipur, India; Ul Haq A., Kota Heart Hospital, Kota, India","Cancer bears a poisoning threat to human society. Melanoma, the skin cancer, originates from skin layers and penetrates deep into subcutaneous layers. There exists an extensive research in melanoma diagnosis using dermatoscopic images captured through a dermatoscope. While designing a diagnostic model for general handheld imaging systems is an emerging trend, this article proposes a computer-aided decision support system for macro images captured by a general-purpose camera. General imaging conditions are adversely affected by nonuniform illumination, which further affects the extraction of relevant information. To mitigate it, we process an image to define a smooth illumination surface using the multistage illumination compensation approach, and the infected region is extracted using the proposed multimode segmentation method. The lesion information is numerated as a feature set comprising geometry, photometry, border series, and texture measures. The redundancy in feature set is reduced using information theory methods, and a classification boundary is modeled to distinguish benign and malignant samples using support vector machine, random forest, neural network, and fast discriminative mixed-membership–based naive Bayesian classifiers. Moreover, the experimental outcome is supported by hypothesis testing and boxplot representation for classification losses. The simulation results prove the significance of the proposed model that shows an improved performance as compared with competing arts. Copyright © 2017 John Wiley & Sons, Ltd.","benign and malignant melanoma; computer-aided decision support system; feature selection; information theory; machine learning; texture","Algorithms; Bayes Theorem; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Melanoma; Support Vector Machine; Artificial intelligence; Classification (of information); Computer aided instruction; Decision support systems; Decision theory; Decision trees; Dermatology; Diseases; Feature extraction; Image segmentation; Information theory; Learning systems; Macros; Oncology; Textures; Classification boundary; Computer-aided decision supports; Hypothesis testing; Illumination compensation; Malignant melanoma; Naive Bayesian Classifier; Non-uniform illumination; Segmentation methods; algorithm; Bayes theorem; computer assisted diagnosis; human; machine learning; melanoma; support vector machine; Image processing","Wiley-Blackwell","20407939","","","29266819","Article","Scopus","2-s2.0-85042181700"
"Lee H.; Hong H.; Kim J.; Jung D.C.","Lee, Hansang (54784736000); Hong, Helen (8731445000); Kim, Junmo (36015494900); Jung, Dae Chul (23485390000)","54784736000; 8731445000; 36015494900; 23485390000","Deep feature classification of angiomyolipoma without visible fat and renal cell carcinoma in abdominal contrast-enhanced CT images with texture image patches and hand-crafted feature concatenation","2018","Medical Physics","63","10.1002/mp.12828","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045415415&doi=10.1002%2fmp.12828&partnerID=40&md5=ee77f3be5221ceb1e10eae77e6109370","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Department of Software Convergence, College of Interdisciplinary Studies for Emerging Industries, Seoul Women's University, 621 Hwarang-ro, Nowon-gu, Seoul, 01797, South Korea; Department of Radiology, Severance Hospital, Research Institute of Radiological Science, Yonsei University College of Medicine, 50-1 Yonsei-ro, Seodaemun-gu, Seoul, 03722, South Korea","Lee H., School of Electrical Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Hong H., Department of Software Convergence, College of Interdisciplinary Studies for Emerging Industries, Seoul Women's University, 621 Hwarang-ro, Nowon-gu, Seoul, 01797, South Korea; Kim J., School of Electrical Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Jung D.C., Department of Radiology, Severance Hospital, Research Institute of Radiological Science, Yonsei University College of Medicine, 50-1 Yonsei-ro, Seodaemun-gu, Seoul, 03722, South Korea","Purpose: To develop an automatic deep feature classification (DFC) method for distinguishing benign angiomyolipoma without visible fat (AMLwvf) from malignant clear cell renal cell carcinoma (ccRCC) from abdominal contrast-enhanced computer tomography (CE CT) images. Methods: A dataset including 80 abdominal CT images of 39 AMLwvf and 41 ccRCC patients was used. We proposed a DFC method for differentiating the small renal masses (SRM) into AMLwvf and ccRCC using the combination of hand-crafted and deep features, and machine learning classifiers. First, 71-dimensional hand-crafted features (HCF) of texture and shape were extracted from the SRM contours. Second, 1000–4000-dimensional deep features (DF) were extracted from the ImageNet pretrained deep learning model with the SRM image patches. In DF extraction, we proposed the texture image patches (TIP) to emphasize the texture information inside the mass in DFs and reduce the mass size variability. Finally, the two features were concatenated and the random forest (RF) classifier was trained on these concatenated features to classify the types of SRMs. The proposed method was tested on our dataset using leave-one-out cross-validation and evaluated using accuracy, sensitivity, specificity, positive predictive values (PPV), negative predictive values (NPV), and area under receiver operating characteristics curve (AUC). In experiments, the combinations of four deep learning models, AlexNet, VGGNet, GoogleNet, and ResNet, and four input image patches, including original, masked, mass-size, and texture image patches, were compared and analyzed. Results: In qualitative evaluation, we observed the change in feature distributions between the proposed and comparative methods using tSNE method. In quantitative evaluation, we evaluated and compared the classification results, and observed that (a) the proposed HCF + DF outperformed HCF-only and DF-only, (b) AlexNet showed generally the best performances among the CNN models, and (c) the proposed TIPs not only achieved the competitive performances among the input patches, but also steady performance regardless of CNN models. As a result, the proposed method achieved the accuracy of 76.6 ± 1.4% for the proposed HCF + DF with AlexNet and TIPs, which improved the accuracy by 6.6%p and 8.3%p compared to HCF-only and DF-only, respectively. Conclusions: The proposed shape features and TIPs improved the HCFs and DFs, respectively, and the feature concatenation further enhanced the quality of features for differentiating AMLwvf from ccRCC in abdominal CE CT images. © 2018 American Association of Physicists in Medicine","angiomyolipoma without visible fat (AMLwvf); clear cell renal cell carcinoma (ccRCC); computed tomography (CT); computer-aided diagnosis (CAD); deep feature classification","Angiomyolipoma; Carcinoma, Renal Cell; Contrast Media; Diagnosis, Differential; Humans; Image Processing, Computer-Assisted; Kidney Neoplasms; Machine Learning; Radiography, Abdominal; Sensitivity and Specificity; Tomography, X-Ray Computed; Cells; Classification (of information); Computerized tomography; Cytology; Decision trees; Deep learning; Image classification; Image enhancement; Image segmentation; Image texture; Statistical methods; Textures; iobitridol; contrast medium; Angiomyolipoma; Angiomyolipoma without visible fat; Clear cell renal cell carcinoma; Computed tomography; Computer-aided diagnose; Contrast-enhanced; Deep feature classification; Feature classification; Image patches; Renal cell carcinoma; angiomyolipoma; Article; cancer classification; classification algorithm; classifier; contrast enhancement; deep feature classification; diagnostic accuracy; diagnostic test accuracy study; human; kidney tumor; major clinical study; predictive value; qualitative analysis; random forest; receiver operating characteristic; renal angiomyolipoma; renal cell carcinoma; sensitivity and specificity; x-ray computed tomography; abdominal radiography; angiomyolipoma; diagnostic imaging; differential diagnosis; image processing; kidney tumor; machine learning; procedures; renal cell carcinoma; Computer aided diagnosis","John Wiley and Sons Ltd","00942405","","MPHYA","29474742","Article","Scopus","2-s2.0-85045415415"
"Kim S.; Lee H.; Kim K.; Kang J.","Kim, Sunkyu (37026402000); Lee, Heewon (57201299439); Kim, Keonwoo (57201703594); Kang, Jaewoo (8914056400)","37026402000; 57201299439; 57201703594; 8914056400","Mut2Vec: Distributed representation of cancerous mutations","2018","BMC Medical Genomics","28","10.1186/s12920-018-0349-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045845251&doi=10.1186%2fs12920-018-0349-7&partnerID=40&md5=5c83043e447e8272c7d164ee187c5d86","Department of Computer Science and Engineering, Korea University, Seoul, South Korea; Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, South Korea","Kim S., Department of Computer Science and Engineering, Korea University, Seoul, South Korea; Lee H., Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, South Korea; Kim K., Department of Computer Science and Engineering, Korea University, Seoul, South Korea; Kang J., Department of Computer Science and Engineering, Korea University, Seoul, South Korea, Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, South Korea","Background: Embedding techniques for converting high-dimensional sparse data into low-dimensional distributed representations have been gaining popularity in various fields of research. In deep learning models, embedding is commonly used and proven to be more effective than naive binary representation. However, yet no attempt has been made to embed highly sparse mutation profiles into densely distributed representations. Since binary representation does not capture biological context, its use is limited in many applications such as discovering novel driver mutations. Additionally, training distributed representations of mutations is challenging due to a relatively small amount of available biological data compared with the large amount of text corpus data in text mining fields. Methods: We introduce Mut2Vec, a novel computational pipeline that can be used to create a distributed representation of cancerous mutations. Mut2Vec is trained on cancer profiles using Skip-Gram since cancer can be characterized by a series of co-occurring mutations. We also augmented our pipeline with existing information in the biomedical literature and protein-protein interaction networks to compensate for the data insufficiency. Results: To evaluate our models, we conducted two experiments that involved the following tasks: a) visualizing driver and passenger mutations, b) identifying novel driver mutations using a clustering method. Our visualization showed a clear distinction between passenger mutations and driver mutations. We also found driver mutation candidates and proved that these were true driver mutations based on our literature survey. The pre-trained mutation vectors and the candidate driver mutations are publicly available at http://infos.korea.ac.kr/mut2vec. Conclusions: We introduce Mut2Vec that can be utilized to generate distributed representations of mutations and experimentally validate the efficacy of the generated mutation representations. Mut2Vec can be used in various deep learning applications such as cancer classification and drug sensitivity prediction. © 2018 The Author(s).","Cancer; Deep learning; Distributed representation; Mut2Vec; Mutation embedding","Computational Biology; Models, Genetic; Mutation; Neoplasms; Neural Networks (Computer); Article; cancer cell; cancer classification; gene mutation; human; information system; Internet; machine learning; malignant neoplasm; Mut2Vec; natural language processing; priority journal; protein protein interaction; artificial neural network; biological model; biology; genetics; mutation; neoplasm; procedures","BioMed Central Ltd.","17558794","","","29697361","Article","Scopus","2-s2.0-85045845251"
"Avsec Z.; Barekatain M.; Cheng J.; Gagneur J.","Avsec, Ziga (57192835030); Barekatain, Mohammadamin (56732801500); Cheng, Jun (34976376600); Gagneur, Julien (14046789700)","57192835030; 56732801500; 34976376600; 14046789700","Modeling positional effects of regulatory sequences with spline transformations increases prediction accuracy of deep neural networks","2018","Bioinformatics","20","10.1093/bioinformatics/btx727","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046801446&doi=10.1093%2fbioinformatics%2fbtx727&partnerID=40&md5=f4f9221c68ae31b4101c49ea1185f7b9","Department of Informatics, Technical University of Munich, Garching, 85748, Germany; Graduate School of Quantitative Biosciences (QBM), Gene Center, Ludwig-Maximilians-Universität München, Munich, 81377, Germany","Avsec Z., Department of Informatics, Technical University of Munich, Garching, 85748, Germany, Graduate School of Quantitative Biosciences (QBM), Gene Center, Ludwig-Maximilians-Universität München, Munich, 81377, Germany; Barekatain M., Department of Informatics, Technical University of Munich, Garching, 85748, Germany; Cheng J., Department of Informatics, Technical University of Munich, Garching, 85748, Germany, Graduate School of Quantitative Biosciences (QBM), Gene Center, Ludwig-Maximilians-Universität München, Munich, 81377, Germany; Gagneur J., Department of Informatics, Technical University of Munich, Garching, 85748, Germany","Motivation Regulatory sequences are not solely defined by their nucleic acid sequence but also by their relative distances to genomic landmarks such as transcription start site, exon boundaries or polyadenylation site. Deep learning has become the approach of choice for modeling regulatory sequences because of its strength to learn complex sequence features. However, modeling relative distances to genomic landmarks in deep neural networks has not been addressed. Results Here we developed spline transformation, a neural network module based on splines to flexibly and robustly model distances. Modeling distances to various genomic landmarks with spline transformations significantly increased state-of-the-art prediction accuracy of in vivo RNA-binding protein binding sites for 120 out of 123 proteins. We also developed a deep neural network for human splice branchpoint based on spline transformations that outperformed the current best, already distance-based, machine learning model. Compared to piecewise linear transformation, as obtained by composition of rectified linear units, spline transformation yields higher prediction accuracy as well as faster and more robust training. As spline transformation can be applied to further quantities beyond distances, such as methylation or conservation, we foresee it as a versatile component in the genomics deep learning toolbox. © 2017 The Author. Published by Oxford University Press. All rights reserved.","","DNA; Genomics; Hep G2 Cells; Humans; K562 Cells; Machine Learning; Models, Genetic; Neural Networks (Computer); Protein Binding; Proteins; Regulatory Sequences, Nucleic Acid; RNA; Sequence Analysis, DNA; Sequence Analysis, RNA; Software; DNA; protein; protein binding; RNA; artificial neural network; biological model; DNA sequence; genomics; Hep-G2 cell line; human; K-562 cell line; machine learning; metabolism; procedures; regulatory sequence; sequence analysis; software","Oxford University Press","13674803","","BOINF","29155928","Article","Scopus","2-s2.0-85046801446"
"Yang J.; Sun W.; Liu N.; Chen Y.; Wang Y.; Han S.","Yang, Jucheng (25930235600); Sun, Wenhui (57191694218); Liu, Na (57007556200); Chen, Yarui (25929888400); Wang, Yuan (56572214700); Han, Shujie (57201776906)","25930235600; 57191694218; 57007556200; 25929888400; 56572214700; 57201776906","A novel multimodal biometrics recognition model based on stacked ELM and CCA methods","2018","Symmetry","17","10.3390/sym10040096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046091272&doi=10.3390%2fsym10040096&partnerID=40&md5=7224a8c298695c2a672d73dfc5aa32ac","College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin, 300457, China","Yang J., College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin, 300457, China; Sun W., College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin, 300457, China; Liu N., College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin, 300457, China; Chen Y., College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin, 300457, China; Wang Y., College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin, 300457, China; Han S., College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin, 300457, China","Multimodal biometrics combine a variety of biological features to have a significant impact on identification performance, which is a newly developed trend in biometrics identification technology. This study proposes a novel multimodal biometrics recognition model based on the stacked extreme learning machines (ELMs) and canonical correlation analysis (CCA) methods. The model, which has a symmetric structure, is found to have high potential for multimodal biometrics. The model works as follows. First, it learns the hidden-layer representation of biological images using extreme learning machines layer by layer. Second, the canonical correlation analysis method is applied to map the representation to a feature space, which is used to reconstruct the multimodal image feature representation. Third, the reconstructed features are used as the input of a classifier for supervised training and output. To verify the validity and efficiency of the method, we adopt it for new hybrid datasets obtained from typical face image datasets and finger-vein image datasets. Our experimental results demonstrate that our model performs better than traditional methods. © 2018 by the authors.","Canonical correlation analysis; Deep network; Extreme learning machine; Multimodal biometrics","","MDPI AG","20738994","","","","Article","Scopus","2-s2.0-85046091272"
"Kolachalama V.B.; Singh P.; Lin C.Q.; Mun D.; Belghasem M.E.; Henderson J.M.; Francis J.M.; Salant D.J.; Chitalia V.C.","Kolachalama, Vijaya B. (16239501900); Singh, Priyamvada (54795775900); Lin, Christopher Q. (57201450985); Mun, Dan (57201449271); Belghasem, Mostafa E. (56691707700); Henderson, Joel M. (57220733703); Francis, Jean M. (22953763300); Salant, David J. (7006623785); Chitalia, Vipul C. (6507682487)","16239501900; 54795775900; 57201450985; 57201449271; 56691707700; 57220733703; 22953763300; 7006623785; 6507682487","Association of Pathological Fibrosis With Renal Survival Using Deep Neural Networks","2018","Kidney International Reports","104","10.1016/j.ekir.2017.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044436858&doi=10.1016%2fj.ekir.2017.11.002&partnerID=40&md5=df5bfe4d04df66f572e1b4ec5bc1df25","Section of Computational Biomedicine, Department of Medicine, Boston University School of Medicine, Boston, Massachusetts, United States; Whitaker Cardiovascular Institute, Boston University School of Medicine, Boston, Massachusetts, United States; Hariri Institute for Computing and Computational Science & Engineering, Boston University, Boston, MA, United States; Renal Section, Department of Medicine, Boston University School of Medicine, Boston, Massachusetts, United States; College of Engineering, Boston University, Boston, Massachusetts, United States; College of Health & Rehabilitation Sciences: Sargent College, Boston University, Boston, Massachusetts, United States; Department of Pathology and Laboratory Medicine, Boston University School of Medicine, Boston, Massachusetts, United States","Kolachalama V.B., Section of Computational Biomedicine, Department of Medicine, Boston University School of Medicine, Boston, Massachusetts, United States, Whitaker Cardiovascular Institute, Boston University School of Medicine, Boston, Massachusetts, United States, Hariri Institute for Computing and Computational Science & Engineering, Boston University, Boston, MA, United States; Singh P., Renal Section, Department of Medicine, Boston University School of Medicine, Boston, Massachusetts, United States; Lin C.Q., College of Engineering, Boston University, Boston, Massachusetts, United States; Mun D., College of Health & Rehabilitation Sciences: Sargent College, Boston University, Boston, Massachusetts, United States; Belghasem M.E., Department of Pathology and Laboratory Medicine, Boston University School of Medicine, Boston, Massachusetts, United States; Henderson J.M., Department of Pathology and Laboratory Medicine, Boston University School of Medicine, Boston, Massachusetts, United States; Francis J.M., Renal Section, Department of Medicine, Boston University School of Medicine, Boston, Massachusetts, United States; Salant D.J., Renal Section, Department of Medicine, Boston University School of Medicine, Boston, Massachusetts, United States; Chitalia V.C., Whitaker Cardiovascular Institute, Boston University School of Medicine, Boston, Massachusetts, United States, Renal Section, Department of Medicine, Boston University School of Medicine, Boston, Massachusetts, United States","Introduction: Chronic kidney damage is routinely assessed semiquantitatively by scoring the amount of fibrosis and tubular atrophy in a renal biopsy sample. Although image digitization and morphometric techniques can better quantify the extent of histologic damage, we need more widely applicable ways to stratify kidney disease severity. Methods: We leveraged a deep learning architecture to better associate patient-specific histologic images with clinical phenotypes (training classes) including chronic kidney disease (CKD) stage, serum creatinine, and nephrotic-range proteinuria at the time of biopsy, and 1-, 3-, and 5-year renal survival. Trichrome-stained images processed from renal biopsy samples were collected on 171 patients treated at the Boston Medical Center from 2009 to 2012. Six convolutional neural network (CNN) models were trained using these images as inputs and the training classes as outputs, respectively. For comparison, we also trained separate classifiers using the pathologist-estimated fibrosis score (PEFS) as input and the training classes as outputs, respectively. Results: CNN models outperformed PEFS across the classification tasks. Specifically, the CNN model predicted the CKD stage more accurately than the PEFS model (κ = 0.519 vs. 0.051). For creatinine models, the area under curve (AUC) was 0.912 (CNN) versus 0.840 (PEFS). For proteinuria models, AUC was 0.867 (CNN) versus 0.702 (PEFS). AUC values for the CNN models for 1-, 3-, and 5-year renal survival were 0.878, 0.875, and 0.904, respectively, whereas the AUC values for PEFS model were 0.811, 0.800, and 0.786, respectively. Conclusion: The study demonstrates a proof of principle that deep learning can be applied to routine renal biopsy images. © 2017 International Society of Nephrology","histology; machine learning; renal fibrosis; renal survival","","Elsevier Inc","24680249","","","","Article","Scopus","2-s2.0-85044436858"
"Kim H.K.; Min S.; Song M.; Jung S.; Choi J.W.; Kim Y.; Lee S.; Yoon S.; Kim H.","Kim, Hui Kwon (57192435442); Min, Seonwoo (57194152306); Song, Myungjae (56664976800); Jung, Soobin (57192427841); Choi, Jae Woo (57203732650); Kim, Younggwang (57201034342); Lee, Sangeun (56675689600); Yoon, Sungroh (7404035832); Kim, Hyongbum (24280276300)","57192435442; 57194152306; 56664976800; 57192427841; 57203732650; 57201034342; 56675689600; 7404035832; 24280276300","Deep learning improves prediction of CRISPR-Cpf1 guide RNA activity","2018","Nature Biotechnology","202","10.1038/nbt.4061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042934649&doi=10.1038%2fnbt.4061&partnerID=40&md5=9c9e03839c8289a6d38d440e4492d07f","Department of Pharmacology, Yonsei University College of Medicine, Seoul, South Korea; Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, South Korea; Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Graduate School of Biomedical Science and Engineering, Hanyang University, Seoul, South Korea; Severance Biomedical Science Institute, Yonsei University College of Medicine, Seoul, South Korea; Interdisciplinary Program in Bioinformatics, Seoul National University, Seoul, South Korea; Center for Nanomedicine, Institute for Basic Science (IBS), Seoul, South Korea; Yonsei-IBS Institute, Yonsei University, Seoul, South Korea","Kim H.K., Department of Pharmacology, Yonsei University College of Medicine, Seoul, South Korea, Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, South Korea; Min S., Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Song M., Department of Pharmacology, Yonsei University College of Medicine, Seoul, South Korea, Graduate School of Biomedical Science and Engineering, Hanyang University, Seoul, South Korea; Jung S., Department of Pharmacology, Yonsei University College of Medicine, Seoul, South Korea, Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, South Korea; Choi J.W., Department of Pharmacology, Yonsei University College of Medicine, Seoul, South Korea, Severance Biomedical Science Institute, Yonsei University College of Medicine, Seoul, South Korea; Kim Y., Department of Pharmacology, Yonsei University College of Medicine, Seoul, South Korea, Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, South Korea; Lee S., Department of Pharmacology, Yonsei University College of Medicine, Seoul, South Korea, Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, South Korea; Yoon S., Electrical and Computer Engineering, Seoul National University, Seoul, South Korea, Interdisciplinary Program in Bioinformatics, Seoul National University, Seoul, South Korea; Kim H., Department of Pharmacology, Yonsei University College of Medicine, Seoul, South Korea, Brain Korea 21 Plus Project for Medical Sciences, Yonsei University College of Medicine, Seoul, South Korea, Severance Biomedical Science Institute, Yonsei University College of Medicine, Seoul, South Korea, Center for Nanomedicine, Institute for Basic Science (IBS), Seoul, South Korea, Yonsei-IBS Institute, Yonsei University, Seoul, South Korea","We present two algorithms to predict the activity of AsCpf1 guide RNAs. Indel frequencies for 15,000 target sequences were used in a deep-learning framework based on a convolutional neural network to train Seq-deepCpf1. We then incorporated chromatin accessibility information to create the better-performing DeepCpf1 algorithm for cell lines for which such information is available and show that both algorithms outperform previous machine learning algorithms on our own and published data sets. © 2018 Nature America, Inc., part of Springer Nature. All rights reserved.","","Algorithms; Cell Line; CRISPR-Cas Systems; Deep Learning; Endonucleases; Neural Networks (Computer); RNA, Guide; Cell culture; Learning algorithms; Neural networks; Nucleic acids; Cpf1 protein; endonuclease; guide RNA; unclassified drug; endonuclease; guide RNA; Cell lines; Convolutional neural network; Learning frameworks; Target sequences; Article; artificial neural network; cell line; chromatin; controlled study; CRISPR Cas system; embryo; gene frequency; human; human cell; indel mutation; learning algorithm; machine learning; prediction; priority journal; algorithm; CRISPR Cas system; genetics; Deep learning","Nature Publishing Group","10870156","","NABIF","29431740","Article","Scopus","2-s2.0-85042934649"
"Gao S.; Young M.T.; Qiu J.X.; Yoon H.-J.; Christian J.B.; Fearn P.A.; Tourassi G.D.; Ramanthan A.","Gao, Shang (57201077784); Young, Michael T. (57201072456); Qiu, John X. (57200219582); Yoon, Hong-Jun (34874205500); Christian, James B. (57201068744); Fearn, Paul A. (57217963699); Tourassi, Georgia D. (7003845683); Ramanthan, Arvind (57204334274)","57201077784; 57201072456; 57200219582; 34874205500; 57201068744; 57217963699; 7003845683; 57204334274","Hierarchical attention networks for information extraction from cancer pathology reports","2018","Journal of the American Medical Informatics Association","91","10.1093/jamia/ocx131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043351112&doi=10.1093%2fjamia%2focx131&partnerID=40&md5=53edb4a6cfe80806f8d4675681bc4691","Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Surveillance Informatics Branch, Division of Cancer Control and Population Sciences, National Cancer Institute, Bethesda, MD, United States","Gao S., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Young M.T., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Qiu J.X., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Yoon H.-J., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Christian J.B., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Fearn P.A., Surveillance Informatics Branch, Division of Cancer Control and Population Sciences, National Cancer Institute, Bethesda, MD, United States; Tourassi G.D., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Ramanthan A., Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States","Objective: We explored how a deep learning (DL) approach based on hierarchical attention networks (HANs) can improve model performance for multiple information extraction tasks from unstructured cancer pathology reports compared to conventional methods that do not sufficiently capture syntactic and semantic contexts from free-text documents. Materials and Methods: Data for our analyses were obtained from 942 deidentified pathology reports collected by the National Cancer Institute Surveillance, Epidemiology, and End Results program. The HAN was implemented for 2 information extraction tasks: (1) primary site, matched to 12 International Classification of Diseases for Oncology topography codes (7 breast, 5 lung primary sites), and (2) histological grade classification, matched to G1-G4. Model performance metrics were compared to conventional machine learning (ML) approaches including naive Bayes, logistic regression, support vector machine, random forest, and extreme gradient boosting, and other DL models, including a recurrent neural network (RNN), a recurrent neural network with attention (RNN w/A), and a convolutional neural network. Results: Our results demonstrate that for both information tasks, HAN performed significantly better compared to the conventional ML and DL techniques. In particular, across the 2 tasks, the mean micro and macro F-scores for the HAN with pretraining were (0.852,0.708), compared to naive Bayes (0.518, 0.213), logistic regression (0.682, 0.453), support vector machine (0.634, 0.434), random forest (0.698, 0.508), extreme gradient boosting (0.696, 0.522), RNN (0.505, 0.301), RNN w/A (0.637, 0.471), and convolutional neural network (0.714, 0.460). Conclusions: HAN-based DL models show promise in information abstraction tasks within unstructured clinical pathology reports. © The Author 2017. Published by Oxford University Press on behalf of the American Medical Informatics Association.","Attention networks; Classification; Clinical pathology reports; Information retrieval; Recurrent neural nets","Article; Bayesian learning; hierarchical attention network; human; intermethod comparison; International Classification of Diseases for Oncology; logistic regression analysis; machine learning; medical information; natural language processing; random forest; support vector machine","Oxford University Press","10675027","","JAMAF","29155996","Article","Scopus","2-s2.0-85043351112"
"Xia P.; Hu J.; Peng Y.","Xia, Peng (55786581200); Hu, Jie (56239213600); Peng, Yinghong (55754470800)","55786581200; 56239213600; 55754470800","EMG-Based Estimation of Limb Movement Using Deep Learning With Recurrent Convolutional Neural Networks","2018","Artificial Organs","164","10.1111/aor.13004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032230997&doi=10.1111%2faor.13004&partnerID=40&md5=54d2c5e695d9819c82428fb38447c30f","School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China","Xia P., School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Hu J., School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Peng Y., School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China","A novel model based on deep learning is proposed to estimate kinematic information for myoelectric control from multi-channel electromyogram (EMG) signals. The neural information of limb movement is embedded in EMG signals that are influenced by all kinds of factors. In order to overcome the negative effects of variability in signals, the proposed model employs the deep architecture combining convolutional neural networks (CNNs) and recurrent neural networks (RNNs). The EMG signals are transformed to time-frequency frames as the input to the model. The limb movement is estimated by the model that is trained with the gradient descent and backpropagation procedure. We tested the model for simultaneous and proportional estimation of limb movement in eight healthy subjects and compared it with support vector regression (SVR) and CNNs on the same data set. The experimental studies show that the proposed model has higher estimation accuracy and better robustness with respect to time. The combination of CNNs and RNNs can improve the model performance compared with using CNNs alone. The model of deep architecture is promising in EMG decoding and optimization of network structures can increase the accuracy and robustness. © 2017 International Center for Artificial Organs and Transplantation and Wiley Periodicals, Inc.","Convolutional neural network; Deep learning; Electromyogram; Myoelectric control; Recurrent neural network","Adult; Biomechanical Phenomena; Computer Simulation; Electromyography; Female; Hand; Humans; Machine Learning; Male; Models, Biological; Movement; Neural Networks (Computer); Young Adult; Convolution; Deep neural networks; Electromyography; Motion estimation; Network architecture; Robustness (control systems); Structural optimization; Convolutional neural network; Deep architectures; Deep learning; Electromyo grams; Electromyogram signals; Kinematic information; Limb movements; Model-based OPC; Multi channel; Myoelectric control; adult; Article; biceps brachii muscle; controlled study; convolutional neural network; deltoid muscle; electromyography; female; human; human experiment; limb movement; male; mathematical computing; mathematical model; measurement accuracy; myoelectric control; nerve cell network; normal human; performance; priority journal; range of motion; recurrent neural network; support vector machine; triceps brachii muscle; artificial neural network; biological model; biomechanics; computer simulation; electromyography; hand; machine learning; movement (physiology); physiology; procedures; young adult; Recurrent neural networks","John Wiley and Sons Inc","0160564X","","ARORD","29068076","Article","Scopus","2-s2.0-85032230997"
"Dai L.; Fang R.; Li H.; Hou X.; Sheng B.; Wu Q.; Jia W.","Dai, Ling (57194144659); Fang, Ruogu (36720287600); Li, Huating (24066677600); Hou, Xuhong (25653889700); Sheng, Bin (7004699346); Wu, Qiang (57191962897); Jia, Weiping (34768292900)","57194144659; 36720287600; 24066677600; 25653889700; 7004699346; 57191962897; 34768292900","Clinical report guided retinal microaneurysm detection with multi-sieving deep learning","2018","IEEE Transactions on Medical Imaging","130","10.1109/TMI.2018.2794988","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040931169&doi=10.1109%2fTMI.2018.2794988&partnerID=40&md5=af81f485e3e3346b8c2036c296bd437f","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Department of Biomedical Engineering, University of Florida, Gainesville, 32611, FL, United States; Shanghai Jiao Tong University, Affiliated Sixth People's Hospital, Shanghai, 200233, China","Dai L., Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Fang R., Department of Biomedical Engineering, University of Florida, Gainesville, 32611, FL, United States; Li H., Shanghai Jiao Tong University, Affiliated Sixth People's Hospital, Shanghai, 200233, China; Hou X., Shanghai Jiao Tong University, Affiliated Sixth People's Hospital, Shanghai, 200233, China; Sheng B., Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China; Wu Q., Shanghai Jiao Tong University, Affiliated Sixth People's Hospital, Shanghai, 200233, China; Jia W., Shanghai Jiao Tong University, Affiliated Sixth People's Hospital, Shanghai, 200233, China","Timely detection and treatment of microaneurysms is a critical step to prevent the development of vision-threatening eye diseases such as diabetic retinopathy. However, detecting microaneurysms in fundus images is a highly challenging task due to the low image contrast, misleading cues of other red lesions, and the large variation of imaging conditions. Existing methods tend to fail in face of the large intra-class variation and small inter-class variations for microaneurysm detection in fundus images. Recently, hybrid text/image mining computer-aided diagnosis systems have emerged to offer a promise of bridging the semantic gap between images and diagnostic information. In this paper, we focus on developing an interleaved deep mining technique to cope intelligently with the unbalanced microaneurysm detection problem. Specifically, we present a clinical report guided multi-sieving convolutional neural network, which leverages a small amount of supervised information in clinical reports to identify the potential microaneurysm regions via the image-to-text mapping in the feature space. These potential microaneurysm regions are then interleaved with fundus image information for multi-sieving deep mining in a highly unbalanced classification problem. Critically, the clinical reports are employed to bridge the semantic gap between low-level image features and high-level diagnostic information. We build an efficient microaneurysm detection framework based on the hybrid text/image interleaving and validate its performance on challenging clinical data sets acquired from diabetic retinopathy patients. Extensive evaluations are carried out in terms of fundus detection and classification. Experimental results show that our framework achieves 99.7% precision and 87.8% recall, comparing favorably with the state-of-the-art algorithms. Integration of expert domain knowledge and image information demonstrates the feasibility of reducing the difficulty of training classifiers under extremely unbalanced data distributions. © 1982-2012 IEEE.","clinical reports; deep learning; Diabetic retinopathy; fundus image analysis; microaneurysm detection; multi-sieving CNN","Deep Learning; Diabetic Retinopathy; Humans; Image Interpretation, Computer-Assisted; Microaneurysm; Retinal Vessels; Classification (of information); Diagnosis; Eye protection; Neural networks; Ophthalmology; Semantics; Clinical Reports; Diabetic retinopathy; Fundus image; Microaneurysms; Multi-Sieving CNN; Article; clinical evaluation; clinical feature; diabetic retinopathy; hybrid; image enhancement; image segmentation; machine learning; microaneurysm; multi sieve convolutional neural network; nerve cell network; retina image; semantics; computer assisted diagnosis; diagnostic imaging; human; microaneurysm; retina blood vessel; Deep learning","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29727278","Article","Scopus","2-s2.0-85040931169"
"Saltz J.; Gupta R.; Hou L.; Kurc T.; Singh P.; Nguyen V.; Samaras D.; Shroyer K.R.; Zhao T.; Batiste R.; Van Arnam J.; Caesar-Johnson S.J.; Demchok J.A.; Felau I.; Kasapi M.; Ferguson M.L.; Hutter C.M.; Sofia H.J.; Tarnuzzer R.; Wang Z.; Yang L.; Zenklusen J.C.; Zhang J.J.; Chudamani S.; Liu J.; Lolla L.; Naresh R.; Pihl T.; Sun Q.; Wan Y.; Wu Y.; Cho J.; DeFreitas T.; Frazer S.; Gehlenborg N.; Getz G.; Heiman D.I.; Kim J.; Lawrence M.S.; Lin P.; Meier S.; Noble M.S.; Saksena G.; Voet D.; Zhang H.; Bernard B.; Chambwe N.; Dhankani V.; Knijnenburg T.; Kramer R.; Leinonen K.; Liu Y.; Miller M.; Reynolds S.; Shmulevich I.; Thorsson V.; Zhang W.; Akbani R.; Broom B.M.; Hegde A.M.; Ju Z.; Kanchi R.S.; Korkut A.; Li J.; Liang H.; Ling S.; Liu W.; Lu Y.; Mills G.B.; Ng K.-S.; Rao A.; Ryan M.; Wang J.; Weinstein J.N.; Zhang J.; Abeshouse A.; Armenia J.; Chakravarty D.; Chatila W.K.; de Bruijn I.; Gao J.; Gross B.E.; Heins Z.J.; Kundra R.; La K.; Ladanyi M.; Luna A.; Nissan M.G.; Ochoa A.; Phillips S.M.; Reznik E.; Sanchez-Vega F.; Sander C.; Schultz N.; Sheridan R.; Sumer S.O.; Sun Y.; Taylor B.S.; Wang J.; Zhang H.; Anur P.; Peto M.; Spellman P.; Benz C.; Stuart J.M.; Wong C.K.; Yau C.; Hayes D.N.; Parker J.S.; Wilkerson M.D.; Ally A.; Balasundaram M.; Bowlby R.; Brooks D.; Carlsen R.; Chuah E.; Dhalla N.; Holt R.; Jones S.J.M.; Kasaian K.; Lee D.; Ma Y.; Marra M.A.; Mayo M.; Moore R.A.; Mungall A.J.; Mungall K.; Robertson A.G.; Sadeghi S.; Schein J.E.; Sipahimalani P.; Tam A.; Thiessen N.; Tse K.; Wong T.; Berger A.C.; Beroukhim R.; Cherniack A.D.; Cibulskis C.; Gabriel S.B.; Gao G.F.; Ha G.; Meyerson M.; Schumacher S.E.; Shih J.; Kucherlapati M.H.; Kucherlapati R.S.; Baylin S.; Cope L.; Danilova L.; Bootwalla M.S.; Lai P.H.; Maglinte D.T.; Van Den Berg D.J.; Weisenberger D.J.; Auman J.T.; Balu S.; Bodenheimer T.; Fan C.; Hoadley K.A.; Hoyle A.P.; Jefferys S.R.; Jones C.D.; Meng S.; Mieczkowski P.A.; Mose L.E.; Perou A.H.; Perou C.M.; Roach J.; Shi Y.; Simons J.V.; Skelly T.; Soloway M.G.; Tan D.; Veluvolu U.; Fan H.; Hinoue T.; Laird P.W.; Shen H.; Zhou W.; Bellair M.; Chang K.; Covington K.; Creighton C.J.; Dinh H.; Doddapaneni H.; Donehower L.A.; Drummond J.; Gibbs R.A.; Glenn R.; Hale W.; Han Y.; Hu J.; Korchina V.; Lee S.; Lewis L.; Li W.; Liu X.; Morgan M.; Morton D.; Muzny D.; Santibanez J.; Sheth M.; Shinbrot E.; Wang L.; Wang M.; Wheeler D.A.; Xi L.; Zhao F.; Hess J.; Appelbaum E.L.; Bailey M.; Cordes M.G.; Ding L.; Fronick C.C.; Fulton L.A.; Fulton R.S.; Kandoth C.; Mardis E.R.; McLellan M.D.; Miller C.A.; Schmidt H.K.; Wilson R.K.; Crain D.; Curley E.; Gardner J.; Lau K.; Mallery D.; Morris S.; Paulauskis J.; Penny R.; Shelton C.; Shelton T.; Sherman M.; Thompson E.; Yena P.; Bowen J.; Gastier-Foster J.M.; Gerken M.; Leraas K.M.; Lichtenberg T.M.; Ramirez N.C.; Wise L.; Zmuda E.; Corcoran N.; Costello T.; Hovens C.; Carvalho A.L.; de Carvalho A.C.; Fregnani J.H.; Longatto-Filho A.; Reis R.M.; Scapulatempo-Neto C.; Silveira H.C.S.; Vidal D.O.; Burnette A.; Eschbacher J.; Hermes B.; Noss A.; Singh R.; Anderson M.L.; Castro P.D.; Ittmann M.; Huntsman D.; Kohl B.; Le X.; Thorp R.; Andry C.; Duffy E.R.; Lyadov V.; Paklina O.; Setdikova G.; Shabunin A.; Tavobilov M.; McPherson C.; Warnick R.; Berkowitz R.; Cramer D.; Feltmate C.; Horowitz N.; Kibel A.; Muto M.; Raut C.P.; Malykh A.; Barnholtz-Sloan J.S.; Barrett W.; Devine K.; Fulop J.; Ostrom Q.T.; Shimmel K.; Wolinsky Y.; Sloan A.E.; De Rose A.; Giuliante F.; Goodman M.; Karlan B.Y.; Hagedorn C.H.; Eckman J.; Harr J.; Myers J.; Tucker K.; Zach L.A.; Deyarmin B.; Hu H.; Kvecher L.; Larson C.; Mural R.J.; Somiari S.; Vicha A.; Zelinka T.; Bennett J.; Iacocca M.; Rabeno B.; Swanson P.; Latour M.; Lacombe L.; Têtu B.; Bergeron A.; McGraw M.; Staugaitis S.M.; Chabot J.; Hibshoosh H.; Sepulveda A.; Su T.; Wang T.; Potapova O.; Voronina O.; Desjardins L.; Mariani O.; Roman-Roman S.; Sastre X.; Stern M.-H.; Cheng F.; Signoretti S.; Berchuck A.; Bigner D.; Lipp E.; Marks J.; McCall S.; McLendon R.; Secord A.; Sharp A.; Behera M.; Brat D.J.; Chen A.; Delman K.; Force S.; Khuri F.; Magliocca K.; Maithel S.; Olson J.J.; Owonikoko T.; Pickens A.; Ramalingam S.; Shin D.M.; Sica G.; Van Meir E.G.; Zhang H.; Eijckenboom W.; Gillis A.; Korpershoek E.; Looijenga L.; Oosterhuis W.; Stoop H.; van Kessel K.E.; Zwarthoff E.C.; Calatozzolo C.; Cuppini L.; Cuzzubbo S.; DiMeco F.; Finocchiaro G.; Mattei L.; Perin A.; Pollo B.; Chen C.; Houck J.; Lohavanichbutr P.; Hartmann A.; Stoehr C.; Stoehr R.; Taubert H.; Wach S.; Wullich B.; Kycler W.; Murawa D.; Wiznerowicz M.; Chung K.; Edenfield W.J.; Martin J.; Baudin E.; Bubley G.; Bueno R.; De Rienzo A.; Richards W.G.; Kalkanis S.; Mikkelsen T.; Noushmehr H.; Scarpace L.; Girard N.; Aymerich M.; Campo E.; Giné E.; Guillermo A.L.; Van Bang N.; Hanh P.T.; Phu B.D.; Tang Y.; Colman H.; Evason K.; Dottino P.R.; Martignetti J.A.; Gabra H.; Juhl H.; Akeredolu T.; Stepa S.; Hoon D.; Ahn K.; Kang K.J.; Beuschlein F.; Breggia A.; Birrer M.; Bell D.; Borad M.; Bryce A.H.; Castle E.; Chandan V.; Cheville J.; Copland J.A.; Farnell M.; Flotte T.; Giama N.; Ho T.; Kendrick M.; Kocher J.-P.; Kopp K.; Moser C.; Nagorney D.; O'Brien D.; O'Neill B.P.; Patel T.; Petersen G.; Que F.; Rivera M.; Roberts L.; Smallridge R.; Smyrk T.; Stanton M.; Thompson R.H.; Torbenson M.; Yang J.D.; Zhang L.; Brimo F.; Ajani J.A.; Gonzalez A.M.A.; Behrens C.; Bondaruk J.; Broaddus R.; Czerniak B.; Esmaeli B.; Fujimoto J.; Gershenwald J.; Guo C.; Lazar A.J.; Logothetis C.; Meric-Bernstam F.; Moran C.; Ramondetta L.; Rice D.; Sood A.; Tamboli P.; Thompson T.; Troncoso P.; Tsao A.; Wistuba I.; Carter C.; Haydu L.; Hersey P.; Jakrot V.; Kakavand H.; Kefford R.; Lee K.; Long G.; Mann G.; Quinn M.; Saw R.; Scolyer R.; Shannon K.; Spillane A.; Stretch O.; Synott M.; Thompson J.; Wilmott J.; Al-Ahmadie H.; Chan T.A.; Ghossein R.; Gopalan A.; Levine D.A.; Reuter V.; Singer S.; Singh B.; Tien N.V.; Broudy T.; Mirsaidi C.; Nair P.; Drwiega P.; Miller J.; Smith J.; Zaren H.; Park J.-W.; Hung N.P.; Kebebew E.; Linehan W.M.; Metwalli A.R.; Pacak K.; Pinto P.A.; Schiffman M.; Schmidt L.S.; Vocke C.D.; Wentzensen N.; Worrell R.; Yang H.; Moncrieff M.; Goparaju C.; Melamed J.; Pass H.; Botnariuc N.; Caraman I.; Cernat M.; Chemencedji I.; Clipca A.; Doruc S.; Gorincioi G.; Mura S.; Pirtac M.; Stancul I.; Tcaciuc D.; Albert M.; Alexopoulou I.; Arnaout A.; Bartlett J.; Engel J.; Gilbert S.; Parfitt J.; Sekhon H.; Thomas G.; Rassl D.M.; Rintoul R.C.; Bifulco C.; Tamakawa R.; Urba W.; Hayward N.; Timmers H.; Antenucci A.; Facciolo F.; Grazi G.; Marino M.; Merola R.; de Krijger R.; Gimenez-Roqueplo A.-P.; Piché A.; Chevalier S.; McKercher G.; Birsoy K.; Barnett G.; Brewer C.; Farver C.; Naska T.; Pennell N.A.; Raymond D.; Schilero C.; Smolenski K.; Williams F.; Morrison C.; Borgia J.A.; Liptay M.J.; Pool M.; Seder C.W.; Junker K.; Omberg L.; Dinkin M.; Manikhas G.; Alvaro D.; Bragazzi M.C.; Cardinale V.; Carpino G.; Gaudio E.; Chesla D.; Cottingham S.; Dubina M.; Moiseenko F.; Dhanasekaran R.; Becker K.-F.; Janssen K.-P.; Slotta-Huspenina J.; Abdel-Rahman M.H.; Aziz D.; Bell S.; Cebulla C.M.; Davis A.; Duell R.; Elder J.B.; Hilty J.; Kumar B.; Lang J.; Lehman N.L.; Mandt R.; Nguyen P.; Pilarski R.; Rai K.; Schoenfield L.; Senecal K.; Wakely P.; Hansen P.; Lechan R.; Powers J.; Tischler A.; Grizzle W.E.; Sexton K.C.; Kastl A.; Henderson J.; Porten S.; Waldmann J.; Fassnacht M.; Asa S.L.; Schadendorf D.; Couce M.; Graefen M.; Huland H.; Sauter G.; Schlomm T.; Simon R.; Tennstedt P.; Olabode O.; Nelson M.; Bathe O.; Carroll P.R.; Chan J.M.; Disaia P.; Glenn P.; Kelley R.K.; Landen C.N.; Phillips J.; Prados M.; Simko J.; Smith-McCune K.; VandenBerg S.; Roggin K.; Fehrenbach A.; Kendler A.; Sifri S.; Steele R.; Jimeno A.; Carey F.; Forgie I.; Mannelli M.; Carney M.; Hernandez B.; Campos B.; Herold-Mende C.; Jungk C.; Unterberg A.; von Deimling A.; Bossler A.; Galbraith J.; Jacobus L.; Knudson M.; Knutson T.; Ma D.; Milhem M.; Sigmund R.; Godwin A.K.; Madan R.; Rosenthal H.G.; Adebamowo C.; Adebamowo S.N.; Boussioutas A.; Beer D.; Giordano T.; Mes-Masson A.-M.; Saad F.; Bocklage T.; Landrum L.; Mannel R.; Moore K.; Moxley K.; Postier R.; Walker J.; Zuna R.; Feldman M.; Valdivieso F.; Dhir R.; Luketich J.; Pinero E.M.M.; Quintero-Aguilo M.; Carlotti C.G., Jr.; Dos Santos J.S.; Kemp R.; Sankarankuty A.; Tirapelli D.; Catto J.; Agnew K.; Swisher E.; Creaney J.; Robinson B.; Shelley C.S.; Godwin E.M.; Kendall S.; Shipman C.; Bradford C.; Carey T.; Haddad A.; Moyer J.; Peterson L.; Prince M.; Rozek L.; Wolf G.; Bowman R.; Fong K.M.; Yang I.; Korst R.; Rathmell W.K.; Fantacone-Campbell J.L.; Hooke J.A.; Kovatich A.J.; Shriver C.D.; DiPersio J.; Drake B.; Govindan R.; Heath S.; Ley T.; Van Tine B.; Westervelt P.; Rubin M.A.; Lee J.I.; Aredes N.D.; Mariamidze A.; Rao A.U.K.; Sharma A.","Saltz, Joel (7004423034); Gupta, Rajarsi (55783928600); Hou, Le (57191076642); Kurc, Tahsin (6701424615); Singh, Pankaj (35549324900); Nguyen, Vu (57190275018); Samaras, Dimitris (7003833968); Shroyer, Kenneth R. (7005334071); Zhao, Tianhao (57194462526); Batiste, Rebecca (12794116100); Van Arnam, John (6507704197); Caesar-Johnson, Samantha J. (57201315251); Demchok, John A. (55314806900); Felau, Ina (57216583931); Kasapi, Melpomeni (57201311009); Ferguson, Martin L. (24766185200); Hutter, Carolyn M. (13309062600); Sofia, Heidi J. (6603766491); Tarnuzzer, Roy (6603920941); Wang, Zhining (58789161000); Yang, Liming (58666293000); Zenklusen, Jean C. (57208766561); Zhang, Jiashan (Julia) (57221656291); Chudamani, Sudha (57191100885); Liu, Jia (57775848100); Lolla, Laxmi (56897272300); Naresh, Rashi (56896982900); Pihl, Todd (57191098401); Sun, Qiang (56512908300); Wan, Yunhu (55750810600); Wu, Ye (56697706100); Cho, Juok (37033580800); DeFreitas, Timothy (57140701800); Frazer, Scott (57208806584); Gehlenborg, Nils (57208464039); Getz, Gad (8634683800); Heiman, David I. (36128705200); Kim, Jaegil (58823922000); Lawrence, Michael S. (55861159400); Lin, Pei (57191539857); Meier, Sam (57193744122); Noble, Michael S. (36882694700); Saksena, Gordon (57222282079); Voet, Doug (43861964100); Zhang, Hailei (57195311548); Bernard, Brady (55314581300); Chambwe, Nyasha (36815706400); Dhankani, Varsha (56429497800); Knijnenburg, Theo (12775043700); Kramer, Roger (16022412700); Leinonen, Kalle (56698108600); Liu, Yuexin (55938836900); Miller, Michael (57213747561); Reynolds, Sheila (57206147525); Shmulevich, Ilya (7004922117); Thorsson, Vésteinn (6602742809); Zhang, Wei (55163436500); Akbani, Rehan (57195433027); Broom, Bradley M. (6701321805); Hegde, Apurva M. (57191442533); Ju, Zhenlin (8259178200); Kanchi, Rupa S. (57195973893); Korkut, Anil (57195425943); Li, Jun (56099496000); Liang, Han (23489595000); Ling, Shiyun (35731840800); Liu, Wenbin (55723551900); Lu, Yiling (8760329300); Mills, Gordon B. (35379638300); Ng, Kwok-Shing (57201323733); Rao, Arvind (36148265300); Ryan, Michael (57218185059); Wang, Jing (56019552200); Weinstein, John N. (7201817430); Zhang, Jiexin (57225985526); Abeshouse, Adam (56943491500); Armenia, Joshua (55964730500); Chakravarty, Debyani (54787362300); Chatila, Walid K. (57200878932); de Bruijn, Ino (56387303400); Gao, Jianjiong (55370612000); Gross, Benjamin E. (57190211000); Heins, Zachary J. (57190137855); Kundra, Ritika (57191913305); La, Konnor (56965068700); Ladanyi, Marc (7006141808); Luna, Augustin (57217576878); Nissan, Moriah G. (57201323722); Ochoa, Angelica (57194463342); Phillips, Sarah M. (57201308742); Reznik, Ed (36239156300); Sanchez-Vega, Francisco (55542379900); Sander, Chris (55146122100); Schultz, Nikolaus (24766753800); Sheridan, Robert (55722738100); Sumer, S. Onur (57196395059); Sun, Yichao (56521910400); Taylor, Barry S. (55553331500); Wang, Jioajiao (57223116461); Zhang, Hongxin (55685526000); Anur, Pavana (57202296209); Peto, Myron (57964832200); Spellman, Paul (7003583259); Benz, Christopher (57210225898); Stuart, Joshua M. (56720469500); Wong, Christopher K. (57202659852); Yau, Christina (7007038412); Hayes, D. Neil (9737310200); Parker, Joel S. (57201827326); Wilkerson, Matthew D. (56972335100); Ally, Adrian (14526672200); Balasundaram, Miruna (8976677500); Bowlby, Reanne (56087624200); Brooks, Denise (57216576844); Carlsen, Rebecca (55682318500); Chuah, Eric (58945991500); Dhalla, Noreen (10340222700); Holt, Robert (7402085535); Jones, Steven J.M. (55732380600); Kasaian, Katayoon (57214907245); Lee, Darlene (8295518800); Ma, Yussanne (57198592425); Marra, Marco A. (55553154800); Mayo, Michael (56155388900); Moore, Richard A. (56696653600); Mungall, Andrew J. (7004571024); Mungall, Karen (6603464538); Robertson, A. Gordon (56597396300); Sadeghi, Sara (56397742700); Schein, Jacqueline E. (35351155100); Sipahimalani, Payal (16647178800); Tam, Angela (57208170428); Thiessen, Nina (18234177300); Tse, Kane (35171635300); Wong, Tina (56087571200); Berger, Ashton C. (57199995373); Beroukhim, Rameen (6507380004); Cherniack, Andrew D. (57191545739); Cibulskis, Carrie (57189243613); Gabriel, Stacey B. (7202104113); Gao, Galen F. (57200880842); Ha, Gavin (36015155300); Meyerson, Matthew (35371816700); Schumacher, Steven E. (57211974896); Shih, Juliann (56896759600); Kucherlapati, Melanie H. (6506056321); Kucherlapati, Raju S. (7006287763); Baylin, Stephen (7101927923); Cope, Leslie (56412182000); Danilova, Ludmila (57202686141); Bootwalla, Moiz S. (57216304945); Lai, Phillip H. (57202963771); Maglinte, Dennis T. (36542873900); Van Den Berg, David J. (56363265200); Weisenberger, Daniel J. (57196961630); Auman, J. Todd (57202636637); Balu, Saianand (57216589889); Bodenheimer, Tom (57506819500); Fan, Cheng (57199887374); Hoadley, Katherine A. (57194640516); Hoyle, Alan P. (57202694615); Jefferys, Stuart R. (57209687978); Jones, Corbin D. (36618778900); Meng, Shaowu (57207900530); Mieczkowski, Piotr A. (55644001268); Mose, Lisle E. (57203518927); Perou, Amy H. (57193305609); Perou, Charles M. (7003834979); Roach, Jeffrey (57216110608); Shi, Yan (57998015900); Simons, Janae V. (55315962600); Skelly, Tara (8611001000); Soloway, Matthew G. (55314979300); Tan, Donghui (55314931000); Veluvolu, Umadevi (24172169900); Fan, Huihui (52263520500); Hinoue, Toshinori (57495824900); Laird, Peter W. (7007131889); Shen, Hui (57216321428); Zhou, Wanding (56119657900); Bellair, Michelle (41160952000); Chang, Kyle (8293974000); Covington, Kyle (36672634500); Creighton, Chad J. (7003881193); Dinh, Huyen (8305228300); Doddapaneni, HarshaVardhan (57203148810); Donehower, Lawrence A. (7006063179); Drummond, Jennifer (43861125000); Gibbs, Richard A. (7202068919); Glenn, Robert (57194557954); Hale, Walker (55445984800); Han, Yi (7404095823); Hu, Jianhong (58533706700); Korchina, Viktoriya (56431045800); Lee, Sandra (35314862200); Lewis, Lora (35353938300); Li, Wei (57317069500); Liu, Xiuping (52163848900); Morgan, Margaret (8305236500); Morton, Donna (57212518149); Muzny, Donna (6603763638); Santibanez, Jireh (12785255100); Sheth, Margi (55314429000); Shinbrot, Eve (57207802130); Wang, Linghua (35771877000); Wang, Min (57210001965); Wheeler, David A. (58417390400); Xi, Liu (57207803680); Zhao, Fengmei (57201312635); Hess, Julian (56924492700); Appelbaum, Elizabeth L. (36129978900); Bailey, Matthew (55548772724); Cordes, Matthew G. (56868360900); Ding, Li (36570198600); Fronick, Catrina C. (8221705800); Fulton, Lucinda A. (58314631000); Fulton, Robert S. (35351030100); Kandoth, Cyriac (57195301061); Mardis, Elaine R. (7003499321); McLellan, Michael D. (8727005300); Miller, Christopher A. (58315874400); Schmidt, Heather K. (57652245100); Wilson, Richard K. (56713341900); Crain, Daniel (56522800300); Curley, Erin (57218403050); Gardner, Johanna (57218833177); Lau, Kevin (56297090900); Mallery, David (6507282745); Morris, Scott (57214116915); Paulauskis, Joseph (7004220743); Penny, Robert (57220734334); Shelton, Candace (55315771000); Shelton, Troy (57199421398); Sherman, Mark (57201250489); Thompson, Eric (58755959100); Yena, Peggy (54783850400); Bowen, Jay (57077792300); Gastier-Foster, Julie M. (8625688700); Gerken, Mark (57220733644); Leraas, Kristen M. (24830707200); Lichtenberg, Tara M. (57193306115); Ramirez, Nilsa C. (56942264200); Wise, Lisa (16246846300); Zmuda, Erik (6506276755); Corcoran, Niall (6603550796); Costello, Tony (57189951791); Hovens, Christopher (56723789200); Carvalho, Andre L. (7201882443); de Carvalho, Ana C. (14318875400); Fregnani, José H. (14013521000); Longatto-Filho, Adhemar (56789731500); Reis, Rui M. (8203632800); Scapulatempo-Neto, Cristovam (16246143600); Silveira, Henrique C.S. (55545860710); Vidal, Daniel O. (57201313387); Burnette, Andrew (57220734475); Eschbacher, Jennifer (14065813800); Hermes, Beth (56698050100); Noss, Ardene (57192326592); Singh, Rosy (57192089292); Anderson, Matthew L. (56399834500); Castro, Patricia D. (55812295700); Ittmann, Michael (7004507505); Huntsman, David (7003437964); Kohl, Bernard (55370982700); Le, Xuan (58045979700); Thorp, Richard (55314795700); Andry, Chris (6602648682); Duffy, Elizabeth R. (57201323625); Lyadov, Vladimir (57218552793); Paklina, Oxana (6603393035); Setdikova, Galiya (25422894200); Shabunin, Alexey (57201321065); Tavobilov, Mikhail (57201310779); McPherson, Christopher (57217653610); Warnick, Ronald (57190210624); Berkowitz, Ross (7201352221); Cramer, Daniel (7202751360); Feltmate, Colleen (6602438484); Horowitz, Neil (7003690621); Kibel, Adam (7003579650); Muto, Michael (56517673900); Raut, Chandrajit P. (6603353594); Malykh, Andrei (6701340446); Barnholtz-Sloan, Jill S. (7005410780); Barrett, Wendi (57191773208); Devine, Karen (54790681100); Fulop, Jordonna (56698042900); Ostrom, Quinn T. (36970981700); Shimmel, Kristen (56698314100); Wolinsky, Yingli (54791691000); Sloan, Andrew E. (7005636524); De Rose, Agostino (57506826400); Giuliante, Felice (6701524019); Goodman, Marc (7401997536); Karlan, Beth Y. (7006780020); Hagedorn, Curt H. (7006684877); Eckman, John (55370565500); Harr, Jodi (55831411000); Myers, Jerome (57216794234); Tucker, Kelinda (55831560200); Zach, Leigh Anne (57202302997); Deyarmin, Brenda (6506798338); Hu, Hai (58455318100); Kvecher, Leonid (24721309100); Larson, Caroline (57201309336); Mural, Richard J. (7003349003); Somiari, Stella (6602844448); Vicha, Ales (6506952685); Zelinka, Tomas (57218473481); Bennett, Joseph (7404251719); Iacocca, Mary (6603110348); Rabeno, Brenda (54783342900); Swanson, Patricia (13410382800); Latour, Mathieu (25224411400); Lacombe, Louis (57205554093); Têtu, Bernard (7005270944); Bergeron, Alain (36862182000); McGraw, Mary (55758067700); Staugaitis, Susan M. (57192085562); Chabot, John (7102977371); Hibshoosh, Hanina (7004691389); Sepulveda, Antonia (35500186600); Su, Tao (24529299500); Wang, Timothy (35199244700); Potapova, Olga (57207899300); Voronina, Olga (55701534600); Desjardins, Laurence (7006696518); Mariani, Odette (6602349409); Roman-Roman, Sergio (7003815237); Sastre, Xavier (7005955220); Stern, Marc-Henri (55168356000); Cheng, Feixiong (36514277000); Signoretti, Sabina (56231549200); Berchuck, Andrew (57203048593); Bigner, Darell (35397775800); Lipp, Eric (25626345100); Marks, Jeffrey (7402796968); McCall, Shannon (8358859300); McLendon, Roger (57203214138); Secord, Angeles (6604094111); Sharp, Alexis (56943053800); Behera, Madhusmita (16174630600); Brat, Daniel J. (7005451603); Chen, Amy (57825938000); Delman, Keith (6602139878); Force, Seth (57218790356); Khuri, Fadlo (7007043446); Magliocca, Kelly (8723051900); Maithel, Shishir (8517808600); Olson, Jeffrey J. (57210526896); Owonikoko, Taofeek (57210201359); Pickens, Alan (7003635745); Ramalingam, Suresh (56931920000); Shin, Dong M. (57203976200); Sica, Gabriel (57220113992); Van Meir, Erwin G. (7007043406); Zhang, Hongzheng (15051309700); Eijckenboom, Wil (57201326942); Gillis, Ad (57205408485); Korpershoek, Esther (55967252200); Looijenga, Leendert (7004873470); Oosterhuis, Wolter (57205479230); Stoop, Hans (6602566360); van Kessel, Kim E. (55653268300); Zwarthoff, Ellen C. (57223243430); Calatozzolo, Chiara (57192314700); Cuppini, Lucia (57192343513); Cuzzubbo, Stefania (56442629700); DiMeco, Francesco (6701803013); Finocchiaro, Gaetano (7006048169); Mattei, Luca (57201312600); Perin, Alessandro (14060833100); Pollo, Bianca (7004181729); Chen, Chu (57026486000); Houck, John (57201316412); Lohavanichbutr, Pawadee (25422458300); Hartmann, Arndt (7402943612); Stoehr, Christine (7004456793); Stoehr, Robert (7003301964); Taubert, Helge (7101911081); Wach, Sven (36132554500); Wullich, Bernd (7006062347); Kycler, Witold (14008720700); Murawa, Dawid (55946668500); Wiznerowicz, Maciej (6602377756); Chung, Ki (57201315235); Edenfield, W. Jeffrey (57201723458); Martin, Julie (57201326536); Baudin, Eric (7005202733); Bubley, Glenn (7003367199); Bueno, Raphael (7006034260); De Rienzo, Assunta (6603276520); Richards, William G. (57216110599); Kalkanis, Steven (8882614000); Mikkelsen, Tom (7005744554); Noushmehr, Houtan (57208521004); Scarpace, Lisa (6506639381); Girard, Nicolas (56443626100); Aymerich, Marta (35502361700); Campo, Elias (7103168343); Giné, Eva (6701325681); Guillermo, Armando López (57201312132); Van Bang, Nguyen (54880606300); Hanh, Phan Thi (56087550900); Phu, Bui Duc (55370186100); Tang, Yufang (57201317201); Colman, Howard (35279503000); Evason, Kimberley (55388366800); Dottino, Peter R. (7004384282); Martignetti, John A. (35417611400); Gabra, Hani (6603699691); Juhl, Hartmut (57224746625); Akeredolu, Teniola (57188767368); Stepa, Serghei (56943415700); Hoon, Dave (7006671900); Ahn, Keunsoo (57201320116); Kang, Koo Jeong (7402223477); Beuschlein, Felix (6701652261); Breggia, Anne (6507686954); Birrer, Michael (7006077011); Bell, Debra (57189526655); Borad, Mitesh (57202377479); Bryce, Alan H. (14031164700); Castle, Erik (55554628900); Chandan, Vishal (54790510200); Cheville, John (7005904607); Copland, John A. (7004180828); Farnell, Michael (7006074528); Flotte, Thomas (7103314284); Giama, Nasra (57951674600); Ho, Thai (57202373312); Kendrick, Michael (36746297200); Kocher, Jean-Pierre (57202964001); Kopp, Karla (57218832984); Moser, Catherine (13805846000); Nagorney, David (35400419300); O'Brien, Daniel (57201326440); O'Neill, Brian Patrick (57964935400); Patel, Tushar (57216944649); Petersen, Gloria (7202062781); Que, Florencia (7203008419); Rivera, Michael (8272710500); Roberts, Lewis (57816837300); Smallridge, Robert (7006058296); Smyrk, Thomas (7006123619); Stanton, Melissa (37102594700); Thompson, R. Houston (35075178800); Torbenson, Michael (7004312220); Yang, Ju Dong (36457882200); Zhang, Lizhi (35312950800); Brimo, Fadi (19640087800); Ajani, Jaffer A. (57194055589); Gonzalez, Ana Maria Angulo (57201396349); Behrens, Carmen (36604540300); Bondaruk, Jolanta (6508289558); Broaddus, Russell (6701639477); Czerniak, Bogdan (57202963489); Esmaeli, Bita (7004910000); Fujimoto, Junya (57202921919); Gershenwald, Jeffrey (55630340500); Guo, Charles (14060353200); Lazar, Alexander J. (8771754600); Logothetis, Christopher (35406084500); Meric-Bernstam, Funda (7401560620); Moran, Cesar (7202557877); Ramondetta, Lois (6701310804); Rice, David (6506974896); Sood, Anil (7201450975); Tamboli, Pheroze (6701447154); Thompson, Timothy (7401553767); Troncoso, Patricia (7007092737); Tsao, Anne (7004488726); Wistuba, Ignacio (35375776900); Carter, Candace (57214434833); Haydu, Lauren (25122578700); Hersey, Peter (7005668565); Jakrot, Valerie (55253701600); Kakavand, Hojabr (55360426400); Kefford, Richard (7103091133); Lee, Kenneth (7501500606); Long, Georgina (57202703641); Mann, Graham (7201974520); Quinn, Michael (15833001200); Saw, Robyn (6602475899); Scolyer, Richard (7007084989); Shannon, Kerwin (7102515974); Spillane, Andrew (7003316341); Stretch, onathan (57201391095); Synott, Maria (56708886600); Thompson, John (55574181918); Wilmott, James (31067595400); Al-Ahmadie, Hikmat (6506517069); Chan, Timothy A. (7402687744); Ghossein, Ronald (7003507833); Gopalan, Anuradha (57203237513); Levine, Douglas A. (7403166090); Reuter, Victor (7102568582); Singer, Samuel (7201795148); Singh, Bhuvanesh (7405639360); Tien, Nguyen Viet (57201317769); Broudy, Thomas (57201322844); Mirsaidi, Cyrus (57190440424); Nair, Praveen (57201306540); Drwiega, Paul (57195487490); Miller, Judy (57201310492); Smith, Jennifer (57218091490); Zaren, Howard (7004548419); Park, Joong-Won (8422530400); Hung, Nguyen Phi (57201318578); Kebebew, Electron (7003372219); Linehan, W. Marston (7102686573); Metwalli, Adam R. (6603028226); Pacak, Karel (56911173300); Pinto, Peter A. (7103408914); Schiffman, Mark (19738312900); Schmidt, Laura S. (7401563940); Vocke, Cathy D. (6701789391); Wentzensen, Nicolas (6602386738); Worrell, Robert (57201317981); Yang, Hannah (57043681000); Moncrieff, Marc (16245598400); Goparaju, Chandra (57203677877); Melamed, Jonathan (7005398626); Pass, Harvey (7102719161); Botnariuc, Natalia (57203677879); Caraman, Irina (57203677878); Cernat, Mircea (57201326140); Chemencedji, Inga (57201324788); Clipca, Adrian (57201319089); Doruc, Serghei (57201323711); Gorincioi, Ghenadie (57201307848); Mura, Sergiu (57201311694); Pirtac, Maria (57201320758); Stancul, Irina (57201318510); Tcaciuc, Diana (57201325523); Albert, Monique (55966939500); Alexopoulou, Iakovina (57201436270); Arnaout, Angel (6603463136); Bartlett, John (36063907600); Engel, Jay (57202650327); Gilbert, Sebastien (56799906500); Parfitt, Jeremy (57205637107); Sekhon, Harman (57216385996); Thomas, George (37019693900); Rassl, Doris M. (58302491900); Rintoul, Robert C. (6602134551); Bifulco, Carlo (6603274856); Tamakawa, Raina (57201321934); Urba, Walter (7006671287); Hayward, Nicholas (36804082100); Timmers, Henri (7006526013); Antenucci, Anna (6602881778); Facciolo, Francesco (6701581187); Grazi, Gianluca (13102992200); Marino, Mirella (7201366036); Merola, Roberta (8643789600); de Krijger, Ronald (7003987064); Gimenez-Roqueplo, Anne-Paule (6701657164); Piché, Alain (7004356236); Chevalier, Simone (57219699556); McKercher, Ginette (57205034182); Birsoy, Kivanc (8317554400); Barnett, Gene (7103006808); Brewer, Cathy (57201321847); Farver, Carol (57194928234); Naska, Theresa (8390427500); Pennell, Nathan A. (57202645461); Raymond, Daniel (7103274579); Schilero, Cathy (55985631300); Smolenski, Kathy (57192078497); Williams, Felicia (56697836500); Morrison, Carl (7201898006); Borgia, Jeffrey A. (6602993443); Liptay, Michael J. (6701356444); Pool, Mark (7006681410); Seder, Christopher W. (26024502100); Junker, Kerstin (7005988974); Omberg, Larsson (23028807900); Dinkin, Mikhail (57201317035); Manikhas, George (6602361853); Alvaro, Domenico (7006353760); Bragazzi, Maria Consiglia (57204922018); Cardinale, Vincenzo (57523299200); Carpino, Guido (6508122425); Gaudio, Eugenio (7006542760); Chesla, David (56897196400); Cottingham, Sandra (6602464570); Dubina, Michael (6602132091); Moiseenko, Fedor (24339971800); Dhanasekaran, Renumathy (35782908700); Becker, Karl-Friedrich (36749269400); Janssen, Klaus-Peter (35496038900); Slotta-Huspenina, Julia (14421823700); Abdel-Rahman, Mohamed H. (57198053337); Aziz, Dina (57192091571); Bell, Sue (7401588022); Cebulla, Colleen M. (57218184898); Davis, Amy (57195236385); Duell, Rebecca (57205637353); Elder, J. Bradley (23476318200); Hilty, Joe (57201211916); Kumar, Bahavna (57189339717); Lang, James (35310913700); Lehman, Norman L. (57220734181); Mandt, Randy (56698374700); Nguyen, Phuong (7201630225); Pilarski, Robert (7003596006); Rai, Karan (55927857700); Schoenfield, Lynn (16480778500); Senecal, Kelly (57218832669); Wakely, Paul (7005074776); Hansen, Paul (58211494600); Lechan, Ronald (7005636129); Powers, James (57218831758); Tischler, Arthur (7005414826); Grizzle, William E. (7006493765); Sexton, Katherine C. (57206318879); Kastl, Alison (55986098400); Henderson, Joel (58386232300); Porten, Sima (35196877000); Waldmann, Jens (57220733742); Fassnacht, Martin (6603031564); Asa, Sylvia L. (57203054854); Schadendorf, Dirk (56042878100); Couce, Marta (7003683108); Graefen, Markus (26642918300); Huland, Hartwig (36040724900); Sauter, Guido (55828366200); Schlomm, Thorsten (6507031471); Simon, Ronald (55129740500); Tennstedt, Pierre (21934718700); Olabode, Oluwole (57195488584); Nelson, Mark (7403461044); Bathe, Oliver (7003608483); Carroll, Peter R. (35393492100); Chan, June M. (57213089196); Disaia, Philip (7102187115); Glenn, Pat (57201314418); Kelley, Robin K. (17635112900); Landen, Charles N. (6603272062); Phillips, Joanna (57200906051); Prados, Michael (7102738132); Simko, Jeffry (8959650300); Smith-McCune, Karen (57221739064); VandenBerg, Scott (7005314874); Roggin, Kevin (8330761000); Fehrenbach, Ashley (57192312937); Kendler, Ady (57205637929); Sifri, Suzanne (56698390600); Steele, Ruth (55986071800); Jimeno, Antonio (57203074817); Carey, Francis (7006356788); Forgie, Ian (58220584100); Mannelli, Massimo (7005177865); Carney, Michael (54790538800); Hernandez, Brenda (7007173293); Campos, Benito (56396345100); Herold-Mende, Christel (6604063528); Jungk, Christin (57212520265); Unterberg, Andreas (7004554335); von Deimling, Andreas (7005605204); Bossler, Aaron (14619134700); Galbraith, Joseph (57201320898); Jacobus, Laura (57201309852); Knudson, Michael (57201325210); Knutson, Tina (57201306531); Ma, Deqin (55882521700); Milhem, Mohammed (6508228025); Sigmund, Rita (57201310118); Godwin, Andrew K. (7004511914); Madan, Rashna (57225820831); Rosenthal, Howard G. (57201318058); Adebamowo, Clement (7003441563); Adebamowo, Sally N. (56669713900); Boussioutas, Alex (8745611400); Beer, David (57203054234); Giordano, Thomas (35372744300); Mes-Masson, Anne-Marie (7003842511); Saad, Fred (34868640300); Bocklage, Therese (35586240800); Landrum, Lisa (6701430831); Mannel, Robert (7003326942); Moore, Kathleen (8560429300); Moxley, Katherine (23009115400); Postier, Russel (7004526785); Walker, Joan (7405586662); Zuna, Rosemary (6701422748); Feldman, Michael (56647460100); Valdivieso, Federico (57201308380); Dhir, Rajiv (56758565000); Luketich, James (7005255441); Pinero, Edna M. Mora (57201398353); Quintero-Aguilo, Mario (55255193700); Carlotti, Carlos Gilberto (57194555276); Dos Santos, Jose Sebastião (8212946100); Kemp, Rafael (14832776100); Sankarankuty, Ajith (57201312404); Tirapelli, Daniela (57207900755); Catto, James (6603789337); Agnew, Kathy (6603930435); Swisher, Elizabeth (57202569232); Creaney, Jenette (6603302385); Robinson, Bruce (7402517854); Shelley, Carl Simon (7004142271); Godwin, Eryn M. (57196346713); Kendall, Sara (57201309974); Shipman, Cassaundra (57201326982); Bradford, Carol (35432002600); Carey, Thomas (7102905089); Haddad, Andrea (57201320126); Moyer, Jeffey (57201309421); Peterson, Lisa (57206295696); Prince, Mark (57201902573); Rozek, Laura (57200610365); Wolf, Gregory (58713694400); Bowman, Rayleen (8576061200); Fong, Kwun M. (7102709025); Yang, Ian (7101797862); Korst, Robert (7003371276); Rathmell, W. Kimryn (56883156900); Fantacone-Campbell, J. Leigh (57709002800); Hooke, Jeffrey A. (7003851288); Kovatich, Albert J. (7004502384); Shriver, Craig D. (7004122081); DiPersio, John (7006336588); Drake, Bettina (57221184039); Govindan, Ramaswamy (24176800100); Heath, Sharon (57221183795); Ley, Timothy (57541849100); Van Tine, Brian (6602348306); Westervelt, Peter (57213811106); Rubin, Mark A. (7402540442); Lee, Jung Il (57218516593); Aredes, Natália D. (57201310324); Mariamidze, Armaz (56190771600); Rao, Arvind U.K. (57201316395); Sharma, Ashish (57201794355)","7004423034; 55783928600; 57191076642; 6701424615; 35549324900; 57190275018; 7003833968; 7005334071; 57194462526; 12794116100; 6507704197; 57201315251; 55314806900; 57216583931; 57201311009; 24766185200; 13309062600; 6603766491; 6603920941; 58789161000; 58666293000; 57208766561; 57221656291; 57191100885; 57775848100; 56897272300; 56896982900; 57191098401; 56512908300; 55750810600; 56697706100; 37033580800; 57140701800; 57208806584; 57208464039; 8634683800; 36128705200; 58823922000; 55861159400; 57191539857; 57193744122; 36882694700; 57222282079; 43861964100; 57195311548; 55314581300; 36815706400; 56429497800; 12775043700; 16022412700; 56698108600; 55938836900; 57213747561; 57206147525; 7004922117; 6602742809; 55163436500; 57195433027; 6701321805; 57191442533; 8259178200; 57195973893; 57195425943; 56099496000; 23489595000; 35731840800; 55723551900; 8760329300; 35379638300; 57201323733; 36148265300; 57218185059; 56019552200; 7201817430; 57225985526; 56943491500; 55964730500; 54787362300; 57200878932; 56387303400; 55370612000; 57190211000; 57190137855; 57191913305; 56965068700; 7006141808; 57217576878; 57201323722; 57194463342; 57201308742; 36239156300; 55542379900; 55146122100; 24766753800; 55722738100; 57196395059; 56521910400; 55553331500; 57223116461; 55685526000; 57202296209; 57964832200; 7003583259; 57210225898; 56720469500; 57202659852; 7007038412; 9737310200; 57201827326; 56972335100; 14526672200; 8976677500; 56087624200; 57216576844; 55682318500; 58945991500; 10340222700; 7402085535; 55732380600; 57214907245; 8295518800; 57198592425; 55553154800; 56155388900; 56696653600; 7004571024; 6603464538; 56597396300; 56397742700; 35351155100; 16647178800; 57208170428; 18234177300; 35171635300; 56087571200; 57199995373; 6507380004; 57191545739; 57189243613; 7202104113; 57200880842; 36015155300; 35371816700; 57211974896; 56896759600; 6506056321; 7006287763; 7101927923; 56412182000; 57202686141; 57216304945; 57202963771; 36542873900; 56363265200; 57196961630; 57202636637; 57216589889; 57506819500; 57199887374; 57194640516; 57202694615; 57209687978; 36618778900; 57207900530; 55644001268; 57203518927; 57193305609; 7003834979; 57216110608; 57998015900; 55315962600; 8611001000; 55314979300; 55314931000; 24172169900; 52263520500; 57495824900; 7007131889; 57216321428; 56119657900; 41160952000; 8293974000; 36672634500; 7003881193; 8305228300; 57203148810; 7006063179; 43861125000; 7202068919; 57194557954; 55445984800; 7404095823; 58533706700; 56431045800; 35314862200; 35353938300; 57317069500; 52163848900; 8305236500; 57212518149; 6603763638; 12785255100; 55314429000; 57207802130; 35771877000; 57210001965; 58417390400; 57207803680; 57201312635; 56924492700; 36129978900; 55548772724; 56868360900; 36570198600; 8221705800; 58314631000; 35351030100; 57195301061; 7003499321; 8727005300; 58315874400; 57652245100; 56713341900; 56522800300; 57218403050; 57218833177; 56297090900; 6507282745; 57214116915; 7004220743; 57220734334; 55315771000; 57199421398; 57201250489; 58755959100; 54783850400; 57077792300; 8625688700; 57220733644; 24830707200; 57193306115; 56942264200; 16246846300; 6506276755; 6603550796; 57189951791; 56723789200; 7201882443; 14318875400; 14013521000; 56789731500; 8203632800; 16246143600; 55545860710; 57201313387; 57220734475; 14065813800; 56698050100; 57192326592; 57192089292; 56399834500; 55812295700; 7004507505; 7003437964; 55370982700; 58045979700; 55314795700; 6602648682; 57201323625; 57218552793; 6603393035; 25422894200; 57201321065; 57201310779; 57217653610; 57190210624; 7201352221; 7202751360; 6602438484; 7003690621; 7003579650; 56517673900; 6603353594; 6701340446; 7005410780; 57191773208; 54790681100; 56698042900; 36970981700; 56698314100; 54791691000; 7005636524; 57506826400; 6701524019; 7401997536; 7006780020; 7006684877; 55370565500; 55831411000; 57216794234; 55831560200; 57202302997; 6506798338; 58455318100; 24721309100; 57201309336; 7003349003; 6602844448; 6506952685; 57218473481; 7404251719; 6603110348; 54783342900; 13410382800; 25224411400; 57205554093; 7005270944; 36862182000; 55758067700; 57192085562; 7102977371; 7004691389; 35500186600; 24529299500; 35199244700; 57207899300; 55701534600; 7006696518; 6602349409; 7003815237; 7005955220; 55168356000; 36514277000; 56231549200; 57203048593; 35397775800; 25626345100; 7402796968; 8358859300; 57203214138; 6604094111; 56943053800; 16174630600; 7005451603; 57825938000; 6602139878; 57218790356; 7007043446; 8723051900; 8517808600; 57210526896; 57210201359; 7003635745; 56931920000; 57203976200; 57220113992; 7007043406; 15051309700; 57201326942; 57205408485; 55967252200; 7004873470; 57205479230; 6602566360; 55653268300; 57223243430; 57192314700; 57192343513; 56442629700; 6701803013; 7006048169; 57201312600; 14060833100; 7004181729; 57026486000; 57201316412; 25422458300; 7402943612; 7004456793; 7003301964; 7101911081; 36132554500; 7006062347; 14008720700; 55946668500; 6602377756; 57201315235; 57201723458; 57201326536; 7005202733; 7003367199; 7006034260; 6603276520; 57216110599; 8882614000; 7005744554; 57208521004; 6506639381; 56443626100; 35502361700; 7103168343; 6701325681; 57201312132; 54880606300; 56087550900; 55370186100; 57201317201; 35279503000; 55388366800; 7004384282; 35417611400; 6603699691; 57224746625; 57188767368; 56943415700; 7006671900; 57201320116; 7402223477; 6701652261; 6507686954; 7006077011; 57189526655; 57202377479; 14031164700; 55554628900; 54790510200; 7005904607; 7004180828; 7006074528; 7103314284; 57951674600; 57202373312; 36746297200; 57202964001; 57218832984; 13805846000; 35400419300; 57201326440; 57964935400; 57216944649; 7202062781; 7203008419; 8272710500; 57816837300; 7006058296; 7006123619; 37102594700; 35075178800; 7004312220; 36457882200; 35312950800; 19640087800; 57194055589; 57201396349; 36604540300; 6508289558; 6701639477; 57202963489; 7004910000; 57202921919; 55630340500; 14060353200; 8771754600; 35406084500; 7401560620; 7202557877; 6701310804; 6506974896; 7201450975; 6701447154; 7401553767; 7007092737; 7004488726; 35375776900; 57214434833; 25122578700; 7005668565; 55253701600; 55360426400; 7103091133; 7501500606; 57202703641; 7201974520; 15833001200; 6602475899; 7007084989; 7102515974; 7003316341; 57201391095; 56708886600; 55574181918; 31067595400; 6506517069; 7402687744; 7003507833; 57203237513; 7403166090; 7102568582; 7201795148; 7405639360; 57201317769; 57201322844; 57190440424; 57201306540; 57195487490; 57201310492; 57218091490; 7004548419; 8422530400; 57201318578; 7003372219; 7102686573; 6603028226; 56911173300; 7103408914; 19738312900; 7401563940; 6701789391; 6602386738; 57201317981; 57043681000; 16245598400; 57203677877; 7005398626; 7102719161; 57203677879; 57203677878; 57201326140; 57201324788; 57201319089; 57201323711; 57201307848; 57201311694; 57201320758; 57201318510; 57201325523; 55966939500; 57201436270; 6603463136; 36063907600; 57202650327; 56799906500; 57205637107; 57216385996; 37019693900; 58302491900; 6602134551; 6603274856; 57201321934; 7006671287; 36804082100; 7006526013; 6602881778; 6701581187; 13102992200; 7201366036; 8643789600; 7003987064; 6701657164; 7004356236; 57219699556; 57205034182; 8317554400; 7103006808; 57201321847; 57194928234; 8390427500; 57202645461; 7103274579; 55985631300; 57192078497; 56697836500; 7201898006; 6602993443; 6701356444; 7006681410; 26024502100; 7005988974; 23028807900; 57201317035; 6602361853; 7006353760; 57204922018; 57523299200; 6508122425; 7006542760; 56897196400; 6602464570; 6602132091; 24339971800; 35782908700; 36749269400; 35496038900; 14421823700; 57198053337; 57192091571; 7401588022; 57218184898; 57195236385; 57205637353; 23476318200; 57201211916; 57189339717; 35310913700; 57220734181; 56698374700; 7201630225; 7003596006; 55927857700; 16480778500; 57218832669; 7005074776; 58211494600; 7005636129; 57218831758; 7005414826; 7006493765; 57206318879; 55986098400; 58386232300; 35196877000; 57220733742; 6603031564; 57203054854; 56042878100; 7003683108; 26642918300; 36040724900; 55828366200; 6507031471; 55129740500; 21934718700; 57195488584; 7403461044; 7003608483; 35393492100; 57213089196; 7102187115; 57201314418; 17635112900; 6603272062; 57200906051; 7102738132; 8959650300; 57221739064; 7005314874; 8330761000; 57192312937; 57205637929; 56698390600; 55986071800; 57203074817; 7006356788; 58220584100; 7005177865; 54790538800; 7007173293; 56396345100; 6604063528; 57212520265; 7004554335; 7005605204; 14619134700; 57201320898; 57201309852; 57201325210; 57201306531; 55882521700; 6508228025; 57201310118; 7004511914; 57225820831; 57201318058; 7003441563; 56669713900; 8745611400; 57203054234; 35372744300; 7003842511; 34868640300; 35586240800; 6701430831; 7003326942; 8560429300; 23009115400; 7004526785; 7405586662; 6701422748; 56647460100; 57201308380; 56758565000; 7005255441; 57201398353; 55255193700; 57194555276; 8212946100; 14832776100; 57201312404; 57207900755; 6603789337; 6603930435; 57202569232; 6603302385; 7402517854; 7004142271; 57196346713; 57201309974; 57201326982; 35432002600; 7102905089; 57201320126; 57201309421; 57206295696; 57201902573; 57200610365; 58713694400; 8576061200; 7102709025; 7101797862; 7003371276; 56883156900; 57709002800; 7003851288; 7004502384; 7004122081; 7006336588; 57221184039; 24176800100; 57221183795; 57541849100; 6602348306; 57213811106; 7402540442; 57218516593; 57201310324; 56190771600; 57201316395; 57201794355","Spatial Organization and Molecular Correlation of Tumor-Infiltrating Lymphocytes Using Deep Learning on Pathology Images","2018","Cell Reports","583","10.1016/j.celrep.2018.03.086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044586207&doi=10.1016%2fj.celrep.2018.03.086&partnerID=40&md5=dd9467c2aedfcbaf72b3418e99086ffc","Department of Biomedical Informatics, Stony Brook Medicine, Stony Brook, 11794, NY, United States; Department of Computer Science, Stony Brook University, Stony Brook, 11794, NY, United States; Department of Bioinformatics and Computational Biology, University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; Department of Pathology, Stony Brook Medicine, Stony Brook, 11794, NY, United States; Department of Pathology and Laboratory Medicine, Perelman School at the University of Pennsylvania, Philadelphia, 19104, PA, United States; Institute for Systems Biology, Seattle, 98109, WA, United States; Department of Radiation Oncology, University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; Departments of Pathology, Genomic Medicine, Translational Molecular Pathology, The University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; Department of Biomedical Informatics, Emory University, Atlanta, 30322, GA, United States","Saltz J., Department of Biomedical Informatics, Stony Brook Medicine, Stony Brook, 11794, NY, United States; Gupta R., Department of Biomedical Informatics, Stony Brook Medicine, Stony Brook, 11794, NY, United States, Department of Pathology, Stony Brook Medicine, Stony Brook, 11794, NY, United States; Hou L., Department of Computer Science, Stony Brook University, Stony Brook, 11794, NY, United States; Kurc T., Department of Biomedical Informatics, Stony Brook Medicine, Stony Brook, 11794, NY, United States; Singh P., Department of Bioinformatics and Computational Biology, University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; Nguyen V., Department of Computer Science, Stony Brook University, Stony Brook, 11794, NY, United States; Samaras D., Department of Computer Science, Stony Brook University, Stony Brook, 11794, NY, United States; Shroyer K.R., Department of Pathology, Stony Brook Medicine, Stony Brook, 11794, NY, United States; Zhao T., Department of Pathology, Stony Brook Medicine, Stony Brook, 11794, NY, United States; Batiste R., Department of Pathology, Stony Brook Medicine, Stony Brook, 11794, NY, United States; Van Arnam J., Department of Pathology and Laboratory Medicine, Perelman School at the University of Pennsylvania, Philadelphia, 19104, PA, United States; Caesar-Johnson S.J.; Demchok J.A.; Felau I.; Kasapi M.; Ferguson M.L.; Hutter C.M.; Sofia H.J.; Tarnuzzer R.; Wang Z.; Yang L.; Zenklusen J.C.; Zhang J.J.; Chudamani S.; Liu J.; Lolla L.; Naresh R.; Pihl T.; Sun Q.; Wan Y.; Wu Y.; Cho J.; DeFreitas T.; Frazer S.; Gehlenborg N.; Getz G.; Heiman D.I.; Kim J.; Lawrence M.S.; Lin P.; Meier S.; Noble M.S.; Saksena G.; Voet D.; Zhang H.; Bernard B.; Chambwe N.; Dhankani V.; Knijnenburg T.; Kramer R.; Leinonen K.; Liu Y.; Miller M.; Reynolds S.; Shmulevich I., Institute for Systems Biology, Seattle, 98109, WA, United States; Thorsson V., Institute for Systems Biology, Seattle, 98109, WA, United States; Zhang W.; Akbani R.; Broom B.M.; Hegde A.M.; Ju Z.; Kanchi R.S.; Korkut A.; Li J.; Liang H.; Ling S.; Liu W.; Lu Y.; Mills G.B.; Ng K.-S.; Rao A.; Ryan M.; Wang J.; Weinstein J.N.; Zhang J.; Abeshouse A.; Armenia J.; Chakravarty D.; Chatila W.K.; de Bruijn I.; Gao J.; Gross B.E.; Heins Z.J.; Kundra R.; La K.; Ladanyi M.; Luna A.; Nissan M.G.; Ochoa A.; Phillips S.M.; Reznik E.; Sanchez-Vega F.; Sander C.; Schultz N.; Sheridan R.; Sumer S.O.; Sun Y.; Taylor B.S.; Wang J.; Zhang H.; Anur P.; Peto M.; Spellman P.; Benz C.; Stuart J.M.; Wong C.K.; Yau C.; Hayes D.N.; Parker J.S.; Wilkerson M.D.; Ally A.; Balasundaram M.; Bowlby R.; Brooks D.; Carlsen R.; Chuah E.; Dhalla N.; Holt R.; Jones S.J.M.; Kasaian K.; Lee D.; Ma Y.; Marra M.A.; Mayo M.; Moore R.A.; Mungall A.J.; Mungall K.; Robertson A.G.; Sadeghi S.; Schein J.E.; Sipahimalani P.; Tam A.; Thiessen N.; Tse K.; Wong T.; Berger A.C.; Beroukhim R.; Cherniack A.D.; Cibulskis C.; Gabriel S.B.; Gao G.F.; Ha G.; Meyerson M.; Schumacher S.E.; Shih J.; Kucherlapati M.H.; Kucherlapati R.S.; Baylin S.; Cope L.; Danilova L.; Bootwalla M.S.; Lai P.H.; Maglinte D.T.; Van Den Berg D.J.; Weisenberger D.J.; Auman J.T.; Balu S.; Bodenheimer T.; Fan C.; Hoadley K.A.; Hoyle A.P.; Jefferys S.R.; Jones C.D.; Meng S.; Mieczkowski P.A.; Mose L.E.; Perou A.H.; Perou C.M.; Roach J.; Shi Y.; Simons J.V.; Skelly T.; Soloway M.G.; Tan D.; Veluvolu U.; Fan H.; Hinoue T.; Laird P.W.; Shen H.; Zhou W.; Bellair M.; Chang K.; Covington K.; Creighton C.J.; Dinh H.; Doddapaneni H.; Donehower L.A.; Drummond J.; Gibbs R.A.; Glenn R.; Hale W.; Han Y.; Hu J.; Korchina V.; Lee S.; Lewis L.; Li W.; Liu X.; Morgan M.; Morton D.; Muzny D.; Santibanez J.; Sheth M.; Shinbrot E.; Wang L.; Wang M.; Wheeler D.A.; Xi L.; Zhao F.; Hess J.; Appelbaum E.L.; Bailey M.; Cordes M.G.; Ding L.; Fronick C.C.; Fulton L.A.; Fulton R.S.; Kandoth C.; Mardis E.R.; McLellan M.D.; Miller C.A.; Schmidt H.K.; Wilson R.K.; Crain D.; Curley E.; Gardner J.; Lau K.; Mallery D.; Morris S.; Paulauskis J.; Penny R.; Shelton C.; Shelton T.; Sherman M.; Thompson E.; Yena P.; Bowen J.; Gastier-Foster J.M.; Gerken M.; Leraas K.M.; Lichtenberg T.M.; Ramirez N.C.; Wise L.; Zmuda E.; Corcoran N.; Costello T.; Hovens C.; Carvalho A.L.; de Carvalho A.C.; Fregnani J.H.; Longatto-Filho A.; Reis R.M.; Scapulatempo-Neto C.; Silveira H.C.S.; Vidal D.O.; Burnette A.; Eschbacher J.; Hermes B.; Noss A.; Singh R.; Anderson M.L.; Castro P.D.; Ittmann M.; Huntsman D.; Kohl B.; Le X.; Thorp R.; Andry C.; Duffy E.R.; Lyadov V.; Paklina O.; Setdikova G.; Shabunin A.; Tavobilov M.; McPherson C.; Warnick R.; Berkowitz R.; Cramer D.; Feltmate C.; Horowitz N.; Kibel A.; Muto M.; Raut C.P.; Malykh A.; Barnholtz-Sloan J.S.; Barrett W.; Devine K.; Fulop J.; Ostrom Q.T.; Shimmel K.; Wolinsky Y.; Sloan A.E.; De Rose A.; Giuliante F.; Goodman M.; Karlan B.Y.; Hagedorn C.H.; Eckman J.; Harr J.; Myers J.; Tucker K.; Zach L.A.; Deyarmin B.; Hu H.; Kvecher L.; Larson C.; Mural R.J.; Somiari S.; Vicha A.; Zelinka T.; Bennett J.; Iacocca M.; Rabeno B.; Swanson P.; Latour M.; Lacombe L.; Têtu B.; Bergeron A.; McGraw M.; Staugaitis S.M.; Chabot J.; Hibshoosh H.; Sepulveda A.; Su T.; Wang T.; Potapova O.; Voronina O.; Desjardins L.; Mariani O.; Roman-Roman S.; Sastre X.; Stern M.-H.; Cheng F.; Signoretti S.; Berchuck A.; Bigner D.; Lipp E.; Marks J.; McCall S.; McLendon R.; Secord A.; Sharp A.; Behera M.; Brat D.J.; Chen A.; Delman K.; Force S.; Khuri F.; Magliocca K.; Maithel S.; Olson J.J.; Owonikoko T.; Pickens A.; Ramalingam S.; Shin D.M.; Sica G.; Van Meir E.G.; Zhang H.; Eijckenboom W.; Gillis A.; Korpershoek E.; Looijenga L.; Oosterhuis W.; Stoop H.; van Kessel K.E.; Zwarthoff E.C.; Calatozzolo C.; Cuppini L.; Cuzzubbo S.; DiMeco F.; Finocchiaro G.; Mattei L.; Perin A.; Pollo B.; Chen C.; Houck J.; Lohavanichbutr P.; Hartmann A.; Stoehr C.; Stoehr R.; Taubert H.; Wach S.; Wullich B.; Kycler W.; Murawa D.; Wiznerowicz M.; Chung K.; Edenfield W.J.; Martin J.; Baudin E.; Bubley G.; Bueno R.; De Rienzo A.; Richards W.G.; Kalkanis S.; Mikkelsen T.; Noushmehr H.; Scarpace L.; Girard N.; Aymerich M.; Campo E.; Giné E.; Guillermo A.L.; Van Bang N.; Hanh P.T.; Phu B.D.; Tang Y.; Colman H.; Evason K.; Dottino P.R.; Martignetti J.A.; Gabra H.; Juhl H.; Akeredolu T.; Stepa S.; Hoon D.; Ahn K.; Kang K.J.; Beuschlein F.; Breggia A.; Birrer M.; Bell D.; Borad M.; Bryce A.H.; Castle E.; Chandan V.; Cheville J.; Copland J.A.; Farnell M.; Flotte T.; Giama N.; Ho T.; Kendrick M.; Kocher J.-P.; Kopp K.; Moser C.; Nagorney D.; O'Brien D.; O'Neill B.P.; Patel T.; Petersen G.; Que F.; Rivera M.; Roberts L.; Smallridge R.; Smyrk T.; Stanton M.; Thompson R.H.; Torbenson M.; Yang J.D.; Zhang L.; Brimo F.; Ajani J.A.; Gonzalez A.M.A.; Behrens C.; Bondaruk J.; Broaddus R.; Czerniak B.; Esmaeli B.; Fujimoto J.; Gershenwald J.; Guo C.; Lazar A.J., Departments of Pathology, Genomic Medicine, Translational Molecular Pathology, The University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; Logothetis C.; Meric-Bernstam F.; Moran C.; Ramondetta L.; Rice D.; Sood A.; Tamboli P.; Thompson T.; Troncoso P.; Tsao A.; Wistuba I.; Carter C.; Haydu L.; Hersey P.; Jakrot V.; Kakavand H.; Kefford R.; Lee K.; Long G.; Mann G.; Quinn M.; Saw R.; Scolyer R.; Shannon K.; Spillane A.; Stretch O.; Synott M.; Thompson J.; Wilmott J.; Al-Ahmadie H.; Chan T.A.; Ghossein R.; Gopalan A.; Levine D.A.; Reuter V.; Singer S.; Singh B.; Tien N.V.; Broudy T.; Mirsaidi C.; Nair P.; Drwiega P.; Miller J.; Smith J.; Zaren H.; Park J.-W.; Hung N.P.; Kebebew E.; Linehan W.M.; Metwalli A.R.; Pacak K.; Pinto P.A.; Schiffman M.; Schmidt L.S.; Vocke C.D.; Wentzensen N.; Worrell R.; Yang H.; Moncrieff M.; Goparaju C.; Melamed J.; Pass H.; Botnariuc N.; Caraman I.; Cernat M.; Chemencedji I.; Clipca A.; Doruc S.; Gorincioi G.; Mura S.; Pirtac M.; Stancul I.; Tcaciuc D.; Albert M.; Alexopoulou I.; Arnaout A.; Bartlett J.; Engel J.; Gilbert S.; Parfitt J.; Sekhon H.; Thomas G.; Rassl D.M.; Rintoul R.C.; Bifulco C.; Tamakawa R.; Urba W.; Hayward N.; Timmers H.; Antenucci A.; Facciolo F.; Grazi G.; Marino M.; Merola R.; de Krijger R.; Gimenez-Roqueplo A.-P.; Piché A.; Chevalier S.; McKercher G.; Birsoy K.; Barnett G.; Brewer C.; Farver C.; Naska T.; Pennell N.A.; Raymond D.; Schilero C.; Smolenski K.; Williams F.; Morrison C.; Borgia J.A.; Liptay M.J.; Pool M.; Seder C.W.; Junker K.; Omberg L.; Dinkin M.; Manikhas G.; Alvaro D.; Bragazzi M.C.; Cardinale V.; Carpino G.; Gaudio E.; Chesla D.; Cottingham S.; Dubina M.; Moiseenko F.; Dhanasekaran R.; Becker K.-F.; Janssen K.-P.; Slotta-Huspenina J.; Abdel-Rahman M.H.; Aziz D.; Bell S.; Cebulla C.M.; Davis A.; Duell R.; Elder J.B.; Hilty J.; Kumar B.; Lang J.; Lehman N.L.; Mandt R.; Nguyen P.; Pilarski R.; Rai K.; Schoenfield L.; Senecal K.; Wakely P.; Hansen P.; Lechan R.; Powers J.; Tischler A.; Grizzle W.E.; Sexton K.C.; Kastl A.; Henderson J.; Porten S.; Waldmann J.; Fassnacht M.; Asa S.L.; Schadendorf D.; Couce M.; Graefen M.; Huland H.; Sauter G.; Schlomm T.; Simon R.; Tennstedt P.; Olabode O.; Nelson M.; Bathe O.; Carroll P.R.; Chan J.M.; Disaia P.; Glenn P.; Kelley R.K.; Landen C.N.; Phillips J.; Prados M.; Simko J.; Smith-McCune K.; VandenBerg S.; Roggin K.; Fehrenbach A.; Kendler A.; Sifri S.; Steele R.; Jimeno A.; Carey F.; Forgie I.; Mannelli M.; Carney M.; Hernandez B.; Campos B.; Herold-Mende C.; Jungk C.; Unterberg A.; von Deimling A.; Bossler A.; Galbraith J.; Jacobus L.; Knudson M.; Knutson T.; Ma D.; Milhem M.; Sigmund R.; Godwin A.K.; Madan R.; Rosenthal H.G.; Adebamowo C.; Adebamowo S.N.; Boussioutas A.; Beer D.; Giordano T.; Mes-Masson A.-M.; Saad F.; Bocklage T.; Landrum L.; Mannel R.; Moore K.; Moxley K.; Postier R.; Walker J.; Zuna R.; Feldman M.; Valdivieso F.; Dhir R.; Luketich J.; Pinero E.M.M.; Quintero-Aguilo M.; Carlotti C.G., Jr.; Dos Santos J.S.; Kemp R.; Sankarankuty A.; Tirapelli D.; Catto J.; Agnew K.; Swisher E.; Creaney J.; Robinson B.; Shelley C.S.; Godwin E.M.; Kendall S.; Shipman C.; Bradford C.; Carey T.; Haddad A.; Moyer J.; Peterson L.; Prince M.; Rozek L.; Wolf G.; Bowman R.; Fong K.M.; Yang I.; Korst R.; Rathmell W.K.; Fantacone-Campbell J.L.; Hooke J.A.; Kovatich A.J.; Shriver C.D.; DiPersio J.; Drake B.; Govindan R.; Heath S.; Ley T.; Van Tine B.; Westervelt P.; Rubin M.A.; Lee J.I.; Aredes N.D.; Mariamidze A.; Rao A.U.K., Department of Bioinformatics and Computational Biology, University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States, Department of Radiation Oncology, University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; Sharma A., Department of Biomedical Informatics, Emory University, Atlanta, 30322, GA, United States","Beyond sample curation and basic pathologic characterization, the digitized H&E-stained images of TCGA samples remain underutilized. To highlight this resource, we present mappings of tumor-infiltrating lymphocytes (TILs) based on H&E images from 13 TCGA tumor types. These TIL maps are derived through computational staining using a convolutional neural network trained to classify patches of images. Affinity propagation revealed local spatial structure in TIL patterns and correlation with overall survival. TIL map structural patterns were grouped using standard histopathological parameters. These patterns are enriched in particular T cell subpopulations derived from molecular measures. TIL densities and spatial structure were differentially enriched among tumor types, immune subtypes, and tumor molecular subtypes, implying that spatial infiltrate state could reflect particular tumor cell aberration states. Obtaining spatial lymphocytic patterns linked to the rich genomic characterization of TCGA samples demonstrates one use for the TCGA image archives with insights into the tumor-immune microenvironment. Tumor-infiltrating lymphocytes (TILs) were identified from standard pathology cancer images by a deep-learning-derived “computational stain” developed by Saltz et al. They processed 5,202 digital images from 13 cancer types. Resulting TIL maps were correlated with TCGA molecular data, relating TIL content to survival, tumor subtypes, and immune profiles. © 2018 The Authors","artificial intelligence; bioinformatics; computer vision; deep learning; digital pathology; immuno-oncology; lymphocytes; machine learning; tumor microenvironment; tumor-infiltrating lymphocytes","Deep Learning; Humans; Image Interpretation, Computer-Assisted; Lymphocytes, Tumor-Infiltrating; Neoplasms; eosin; hematoxylin; adolescent; adult; Article; artificial neural network; cancer genetics; cancer survival; cell infiltration; cell structure; controlled study; correlation coefficient; deep learning method; female; gene mapping; histopathology; human; human cell; human genome; human tissue; image analysis; machine learning; major clinical study; male; molecular pathology; overall survival; priority journal; spatial analysis; staining; T lymphocyte subpopulation; tumor associated leukocyte; computer assisted diagnosis; metabolism; neoplasm; pathology; procedures; tumor associated leukocyte","Elsevier B.V.","22111247","","","29617659","Article","Scopus","2-s2.0-85044586207"
"Zeng L.-L.; Wang H.; Hu P.; Yang B.; Pu W.; Shen H.; Chen X.; Liu Z.; Yin H.; Tan Q.; Wang K.; Hu D.","Zeng, Ling-Li (35147001500); Wang, Huaning (35109844400); Hu, Panpan (36165563300); Yang, Bo (55350905000); Pu, Weidan (51864454000); Shen, Hui (35436091400); Chen, Xingui (55832935100); Liu, Zhening (55830586600); Yin, Hong (7403114096); Tan, Qingrong (7102120177); Wang, Kai (56959592900); Hu, Dewen (7402585423)","35147001500; 35109844400; 36165563300; 55350905000; 51864454000; 35436091400; 55832935100; 55830586600; 7403114096; 7102120177; 56959592900; 7402585423","Multi-Site Diagnostic Classification of Schizophrenia Using Discriminant Deep Learning with Functional Connectivity MRI","2018","EBioMedicine","184","10.1016/j.ebiom.2018.03.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044785202&doi=10.1016%2fj.ebiom.2018.03.017&partnerID=40&md5=7e6aa18958c41a41e8cc8bf954f80bd8","College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; Department of Psychiatry, Xijing Hospital, Fourth Military Medical University, Xi'an, China; Department of Neurology, The First Affiliated Hospital of Anhui Medical University, Hefei, China; Medical Psychological Center, Second Xiangya Hospital, Central South University, Changsha, China; Mental Health Institute, Second Xiangya Hospital, Central South University, Changsha, China; Department of Radiology, Xijing Hospital, Fourth Military Medical University, Xi'an, China","Zeng L.-L., College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; Wang H., Department of Psychiatry, Xijing Hospital, Fourth Military Medical University, Xi'an, China; Hu P., Department of Neurology, The First Affiliated Hospital of Anhui Medical University, Hefei, China; Yang B., College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; Pu W., Medical Psychological Center, Second Xiangya Hospital, Central South University, Changsha, China; Shen H., College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; Chen X., Department of Neurology, The First Affiliated Hospital of Anhui Medical University, Hefei, China; Liu Z., Mental Health Institute, Second Xiangya Hospital, Central South University, Changsha, China; Yin H., Department of Radiology, Xijing Hospital, Fourth Military Medical University, Xi'an, China; Tan Q., Department of Psychiatry, Xijing Hospital, Fourth Military Medical University, Xi'an, China; Wang K., Department of Neurology, The First Affiliated Hospital of Anhui Medical University, Hefei, China; Hu D., College of Mechatronics and Automation, National University of Defense Technology, Changsha, China","Background: A lack of a sufficiently large sample at single sites causes poor generalizability in automatic diagnosis classification of heterogeneous psychiatric disorders such as schizophrenia based on brain imaging scans. Advanced deep learning methods may be capable of learning subtle hidden patterns from high dimensional imaging data, overcome potential site-related variation, and achieve reproducible cross-site classification. However, deep learning-based cross-site transfer classification, despite less imaging site-specificity and more generalizability of diagnostic models, has not been investigated in schizophrenia. Methods: A large multi-site functional MRI sample (n = 734, including 357 schizophrenic patients from seven imaging resources) was collected, and a deep discriminant autoencoder network, aimed at learning imaging site-shared functional connectivity features, was developed to discriminate schizophrenic individuals from healthy controls. Findings: Accuracies of approximately 85·0% and 81·0% were obtained in multi-site pooling classification and leave-site-out transfer classification, respectively. The learned functional connectivity features revealed dysregulation of the cortical-striatal-cerebellar circuit in schizophrenia, and the most discriminating functional connections were primarily located within and across the default, salience, and control networks. Interpretation: The findings imply that dysfunctional integration of the cortical-striatal-cerebellar circuit across the default, salience, and control networks may play an important role in the “disconnectivity” model underlying the pathophysiology of schizophrenia. The proposed discriminant deep learning method may be capable of learning reliable connectome patterns and help in understanding the pathophysiology and achieving accurate prediction of schizophrenia across multiple independent imaging sites. © 2018 German Center for Neurodegenerative Diseases (DZNE)","Cerebellum; Connectome; Deep learning; fMRI; Schizophrenia; Striatum","Adult; Demography; Discriminant Analysis; Female; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Neural Pathways; Schizophrenia; Support Vector Machine; adolescent; adult; anatomical concepts; Article; artifact; artificial neural network; BOLD signal; brain cortex layer; cerebellum cortex; classification; cohort analysis; computer assisted diagnosis; conceptual framework; controlled study; correlation coefficient; echo planar imaging; female; frontoparietal cortex; functional connectivity; functional neuroimaging; head movement; human; learning; major clinical study; male; medial frontal cortex; mental disease; middle aged; multivariate analysis; neuroscience; nuclear magnetic resonance imaging; pathophysiology; Positive and Negative Syndrome Scale; priority journal; retrospective study; schizophrenia; scoring system; semi structured interview; striate cortex; support vector machine; training; univariate analysis; working memory; young adult; demography; discriminant analysis; machine learning; nerve tract; pathophysiology; schizophrenia","Elsevier B.V.","23523964","","","29622496","Article","Scopus","2-s2.0-85044785202"
"Ambe K.; Ishihara K.; Ochibe T.; Ohya K.; Tamura S.; Inoue K.; Yoshida M.; Tohkin M.","Ambe, Kaori (57194390423); Ishihara, Kana (57201448557); Ochibe, Tatsuya (57201449547); Ohya, Kazuyuki (57201447826); Tamura, Sorami (57201449064); Inoue, Kaoru (56430197000); Yoshida, Midori (7601541060); Tohkin, Masahiro (6603892330)","57194390423; 57201448557; 57201449547; 57201447826; 57201449064; 56430197000; 7601541060; 6603892330","In silico prediction of chemical-induced hepatocellular hypertrophy using molecular descriptors","2018","Toxicological Sciences","19","10.1093/toxsci/kfx287","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044857599&doi=10.1093%2ftoxsci%2fkfx287&partnerID=40&md5=08b1bfcfaabbf670566b1024a8a105a4","Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya, 467-8603, Japan; Division of Pathology, National Institute of Health Sciences, Kawasaki, 1210-9501, Japan; Food Safety Commission, Cabinet Office, Tokyo, 107-6122, Japan","Ambe K., Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya, 467-8603, Japan; Ishihara K., Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya, 467-8603, Japan; Ochibe T., Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya, 467-8603, Japan; Ohya K., Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya, 467-8603, Japan; Tamura S., Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya, 467-8603, Japan; Inoue K., Division of Pathology, National Institute of Health Sciences, Kawasaki, 1210-9501, Japan; Yoshida M., Food Safety Commission, Cabinet Office, Tokyo, 107-6122, Japan; Tohkin M., Department of Regulatory Science, Graduate School of Pharmaceutical Sciences, Nagoya City University, Nagoya, 467-8603, Japan","In silico prediction for toxicity of chemicals is required to reduce cost, time, and animal testing. However, predicting hepatocellular hypertrophy, which often affects the derivation of the No-Observed-Adverse-Effect Level in repeated dose toxicity studies, is difficult because pathological findings are diverse, mechanisms are largely unknown, and a wide variety of chemical structures exists. Therefore, a method for predicting the hepatocellular hypertrophy of diverse chemicals without complete understanding of their mechanisms is necessary. In this study, we developed predictive classification models of hepatocellular hypertrophy using machine learning-specifically, deep learning, random forest, and support vector machine. We extracted hepatocellular hypertrophy data on rats from 2 toxicological databases, our original database developed from risk assessment reports such as pesticides, and the Hazard Evaluation Support System Integrated Platform. Then, we constructed prediction models based on molecular descriptors and evaluated their performance using independent test chemicals datasets, which differed from the training chemicals datasets. Further, we defined the applicability domain (AD), which generally limits the application for chemicals, as structurally similar to the training chemicals dataset. The best model was found to be the support vector machine model using the Hazard Evaluation Support System Integrated Platform dataset, which was trained with 251 chemicals and predicted 214 test chemicals inside the applicability domain. It afforded a prediction accuracy of 0.76, sensitivity of 0.90, and area under the curve of 0.81. These in silico predictive classification models could be reliable tools for hepatocellular hypertrophy assessments and can facilitate the development of in silico models for toxicity prediction. © The Author 2017. Published by Oxford University Press on behalf of the Society of Toxicology.","Applicability domain; Hepatocellular hypertrophy; In silico prediction; Machine learning methods; Repeated dose toxicity","Animal Testing Alternatives; Animals; Computer Simulation; Deep Learning; Food Additives; Hepatocytes; Hypertrophy; Liver; Models, Biological; Molecular Structure; Pesticides; Quantitative Structure-Activity Relationship; Rats; Support Vector Machine; Toxicity Tests; Veterinary Drugs; food additive; pesticide; veterinary drug; accuracy; Article; chemically induced disorder; classification algorithm; computer model; deep learning; learning algorithm; liver hypertrophy; nonhuman; prediction; predictive value; random forest; rat; risk assessment; support vector machine; animal; animal testing alternative; biological model; chemical structure; chemistry; computer simulation; drug effect; hypertrophy; liver; liver cell; pathology; procedures; quantitative structure activity relation; toxicity testing","Oxford University Press","10966080","","TOSCF","29309657","Article","Scopus","2-s2.0-85044857599"
"Syeda-Mahmood T.","Syeda-Mahmood, Tanveer (7003810087)","7003810087","Role of Big Data and Machine Learning in Diagnostic Decision Support in Radiology","2018","Journal of the American College of Radiology","68","10.1016/j.jacr.2018.01.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042759908&doi=10.1016%2fj.jacr.2018.01.028&partnerID=40&md5=5179ec3b17128bf2474a32c4908a29ef","IBM Almaden Research Center, San Jose, California, United States","Syeda-Mahmood T., IBM Almaden Research Center, San Jose, California, United States","The field of diagnostic decision support in radiology is undergoing rapid transformation with the availability of large amounts of patient data and the development of new artificial intelligence methods of machine learning such as deep learning. They hold the promise of providing imaging specialists with tools for improving the accuracy and efficiency of diagnosis and treatment. In this article, we will describe the growth of this field for radiology and outline general trends highlighting progress in the field of diagnostic decision support from the early days of rule-based expert systems to cognitive assistants of the modern era. © 2018 American College of Radiology","artificial intelligence; cognitive assistants; deep learning; Diagnostic decision support; knowledge and reasoning; machine learning; medical image analysis","Big Data; Decision Support Techniques; Deep Learning; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Radiology; article; artificial intelligence; decision support system; expert system; human; human experiment; image analysis; machine learning; radiology; computer assisted diagnosis; radiology; trends","Elsevier B.V.","15461440","","","29502585","Article","Scopus","2-s2.0-85042759908"
"Zhao Y.; Liu A.; Liu J.; Liu Y.; Wu J.; Fang X.; Pan J.","Zhao, Ying (57194576922); Liu, Ailian (55459861500); Liu, Jinghong (57202993547); Liu, Yijun (42761872900); Wu, Jingjun (57198430746); Fang, Xin (57190969851); Pan, Judong (11840381900)","57194576922; 55459861500; 57202993547; 42761872900; 57198430746; 57190969851; 11840381900","Impact of pixel shine algorithm based on deep machine learning on image quality of abdominal low-dose plain CT scanning in patients with high body mass index; [基于深度学习的像素闪烁算法对高体质量指数患者低剂量腹部CT平扫图像质量的影响]","2018","Chinese Journal of Medical Imaging Technology","0","10.13929/j.1003-3289.201708199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060452031&doi=10.13929%2fj.1003-3289.201708199&partnerID=40&md5=934146b0f880fe21598423e4b637d51d","Department of Radiology, the First Affiliated Hospital of Dalian Medical University, Dalian, 116011, China; Department of Radiology & Biomedical Imaging, University of California, San Francisco, 94143, United States","Zhao Y., Department of Radiology, the First Affiliated Hospital of Dalian Medical University, Dalian, 116011, China; Liu A., Department of Radiology, the First Affiliated Hospital of Dalian Medical University, Dalian, 116011, China; Liu J., Department of Radiology, the First Affiliated Hospital of Dalian Medical University, Dalian, 116011, China; Liu Y., Department of Radiology, the First Affiliated Hospital of Dalian Medical University, Dalian, 116011, China; Wu J., Department of Radiology, the First Affiliated Hospital of Dalian Medical University, Dalian, 116011, China; Fang X., Department of Radiology, the First Affiliated Hospital of Dalian Medical University, Dalian, 116011, China; Pan J., Department of Radiology & Biomedical Imaging, University of California, San Francisco, 94143, United States","                             Objective To investigate the impact of deep machine learning Pixel Shine (PS) algorithm on image quality of abdominal low-dose plain CT scanning in BMI≥25 kg/m                             2                              patients. Methods A total of 59 patients (BMI≥25 kg/m                             2                             ) who underwent abdominal CT scan were collected. The patients were divided into group A (100 kVp, n=30) and B (120 kVp, n=29) according to the tube voltage. According to different reconstruction algorithms and treatment methods, patients in group A were divided into A1 (FBP), A2 (FBP+PS), A3 (50%ASiR-V) and A4 (50%ASiR-V+PS) subgroups, while in group B were divided into B1 (FBP) and B2 (50%ASiR-V) subgroups. CT and SD values of right hepatic lobe and right erector spinae were measured, then SNR and CNR of liver and CT dose index of volume (CTDI                             vol                             ) were calculated. The consistency of parameters measured by two observers was evaluated. Results The consistency of parameters measured by two observers was good (all ICC>0.80). There was no statistical difference of CT values of liver and erector among A1-A4 subgroups (all P>0.05), whereas statistical differences of SD values of liver and erector spinae, also of SNR and CNR of liver were found (all P<0.001). Among A1-A4 subgroups, SD                             A4                             <SD                             A2                             <SD                             A3                             <SD                             A1                             , SNR                             A4                             >SNR                             A2                             >SNR                             A3                             >SNR                             A1                              (all P<0.001) was observed. There was no significant difference of CNR between A1 and A3 subgroup (P=0.078), while CNR                             A4                             > CNR                             A2                             > CNR                             A3                              or CNR                             A1                              (P<0.001) was noticed. SD values of the liver in subgroup A2 was lower than subgroup B1, and A4 was lower than B2 subgroup (all P<0.001), and SNR and CNR increased significantly in A2 and A4 subgroups (all P<0.001). CTDI                             vol                              of group A was lower than that of group B (P<0.001). Conclusion Deep machine learning PS algorithm can improve image quality of abdominal low-dose plain CT scanning in high-BMI patients.                          Copyright © 2018 by the Press of Chinese Journal of Medical Imaging and Technology.","Image quality; Low dose; Pixel shine algorithm; Tomography, X-ray computed","adult; article; body mass; body weight; controlled study; erector spinae muscle; female; human; image quality; low drug dose; machine learning; major clinical study; male; right liver lobe; X ray; x-ray computed tomography","Editorial Board of Chinese Journal of Medical Imaging Technology","10033289","","","","Article","Scopus","2-s2.0-85060452031"
"Al-masni M.A.; Al-antari M.A.; Park J.-M.; Gi G.; Kim T.-Y.; Rivera P.; Valarezo E.; Choi M.-T.; Han S.-M.; Kim T.-S.","Al-masni, Mohammed A. (57192575678); Al-antari, Mugahed A. (57189003551); Park, Jeong-Min (57196187931); Gi, Geon (57196186341); Kim, Tae-Yeon (57196187437); Rivera, Patricio (57196189781); Valarezo, Edwin (57196190020); Choi, Mun-Taek (16229647800); Han, Seung-Moo (8564174800); Kim, Tae-Seong (36072897600)","57192575678; 57189003551; 57196187931; 57196186341; 57196187437; 57196189781; 57196190020; 16229647800; 8564174800; 36072897600","Simultaneous detection and classification of breast masses in digital mammograms via a deep learning YOLO-based CAD system","2018","Computer Methods and Programs in Biomedicine","322","10.1016/j.cmpb.2018.01.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041410686&doi=10.1016%2fj.cmpb.2018.01.017&partnerID=40&md5=fbde2b90821e2568a51d3b8a21d6dc5c","Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; School of Mechanical Engineering, Sungkyunkwan University, South Korea","Al-masni M.A., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Al-antari M.A., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Park J.-M., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Gi G., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Kim T.-Y., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Rivera P., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Valarezo E., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Choi M.-T., School of Mechanical Engineering, Sungkyunkwan University, South Korea; Han S.-M., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea; Kim T.-S., Department of Biomedical Engineering, College of Electronics and Information, Kyung Hee University, Yongin, South Korea","Background and objective: Automatic detection and classification of the masses in mammograms are still a big challenge and play a crucial role to assist radiologists for accurate diagnosis. In this paper, we propose a novel Computer-Aided Diagnosis (CAD) system based on one of the regional deep learning techniques, a ROI-based Convolutional Neural Network (CNN) which is called You Only Look Once (YOLO). Although most previous studies only deal with classification of masses, our proposed YOLO-based CAD system can handle detection and classification simultaneously in one framework. Methods: The proposed CAD system contains four main stages: preprocessing of mammograms, feature extraction utilizing deep convolutional networks, mass detection with confidence, and finally mass classification using Fully Connected Neural Networks (FC-NNs). In this study, we utilized original 600 mammograms from Digital Database for Screening Mammography (DDSM) and their augmented mammograms of 2,400 with the information of the masses and their types in training and testing our CAD. The trained YOLO-based CAD system detects the masses and then classifies their types into benign or malignant. Results: Our results with five-fold cross validation tests show that the proposed CAD system detects the mass location with an overall accuracy of 99.7%. The system also distinguishes between benign and malignant lesions with an overall accuracy of 97%. Conclusions: Our proposed system even works on some challenging breast cancer cases where the masses exist over the pectoral muscles or dense regions. © 2018 Elsevier B.V.","Breast cancer; Computer Aided Diagnosis; Deep learning; Mass detection and classification; You Only Look Once (YOLO)","Breast Neoplasms; Diagnosis, Computer-Assisted; Female; Humans; Machine Learning; Mammography; Neural Networks (Computer); Probability; Radiology Information Systems; Reproducibility of Results; Computer aided instruction; Convolution; Convolutional neural networks; Deep learning; Diseases; E-learning; Feature extraction; Learning systems; Mammography; X ray screens; Breast Cancer; Computer Aided Diagnosis(CAD); Cross-validation tests; Digital database for screening mammographies; Fully connected neural network; Mass detection; Simultaneous detection; You Only Look Once (YOLO); Article; artificial neural network; benign breast tumor; breast tumor; computer assisted diagnosis; convolutional neural network; diagnostic accuracy; digital mammography; Fully Connected Neural Network; malignant breast tumor; malignant neoplasm; pectoral muscle; tumor classification; tumor diagnosis; You Only Look Once; artificial neural network; breast tumor; classification; devices; diagnostic imaging; female; human; machine learning; mammography; probability; procedures; radiology information system; reproducibility; Computer aided diagnosis","Elsevier Ireland Ltd","01692607","","CMPBE","29477437","Article","Scopus","2-s2.0-85041410686"
"Yin Z.; Zhang J.","Yin, Zhong (51061764400); Zhang, Jianhua (57057829600)","51061764400; 57057829600","Task-generic mental fatigue recognition based on neurophysiological signals and dynamical deep extreme learning machine","2018","Neurocomputing","35","10.1016/j.neucom.2017.12.062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041560038&doi=10.1016%2fj.neucom.2017.12.062&partnerID=40&md5=88377fdea79c88969361223cb81f0870","Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Jungong Road 516, Yangpu District, Shanghai, 200093, China; Department of Automation, East China University of Science and Technology, Shanghai, 200237, China","Yin Z., Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Jungong Road 516, Yangpu District, Shanghai, 200093, China; Zhang J., Department of Automation, East China University of Science and Technology, Shanghai, 200237, China","The electroencephalography (EEG) based machine-learning model for mental fatigue recognition can evaluate the reliability of the human operator performance. The task-generic model is particularly important since the time cost for preparing the task-specific training EEG dataset is avoid. This study develops a novel mental fatigue classifier, dynamical deep extreme learning machine (DD-ELM), to adapt the variation of the EEG feature distributions across two mental tasks. Different from the static deep learning approaches, DD-ELM iteratively updates the shallow weights at multiple time steps during the testing stage. The proposed method incorporates the both of the merits from the deep network for EEG feature abstraction and the ELM autoencoder for fast weight recompuation. The feasibility of the DD-ELM is validated by investigating EEG datasets recorded under two paradigms of AutoCAMS human–machine tasks. The accuracy comparison indicates the new classifier significantly outperforms several state-of-the-art mental fatigue estimators. By examining the CPU time, the computational burden of the DD-ELM is also acceptable for high-dimensional EEG features. © 2018 Elsevier B.V.","Deep learning; Electroencephalography; Extreme learning machine; Human–machine system; Mental fatigue","Biomedical signal processing; Diseases; Electroencephalography; Electrophysiology; Iterative methods; Knowledge acquisition; Learning systems; Man machine systems; Accuracy comparisons; Computational burden; Extreme learning machine; Feature abstraction; Feature distribution; Machine learning models; Mental fatigue; Multiple time step; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85041560038"
"Kim K.H.; Choi S.H.; Park S.-H.","Kim, Ki Hwan (56987946700); Choi, Seung Hong (36068182300); Park, Sung-Hong (16686626100)","56987946700; 36068182300; 16686626100","Improving arterial spin labeling by using deep learning","2018","Radiology","75","10.1148/radiol.2017171154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046029018&doi=10.1148%2fradiol.2017171154&partnerID=40&md5=a6cb6da683ce95f4bbc936e5b0063c07","Graduate School of Medical Science and Engineering, Korea Advanced Institute of Science and Technology, CMS (E16) Building, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, CMS (E16) Building, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Department of Radiology, Seoul National University Hospital, Seoul, South Korea; Department of Radiology, Seoul National University, College of Medicine, Institute of Radiation Medicine, Seoul National University, Medical Research Center, Seoul, South Korea; Center for Nanoparticle Research, Institute for Basic Science, Seoul, South Korea","Kim K.H., Graduate School of Medical Science and Engineering, Korea Advanced Institute of Science and Technology, CMS (E16) Building, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Choi S.H., Department of Radiology, Seoul National University Hospital, Seoul, South Korea, Department of Radiology, Seoul National University, College of Medicine, Institute of Radiation Medicine, Seoul National University, Medical Research Center, Seoul, South Korea, Center for Nanoparticle Research, Institute for Basic Science, Seoul, South Korea; Park S.-H., Graduate School of Medical Science and Engineering, Korea Advanced Institute of Science and Technology, CMS (E16) Building, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea, Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, CMS (E16) Building, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea","Purpose: To develop a deep learning algorithm that generates arterial spin labeling (ASL) perfusion images with higher accuracy and robustness by using a smaller number of subtraction images. Materials and Methods: For ASL image generation from pair-wise subtraction, we used a convolutional neural network (CNN) as a deep learning algorithm. The ground truth perfusion images were generated by averaging six or seven pairwise subtraction images acquired with (a) conventional pseudocontinuous arterial spin labeling from seven healthy subjects or (b) Hadamard-encoded pseudocontinuous ASL from 114 patients with various diseases. CNNs were trained to generate perfusion images from a smaller number (two or three) of subtraction images and evaluated by means of cross-validation. CNNs from the patient data sets were also tested on 26 separate stroke data sets. CNNs were compared with the conventional averaging method in terms of mean square error and radiologic score by using a paired t test and/or Wilcoxon signed-rank test. Results: Mean square errors were approximately 40% lower than those of the conventional averaging method for the crossvalidation with the healthy subjects and patients and the separate test with the patients who had experienced a stroke (P <.001). Region-of-interest analysis in stroke regions showed that cerebral blood flow maps from CNN (mean ± standard deviation, 19.7 mL per 100 g/min ± 9.7) had smaller mean square errors than those determined with the conventional averaging method (43.2 ± 29.8) (P <.001). Radiologic scoring demonstrated that CNNs suppressed noise and motion and/or segmentation artifacts better than the conventional averaging method did (P <.001). Conclusion: CNNs provided superior perfusion image quality and more accurate perfusion measurement compared with those of the conventional averaging method for generation of ASL images from pair-wise subtraction images. © RSNA, 2018.","","Adult; Algorithms; Brain Neoplasms; Cerebrovascular Circulation; Female; Humans; Machine Learning; Magnetic Resonance Angiography; Male; Middle Aged; Perfusion Imaging; Reference Values; Retrospective Studies; Spin Labels; Stroke; spin label; adult; aged; arterial spin labeling; Article; artificial neural network; brain blood flow; brain infarction; cerebrovascular accident; controlled study; convolutional neural network; diagnostic accuracy; female; human; image quality; image segmentation; image subtraction; intermethod comparison; learning algorithm; major clinical study; male; middle aged; perfusion weighted imaging; priority journal; radiology; retrospective study; algorithm; brain circulation; brain tumor; diagnostic imaging; machine learning; magnetic resonance angiography; pathophysiology; physiology; procedures; reference value; scintigraphy","Radiological Society of North America Inc.","00338419","","RADLA","29267145","Article","Scopus","2-s2.0-85046029018"
"Choi S.B.; Lee W.; Yoon J.-H.; Won J.-U.; Kim D.W.","Choi, Soo Beom (56147868100); Lee, Wanhyung (57191079763); Yoon, Jin-Ha (35766041900); Won, Jong-Uk (7201429810); Kim, Deok Won (35264177400)","56147868100; 57191079763; 35766041900; 7201429810; 35264177400","Ten-year prediction of suicide death using Cox regression and machine learning in a nationwide retrospective cohort study in South Korea","2018","Journal of Affective Disorders","55","10.1016/j.jad.2018.01.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041482472&doi=10.1016%2fj.jad.2018.01.019&partnerID=40&md5=a8858a34d25ee2ff24442e1b700c07b0","Department of Medical Engineering, Yonsei University College of Medicine, Seoul, South Korea; Graduate Program in Biomedical Engineering, Yonsei University, Seoul, South Korea; The Institute for Occupational Health, Yonsei University College of Medicine, Seoul, South Korea; Graduate School of Public Health, Yonsei University College of Medicine, Seoul, South Korea; Incheon Worker's Health Center, Incheon, South Korea","Choi S.B., Department of Medical Engineering, Yonsei University College of Medicine, Seoul, South Korea, Graduate Program in Biomedical Engineering, Yonsei University, Seoul, South Korea; Lee W., The Institute for Occupational Health, Yonsei University College of Medicine, Seoul, South Korea, Graduate School of Public Health, Yonsei University College of Medicine, Seoul, South Korea, Incheon Worker's Health Center, Incheon, South Korea; Yoon J.-H., The Institute for Occupational Health, Yonsei University College of Medicine, Seoul, South Korea, Graduate School of Public Health, Yonsei University College of Medicine, Seoul, South Korea, Incheon Worker's Health Center, Incheon, South Korea; Won J.-U., The Institute for Occupational Health, Yonsei University College of Medicine, Seoul, South Korea, Graduate School of Public Health, Yonsei University College of Medicine, Seoul, South Korea, Incheon Worker's Health Center, Incheon, South Korea; Kim D.W., Department of Medical Engineering, Yonsei University College of Medicine, Seoul, South Korea, Graduate Program in Biomedical Engineering, Yonsei University, Seoul, South Korea","Background: Death by suicide is a preventable public health concern worldwide. The aim of this study is to investigate the probability of suicide death using baseline characteristics and simple medical facility visit history data using Cox regression, support vector machines (SVMs), and deep neural networks (DNNs). Method: This study included 819,951 subjects in the National Health Insurance Service (NHIS)–Cohort Sample Database from 2004 to 2013. The dataset was divided randomly into two independent training and validation groups. To improve the performance of predicting suicide death, we applied SVM and DNN to the same training set as the Cox regression model. Results: Among the study population, 2546 people died by intentional self-harm during the follow-up time. Sex, age, type of insurance, household income, disability, and medical records of eight ICD-10 codes (including mental and behavioural disorders) were selected by a Cox regression model with backward stepwise elimination. The area of under the curve (AUC) of Cox regression (0.688), SVM (0.687), and DNN (0.683) were approximately the same. The group with top.5% of predicted probability had hazard ratio of 26.21 compared to that with the lowest 10% of predicted probability. Limitations: This study is limited by the lack of information on suicidal ideation and attempts, other potential covariates such as information of medication and subcategory ICD-10 codes. Moreover, predictors from the prior 12–24 months of the date of death could be expected to show better performances than predictors from up to 10 years ago. Conclusions: We suggest a 10-year probability prediction model for suicide death using general characteristics and simple insurance data, which are annually conducted by the Korean government. Suicide death prevention might be enhanced by our prediction model. © 2018 Elsevier B.V.","Cox regression; Deep learning; Suicide prediction; Support vector machine","Adult; Area Under Curve; Databases, Factual; Female; Humans; Insurance, Health; Machine Learning; Male; Mental Disorders; Middle Aged; Neural Networks (Computer); Proportional Hazards Models; Republic of Korea; Retrospective Studies; Risk Factors; Suicide; Young Adult; adolescent; adult; aged; Article; automutilation; cohort analysis; controlled study; deep neural network; female; follow up; household income; human; ICD-10; machine learning; major clinical study; male; medical record; national health insurance; pattern recognition; prediction; priority journal; proportional hazards model; public health insurance; retrospective study; South Korea; suicide; support vector machine; area under the curve; artificial neural network; factual database; health insurance; machine learning; mental disease; middle aged; proportional hazards model; risk factor; statistics and numerical data; suicide; young adult","Elsevier B.V.","01650327","","JADID","29408160","Article","Scopus","2-s2.0-85041482472"
"Ahmedt-Aristizabal D.; Fookes C.; Nguyen K.; Denman S.; Sridharan S.; Dionisio S.","Ahmedt-Aristizabal, David (57195974557); Fookes, Clinton (7003338437); Nguyen, Kien (56036524800); Denman, Simon (56238954000); Sridharan, Sridha (7102172665); Dionisio, Sasha (41661230600)","57195974557; 7003338437; 56036524800; 56238954000; 7102172665; 41661230600","Deep facial analysis: A new phase I epilepsy evaluation using computer vision","2018","Epilepsy and Behavior","42","10.1016/j.yebeh.2018.02.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044121815&doi=10.1016%2fj.yebeh.2018.02.010&partnerID=40&md5=8db288ca74fc9e3c8dcc2d7d1587dcac","Speech, Audio, Image and Video Technologies (SAIVT) Research Program, School of Electrical Engineering & Computer Science, Queensland University of Technology, Brisbane, Australia; Department of Mater Advanced Epilepsy Unit, Mater Centre for Neurosciences, Brisbane, Australia","Ahmedt-Aristizabal D., Speech, Audio, Image and Video Technologies (SAIVT) Research Program, School of Electrical Engineering & Computer Science, Queensland University of Technology, Brisbane, Australia; Fookes C., Speech, Audio, Image and Video Technologies (SAIVT) Research Program, School of Electrical Engineering & Computer Science, Queensland University of Technology, Brisbane, Australia; Nguyen K., Speech, Audio, Image and Video Technologies (SAIVT) Research Program, School of Electrical Engineering & Computer Science, Queensland University of Technology, Brisbane, Australia; Denman S., Speech, Audio, Image and Video Technologies (SAIVT) Research Program, School of Electrical Engineering & Computer Science, Queensland University of Technology, Brisbane, Australia; Sridharan S., Speech, Audio, Image and Video Technologies (SAIVT) Research Program, School of Electrical Engineering & Computer Science, Queensland University of Technology, Brisbane, Australia; Dionisio S., Department of Mater Advanced Epilepsy Unit, Mater Centre for Neurosciences, Brisbane, Australia","Semiology observation and characterization play a major role in the presurgical evaluation of epilepsy. However, the interpretation of patient movements has subjective and intrinsic challenges. In this paper, we develop approaches to attempt to automatically extract and classify semiological patterns from facial expressions. We address limitations of existing computer-based analytical approaches of epilepsy monitoring, where facial movements have largely been ignored. This is an area that has seen limited advances in the literature. Inspired by recent advances in deep learning, we propose two deep learning models, landmark-based and region-based, to quantitatively identify changes in facial semiology in patients with mesial temporal lobe epilepsy (MTLE) from spontaneous expressions during phase I monitoring. A dataset has been collected from the Mater Advanced Epilepsy Unit (Brisbane, Australia) and is used to evaluate our proposed approach. Our experiments show that a landmark-based approach achieves promising results in analyzing facial semiology, where movements can be effectively marked and tracked when there is a frontal face on visualization. However, the region-based counterpart with spatiotemporal features achieves more accurate results when confronted with extreme head positions. A multifold cross-validation of the region-based approach exhibited an average test accuracy of 95.19% and an average AUC of 0.98 of the ROC curve. Conversely, a leave-one-subject-out cross-validation scheme for the same approach reveals a reduction in accuracy for the model as it is affected by data limitations and achieves an average test accuracy of 50.85%. Overall, the proposed deep learning models have shown promise in quantifying ictal facial movements in patients with MTLE. In turn, this may serve to enhance the automated presurgical epilepsy evaluation by allowing for standardization, mitigating bias, and assessing key features. The computer-aided diagnosis may help to support clinical decision-making and prevent erroneous localization and surgery. © 2017 Elsevier Inc.","Convolutional neural network (CNN); Deep learning; Epilepsy evaluation; Facial semiology; Long short-term memory (LSTM); Neuroethology","Australia; Biometric Identification; Diagnosis, Computer-Assisted; Epilepsy; Face; Humans; Male; Movement; Neurologic Examination; Reproducibility of Results; Video Recording; anatomic landmark; Article; Australia; automated pattern recognition; clinical article; computer vision; deep facial analysis; deep learning; drug resistant epilepsy; facial expression; head position; human; machine learning; measurement accuracy; mesial temporal lobe epilepsy; patient monitoring; receiver operating characteristic; stereoelectroencephalography; videorecording; anatomy and histology; biometry; computer assisted diagnosis; epilepsy; face; male; movement (physiology); neurologic examination; pathophysiology; physiology; procedures; reproducibility; standards","Academic Press Inc.","15255050","","EBPEA","29574299","Article","Scopus","2-s2.0-85044121815"
"Badal V.D.; Kundrotas P.J.; Vakser I.A.","Badal, Varsha D. (57224560152); Kundrotas, Petras J. (6701624993); Vakser, Ilya A. (7003854995)","57224560152; 6701624993; 7003854995","Natural language processing in text mining for structural modeling of protein complexes","2018","BMC Bioinformatics","24","10.1186/s12859-018-2079-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043323635&doi=10.1186%2fs12859-018-2079-4&partnerID=40&md5=38ea556f8af7ead717a2b3ab183179e9","The University of Kansas, Center for Computational Biology and Department of Molecular Biosciences, Lawrence, 66047, KS, United States","Badal V.D., The University of Kansas, Center for Computational Biology and Department of Molecular Biosciences, Lawrence, 66047, KS, United States; Kundrotas P.J., The University of Kansas, Center for Computational Biology and Department of Molecular Biosciences, Lawrence, 66047, KS, United States; Vakser I.A., The University of Kansas, Center for Computational Biology and Department of Molecular Biosciences, Lawrence, 66047, KS, United States","Background: Structural modeling of protein-protein interactions produces a large number of putative configurations of the protein complexes. Identification of the near-native models among them is a serious challenge. Publicly available results of biomedical research may provide constraints on the binding mode, which can be essential for the docking. Our text-mining (TM) tool, which extracts binding site residues from the PubMed abstracts, was successfully applied to protein docking (Badal et al., PLoS Comput Biol, 2015; 11: e1004630). Still, many extracted residues were not relevant to the docking. Results: We present an extension of the TM tool, which utilizes natural language processing (NLP) for analyzing the context of the residue occurrence. The procedure was tested using generic and specialized dictionaries. The results showed that the keyword dictionaries designed for identification of protein interactions are not adequate for the TM prediction of the binding mode. However, our dictionary designed to distinguish keywords relevant to the protein binding sites led to considerable improvement in the TM performance. We investigated the utility of several methods of context analysis, based on dissection of the sentence parse trees. The machine learning-based NLP filtered the pool of the mined residues significantly more efficiently than the rule-based NLP. Constraints generated by NLP were tested in docking of unbound proteins from the DOCKGROUND X-ray benchmark set 4. The output of the global low-resolution docking scan was post-processed, separately, by constraints from the basic TM, constraints re-ranked by NLP, and the reference constraints. The quality of a match was assessed by the interface root-mean-square deviation. The results showed significant improvement of the docking output when using the constraints generated by the advanced TM with NLP. Conclusions: The basic TM procedure for extracting protein-protein binding site residues from the PubMed abstracts was significantly advanced by the deep parsing (NLP techniques for contextual analysis) in purging of the initial pool of the extracted residues. Benchmarking showed a substantial increase of the docking success rate based on the constraints generated by the advanced TM with NLP. © 2018 The Author(s).","Binding site prediction; Dependency parser; Protein docking; Protein interactions; Rule-based system; Supervised learning","Data Mining; Machine Learning; Models, Molecular; Natural Language Processing; Protein Binding; Proteins; Semantics; Support Vector Machine; Abstracting; Binding energy; Binding sites; Bins; Biochemistry; Data mining; Knowledge based systems; Learning algorithms; Learning systems; Modeling languages; Proteins; Supervised learning; Syntactics; protein; protein binding; Binding site predictions; Dependency parser; Identification of proteins; Protein docking; Protein interaction; Protein-protein binding; Protein-protein interactions; Root mean square deviations; article; benchmarking; binding site; dissection; human; human experiment; machine learning; Medline; mining; natural language processing; prediction; protein binding; protein interaction; X ray; chemistry; data mining; machine learning; molecular model; semantics; support vector machine; Natural language processing systems","BioMed Central Ltd.","14712105","","BBMIC","29506465","Article","Scopus","2-s2.0-85043323635"
"Yang Y.; Gao J.; Wang J.; Heffernan R.; Hanson J.; Paliwal K.; Zhou Y.","Yang, Yuedong (8439078900); Gao, Jianzhao (36349116400); Wang, Jihua (55742534200); Heffernan, Rhys (56388539300); Hanson, Jack (57194425812); Paliwal, Kuldip (7005281122); Zhou, Yaoqi (7405366766)","8439078900; 36349116400; 55742534200; 56388539300; 57194425812; 7005281122; 7405366766","Sixty-five years of the long march in protein secondary structure prediction: The final stretch?","2018","Briefings in Bioinformatics","174","10.1093/bib/bbw129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041440357&doi=10.1093%2fbib%2fbbw129&partnerID=40&md5=c5551f5b0f0ac7f56524860104a218e0","Institute for Glycomics, Gold Coast Campus, Griffith University, Australia; School of Mathematical Sciences and LPMC, Nankai University, Tianjin, China; Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University, China; Signal Processing Laboratory, Griffith University, Brisbane, Australia; Institute for Glycomics and School of Information and Communication Technology, Gold Coast Campus, Griffith University, Australia; Dezhou University, China","Yang Y., Institute for Glycomics, Gold Coast Campus, Griffith University, Australia; Gao J., School of Mathematical Sciences and LPMC, Nankai University, Tianjin, China; Wang J., Shandong Provincial Key Laboratory of Biophysics, Institute of Biophysics, Dezhou University, China; Heffernan R., Signal Processing Laboratory, Griffith University, Brisbane, Australia; Hanson J., Signal Processing Laboratory, Griffith University, Brisbane, Australia; Paliwal K., Signal Processing Laboratory, Griffith University, Brisbane, Australia; Zhou Y., Institute for Glycomics and School of Information and Communication Technology, Gold Coast Campus, Griffith University, Australia, Dezhou University, China","Protein secondary structure prediction began in 1951 when Pauling and Corey predicted helical and sheet conformations for protein polypeptide backbone even before the first protein structure was determined. Sixty-five years later, powerful new methods breathe new life into this field. The highest three-state accuracy without relying on structure templates is now at 82-84%, a number unthinkable just a few years ago. These improvements came from increasingly larger databases of protein sequences and structures for training, the use of template secondary structure information and more powerful deep learning techniques. As we are approaching to the theoretical limit of three-state prediction (88-90%), alternative to secondary structure prediction (prediction of backbone torsion angles and Ca-atom-based angles and torsion angles) not only has more room for further improvement but also allows direct prediction of three-dimensional fragment structures with constantly improved accuracy. About 20% of all 40-residue fragments in a database of 1199 non-redundant proteins have < 6 A° root-mean-squared distance from the native conformations by SPIDER2. More powerful deep learning methods with improved capability of capturing long-range interactions begin to emerge as the next generation of techniques for secondary structure prediction. The time has come to finish off the final stretch of the long march towards protein secondary structure prediction. © The Author 2017. Published by Oxford University Press. All rights reserved.","Backbone structure prediction; Deep neural networks; Machine learning; Secondary structure prediction; Torsion angle prediction","Algorithms; Computational Biology; Databases, Protein; Humans; Models, Theoretical; Neural Networks (Computer); Protein Structure, Secondary; Proteins; protein; algorithm; artificial neural network; biology; chemistry; human; procedures; protein database; protein secondary structure; theoretical model","Oxford University Press","14675463","","","28040746","Article","Scopus","2-s2.0-85041440357"
"Shin M.; Jang D.; Nam H.; Lee K.H.; Lee D.","Shin, Moonshik (55559899600); Jang, Donjin (57201464646); Nam, Hojung (58254028000); Lee, Kwang Hyung (36071166200); Lee, Doheon (7406661433)","55559899600; 57201464646; 58254028000; 36071166200; 7406661433","Predicting the Absorption Potential of Chemical Compounds Through a Deep Learning Approach","2018","IEEE/ACM Transactions on Computational Biology and Bioinformatics","32","10.1109/TCBB.2016.2535233","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044928925&doi=10.1109%2fTCBB.2016.2535233&partnerID=40&md5=e19f5a7b51d05833f0e4b2c3b8bd0c31","Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, South Korea; School of Information and Communications, Gwangju Institute of Science and Technology (GIST), Gwangju, South Korea","Shin M., Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, South Korea; Jang D., Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, South Korea; Nam H., School of Information and Communications, Gwangju Institute of Science and Technology (GIST), Gwangju, South Korea; Lee K.H., Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, South Korea; Lee D., Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, South Korea","The human colorectal carcinoma cell line (Caco-2) is a commonly used in-vitro test that predicts the absorption potential of orally administered drugs. In-silico prediction methods, based on the Caco-2 assay data, may increase the effectiveness of the high-throughput screening of new drug candidates. However, previously developed in-silico models that predict the Caco-2 cellular permeability of chemical compounds use handcrafted features that may be dataset-specific and induce over-fitting problems. Deep Neural Network (DNN) generates high-level features based on non-linear transformations for raw features, which provides high discriminant power and, therefore, creates a good generalized model. We present a DNN-based binary Caco-2 permeability classifier. Our model was constructed based on 663 chemical compounds with in-vitro Caco-2 apparent permeability data. Two hundred nine molecular descriptors are used for generating the high-level features during DNN model generation. Dropout regularization is applied to solve the over-fitting problem and the non-linear activation. The Rectified Linear Unit (ReLU) is adopted to reduce the vanishing gradient problem. The results demonstrate that the high-level features generated by the DNN are more robust than handcrafted features for predicting the cellular permeability of structurally diverse chemical compounds in Caco-2 cell lines. © 2004-2012 IEEE.","absorption prediction; Caco-2 permeability; deep learning; Machine learning; neural nets","Absorption, Physicochemical; Caco-2 Cells; Cell Membrane Permeability; Computational Biology; Computer Simulation; Deep Learning; Drug Evaluation, Preclinical; Humans; Models, Statistical; Pharmaceutical Preparations; Cell culture; Deep learning; Forecasting; Learning systems; Linear transformations; Mathematical transformations; Neural networks; drug; Apparent permeabilities; Caco-2 permeability; Colorectal carcinoma; High throughput screening; Molecular descriptors; Non-linear activation; Non-linear transformations; Over fitting problem; absorption; biology; Caco-2 cell line; cell membrane permeability; computer simulation; drug effect; human; metabolism; preclinical study; statistical model; Deep neural networks","Institute of Electrical and Electronics Engineers Inc.","15455963","","","26930688","Article","Scopus","2-s2.0-85044928925"
"Li C.; Wang X.; Liu W.; Latecki L.J.","Li, Chao (57193308269); Wang, Xinggang (36100811100); Liu, Wenyu (8043635200); Latecki, Longin Jan (7004123980)","57193308269; 36100811100; 8043635200; 7004123980","DeepMitosis: Mitosis detection via deep detection, verification and segmentation networks","2018","Medical Image Analysis","131","10.1016/j.media.2017.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042188295&doi=10.1016%2fj.media.2017.12.002&partnerID=40&md5=b11e56d54e385690491125e57b2c5297","School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, China; CIS Department, Temple University, Philadelphia, 19122, PA, United States","Li C., School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Wang X., School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Liu W., School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Latecki L.J., CIS Department, Temple University, Philadelphia, 19122, PA, United States","Mitotic count is a critical predictor of tumor aggressiveness in the breast cancer diagnosis. Nowadays mitosis counting is mainly performed by pathologists manually, which is extremely arduous and time-consuming. In this paper, we propose an accurate method for detecting the mitotic cells from histopathological slides using a novel multi-stage deep learning framework. Our method consists of a deep segmentation network for generating mitosis region when only a weak label is given (i.e., only the centroid pixel of mitosis is annotated), an elaborately designed deep detection network for localizing mitosis by using contextual region information, and a deep verification network for improving detection accuracy by removing false positives. We validate the proposed deep learning method on two widely used Mitosis Detection in Breast Cancer Histological Images (MITOSIS) datasets. Experimental results show that we can achieve the highest F-score on the MITOSIS dataset from ICPR 2012 grand challenge merely using the deep detection network. For the ICPR 2014 MITOSIS dataset that only provides the centroid location of mitosis, we employ the segmentation model to estimate the bounding box annotation for training the deep detection network. We also apply the verification model to eliminate some false positives produced from the detection model. By fusing scores of the detection and verification models, we achieve the state-of-the-art results. Moreover, our method is very fast with GPU computing, which makes it feasible for clinical practice. © 2018 Elsevier B.V.","Breast cancer grading; Faster R-CNN; Fully convolutional network; Mitosis detection","Algorithms; Breast Neoplasms; Deep Learning; Female; Humans; Image Processing, Computer-Assisted; Mitosis; Diagnosis; Diseases; Grading; Medical imaging; Breast cancer diagnosis; Breast cancer grading; Convolutional networks; Faster R-CNN; Histological images; Mitosis detections; Segmentation models; Verification networks; analytical parameters; Article; breast cancer; cancer diagnosis; cancer grading; cellular distribution; classifier; clinical practice; diagnostic accuracy; false positive result; histopathology; image segmentation; mitosis; oncological parameters; priority journal; random forest; support vector machine; tumor growth; algorithm; breast tumor; diagnostic imaging; female; human; image processing; pathology; procedures; Deep learning","Elsevier B.V.","13618415","","MIAEC","29455111","Article","Scopus","2-s2.0-85042188295"
"Zeng X.; Leung M.R.; Zeev-Ben-Mordehai T.; Xu M.","Zeng, Xiangrui (57201280726); Leung, Miguel Ricardo (57201271244); Zeev-Ben-Mordehai, Tzviya (6506284098); Xu, Min (57195340740)","57201280726; 57201271244; 6506284098; 57195340740","A convolutional autoencoder approach for mining features in cellular electron cryo-tomograms and weakly supervised coarse segmentation","2018","Journal of Structural Biology","31","10.1016/j.jsb.2017.12.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044113529&doi=10.1016%2fj.jsb.2017.12.015&partnerID=40&md5=8a14c80f0fc6bb5d0d5463af428ed704","Computational Biology Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, 15213, United States; Division of Structural Biology, Wellcome Trust Centre for Human Genetics, University of Oxford, Oxford, OX3 7BN, United Kingdom; Cryo-electron Microscopy, Bijvoet Center for Biomolecular Research, Utrecht University, Utrecht, Netherlands","Zeng X., Computational Biology Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, 15213, United States; Leung M.R., Division of Structural Biology, Wellcome Trust Centre for Human Genetics, University of Oxford, Oxford, OX3 7BN, United Kingdom, Cryo-electron Microscopy, Bijvoet Center for Biomolecular Research, Utrecht University, Utrecht, Netherlands; Zeev-Ben-Mordehai T., Division of Structural Biology, Wellcome Trust Centre for Human Genetics, University of Oxford, Oxford, OX3 7BN, United Kingdom, Cryo-electron Microscopy, Bijvoet Center for Biomolecular Research, Utrecht University, Utrecht, Netherlands; Xu M., Computational Biology Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, 15213, United States","Cellular electron cryo-tomography enables the 3D visualization of cellular organization in the near-native state and at submolecular resolution. However, the contents of cellular tomograms are often complex, making it difficult to automatically isolate different in situ cellular components. In this paper, we propose a convolutional autoencoder-based unsupervised approach to provide a coarse grouping of 3D small subvolumes extracted from tomograms. We demonstrate that the autoencoder can be used for efficient and coarse characterization of features of macromolecular complexes and surfaces, such as membranes. In addition, the autoencoder can be used to detect non-cellular features related to sample preparation and data collection, such as carbon edges from the grid and tomogram boundaries. The autoencoder is also able to detect patterns that may indicate spatial interactions between cellular components. Furthermore, we demonstrate that our autoencoder can be used for weakly supervised semantic segmentation of cellular components, requiring a very small amount of manual annotation. © 2017 Elsevier Inc.","Cellular electron cryo-tomography; Convolutional autoencoder; Convolutional neural network; Deep learning; Image semantic segmentation; Machine learning; Macromolecular complex; Particle picking; Pose normalization; Structural pattern mining; Subtomogram classification; Unsupervised learning; Visual proteomics; Weakly supervised learning","Algorithms; Cryoelectron Microscopy; Image Processing, Computer-Assisted; Macromolecular Substances; Software; animal cell; Article; autoencoder; automation; cell structure; cellular electron cryotomography; controlled study; data analysis; electron tomography; image analysis; image processing; machine learning; membrane; nonhuman; priority journal; semantics; three dimensional imaging; algorithm; chemistry; cryoelectron microscopy; macromolecule; procedures; software","Academic Press Inc.","10478477","","JSBIE","29289599","Article","Scopus","2-s2.0-85044113529"
"Movahedi F.; Coyle J.L.; Sejdic E.","Movahedi, Faezeh (57190248462); Coyle, James L. (8108458200); Sejdic, Ervin (12760262300)","57190248462; 8108458200; 12760262300","Deep belief networks for electroencephalography: A review of recent contributions and future outlooks","2018","IEEE Journal of Biomedical and Health Informatics","83","10.1109/JBHI.2017.2727218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028913822&doi=10.1109%2fJBHI.2017.2727218&partnerID=40&md5=03420630828bcc7899dfd8f2ff1a73d3","Department of Electrical and Computer Engineering, Swanson School of Engineering, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Department of Communication Science and Disorders, School of Health and Rehabilitation Sciences, University of Pittsburgh, Pittsburgh, 15260, PA, United States","Movahedi F., Department of Electrical and Computer Engineering, Swanson School of Engineering, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Coyle J.L., Department of Communication Science and Disorders, School of Health and Rehabilitation Sciences, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Sejdic E., Department of Electrical and Computer Engineering, Swanson School of Engineering, University of Pittsburgh, Pittsburgh, 15260, PA, United States","Deep learning, a relatively new branch of machine learning, has been investigated for use in a variety of biomedical applications. Deep learning algorithms have been used to analyze different physiological signals and gain a better understanding of human physiology for automated diagnosis of abnormal conditions. In this paper, we provide an overview of deep learning approaches with a focus on deep belief networks in electroencephalography applications. We investigate the state-of-the-art algorithms for deep belief networks and then cover the application of these algorithms and their performances in electroencephalographic applications. We covered various applications of electroencephalography in medicine, including emotion recognition, sleep stage classification, and seizure detection, in order to understand how deep learning algorithms could be modified to better suit the tasks desired. This review is intended to provide researchers with a broad overview of the currently existing deep belief network methodology for electroencephalography signals, as well as to highlight potential challenges for future research. © 2013 IEEE.","Classification; deep learning; electroencephalography; machine learning","Deep Learning; Electroencephalography; Humans; Signal Processing, Computer-Assisted; Bayesian networks; Biomedical signal processing; Classification (of information); Electroencephalography; Electrophysiology; Learning algorithms; Learning systems; Medical applications; Abnormal conditions; Automated diagnosis; Biomedical applications; Deep belief networks; Emotion recognition; Physiological signals; Seizure detection; State-of-the-art algorithms; algorithm; Article; artificial neural network; electroencephalography; emotion; human; machine learning; physiology; seizure; signal processing; sleep stage; support vector machine; signal processing; Deep learning","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28715343","Article","Scopus","2-s2.0-85028913822"
"Zheng S.; Jiang M.; Zhao C.; Zhu R.; Hu Z.; Xu Y.; Lin F.","Zheng, Suqing (57201933418); Jiang, Mengying (57202214610); Zhao, Chengwei (57202214652); Zhu, Rui (57202209720); Hu, Zhicheng (57222275318); Xu, Yong (57873276300); Lin, Fu (35332465400)","57201933418; 57202214610; 57202214652; 57202209720; 57222275318; 57873276300; 35332465400","e-Bitter: Bitterant prediction by the consensus voting from the machine-learning methods","2018","Frontiers in Chemistry","38","10.3389/fchem.2018.00082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047466572&doi=10.3389%2ffchem.2018.00082&partnerID=40&md5=5e671e140c067ca719b33c77e7a98a81","School of Pharmaceutical Sciences, Wenzhou Medical University, Wenzhou, China; Chemical Biology Research Center, Wenzhou Medical University, Wenzhou, China; Center of Chemical Biology, Guangzhou Institutes of Biomedicine and Health, Chinese Academy of Sciences, Guangzhou, China","Zheng S., School of Pharmaceutical Sciences, Wenzhou Medical University, Wenzhou, China, Chemical Biology Research Center, Wenzhou Medical University, Wenzhou, China; Jiang M., School of Pharmaceutical Sciences, Wenzhou Medical University, Wenzhou, China; Zhao C., School of Pharmaceutical Sciences, Wenzhou Medical University, Wenzhou, China; Zhu R., School of Pharmaceutical Sciences, Wenzhou Medical University, Wenzhou, China; Hu Z., School of Pharmaceutical Sciences, Wenzhou Medical University, Wenzhou, China; Xu Y., Center of Chemical Biology, Guangzhou Institutes of Biomedicine and Health, Chinese Academy of Sciences, Guangzhou, China; Lin F., School of Pharmaceutical Sciences, Wenzhou Medical University, Wenzhou, China","In-silico bitterant prediction received the considerable attention due to the expensive and laborious experimental-screening of the bitterant. In this work, we collect the fully experimental dataset containing 707 bitterants and 592 non-bitterants, which is distinct from the fully or partially hypothetical non-bitterant dataset used in the previous works. Based on this experimental dataset, we harness the consensus votes from the multiple machine-learning methods (e.g., deep learning etc.) combined with the molecular fingerprint to build the bitter/bitterless classification models with five-fold cross-validation, which are further inspected by the Y-randomization test and applicability domain analysis. One of the best consensus models affords the accuracy, precision, specificity, sensitivity, F1-score, and Matthews correlation coefficient (MCC) of 0.929, 0.918, 0.898, 0.954, 0.936, and 0.856 respectively on our test set. For the automatic prediction of bitterant, a graphic program ""e-Bitter"" is developed for the convenience of users via the simple mouse click. To our best knowledge, it is for the first time to adopt the consensus model for the bitterant prediction and develop the first free stand-alone software for the experimental food scientist. © 2018 Zheng, Jiang, Zhao, Zhu, Hu, Xu and Lin.","Bitter taste; Bitterant prediction; Classification; Machine learning; QSAR; Taste prediction","","Frontiers Media S. A","22962646","","","","Article","Scopus","2-s2.0-85047466572"
"Abidin A.Z.; Deng B.; DSouza A.M.; Nagarajan M.B.; Coan P.; Wismüller A.","Abidin, Anas Z. (56800380800); Deng, Botao (57194468642); DSouza, Adora M. (57073514000); Nagarajan, Mahesh B. (57206208042); Coan, Paola (6701464571); Wismüller, Axel (6603949802)","56800380800; 57194468642; 57073514000; 57206208042; 6701464571; 6603949802","Deep transfer learning for characterizing chondrocyte patterns in phase contrast X-Ray computed tomography images of the human patellar cartilage","2018","Computers in Biology and Medicine","57","10.1016/j.compbiomed.2018.01.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041534979&doi=10.1016%2fj.compbiomed.2018.01.008&partnerID=40&md5=39d7efa7db506cc04eedd6c033e474e9","Department of Biomedical Engineering, University of Rochester Medical Center, Rochester, NY, United States; Department of Imaging Sciences, University of Rochester Medical Center, Rochester, NY, United States; Department of Electrical Engineering, University of Rochester Medical Center, Rochester, NY, United States; Department of Radiological Sciences, University of California Los Angeles, Los Angeles, United States; European Synchrotron Radiation Facility, Grenoble, France; Faculty of Medicine and Institute of Clinical Radiology, Ludwig Maximilians University, Munich, Germany","Abidin A.Z., Department of Biomedical Engineering, University of Rochester Medical Center, Rochester, NY, United States; Deng B., Department of Electrical Engineering, University of Rochester Medical Center, Rochester, NY, United States; DSouza A.M., Department of Electrical Engineering, University of Rochester Medical Center, Rochester, NY, United States; Nagarajan M.B., Department of Radiological Sciences, University of California Los Angeles, Los Angeles, United States; Coan P., European Synchrotron Radiation Facility, Grenoble, France, Faculty of Medicine and Institute of Clinical Radiology, Ludwig Maximilians University, Munich, Germany; Wismüller A., Department of Biomedical Engineering, University of Rochester Medical Center, Rochester, NY, United States, Department of Imaging Sciences, University of Rochester Medical Center, Rochester, NY, United States, Department of Electrical Engineering, University of Rochester Medical Center, Rochester, NY, United States, Faculty of Medicine and Institute of Clinical Radiology, Ludwig Maximilians University, Munich, Germany","Phase contrast X-ray computed tomography (PCI-CT) has been demonstrated to be effective for visualization of the human cartilage matrix at micrometer resolution, thereby capturing osteoarthritis induced changes to chondrocyte organization. This study aims to systematically assess the efficacy of deep transfer learning methods for classifying between healthy and diseased tissue patterns. We extracted features from two different convolutional neural network architectures, CaffeNet and Inception-v3 for characterizing such patterns. These features were quantitatively evaluated in a classification task measured by the area (AUC) under the Receiver Operating Characteristic (ROC) curve as well as qualitative visualization through a dimension reduction approach t-Distributed Stochastic Neighbor Embedding (t-SNE). The best classification performance, for CaffeNet, was observed when using features from the last convolutional layer and the last fully connected layer (AUCs >0.91). Meanwhile, off-the-shelf features from Inception-v3 produced similar classification performance (AUC >0.95). Visualization of features from these layers further confirmed adequate characterization of chondrocyte patterns for reliably distinguishing between healthy and osteoarthritic tissue classes. Such techniques, can be potentially used for detecting the presence of osteoarthritis related changes in the human patellar cartilage. © 2018 Elsevier Ltd","Convolutional neural network; Deep transfer learning; Patellar cartilage; Phase contrast imaging","Cartilage; Chondrocytes; Humans; Machine Learning; Neural Networks (Computer); Osteoarthritis; Patella; Tomography, X-Ray Computed; Body fluids; Cartilage; Classification (of information); Convolution; Deep learning; Network architecture; Neural networks; Stochastic systems; Tissue; Visualization; X rays; Classification performance; Convolutional neural network; Patellar cartilage; Phase-contrast imaging; Receiver Operating Characteristic (ROC) curves; Stochastic neighbor embedding; Transfer learning; Transfer learning methods; Article; articular cartilage; artificial neural network; chondrocyte; contrast enhancement; deep transfer learning; human; image analysis; imaging; osteoarthritis; patella; priority journal; x-ray computed tomography; cartilage; diagnostic imaging; machine learning; osteoarthritis; patella; procedures; x-ray computed tomography; Computerized tomography","Elsevier Ltd","00104825","","CBMDA","29433038","Article","Scopus","2-s2.0-85041534979"
"Chapelais-Baron M.; Goubet I.; Péteri R.; Pereira M.F.; Mignot T.; Jabveneau A.; Rosenfeld E.","Chapelais-Baron, Maylis (57195615577); Goubet, Isabelle (6602443207); Péteri, Renaud (6508075222); Pereira, Maria de Fatima (12773856900); Mignot, T. (7003847319); Jabveneau, Apolline (57201199019); Rosenfeld, Eric (8787485400)","57195615577; 6602443207; 6508075222; 12773856900; 7003847319; 57201199019; 8787485400","Colony analysis and deep learning uncover 5-hydroxyindole as an inhibitor of gliding motility and iridescence in cellulophaga lytica","2018","Microbiology (United Kingdom)","8","10.1099/mic.0.000617","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043756351&doi=10.1099%2fmic.0.000617&partnerID=40&md5=ca0a10aa0cdfe16c71789fecf1d5cf0e","UMR 7266 CNRS- Littoral Environnement et Sociétés, Microbial Physiology Group - Université de La Rochelle, Faculté des Sciences et Technologies, Avenue Michel Crépeau, La Rochelle, 17042, France; Laboratoire Mathématiques, Image et Applications EA 3165, Université de La Rochelle, La Rochelle, France; Université de Caen Normandie, UNICAEN, CERMN - EA 4258, FR CNRS 3038 INC3M, SF 4206 ICORE, Boulevard Becquerel, Caen, F-14032, France; UMR 7283 CNRS Laboratoire de Chimie Bactérienne, Institut de Microbiologie de la Méditerranée, University of Aix-Marseille, Marseille, France","Chapelais-Baron M., UMR 7266 CNRS- Littoral Environnement et Sociétés, Microbial Physiology Group - Université de La Rochelle, Faculté des Sciences et Technologies, Avenue Michel Crépeau, La Rochelle, 17042, France; Goubet I., UMR 7266 CNRS- Littoral Environnement et Sociétés, Microbial Physiology Group - Université de La Rochelle, Faculté des Sciences et Technologies, Avenue Michel Crépeau, La Rochelle, 17042, France; Péteri R., Laboratoire Mathématiques, Image et Applications EA 3165, Université de La Rochelle, La Rochelle, France; Pereira M.F., UMR 7266 CNRS- Littoral Environnement et Sociétés, Microbial Physiology Group - Université de La Rochelle, Faculté des Sciences et Technologies, Avenue Michel Crépeau, La Rochelle, 17042, France, Université de Caen Normandie, UNICAEN, CERMN - EA 4258, FR CNRS 3038 INC3M, SF 4206 ICORE, Boulevard Becquerel, Caen, F-14032, France; Mignot T., UMR 7283 CNRS Laboratoire de Chimie Bactérienne, Institut de Microbiologie de la Méditerranée, University of Aix-Marseille, Marseille, France; Jabveneau A., UMR 7266 CNRS- Littoral Environnement et Sociétés, Microbial Physiology Group - Université de La Rochelle, Faculté des Sciences et Technologies, Avenue Michel Crépeau, La Rochelle, 17042, France; Rosenfeld E., UMR 7266 CNRS- Littoral Environnement et Sociétés, Microbial Physiology Group - Université de La Rochelle, Faculté des Sciences et Technologies, Avenue Michel Crépeau, La Rochelle, 17042, France","Iridescence is an original type of colouration that is relatively widespread in nature but has been either incompletely described or entirely neglected in prokaryotes. Recently, we reported a brilliant ‘pointillistic’ iridescence in agar-grown colony biofilms of Cellulophaga lytica and some other marine Flavobacteria that exhibit gliding motility. Bacterial iridescence is created by a unique self-organization of sub-communities of cells, but the mechanisms underlying such living photonic crystals are unknown. In this study, we used Petri dish assays to screen a large panel of potential activators or inhibitors of C. lytica’s iridescence. Derivatives potentially interfering with quorum-sensing and other communication or biofilm formation processes were tested, as well as metabolic poisons or algal exoproducts. We identified an indole derivative, 5-hydroxyindole (5HI, 250 μM) which inhibited both gliding and iridescence at the colonial level. 5HI did not affect growth or cell respiration. At the microscopic level, phase-contrast imaging confirmed that 5HI inhibits the gliding motility of cells. Moreover, the lack of iridescence correlated with a perturbation of self-organization of the cell sub-communities in both the WT and a glidingnegative mutant. This effect was proved using recent advances in machine learning (deep neuronal networks). In addition to its effect on colony biofilms, 5HI was found to stimulate biofilm formation in microplates. Our data are compatible with possible roles of 5HI or marine analogues in the eco-biology of iridescent bacteria. © 2018 The Authors.","5-hydroxyindole; Cell-to-cell communication; Cellulophaga lytica; Colony biofilm; Deep learning; Gliding motility; Indoles; Iridescence; Machine learning; Marine Flavobacteria; Self-organization","Bacterial Physiological Phenomena; Biofilms; Deep Learning; Flavobacteriaceae; High-Throughput Screening Assays; Indoles; Iridescence; Microbial Interactions; Microscopy, Phase-Contrast; 5 hydroxyindole; 5-hydroxyindole; indole derivative; Article; bacterial cell; bacterial strain; biofilm; cell adhesion; cell growth; cell motility; cell population; Cellulophaga; Cellulophaga lytica; colony formation; controlled study; iridescence; machine learning; microbial biomass; nonhuman; phase contrast microscopy; priority journal; quorum sensing; bacterial phenomena and functions; chemistry; drug effect; Flavobacteriaceae; high throughput screening; iridescence; organismal interaction; physiology","Microbiology Society","13500872","","MROBE","29458680","Article","Scopus","2-s2.0-85043756351"
"Shi J.; Liu Q.; Wang C.; Zhang Q.; Ying S.; Xu H.","Shi, Jun (7404495816); Liu, Qingping (57201911539); Wang, Chaofeng (57196193051); Zhang, Qi (56841055400); Ying, Shihui (24451523300); Xu, Haoyu (56135894000)","7404495816; 57201911539; 57196193051; 56841055400; 24451523300; 56135894000","Super-resolution reconstruction of MR image with a novel residual learning network algorithm","2018","Physics in Medicine and Biology","90","10.1088/1361-6560/aab9e9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046424101&doi=10.1088%2f1361-6560%2faab9e9&partnerID=40&md5=86a6faa4129a169903e72d7c0e6c33d6","Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, 200444, China; School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Department of Mathematics, School of Science, Shanghai University, Shanghai, 200444, China; Shanghai Advanced Research Institute, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shanghai, 201210, China","Shi J., Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, 200444, China, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Liu Q., School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Wang C., School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Zhang Q., Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, 200444, China, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Ying S., Department of Mathematics, School of Science, Shanghai University, Shanghai, 200444, China; Xu H., Shanghai Advanced Research Institute, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shanghai, 201210, China","Spatial resolution is one of the key parameters of magnetic resonance imaging (MRI). The image super-resolution (SR) technique offers an alternative approach to improve the spatial resolution of MRI due to its simplicity. Convolutional neural networks (CNN)-based SR algorithms have achieved state-of-the-art performance, in which the global residual learning (GRL) strategy is now commonly used due to its effectiveness for learning image details for SR. However, the partial loss of image details usually happens in a very deep network due to the degradation problem. In this work, we propose a novel residual learning-based SR algorithm for MRI, which combines both multi-scale GRL and shallow network block-based local residual learning (LRL). The proposed LRL module works effectively in capturing high-frequency details by learning local residuals. One simulated MRI dataset and two real MRI datasets have been used to evaluate our algorithm. The experimental results show that the proposed SR algorithm achieves superior performance to all of the other compared CNN-based SR algorithms in this work. © 2018 Institute of Physics and Engineering in Medicine.","convolutional neural networks; global residual learning; local residual learning; magnetic resonance imaging; super-resolution","Algorithms; Brain; Computer Simulation; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Convolution; Image enhancement; Image reconstruction; Image resolution; Magnetic resonance imaging; Neural networks; Optical resolving power; Convolutional neural network; Convolutional Neural Networks (CNN); global residual learning; local residual learning; Magnetic Resonance Imaging (MRI); State-of-the-art performance; Super resolution; Super resolution reconstruction; algorithm; artificial neural network; brain; computer simulation; diagnostic imaging; human; image processing; machine learning; nuclear magnetic resonance imaging; procedures; Learning algorithms","Institute of Physics Publishing","00319155","","PHMBA","29583134","Article","Scopus","2-s2.0-85046424101"
"Zhou D.; Miao L.; He Y.","Zhou, Deyu (36989177000); Miao, Lei (57201251714); He, Yulan (22985368400)","36989177000; 57201251714; 22985368400","Position-aware deep multi-task learning for drug–drug interaction extraction","2018","Artificial Intelligence in Medicine","59","10.1016/j.artmed.2018.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044025805&doi=10.1016%2fj.artmed.2018.03.001&partnerID=40&md5=c9e78a871ffad8cadf34dc7154b0a4c5","School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, 210096, China; School of Engineering and Applied Science, Aston University, United Kingdom","Zhou D., School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, 210096, China; Miao L., School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, 210096, China; He Y., School of Engineering and Applied Science, Aston University, United Kingdom","Objective: A drug–drug interaction (DDI) is a situation in which a drug affects the activity of another drug synergistically or antagonistically when being administered together. The information of DDIs is crucial for healthcare professionals to prevent adverse drug events. Although some known DDIs can be found in purposely-built databases such as DrugBank, most information is still buried in scientific publications. Therefore, automatically extracting DDIs from biomedical texts is sorely needed. Methods and material: In this paper, we propose a novel position-aware deep multi-task learning approach for extracting DDIs from biomedical texts. In particular, sentences are represented as a sequence of word embeddings and position embeddings. An attention-based bidirectional long short-term memory (BiLSTM) network is used to encode each sentence. The relative position information of words with the target drugs in text is combined with the hidden states of BiLSTM to generate the position-aware attention weights. Moreover, the tasks of predicting whether or not two drugs interact with each other and further distinguishing the types of interactions are learned jointly in multi-task learning framework. Results: The proposed approach has been evaluated on the DDIExtraction challenge 2013 corpus and the results show that with the position-aware attention only, our proposed approach outperforms the state-of-the-art method by 0.99% for binary DDI classification, and with both position-aware attention and multi-task learning, our approach achieves a micro F-score of 72.99% on interaction type identification, outperforming the state-of-the-art approach by 1.51%, which demonstrates the effectiveness of the proposed approach. © 2018 Elsevier B.V.","Classification; Drug–drug interaction extraction; Long short-term memory network; Multi-task learning","Data Mining; Databases, Factual; Deep Learning; Drug Interactions; Drug-Related Side Effects and Adverse Reactions; Brain; Classification (of information); Deep learning; Extraction; Long short-term memory; Health care professionals; Interaction extraction; Methods and materials; Multitask learning; Scientific publications; Short term memory; State-of-the-art approach; State-of-the-art methods; accuracy; analytical error; Article; classifier; data extraction; data processing; drug database; drug drug interaction extraction; human; learning; machine learning; position aware deep multi task learning; priority journal; recall; recurrent neural network; short term memory; adverse drug reaction; data mining; drug interaction; factual database; Drug interactions","Elsevier B.V.","09333657","","AIMEE","29559249","Article","Scopus","2-s2.0-85044025805"
"Heredia-Juesas J.; Thatcher J.E.; Lu Y.; Squiers J.J.; King D.; Fan W.; Dimaio J.M.; Martinez-Lorenzo J.A.","Heredia-Juesas, Juan (56404639500); Thatcher, Jeffrey E. (16305768500); Lu, Yang (56808379600); Squiers, John J. (55759359100); King, Darlene (56527630000); Fan, Wensheng (56527624700); Dimaio, J. Michael (57197833377); Martinez-Lorenzo, Jose A. (24483395900)","56404639500; 16305768500; 56808379600; 55759359100; 56527630000; 56527624700; 57197833377; 24483395900","Burn-injured tissue detection for debridement surgery through the combination of non-invasive optical imaging techniques","2018","Biomedical Optics Express","17","10.1364/BOE.9.001809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044957735&doi=10.1364%2fBOE.9.001809&partnerID=40&md5=d8f4597f8d29ed8e722254e40b8f6ee3","Departments of Electrical and Computer and Mechanical and Industrial Engineering, Northeastern University, Boston, MA, United States; Spectral MD, Inc., Dallas, TX, United States; Baylor Research Institute, Dallas, TX, United States","Heredia-Juesas J., Departments of Electrical and Computer and Mechanical and Industrial Engineering, Northeastern University, Boston, MA, United States; Thatcher J.E., Spectral MD, Inc., Dallas, TX, United States; Lu Y., Spectral MD, Inc., Dallas, TX, United States; Squiers J.J., Spectral MD, Inc., Dallas, TX, United States, Baylor Research Institute, Dallas, TX, United States; King D., Spectral MD, Inc., Dallas, TX, United States; Fan W., Spectral MD, Inc., Dallas, TX, United States; Dimaio J.M., Spectral MD, Inc., Dallas, TX, United States, Baylor Research Institute, Dallas, TX, United States; Martinez-Lorenzo J.A., Departments of Electrical and Computer and Mechanical and Industrial Engineering, Northeastern University, Boston, MA, United States","The process of burn debridement is a challenging technique requiring significant skills to identify the regions that need excision and their appropriate excision depths. In order to assist surgeons, a machine learning tool is being developed to provide a quantitative assessment of burn-injured tissue. This paper presents three non-invasive optical imaging techniques capable of distinguishing four kinds of tissue-healthy skin, viable wound bed, shallow burn, and deep burn-during serial burn debridement in a porcine model. All combinations of these three techniques have been studied through a k-fold cross-validation method. In terms of global performance, the combination of all three techniques significantly improves the classification accuracy with respect to just one technique, from 0.42 up to more than 0.76. Furthermore, a non-linear spatial filtering based on the mode of a small neighborhood has been applied as a post-processing technique, in order to improve the performance of the classification. Using this technique, the global accuracy reaches a value close to 0.78 and, for some particular tissues and combination of techniques, the accuracy improves by 13%. © 2018 Optical Society of America.","","Learning systems; Optical image storage; Classification accuracy; Global performance; K fold cross validations; Optical imaging technique; Porcine models; Post-processing techniques; Quantitative assessments; Spatial filterings; animal experiment; animal model; animal tissue; Article; burn; classification algorithm; controlled study; debridement; filtration; fluorescence imaging; nonhuman; porcine model; tissue characterization; Tissue","OSA - The Optical Society","21567085","","","","Article","Scopus","2-s2.0-85044957735"
"Hu B.; Dixon P.C.; Jacobs J.V.; Dennerlein J.T.; Schiffman J.M.","Hu, B. (55860392700); Dixon, P.C. (35784144900); Jacobs, J.V. (12753651600); Dennerlein, J.T. (7003268401); Schiffman, J.M. (7004585961)","55860392700; 35784144900; 12753651600; 7003268401; 7004585961","Machine learning algorithms based on signals from a single wearable inertial sensor can detect surface- and age-related differences in walking","2018","Journal of Biomechanics","68","10.1016/j.jbiomech.2018.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041955354&doi=10.1016%2fj.jbiomech.2018.01.005&partnerID=40&md5=c894191abef588e3e191259de2bb7654","Department of Environmental Health, Harvard T.H. Chan School of Public Health, United States; Liberty Mutual Research Institute for Safety, United States; Bouvé College of Health Sciences, Northeastern University, United States","Hu B., Department of Environmental Health, Harvard T.H. Chan School of Public Health, United States, Liberty Mutual Research Institute for Safety, United States; Dixon P.C., Department of Environmental Health, Harvard T.H. Chan School of Public Health, United States, Liberty Mutual Research Institute for Safety, United States; Jacobs J.V., Liberty Mutual Research Institute for Safety, United States; Dennerlein J.T., Department of Environmental Health, Harvard T.H. Chan School of Public Health, United States, Bouvé College of Health Sciences, Northeastern University, United States; Schiffman J.M., Liberty Mutual Research Institute for Safety, United States","The aim of this study was to investigate if a machine learning algorithm utilizing triaxial accelerometer, gyroscope, and magnetometer data from an inertial motion unit (IMU) could detect surface- and age-related differences in walking. Seventeen older (71.5 ± 4.2 years) and eighteen young (27.0 ± 4.7 years) healthy adults walked over flat and uneven brick surfaces wearing an inertial measurement unit (IMU) over the L5 vertebra. IMU data were binned into smaller data segments using 4-s sliding windows with 1-s step lengths. Ninety percent of the data were used as training inputs and the remaining ten percent were saved for testing. A deep learning network with long short-term memory units was used for training (fully supervised), prediction, and implementation. Four models were trained using the following inputs: all nine channels from every sensor in the IMU (fully trained model), accelerometer signals alone, gyroscope signals alone, and magnetometer signals alone. The fully trained models for surface and age outperformed all other models (area under the receiver operator curve, AUC = 0.97 and 0.96, respectively; p ≤.045). The fully trained models for surface and age had high accuracy (96.3, 94.7%), precision (96.4, 95.2%), recall (96.3, 94.7%), and f1-score (96.3, 94.6%). These results demonstrate that processing the signals of a single IMU device with machine-learning algorithms enables the detection of surface conditions and age-group status from an individual's walking behavior which, with further learning, may be utilized to facilitate identifying and intervening on fall risk. © 2018 Elsevier Ltd","Ageing; Falls; Gait; Inertial measurement units; Irregular surface; Neural networks","Adult; Age Factors; Aged; Aging; Algorithms; Deep Learning; Female; Fitness Trackers; Humans; Machine Learning; Male; Models, Biological; Motion; Walking; Wearable Electronic Devices; Young Adult; Accelerometers; Artificial intelligence; Deep learning; Gyroscopes; Magnetometers; Neural networks; Walking aids; Wearable sensors; Ageing; Falls; Gait; Inertial measurement unit; Irregular surface; accelerometry; adult; age distribution; aged; Article; controlled study; female; human; human experiment; learning algorithm; long term memory; magnetometry; male; measurement accuracy; measurement precision; normal human; priority journal; recall; receiver operating characteristic; short term memory; single wearable inertial sensor; walking; activity tracker; age; aging; algorithm; biological model; electronic device; machine learning; motion; physiology; young adult; Learning algorithms","Elsevier Ltd","00219290","","JBMCB","29452755","Article","Scopus","2-s2.0-85041955354"
"Yang B.; Duan K.; Fan C.; Hu C.; Wang J.","Yang, Banghua (23391052600); Duan, Kaiwen (57204283542); Fan, Chengcheng (57195677647); Hu, Chenxiao (57201214185); Wang, Jinlong (57201214670)","23391052600; 57204283542; 57195677647; 57201214185; 57201214670","Automatic ocular artifacts removal in EEG using deep learning","2018","Biomedical Signal Processing and Control","93","10.1016/j.bspc.2018.02.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044008781&doi=10.1016%2fj.bspc.2018.02.021&partnerID=40&md5=1cb5d307e1adf9f9479cdf1a13d011c3","Department of Automation, School of Mechatronics Engineering and Automation, Key Laboratory of Power Station Automation Technology, Shanghai University, Shanghai, 200072, China","Yang B., Department of Automation, School of Mechatronics Engineering and Automation, Key Laboratory of Power Station Automation Technology, Shanghai University, Shanghai, 200072, China; Duan K., Department of Automation, School of Mechatronics Engineering and Automation, Key Laboratory of Power Station Automation Technology, Shanghai University, Shanghai, 200072, China; Fan C., Department of Automation, School of Mechatronics Engineering and Automation, Key Laboratory of Power Station Automation Technology, Shanghai University, Shanghai, 200072, China; Hu C., Department of Automation, School of Mechatronics Engineering and Automation, Key Laboratory of Power Station Automation Technology, Shanghai University, Shanghai, 200072, China; Wang J., Department of Automation, School of Mechatronics Engineering and Automation, Key Laboratory of Power Station Automation Technology, Shanghai University, Shanghai, 200072, China","Ocular artifacts (OAs) are one the most important form of interferences in the analysis of electroencephalogram (EEG) research. OAs removal/reduction is a key analysis before the processing of EEG signals. For classic OAs removal methods, either an additional electrooculogram (EOG) recording or multi-channel EEG is required. To address these limitations of existing methods, this paper investigates the use of deep learning network (DLN) to remove OAs in EEG signals. The proposed method consists of offline stage and online stage. In the offline stage, training samples without OAs are intercepted and used to train an DLN to reconstruct the EEG signals. The high-order statistical moments information of EEG is therefore learned. In the online stage, the trained DLN is used as a filter to automatically remove OAs from the contaminated EEG signals. Compared with the exiting methods, the proposed method has the following advantages: (i) nonuse of additional EOG reference signals, (ii) any few number of EEG channels can be analyzed, (iii) time saving, and (iv) the strong generalization ability, etc. In this paper, both public database and lab individual data for EEG analysis are used, we compared the proposed method with the classic independent component analysis (ICA), kurtosis-ICA (K-ICA), Second-order blind identification (SOBI) and a shallow network method. Experimental results show that the proposed method performs better even for very noisy EEG. © 2018 Elsevier Ltd","Deep learning network (DLN); Electroencephalogram (EEG); Independent component analysis (ICA); Ocular artifacts (OAs) removal; Shallow network","Electroencephalography; Independent component analysis; Learning systems; Electro-encephalogram (EEG); Electro-oculogram; Generalization ability; Independent component analysis(ICA); Learning network; Ocular artifacts; Second order blind identifications; Statistical moments; arithmetic; Article; artifact; automation; clinical article; controlled study; correlation coefficient; electroencephalogram; electrooculogram; human; image processing; imagery; independent component analysis; learning algorithm; neurorehabilitation; ocular artifact; online system; priority journal; rehabilitation research; signal processing; standardization; support vector machine; Deep learning","Elsevier Ltd","17468094","","","","Article","Scopus","2-s2.0-85044008781"
"Winkler D.A.","Winkler, David A. (7102950474)","7102950474","Sparse QSAR modelling methods for therapeutic and regenerative medicine","2018","Journal of Computer-Aided Molecular Design","13","10.1007/s10822-018-0106-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042103198&doi=10.1007%2fs10822-018-0106-1&partnerID=40&md5=4dd14d4f91ca09a0d3c9493aba4bb64b","Monash Institute of Pharmaceutical Sciences, Monash University, Parkville, 3052, Australia; La Trobe Institute for Molecular Science, La Trobe University, Kingsbury Drive, Bundoora, 3086, Australia; CSIRO Manufacturing, Bayview Avenue, Clayton, 3168, Australia; School of Pharmacy, University of Nottingham, Nottingham, NG7 2RD, United Kingdom; School of Chemical and Physical Sciences, Flinders University, Bedford Park, 5042, Australia","Winkler D.A., Monash Institute of Pharmaceutical Sciences, Monash University, Parkville, 3052, Australia, La Trobe Institute for Molecular Science, La Trobe University, Kingsbury Drive, Bundoora, 3086, Australia, CSIRO Manufacturing, Bayview Avenue, Clayton, 3168, Australia, School of Pharmacy, University of Nottingham, Nottingham, NG7 2RD, United Kingdom, School of Chemical and Physical Sciences, Flinders University, Bedford Park, 5042, Australia","The quantitative structure–activity relationships method was popularized by Hansch and Fujita over 50 years ago. The usefulness of the method for drug design and development has been shown in the intervening years. As it was developed initially to elucidate which molecular properties modulated the relative potency of putative agrochemicals, and at a time when computing resources were scarce, there is much scope for applying modern mathematical methods to improve the QSAR method and to extending the general concept to the discovery and optimization of bioactive molecules and materials more broadly. I describe research over the past two decades where we have rebuilt the unit operations of the QSAR method using improved mathematical techniques, and have applied this valuable platform technology to new important areas of research and industry such as nanoscience, omics technologies, advanced materials, and regenerative medicine. This paper was presented as the 2017 ACS Herman Skolnik lecture. © 2018, Springer International Publishing AG, part of Springer Nature.","Deep learning; Machine learning; QSAR; Quantitative structure–activity relationships; Regenerative medicine; Skolnik award; Sparse feature selection","Biocompatible Materials; Bone Regeneration; Computers, Molecular; Drug Design; Humans; Machine Learning; Models, Molecular; Molecular Structure; Nanostructures; Prostheses and Implants; Quantitative Structure-Activity Relationship; Regenerative Medicine; Computational chemistry; Deep learning; Industrial research; Regenerative Medicine; cholesterol; messenger RNA; biomaterial; nanomaterial; Deep learning; Features selection; Machine-learning; QSAR; QSAR modeling; Quantitative structure activity relationship; Regenerative medicine; Skolnik award; Sparse feature selection; Sparse features; algorithm; Article; bone growth; chemical structure; drug development; gene expression; human; lipid raft; mathematical model; priority journal; protein expression; protein prenylation; quantitative analysis; quantitative structure activity relation; regenerative medicine; bone regeneration; chemistry; drug design; machine learning; microbiology; molecular computer; molecular model; procedures; prostheses and orthoses; regenerative medicine; Agricultural chemicals","Springer International Publishing","0920654X","","JCADE","29445894","Article","Scopus","2-s2.0-85042103198"
"Munkhdalai T.; Liu F.; Yu H.","Munkhdalai, Tsendsuren (55130596100); Liu, Feifan (8970846700); Yu, Hong (35785447400)","55130596100; 8970846700; 35785447400","Clinical relation extraction toward drug safety surveillance using electronic health record narratives: Classical learning versus deep learning","2018","JMIR Public Health and Surveillance","47","10.2196/publichealth.9361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047745010&doi=10.2196%2fpublichealth.9361&partnerID=40&md5=87a63b184b0517bb394e9b4e00254fe7","Department of Quantitative Health Sciences, University of Massachusetts, Medical School, Worcester, MA, United States; Bedford Veterans Affairs Medical Center, Bedford, MA, United States; Department of Computer Science, University of Massachusetts Lowell, 1 University Ave, Lowell, 01854, MA, United States","Munkhdalai T., Department of Quantitative Health Sciences, University of Massachusetts, Medical School, Worcester, MA, United States; Liu F., Department of Quantitative Health Sciences, University of Massachusetts, Medical School, Worcester, MA, United States; Yu H., Bedford Veterans Affairs Medical Center, Bedford, MA, United States, Department of Computer Science, University of Massachusetts Lowell, 1 University Ave, Lowell, 01854, MA, United States","Background: Medication and adverse drug event (ADE) information extracted from electronic health record (EHR) notes can be a rich resource for drug safety surveillance. Existing observational studies have mainly relied on structured EHR data to obtain ADE information; however, ADEs are often buried in the EHR narratives and not recorded in structured data. Objective: To unlock ADE-related information from EHR narratives, there is a need to extract relevant entities and identify relations among them. In this study, we focus on relation identification. This study aimed to evaluate natural language processing and machine learning approaches using the expert-annotated medical entities and relations in the context of drug safety surveillance, and investigate how different learning approaches perform under different configurations. Methods: We have manually annotated 791 EHR notes with 9 named entities (eg, medication, indication, severity, and ADEs) and 7 different types of relations (eg, medication-dosage, medication-ADE, and severity-ADE). Then, we explored 3 supervised machine learning systems for relation identification: (1) a support vector machines (SVM) system, (2) an end-to-end deep neural network system, and (3) a supervised descriptive rule induction baseline system. For the neural network system, we exploited the state-of-the-art recurrent neural network (RNN) and attention models. We report the performance by macro-averaged precision, recall, and F1-score across the relation types. Results: Our results show that the SVM model achieved the best average F1-score of 89.1% on test data, outperforming the long short-term memory (LSTM) model with attention (F1-score of 65.72%) as well as the rule induction baseline system (F1-score of 7.47%) by a large margin. The bidirectional LSTM model with attention achieved the best performance among different RNN models. With the inclusion of additional features in the LSTM model, its performance can be boosted to an average F1-score of 77.35%. Conclusions: It shows that classical learning models (SVM) remains advantageous over deep learning models (RNN variants) for clinical relation identification, especially for long-distance intersentential relations. However, RNNs demonstrate a great potential of significant improvement if more training data become available. Our work is an important step toward mining EHRs to improve the efficacy of drug safety surveillance. Most importantly, the annotated data used in this study will be made publicly available, which will further promote drug safety research in the community. © Tsendsuren Munkhdalai, Feifan Liu, Hong Yu.","Adverse reactions; Drug-related side effects; Electronic health records; Medical informatics applications; Natural language processing; Neural networks","","","23692960","","","","Article","Scopus","2-s2.0-85047745010"
"Hao W.; Fan J.; Zhang Z.; Zhu G.","Hao, Wangli (55757033100); Fan, Junsong (56401351100); Zhang, Zhaoxiang (8066042700); Zhu, Guibo (56013201400)","55757033100; 56401351100; 8066042700; 56013201400","End-to-End Lifelong Learning: a Framework to Achieve Plasticities of both the Feature and Classifier Constructions","2018","Cognitive Computation","4","10.1007/s12559-017-9514-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030720304&doi=10.1007%2fs12559-017-9514-0&partnerID=40&md5=9b346db63523bcf5e1b5cf6537964563","Institute of Automation, University of Chinese Academy of Sciences (UCAS), Beijing, China; CAS Center for Excellence in Brain Science and Intelligence Technology (CEBSIT), Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences (NLPR, CASIA), Beijing, China","Hao W., Institute of Automation, University of Chinese Academy of Sciences (UCAS), Beijing, China; Fan J., Institute of Automation, University of Chinese Academy of Sciences (UCAS), Beijing, China; Zhang Z., Institute of Automation, University of Chinese Academy of Sciences (UCAS), Beijing, China, CAS Center for Excellence in Brain Science and Intelligence Technology (CEBSIT), Beijing, China, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences (NLPR, CASIA), Beijing, China; Zhu G., Institute of Automation, University of Chinese Academy of Sciences (UCAS), Beijing, China","Plasticity in our brain offers us promising ability to learn and know the world. Although great successes have been achieved in many fields, few bio-inspired machine learning methods have mimicked this ability. Consequently, when meeting large-scale or time-varying data, these bio-inspired methods are infeasible, due to the reasons that they lack plasticity and need all training data loaded into memory. Furthermore, even the popular deep convolutional neural network (CNN) models have relatively fixed structures and cannot process time varying data well. Through incremental methodologies, this paper aims at exploring an end-to-end lifelong learning framework to achieve plasticities of both the feature and classifier constructions. The proposed model mainly comprises of three parts: Gabor filters followed by max pooling layer offering shift and scale tolerance to input samples, incremental unsupervised feature extraction, and incremental SVM trying to achieve plasticities of both the feature learning and classifier construction. Different from CNN, plasticity in our model has no back propogation (BP) process and does not need huge parameters. Our incremental models, including IncPCANet and IncKmeansNet, have achieved better results than PCANet and KmeansNet on minist and Caltech101 datasets respectively. Meanwhile, IncPCANet and IncKmeansNet show promising plasticity of feature extraction and classifier construction when the distribution of data changes. Lots of experiments have validated the performance of our model and verified a physiological hypothesis that plasticity exists in high level layer better than that in low level layer. © 2017, Springer Science+Business Media, LLC.","End-to-end; Incremental KMeansNet; Incremental PCANet; Incremental SVM; Lifelong learning; Plasticity","Deep neural networks; Extraction; Feature extraction; Gabor filters; Learning systems; Neural networks; Physiological models; Plasticity; End to end; Incremental KMeansNet; Incremental PCANet; Incremental SVM; Life long learning; Classification (of information)","Springer New York LLC","18669956","","","","Article","Scopus","2-s2.0-85030720304"
"Gultepe E.; Edward. Conturo T.; Makrehchi M.","Gultepe, Eren (56022415700); Edward. Conturo, Thomas (7004128472); Makrehchi, Masoud (6506351437)","56022415700; 7004128472; 6506351437","Predicting and grouping digitized paintings by style using unsupervised feature learning","2018","Journal of Cultural Heritage","36","10.1016/j.culher.2017.11.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038885920&doi=10.1016%2fj.culher.2017.11.008&partnerID=40&md5=9881b47f020a8e1aab81f4f60cac56b7","Department of Electrical and Computer Engineering, University of Ontario Institute of Technology, 2000 Simcoe St N, Oshawa, L1H 7K4, ON, Canada; Departments of Radiology, Physics, and Biomedical Engineering, Washington University in St. Louis, 4525 Scott Ave, St. Louis, 63110, MO, United States","Gultepe E., Department of Electrical and Computer Engineering, University of Ontario Institute of Technology, 2000 Simcoe St N, Oshawa, L1H 7K4, ON, Canada; Edward. Conturo T., Departments of Radiology, Physics, and Biomedical Engineering, Washington University in St. Louis, 4525 Scott Ave, St. Louis, 63110, MO, United States; Makrehchi M., Department of Electrical and Computer Engineering, University of Ontario Institute of Technology, 2000 Simcoe St N, Oshawa, L1H 7K4, ON, Canada","Objective: To create n system to aid in the analysis of art history by classifying and grouping digitized paintings based on stylistic features automatically learned without prior knowledge. Material and methods: 6,776 digitized paintings from eight different artistic styles (Art Nouveau, Baroque, Expressionism, Impressionism, Realism, Romanticism, Renaissance, and Post-Impressionism) were utilized to classify (predict) and cluster (group) paintings according to style. The method of unsupervised feature learning with K-means (UFLK), inspired by deep learning, was utilized to extract features from the paintings. These features were then used in: a support vector machine algorithm to classify the style of new test paintings based on a training set of paintings having known style labels; and a spectral clustering algorithm to group the paintings into distinct style groups (anonymously, without employing any known style labels). Classification performance was determined by accuracy and F-score. Clustering performance was determined by: the ability to recover the original stylistic groupings (using a cost analysis of all possible combinations of eight group label assignments); F-score; and a reliability analysis. The latter analysis used two novel ways to determine the distribution of the null-hypothesis: a uniform distribution projected onto the principal components of the original data; and a randomized, weighted adjacency matrix. The ability to gain insights into art was tested by a semantic analysis of the clustering results. For this purpose, we represented the featural characteristics of each painting by an N-dimensional feature vector, and plotted the distance between vector endpoints (i.e., similarity between paintings). Then, we color-coded the endpoints with the assigned lowest-cost style labels. The scatter plot was visually inspected for separation of the paintings, where the amount of separation between color clusters provides semantic information on the interrelatedness between styles. Results: The UFLK-extracted features resembled the edges/lines/colors in the paintings. For feature-based classification of paintings, the macro-averaged F-score was 0.469. Classification accuracy and F-score were similar/higher compared to other classification methods using more complex feature learning models (e.g., convolutional neural networks, a supervised algorithm). The clustering via UFLK-extracted features yielded 8 unlabeled style groupings. In six of eight clusters, the most common true painting style matched the cluster style assigned by cost analysis. The clustering had an F-score of 0.212 (no comparison painting clustering method is available at this time). For the semantic analysis, the featural characteristics of Baroque and Art Nouveau were found to be similar, indicating a relationship between these styles. Discussion/conclusion: The UFLK method can extract features from digitised paintings. We were able to extract characteristics of art without any prior information about the nature of the features or the stylistic designation of the paintings. The methods herein may provide art researchers with the latest computational techniques for the documentation, interpretation, and forensics of art. The tools could assist the preservation of culturally sensitive works of art for future generations, and provide new insights into works of art and the artists who created them. © 2017 Elsevier Masson SAS","Art forensics; Classification; Clustering; Painting styles; Unsupervised feature learning","","Elsevier Masson SAS","12962074","","","","Article","Scopus","2-s2.0-85038885920"
"Nguyen D.T.; Pham T.D.; Baek N.R.; Park K.R.","Nguyen, Dat Tien (35608738000); Pham, Tuyen Danh (55808639500); Baek, Na Rae (57196348326); Park, Kang Ryoung (8983316300)","35608738000; 55808639500; 57196348326; 8983316300","Combining deep and handcrafted image features for presentation attack detection in face recognition systems using visible-light camera sensors","2018","Sensors (Switzerland)","81","10.3390/s18030699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042676531&doi=10.3390%2fs18030699&partnerID=40&md5=f102f12411354d436411a611edd93971","Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea","Nguyen D.T., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Pham T.D., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Baek N.R., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Park K.R., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea","Although face recognition systems have wide application, they are vulnerable to presentation attack samples (fake samples). Therefore, a presentation attack detection (PAD) method is required to enhance the security level of face recognition systems. Most of the previously proposed PAD methods for face recognition systems have focused on using handcrafted image features, which are designed by expert knowledge of designers, such as Gabor filter, local binary pattern (LBP), local ternary pattern (LTP), and histogram of oriented gradients (HOG). As a result, the extracted features reflect limited aspects of the problem, yielding a detection accuracy that is low and varies with the characteristics of presentation attack face images. The deep learning method has been developed in the computer vision research community, which is proven to be suitable for automatically training a feature extractor that can be used to enhance the ability of handcrafted features. To overcome the limitations of previously proposed PAD methods, we propose a new PAD method that uses a combination of deep and handcrafted features extracted from the images by visible-light camera sensor. Our proposed method uses the convolutional neural network (CNN) method to extract deep image features and the multi-level local binary pattern (MLBP) method to extract skin detail features from face images to discriminate the real and presentation attack face images. By combining the two types of image features, we form a new type of image features, called hybrid features, which has stronger discrimination ability than single image features. Finally, we use the support vector machine (SVM) method to classify the image features into real or presentation attack class. Our experimental results indicate that our proposed method outperforms previous PAD methods by yielding the smallest error rates on the same image databases. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural network; Face recognition; Multi-level local binary pattern; Presentation attack detection; Visible-light camera sensor","Algorithms; Face; Neural Networks (Computer); Pattern Recognition, Automated; Support Vector Machine; Cameras; Convolution; Deep learning; Feature extraction; Gabor filters; Image processing; Light; Neural networks; Pattern recognition systems; Support vector machines; Attack detection; Camera sensor; Convolutional neural network; Convolutional Neural Networks (CNN); Histogram of oriented gradients (HOG); Local binary pattern (LBP); Local binary patterns; Local ternary patterns (LTP); algorithm; artificial neural network; automated pattern recognition; face; support vector machine; Face recognition","MDPI AG","14248220","","","29495417","Article","Scopus","2-s2.0-85042676531"
"Sun S.; Liu X.","Sun, Shizhao (58428767000); Liu, Xiaoguang (35173130700)","58428767000; 35173130700","EC-DNN: A new method for parallel training of deep neural networks","2018","Neurocomputing","3","10.1016/j.neucom.2018.01.072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041928093&doi=10.1016%2fj.neucom.2018.01.072&partnerID=40&md5=f80cc71016be85b782ed8c774feb249c","College of Computer and Control Engineering, Nankai University, Tianjin, China","Sun S., College of Computer and Control Engineering, Nankai University, Tianjin, China; Liu X., College of Computer and Control Engineering, Nankai University, Tianjin, China","Parallelization framework has become a necessity to speed up the training of deep neural networks (DNN) recently. In the typical parallelization framework, called MA-DNN, the parameters of local models are periodically averaged to get a global model. However, since DNN is a highly non-convex model, averaging parameters cannot ensure that such global model can perform better than those local models. To tackle this problem, we introduce a new parallelization framework, called EC-DNN. In this framework, we propose to aggregate the local models by the simple ensemble, i.e., averaging the outputs of local models instead of the parameters. As most of prevalent loss functions are convex to the output of DNN, the performance of the global model produced by the simple ensemble is guaranteed to be at least as good as the average performance of local models. To get more performance improvement, we extend the simple ensemble to the generalized ensemble, which produces the global model by the weighted sum instead of the average of the outputs of the local models. However, the model size will explode since each round of ensemble can give rise to multiple times size increment. Thus, we carry out model compression after each ensemble to reduce the size of the global model to be the same as the local ones. Our experimental results show that EC-DNN can achieve better speedup than MA-DNN without loss of accuracy, and there is even accuracy improvement sometimes. © 2018 Elsevier B.V.","Deep learning; Distributed machine learning; Parallel machine learning","Artificial intelligence; Deep learning; Learning systems; Accuracy Improvement; Convex modeling; Distributed machine learning; Loss of accuracy; Model compression; Parallel machine; Parallel training; Parallelizations; Article; artificial neural network; controlled study; ensemble compressin deep neural network; intermethod comparison; learning algorithm; mathematical model; measurement accuracy; priority journal; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85041928093"
"Ruano J.; Gómez-García F.; Gay-Mimbrera J.; Aguilar-Luque M.; Fernández-Rueda J.L.; Fernández-Chaichio J.; Alcalde-Mellado P.; Carmona-Fernandez P.J.; Sanz-Cabanillas J.L.; Viguera-Guerra I.; Franco-García F.; Cárdenas-Aranzana M.; Romero J.L.H.; Gonzalez-Padilla M.; Isla-Tejera B.; Garcia-Nieto A.V.","Ruano, Juan (15037115900); Gómez-García, Francisco (57055577600); Gay-Mimbrera, Jesús (57189076196); Aguilar-Luque, Macarena (56544556200); Fernández-Rueda, José Luis (55572127700); Fernández-Chaichio, Jesús (57201119103); Alcalde-Mellado, Patricia (57193903805); Carmona-Fernandez, Pedro J. (56376637900); Sanz-Cabanillas, Juan Luis (57201345901); Viguera-Guerra, Isabel (57201119096); Franco-García, Francisco (57201122902); Cárdenas-Aranzana, Manuel (11241561900); Romero, José Luis Hernández (57200419862); Gonzalez-Padilla, Marcelino (26028851200); Isla-Tejera, Beatriz (11241102500); Garcia-Nieto, Antonio Velez (7004416133)","15037115900; 57055577600; 57189076196; 56544556200; 55572127700; 57201119103; 57193903805; 56376637900; 57201345901; 57201119096; 57201122902; 11241561900; 57200419862; 26028851200; 11241102500; 7004416133","Evaluating characteristics of PROSPERO records as predictors of eventual publication of non-Cochrane systematic reviews: A meta-epidemiological study protocol","2018","Systematic Reviews","12","10.1186/s13643-018-0709-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043460770&doi=10.1186%2fs13643-018-0709-6&partnerID=40&md5=7a9c226db9d04ea31ec689f193c4aa6d","Reina Sofía University Hospital, Department of Dermatology, Menendez Pidal Ave, Córdoba, 14004, Spain; IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Reina Sofía University Hospital, Department of Pharmacy, Menendez Pidal Ave, Córdoba, 14004, Spain; University of Córdoba, School of Medicine, Menendez Pidal Ave, Córdoba, 14004, Spain","Ruano J., Reina Sofía University Hospital, Department of Dermatology, Menendez Pidal Ave, Córdoba, 14004, Spain, IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Gómez-García F., Reina Sofía University Hospital, Department of Dermatology, Menendez Pidal Ave, Córdoba, 14004, Spain, IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Gay-Mimbrera J., IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Aguilar-Luque M., IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Fernández-Rueda J.L., IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Fernández-Chaichio J., IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Alcalde-Mellado P., IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain, University of Córdoba, School of Medicine, Menendez Pidal Ave, Córdoba, 14004, Spain; Carmona-Fernandez P.J., IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Sanz-Cabanillas J.L., Reina Sofía University Hospital, Department of Dermatology, Menendez Pidal Ave, Córdoba, 14004, Spain, IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Viguera-Guerra I., Reina Sofía University Hospital, Department of Pharmacy, Menendez Pidal Ave, Córdoba, 14004, Spain, University of Córdoba, School of Medicine, Menendez Pidal Ave, Córdoba, 14004, Spain; Franco-García F., IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain, Reina Sofía University Hospital, Department of Pharmacy, Menendez Pidal Ave, Córdoba, 14004, Spain; Cárdenas-Aranzana M., Reina Sofía University Hospital, Department of Pharmacy, Menendez Pidal Ave, Córdoba, 14004, Spain; Romero J.L.H., Reina Sofía University Hospital, Department of Dermatology, Menendez Pidal Ave, Córdoba, 14004, Spain, IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Gonzalez-Padilla M., Reina Sofía University Hospital, Department of Dermatology, Menendez Pidal Ave, Córdoba, 14004, Spain, IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain; Isla-Tejera B., IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain, Reina Sofía University Hospital, Department of Pharmacy, Menendez Pidal Ave, Córdoba, 14004, Spain; Garcia-Nieto A.V., Reina Sofía University Hospital, Department of Dermatology, Menendez Pidal Ave, Córdoba, 14004, Spain, IMIBIC/Reina Sofía University Hospital/University of Córdoba, Menendez Pidal Ave, Córdoba, 14004, Spain","Background: Epidemiology and the reporting characteristics of systematic reviews (SRs) and meta-analyses (MAs) are well known. However, no study has analyzed the influence of protocol features on the probability that a study's results will be finally reported, thereby indirectly assessing the reporting bias of International Prospective Register of Systematic Reviews (PROSPERO) registration records. Objective: The objective of this study is to explore which factors are associated with a higher probability that results derived from a non-Cochrane PROSPERO registration record for a systematic review will be finally reported as an original article in a scientific journal. Methods/design: The PROSPERO repository will be web scraped to automatically and iteratively obtain all completed non-Cochrane registration records stored from February 2011 to December 2017. Downloaded records will be screened, and those with less than 90% fulfilled or are duplicated (i.e., those sharing titles and reviewers) will be excluded. Manual and human-supervised automatic methods will be used for data extraction, depending on the data source (fields of PROSPERO registration records, bibliometric databases, etc.). Records will be classified into published, discontinued, and abandoned review subgroups. All articles derived from published reviews will be obtained through multiple parallel searches using the full protocol ""title"" and/or ""list reviewers"" in MEDLINE/PubMed databases and Google Scholar. Reviewer, author, article, and journal metadata will be obtained using different sources. R and Python programming and analysis languages will be used to describe the datasets; perform text mining, machine learning, and deep learning analyses; and visualize the data. We will report the study according to the recommendations for meta-epidemiological studies adapted from the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement for SRs and MAs. Discussion: This meta-epidemiological study will explore, for the first time, characteristics of PROSPERO records that may be associated with the publication of a completed systematic review. The evidence may help to improve review workflow performance in terms of research topic selection, decision-making regarding team selection, planning relationships with funding sources, implementing literature search strategies, and efficient data extraction and analysis. We expect to make our results, datasets, and R and Python code scripts publicly available during the third quarter of 2018. © 2018 The Author(s).","Deep learning; Meta-epidemiology; Predictive models; PROSPERO; Systematic review protocols; Web scraping","Epidemiologic Studies; Humans; Meta-Analysis as Topic; Periodicals as Topic; Publishing; Systematic Reviews as Topic; Article; clinical outcome; decision making; dispersity; human; machine learning; meta analysis (topic); priority journal; publication; quality control; registration; sensitivity and specificity; systematic review; epidemiology; meta analysis (topic); publication; publishing; standards","BioMed Central Ltd.","20464053","","","29523200","Article","Scopus","2-s2.0-85043460770"
"Fritz B.A.; Chen Y.; Murray-Torres T.M.; Gregory S.; Ben Abdallah A.; Kronzer A.; McKinnon S.L.; Budelier T.; Helsten D.L.; Wildes T.S.; Sharma A.; Avidan M.S.","Fritz, Bradley A. (57219190713); Chen, Yixin (57196271259); Murray-Torres, Teresa M. (52663919500); Gregory, Stephen (57192382602); Ben Abdallah, Arbi (55934095800); Kronzer, Alex (57201665833); McKinnon, Sherry Lynn (57188633391); Budelier, Thaddeus (57221183298); Helsten, Daniel L. (55556715600); Wildes, Troy S. (6507296697); Sharma, Anshuman (55358452200); Avidan, Michael Simon (56392715800)","57219190713; 57196271259; 52663919500; 57192382602; 55934095800; 57201665833; 57188633391; 57221183298; 55556715600; 6507296697; 55358452200; 56392715800","Using machine learning techniques to develop forecasting algorithms for postoperative complications: Protocol for a retrospective study","2018","BMJ Open","28","10.1136/bmjopen-2017-020124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050007498&doi=10.1136%2fbmjopen-2017-020124&partnerID=40&md5=efbd2678fcca52567998018908d510e3","Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Department of Computer Science and Engineering, Washington University in St Louis, St Louis, MO, United States","Fritz B.A., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Chen Y., Department of Computer Science and Engineering, Washington University in St Louis, St Louis, MO, United States; Murray-Torres T.M., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Gregory S., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Ben Abdallah A., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Kronzer A., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; McKinnon S.L., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Budelier T., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Helsten D.L., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Wildes T.S., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Sharma A., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States; Avidan M.S., Department of Anesthesiology, Washington University in St Louis, St Louis, MO, United States","Introduction Mortality and morbidity following surgery are pressing public health concerns in the USA. Traditional prediction models for postoperative adverse outcomes demonstrate good discrimination at the population level, but the ability to forecast an individual patient's trajectory in real time remains poor. We propose to apply machine learning techniques to perioperative time-series data to develop algorithms for predicting adverse perioperative outcomes. Methods and analysis This study will include all adult patients who had surgery at our tertiary care hospital over a 4-year period. Patient history, laboratory values, minute-by-minute intraoperative vital signs and medications administered will be extracted from the electronic medical record. Outcomes will include in-hospital mortality, postoperative acute kidney injury and postoperative respiratory failure. Forecasting algorithms for each of these outcomes will be constructed using density-based logistic regression after employing a Nadaraya-Watson kernel density estimator. Time-series variables will be analysed using first and second-order feature extraction, shapelet methods and convolutional neural networks. The algorithms will be validated through measurement of precision and recall. Ethics and dissemination This study has been approved by the Human Research Protection Office at Washington University in St Louis. The successful development of these forecasting algorithms will allow perioperative healthcare clinicians to predict more accurately an individual patient's risk for specific adverse perioperative outcomes in real time. Knowledge of a patient's dynamic risk profile may allow clinicians to make targeted changes in the care plan that will alter the patient's outcome trajectory. This hypothesis will be tested in a future randomised controlled trial. © 2018 Article author(s) (or their employer(s) unless otherwise stated in the text of the article). All rights reserved.","adult anaesthesia; health informatics; information technology","Adult; Algorithms; Humans; Machine Learning; Missouri; Postoperative Complications; Retrospective Studies; acute kidney failure; adult; adult respiratory distress syndrome; adverse outcome; algorithm; Article; artificial neural network; atrial fibrillation; cerebrovascular accident; clinical trial (topic); cohort analysis; daily life activity; data analysis; deep vein thrombosis; electronic medical record; feature extraction; forecasting; heart arrest; heart failure; heart infarction; historical research; hospital mortality; hospital readmission; human; intensive care unit; intraoperative period; intubation; kernel method; laboratory test; lung embolism; machine learning; major clinical study; measurement accuracy; measurement precision; medical history; medical record review; observational study; patient-reported outcome; perioperative period; pneumonia; postoperative complication; postoperative delirium; postoperative nausea and vomiting; postoperative pain; predictive value; preliminary data; product recall; quality of life; respiratory arrest; respiratory failure; retrospective study; return to work; secondary analysis; sepsis; surgical patient; tertiary care center; time series analysis; validation process; venous thromboembolism; vital sign; Missouri; postoperative complication","BMJ Publishing Group","20446055","","","29643160","Article","Scopus","2-s2.0-85050007498"
"Smith K.P.; Kang A.D.; Kirby J.E.","Smith, Kenneth P. (57213077987); Kang, Anthony D. (57193682194); Kirby, James E. (7202383785)","57213077987; 57193682194; 7202383785","Automated interpretation of blood culture gram stains by use of a deep convolutional neural network","2018","Journal of Clinical Microbiology","91","10.1128/JCM.01521-17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042627886&doi=10.1128%2fJCM.01521-17&partnerID=40&md5=65e4b9505d99e48cd77006e70341c047","Department of Pathology, Beth Israel Deaconess Medical Center, Boston, MA, United States; Harvard Medical School, Boston, MA, United States; United States Army Medical Department Center and School, Fort Sam Houston, TX, United States","Smith K.P., Department of Pathology, Beth Israel Deaconess Medical Center, Boston, MA, United States, Harvard Medical School, Boston, MA, United States; Kang A.D., Department of Pathology, Beth Israel Deaconess Medical Center, Boston, MA, United States, Harvard Medical School, Boston, MA, United States, United States Army Medical Department Center and School, Fort Sam Houston, TX, United States; Kirby J.E., Department of Pathology, Beth Israel Deaconess Medical Center, Boston, MA, United States, Harvard Medical School, Boston, MA, United States","Microscopic interpretation of stained smears is one of the most operator-dependent and time-intensive activities in the clinical microbiology laboratory. Here, we investigated application of an automated image acquisition and convolutional neural network (CNN)-based approach for automated Gram stain classification. Using an automated microscopy platform, uncoverslipped slides were scanned with a 40 dry objective, generating images of sufficient resolution for interpretation. We collected 25,488 images from positive blood culture Gram stains prepared during routine clinical workup. These images were used to generate 100,213 crops containing Gram-positive cocci in clusters, Gram-positive cocci in chains/pairs, Gram-negative rods, or background (no cells). These categories were targeted for proof-of-concept development as they are associated with the majority of bloodstream infections. Our CNN model achieved a classification accuracy of 94.9% on a test set of image crops. Receiver operating characteristic (ROC) curve analysis indicated a robust ability to differentiate between categories with an area under the curve of 0.98 for each. After training and validation, we applied the classification algorithm to new images collected from 189 whole slides without human intervention. Sensitivity and specificity were 98.4% and 75.0% for Gram-positive cocci in chains and pairs, 93.2% and 97.2% for Gram-positive cocci in clusters, and 96.3% and 98.1% for Gram-negative rods. Taken together, our data support a proof of concept for a fully automated classification methodology for blood-culture Gram stains. Importantly, the algorithm was highly adept at identifying image crops with organisms and could be used to present prescreened, classified crops to technologists to accelerate smear review. This concept could potentially be extended to all Gram stain interpretive activities in the clinical laboratory. Copyright © 2018 American Society for Microbiology. All Rights Reserved.","Analytics; Artificial intelligence; Automated microscopy; Big data; Blood culture; Deep learning; Gram stain; Machine learning; Neural network","Algorithms; Automation, Laboratory; Big Data; Blood Culture; Deep Learning; Gentian Violet; Humans; Image Interpretation, Computer-Assisted; Microscopy; Neural Networks (Computer); Phenazines; Reproducibility of Results; Sensitivity and Specificity; crystal violet; Gram's stain; phenazine derivative; Article; artificial neural network; automation; blood culture; bloodstream infection; classification algorithm; controlled study; deep convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; disease association; Gram negative bacterium; Gram positive cocci; Gram staining; image analysis; image processing; microscopy; nonhuman; priority journal; receiver operating characteristic; validation study; algorithm; computer assisted diagnosis; human; laboratory automation; procedures; reproducibility; sensitivity and specificity","American Society for Microbiology","00951137","","JCMID","29187563","Article","Scopus","2-s2.0-85042627886"
"Cheng P.M.; Tejura T.K.; Tran K.N.; Whang G.","Cheng, Phillip M. (8693313300); Tejura, Tapas K. (36024259000); Tran, Khoa N. (57197122575); Whang, Gilbert (35304081500)","8693313300; 36024259000; 57197122575; 35304081500","Detection of high-grade small bowel obstruction on conventional radiography with convolutional neural networks","2018","Abdominal Radiology","31","10.1007/s00261-017-1294-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027975920&doi=10.1007%2fs00261-017-1294-1&partnerID=40&md5=14e605f7ff572a6981ba3c2882059db5","Department of Radiology, USC Norris Comprehensive Cancer Center, Keck School of Medicine of USC, 1441 Eastlake Avenue, Suite 2315B, Los Angeles, 90033-0377, CA, United States","Cheng P.M., Department of Radiology, USC Norris Comprehensive Cancer Center, Keck School of Medicine of USC, 1441 Eastlake Avenue, Suite 2315B, Los Angeles, 90033-0377, CA, United States; Tejura T.K., Department of Radiology, USC Norris Comprehensive Cancer Center, Keck School of Medicine of USC, 1441 Eastlake Avenue, Suite 2315B, Los Angeles, 90033-0377, CA, United States; Tran K.N., Department of Radiology, USC Norris Comprehensive Cancer Center, Keck School of Medicine of USC, 1441 Eastlake Avenue, Suite 2315B, Los Angeles, 90033-0377, CA, United States; Whang G., Department of Radiology, USC Norris Comprehensive Cancer Center, Keck School of Medicine of USC, 1441 Eastlake Avenue, Suite 2315B, Los Angeles, 90033-0377, CA, United States","The purpose of this pilot study is to determine whether a deep convolutional neural network can be trained with limited image data to detect high-grade small bowel obstruction patterns on supine abdominal radiographs. Grayscale images from 3663 clinical supine abdominal radiographs were categorized into obstructive and non-obstructive categories independently by three abdominal radiologists, and the majority classification was used as ground truth; 74 images were found to be consistent with small bowel obstruction. Images were rescaled and randomized, with 2210 images constituting the training set (39 with small bowel obstruction) and 1453 images constituting the test set (35 with small bowel obstruction). Weight parameters for the final classification layer of the Inception v3 convolutional neural network, previously trained on the 2014 Large Scale Visual Recognition Challenge dataset, were retrained on the training set. After training, the neural network achieved an AUC of 0.84 on the test set (95% CI 0.78–0.89). At the maximum Youden index (sensitivity + specificity−1), the sensitivity of the system for small bowel obstruction is 83.8%, with a specificity of 68.1%. The results demonstrate that transfer learning with convolutional neural networks, even with limited training data, may be used to train a detector for high-grade small bowel obstruction gas patterns on supine radiographs. © 2017, Springer Science+Business Media, LLC.","Artificial neural networks; Deep learning; Digital image processing; Machine learning; Small bowel obstruction","Adolescent; Adult; Aged; Aged, 80 and over; Female; Humans; Image Interpretation, Computer-Assisted; Intestinal Obstruction; Intestine, Small; Male; Middle Aged; Neural Networks (Computer); Pilot Projects; Radiography; Sensitivity and Specificity; Young Adult; abdominal radiography; adult; aged; Article; artificial neural network; controlled study; digital imaging and communications in medicine; false positive result; female; human; ileus; image processing; interrater reliability; major clinical study; male; pilot study; priority journal; radiologist; retrospective study; small intestine obstruction; very elderly; Youden index; adolescent; computer assisted diagnosis; diagnostic imaging; intestine obstruction; middle aged; procedures; radiography; sensitivity and specificity; small intestine; young adult","Springer New York LLC","2366004X","","","28828625","Article","Scopus","2-s2.0-85027975920"
"Schlegl T.; Waldstein S.M.; Bogunovic H.; Endstraßer F.; Sadeghipour A.; Philip A.-M.; Podkowinski D.; Gerendas B.S.; Langs G.; Schmidt-Erfurth U.","Schlegl, Thomas (6601911639); Waldstein, Sebastian M. (54396573100); Bogunovic, Hrvoje (9269313300); Endstraßer, Franz (57201403494); Sadeghipour, Amir (57194170951); Philip, Ana-Maria (57090003700); Podkowinski, Dominika (56554237200); Gerendas, Bianca S. (44961113000); Langs, Georg (56954737000); Schmidt-Erfurth, Ursula (7006949003)","6601911639; 54396573100; 9269313300; 57201403494; 57194170951; 57090003700; 56554237200; 44961113000; 56954737000; 7006949003","Fully Automated Detection and Quantification of Macular Fluid in OCT Using Deep Learning","2018","Ophthalmology","383","10.1016/j.ophtha.2017.10.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044656432&doi=10.1016%2fj.ophtha.2017.10.031&partnerID=40&md5=165c07aa6023917be0bec2e769856245","Christian Doppler Laboratory for Ophthalmic Image Analysis, Department of Ophthalmology, Medical University Vienna, Vienna, Austria; Department of Ophthalmology, Medical University of Vienna, Vienna, Austria; Vienna Reading Center, Department of Ophthalmology, Medical University of Vienna, Vienna, Austria; Computational Imaging Research Lab Department of Biomedical Imaging and Image-Guided Therapy, Medical University Vienna, Vienna, Austria","Schlegl T., Christian Doppler Laboratory for Ophthalmic Image Analysis, Department of Ophthalmology, Medical University Vienna, Vienna, Austria, Computational Imaging Research Lab Department of Biomedical Imaging and Image-Guided Therapy, Medical University Vienna, Vienna, Austria; Waldstein S.M., Department of Ophthalmology, Medical University of Vienna, Vienna, Austria; Bogunovic H., Christian Doppler Laboratory for Ophthalmic Image Analysis, Department of Ophthalmology, Medical University Vienna, Vienna, Austria; Endstraßer F., Christian Doppler Laboratory for Ophthalmic Image Analysis, Department of Ophthalmology, Medical University Vienna, Vienna, Austria; Sadeghipour A., Christian Doppler Laboratory for Ophthalmic Image Analysis, Department of Ophthalmology, Medical University Vienna, Vienna, Austria; Philip A.-M., Vienna Reading Center, Department of Ophthalmology, Medical University of Vienna, Vienna, Austria; Podkowinski D., Vienna Reading Center, Department of Ophthalmology, Medical University of Vienna, Vienna, Austria; Gerendas B.S., Department of Ophthalmology, Medical University of Vienna, Vienna, Austria; Langs G., Computational Imaging Research Lab Department of Biomedical Imaging and Image-Guided Therapy, Medical University Vienna, Vienna, Austria; Schmidt-Erfurth U., Christian Doppler Laboratory for Ophthalmic Image Analysis, Department of Ophthalmology, Medical University Vienna, Vienna, Austria, Department of Ophthalmology, Medical University of Vienna, Vienna, Austria","Purpose: Development and validation of a fully automated method to detect and quantify macular fluid in conventional OCT images. Design: Development of a diagnostic modality. Participants: The clinical dataset for fluid detection consisted of 1200 OCT volumes of patients with neovascular age-related macular degeneration (AMD, n = 400), diabetic macular edema (DME, n = 400), or retinal vein occlusion (RVO, n = 400) acquired with Zeiss Cirrus (Carl Zeiss Meditec, Dublin, CA) (n = 600) or Heidelberg Spectralis (Heidelberg Engineering, Heidelberg, Germany) (n = 600) OCT devices. Methods: A method based on deep learning to automatically detect and quantify intraretinal cystoid fluid (IRC) and subretinal fluid (SRF) was developed. The performance of the algorithm in accurately identifying fluid localization and extent was evaluated against a manual consensus reading of 2 masked reading center graders. Main Outcome Measures: Performance of a fully automated method to accurately detect, differentiate, and quantify intraretinal and SRF using area under the receiver operating characteristics curves, precision, and recall. Results: The newly designed, fully automated diagnostic method based on deep learning achieved optimal accuracy for the detection and quantification of IRC for all 3 macular pathologies with a mean accuracy (AUC) of 0.94 (range, 0.91–0.97), a mean precision of 0.91, and a mean recall of 0.84. The detection and measurement of SRF were also highly accurate with an AUC of 0.92 (range, 0.86–0.98), a mean precision of 0.61, and a mean recall of 0.81, with superior performance in neovascular AMD and RVO compared with DME, which was represented rarely in the population studied. High linear correlation was confirmed between automated and manual fluid localization and quantification, yielding an average Pearson's correlation coefficient of 0.90 for IRC and of 0.96 for SRF. Conclusions: Deep learning in retinal image analysis achieves excellent accuracy for the differential detection of retinal fluid types across the most prevalent exudative macular diseases and OCT devices. Furthermore, quantification of fluid achieves a high level of concordance with manual expert assessment. Fully automated analysis of retinal OCT images from clinical routine provides a promising horizon in improving accuracy and reliability of retinal diagnosis for research and clinical practice in ophthalmology. © 2017 American Academy of Ophthalmology","","Aged; Deep Learning; Diabetic Retinopathy; Diagnosis, Computer-Assisted; Female; Humans; Macular Edema; Male; Middle Aged; Reproducibility of Results; Retinal Vein Occlusion; ROC Curve; Subretinal Fluid; Tomography, Optical Coherence; Visual Acuity; Wet Macular Degeneration; area under the curve; Article; controlled study; deep learning; diabetic macular edema; diagnostic accuracy; diagnostic test accuracy study; human; learning algorithm; machine learning; major clinical study; optical coherence tomography; priority journal; recall; receiver operating characteristic; retina image; retina vein occlusion; subretinal fluid; wet macular degeneration; aged; comparative study; computer assisted diagnosis; diabetic retinopathy; diagnostic imaging; female; macular edema; male; middle aged; optical coherence tomography; procedures; reproducibility; retina vein occlusion; validation study; visual acuity; wet macular degeneration","Elsevier Inc.","01616420","","OPHTD","29224926","Article","Scopus","2-s2.0-85044656432"
"daSilva L.F.; Beckedorff F.C.; Ayupe A.C.; Amaral M.S.; Mesel V.; Videira A.; Reis E.M.; Setubal J.C.; Verjovski-Almeida S.","daSilva, Lucas F. (57191094223); Beckedorff, Felipe C. (22984206500); Ayupe, Ana C. (55890425100); Amaral, Murilo S. (42860976200); Mesel, Vinícius (57201775071); Videira, Alexandre (57188562646); Reis, Eduardo M. (57217776306); Setubal, João C. (6602400333); Verjovski-Almeida, Sergio (7003523848)","57191094223; 22984206500; 55890425100; 42860976200; 57201775071; 57188562646; 57217776306; 6602400333; 7003523848","Chromatin landscape distinguishes the genomic loci of hundreds of androgen-receptor-associated lincRNAs from the loci of non-associated lincRNAs","2018","Frontiers in Genetics","9","10.3389/fgene.2018.00132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046073952&doi=10.3389%2ffgene.2018.00132&partnerID=40&md5=112e43327c5eeac65e557b7b33e657ff","Departamento de Bioquímica, Instituto de Química, Universidade de São Paulo, São Paulo, Brazil; Laboratório de Expressão Gênica em Eucariotos, Instituto Butantan, São Paulo, Brazil; Biocomplexity Institute of Virginia Tech, Blacksburg, VA, United States","daSilva L.F., Departamento de Bioquímica, Instituto de Química, Universidade de São Paulo, São Paulo, Brazil, Laboratório de Expressão Gênica em Eucariotos, Instituto Butantan, São Paulo, Brazil; Beckedorff F.C., Departamento de Bioquímica, Instituto de Química, Universidade de São Paulo, São Paulo, Brazil, Laboratório de Expressão Gênica em Eucariotos, Instituto Butantan, São Paulo, Brazil; Ayupe A.C., Departamento de Bioquímica, Instituto de Química, Universidade de São Paulo, São Paulo, Brazil; Amaral M.S., Departamento de Bioquímica, Instituto de Química, Universidade de São Paulo, São Paulo, Brazil, Laboratório de Expressão Gênica em Eucariotos, Instituto Butantan, São Paulo, Brazil; Mesel V., Laboratório de Expressão Gênica em Eucariotos, Instituto Butantan, São Paulo, Brazil; Videira A., Departamento de Bioquímica, Instituto de Química, Universidade de São Paulo, São Paulo, Brazil, Laboratório de Expressão Gênica em Eucariotos, Instituto Butantan, São Paulo, Brazil; Reis E.M., Departamento de Bioquímica, Instituto de Química, Universidade de São Paulo, São Paulo, Brazil; Setubal J.C., Departamento de Bioquímica, Instituto de Química, Universidade de São Paulo, São Paulo, Brazil, Biocomplexity Institute of Virginia Tech, Blacksburg, VA, United States; Verjovski-Almeida S., Departamento de Bioquímica, Instituto de Química, Universidade de São Paulo, São Paulo, Brazil, Laboratório de Expressão Gênica em Eucariotos, Instituto Butantan, São Paulo, Brazil","Cell signaling events triggered by androgen hormone in prostate cells is dependent on activation of the androgen receptor (AR) transcription factor. Androgen hormone binding to AR promotes its displacement from the cytoplasm to the nucleus and AR binding to DNA motifs, thus inducing activatory and inhibitory transcriptional programs through a complex regulatory mechanism not yet fully understood. In this work, we performed RNA-seq deep-sequencing of LNCaP prostate cancer cells and found over 7000 expressed long intergenic non-coding RNAs (lincRNAs), of which ~4000 are novel lincRNAs, and 258 lincRNAs have their expression activated by androgen. Immunoprecipitation of AR, followed by large-scale sequencing of co-immunoprecipitated RNAs (RIP-Seq) has identified in the LNCaP cell line a total of 619 lincRNAs that were significantly enriched (FDR < 10%, DESeq2) in the anti-Androgen Receptor (antiAR) fraction in relation to the control fraction (non-specific IgG), and we named them Androgen-Receptor-Associated lincRNAs (ARA-lincRNAs). A genome-wide analysis showed that protein-coding gene neighbors to ARA-lincRNAs had a significantly higher androgen-induced change in expression than protein-coding genes neighboring lincRNAs not associated to AR. To find relevant epigenetic signatures enriched at the ARA-lincRNAs' transcription start sites (TSSs) we used a machine learning approach and identified that the ARA-lincRNA genomic loci in LNCaP cells are significantly enriched with epigenetic marks that are characteristic of in cis enhancer RNA regulators, and that the H3K27ac mark of active enhancers is conspicuously enriched at the TSS of ARA-lincRNAs adjacent to androgen-activated protein-coding genes. In addition, LNCaP topologically associating domains (TADs) that comprise chromatin regions with ARA-lincRNAs exhibit transcription factor contents, epigenetic marks and gene transcriptional activities that are significantly different from TADs not containing ARA-lincRNAs. This work highlights the possible involvement of hundreds of lincRNAs working in synergy with the AR on the genome-wide androgen-induced gene regulatory program in prostate cells. © 2018 daSilva, Beckedorff, Ayupe, Amaral, Mesel, Videira, Reis, Setubal and Verjovski-Almeida.","Androgen receptor; Androgen receptor associated lincRNAs; Epigenetic marks; Genome-wide profiling; LNCaP prostate cancer cell line; Long intergenic non-coding RNAs; Machine learning; Random forest algorithm","androgen; androgen receptor; histone H3; long untranslated RNA; RNA binding protein; transcription factor; Article; chromatin structure; controlled study; down regulation; gene expression; gene interaction; gene locus; gene regulatory network; genetic association; human; human cell; immunoprecipitation; male; next generation sequencing; prostate cancer; real time polymerase chain reaction; RNA analysis; RNA extraction; RNA sequence; transcription initiation site; upregulation","Frontiers Media S.A.","16648021","","","","Article","Scopus","2-s2.0-85046073952"
"Yang S.J.; Berndl M.; Ando D.M.; Barch M.; Narayanaswamy A.; Christiansen E.; Hoyer S.; Roat C.; Hung J.; Rueden C.T.; Shankar A.; Finkbeiner S.; Nelson P.","Yang, Samuel J. (56709026600); Berndl, Marc (7801530630); Ando, D. Michael (55016305000); Barch, Mariya (55407561600); Narayanaswamy, Arunachalam (24559185300); Christiansen, Eric (57201199072); Hoyer, Stephan (57201197294); Roat, Chris (57200207600); Hung, Jane (57191886560); Rueden, Curtis T. (6506429492); Shankar, Asim (56896844000); Finkbeiner, Steven (7004508339); Nelson, Philip (57192712992)","56709026600; 7801530630; 55016305000; 55407561600; 24559185300; 57201199072; 57201197294; 57200207600; 57191886560; 6506429492; 56896844000; 7004508339; 57192712992","Assessing microscope image focus quality with deep learning","2018","BMC Bioinformatics","102","10.1186/s12859-018-2087-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043760273&doi=10.1186%2fs12859-018-2087-4&partnerID=40&md5=5461c363406d003a649e783a131f3780","Google Inc, Mountain View, CA, United States; Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone, United States; Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Massachusetts Institute of Technology (MIT), Department of Chemical Engineering, Cambridge, MA, United States; University of Wisconsin at Madison, Laboratory for Optical and Computational Instrumentation, Madison, WI, United States; University of California, San Francisco, Departments of Neurology and Physiology, CA, United States","Yang S.J., Google Inc, Mountain View, CA, United States; Berndl M., Google Inc, Mountain View, CA, United States; Ando D.M., Google Inc, Mountain View, CA, United States; Barch M., Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone, United States; Narayanaswamy A., Google Inc, Mountain View, CA, United States; Christiansen E., Google Inc, Mountain View, CA, United States; Hoyer S., Google Inc, Mountain View, CA, United States; Roat C., Google Inc, Mountain View, CA, United States; Hung J., Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, MA, United States, Massachusetts Institute of Technology (MIT), Department of Chemical Engineering, Cambridge, MA, United States; Rueden C.T., University of Wisconsin at Madison, Laboratory for Optical and Computational Instrumentation, Madison, WI, United States; Shankar A., Google Inc, Mountain View, CA, United States; Finkbeiner S., Taube/Koret Center for Neurodegenerative Disease Research and DaedalusBio, Gladstone, United States, University of California, San Francisco, Departments of Neurology and Physiology, CA, United States; Nelson P., Google Inc, Mountain View, CA, United States","Background: Large image datasets acquired on automated microscopes typically have some fraction of low quality, out-of-focus images, despite the use of hardware autofocus systems. Identification of these images using automated image analysis with high accuracy is important for obtaining a clean, unbiased image dataset. Complicating this task is the fact that image focus quality is only well-defined in foreground regions of images, and as a result, most previous approaches only enable a computation of the relative difference in quality between two or more images, rather than an absolute measure of quality. Results: We present a deep neural network model capable of predicting an absolute measure of image focus on a single image in isolation, without any user-specified parameters. The model operates at the image-patch level, and also outputs a measure of prediction certainty, enabling interpretable predictions. The model was trained on only 384 in-focus Hoechst (nuclei) stain images of U2OS cells, which were synthetically defocused to one of 11 absolute defocus levels during training. The trained model can generalize on previously unseen real Hoechst stain images, identifying the absolute image focus to within one defocus level (approximately 3 pixel blur diameter difference) with 95% accuracy. On a simpler binary in/out-of-focus classification task, the trained model outperforms previous approaches on both Hoechst and Phalloidin (actin) stain images (F-scores of 0.89 and 0.86, respectively over 0.84 and 0.83), despite only having been presented Hoechst stain images during training. Lastly, we observe qualitatively that the model generalizes to two additional stains, Hoechst and Tubulin, of an unseen cell type (Human MCF-7) acquired on a different instrument. Conclusions: Our deep neural network enables classification of out-of-focus microscope images with both higher accuracy and greater precision than previous approaches via interpretable patch-level focus and certainty predictions. The use of synthetically defocused images precludes the need for a manually annotated training dataset. The model also generalizes to different image and cell types. The framework for model training and image prediction is available as a free software library and the pre-trained model is available for immediate use in Fiji (ImageJ) and CellProfiler. © 2018 The Author(s).","CellProfiler; Deep learning; Defocus; Focus; Image analysis; Image quality; ImageJ; Machine learning; Open-source","Bone Neoplasms; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Microscopy; Osteosarcoma; Software; Tumor Cells, Cultured; Deep learning; Deep neural networks; Focusing; Forecasting; Image analysis; Learning systems; Microscopes; Open source software; Proteins; Quality control; Automated image analysis; Automated microscope; CellProfiler; Classification tasks; Defocus; ImageJ; Neural network model; Open sources; bone tumor; diagnostic imaging; human; image processing; machine learning; microscopy; osteosarcoma; procedures; software; tumor cell culture; Image quality","BioMed Central Ltd.","14712105","","BBMIC","29540156","Article","Scopus","2-s2.0-85043760273"
"Saussele S.; Hehlmann R.; Fabarius A.; Jeromin S.; Proetel U.; Rinaldetti S.; Kohlbrenner K.; Einsele H.; Falge C.; Kanz L.; Neubauer A.; Kneba M.; Stegelmann F.; Pfreundschuh M.; Waller C.F.; Oppliger Leibundgut E.; Heim D.; Krause S.W.; Hofmann W.-K.; Hasford J.; Pfirrmann M.; Müller M.C.; Hochhaus A.; Lauseker M.","Saussele, Susanne (6602678316); Hehlmann, Rüdiger (55402002100); Fabarius, Alice (6507389920); Jeromin, Sabine (54418875100); Proetel, Ulrike (45761486200); Rinaldetti, Sebastien (56544657100); Kohlbrenner, Katharina (57196317811); Einsele, Hermann (26643371100); Falge, Christiane (6603089524); Kanz, Lothar (55110593500); Neubauer, Andreas (7102006569); Kneba, Michael (56881749300); Stegelmann, Frank (23996220300); Pfreundschuh, Michael (7101744196); Waller, Cornelius F. (7006001726); Oppliger Leibundgut, Elisabeth (6602225301); Heim, Dominik (7006620847); Krause, Stefan W. (57223624060); Hofmann, Wolf-Karsten (35242508900); Hasford, Joerg (7004911145); Pfirrmann, Markus (6602356605); Müller, Martin C. (14626732300); Hochhaus, Andreas (35406412600); Lauseker, Michael (35177765100)","6602678316; 55402002100; 6507389920; 54418875100; 45761486200; 56544657100; 57196317811; 26643371100; 6603089524; 55110593500; 7102006569; 56881749300; 23996220300; 7101744196; 7006001726; 6602225301; 7006620847; 57223624060; 35242508900; 7004911145; 6602356605; 14626732300; 35406412600; 35177765100","Defining therapy goals for major molecular remission in chronic myeloid leukemia: Results of the randomized CML Study IV","2018","Leukemia","22","10.1038/s41375-018-0055-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042542477&doi=10.1038%2fs41375-018-0055-7&partnerID=40&md5=50209a00b80268efb6161f8362c47dab","III. Medizinische Klinik, Universitätsmedizin Mannheim, Universität Heidelberg, Mannheim, Germany; MLL Münchner Leukämielabor, München, Germany; Medizinische Klinik II, Universitätsklinikum, Würzburg, Germany; Medizinische Klinik 5, Klinikum Nord, Nürnberg, Germany; Innere Medizin II, Universitätsklinikum, Tübingen, Germany; Klinik für Hämatologie, Zentrum Innere Medizin, Philipps-Universität, Marburg, Germany; II. Medizinische Klinik und Poliklinik im SKK, Universitätsklinikum Schleswig-Holstein, Kiel, Germany; Klinik für Innere Medizin III, Universitätsklinikum, Ulm, Germany; Klinik für Innere Medizin i, Universitätsklinikum des Saarlandes, Homburg/Saar, Germany; Klinik für Innere Medizin i, Universitätsklinikum, Freiburg, Germany; Universitätsklinik für Hämatologie und Hämatologisches Zentrallabor, Inselspital, Bern, Switzerland; Klinik für Hämatologie, Universitätsspital, Basel, Switzerland; Medizinische Klinik 5, Universitätsklinikum, Erlangen, Germany; Institut für Medizinische Informationsverarbeitung, Biometrie und Epidemiologie, Ludwig-Maximilians-Universität, München, Germany; Klinik für Innere Medizin II, Abt. Hämatologie und Intern. Onkologie, Universitätsklinikum, Jena, Germany","Saussele S., III. Medizinische Klinik, Universitätsmedizin Mannheim, Universität Heidelberg, Mannheim, Germany; Hehlmann R., III. Medizinische Klinik, Universitätsmedizin Mannheim, Universität Heidelberg, Mannheim, Germany; Fabarius A., III. Medizinische Klinik, Universitätsmedizin Mannheim, Universität Heidelberg, Mannheim, Germany; Jeromin S., MLL Münchner Leukämielabor, München, Germany; Proetel U., III. Medizinische Klinik, Universitätsmedizin Mannheim, Universität Heidelberg, Mannheim, Germany; Rinaldetti S., III. Medizinische Klinik, Universitätsmedizin Mannheim, Universität Heidelberg, Mannheim, Germany; Kohlbrenner K., III. Medizinische Klinik, Universitätsmedizin Mannheim, Universität Heidelberg, Mannheim, Germany; Einsele H., Medizinische Klinik II, Universitätsklinikum, Würzburg, Germany; Falge C., Medizinische Klinik 5, Klinikum Nord, Nürnberg, Germany; Kanz L., Innere Medizin II, Universitätsklinikum, Tübingen, Germany; Neubauer A., Klinik für Hämatologie, Zentrum Innere Medizin, Philipps-Universität, Marburg, Germany; Kneba M., II. Medizinische Klinik und Poliklinik im SKK, Universitätsklinikum Schleswig-Holstein, Kiel, Germany; Stegelmann F., Klinik für Innere Medizin III, Universitätsklinikum, Ulm, Germany; Pfreundschuh M., Klinik für Innere Medizin i, Universitätsklinikum des Saarlandes, Homburg/Saar, Germany; Waller C.F., Klinik für Innere Medizin i, Universitätsklinikum, Freiburg, Germany; Oppliger Leibundgut E., Universitätsklinik für Hämatologie und Hämatologisches Zentrallabor, Inselspital, Bern, Switzerland; Heim D., Klinik für Hämatologie, Universitätsspital, Basel, Switzerland; Krause S.W., Medizinische Klinik 5, Universitätsklinikum, Erlangen, Germany; Hofmann W.-K., III. Medizinische Klinik, Universitätsmedizin Mannheim, Universität Heidelberg, Mannheim, Germany; Hasford J., Institut für Medizinische Informationsverarbeitung, Biometrie und Epidemiologie, Ludwig-Maximilians-Universität, München, Germany; Pfirrmann M., Institut für Medizinische Informationsverarbeitung, Biometrie und Epidemiologie, Ludwig-Maximilians-Universität, München, Germany; Müller M.C., III. Medizinische Klinik, Universitätsmedizin Mannheim, Universität Heidelberg, Mannheim, Germany; Hochhaus A., Klinik für Innere Medizin II, Abt. Hämatologie und Intern. Onkologie, Universitätsklinikum, Jena, Germany; Lauseker M., Institut für Medizinische Informationsverarbeitung, Biometrie und Epidemiologie, Ludwig-Maximilians-Universität, München, Germany","Major molecular remission (MMR) is an important therapy goal in chronic myeloid leukemia (CML). So far, MMR is not a failure criterion according to ELN management recommendation leading to uncertainties when to change therapy in CML patients not reaching MMR after 12 months. At monthly landmarks, for different molecular remission status Hazard ratios (HR) were estimated for patients registered to CML study IV who were divided in a learning and a validation sample. The minimum HR for MMR was found at 2.5 years with 0.28 (compared to patients without remission). In the validation sample, a significant advantage for progression-free survival (PFS) for patients in MMR could be detected (p-value 0.007). The optimal time to predict PFS in patients with MMR could be validated in an independent sample at 2.5 years. With our model we provide a suggestion when to define lack of MMR as therapy failure and thus treatment change should be considered. The optimal response time for 1% BCR-ABL at about 12-15 months was confirmed and for deep molecular remission no specific time point was detected. Nevertheless, it was demonstrated that the earlier the MMR is achieved the higher is the chance to attain deep molecular response later. © 2018 The Author(s).","","Adolescent; Adult; Aged; Aged, 80 and over; Female; Humans; Imatinib Mesylate; Leukemia, Myelogenous, Chronic, BCR-ABL Positive; Machine Learning; Male; Middle Aged; Models, Theoretical; Progression-Free Survival; Remission Induction; Treatment Failure; Young Adult; imatinib; protein tyrosine kinase inhibitor; imatinib; adolescent; aged; Article; cancer regression; chronic myeloid leukemia; controlled study; drug dose comparison; female; human; major clinical study; major molecular remission; male; outcome assessment; priority journal; progression free survival; randomized controlled trial (topic); treatment failure; treatment response; validation process; adult; chronic myeloid leukemia; machine learning; middle aged; mortality; procedures; randomized controlled trial; remission; theoretical model; very elderly; young adult","Nature Publishing Group","08876924","","LEUKE","29479070","Article","Scopus","2-s2.0-85042542477"
"Zech J.; Pain M.; Titano J.; Badgeley M.; Schefflein J.; Su A.; Costa A.; Bederson J.; Lehar J.; Oermann E.K.","Zech, John (56954783800); Pain, Margaret (56089850500); Titano, Joseph (56016598000); Badgeley, Marcus (55262062500); Schefflein, Javin (55207295800); Su, Andres (57201745693); Costa, Anthony (23484900800); Bederson, Joshua (7004176874); Lehar, Joseph (7004830993); Oermann, Eric Karl (23973230500)","56954783800; 56089850500; 56016598000; 55262062500; 55207295800; 57201745693; 23484900800; 7004176874; 7004830993; 23973230500","Natural language-based machine learning models for the annotation of clinical radiology reports","2018","Radiology","106","10.1148/radiol.2018171093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046006819&doi=10.1148%2fradiol.2018171093&partnerID=40&md5=c74ab7a20805bcf57725a185cf4e0729","Department of Radiology, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States; Neurosurgery, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States; Verily Life Sciences, South San Francisco, CA, United States; Department of Bioengineering and Bioinformatics, Boston University, Boston, MA, United States","Zech J., Department of Radiology, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States; Pain M., Neurosurgery, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States; Titano J., Department of Radiology, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States; Badgeley M., Neurosurgery, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States, Verily Life Sciences, South San Francisco, CA, United States; Schefflein J., Department of Radiology, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States; Su A., Department of Radiology, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States; Costa A., Neurosurgery, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States; Bederson J., Neurosurgery, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States; Lehar J., Department of Bioengineering and Bioinformatics, Boston University, Boston, MA, United States; Oermann E.K., Neurosurgery, Icahn School of Medicine, 1 Gustave Levy Pl., New York, 10029, NY, United States","Purpose: To compare different methods for generating features from radiology reports and to develop a method to automatically identify findings in these reports. Materials and Methods: In this study, 96 303 head computed tomography (CT) reports were obtained. The linguistic complexity of these reports was compared with that of alternative corpora. Head CT reports were preprocessed, and machine-analyzable features were constructed by using bag-of-words (BOW), word embedding, and Latent Dirichlet allocation-based approaches. Ultimately, 1004 head CT reports were manually labeled for findings of interest by physicians, and a subset of these were deemed critical findings. Lasso logistic regression was used to train models for physician-assigned labels on 602 of 1004 head CT reports (60%) using the constructed features, and the performance of these models was validated on a held-out 402 of 1004 reports (40%). Models were scored by area under the receiver operating characteristic curve (AUC), and aggregate AUC statistics were reported for (a) all labels, (b) critical labels, and (c) the presence of any critical finding in a report. Sensitivity, specificity, accuracy, and F1 score were reported for the best performing model's (a) predictions of all labels and (b) identification of reports containing critical findings. Results: The best-performing model (BOW with unigrams, bigrams, and trigrams plus average word embeddings vector) had a held-out AUC of 0.966 for identifying the presence of any critical head CT finding and an average 0.957 AUC across all head CT findings. Sensitivity and specificity for identifying the presence of any critical finding were 92.59% (175 of 189) and 89.67% (191 of 213), respectively. Average sensitivity and specificity across all findings were 90.25% (1898 of 2103) and 91.72% (18 351 of 20 007), respectively. Simpler BOW methods achieved results competitive with those of more sophisticated approaches, with an average AUC for presence of any critical finding of 0.951 for unigram BOW versus 0.966 for the best-performing model. The Yule I of the head CT corpus was 34, markedly lower than that of the Reuters corpus (at 103) or I2B2 discharge summaries (at 271), indicating lower linguistic complexity. Conclusion: Automated methods can be used to identify findings in radiology reports. The success of this approach benefits from the standardized language of these reports. With this method, a large labeled corpus can be generated for applications such as deep learning. © RSNA, 2018.","","Area Under Curve; Databases, Factual; Electronic Health Records; Humans; Machine Learning; Natural Language Processing; Radiology; Sensitivity and Specificity; Tomography, X-Ray Computed; Article; computer assisted tomography; data processing; diagnostic value; electronic medical record; human; information processing; logistic regression analysis; machine learning; measurement accuracy; natural language processing; priority journal; receiver operating characteristic; sensitivity and specificity; validation study; area under the curve; electronic health record; factual database; procedures; radiology; x-ray computed tomography","Radiological Society of North America Inc.","00338419","","RADLA","29381109","Article","Scopus","2-s2.0-85046006819"
"Sors A.; Bonnet S.; Mirek S.; Vercueil L.; Payen J.-F.","Sors, Arnaud (57386185100); Bonnet, Stéphane (7005908149); Mirek, Sébastien (55346683600); Vercueil, Laurent (12800700600); Payen, Jean-François (55851944430)","57386185100; 7005908149; 55346683600; 12800700600; 55851944430","A convolutional neural network for sleep stage scoring from raw single-channel EEG","2018","Biomedical Signal Processing and Control","308","10.1016/j.bspc.2017.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041487824&doi=10.1016%2fj.bspc.2017.12.001&partnerID=40&md5=1858cc4d1c8d73e3fd474179ee6a9012","Univ. Grenoble Alpes, Grenoble, F-38000, France; CEA Leti, MINATEC Campus, 17 rue des Martyrs, Grenoble, F-38054, France; Dijon University Hospital, Dpt. Anesth. and Crit. Care, 14 rue Paul Gaffarel, Dijon, F-21079, France; Grenoble University Hospital, Dpt. Exploration Fonctionnelle du Système Nerveux, Avenue du Maquis du Grésivaudan, F-38700, La Tronche, France; Grenoble University Hospital, Dpt. Anesth. and Crit. Care, Avenue Maquis du Grésivaudan, F-38700, La Tronche, France","Sors A., Univ. Grenoble Alpes, Grenoble, F-38000, France, CEA Leti, MINATEC Campus, 17 rue des Martyrs, Grenoble, F-38054, France; Bonnet S., Univ. Grenoble Alpes, Grenoble, F-38000, France, CEA Leti, MINATEC Campus, 17 rue des Martyrs, Grenoble, F-38054, France; Mirek S., Dijon University Hospital, Dpt. Anesth. and Crit. Care, 14 rue Paul Gaffarel, Dijon, F-21079, France; Vercueil L., Univ. Grenoble Alpes, Grenoble, F-38000, France, Grenoble University Hospital, Dpt. Exploration Fonctionnelle du Système Nerveux, Avenue du Maquis du Grésivaudan, F-38700, La Tronche, France; Payen J.-F., Univ. Grenoble Alpes, Grenoble, F-38000, France, Grenoble University Hospital, Dpt. Anesth. and Crit. Care, Avenue Maquis du Grésivaudan, F-38700, La Tronche, France","We present a novel method for automatic sleep scoring based on single-channel EEG. We introduce the use of a deep convolutional neural network (CNN) on raw EEG samples for supervised learning of 5-class sleep stage prediction. The network has 14 layers, takes as input the 30-s epoch to be classified as well as two preceding epochs and one following epoch for temporal context, and requires no signal preprocessing or feature extraction phase. We train and evaluate our system using data from the Sleep Heart Health Study (SHHS), a large multi-center cohort study including expert-rated polysomnographic records. Performance metrics reach the state of the art, with accuracy of 0.87 and Cohen kappa of 0.81. The use of a large cohort with multiple expert raters guarantees good generalization. Finally, we present a method for visualizing class-wise patterns learned by the network. © 2017 Elsevier Ltd","Classification; Convolutional neural network; EEG; Single-channel; Sleep Heart Health Study; Sleep staging","Classification (of information); Convolution; Deep neural networks; Electroencephalography; Network layers; Sleep research; Automatic sleep scoring; Health-study; Performance metrics; Signal preprocessing; Single channel eeg; Single channels; Sleep staging; State of the art; algorithm; Article; best corrected visual acuity; brain computer interface; cohort analysis; comparative study; controlled study; electroencephalogram; electromyogram; electrooculogram; entropy; eye movement; false negative result; false positive result; human; major clinical study; nerve cell network; predictive value; priority journal; reading; sleep spindle; sleep stage; support vector machine; task performance; theta rhythm; Convolutional neural networks","Elsevier Ltd","17468094","","","","Article","Scopus","2-s2.0-85041487824"
"Zhong W.; Liao L.; Guo X.; Wang G.","Zhong, Wei (57202162358); Liao, Lijuan (57202154184); Guo, Xuemei (25822445600); Wang, Guoli (35231538600)","57202162358; 57202154184; 25822445600; 35231538600","A deep learning approach for fetal QRS complex detection","2018","Physiological Measurement","73","10.1088/1361-6579/aab297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047365215&doi=10.1088%2f1361-6579%2faab297&partnerID=40&md5=4e8284cb507b95e9dde551dcf8371d02","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, 510006, China; School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, 510006, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China","Zhong W., School of Data and Computer Science, Sun Yat-sen University, Guangzhou, 510006, China; Liao L., School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, 510006, China; Guo X., School of Data and Computer Science, Sun Yat-sen University, Guangzhou, 510006, China, Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China; Wang G., School of Data and Computer Science, Sun Yat-sen University, Guangzhou, 510006, China, Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China","Objective: Non-invasive foetal electrocardiography (NI-FECG) has the potential to provide more additional clinical information for detecting and diagnosing fetal diseases. We propose and demonstrate a deep learning approach for fetal QRS complex detection from raw NI-FECG signals by using a convolutional neural network (CNN) model. The main objective is to investigate whether reliable fetal QRS complex detection performance can still be obtained from features of single-channel NI-FECG signals, without canceling maternal ECG (MECG) signals. Approach: A deep learning method is proposed for recognizing fetal QRS complexes. Firstly, we collect data from set-a of the PhysioNet/computing in Cardiology Challenge database. The sample entropy method is used for signal quality assessment. Part of the bad quality signals is excluded in the further analysis. Secondly, in the proposed method, the features of raw NI-FECG signals are normalized before they are fed to a CNN classifier to perform fetal QRS complex detection. We use precision, recall, F-measure and accuracy as the evaluation metrics to assess the performance of fetal QRS complex detection. Main results: The proposed deep learning method can achieve relatively high precision (75.33%), recall (80.54%), and F-measure scores (77.85%) compared with three other well-known pattern classification methods, namely KNN, naive Bayes and SVM. Significance: The proposed deep learning method can attain reliable fetal QRS complex detection performance from the raw NI-FECG signals without canceling MECG signals. In addition, the influence of different activation functions and signal quality assessment on classification performance are evaluated, and results show that Relu outperforms the Sigmoid and Tanh on this particular task, and better classification performance is obtained with the signal quality assessment step in this study. © 2018 Institute of Physics and Engineering in Medicine.","convolutional neural network; deep learning; fetal QRS complexes; Non-invasive foetal ECG; signal quality assessment","Deep Learning; Electrocardiography; Fetus; Humans; Neural Networks (Computer); Signal Processing, Computer-Assisted; Biomedical signal processing; Convolution; Deep neural networks; Electrocardiography; Feature extraction; Quality control; Signal detection; Support vector machines; Convolutional neural network; Deep learning; Fetal ECG; Fetal electrocardiographies; Fetal QRS complex; Learning methods; Non-invasive fetal ECG; QRS complex detection; QRS complexes; Signal quality assessment; artificial neural network; electrocardiography; fetus; human; physiology; signal processing; Complex networks","IOP Publishing Ltd","09673334","","PMEAE","29485406","Article","Scopus","2-s2.0-85047365215"
"Calderon C.P.; Daniels A.L.; Randolph T.W.","Calderon, Christopher P. (16027717000); Daniels, Austin L. (57193650821); Randolph, Theodore W. (7005729819)","16027717000; 57193650821; 7005729819","Deep Convolutional Neural Network Analysis of Flow Imaging Microscopy Data to Classify Subvisible Particles in Protein Formulations","2018","Journal of Pharmaceutical Sciences","57","10.1016/j.xphs.2017.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041004188&doi=10.1016%2fj.xphs.2017.12.008&partnerID=40&md5=867e2e1d55653443222ca22cc3b84eab","Ursa Analytics, Inc., Denver, 80212-1962, Colorado, United States; Department of Chemical and Biological Engineering, University of Colorado, Boulder, 80309-0596, Colorado, United States","Calderon C.P., Ursa Analytics, Inc., Denver, 80212-1962, Colorado, United States, Department of Chemical and Biological Engineering, University of Colorado, Boulder, 80309-0596, Colorado, United States; Daniels A.L., Department of Chemical and Biological Engineering, University of Colorado, Boulder, 80309-0596, Colorado, United States; Randolph T.W., Department of Chemical and Biological Engineering, University of Colorado, Boulder, 80309-0596, Colorado, United States","Flow-imaging microscopy (FIM) is commonly used to characterize subvisible particles in therapeutic protein formulations. Although pharmaceutical companies often collect large repositories of FIM images of protein therapeutic products, current state-of-the-art methods for analyzing these images rely on low-dimensional lists of “morphological features” to characterize particles that ignore much of the information encoded in the existing image databases. Deep convolutional neural networks (sometimes referred to as “CNNs or ConvNets”) have demonstrated the ability to extract predictive information from raw macroscopic image data without requiring the selection or specification of “morphological features” in a variety of tasks. However, the inherent heterogeneity of protein therapeutics and optical phenomena associated with subvisible FIM particle measurements introduces new challenges regarding the application of ConvNets to FIM image analysis. We demonstrate a supervised learning technique leveraging ConvNets to extract information from raw images in order to predict the process conditions or stress states (freeze-thawing, mechanical shaking, etc.) that produced a variety of different protein particles. We demonstrate that our new classifier, in combination with a “data pooling” strategy, can nearly perfectly differentiate between protein formulations in a variety of scenarios of relevance to protein therapeutics quality control and process monitoring using as few as 20 particles imaged via FIM. © 2018 American Pharmacists Association®","image analysis; protein aggregation; protein formulation; quality control; regulatory science","Chemistry, Pharmaceutical; Databases, Factual; Drug Compounding; Microscopy; Neural Networks (Computer); Proteins; anakinra; human immunoglobulin; silicone oil; protein; Article; artificial neural network; classifier; controlled study; data pooling; deep convolutional neural network; drug formulation; drug quality; flow imaging microscopy; freeze thawing; image processing; information processing; machine learning; mechanical stress; microscopy; process monitoring; protein aggregation; quality control; artificial neural network; chemistry; drug formulation; factual database; medicinal chemistry; microscopy; procedures","Elsevier B.V.","00223549","","JPMSA","29269269","Article","Scopus","2-s2.0-85041004188"
"Wachinger C.; Reuter M.; Klein T.","Wachinger, Christian (15043432000); Reuter, Martin (7202271978); Klein, Tassilo (42761665500)","15043432000; 7202271978; 42761665500","DeepNAT: Deep convolutional neural network for segmenting neuroanatomy","2018","NeuroImage","238","10.1016/j.neuroimage.2017.02.035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014101907&doi=10.1016%2fj.neuroimage.2017.02.035&partnerID=40&md5=4bd17a6f48c96a97042c50919657b0db","Department of Child and Adolescent Psychiatry, Psychosomatic and Psychotherapy, Ludwig-Maximilian-University, Waltherstr. 23, München, 81369, Munich, Germany; Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States; SAP SE, Berlin, Germany; German Centre for Neurodegenerative Diseases (DZNE), Department of Image Analysis, Bonn, Germany","Wachinger C., Department of Child and Adolescent Psychiatry, Psychosomatic and Psychotherapy, Ludwig-Maximilian-University, Waltherstr. 23, München, 81369, Munich, Germany; Reuter M., Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States, Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States, German Centre for Neurodegenerative Diseases (DZNE), Department of Image Analysis, Bonn, Germany; Klein T., SAP SE, Berlin, Germany","We introduce DeepNAT, a 3D Deep convolutional neural network for the automatic segmentation of NeuroAnaTomy in T1-weighted magnetic resonance images. DeepNAT is an end-to-end learning-based approach to brain segmentation that jointly learns an abstract feature representation and a multi-class classification. We propose a 3D patch-based approach, where we do not only predict the center voxel of the patch but also neighbors, which is formulated as multi-task learning. To address a class imbalance problem, we arrange two networks hierarchically, where the first one separates foreground from background, and the second one identifies 25 brain structures on the foreground. Since patches lack spatial context, we augment them with coordinates. To this end, we introduce a novel intrinsic parameterization of the brain volume, formed by eigenfunctions of the Laplace-Beltrami operator. As network architecture, we use three convolutional layers with pooling, batch normalization, and non-linearities, followed by fully connected layers with dropout. The final segmentation is inferred from the probabilistic output of the network with a 3D fully connected conditional random field, which ensures label agreement between close voxels. The roughly 2.7 million parameters in the network are learned with stochastic gradient descent. Our results show that DeepNAT compares favorably to state-of-the-art methods. Finally, the purely learning-based method may have a high potential for the adaptation to young, old, or diseased brains by fine-tuning the pre-trained network with a small training sample on the target application, where the availability of larger datasets with manual annotations may boost the overall segmentation accuracy in the future. © 2017 Elsevier Inc.","Brain segmentation; Conditional random field; Convolutional neural networks; Deep learning; Multi-task learning","Brain; Deep Learning; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Neuroimaging; Article; artificial neural network; brain region; brain size; controlled study; deep convolutional neural network; image segmentation; intermethod comparison; mathematical model; neuroanatomy; nuclear magnetic resonance imaging; prediction; priority journal; anatomy and histology; brain; diagnostic imaging; evaluation study; human; image processing; machine learning; neuroimaging; procedures","Academic Press Inc.","10538119","","NEIME","28223187","Article","Scopus","2-s2.0-85014101907"
"Belharbi S.; Hérault R.; Chatelain C.; Adam S.","Belharbi, Soufiane (57191838341); Hérault, Romain (15057961600); Chatelain, Clément (56186063500); Adam, Sébastien (7102425754)","57191838341; 15057961600; 56186063500; 7102425754","Deep neural networks regularization for structured output prediction","2018","Neurocomputing","9","10.1016/j.neucom.2017.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039420909&doi=10.1016%2fj.neucom.2017.12.002&partnerID=40&md5=6f452afd4e99e3e7ceec4c98d05daaff","Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France","Belharbi S., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France; Hérault R., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France; Chatelain C., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France; Adam S., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France","A deep neural network model is a powerful framework for learning representations. Usually, it is used to learn the relation x → y by exploiting the regularities in the input x. In structured output prediction problems, y is multi-dimensional and structural relations often exist between the dimensions. The motivation of this work is to learn the output dependencies that may lie in the output data in order to improve the prediction accuracy. Unfortunately, feedforward networks are unable to exploit the relations between the outputs. In order to overcome this issue, we propose in this paper a regularization scheme for training neural networks for these particular tasks using a multi-task framework. Our scheme aims at incorporating the learning of the output representation y in the training process in an unsupervised fashion while learning the supervised mapping function x → y. We evaluate our framework on a facial landmark detection problem which is a typical structured output task. We show over two public challenging datasets (LFPW and HELEN) that our regularization scheme improves the generalization of deep neural networks and accelerates their training. The use of unlabeled data and label-only data is also explored, showing an additional improvement of the results. We provide an opensource implementation of our framework. © 2017 Elsevier B.V.","Deep learning; Multi-task learning; Regularization; Representations learning; Structured output prediction","Deep learning; Forecasting; Facial landmark detection; Feed-forward network; Multitask learning; Open source implementation; Regularization; Regularization schemes; Representations learning; Structured output prediction; Article; artificial neural network; deep neural network; hidden Markov model; machine learning; mathematical analysis; mathematical computing; prediction; priority journal; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85039420909"
"Wang K.; Shang C.; Ke W.; Jiang Y.; Huang D.","Wang, Kangcheng (57044978900); Shang, Chao (55839423100); Ke, Wensi (57220169754); Jiang, Yongheng (7404832991); Huang, Dexian (55839074000)","57044978900; 55839423100; 57220169754; 7404832991; 55839074000","Automatic structure and parameters tuning method for deep neural network soft sensor in chemical industries","2018","Huagong Xuebao/CIESC Journal","7","10.11949/j.issn.0438-1157.20171435","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070322308&doi=10.11949%2fj.issn.0438-1157.20171435&partnerID=40&md5=b750a01ced4aa742895d8179fb32afad","Department of Automation, Tsinghua University, Beijing, 100084, China; Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China","Wang K., Department of Automation, Tsinghua University, Beijing, 100084, China, Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China; Shang C., Department of Automation, Tsinghua University, Beijing, 100084, China, Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China; Ke W., Department of Automation, Tsinghua University, Beijing, 100084, China, Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China; Jiang Y., Department of Automation, Tsinghua University, Beijing, 100084, China, Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China; Huang D., Department of Automation, Tsinghua University, Beijing, 100084, China, Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China","Deep learning has been applied to the field of soft sensing in process industries. However, the structure and parameters of deep neural network (DNN) have to be tuned manually, which require solid fundamental knowledge about machine learning and rich experiences on parameters tuning. Complicated tuning procedure restricts generalization application of deep learning in chemical industries. A structure and parameters tuning method for DNN soft sensor with little manual intervention was proposed by systematic analysis on selection process of each essential DNN parameter from massive experiments. The presented method could greatly simplify the tuning procedure and offer a reference for engineers to study and use deep learning. Studies on crude-oil distillation and coal gasification process verified effectiveness and generality of the proposed method. © All Right Reserved.","Algorithm; Deep learning; Neural network; Parameter tuning; Prediction","Algorithms; Chemical industry; Deep neural networks; Distillation; Forecasting; Genetic algorithms; Learning systems; Neural networks; Automatic structures; Gasification process; In-process; Manual intervention; Parameter-tuning; Parameters tuning; Soft sensors; Systematic analysis; Deep learning","Materials China","04381157","","HUKHA","","Article","Scopus","2-s2.0-85070322308"
"Campanella G.; Rajanna A.R.; Corsale L.; Schüffler P.J.; Yagi Y.; Fuchs T.J.","Campanella, Gabriele (57199091626); Rajanna, Arjun R. (57189352056); Corsale, Lorraine (57199068025); Schüffler, Peter J. (22036306700); Yagi, Yukako (8375875100); Fuchs, Thomas J. (56454885300)","57199091626; 57189352056; 57199068025; 22036306700; 8375875100; 56454885300","Towards machine learned quality control: A benchmark for sharpness quantification in digital pathology","2018","Computerized Medical Imaging and Graphics","33","10.1016/j.compmedimag.2017.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037581032&doi=10.1016%2fj.compmedimag.2017.09.001&partnerID=40&md5=786918733a003434d0a46977028d1bca","Weill Cornell Medicine, New York, United States; Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, United States; Department of Pathology, Memorial Sloan Kettering Cancer Center, New York, United States","Campanella G., Weill Cornell Medicine, New York, United States, Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, United States; Rajanna A.R., Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, United States; Corsale L., Department of Pathology, Memorial Sloan Kettering Cancer Center, New York, United States; Schüffler P.J., Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, United States; Yagi Y., Department of Pathology, Memorial Sloan Kettering Cancer Center, New York, United States; Fuchs T.J., Weill Cornell Medicine, New York, United States, Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, United States, Department of Pathology, Memorial Sloan Kettering Cancer Center, New York, United States","Pathology is on the verge of a profound change from an analog and qualitative to a digital and quantitative discipline. This change is mostly driven by the high-throughput scanning of microscope slides in modern pathology departments, reaching tens of thousands of digital slides per month. The resulting vast digital archives form the basis of clinical use in digital pathology and allow large scale machine learning in computational pathology. One of the most crucial bottlenecks of high-throughput scanning is quality control (QC). Currently, digital slides are screened manually to detected out-of-focus regions, to compensate for the limitations of scanner software. We present a solution to this problem by introducing a benchmark dataset for blur detection, an in-depth comparison of state-of-the art sharpness descriptors and their prediction performance within a random forest framework. Furthermore, we show that convolution neural networks, like residual networks, can be used to train blur detectors from scratch. We thoroughly evaluate the accuracy of feature based and deep learning based approaches for sharpness classification (99.74% accuracy) and regression (MSE 0.004) and additionally compare them to domain experts in a comprehensive human perception study. Our pipeline outputs spacial heatmaps enabling to quantify and localize blurred areas on a slide. Finally, we tested the proposed framework in the clinical setting and demonstrate superior performance over the state-of-the-art QC pipeline comprising commercial software and human expert inspection by reducing the error rate from 17% to 4.7%. © 2017","Computational pathology; Deep learning; Digital pathology; Machine learning; Quality control; Quantitative blur detection","Benchmarking; Diagnostic Imaging; Image Enhancement; Machine Learning; Neural Networks (Computer); Quality Control; Artificial intelligence; Benchmarking; Computer graphics; Decision trees; Deep learning; Learning systems; Pathology; Pipelines; Quality assurance; Software testing; Throughput; Blur detection; Commercial software; Convolution neural network; Digital pathologies; High-throughput scanning; Large-scale machine learning; Learning-based approach; Prediction performance; accuracy; Article; artificial neural network; benchmarking; controlled study; digital imaging; digital pathology; human; human tissue; image quality; machine learning; male; medical expert; pathology; prediction; priority journal; quality control; quantitative analysis; random forest; diagnostic imaging; image enhancement; standards; Quality control","Elsevier Ltd","08956111","","CMIGE","29241972","Article","Scopus","2-s2.0-85037581032"
"Tuttle A.H.; Molinaro M.J.; Jethwa J.F.; Sotocinal S.G.; Prieto J.C.; Styner M.A.; Mogil J.S.; Zylka M.J.","Tuttle, Alexander H (36086754200); Molinaro, Mark J (57204285722); Jethwa, Jasmine F (57204282661); Sotocinal, Susana G (8730872200); Prieto, Juan C (35189257500); Styner, Martin A (6701492552); Mogil, Jeffrey S (7006362839); Zylka, Mark J (6602126384)","36086754200; 57204285722; 57204282661; 8730872200; 35189257500; 6701492552; 7006362839; 6602126384","A deep neural network to assess spontaneous pain from mouse facial expressions","2018","Molecular Pain","92","10.1177/1744806918763658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054823532&doi=10.1177%2f1744806918763658&partnerID=40&md5=2b02d4f781746aa7897b3a37be4617e7","Department of Cell Biology and Physiology, UNC Neuroscience Center, The University of North Carolina, Chapel Hill, NC, United States; Department of Psychology, Alan Edwards Centre for Research on Pain, McGill University, Montreal, QC, Canada; Department of Psychiatry, Carolina Institute for Developmental Disabilities, The University of North Carolina, Chapel Hill, NC, United States","Tuttle A.H., Department of Cell Biology and Physiology, UNC Neuroscience Center, The University of North Carolina, Chapel Hill, NC, United States; Molinaro M.J., Department of Cell Biology and Physiology, UNC Neuroscience Center, The University of North Carolina, Chapel Hill, NC, United States; Jethwa J.F., Department of Cell Biology and Physiology, UNC Neuroscience Center, The University of North Carolina, Chapel Hill, NC, United States; Sotocinal S.G., Department of Psychology, Alan Edwards Centre for Research on Pain, McGill University, Montreal, QC, Canada; Prieto J.C., Department of Psychiatry, Carolina Institute for Developmental Disabilities, The University of North Carolina, Chapel Hill, NC, United States; Styner M.A., Department of Psychiatry, Carolina Institute for Developmental Disabilities, The University of North Carolina, Chapel Hill, NC, United States; Mogil J.S., Department of Psychology, Alan Edwards Centre for Research on Pain, McGill University, Montreal, QC, Canada; Zylka M.J., Department of Cell Biology and Physiology, UNC Neuroscience Center, The University of North Carolina, Chapel Hill, NC, United States","Grimace scales quantify characteristic facial expressions associated with spontaneous pain in rodents and other mammals. However, these scales have not been widely adopted largely because of the time and effort required for highly trained humans to manually score the images. Convoluted neural networks were recently developed that distinguish individual humans and objects in images. Here, we trained one of these networks, the InceptionV3 convolutional neural net, with a large set of human-scored mouse images. Output consists of a binary pain/no-pain assessment and a confidence score. Our automated Mouse Grimace Scale integrates these two outputs and is highly accurate (94%) at assessing the presence of pain in mice across different experimental assays. In addition, we used a novel set of “pain” and “no pain” images to show that automated Mouse Grimace Scale scores are highly correlated with human scores (Pearson’s r = 0.75). Moreover, the automated Mouse Grimace Scale classified a greater proportion of images as “pain” following laparotomy surgery when compared to animals receiving a sham surgery or a post-surgical analgesic. Together, these findings suggest that the automated Mouse Grimace Scale can eliminate the need for tedious human scoring of images and provide an objective and rapid way to quantify spontaneous pain and pain relief in mice. © The Author(s) 2018.","animal models; facial expressions; machine learning; Spontaneous pain","Animals; Automation; Facial Expression; Humans; Mice; Nerve Net; Pain; Postoperative Care; Video Recording; animal; automation; facial expression; human; mouse; nerve cell network; pain; pathophysiology; postoperative care; videorecording","SAGE Publications Inc.","17448069","","","29546805","Article","Scopus","2-s2.0-85054823532"
"Bagattini F.; Schoen F.; Tigli L.","Bagattini, Francesco (57197837460); Schoen, Fabio (7101657017); Tigli, Luca (57201590251)","57197837460; 7101657017; 57201590251","Clustering methods for the optimization of atomic cluster structure","2018","Journal of Chemical Physics","5","10.1063/1.5020858","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045319214&doi=10.1063%2f1.5020858&partnerID=40&md5=5748f317a8562ff87284389bc092859a","University of Florence, Florence, Italy","Bagattini F., University of Florence, Florence, Italy; Schoen F., University of Florence, Florence, Italy; Tigli L., University of Florence, Florence, Italy","In this paper, we propose a revised global optimization method and apply it to large scale cluster conformation problems. In the 1990s, the so-called clustering methods were considered among the most efficient general purpose global optimization techniques; however, their usage has quickly declined in recent years, mainly due to the inherent difficulties of clustering approaches in large dimensional spaces. Inspired from the machine learning literature, we redesigned clustering methods in order to deal with molecular structures in a reduced feature space. Our aim is to show that by suitably choosing a good set of geometrical features coupled with a very efficient descent method, an effective optimization tool is obtained which is capable of finding, with a very high success rate, all known putative optima for medium size clusters without any prior information, both for Lennard-Jones and Morse potentials. The main result is that, beyond being a reliable approach, the proposed method, based on the idea of starting a computationally expensive deep local search only when it seems worth doing so, is capable of saving a huge amount of searches with respect to an analogous algorithm which does not employ a clustering phase. In this paper, we are not claiming the superiority of the proposed method compared to specific, refined, state-of-the-art procedures, but rather indicating a quite straightforward way to save local searches by means of a clustering scheme working in a reduced variable space, which might prove useful when included in many modern methods. © 2018 Author(s).","","Global optimization; Learning systems; Morse potential; Atomic cluster structures; Clustering approach; Geometrical features; Global optimization method; Global optimization techniques; Large-scale clusters; Machine learning literature; State-of-the-art procedures; article; machine learning; Cluster analysis","American Institute of Physics Inc.","00219606","","JCPSA","29655362","Article","Scopus","2-s2.0-85045319214"
"Kucewicz M.T.; Berry B.M.; Miller L.R.; Khadjevand F.; Ezzyat Y.; Stein J.M.; Kremen V.; Brinkmann B.H.; Wanda P.; Sperling M.R.; Gorniak R.; Davis K.A.; Jobst B.C.; Gross R.E.; Lega B.; Van Gompel J.; Matt Stead S.; Rizzuto D.S.; Kahana M.J.; Worrell G.A.","Kucewicz, Michal T. (54393385400); Berry, Brent M (56298366100); Miller, Laura R. (57192574347); Khadjevand, Fatemeh (57193682724); Ezzyat, Youssef (17342011300); Stein, Joel M. (56415623100); Kremen, Vaclav (24721954400); Brinkmann, Benjamin H. (7103117272); Wanda, Paul (55613721500); Sperling, Michael R. (7102143426); Gorniak, Richard (6507248589); Davis, Kathryn A. (28767557800); Jobst, Barbara C. (7004544528); Gross, Robert E. (57203503062); Lega, Bradley (14066258400); Van Gompel, Jamie (24391340000); Matt Stead, S. (19640612100); Rizzuto, Daniel S. (6602612030); Kahana, Michael J. (7004417058); Worrell, Gregory A. (6701826547)","54393385400; 56298366100; 57192574347; 57193682724; 17342011300; 56415623100; 24721954400; 7103117272; 55613721500; 7102143426; 6507248589; 28767557800; 7004544528; 57203503062; 14066258400; 24391340000; 19640612100; 6602612030; 7004417058; 6701826547","Evidence for verbal memory enhancement with electrical brain stimulation in the lateral temporal cortex","2018","Brain","51","10.1093/brain/awx373","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046488050&doi=10.1093%2fbrain%2fawx373&partnerID=40&md5=4d8fd867c1df5d9de08afcb21ff67c53","Mayo Clinic, Department of Neurology, Rochester, MN, United States; Mayo Clinic, Department of Physiology and Biomedical Engineering, Rochester, MN, United States; University of Pennsylvania, Department of Psychology, Philadelphia, PA, United States; University of Pennsylvania Hospital, Department of Radiology, Philadelphia, PA, United States; Czech Technical University, Czech Institute of Informatics, Robotics and Cybernetics, Prague, Czech Republic; Thomas Jefferson University Hospital, Department of Neurology, Philadelphia, PA, United States; Thomas Jefferson University Hospital, Department of Radiology, Philadelphia, PA, United States; University of Pennsylvania Hospital, Department of Neurology, Philadelphia, PA, United States; Dartmouth-Hitchcock Medical Center, Department of Neurology, Lebanon NH, United States; Emory University, Department of Neurosurgery, Atlanta, GA, United States; UT Southwestern Medical Center, Department of Neurosurgery, Dallas, TX, United States; Mayo Clinic, Department of Neurosurgery, Rochester, MN, United States","Kucewicz M.T., Mayo Clinic, Department of Neurology, Rochester, MN, United States, Mayo Clinic, Department of Physiology and Biomedical Engineering, Rochester, MN, United States; Berry B.M., Mayo Clinic, Department of Neurology, Rochester, MN, United States, Mayo Clinic, Department of Physiology and Biomedical Engineering, Rochester, MN, United States; Miller L.R., Mayo Clinic, Department of Neurology, Rochester, MN, United States, Mayo Clinic, Department of Physiology and Biomedical Engineering, Rochester, MN, United States; Khadjevand F., Mayo Clinic, Department of Neurology, Rochester, MN, United States, Mayo Clinic, Department of Physiology and Biomedical Engineering, Rochester, MN, United States; Ezzyat Y., University of Pennsylvania, Department of Psychology, Philadelphia, PA, United States; Stein J.M., University of Pennsylvania Hospital, Department of Radiology, Philadelphia, PA, United States; Kremen V., Mayo Clinic, Department of Neurology, Rochester, MN, United States, Mayo Clinic, Department of Physiology and Biomedical Engineering, Rochester, MN, United States, Czech Technical University, Czech Institute of Informatics, Robotics and Cybernetics, Prague, Czech Republic; Brinkmann B.H., Mayo Clinic, Department of Neurology, Rochester, MN, United States, Mayo Clinic, Department of Physiology and Biomedical Engineering, Rochester, MN, United States; Wanda P., University of Pennsylvania, Department of Psychology, Philadelphia, PA, United States; Sperling M.R., Thomas Jefferson University Hospital, Department of Neurology, Philadelphia, PA, United States; Gorniak R., Thomas Jefferson University Hospital, Department of Radiology, Philadelphia, PA, United States; Davis K.A., University of Pennsylvania Hospital, Department of Neurology, Philadelphia, PA, United States; Jobst B.C., Dartmouth-Hitchcock Medical Center, Department of Neurology, Lebanon NH, United States; Gross R.E., Emory University, Department of Neurosurgery, Atlanta, GA, United States; Lega B., UT Southwestern Medical Center, Department of Neurosurgery, Dallas, TX, United States; Van Gompel J., Mayo Clinic, Department of Neurosurgery, Rochester, MN, United States; Matt Stead S., Mayo Clinic, Department of Neurology, Rochester, MN, United States, Mayo Clinic, Department of Physiology and Biomedical Engineering, Rochester, MN, United States; Rizzuto D.S., University of Pennsylvania, Department of Psychology, Philadelphia, PA, United States; Kahana M.J., University of Pennsylvania, Department of Psychology, Philadelphia, PA, United States; Worrell G.A., Mayo Clinic, Department of Neurology, Rochester, MN, United States, Mayo Clinic, Department of Physiology and Biomedical Engineering, Rochester, MN, United States","Direct electrical stimulation of the human brain can elicit sensory and motor perceptions as well as recall of memories. Stimulating higher order association areas of the lateral temporal cortex in particular was reported to activate visual and auditory memory representations of past experiences (Penfield and Perot, 1963). We hypothesized that this effect could be used to modulate memory processing. Recent attempts at memory enhancement in the human brain have been focused on the hippocampus and other mesial temporal lobe structures, with a few reports of memory improvement in small studies of individual brain regions. Here, we investigated the effect of stimulation in four brain regions known to support declarative memory: hippocampus, parahippocampal neocortex, prefrontal cortex and temporal cortex. Intracranial electrode recordings with stimulation were used to assess verbal memory performance in a group of 22 patients (nine males). We show enhanced performance with electrical stimulation in the lateral temporal cortex (paired t-test, P = 0.0067), but not in the other brain regions tested. This selective enhancement was observed both on the group level, and for two of the four individual subjects stimulated in the temporal cortex. This study shows that electrical stimulation in specific brain areas can enhance verbal memory performance in humans. © The Author(s) (2018).","BRAIN initiative; Brain-machine interface; Direct brain stimulation; Electrocorticography; Gamma oscillations","Adult; Brain Mapping; Deep Brain Stimulation; Epilepsy; Female; Humans; Male; Memory Disorders; Middle Aged; Temporal Lobe; Time Factors; Verbal Learning; Young Adult; adult; Article; brain depth stimulation; clinical article; controlled study; declarative memory; electric current; electrophysiological procedures; electrostimulation; female; hemisphere; hippocampus; human; language; lateral temporal cortex; male; mental performance; middle aged; neocortex; parahippocampal neocortex; prefrontal cortex; priority journal; temporal cortex; verbal memory; verbal memory test; wakefulness; young adult; brain depth stimulation; brain mapping; complication; epilepsy; memory disorder; physiology; procedures; temporal lobe; time factor; verbal learning","Oxford University Press","00068950","","BRAIA","29324988","Article","Scopus","2-s2.0-85046488050"
"Lu D.; Popuri K.; Ding G.W.; Balachandar R.; Beg M.F.","Lu, Donghuan (57194828229); Popuri, Karteek (35218351700); Ding, Gavin Weiguang (57201008172); Balachandar, Rakesh (58340586700); Beg, Mirza Faisal (7102797387)","57194828229; 35218351700; 57201008172; 58340586700; 7102797387","Multiscale deep neural network based analysis of FDG-PET images for the early diagnosis of Alzheimer's disease","2018","Medical Image Analysis","129","10.1016/j.media.2018.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042877208&doi=10.1016%2fj.media.2018.02.002&partnerID=40&md5=19304edcbe4eb23b2c4d5294307aafe7","Simon Fraser University, School of Engineering Science, Burnaby, V5A 1S6, Canada","Lu D., Simon Fraser University, School of Engineering Science, Burnaby, V5A 1S6, Canada; Popuri K., Simon Fraser University, School of Engineering Science, Burnaby, V5A 1S6, Canada; Ding G.W., Simon Fraser University, School of Engineering Science, Burnaby, V5A 1S6, Canada; Balachandar R., Simon Fraser University, School of Engineering Science, Burnaby, V5A 1S6, Canada; Beg M.F., Simon Fraser University, School of Engineering Science, Burnaby, V5A 1S6, Canada","Alzheimer's disease (AD) is one of the most common neurodegenerative diseases with a commonly seen prodromal mild cognitive impairment (MCI) phase where memory loss is the main complaint progressively worsening with behavior issues and poor self-care. However, not all individuals clinically diagnosed with MCI progress to AD. A fraction of subjects with MCI either progress to non-AD dementia or remain stable at the MCI stage without progressing to dementia. Although a curative treatment of AD is currently unavailable, it is extremely important to correctly identify the individuals in the MCI phase that will go on to develop AD so that they may benefit from a curative treatment when one becomes available in the near future. At the same time, it would be highly desirable to also correctly identify those in the MCI phase that do not have AD pathology so they may be spared from unnecessary pharmocologic interventions that, at best, may provide them no benefit, and at worse, could further harm them with adverse side-effects. Additionally, it may be easier and simpler to identify the cause of the cognitive impairment in these non-AD cases, and hence proper identification of prodromal AD will be of benefit to these individuals as well. Fluorodeoxy glucose positron emission tomography (FDG-PET) captures the metabolic activity of the brain, and this imaging modality has been reported to identify changes related to AD prior to the onset of structural changes. Prior work on designing classifier using FDG-PET imaging has been promising. Since deep-learning has recently emerged as a powerful tool to mine features and use them for accurate labeling of the group membership of given images, we propose a novel deep-learning framework using FDG-PET metabolism imaging to identify subjects at the MCI stage with presymptomatic AD and discriminate them from other subjects with MCI (non-AD / non-progressive). Our multiscale deep neural network obtained 82.51% accuracy of classification just using measures from a single modality (FDG-PET metabolism data) outperforming other comparable FDG-PET classifiers published in the recent literature. © 2018 Elsevier B.V.","Alzheimer's disease; Early diagnosis; Metabolism FDG-PET; Multiscale deep neural network learning","Aged; Alzheimer Disease; Early Diagnosis; Female; Fluorodeoxyglucose F18; Humans; Male; Neural Networks (Computer); Positron-Emission Tomography; Radiopharmaceuticals; Brain; Diagnosis; Metabolism; Neurodegenerative diseases; Positron emission tomography; fluorodeoxyglucose; fluorodeoxyglucose f 18; radiopharmaceutical agent; Accuracy of classifications; Alzheimer's disease; Cognitive impairment; Early diagnosis; FDG PET; Mild cognitive impairments (MCI); Network-based analysis; Neural network learning; aged; Alzheimer disease; Article; classifier; cohort analysis; controlled study; diagnostic accuracy; diagnostic test accuracy study; differential diagnosis; early diagnosis; female; human; image processing; image segmentation; intermethod comparison; longitudinal study; machine learning; major clinical study; male; measurement error; metabolism; mild cognitive impairment; multiscale deep neural network; neuroimaging; nuclear magnetic resonance imaging; positron emission tomography; priority journal; quality control; sensitivity and specificity; staging; supervised machine learning; transfer of learning; unsupervised machine learning; Alzheimer disease; artificial neural network; diagnostic imaging; early diagnosis; positron emission tomography; procedures; Deep neural networks","Elsevier B.V.","13618415","","MIAEC","29502031","Article","Scopus","2-s2.0-85042877208"
"Yang H.; Shen S.; Yao X.; Sheng M.; Wang C.","Yang, Honghui (9232407200); Shen, Sheng (56042518800); Yao, Xiaohui (57191895168); Sheng, Meiping (7102446840); Wang, Chen (56373683300)","9232407200; 56042518800; 57191895168; 7102446840; 56373683300","Competitive deep-belief networks for underwater acoustic target recognition","2018","Sensors (Switzerland)","73","10.3390/s18040952","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044451376&doi=10.3390%2fs18040952&partnerID=40&md5=f66f99308b57e4fdfcf62c4d70001131","School of Marine Science and Technology, Northwestern Polytechnical University, 127 West Youyi Road, Beilin District, Xi’an, 710072, China","Yang H., School of Marine Science and Technology, Northwestern Polytechnical University, 127 West Youyi Road, Beilin District, Xi’an, 710072, China; Shen S., School of Marine Science and Technology, Northwestern Polytechnical University, 127 West Youyi Road, Beilin District, Xi’an, 710072, China; Yao X., School of Marine Science and Technology, Northwestern Polytechnical University, 127 West Youyi Road, Beilin District, Xi’an, 710072, China; Sheng M., School of Marine Science and Technology, Northwestern Polytechnical University, 127 West Youyi Road, Beilin District, Xi’an, 710072, China; Wang C., School of Marine Science and Technology, Northwestern Polytechnical University, 127 West Youyi Road, Beilin District, Xi’an, 710072, China","Underwater acoustic target recognition based on ship-radiated noise belongs to the small-sample-size recognition problems. A competitive deep-belief network is proposed to learn features with more discriminative information from labeled and unlabeled samples. The proposed model consists of four stages: (1) A standard restricted Boltzmann machine is pretrained using a large number of unlabeled data to initialize its parameters; (2) the hidden units are grouped according to categories, which provides an initial clustering model for competitive learning; (3) competitive training and back-propagation algorithms are used to update the parameters to accomplish the task of clustering; (4) by applying layer-wise training and supervised fine-tuning, a deep neural network is built to obtain features. Experimental results show that the proposed method can achieve classification accuracy of 90.89%, which is 8.95% higher than the accuracy obtained by the compared methods. In addition, the highest accuracy of our method is obtained with fewer features than other methods. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Hydrophone; Machine learning; Underwater acoustics","Backpropagation algorithms; Bayesian networks; Deep learning; Deep neural networks; Hydrophones; Learning systems; Classification accuracy; Competitive learning; Deep belief networks; Restricted boltzmann machine; Ship radiated noise; Small Sample Size; Underwater acoustic target recognition; Unlabeled samples; acoustics; algorithm; article; back propagation; deep belief network; deep learning; Underwater acoustics","MDPI AG","14248220","","","29570642","Article","Scopus","2-s2.0-85044451376"
"Nguyen D.T.; Baek N.R.; Pham T.D.; Park K.R.","Nguyen, Dat Tien (35608738000); Baek, Na Rae (57196348326); Pham, Tuyen Danh (55808639500); Park, Kang Ryoung (8983316300)","35608738000; 57196348326; 55808639500; 8983316300","Presentation attack detection for iris recognition system using NIR camera sensor","2018","Sensors (Switzerland)","16","10.3390/s18051315","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046073008&doi=10.3390%2fs18051315&partnerID=40&md5=fab67d14d2ed548e710afede9f76916d","Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea","Nguyen D.T., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Baek N.R., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Pham T.D., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Park K.R., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea","Among biometric recognition systems such as fingerprint, finger-vein, or face, the iris recognition system has proven to be effective for achieving a high recognition accuracy and security level. However, several recent studies have indicated that an iris recognition system can be fooled by using presentation attack images that are recaptured using high-quality printed images or by contact lenses with printed iris patterns. As a result, this potential threat can reduce the security level of an iris recognition system. In this study, we propose a new presentation attack detection (PAD) method for an iris recognition system (iPAD) using a near infrared light (NIR) camera image. To detect presentation attack images, we first localized the iris region of the input iris image using circular edge detection (CED). Based on the result of iris localization, we extracted the image features using deep learning-based and handcrafted-based methods. The input iris images were then classified into real and presentation attack categories using support vector machines (SVM). Through extensive experiments with two public datasets, we show that our proposed method effectively solves the iris recognition presentation attack detection problem and produces detection accuracy superior to previous studies. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural network; Iris recognition; Presentation attack detection; Support vector machines","Biometrics; Cameras; Deep learning; Edge detection; Infrared devices; Neural networks; Support vector machines; Attack detection; Biometric recognition system; Convolutional neural network; Detection accuracy; Iris recognition; Iris recognition systems; Near infrared light; Recognition accuracy; Pattern recognition systems","MDPI AG","14248220","","","29695113","Article","Scopus","2-s2.0-85046073008"
"Ting D.S.W.; Liu Y.; Burlina P.; Xu X.; Bressler N.M.; Wong T.Y.","Ting, Daniel S. W. (37010354600); Liu, Yong (55187331400); Burlina, Philippe (6603713214); Xu, Xinxing (56091418600); Bressler, Neil M. (7005055349); Wong, Tien Y. (7403147159)","37010354600; 55187331400; 6603713214; 56091418600; 7005055349; 7403147159","AI for medical imaging goes deep","2018","Nature Medicine","130","10.1038/s41591-018-0029-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046542182&doi=10.1038%2fs41591-018-0029-3&partnerID=40&md5=b3f5a6069d16033b2b8640479681701b","Singapore National Eye Center, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Institute of High Performance Computing, Agency for Science, Technology and Research (ASTAR), Singapore, Singapore; Applied Physics Laboratory, Johns Hopkins University, Baltimore, MD, United States; Wilmer Eye Institute, Johns Hopkins University, Baltimore, MD, United States","Ting D.S.W., Singapore National Eye Center, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore, Institute of High Performance Computing, Agency for Science, Technology and Research (ASTAR), Singapore, Singapore; Liu Y., Institute of High Performance Computing, Agency for Science, Technology and Research (ASTAR), Singapore, Singapore; Burlina P., Applied Physics Laboratory, Johns Hopkins University, Baltimore, MD, United States; Xu X., Institute of High Performance Computing, Agency for Science, Technology and Research (ASTAR), Singapore, Singapore; Bressler N.M., Wilmer Eye Institute, Johns Hopkins University, Baltimore, MD, United States; Wong T.Y., Singapore National Eye Center, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore","An artificial intelligence (AI) using a deep-learning approach can classify retinal images from optical coherence tomography for early diagnosis of retinal diseases and has the potential to be used in other image-based medical diagnoses. © 2018 Nature America Inc., part of Springer Nature. All rights reserved.","","Artificial Intelligence; Deep Learning; Diagnostic Imaging; Humans; Imaging, Three-Dimensional; Article; diabetes mellitus; diabetic macular edema; diagnostic accuracy; diagnostic imaging; drusen; human; machine learning; nerve cell; optical coherence tomography; pneumonia; priority journal; subretinal neovascularization; thorax radiography; United States; artificial intelligence; three dimensional imaging","Nature Publishing Group","10788956","","NAMEF","29736024","Article","Scopus","2-s2.0-85046542182"
"Fioravanti D.; Giarratano Y.; Maggio V.; Agostinelli C.; Chierici M.; Jurman G.; Furlanello C.","Fioravanti, Diego (57201116861); Giarratano, Ylenia (57201115815); Maggio, Valerio (36675258000); Agostinelli, Claudio (35323943900); Chierici, Marco (16070093000); Jurman, Giuseppe (6602367398); Furlanello, Cesare (6701821823)","57201116861; 57201115815; 36675258000; 35323943900; 16070093000; 6602367398; 6701821823","Phylogenetic convolutional neural networks in metagenomics","2018","BMC Bioinformatics","57","10.1186/s12859-018-2033-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043448826&doi=10.1186%2fs12859-018-2033-5&partnerID=40&md5=6f9048f611804f32fd6f4caf7cf3a717","Fondazione Bruno Kessler (FBK), Via Sommarive 18 Povo, Trento, I-38123, Italy; Max Planck Institute for Intelligent Systems, Spemannstraße 34, Tübingen, 72076, Germany; University of Edinburgh, Centre for Medical Informatics, Usher Institute, 9 Little France Road, Edinburgh, EH16 4UX, United Kingdom; University of Trento, Department of Mathematics, Via Sommarive 14 Povo, Trento, I-38123, Italy","Fioravanti D., Fondazione Bruno Kessler (FBK), Via Sommarive 18 Povo, Trento, I-38123, Italy, Max Planck Institute for Intelligent Systems, Spemannstraße 34, Tübingen, 72076, Germany; Giarratano Y., University of Edinburgh, Centre for Medical Informatics, Usher Institute, 9 Little France Road, Edinburgh, EH16 4UX, United Kingdom; Maggio V., Fondazione Bruno Kessler (FBK), Via Sommarive 18 Povo, Trento, I-38123, Italy; Agostinelli C., University of Trento, Department of Mathematics, Via Sommarive 14 Povo, Trento, I-38123, Italy; Chierici M., Fondazione Bruno Kessler (FBK), Via Sommarive 18 Povo, Trento, I-38123, Italy; Jurman G., Fondazione Bruno Kessler (FBK), Via Sommarive 18 Povo, Trento, I-38123, Italy; Furlanello C., Fondazione Bruno Kessler (FBK), Via Sommarive 18 Povo, Trento, I-38123, Italy","Background: Convolutional Neural Networks can be effectively used only when data are endowed with an intrinsic concept of neighbourhood in the input space, as is the case of pixels in images. We introduce here Ph-CNN, a novel deep learning architecture for the classification of metagenomics data based on the Convolutional Neural Networks, with the patristic distance defined on the phylogenetic tree being used as the proximity measure. The patristic distance between variables is used together with a sparsified version of MultiDimensional Scaling to embed the phylogenetic tree in a Euclidean space. Results: Ph-CNN is tested with a domain adaptation approach on synthetic data and on a metagenomics collection of gut microbiota of 38 healthy subjects and 222 Inflammatory Bowel Disease patients, divided in 6 subclasses. Classification performance is promising when compared to classical algorithms like Support Vector Machines and Random Forest and a baseline fully connected neural network, e.g. the Multi-Layer Perceptron. Conclusion: Ph-CNN represents a novel deep learning approach for the classification of metagenomics data. Operatively, the algorithm has been implemented as a custom Keras layer taking care of passing to the following convolutional layer not only the data but also the ranked list of neighbourhood of each sample, thus mimicking the case of image data, transparently to the user. © 2018 The Author(s).","Convolutional neural networks; Deep learning; Metagenomics; Phylogenetic trees","Algorithms; Data Analysis; Databases, Genetic; Humans; Inflammatory Bowel Diseases; Metagenomics; Neural Networks (Computer); Phylogeny; Principal Component Analysis; Reproducibility of Results; Support Vector Machine; Bioinformatics; Convolution; Decision trees; Deep learning; Neural networks; Classification performance; Convolutional neural network; Fully connected neural network; Inflammatory bowel disease; Metagenomics; Multi layer perceptron; Multi-dimensional scaling; Phylogenetic trees; algorithm; artificial neural network; data analysis; genetic database; genetics; human; inflammatory bowel disease; metagenomics; phylogeny; principal component analysis; reproducibility; support vector machine; Classification (of information)","BioMed Central Ltd.","14712105","","BBMIC","29536822","Article","Scopus","2-s2.0-85043448826"
"Chen Z.; Zhang C.; Zhao Z.; Yao C.; Cai D.","Chen, Zheqian (57200548946); Zhang, Chi (57202085590); Zhao, Zhou (55959624600); Yao, Chengwei (55420945300); Cai, Deng (35228598300)","57200548946; 57202085590; 55959624600; 55420945300; 35228598300","Question retrieval for community-based question answering via heterogeneous social influential network","2018","Neurocomputing","35","10.1016/j.neucom.2018.01.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041621612&doi=10.1016%2fj.neucom.2018.01.034&partnerID=40&md5=836882d80c5ae45d3fccb8ff62a385d4","State Key Lab of CAD & CG, Zhejiang University, Hangzhou, 310058, Zhejiang, China","Chen Z., State Key Lab of CAD & CG, Zhejiang University, Hangzhou, 310058, Zhejiang, China; Zhang C., State Key Lab of CAD & CG, Zhejiang University, Hangzhou, 310058, Zhejiang, China; Zhao Z., State Key Lab of CAD & CG, Zhejiang University, Hangzhou, 310058, Zhejiang, China; Yao C., State Key Lab of CAD & CG, Zhejiang University, Hangzhou, 310058, Zhejiang, China; Cai D., State Key Lab of CAD & CG, Zhejiang University, Hangzhou, 310058, Zhejiang, China","Community-based question answering platforms have attracted substantial users to share knowledge and learn from each other. As the rapid enlargement of community-based question answering (CQA) platforms, quantities of overlapped questions emerge, which makes users confounded to select a proper reference. It is urgent for us to take effective automated algorithms to reuse historical questions with corresponding answers. In this paper, we focus on the problem with question retrieval, which aims to match historical questions that are relevant or semantically equivalent to resolve one's query directly. The challenges in this task are the lexical gaps between questions for the word ambiguity and word mismatch problem. Furthermore, limited words in queried sentences cause sparsity of word features. To alleviate these challenges, we propose a novel framework named HSIN which encodes not only the question contents but also the asker's social interactions to enhance the question embedding performance. More specifically, we apply random walk based learning method with recurrent neural network to match the similarities between asker's question and historical questions proposed by other users. Extensive experiments on a large-scale dataset from a real world CQA site Quora show that employing the heterogeneous social network information outperforms the other state-of-the-art solutions in this task. © 2018 Elsevier B.V.","CQA; Deep learning; Question retrieval; Social network","Recurrent neural networks; Social networking (online); Automated algorithms; Community-based question answering; Large-scale dataset; Mismatch problems; Question retrieval; Question-embedding; Social interactions; Social network informations; Article; artificial neural network; heterogeneous social influential network; information retrieval; machine learning; network learning; priority journal; random walk; recurrent neural network; social interaction; social network; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85041621612"
"Wang Z.; Hu M.; Zhai G.","Wang, Zhaodi (57200649872); Hu, Menghan (55818700700); Zhai, Guangtao (15847120000)","57200649872; 55818700700; 15847120000","Application of deep learning architectures for accurate and rapid detection of internal mechanical damage of blueberry using hyperspectral transmittance data","2018","Sensors (Switzerland)","112","10.3390/s18041126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045117620&doi=10.3390%2fs18041126&partnerID=40&md5=3eea2511f3ac04fd7bb849c22bb18a4f","Institute of Image Communication and Information Processing, Shanghai Jiao Tong University, Shanghai, 200240, China","Wang Z., Institute of Image Communication and Information Processing, Shanghai Jiao Tong University, Shanghai, 200240, China; Hu M., Institute of Image Communication and Information Processing, Shanghai Jiao Tong University, Shanghai, 200240, China; Zhai G., Institute of Image Communication and Information Processing, Shanghai Jiao Tong University, Shanghai, 200240, China","Deep learning has become a widely used powerful tool in many research fields, although not much so yet in agriculture technologies. In this work, two deep convolutional neural networks (CNN), viz. Residual Network (ResNet) and its improved version named ResNeXt, are used to detect internal mechanical damage of blueberries using hyperspectral transmittance data. The original structure and size of hypercubes are adapted for the deep CNN training. To ensure that the models are applicable to hypercube, we adjust the number of filters in the convolutional layers. Moreover, a total of 5 traditional machine learning algorithms, viz. Sequential Minimal Optimization (SMO), Linear Regression (LR), Random Forest (RF), Bagging and Multilayer Perceptron (MLP), are performed as the comparison experiments. In terms of model assessment, k-fold cross validation is used to indicate that the model performance does not vary with the different combination of dataset. In real-world application, selling damaged berries will lead to greater interest loss than discarding the sound ones. Thus, precision, recall, and F1-score are also used as the evaluation indicators alongside accuracy to quantify the false positive rate. The first three indicators are seldom used by investigators in the agricultural engineering domain. Furthermore, ROC curves and Precision-Recall curves are plotted to visualize the performance of classifiers. The fine-tuned ResNet/ResNeXt achieve average accuracy and F1-score of 0.8844/0.8784 and 0.8952/0.8905, respectively. Classifiers SMO/ LR/RF/Bagging/MLP obtain average accuracy and F1-score of 0.8082/0.7606/0.7314/0.7113/0.7827 and 0.8268/0.7796/0.7529/0.7339/0.7971, respectively. Two deep learning models achieve better classification performance than the traditional machine learning methods. Classification for each testing sample only takes 5.2 ms and 6.5 ms respectively for ResNet and ResNeXt, indicating that the deep learning framework has great potential for online fruit sorting. The results of this study demonstrate the potential of deep CNN application on analyzing the internal mechanical damage of fruit. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Fruit quality detection; Hyperspectral transmittance image; Internal mechanical damage detection; Machine learning","Algorithms; Blueberry Plants; Machine Learning; Neural Networks (Computer); ROC Curve; Time Factors; Agricultural machinery; Convolution; Damage detection; Decision trees; Deep neural networks; Fruits; Learning systems; Neural networks; Optimization; Classification performance; Convolutional neural network; Deep convolutional neural networks; Fruit quality; Mechanical damages; Performance of classifier; Sequential minimal optimization; Transmittance images; algorithm; artificial neural network; blueberry; machine learning; receiver operating characteristic; time factor; Learning algorithms","MDPI AG","14248220","","","29642454","Article","Scopus","2-s2.0-85045117620"
"Sun B.; Lam D.; Yang D.; Grantham K.; Zhang T.; Mutic S.; Zhao T.","Sun, Baozhou (36648110300); Lam, Dao (35409628600); Yang, Deshan (57203771564); Grantham, Kevin (56958238800); Zhang, Tiezhi (7404373557); Mutic, Sasa (7004029328); Zhao, Tianyu (55385417100)","36648110300; 35409628600; 57203771564; 56958238800; 7404373557; 7004029328; 55385417100","A machine learning approach to the accurate prediction of monitor units for a compact proton machine","2018","Medical Physics","26","10.1002/mp.12842","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044312259&doi=10.1002%2fmp.12842&partnerID=40&md5=aa7ca13ee007c985fdda7d909e95424f","Department of Radiation Oncology, Washington University School of Medicine, 4921 Parkview Place, Campus Box 8224, St. Louis, 63110, MO, United States","Sun B., Department of Radiation Oncology, Washington University School of Medicine, 4921 Parkview Place, Campus Box 8224, St. Louis, 63110, MO, United States; Lam D., Department of Radiation Oncology, Washington University School of Medicine, 4921 Parkview Place, Campus Box 8224, St. Louis, 63110, MO, United States; Yang D., Department of Radiation Oncology, Washington University School of Medicine, 4921 Parkview Place, Campus Box 8224, St. Louis, 63110, MO, United States; Grantham K., Department of Radiation Oncology, Washington University School of Medicine, 4921 Parkview Place, Campus Box 8224, St. Louis, 63110, MO, United States; Zhang T., Department of Radiation Oncology, Washington University School of Medicine, 4921 Parkview Place, Campus Box 8224, St. Louis, 63110, MO, United States; Mutic S., Department of Radiation Oncology, Washington University School of Medicine, 4921 Parkview Place, Campus Box 8224, St. Louis, 63110, MO, United States; Zhao T., Department of Radiation Oncology, Washington University School of Medicine, 4921 Parkview Place, Campus Box 8224, St. Louis, 63110, MO, United States","Purpose: Clinical treatment planning systems for proton therapy currently do not calculate monitor units (MUs) in passive scatter proton therapy due to the complexity of the beam delivery systems. Physical phantom measurements are commonly employed to determine the field-specific output factors (OFs) but are often subject to limited machine time, measurement uncertainties and intensive labor. In this study, a machine learning-based approach was developed to predict output (cGy/MU) and derive MUs, incorporating the dependencies on gantry angle and field size for a single-room proton therapy system. The goal of this study was to develop a secondary check tool for OF measurements and eventually eliminate patient-specific OF measurements. Method: The OFs of 1754 fields previously measured in a water phantom with calibrated ionization chambers and electrometers for patient-specific fields with various range and modulation width combinations for 23 options were included in this study. The training data sets for machine learning models in three different methods (Random Forest, XGBoost and Cubist) included 1431 (~81%) OFs. Ten-fold cross-validation was used to prevent “overfitting” and to validate each model. The remaining 323 (~19%) OFs were used to test the trained models. The difference between the measured and predicted values from machine learning models was analyzed. Model prediction accuracy was also compared with that of the semi-empirical model developed by Kooy (Phys. Med. Biol. 50, 2005). Additionally, gantry angle dependence of OFs was measured for three groups of options categorized on the selection of the second scatters. Field size dependence of OFs was investigated for the measurements with and without patient-specific apertures. Results: All three machine learning methods showed higher accuracy than the semi-empirical model which shows considerably large discrepancy of up to 7.7% for the treatment fields with full range and full modulation width. The Cubist-based solution outperformed all other models (P < 0.001) with the mean absolute discrepancy of 0.62% and maximum discrepancy of 3.17% between the measured and predicted OFs. The OFs showed a small dependence on gantry angle for small and deep options while they were constant for large options. The OF decreased by 3%–4% as the field radius was reduced to 2.5 cm. Conclusion: Machine learning methods can be used to predict OF for double-scatter proton machines with greater prediction accuracy than the most popular semi-empirical prediction model. By incorporating the gantry angle dependence and field size dependence, the machine learning-based methods can be used for a sanity check of OF measurements and bears the potential to eliminate the time-consuming patient-specific OF measurements. © 2018 American Association of Physicists in Medicine","machine learning; monitor units; output factor; proton therapy","Humans; Machine Learning; Phantoms, Imaging; Proton Therapy; Radiotherapy Planning, Computer-Assisted; Scattering, Radiation; Decision trees; Electrometers; Forecasting; Ionization of liquids; Modulation; Phantoms; Proton beam therapy; Proton beams; Uncertainty analysis; Field size; Gantry angles; Machine learning models; Machine-learning; Monitor units; Output factor measurements; Output factors; Patient specific; Prediction accuracy; Proton therapy; Article; comparative study; decision tree; learning curve; machine learning; magnetic field; measurement accuracy; prediction; proton radiation; proton therapy; random forest; time; human; imaging phantom; procedures; proton therapy; radiation scattering; radiotherapy planning system; Machine learning","John Wiley and Sons Ltd","00942405","","MPHYA","29500818","Article","Scopus","2-s2.0-85044312259"
"Gibson E.; Li W.; Sudre C.; Fidon L.; Shakir D.I.; Wang G.; Eaton-Rosen Z.; Gray R.; Doel T.; Hu Y.; Whyntie T.; Nachev P.; Modat M.; Barratt D.C.; Ourselin S.; Cardoso M.J.; Vercauteren T.","Gibson, Eli (36026807300); Li, Wenqi (55823995400); Sudre, Carole (56198868700); Fidon, Lucas (57194528760); Shakir, Dzhoshkun I. (38562092100); Wang, Guotai (55682589900); Eaton-Rosen, Zach (55890955800); Gray, Robert (57212016427); Doel, Tom (55331921900); Hu, Yipeng (24512208500); Whyntie, Tom (57541821400); Nachev, Parashkev (6602253325); Modat, Marc (24376919100); Barratt, Dean C. (7005201740); Ourselin, Sébastien (6602233595); Cardoso, M. Jorge (57204636980); Vercauteren, Tom (23010613000)","36026807300; 55823995400; 56198868700; 57194528760; 38562092100; 55682589900; 55890955800; 57212016427; 55331921900; 24512208500; 57541821400; 6602253325; 24376919100; 7005201740; 6602233595; 57204636980; 23010613000","NiftyNet: a deep-learning platform for medical imaging","2018","Computer Methods and Programs in Biomedicine","419","10.1016/j.cmpb.2018.01.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041815481&doi=10.1016%2fj.cmpb.2018.01.025&partnerID=40&md5=eb8bfaacd938df03278876a7aedeacdb","Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom; Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, United Kingdom; Institute of Neurology, University College London, United Kingdom; National Hospital for Neurology and Neurosurgery, London, United Kingdom","Gibson E., Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom, Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, United Kingdom; Li W., Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom; Sudre C., Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, United Kingdom; Fidon L., Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom; Shakir D.I., Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom; Wang G., Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom; Eaton-Rosen Z., Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, United Kingdom; Gray R., Institute of Neurology, University College London, United Kingdom, National Hospital for Neurology and Neurosurgery, London, United Kingdom; Doel T., Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom; Hu Y., Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, United Kingdom; Whyntie T., Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, United Kingdom; Nachev P., Institute of Neurology, University College London, United Kingdom, National Hospital for Neurology and Neurosurgery, London, United Kingdom; Modat M., Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, United Kingdom; Barratt D.C., Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom, Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, United Kingdom; Ourselin S., Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom; Cardoso M.J., Centre for Medical Image Computing (CMIC), Departments of Medical Physics & Biomedical Engineering and Computer Science, University College London, United Kingdom; Vercauteren T., Wellcome / EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, United Kingdom","Background and objectives: Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. Established deep-learning platforms are flexible but do not provide specific functionality for medical image analysis and adapting them for this domain of application requires substantial implementation effort. Consequently, there has been substantial duplication of effort and incompatible infrastructure developed across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon. Methods: The NiftyNet infrastructure provides a modular deep-learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications. Components of the NiftyNet pipeline including data loading, data augmentation, network architectures, loss functions and evaluation metrics are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted intervention. NiftyNet is built on the TensorFlow framework and supports features such as TensorBoard visualization of 2D and 3D images and computational graphs by default. Results: We present three illustrative medical image analysis applications built using NiftyNet infrastructure: (1) segmentation of multiple abdominal organs from computed tomography; (2) image regression to predict computed tomography attenuation maps from brain magnetic resonance images; and (3) generation of simulated ultrasound images for specified anatomical poses. Conclusions: The NiftyNet infrastructure enables researchers to rapidly develop and distribute deep learning solutions for segmentation, regression, image generation and representation learning applications, or extend the platform to new applications. © 2018 The Authors","Convolutional neural network; Deep learning; Generative adversarial network; Image regression; Medical image analysis; Segmentation","Abdomen; Brain; Computer Simulation; Databases, Factual; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Ultrasonography; Computer aided analysis; Computer aided instruction; Computerized tomography; E-learning; Image analysis; Image segmentation; Magnetic resonance; Magnetic resonance imaging; Medical image processing; Medical imaging; Medical problems; Network architecture; Neural networks; Pipelines; Regression analysis; Three dimensional computer graphics; Adversarial networks; Brain magnetic resonance images; Computational graph; Convolutional neural network; Evaluation metrics; Image regression; Imaging applications; Learning platform; article; attenuation; brain; computer assisted tomography; diagnostic imaging; human; image analysis; learning; loss of function mutation; nuclear magnetic resonance; pipeline; scientist; simulation; ultrasound; abdomen; artificial neural network; brain; computer simulation; devices; diagnostic imaging; echography; factual database; image processing; machine learning; nuclear magnetic resonance imaging; procedures; Deep learning","Elsevier Ireland Ltd","01692607","","CMPBE","29544777","Article","Scopus","2-s2.0-85041815481"
"Yousefi M.; Krzyżak A.; Suen C.Y.","Yousefi, Mina (56185661200); Krzyżak, Adam (7006444972); Suen, Ching Y. (7102317250)","56185661200; 7006444972; 7102317250","Mass detection in digital breast tomosynthesis data using convolutional neural networks and multiple instance learning","2018","Computers in Biology and Medicine","75","10.1016/j.compbiomed.2018.04.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045388355&doi=10.1016%2fj.compbiomed.2018.04.004&partnerID=40&md5=5e2ed464daa13950c7f5b2f7176519ed","Department of Computer Science and Software Engineering Concordia University, 1455 De Maisonneuve Blvd. W, Montreal, H3G 1M8, Quebec, Canada","Yousefi M., Department of Computer Science and Software Engineering Concordia University, 1455 De Maisonneuve Blvd. W, Montreal, H3G 1M8, Quebec, Canada; Krzyżak A., Department of Computer Science and Software Engineering Concordia University, 1455 De Maisonneuve Blvd. W, Montreal, H3G 1M8, Quebec, Canada; Suen C.Y., Department of Computer Science and Software Engineering Concordia University, 1455 De Maisonneuve Blvd. W, Montreal, H3G 1M8, Quebec, Canada","Digital breast tomosynthesis (DBT) was developed in the field of breast cancer screening as a new tomographic technique to minimize the limitations of conventional digital mammography breast screening methods. A computer-aided detection (CAD) framework for mass detection in DBT has been developed and is described in this paper. The proposed framework operates on a set of two-dimensional (2D) slices. With plane-to-plane analysis on corresponding 2D slices from each DBT, it automatically learns complex patterns of 2D slices through a deep convolutional neural network (DCNN). It then applies multiple instance learning (MIL) with a randomized trees approach to classify DBT images based on extracted information from 2D slices. This CAD framework was developed and evaluated using 5040 2D image slices derived from 87 DBT volumes. The empirical results demonstrate that this proposed CAD framework achieves much better performance than CAD systems that use hand-crafted features and deep cardinality-restricted Bolzmann machines to detect masses in DBTs. © 2018 Elsevier Ltd","Computer-aided detection; Deep convolutional neural networks; Deep learning; Digital breast tomosynthesis; Masses; Multiple instance learning","Algorithms; Breast; Breast Neoplasms; Deep Learning; Female; Humans; Mammography; Radiographic Image Interpretation, Computer-Assisted; Classification (of information); Computer aided instruction; Convolution; Deep learning; Deep neural networks; E-learning; Mammography; Neural networks; Tomography; Computer aided detection; Deep convolutional neural networks; Digital breast tomosynthesis; Masses; Multiple instance learning; Article; clinical feature; convolutional neural network; digital breast tomosynthesis; general hospital; human; learning; Massachusetts; multiple instance learning; nerve cell network; priority journal; radiologist; task performance; two-dimensional imaging; algorithm; breast; breast tumor; computer assisted diagnosis; diagnostic imaging; female; mammography; procedures; Computer aided diagnosis","Elsevier Ltd","00104825","","CBMDA","29665537","Article","Scopus","2-s2.0-85045388355"
"Li J.; Zhang Z.; He H.","Li, Jinpeng (54385263700); Zhang, Zhaoxiang (8066042700); He, Huiguang (16177199000)","54385263700; 8066042700; 16177199000","Hierarchical Convolutional Neural Networks for EEG-Based Emotion Recognition","2018","Cognitive Computation","208","10.1007/s12559-017-9533-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038124979&doi=10.1007%2fs12559-017-9533-x&partnerID=40&md5=37e92505f5214720520701c3d1445f2a","Research Center for Brain-inspired Intelligence, Institute of Automation, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences (UCAS), Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Beijing, China","Li J., Research Center for Brain-inspired Intelligence, Institute of Automation, Chinese Academy of Sciences, Beijing, China, University of Chinese Academy of Sciences (UCAS), Beijing, China; Zhang Z., Research Center for Brain-inspired Intelligence, Institute of Automation, Chinese Academy of Sciences, Beijing, China, University of Chinese Academy of Sciences (UCAS), Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Beijing, China; He H., Research Center for Brain-inspired Intelligence, Institute of Automation, Chinese Academy of Sciences, Beijing, China, University of Chinese Academy of Sciences (UCAS), Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Beijing, China","Traditional machine learning methods suffer from severe overfitting in EEG-based emotion reading. In this paper, we use hierarchical convolutional neural network (HCNN) to classify the positive, neutral, and negative emotion states. We organize differential entropy features from different channels as two-dimensional maps to train the HCNNs. This approach maintains information in the spatial topology of electrodes. We use stacked autoencoder (SAE), SVM, and KNN as competing methods. HCNN yields the highest accuracy, and SAE is slightly inferior. Both of them show absolute advantage over traditional shallow models including SVM and KNN. We confirm that the high-frequency wave bands Beta and Gamma are the most suitable bands for emotion reading. We visualize the hidden layers of HCNNs to investigate the feature transformation flow along the hierarchical structure. Benefiting from the strong representational learning capacity in the two-dimensional space, HCNN is efficient in emotion recognition especially on Beta and Gamma waves. © 2017, Springer Science+Business Media, LLC, part of Springer Nature.","Affective brain-computer interface; Brain wave; Deep learning; EEG; Emotion recognition","Brain computer interface; Convolution; Deep learning; Electroencephalography; Interfaces (computer); Learning systems; Neural networks; Brain wave; Convolutional neural network; Differential entropy; Emotion recognition; Feature transformations; Hierarchical structures; Machine learning methods; Two dimensional spaces; Speech recognition","Springer New York LLC","18669956","","","","Article","Scopus","2-s2.0-85038124979"
"Takase T.; Oyama S.; Kurihara M.","Takase, Tomoumi (57200818101); Oyama, Satoshi (13906820100); Kurihara, Masahito (55334310200)","57200818101; 13906820100; 55334310200","Effective neural network training with adaptive learning rate based on training loss","2018","Neural Networks","96","10.1016/j.neunet.2018.01.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042489577&doi=10.1016%2fj.neunet.2018.01.016&partnerID=40&md5=242aca3a56dc01532cfdcb25d543c888","Graduate School of Information Science and Technology, Hokkaido University, Kita 14 Nishi 9 Kita-ku, Sapporo, Japan","Takase T., Graduate School of Information Science and Technology, Hokkaido University, Kita 14 Nishi 9 Kita-ku, Sapporo, Japan; Oyama S., Graduate School of Information Science and Technology, Hokkaido University, Kita 14 Nishi 9 Kita-ku, Sapporo, Japan; Kurihara M., Graduate School of Information Science and Technology, Hokkaido University, Kita 14 Nishi 9 Kita-ku, Sapporo, Japan","A method that uses an adaptive learning rate is presented for training neural networks. Unlike most conventional updating methods in which the learning rate gradually decreases during training, the proposed method increases or decreases the learning rate adaptively so that the training loss (the sum of cross-entropy losses for all training samples) decreases as much as possible. It thus provides a wider search range for solutions and thus a lower test error rate. The experiments with some well-known datasets to train a multilayer perceptron show that the proposed method is effective for obtaining a better test accuracy under certain conditions. © 2018 Elsevier Ltd","Beam search; Deep learning; Learning rate; Multilayer perceptron; Neural network training; Stochastic gradient descent","Entropy; Machine Learning; Neural Networks (Computer); Learning algorithms; Multilayer neural networks; Multilayers; Neural networks; Stochastic systems; Adaptive learning rates; Beam search; Learning rates; Neural network training; Stochastic gradient descent; Test accuracy; Training sample; Updating methods; accuracy; adaptive learning; algorithm; Article; artificial neural network; automation; convolutional neural network; entropy; intermethod comparison; learning; mathematical computing; priority journal; process optimization; reinforcement; task performance; machine learning; Deep learning","Elsevier Ltd","08936080","","NNETE","29494873","Article","Scopus","2-s2.0-85042489577"
"Lyon A.; Ariga R.; Mincholé A.; Mahmod M.; Ormondroyd E.; Laguna P.; de Freitas N.; Neubauer S.; Watkins H.; Rodriguez B.","Lyon, Aurore (57188873560); Ariga, Rina (36674671600); Mincholé, Ana (23389571900); Mahmod, Masliza (26648842800); Ormondroyd, Elizabeth (6506615403); Laguna, Pablo (56216881700); de Freitas, Nando (6602751682); Neubauer, Stefan (55794522200); Watkins, Hugh (7004286071); Rodriguez, Blanca (35594111500)","57188873560; 36674671600; 23389571900; 26648842800; 6506615403; 56216881700; 6602751682; 55794522200; 7004286071; 35594111500","Distinct ECG phenotypes identified in hypertrophic cardiomyopathy using machine learning associate with arrhythmic risk markers","2018","Frontiers in Physiology","58","10.3389/fphys.2018.00213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043516149&doi=10.3389%2ffphys.2018.00213&partnerID=40&md5=ee8df8e481cd49f7ccd06ec285060d3d","Department of Computer Science, University of Oxford, Oxford, United Kingdom; Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Biomedical Signal Interpretation and Computational Simulation Group, CIBER-BBN, University of Zaragoza, Zaragoza, Spain","Lyon A., Department of Computer Science, University of Oxford, Oxford, United Kingdom; Ariga R., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Mincholé A., Department of Computer Science, University of Oxford, Oxford, United Kingdom; Mahmod M., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Ormondroyd E., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Laguna P., Biomedical Signal Interpretation and Computational Simulation Group, CIBER-BBN, University of Zaragoza, Zaragoza, Spain; de Freitas N., Department of Computer Science, University of Oxford, Oxford, United Kingdom; Neubauer S., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Watkins H., Division of Cardiovascular Medicine, Radcliffe Department of Medicine, University of Oxford, Oxford, United Kingdom; Rodriguez B., Department of Computer Science, University of Oxford, Oxford, United Kingdom","Aims: Ventricular arrhythmia triggers sudden cardiac death (SCD) in hypertrophic cardiomyopathy (HCM), yet electrophysiological biomarkers are not used for risk stratification. Our aim was to identify distinct HCM phenotypes based on ECG computational analysis, and characterize differences in clinical risk factors and anatomical differences using cardiac magnetic resonance (CMR) imaging. Methods: High-fidelity 12-lead Holter ECGs from 85 HCM patients and 38 healthy volunteers were analyzed using mathematical modeling and computational clustering to identify phenotypic subgroups. Clinical features and the extent and distribution of hypertrophy assessed by CMR were evaluated in the subgroups. Results: QRS morphology alone was crucial to identify three HCM phenotypes with very distinct QRS patterns. Group 1 (n = 44) showed normal QRS morphology, Group 2 (n = 19) showed short R and deep S waves in V4, and Group 3 (n = 22) exhibited short R and long S waves in V4-6, and left QRS axis deviation. However, no differences in arrhythmic risk or distribution of hypertrophy were observed between these groups. Including T wave biomarkers in the clustering, four HCM phenotypes were identified: Group 1A (n = 20), with primary repolarization abnormalities showing normal QRS yet inverted T waves, Group 1B (n = 24), with normal QRS morphology and upright T waves, and Group 2 and Group 3 remaining as before, with upright T waves. Group 1A patients, with normal QRS and inverted T wave, showed increased HCM Risk-SCD scores (1A: 4.0%, 1B: 1.8%, 2: 2.1%, 3: 2.5%, p = 0.0001), and a predominance of coexisting septal and apical hypertrophy (p < 0.0001). HCM patients in Groups 2 and 3 exhibited predominantly septal hypertrophy (85 and 90%, respectively). Conclusion: HCM patients were classified in four subgroups with distinct ECG features. Patients with primary T wave inversion not secondary to QRS abnormalities had increased HCM Risk-SCD scores and coexisting septal and apical hypertrophy, suggesting that primary T wave inversion may increase SCD risk in HCM, rather than T wave inversion secondary to depolarization abnormalities. Computational ECG phenotyping provides insight into the underlying processes captured by the ECG and has the potential to be a novel and independent factor for risk stratification. © 2018 Lyon, Ariga, Mincholé, Mahmod, Ormondroyd, Laguna, de Freitas, Neubauer, Watkins and Rodriguez.","Computational clustering; E-cardiology; Electrocardiography; Hypertrophic cardiomyopathy; Phenotyping","adult; Article; asymptomatic disease; cardiovascular magnetic resonance; clinical feature; cohort analysis; controlled study; disease classification; female; follow up; Holter monitoring; human; hypertrophic cardiomyopathy; machine learning; major clinical study; male; mathematical model; middle aged; prospective study; QRS amplitude; QRS interval; R wave; risk factor; S wave amplitude; sudden cardiac death; T wave amplitude; T wave inversion","Frontiers Media S.A.","1664042X","","","","Article","Scopus","2-s2.0-85043516149"
"Küstner T.; Liebgott A.; Mauch L.; Martirosian P.; Bamberg F.; Nikolaou K.; Yang B.; Schick F.; Gatidis S.","Küstner, Thomas (56549927000); Liebgott, Annika (57189597296); Mauch, Lukas (55762682000); Martirosian, Petros (6506369484); Bamberg, Fabian (23975531900); Nikolaou, Konstantin (55744104000); Yang, Bin (55584795030); Schick, Fritz (7004668646); Gatidis, Sergios (26658018800)","56549927000; 57189597296; 55762682000; 6506369484; 23975531900; 55744104000; 55584795030; 7004668646; 26658018800","Automated reference-free detection of motion artifacts in magnetic resonance images","2018","Magnetic Resonance Materials in Physics, Biology and Medicine","66","10.1007/s10334-017-0650-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029592992&doi=10.1007%2fs10334-017-0650-z&partnerID=40&md5=984afb0ee1cfc2eb1173a8633b083b2b","University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany; Department of Radiology, University of Tübingen, Hoppe-Seyler-Str. 3, Tübingen, 72076, Germany","Küstner T., University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany, Department of Radiology, University of Tübingen, Hoppe-Seyler-Str. 3, Tübingen, 72076, Germany; Liebgott A., University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany, Department of Radiology, University of Tübingen, Hoppe-Seyler-Str. 3, Tübingen, 72076, Germany; Mauch L., University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany; Martirosian P., Department of Radiology, University of Tübingen, Hoppe-Seyler-Str. 3, Tübingen, 72076, Germany; Bamberg F., Department of Radiology, University of Tübingen, Hoppe-Seyler-Str. 3, Tübingen, 72076, Germany; Nikolaou K., Department of Radiology, University of Tübingen, Hoppe-Seyler-Str. 3, Tübingen, 72076, Germany; Yang B., University of Stuttgart, Institute of Signal Processing and System Theory, Stuttgart, Germany; Schick F., Department of Radiology, University of Tübingen, Hoppe-Seyler-Str. 3, Tübingen, 72076, Germany; Gatidis S., Department of Radiology, University of Tübingen, Hoppe-Seyler-Str. 3, Tübingen, 72076, Germany","Objectives: Our objectives were to provide an automated method for spatially resolved detection and quantification of motion artifacts in MR images of the head and abdomen as well as a quality control of the trained architecture. Materials and methods: T1-weighted MR images of the head and the upper abdomen were acquired in 16 healthy volunteers under rest and under motion. Images were divided into overlapping patches of different sizes achieving spatial separation. Using these patches as input data, a convolutional neural network (CNN) was trained to derive probability maps for the presence of motion artifacts. A deep visualization offers a human-interpretable quality control of the trained CNN. Results were visually assessed on probability maps and as classification accuracy on a per-patch, per-slice and per-volunteer basis. Results: On visual assessment, a clear difference of probability maps was observed between data sets with and without motion. The overall accuracy of motion detection on a per-patch/per-volunteer basis reached 97%/100% in the head and 75%/100% in the abdomen, respectively. Conclusion: Automated detection of motion artifacts in MRI is feasible with good accuracy in the head and abdomen. The proposed method provides quantification and localization of artifacts as well as a visualization of the learned content. It may be extended to other anatomic areas and used for quality assurance of MR images. © 2017, ESMRMB.","Artifacts; Machine learning; Neural networks; Quality assurance","Abdomen; Algorithms; Artifacts; Automatic Data Processing; Automation; Head; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Magnetic Resonance Imaging; Motion; Neural Networks (Computer); Probability; Quality Assurance, Health Care; Reproducibility of Results; Signal Processing, Computer-Assisted; abdomen; algorithm; artifact; artificial neural network; automation; diagnostic imaging; head; health care quality; human; image processing; information processing; machine learning; motion; nuclear magnetic resonance imaging; probability; procedures; reproducibility; signal processing; three dimensional imaging","Springer Verlag","09685243","","MRBME","28932991","Article","Scopus","2-s2.0-85029592992"
"Tsigelny I.F.","Tsigelny, Igor F (7003552153)","7003552153","Artificial intelligence in drug combination therapy","2018","Briefings in Bioinformatics","61","10.1093/bib/bby004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072968821&doi=10.1093%2fbib%2fbby004&partnerID=40&md5=fdd2e77eece90b008fa1ee9928f7ddfa","UCSD, 9500 Gilman Dr., San Diego, 92093-0505, CA, United States","Tsigelny I.F., UCSD, 9500 Gilman Dr., San Diego, 92093-0505, CA, United States","Currently, the development of medicines for complex diseases requires the development of combination drug therapies. It is necessary because in many cases, one drug cannot target all necessary points of intervention. For example, in cancer therapy, a physician often meets a patient having a genomic profile including more than five molecular aberrations. Drug combination therapy has been an area of interest for a while, for example the classical work of Loewe devoted to the synergism of drugs was published in 1928-and it is still used in calculations for optimal drug combinations. More recently, over the past several years, there has been an explosion in the available information related to the properties of drugs and the biomedical parameters of patients. For the drugs, hundreds of 2D and 3D molecular descriptors for medicines are now available, while for patients, large data sets related to genetic/proteomic and metabolomics profiles of the patients are now available, as well as the more traditional data relating to the histology, history of treatments, pretreatment state of the organism, etc. Moreover, during disease progression, the genetic profile can change. Thus, the ability to optimize drug combinations for each patient is rapidly moving beyond the comprehension and capabilities of an individual physician. This is the reason, that biomedical informatics methods have been developed and one of the more promising directions in this field is the application of artificial intelligence (AI). In this review, we discuss several AI methods that have been successfully implemented in several instances of combination drug therapy from HIV, hypertension, infectious diseases to cancer. The data clearly show that the combination of rule-based expert systems with machine learning algorithms may be promising direction in this field. © 2018 The Author(s) 2018. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.","artificial intelligence; combination therapy; drug combination; genomic profile; machine learning","Artificial Intelligence; Bayes Theorem; Computational Biology; Deep Learning; Drug Interactions; Drug Resistance; Drug Therapy, Combination; Expert Systems; Gene Expression Regulation, Neoplastic; Humans; Least-Squares Analysis; Logistic Models; Machine Learning; Neoplasms; Neural Networks, Computer; Stochastic Processes; Support Vector Machine; artificial intelligence; Bayes theorem; biology; combination drug therapy; comparative study; drug effect; drug interaction; drug resistance; expert system; gene expression regulation; genetics; human; least square analysis; machine learning; Markov chain; neoplasm; statistical model; support vector machine","Oxford University Press","14675463","","","29438494","Article","Scopus","2-s2.0-85072968821"
"Fang C.; Shang Y.; Xu D.","Fang, Chao (57201117004); Shang, Yi (7101867894); Xu, Dong (7404074295)","57201117004; 7101867894; 7404074295","MUFOLD-SS: New deep inception-inside-inception networks for protein secondary structure prediction","2018","Proteins: Structure, Function and Bioinformatics","120","10.1002/prot.25487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045841415&doi=10.1002%2fprot.25487&partnerID=40&md5=df0c1a99ae8e408a2623beae228c000a","Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, United States; Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, United States","Fang C., Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, United States; Shang Y., Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, United States; Xu D., Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, United States, Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, United States","Protein secondary structure prediction can provide important information for protein 3D structure prediction and protein functions. Deep learning offers a new opportunity to significantly improve prediction accuracy. In this article, a new deep neural network architecture, named the Deep inception-inside-inception (Deep3I) network, is proposed for protein secondary structure prediction and implemented as a software tool MUFOLD-SS. The input to MUFOLD-SS is a carefully designed feature matrix corresponding to the primary amino acid sequence of a protein, which consists of a rich set of information derived from individual amino acid, as well as the context of the protein sequence. Specifically, the feature matrix is a composition of physio-chemical properties of amino acids, PSI-BLAST profile, and HHBlits profile. MUFOLD-SS is composed of a sequence of nested inception modules and maps the input matrix to either eight states or three states of secondary structures. The architecture of MUFOLD-SS enables effective processing of local and global interactions between amino acids in making accurate prediction. In extensive experiments on multiple datasets, MUFOLD-SS outperformed the best existing methods and other deep neural networks significantly. MUFold-SS can be downloaded from http://dslsrv8.cs.missouri.edu/~cf797/MUFoldSS/download.html. © 2018 Wiley Periodicals, Inc.","deep learning; deep neural networks; protein secondary structure; protein structure prediction","Algorithms; Amino Acid Sequence; Amino Acids; Binding Sites; Deep Learning; Models, Molecular; Protein Binding; Protein Structure, Secondary; Proteins; Software; amino acid; protein; protein binding; access to information; amino acid sequence; Article; artificial neural network; data analysis software; intermethod comparison; Internet; machine learning; physical chemistry; prediction; priority journal; protein function; protein interaction; protein secondary structure; protein structure; sequence alignment; algorithm; binding site; chemistry; molecular model; software","John Wiley and Sons Inc.","08873585","","","29492997","Article","Scopus","2-s2.0-85045841415"
"Larson D.B.; Chen M.C.; Lungren M.P.; Halabi S.S.; Stence N.V.; Langlotz C.P.","Larson, David B. (35725554000); Chen, Matthew C. (57197876745); Lungren, Matthew P. (36729660500); Halabi, Safwan S. (56056991200); Stence, Nicholas V. (54781831500); Langlotz, Curtis P. (20134955200)","35725554000; 57197876745; 36729660500; 56056991200; 54781831500; 20134955200","Performance of a deep-learning neural network model in assessing skeletal maturity on pediatric hand radiographs","2018","Radiology","344","10.1148/radiol.2017170236","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044285842&doi=10.1148%2fradiol.2017170236&partnerID=40&md5=5f4e875204c919bcaa9ea3a726663db6","Departments of Radiology, 300 Pasteur Dr, Stanford, 94305-5105, CA, United States; Departments of Computer Science, 300 Pasteur Dr, Stanford, 94305-5105, CA, United States; Departments of Biomedical Informatics, Stanford University School of Medicine, 300 Pasteur Dr, Stanford, 94305-5105, CA, United States; Department of Radiology, Children's Hospital Colorado, Aurora, CO, United States","Larson D.B., Departments of Radiology, 300 Pasteur Dr, Stanford, 94305-5105, CA, United States; Chen M.C., Departments of Computer Science, 300 Pasteur Dr, Stanford, 94305-5105, CA, United States; Lungren M.P., Departments of Radiology, 300 Pasteur Dr, Stanford, 94305-5105, CA, United States; Halabi S.S., Departments of Radiology, 300 Pasteur Dr, Stanford, 94305-5105, CA, United States; Stence N.V., Department of Radiology, Children's Hospital Colorado, Aurora, CO, United States; Langlotz C.P., Departments of Radiology, 300 Pasteur Dr, Stanford, 94305-5105, CA, United States, Departments of Biomedical Informatics, Stanford University School of Medicine, 300 Pasteur Dr, Stanford, 94305-5105, CA, United States","Purpose: To compare the performance of a deep-learning bone age assessment model based on hand radiographs with that of expert radiologists and that of existing automated models. Materials and Methods: The institutional review board approved the study. A total of 14 036 clinical hand radiographs and corresponding reports were obtained from two children's hospitals to train and validate the model. For the first test set, composed of 200 examinations, the mean of bone age estimates from the clinical report and three additional human reviewers was used as the reference standard. Overall model performance was assessed by comparing the root mean square (RMS) and mean absolute difference (MAD) between the model estimates and the reference standard bone ages. Ninety-five percent limits of agreement were calculated in a pairwise fashion for all reviewers and the model. The RMS of a second test set composed of 913 examinations from the publicly available Digital Hand Atlas was compared with published reports of an existing automated model. Results: The mean difference between bone age estimates of the model and of the reviewers was 0 years, with a mean RMS and MAD of 0.63 and 0.50 years, respectively. The estimates of the model, the clinical report, and the three reviewers were within the 95% limits of agreement. RMS for the Digital Hand Atlas data set was 0.73 years, compared with 0.61 years of a previously reported model. Conclusion: A deep-learning convolutional neural network model can estimate skeletal maturity with accuracy similar to that of an expert radiologist and to that of existing automated models. © 2017 RSNA.","","Adolescent; Adult; Age Determination by Skeleton; Child; Child, Preschool; Female; Hand; Humans; Infant; Machine Learning; Male; Neural Networks (Computer); Radiography; Young Adult; Article; artificial neural network; bone age; bone age determination; bone maturation; child; female; hand radiography; human; learning; male; priority journal; statistical analysis; statistical model; adolescent; adult; anatomy and histology; diagnostic imaging; hand; infant; machine learning; preschool child; procedures; radiography; young adult","Radiological Society of North America Inc.","00338419","","RADLA","29095675","Article","Scopus","2-s2.0-85044285842"
"Drevinskas T.; Mickiene R.; Maruška A.; Stankevičius M.; Tiso N.; Šalomskas A.; Lelešius R.; Karpovaite A.; Ragažinskiene O.","Drevinskas, Tomas (54879389600); Mickiene, Rūta (43261699200); Maruška, Audrius (6603372618); Stankevičius, Mantas (36700351200); Tiso, Nicola (56891170900); Šalomskas, Algirdas (7801333790); Lelešius, Raimundas (14066270100); Karpovaite, Agneta (55744338000); Ragažinskiene, Ona (6508231437)","54879389600; 43261699200; 6603372618; 36700351200; 56891170900; 7801333790; 14066270100; 55744338000; 6508231437","Confirmation of the antiviral properties of medicinal plants via chemical analysis, machine learning methods and antiviral tests: A methodological approach","2018","Analytical Methods","18","10.1039/c8ay00318a","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046143328&doi=10.1039%2fc8ay00318a&partnerID=40&md5=4e2bc13a338a57829478f8a2225c526f","Faculty of Natural Sciences, Instrumental Analysis Open Access Centre, Vytautas Magnus University, Vileikos str. 8, Kaunas, LT44404, Lithuania; Department of Veterinary Pathobiology, Veterinary Academy, Lithuanian University of Health Science, Tilžes str.18, Kaunas, LT-47181, Lithuania; Institute of Microbiology and Virology, Veterinary Academy, Lithuanian University of Health Science, Tilžes str.18, Kaunas, LT-47181, Lithuania; Sector of Medicinal Plants, Kaunas Botanical Garden of Vytautas Magnus University, Z. E. Žilibero str. 6, Kaunas, LT-46324, Lithuania","Drevinskas T., Faculty of Natural Sciences, Instrumental Analysis Open Access Centre, Vytautas Magnus University, Vileikos str. 8, Kaunas, LT44404, Lithuania; Mickiene R., Faculty of Natural Sciences, Instrumental Analysis Open Access Centre, Vytautas Magnus University, Vileikos str. 8, Kaunas, LT44404, Lithuania; Maruška A., Faculty of Natural Sciences, Instrumental Analysis Open Access Centre, Vytautas Magnus University, Vileikos str. 8, Kaunas, LT44404, Lithuania; Stankevičius M., Faculty of Natural Sciences, Instrumental Analysis Open Access Centre, Vytautas Magnus University, Vileikos str. 8, Kaunas, LT44404, Lithuania; Tiso N., Faculty of Natural Sciences, Instrumental Analysis Open Access Centre, Vytautas Magnus University, Vileikos str. 8, Kaunas, LT44404, Lithuania; Šalomskas A., Department of Veterinary Pathobiology, Veterinary Academy, Lithuanian University of Health Science, Tilžes str.18, Kaunas, LT-47181, Lithuania; Lelešius R., Department of Veterinary Pathobiology, Veterinary Academy, Lithuanian University of Health Science, Tilžes str.18, Kaunas, LT-47181, Lithuania, Institute of Microbiology and Virology, Veterinary Academy, Lithuanian University of Health Science, Tilžes str.18, Kaunas, LT-47181, Lithuania; Karpovaite A., Department of Veterinary Pathobiology, Veterinary Academy, Lithuanian University of Health Science, Tilžes str.18, Kaunas, LT-47181, Lithuania; Ragažinskiene O., Sector of Medicinal Plants, Kaunas Botanical Garden of Vytautas Magnus University, Z. E. Žilibero str. 6, Kaunas, LT-46324, Lithuania","Medicinal plants are reported to possess antiviral activity, but finding the substances that are responsible for antiviral activity in the complex mixture of the plant extract is an extremely difficult task. In this paper a methodology related to the determination of the antiviral properties of medicinal plant extracts and based on phytochemical analysis, antiviral tests and machine learning methods is described. 16 potentially antiviral medicinal plants were selected, and their chemometric characteristics and antiviral properties were investigated. Three different analytical methods were used for chemical analysis: (i) spectrophotometry, (ii) capillary electrophoresis with contactless conductivity detection, and (iii) gas chromatography-mass spectrometry. 14 attributes were obtained describing the composition of the plant extracts. Viral growth inhibition properties were investigated and 8 candidate plant extracts were selected as being active against viruses. Infectious bronchitis virus was used as a model virus. Machine learning techniques including deep neural network classification, classification and regression tree induction and hierarchical clusterization were used for mining the factors that are responsible for antiviral effects. It was determined that (i) phenolic compounds providing high radical scavenging activity and fractions containing high content of phenolic compounds are positively related to antiviral activity in plant extracts, (ii) hydrophilic compounds that are positively charged (pKa > 4.7) in acidic media and possess medium and low electrophoretic mobility properties are negatively related to antiviral activity in medicinal plants, (iii) phenolic acids with pKa lower than 4.7 are not related to antiviral activity in the extracts, and (iv) volatile compounds in the extracts, including diversity, quantity and different volatility properties, do not affect the antiviral activity of plant extracts. Following the proposed methodological approach, it is possible to confirm which chemometric attributes are responsible for antiviral activity in medicinal plant extracts. © 2018 The Royal Society of Chemistry.","","Capillary electrophoresis; Chemical detection; Deep neural networks; Electrophoretic mobility; Gas chromatography; Mass spectrometry; Neural networks; Phenols; Viruses; Volatile organic compounds; Classification and regression tree; Contactless conductivity detection; Gas chromatography-mass spectrometry; Hierarchical clusterization; Machine learning methods; Machine learning techniques; Neural network classification; Radical scavenging activity; Plant extracts","Royal Society of Chemistry","17599660","","","","Article","Scopus","2-s2.0-85046143328"
"Behrmann J.; Etmann C.; Boskamp T.; Casadonte R.; Kriegsmann J.; Maaß P.","Behrmann, Jens (57201698451); Etmann, Christian (57201702756); Boskamp, Tobias (6507852134); Casadonte, Rita (22733247200); Kriegsmann, Jörg (7006516510); Maaß, Peter (7005621237)","57201698451; 57201702756; 6507852134; 22733247200; 7006516510; 7005621237","Deep learning for tumor classification in imaging mass spectrometry","2018","Bioinformatics","87","10.1093/bioinformatics/btx724","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045845974&doi=10.1093%2fbioinformatics%2fbtx724&partnerID=40&md5=eeee77460d81b81d2e62d954f15e407f","Center for Industrial Mathematics, University of Bremen, Bremen, 28359, Germany; SCiLS, Bremen, 28359, Germany; Proteopath GmbH, Trier, 54296, Germany; Center for Histology, Cytology and Molecular Diagnosis, Trier, 54296, Germany","Behrmann J., Center for Industrial Mathematics, University of Bremen, Bremen, 28359, Germany; Etmann C., Center for Industrial Mathematics, University of Bremen, Bremen, 28359, Germany; Boskamp T., Center for Industrial Mathematics, University of Bremen, Bremen, 28359, Germany, SCiLS, Bremen, 28359, Germany; Casadonte R., Proteopath GmbH, Trier, 54296, Germany; Kriegsmann J., Proteopath GmbH, Trier, 54296, Germany, Center for Histology, Cytology and Molecular Diagnosis, Trier, 54296, Germany; Maaß P., Center for Industrial Mathematics, University of Bremen, Bremen, 28359, Germany, SCiLS, Bremen, 28359, Germany","Motivation Tumor classification using imaging mass spectrometry (IMS) data has a high potential for future applications in pathology. Due to the complexity and size of the data, automated feature extraction and classification steps are required to fully process the data. Since mass spectra exhibit certain structural similarities to image data, deep learning may offer a promising strategy for classification of IMS data as it has been successfully applied to image classification. Results Methodologically, we propose an adapted architecture based on deep convolutional networks to handle the characteristics of mass spectrometry data, as well as a strategy to interpret the learned model in the spectral domain based on a sensitivity analysis. The proposed methods are evaluated on two algorithmically challenging tumor classification tasks and compared to a baseline approach. Competitiveness of the proposed methods is shown on both tasks by studying the performance via cross-validation. Moreover, the learned models are analyzed by the proposed sensitivity analysis revealing biologically plausible effects as well as confounding factors of the considered tasks. Thus, this study may serve as a starting point for further development of deep learning approaches in IMS classification tasks. Availability and implementation https://gitlab.informatik.uni-bremen.de/digipath/Deep-Learning-for-Tumor-Classification-in-IMS. Contact jbehrmann@uni-bremen.de or christianetmann@uni-bremen.de Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author 2017. Published by Oxford University Press. All rights reserved.","","Animals; Computational Biology; Humans; Mass Spectrometry; Neoplasm Proteins; Neoplasms; Supervised Machine Learning; tumor protein; animal; biology; classification; human; mass spectrometry; metabolism; neoplasm; procedures; supervised machine learning","Oxford University Press","13674803","","BOINF","29126286","Article","Scopus","2-s2.0-85045845974"
"Mac Aodha O.; Gibb R.; Barlow K.E.; Browning E.; Firman M.; Freeman R.; Harder B.; Kinsey L.; Mead G.R.; Newson S.E.; Pandourski I.; Parsons S.; Russ J.; Szodoray-Paradi A.; Szodoray-Paradi F.; Tilova E.; Girolami M.; Brostow G.; Jones K.E.","Mac Aodha, Oisin (35177072300); Gibb, Rory (57195273675); Barlow, Kate E. (7004910872); Browning, Ella (57197736235); Firman, Michael (6602655015); Freeman, Robin (56079348600); Harder, Briana (57201430974); Kinsey, Libby (58362865900); Mead, Gary R. (57201424263); Newson, Stuart E. (8889109300); Pandourski, Ivan (15756387300); Parsons, Stuart (7202703211); Russ, Jon (7102769905); Szodoray-Paradi, Abigel (55920274700); Szodoray-Paradi, Farkas (55920144800); Tilova, Elena (55920243300); Girolami, Mark (7005215170); Brostow, Gabriel (15135206900); Jones, Kate E. (7404728090)","35177072300; 57195273675; 7004910872; 57197736235; 6602655015; 56079348600; 57201430974; 58362865900; 57201424263; 8889109300; 15756387300; 7202703211; 7102769905; 55920274700; 55920144800; 55920243300; 7005215170; 15135206900; 7404728090","Bat detective—Deep learning tools for bat acoustic signal detection","2018","PLoS Computational Biology","141","10.1371/journal.pcbi.1005995","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044788623&doi=10.1371%2fjournal.pcbi.1005995&partnerID=40&md5=eb11d274ba0c0d1b6c99be496b0ed05b","Department of Computer Science, University College London, London, United Kingdom; Centre for Biodiversity and Environment Research, Department of Genetics, Evolution and Environment, University College London, London, United Kingdom; Bat Conservation Trust, Quadrant House, London, United Kingdom; Institute of Zoology, Zoological Society of London, Regent’s Park, London, United Kingdom; Bellevue, WA, United States; Wickford, Essex, United Kingdom; British Trust for Ornithology, The Nunnery, Thetford, Norfolk, United Kingdom; Institute of Biodiversity and Ecosystem Research Academy of Sciences, Sofia, Bulgaria; School of Earth Environmental and Biological Sciences, Queensland University of Technology (QUT), Brisbane, QLD, Australia; Ridgeway Ecology, Warwick, United Kingdom; Romanian Bat Protection Association, Satu Mare, Romania; Green Balkans—Stara Zagora, Stara Zagora, Bulgaria; Department of Mathematics, Imperial College London, London, United Kingdom","Mac Aodha O., Department of Computer Science, University College London, London, United Kingdom; Gibb R., Centre for Biodiversity and Environment Research, Department of Genetics, Evolution and Environment, University College London, London, United Kingdom; Barlow K.E., Bat Conservation Trust, Quadrant House, London, United Kingdom; Browning E., Centre for Biodiversity and Environment Research, Department of Genetics, Evolution and Environment, University College London, London, United Kingdom, Institute of Zoology, Zoological Society of London, Regent’s Park, London, United Kingdom; Firman M., Department of Computer Science, University College London, London, United Kingdom; Freeman R., Institute of Zoology, Zoological Society of London, Regent’s Park, London, United Kingdom; Harder B., Bellevue, WA, United States; Kinsey L., Department of Computer Science, University College London, London, United Kingdom; Mead G.R., Wickford, Essex, United Kingdom; Newson S.E., British Trust for Ornithology, The Nunnery, Thetford, Norfolk, United Kingdom; Pandourski I., Institute of Biodiversity and Ecosystem Research Academy of Sciences, Sofia, Bulgaria; Parsons S., School of Earth Environmental and Biological Sciences, Queensland University of Technology (QUT), Brisbane, QLD, Australia; Russ J., Ridgeway Ecology, Warwick, United Kingdom; Szodoray-Paradi A., Romanian Bat Protection Association, Satu Mare, Romania; Szodoray-Paradi F., Romanian Bat Protection Association, Satu Mare, Romania; Tilova E., Green Balkans—Stara Zagora, Stara Zagora, Bulgaria; Girolami M., Department of Mathematics, Imperial College London, London, United Kingdom; Brostow G., Department of Computer Science, University College London, London, United Kingdom; Jones K.E., Centre for Biodiversity and Environment Research, Department of Genetics, Evolution and Environment, University College London, London, United Kingdom, Institute of Zoology, Zoological Society of London, Regent’s Park, London, United Kingdom","Passive acoustic sensing has emerged as a powerful tool for quantifying anthropogenic impacts on biodiversity, especially for echolocating bat species. To better assess bat population trends there is a critical need for accurate, reliable, and open source tools that allow the detection and classification of bat calls in large collections of audio recordings. The majority of existing tools are commercial or have focused on the species classification task, neglecting the important problem of first localizing echolocation calls in audio which is particularly problematic in noisy recordings. We developed a convolutional neural network based open-source pipeline for detecting ultrasonic, full-spectrum, search-phase calls produced by echolocating bats. Our deep learning algorithms were trained on full-spectrum ultrasonic audio collected along road-transects across Europe and labelled by citizen scientists from www.batdetective.org. When compared to other existing algorithms and commercial systems, we show significantly higher detection performance of search-phase echolocation calls with our test sets. As an example application, we ran our detection pipeline on bat monitoring data collected over five years from Jersey (UK), and compared results to a widely-used commercial system. Our detection pipeline can be used for the automatic detection and monitoring of bat populations, and further facilitates their use as indicator species on a large scale. Our proposed pipeline makes only a small number of bat specific design decisions, and with appropriate training data it could be applied to detecting other species in audio. A crucial novelty of our work is showing that with careful, non-trivial, design and implementation considerations, state-of-the-art deep learning methods can be used for accurate and efficient monitoring in audio. © 2018 Mac Aodha et al.","","Algorithms; Animals; Chiroptera; Computational Biology; Echolocation; Endangered Species; Environmental Monitoring; Machine Learning; Neural Networks (Computer); Signal Processing, Computer-Assisted; Zoology; Audio systems; Deep learning; Learning algorithms; Neural networks; Search engines; Signal detection; Ultrasonic applications; Acoustic sensing; Acoustic signal detection; Anthropogenic impacts; Commercial systems; Echolocation calls; Full-spectrum; Learning tool; Open source tools; Passive acoustics; Search phasis; article; echolocation; human; indicator organism; Jersey; learning algorithm; nervous system; nonhuman; pipeline; scientist; signal detection; ultrasound; algorithm; animal; artificial neural network; bat; biology; classification; endangered species; environmental monitoring; machine learning; physiology; procedures; signal processing; zoology; Pipelines","Public Library of Science","1553734X","","","29518076","Article","Scopus","2-s2.0-85044788623"
"McAllister P.; Zheng H.; Bond R.; Moorhead A.","McAllister, Patrick (57189090225); Zheng, Huiru (8982328500); Bond, Raymond (36019802200); Moorhead, Anne (36174297600)","57189090225; 8982328500; 36019802200; 36174297600","Combining deep residual neural network features with supervised machine learning algorithms to classify diverse food image datasets","2018","Computers in Biology and Medicine","96","10.1016/j.compbiomed.2018.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044474907&doi=10.1016%2fj.compbiomed.2018.02.008&partnerID=40&md5=c54b34df89136a2ab7a907c24b4c6361","Ulster University, Jordanstown Campus, School of Computing, Northern Ireland, United Kingdom; Ulster University, Jordanstown Campus, School of Communication and Media, Northern Ireland, United Kingdom","McAllister P., Ulster University, Jordanstown Campus, School of Computing, Northern Ireland, United Kingdom; Zheng H., Ulster University, Jordanstown Campus, School of Computing, Northern Ireland, United Kingdom; Bond R., Ulster University, Jordanstown Campus, School of Computing, Northern Ireland, United Kingdom; Moorhead A., Ulster University, Jordanstown Campus, School of Communication and Media, Northern Ireland, United Kingdom","Obesity is increasing worldwide and can cause many chronic conditions such as type-2 diabetes, heart disease, sleep apnea, and some cancers. Monitoring dietary intake through food logging is a key method to maintain a healthy lifestyle to prevent and manage obesity. Computer vision methods have been applied to food logging to automate image classification for monitoring dietary intake. In this work we applied pretrained ResNet-152 and GoogleNet convolutional neural networks (CNNs), initially trained using ImageNet Large Scale Visual Recognition Challenge (ILSVRC) dataset with MatConvNet package, to extract features from food image datasets; Food 5K, Food-11, RawFooT-DB, and Food-101. Deep features were extracted from CNNs and used to train machine learning classifiers including artificial neural network (ANN), support vector machine (SVM), Random Forest, and Naive Bayes. Results show that using ResNet-152 deep features with SVM with RBF kernel can accurately detect food items with 99.4% accuracy using Food-5K validation food image dataset and 98.8% with Food-5K evaluation dataset using ANN, SVM-RBF, and Random Forest classifiers. Trained with ResNet-152 features, ANN can achieve 91.34%, 99.28% when applied to Food-11 and RawFooT-DB food image datasets respectively and SVM with RBF kernel can achieve 64.98% with Food-101 image dataset. From this research it is clear that using deep CNN features can be used efficiently for diverse food item image classification. The work presented in this research shows that pretrained ResNet-152 features provide sufficient generalisation power when applied to a range of food image classification tasks. © 2018 Elsevier Ltd","Convolutional neural networks; Deep learning; Feature extraction; Food logging; Obesity","Databases, Factual; Food; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Classification (of information); Convolution; Decision trees; Deep learning; Deep neural networks; Diseases; Feature extraction; Image retrieval; Learning algorithms; Nutrition; Radial basis function networks; Supervised learning; Support vector machines; Chronic conditions; Classification tasks; Convolutional neural network; Neural network features; Obesity; Random forest classifier; Supervised machine learning; Visual recognition; Article; artificial neural network; Bayesian learning; classifier; convolutional neural network; food; food 101; food 11; food 5k; information processing; kernel method; nerve cell network; nutritional assessment; priority journal; random forest; rawfoot db; supervised machine learning; support vector machine; artificial neural network; factual database; human; image processing; machine learning; Image classification","Elsevier Ltd","00104825","","CBMDA","29549733","Article","Scopus","2-s2.0-85044474907"
"Naqvi R.A.; Arsalan M.; Batchuluun G.; Yoon H.S.; Park K.R.","Naqvi, Rizwan Ali (55975847900); Arsalan, Muhammad (57203178070); Batchuluun, Ganbayar (57188649020); Yoon, Hyo Sik (57191035819); Park, Kang Ryoung (8983316300)","55975847900; 57203178070; 57188649020; 57191035819; 8983316300","Deep learning-based gaze detection system for automobile drivers using a NIR camera sensor","2018","Sensors (Switzerland)","122","10.3390/s18020456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041704473&doi=10.3390%2fs18020456&partnerID=40&md5=caa51a8c1df1c0d4dab3c82daeff4319","Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro, 1-gil, Jung-gu, Seoul, 100-715, South Korea","Naqvi R.A., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro, 1-gil, Jung-gu, Seoul, 100-715, South Korea; Arsalan M., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro, 1-gil, Jung-gu, Seoul, 100-715, South Korea; Batchuluun G., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro, 1-gil, Jung-gu, Seoul, 100-715, South Korea; Yoon H.S., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro, 1-gil, Jung-gu, Seoul, 100-715, South Korea; Park K.R., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro, 1-gil, Jung-gu, Seoul, 100-715, South Korea","A paradigm shift is required to prevent the increasing automobile accident deaths that are mostly due to the inattentive behavior of drivers. Knowledge of gaze region can provide valuable information regarding a driver’s point of attention. Accurate and inexpensive gaze classification systems in cars can improve safe driving. However, monitoring real-time driving behaviors and conditions presents some challenges: dizziness due to long drives, extreme lighting variations, glasses reflections, and occlusions. Past studies on gaze detection in cars have been chiefly based on head movements. The margin of error in gaze detection increases when drivers gaze at objects by moving their eyes without moving their heads. To solve this problem, a pupil center corneal reflection (PCCR)-based method has been considered. However, the error of accurately detecting the pupil center and corneal reflection center is increased in a car environment due to various environment light changes, reflections on glasses surface, and motion and optical blurring of captured eye image. In addition, existing PCCR-based methods require initial user calibration, which is difficult to perform in a car environment. To address this issue, we propose a deep learning-based gaze detection method using a near-infrared (NIR) camera sensor considering driver head and eye movement that does not require any initial user calibration. The proposed system is evaluated on our self-constructed database as well as on open Columbia gaze dataset (CAVE-DB). The proposed method demonstrated greater accuracy than the previous gaze classification methods. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Driver attention; Eye gaze tracking; NIR camera sensor; User calibration","Automobile Driving; Automobiles; Eye Movements; Fixation, Ocular; Head Movements; Humans; Machine Learning; Accidents; Automobile drivers; Calibration; Cameras; Eye movements; Glass; Infrared devices; Classification methods; Classification system; Corneal reflection; Driver attention; Eye gaze tracking; Lighting variations; NIR camera; User calibration; car; car driving; eye fixation; eye movement; head movement; human; machine learning; Deep learning","MDPI AG","14248220","","","29401681","Article","Scopus","2-s2.0-85041704473"
"Nasr-Esfahani E.; Karimi N.; Jafari M.H.; Soroushmehr S.M.R.; Samavi S.; Nallamothu B.K.; Najarian K.","Nasr-Esfahani, E. (23493078300); Karimi, N. (57928353300); Jafari, M.H. (57188761765); Soroushmehr, S.M.R. (24825477600); Samavi, S. (6603247881); Nallamothu, B.K. (35395213700); Najarian, K. (7003955943)","23493078300; 57928353300; 57188761765; 24825477600; 6603247881; 35395213700; 7003955943","Segmentation of vessels in angiograms using convolutional neural networks","2018","Biomedical Signal Processing and Control","65","10.1016/j.bspc.2017.09.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030682708&doi=10.1016%2fj.bspc.2017.09.012&partnerID=40&md5=0405a56ed142fe6304e4780c4ad1735c","Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, 84156-83111, Iran; Michigan Center for Integrative Research in Critical Care, Ann Arbor, 48109, MI, United States; Department of Emergency Medicine, University of Michigan, Ann Arbor, 48109, MI, United States","Nasr-Esfahani E., Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, 84156-83111, Iran; Karimi N., Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, 84156-83111, Iran; Jafari M.H., Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, 84156-83111, Iran; Soroushmehr S.M.R., Michigan Center for Integrative Research in Critical Care, Ann Arbor, 48109, MI, United States, Department of Emergency Medicine, University of Michigan, Ann Arbor, 48109, MI, United States; Samavi S., Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, 84156-83111, Iran, Michigan Center for Integrative Research in Critical Care, Ann Arbor, 48109, MI, United States, Department of Emergency Medicine, University of Michigan, Ann Arbor, 48109, MI, United States; Nallamothu B.K., Department of Emergency Medicine, University of Michigan, Ann Arbor, 48109, MI, United States; Najarian K., Michigan Center for Integrative Research in Critical Care, Ann Arbor, 48109, MI, United States, Department of Emergency Medicine, University of Michigan, Ann Arbor, 48109, MI, United States","Coronary artery disease (CAD) is the most common type of heart disease and it is the leading cause of death in most parts of the world. About fifty percent of all middle-aged men and thirty percent of all middle-aged women in North America develop some type of CAD. The main tool for diagnosis of CAD is the X-ray angiography. Usually these images lack high quality and they contain noise. Accurate segmentation of vessels in these images could help physicians in accurate CAD diagnosis. Many image processing techniques have been used by researchers for vessel segmentation but achieving high accuracy is still a challenge in this regard. In this paper a method for detecting vessel regions in angiography images is proposed which is based on deep learning approach using convolutional neural networks (CNN). The intended angiogram is first processed to enhance the image quality. Then a patch around each pixel is fed into a trained CNN to determine whether the pixel is of vessel or background regions. Different elements of the proposed method, including the image enhancement method, the architecture of the CNN, and the training procedure of the CNN, all lead to a highly accurate mechanism. Experiments performed on angiograms of a dataset show that the proposed algorithm has a Dice score of 81.51 and an accuracy of 97.93. Results of the proposed algorithm show its superiority in extraction of vessel regions in comparison to state of the art methods. © 2017","Angiograms; Convolutional neural networks; Deep learning; Vessel segmentation","Angiography; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Diseases; Image enhancement; Image segmentation; Pixels; Angiograms; Angiography images; Coronary artery disease; Image processing technique; Learning approach; State-of-the-art methods; Training procedures; Vessel segmentation; accuracy; algorithm; angiography; Article; artificial neural network; coronary artery disease; image enhancement; image processing; image quality; image segmentation; machine learning; mathematical analysis; mathematical model; priority journal; X ray angiography; Convolutional neural networks","Elsevier Ltd","17468094","","","","Article","Scopus","2-s2.0-85030682708"
"Sottile P.D.; Albers D.; Higgins C.; McKeehan J.; Moss M.M.","Sottile, Peter D. (55050994500); Albers, David (55341958200); Higgins, Carrie (57205652145); McKeehan, Jeffery (57205653738); Moss, Marc M. (57223593929)","55050994500; 55341958200; 57205652145; 57205653738; 57223593929","The Association between Ventilator Dyssynchrony, Delivered Tidal Volume, and Sedation Using a Novel Automated Ventilator Dyssynchrony Detection Algorithm","2018","Critical Care Medicine","48","10.1097/CCM.0000000000002849","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056350802&doi=10.1097%2fCCM.0000000000002849&partnerID=40&md5=2f9cea5ad3ad6a43048fdd36b8978da4","Division of Pulmonary Sciences and Critical Care Medicine, Department of Medicine, University of Colorado School of Medicine, Aurora, CO, United States; Department of Biomedical Information, University of Columbia, New York, NY, United States","Sottile P.D., Division of Pulmonary Sciences and Critical Care Medicine, Department of Medicine, University of Colorado School of Medicine, Aurora, CO, United States; Albers D., Department of Biomedical Information, University of Columbia, New York, NY, United States; Higgins C., Division of Pulmonary Sciences and Critical Care Medicine, Department of Medicine, University of Colorado School of Medicine, Aurora, CO, United States; McKeehan J., Division of Pulmonary Sciences and Critical Care Medicine, Department of Medicine, University of Colorado School of Medicine, Aurora, CO, United States; Moss M.M., Division of Pulmonary Sciences and Critical Care Medicine, Department of Medicine, University of Colorado School of Medicine, Aurora, CO, United States","Objective: Ventilator dyssynchrony is potentially harmful to patients with or at risk for the acute respiratory distress syndrome. Automated detection of ventilator dyssynchrony from ventilator waveforms has been difficult. It is unclear if certain types of ventilator dyssynchrony deliver large tidal volumes and whether levels of sedation alter the frequency of ventilator dyssynchrony. Design: A prospective observational study. Setting: A university medical ICU. Patients: Patients with or at risk for acute respiratory distress syndrome. Interventions: Continuous pressure-time, flow-time, and volumetime data were directly obtained from the ventilator. The level of sedation and the use of neuromuscular blockade was extracted from the medical record. Machine learning algorithms that incorporate clinical insight were developed and trained to detect four previously described and clinically relevant forms of ventilator dyssynchrony. The association between normalized tidal volume and ventilator dyssynchrony and the association between sedation and the frequency of ventilator dyssynchrony were determined. Measurements and Main Results: A total of 4.26 million breaths were recorded from 62 ventilated patients. Our algorithm detected three types of ventilator dyssynchrony with an area under the receiver operator curve of greater than 0.89. Ventilator dyssynchrony occurred in 34.4% (95% CI, 34.41-34.49%) of breaths. When compared with synchronous breaths, double-triggered and flow-limited breaths were more likely to deliver tidal volumes greater than 10mL/kg (40% and 11% compared with 0.2%; p < 0.001 for both comparisons). Deep sedation reduced but did not eliminate the frequency of all ventilator dyssynchrony breaths (p < 0.05). Ventilator dyssynchrony was eliminated with neuromuscular blockade (p < 0.001). Conclusion: We developed a computerized algorithm that accurately detects three types of ventilator dyssynchrony. Double-triggered and flow-limited breaths are associated with the frequent delivery of tidal volumes of greater than 10mL/kg. Although ventilator dyssynchrony is reduced by deep sedation, potentially deleterious tidal volumes may still be delivered. However, neuromuscular blockade effectively eliminates ventilator dyssynchrony.  Copyright © 2018 by the Society of Critical Care Medicine and Wolters Kluwer Health, Inc. All Rights Reserved.","Machine learning; neuromuscular blockade; respiratory distress syndrome, adult; ventilator induced lung injury; ventilators, mechanical","Algorithms; Deep Sedation; Equipment Failure; Female; Humans; Male; Middle Aged; Neuromuscular Blockade; Prospective Studies; Respiratory Distress Syndrome, Adult; Tidal Volume; Ventilators, Mechanical; adult; algorithm; Article; artificial ventilation; breathing; deep sedation; detection algorithm; female; heart failure; hospitalization; human; hypoxemia; intensive care unit; learning algorithm; machine learning; major clinical study; male; medical intensive care unit; medical record; neuromuscular blocking; observational study; positive end expiratory pressure ventilation; prospective study; respiratory distress; sedation; tidal volume; ventilator induced lung injury; adult respiratory distress syndrome; deep sedation; device failure; mechanical ventilator; middle aged; neuromuscular blocking","Lippincott Williams and Wilkins","00903493","","CCMDC","29337804","Article","Scopus","2-s2.0-85056350802"
"Zhang N.; Ding S.; Zhang J.; Xue Y.","Zhang, Nan (56994194400); Ding, Shifei (24314525600); Zhang, Jian (56637434200); Xue, Yu (56501123700)","56994194400; 24314525600; 56637434200; 56501123700","An overview on Restricted Boltzmann Machines","2018","Neurocomputing","146","10.1016/j.neucom.2017.09.065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030677110&doi=10.1016%2fj.neucom.2017.09.065&partnerID=40&md5=74e4925c931f6b10d962c9638bae39fa","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; School of Computer and Software, Nanjing University of Information Science & Technology, Nanjing, 210044, China","Zhang N., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Ding S., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Zhang J., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Xue Y., School of Computer and Software, Nanjing University of Information Science & Technology, Nanjing, 210044, China","The Restricted Boltzmann Machine (RBM) has aroused wide interest in machine learning fields during the past decade. This review aims to report the recent developments in theoretical research and applications of the RBM. We first give an overview of the general RBM from the theoretical perspective, including stochastic approximation methods, stochastic gradient methods, and preventing overfitting methods. And then this review focuses on the RBM variants which further improve the learning ability of the RBM under general or specific applications. The RBM has recently been extended for representational learning, document modeling, multi-label learning, weakly supervised learning and many other tasks. The RBM and RBM variants provide powerful tools for representing dependency in the data, and they can be used as the basic building blocks to create deep networks. Apart from the Deep Belief Network (DBN) and the Deep Boltzmann Machine (DBM), the RBM can also be combined with the Convolutional Neural Network (CNN) to create deep networks. This review provides a comprehensive view of these advances in the RBM together with its future perspectives. © 2017","Classification; Deep networks; Representational learning; Restricted Boltzmann Machine","Approximation theory; Classification (of information); Gradient methods; Learning algorithms; Learning systems; Neural networks; Stochastic systems; Convolutional neural network; Deep belief network (DBN); Deep boltzmann machines; Representational learning; Restricted boltzmann machine; Stochastic approximation methods; Stochastic gradient methods; Weakly supervised learning; Article; artificial neural network; Convolutional Neural Network; data analysis; Deep Belief Network; Deep Boltzmann Machine; deep network; document modeling; learning; machine learning; mathematical analysis; preventing overfitting method; priority journal; representational learning; Restricted Boltzmann Machine; stochastic approximation method; stochastic gradient method; stochastic model; theoretical model; weakly supervised learning; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85030677110"
"Chen Y.; Tao G.; Ren H.; Lin X.; Zhang L.","Chen, Yanxiang (35408499700); Tao, Gang (57194090952); Ren, Hongmei (57194087785); Lin, Xinyu (57194098161); Zhang, Luming (35231925400)","35408499700; 57194090952; 57194087785; 57194098161; 35231925400","Accurate seat belt detection in road surveillance images based on CNN and SVM","2018","Neurocomputing","37","10.1016/j.neucom.2016.06.098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018668259&doi=10.1016%2fj.neucom.2016.06.098&partnerID=40&md5=2b8b9b567b900083d10a428cd635dbf9","School of Computer and Information, Hefei University of Technology, Hefei, 230009, China; Anhui Keli Information Industry Co. Ltd., Hefei, 230088, China","Chen Y., School of Computer and Information, Hefei University of Technology, Hefei, 230009, China; Tao G., Anhui Keli Information Industry Co. Ltd., Hefei, 230088, China; Ren H., School of Computer and Information, Hefei University of Technology, Hefei, 230009, China; Lin X., School of Computer and Information, Hefei University of Technology, Hefei, 230009, China; Zhang L., School of Computer and Information, Hefei University of Technology, Hefei, 230009, China","Seat belt detection in intelligent transportation systems is an important research area, but the current algorithms for such systems are not very well developed. Existing methods are mostly based on edge detection and the Hough transform. However, there are many kinds of vehicles and background environments, which produce many possible edges; thus, these methods often produce false positives. We therefore propose a seat belt detection algorithm for complex road backgrounds based on multi-scale feature extraction using deep learning. We first extract multi-scale features from the regions of the labeled vehicle, windshield, and seat belt to train the detection models using convolution neural network (CNN). Then the coarse candidates of the vehicle, windshield, and seat belt in the test image are detected. For the accurate detection results, a post-processing is employed by using the detection scores as well as the relative positions of these vehicle components to train a classification model through support vector machine (SVM). Finally, we perform a fine mapping and identification process using this classification model on the seat belt region. This method performed well when applied to a database of images collected by road surveillance cameras. © 2017","Convolution neural network; Multi-scale features; Seat belt detection; Support vector machine","Automobile seat belts; Belts; Convolution; Deep learning; Edge detection; Hough transforms; Intelligent systems; Neural networks; Roads and streets; Security systems; Support vector machines; Windshields; Background environment; Classification models; Convolution neural network; Identification process; Intelligent transportation systems; Multi-scale features; Seat belt; Surveillance cameras; accuracy; Article; artificial neural network; classification; convolution neural network; learning algorithm; motor vehicle; priority journal; scoring system; seat belt detection; support vector machine; traffic and transport; Feature extraction","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85018668259"
"Joy N.M.; Umesh S.","Joy, Neethu Mariam (55654636600); Umesh, S. (6603913321)","55654636600; 6603913321","Improving acoustic models in TORGO dysarthric speech database","2018","IEEE Transactions on Neural Systems and Rehabilitation Engineering","46","10.1109/TNSRE.2018.2802914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041521634&doi=10.1109%2fTNSRE.2018.2802914&partnerID=40&md5=a8c9c2184aaac00871ea3d23516e0cca","Department of Electrical Engineering, Indian Institute of Technology-Madras, Chennai, 600036, India","Joy N.M., Department of Electrical Engineering, Indian Institute of Technology-Madras, Chennai, 600036, India; Umesh S., Department of Electrical Engineering, Indian Institute of Technology-Madras, Chennai, 600036, India","Assistive speech-based technologies can improve the quality of life for people affected with dysarthria, a motor speech disorder. In this paper, we explore multiple ways to improve Gaussian mixture model and deep neural network (DNN) based hidden Markov model (HMM) automatic speech recognition systems for TORGO dysarthric speech database. This work shows significant improvements over the previous attempts in building such systems in TORGO. We trained speaker-specific acoustic models by tuning various acoustic model parameters, using speaker normalized cepstral features and building complex DNN-HMM models with dropout and sequence-discrimination strategies. The DNN-HMM models for severe and severe-moderate dysarthric speakers were further improved by leveraging specific information from dysarthric speech to DNN models trained on audio files from both dysarthric and normal speech, using generalized distillation framework. To the best of our knowledge, this paper presents the best recognition accuracies for TORGO database till date. © 2001-2011 IEEE.","acoustic model; distillation; DNN; Dysarthria; multitask","Adult; Communication Aids for Disabled; Databases, Factual; Dysarthria; Equipment Design; Female; Humans; Machine Learning; Male; Markov Chains; Models, Statistical; Normal Distribution; Self-Help Devices; Speech Disorders; Speech Production Measurement; Speech Recognition Software; Database systems; Deep neural networks; Distillation; Gaussian distribution; Hidden Markov models; Multitasking; Speech; Trellis codes; Acoustic model; Automatic speech recognition system; Building complexes; Cepstral features; Dysarthria; Gaussian Mixture Model; Recognition accuracy; Specific information; acoustics; Article; artificial neural network; dysarthria; entropy; hidden Markov model; human; motor performance; speech articulation; speech intelligibility; adult; automatic speech recognition; communication aid; complication; dysarthria; equipment design; factual database; female; machine learning; male; Markov chain; normal distribution; self help device; speech analysis; speech disorder; statistical model; Speech recognition","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","29522408","Article","Scopus","2-s2.0-85041521634"
"Jiang S.; Chin K.-S.; Tsui K.L.","Jiang, Shancheng (57193925137); Chin, Kwai-Sang (7202995439); Tsui, Kwok L (7101671584)","57193925137; 7202995439; 7101671584","A universal deep learning approach for modeling the flow of patients under different severities","2018","Computer Methods and Programs in Biomedicine","34","10.1016/j.cmpb.2017.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037134079&doi=10.1016%2fj.cmpb.2017.11.003&partnerID=40&md5=6e8838e2f2b81793ab1aee8341fb4d3d","Dept. of Systems Engineering and Engineering Management, City University of Hong Kong, 83 Tat Chee Avenue, Kowloon Tong, Hong Kong","Jiang S., Dept. of Systems Engineering and Engineering Management, City University of Hong Kong, 83 Tat Chee Avenue, Kowloon Tong, Hong Kong; Chin K.-S., Dept. of Systems Engineering and Engineering Management, City University of Hong Kong, 83 Tat Chee Avenue, Kowloon Tong, Hong Kong; Tsui K.L., Dept. of Systems Engineering and Engineering Management, City University of Hong Kong, 83 Tat Chee Avenue, Kowloon Tong, Hong Kong","Background and objective The Accident and Emergency Department (A&ED) is the frontline for providing emergency care in hospitals. Unfortunately, relative A&ED resources have failed to keep up with continuously increasing demand in recent years, which leads to overcrowding in A&ED. Knowing the fluctuation of patient arrival volume in advance is a significant premise to relieve this pressure. Based on this motivation, the objective of this study is to explore an integrated framework with high accuracy for predicting A&ED patient flow under different triage levels, by combining a novel feature selection process with deep neural networks. Methods Administrative data is collected from an actual A&ED and categorized into five groups based on different triage levels. A genetic algorithm (GA)-based feature selection algorithm is improved and implemented as a pre-processing step for this time-series prediction problem, in order to explore key features affecting patient flow. In our improved GA, a fitness-based crossover is proposed to maintain the joint information of multiple features during iterative process, instead of traditional point-based crossover. Deep neural networks (DNN) is employed as the prediction model to utilize their universal adaptability and high flexibility. In the model-training process, the learning algorithm is well-configured based on a parallel stochastic gradient descent algorithm. Two effective regularization strategies are integrated in one DNN framework to avoid overfitting. All introduced hyper-parameters are optimized efficiently by grid-search in one pass. Results As for feature selection, our improved GA-based feature selection algorithm has outperformed a typical GA and four state-of-the-art feature selection algorithms (mRMR, SAFS, VIFR, and CFR). As for the prediction accuracy of proposed integrated framework, compared with other frequently used statistical models (GLM, seasonal-ARIMA, ARIMAX, and ANN) and modern machine models (SVM-RBF, SVM-linear, RF, and R-LASSO), the proposed integrated “DNN-I-GA” framework achieves higher prediction accuracy on both MAPE and RMSE metrics in pairwise comparisons. Conclusions The contribution of our study is two-fold. Theoretically, the traditional GA-based feature selection process is improved to have less hyper-parameters and higher efficiency, and the joint information of multiple features is maintained by fitness-based crossover operator. The universal property of DNN is further enhanced by merging different regularization strategies. Practically, features selected by our improved GA can be used to acquire an underlying relationship between patient flows and input features. Predictive values are significant indicators of patients' demand and can be used by A&ED managers to make resource planning and allocation. High accuracy achieved by the present framework in different cases enhances the reliability of downstream decision makings. © 2017 Elsevier B.V.","Decision support system; Deep neural network; Demand forecast; Emergency service; Feature selection; Improved genetic algorithm","Algorithms; Clinical Decision-Making; Emergency Service, Hospital; Hong Kong; Humans; Machine Learning; Models, Theoretical; Neural Networks (Computer); Reproducibility of Results; Severity of Illness Index; Stochastic Processes; Triage; Accidents; Artificial intelligence; Decision making; Decision support systems; Deep neural networks; Emergency services; Forecasting; Genetic algorithms; Hospitals; Iterative methods; Learning algorithms; Personnel training; Regression analysis; Stochastic models; Stochastic systems; Demand forecast; Emergency departments; Feature selection algorithm; Integrated frameworks; Pair-wise comparison; Regularization strategies; Stochastic gradient descent algorithm; Time series prediction; accuracy; Article; artificial neural network; conceptual framework; decision making; disease severity; emergency health service; genetic algorithm; human; learning algorithm; machine learning; predictive value; reliability; statistical model; stochastic model; algorithm; clinical decision making; emergency health service; Hong Kong; hospital emergency service; machine learning; Markov chain; organization and management; procedures; reproducibility; severity of illness index; theoretical model; Feature extraction","Elsevier Ireland Ltd","01692607","","CMPBE","29249343","Article","Scopus","2-s2.0-85037134079"
"Kim T.; Kim J.-W.; Lee K.","Kim, Taehoon (57199878191); Kim, Jeong-Whun (9235705200); Lee, Kyogu (8597995500)","57199878191; 9235705200; 8597995500","Detection of sleep disordered breathing severity using acoustic biomarker and machine learning techniques","2018","BioMedical Engineering Online","56","10.1186/s12938-018-0448-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041446129&doi=10.1186%2fs12938-018-0448-x&partnerID=40&md5=5db658ffc7aaf6fe725f14ba2821551c","Seoul National University, Music and Audio Research Group, Graduate School of Convergence Science and Technology, 1 Gwanak-ro, Seoul, 08826, South Korea; Seoul National University College of Medicine, Department of Otorhinolaryngology, Seoul National University Bundang Hospital, Gumi-ro, Seongnam, 13620, South Korea","Kim T., Seoul National University, Music and Audio Research Group, Graduate School of Convergence Science and Technology, 1 Gwanak-ro, Seoul, 08826, South Korea; Kim J.-W., Seoul National University College of Medicine, Department of Otorhinolaryngology, Seoul National University Bundang Hospital, Gumi-ro, Seongnam, 13620, South Korea; Lee K., Seoul National University, Music and Audio Research Group, Graduate School of Convergence Science and Technology, 1 Gwanak-ro, Seoul, 08826, South Korea","Purpose: Breathing sounds during sleep are altered and characterized by various acoustic specificities in patients with sleep disordered breathing (SDB). This study aimed to identify acoustic biomarkers indicative of the severity of SDB by analyzing the breathing sounds collected from a large number of subjects during entire overnight sleep. Methods: The participants were patients who presented at a sleep center with snoring or cessation of breathing during sleep. They were subjected to full-night polysomnography (PSG) during which the breathing sound was recorded using a microphone. Then, audio features were extracted and a group of features differing significantly between different SDB severity groups was selected as a potential acoustic biomarker. To assess the validity of the acoustic biomarker, classification tasks were performed using several machine learning techniques. Based on the apnea-hypopnea index of the subjects, four-group classification and binary classification were performed. Results: Using tenfold cross validation, we achieved an accuracy of 88.3% in the four-group classification and an accuracy of 92.5% in the binary classification. Experimental evaluation demonstrated that the models trained on the proposed acoustic biomarkers can be used to estimate the severity of SDB. Conclusions: Acoustic biomarkers may be useful to accurately predict the severity of SDB based on the patient's breathing sounds during sleep, without conducting attended full-night PSG. This study implies that any device with a microphone, such as a smartphone, could be potentially utilized outside specialized facilities as a screening tool for detecting SDB. © 2018 The Author(s).","Acoustic biomarker; Apnea-hypopnea index; Deep neural network; Polysomnography screening test; Sleep disordered breathing","Acoustics; Adolescent; Adult; Aged; Biomarkers; Body Mass Index; Child; Female; Humans; Machine Learning; Male; Middle Aged; Polysomnography; Sleep; Sleep Apnea Syndromes; Snoring; Young Adult; Artificial intelligence; Audio acoustics; Deep neural networks; Diagnosis; Learning algorithms; Microphones; Sleep research; biological marker; Apnea-hypopnea indices; Binary classification; Breathing sounds; Classification tasks; Experimental evaluation; Machine learning techniques; Screening tests; Sleep-disordered breathing; abnormal respiratory sound; accuracy; acoustics; adult; apnea hypopnea index; Article; audio recording; classification; disease severity; female; human; machine learning; major clinical study; male; polysomnography; priority journal; sleep disordered breathing; snoring; validity; acoustics; adolescent; aged; body mass; child; middle aged; sleep; sleep disordered breathing; snoring; young adult; Biomarkers","BioMed Central Ltd.","1475925X","","BEOIB","29391025","Article","Scopus","2-s2.0-85041446129"
"Thrall J.H.; Li X.; Li Q.; Cruz C.; Do S.; Dreyer K.; Brink J.","Thrall, James H. (7006223004); Li, Xiang (27168120000); Li, Quanzheng (7405862484); Cruz, Cinthia (56533209300); Do, Synho (24173146300); Dreyer, Keith (7006172475); Brink, James (7102886692)","7006223004; 27168120000; 7405862484; 56533209300; 24173146300; 7006172475; 7102886692","Artificial Intelligence and Machine Learning in Radiology: Opportunities, Challenges, Pitfalls, and Criteria for Success","2018","Journal of the American College of Radiology","417","10.1016/j.jacr.2017.12.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041593093&doi=10.1016%2fj.jacr.2017.12.026&partnerID=40&md5=6fb9012f587626e841f6c046d400be98","Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, Massachusetts, United States","Thrall J.H., Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, Massachusetts, United States; Li X., Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, Massachusetts, United States; Li Q., Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, Massachusetts, United States; Cruz C., Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, Massachusetts, United States; Do S., Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, Massachusetts, United States; Dreyer K., Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, Massachusetts, United States; Brink J., Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, Massachusetts, United States","Worldwide interest in artificial intelligence (AI) applications, including imaging, is high and growing rapidly, fueled by availability of large datasets (“big data”), substantial advances in computing power, and new deep-learning algorithms. Apart from developing new AI methods per se, there are many opportunities and challenges for the imaging community, including the development of a common nomenclature, better ways to share image data, and standards for validating AI program use across different imaging platforms and patient populations. AI surveillance programs may help radiologists prioritize work lists by identifying suspicious or positive cases for early review. AI programs can be used to extract “radiomic” information from images not discernible by visual inspection, potentially increasing the diagnostic and prognostic value derived from image datasets. Predictions have been made that suggest AI will put radiologists out of business. This issue has been overstated, and it is much more likely that radiologists will beneficially incorporate AI methods into their practices. Current limitations in availability of technical expertise and even computing power will be resolved over time and can also be addressed by remote access solutions. Success for AI in imaging will be measured by value created: increased diagnostic certainty, faster turnaround, better outcomes for patients, and better quality of work life for radiologists. AI offers a new and promising set of methods for analyzing image data. Radiologists will explore these new pathways and are likely to play a leading role in medical applications of AI. © 2017 American College of Radiology","Artificial intelligence; challenges; machine learning; opportunities; pitfalls","Artificial Intelligence; Big Data; Deep Learning; Forecasting; Humans; Machine Learning; Radiology; adult; article; artificial intelligence; human; learning algorithm; nomenclature; outcome assessment; prediction; radiologist; radiology; forecasting; machine learning; radiology; trends","Elsevier B.V.","15461440","","","29402533","Article","Scopus","2-s2.0-85041593093"
"Kulmanov M.; Khan M.A.; Hoehndorf R.","Kulmanov, Maxat (57193354710); Khan, Mohammed Asif (57200858462); Hoehndorf, Robert (14319077100)","57193354710; 57200858462; 14319077100","DeepGO: Predicting protein functions from sequence and interactions using a deep ontology-aware classifier","2018","Bioinformatics","280","10.1093/bioinformatics/btx624","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042523872&doi=10.1093%2fbioinformatics%2fbtx624&partnerID=40&md5=b13145bd1824a682861e3076cf04e92e","Computer, Electrical and Mathematical Sciences and Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia","Kulmanov M., Computer, Electrical and Mathematical Sciences and Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Khan M.A., Computer, Electrical and Mathematical Sciences and Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Hoehndorf R., Computer, Electrical and Mathematical Sciences and Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia","Motivation A large number of protein sequences are becoming available through the application of novel high-throughput sequencing technologies. Experimental functional characterization of these proteins is time-consuming and expensive, and is often only done rigorously for few selected model organisms. Computational function prediction approaches have been suggested to fill this gap. The functions of proteins are classified using the Gene Ontology (GO), which contains over 40 000 classes. Additionally, proteins have multiple functions, making function prediction a large-scale, multi-class, multi-label problem. Results We have developed a novel method to predict protein function from sequence. We use deep learning to learn features from protein sequences as well as a cross-species protein-protein interaction network. Our approach specifically outputs information in the structure of the GO and utilizes the dependencies between GO classes as background information to construct a deep learning model. We evaluate our method using the standards established by the Computational Assessment of Function Annotation (CAFA) and demonstrate a significant improvement over baseline methods such as BLAST, in particular for predicting cellular locations. Availability and implementation Web server: http://deepgo.bio2vec.net, Source code: https://github.com/bio-ontology-research-group/deepgo Contact robert.hoehndorf@kaust.edu.sa Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author 2017. Published by Oxford University Press.","","Animals; Bacteria; Computational Biology; Eukaryota; Gene Ontology; Humans; Protein Interaction Maps; Proteins; Sequence Analysis, Protein; Software; Supervised Machine Learning; protein; animal; bacterium; biology; eukaryote; gene ontology; human; metabolism; physiology; procedures; protein analysis; sequence analysis; software; supervised machine learning","Oxford University Press","13674803","","BOINF","29028931","Article","Scopus","2-s2.0-85042523872"
"Deng W.; Fang Y.; Xu Z.; Hu J.","Deng, Weihong (8905974100); Fang, Yuke (57194854050); Xu, Zhenqi (57190273785); Hu, Jiani (55712130400)","8905974100; 57194854050; 57190273785; 55712130400","Facial landmark localization by enhanced convolutional neural network","2018","Neurocomputing","23","10.1016/j.neucom.2017.07.052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028364319&doi=10.1016%2fj.neucom.2017.07.052&partnerID=40&md5=75eda9437e4eaa93fb84b2dc8f305bc6","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; International School, Beijing University of Posts and Telecommunications, Beijing, 100876, China","Deng W., School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Fang Y., International School, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Xu Z., School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Hu J., School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China","Facial landmark localization is important to many facial recognition and analysis tasks, such as face attributes analysis, head pose estimation, 3D face modeling, and facial expression analysis. In this paper, we propose a new approach to localizing landmarks in facial image by deep convolutional neural network (DCNN). We make two enhancements on the CNN to adapt it to the feature localization task as follows. First, we replace the commonly used max pooling by depth-wise convolution to obtain better localization performance. Second, we define a response map for each facial points as a 2D probability map indicating the presence likelihood, and train our model with a KL divergence loss. To obtain robust localization results, our approach first takes the expectations of the response maps of enhanced CNN and then applies auto-encoder model to the global shape vector, which is effective to rectify the outlier points by the prior global landmark configurations. The proposed ECNN method achieves 5.32% mean error on the experiments on the 300-W dataset, which is comparable to the state-of-the-art performance on this standard benchmark, showing the effectiveness of our methods. © 2017 Elsevier B.V.","Convolutional neural network; Deep learning; Face alignment; Face recognition; Facial landmark localization","Benchmarking; Convolution; Deep learning; Deep neural networks; Image recognition; Neural networks; Convolutional neural network; Face alignment; Facial expression analysis; Facial landmark; Facial recognition; Head Pose Estimation; Localization performance; State-of-the-art performance; analytical error; Article; artificial neural network; controlled study; data analysis; facial landmark localization; facial recognition; image analysis; intermethod comparison; machine learning; mathematical model; performance; priority journal; probability; quality control; Face recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85028364319"
"Lore K.G.; Stoecklein D.; Davies M.; Ganapathysubramanian B.; Sarkar S.","Lore, Kin Gwn (57190128995); Stoecklein, Daniel (56376495600); Davies, Michael (57193776760); Ganapathysubramanian, Baskar (8589220000); Sarkar, Soumik (55066244300)","57190128995; 56376495600; 57193776760; 8589220000; 55066244300","A deep learning framework for causal shape transformation","2018","Neural Networks","18","10.1016/j.neunet.2017.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039785768&doi=10.1016%2fj.neunet.2017.12.003&partnerID=40&md5=e881dcbb8d3e59f6c06a51d0ffeeddb5","Department of Mechanical Engineering, Iowa State University, Ames, IA-50014, United States","Lore K.G., Department of Mechanical Engineering, Iowa State University, Ames, IA-50014, United States; Stoecklein D., Department of Mechanical Engineering, Iowa State University, Ames, IA-50014, United States; Davies M., Department of Mechanical Engineering, Iowa State University, Ames, IA-50014, United States; Ganapathysubramanian B., Department of Mechanical Engineering, Iowa State University, Ames, IA-50014, United States; Sarkar S., Department of Mechanical Engineering, Iowa State University, Ames, IA-50014, United States","Recurrent neural network (RNN) and Long Short-term Memory (LSTM) networks are the common go-to architecture for exploiting sequential information where the output is dependent on a sequence of inputs. However, in most considered problems, the dependencies typically lie in the latent domain which may not be suitable for applications involving the prediction of a step-wise transformation sequence that is dependent on the previous states only in the visible domain with a known terminal state. We propose a hybrid architecture of convolution neural networks (CNN) and stacked autoencoders (SAE) to learn a sequence of causal actions that nonlinearly transform an input visual pattern or distribution into a target visual pattern or distribution with the same support and demonstrated its practicality in a real-world engineering problem involving the physics of fluids. We solved a high-dimensional one-to-many inverse mapping problem concerning microfluidic flow sculpting, where the use of deep learning methods as an inverse map is very seldom explored. This work serves as a fruitful use-case to applied scientists and engineers in how deep learning can be beneficial as a solution for high-dimensional physical problems, and potentially opening doors to impactful advance in fields such as material sciences and medical biology where multistep topological transformations is a key element. © 2017 Elsevier Ltd","Convolutional neural networks; Sequence learning; Shape transformation; Stacked autoencoders","Machine Learning; Memory, Long-Term; Neural Networks (Computer); Convolution; Deep learning; Learning systems; Long short-term memory; Mathematical transformations; Medical problems; Network architecture; Neural networks; Recurrent neural networks; Autoencoders; Convolution neural network; Convolutional neural network; Recurrent neural network (RNN); Sequence learning; Shape transformation; Topological transformation; Transformation sequences; action prediction network; Article; artificial neural network; bioengineering; comparative study; convolution neural network; fluid flow; genetic algorithm; image quality; intermediate transformation network; machine learning; microfluidics; prediction; priority journal; stacked autoencoder; long term memory; Inverse problems","Elsevier Ltd","08936080","","NNETE","29301111","Article","Scopus","2-s2.0-85039785768"
"Janarish Saju C.; Ravimaran S.","Janarish Saju, C. (57197769174); Ravimaran, S. (47962688900)","57197769174; 47962688900","Efficient extraction of named entities from new domains using big data analytics","2018","Journal of Computational and Theoretical Nanoscience","1","10.1166/jctn.2018.7125","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042745429&doi=10.1166%2fjctn.2018.7125&partnerID=40&md5=76431e1776976756019c49146c5fd264","Anna University, Chennai, 600025, Tamil Nadu, India; MAM College of Engineering, Trichy, 621105, Tamil Nadu, India","Janarish Saju C., Anna University, Chennai, 600025, Tamil Nadu, India; Ravimaran S., MAM College of Engineering, Trichy, 621105, Tamil Nadu, India","The enormous amount of information generated on a day-to-day basis by the internet finds it hard to extract the useful information from it, which results in the need of Information Filtering (IF) in many domains. Named Entity Recognition (NER) technique is used to automatically extract valuable information from the unstructured natural language texts. As many works has been defined in detecting Named Entities. And many different NER tools exist for many domains but NER still remains a big challenge at large. Most of the various NER classifier types have been used to accomplish machine-learned NER, with conditional random fields being a typical choice. Although no work is currently served for domain based NER classification. This paper proposes a three-layered neural network approach using CRF, LDA and Deep Neural networks for detecting Named Entities in three steps. First, a classifier based on Conditional Random Field (CRF) is used to train the input data. Second, LDA (Latent Dirichlet Allocation) is used to enhance the previous output created by CRF to improve the label annotation. Third, the deep learning neural network captures the deep features of the data by itself from the pre-trained information created by CRF and LDA to achieve accurate predictions. Experimental results show that the learned model yields a banking domain specific NER recall of 90%, precision of 93%, accuracy of 91% and F-measure of 90%. Copyright © 2018 American Scientific Publishers All rights reserved.","Conditional random field; Deep Neural networks; Information Filtering; Latent Dirichlet Allocation; Named Entity Recognition","","American Scientific Publishers","15461955","","","","Article","Scopus","2-s2.0-85042745429"
"Dong H.; Supratak A.; Pan W.; Wu C.; Matthews P.M.; Guo Y.","Dong, Hao (56547882800); Supratak, Akara (56461348400); Pan, Wei (55604960500); Wu, Chao (55628577296); Matthews, Paul M. (7202324607); Guo, Yike (12765868000)","56547882800; 56461348400; 55604960500; 55628577296; 7202324607; 12765868000","Mixed Neural Network Approach for Temporal Sleep Stage Classification","2018","IEEE Transactions on Neural Systems and Rehabilitation Engineering","199","10.1109/TNSRE.2017.2733220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028984119&doi=10.1109%2fTNSRE.2017.2733220&partnerID=40&md5=55eae728f9daf4fca2fa9604785e77e6","Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Department of Medicine, Division of Brain Sciences, Imperial College London, London, SW7 2AZ, United Kingdom","Dong H., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Supratak A., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Pan W., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Wu C., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Matthews P.M., Department of Medicine, Division of Brain Sciences, Imperial College London, London, SW7 2AZ, United Kingdom; Guo Y., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom","This paper proposes a practical approach to addressing limitations posed by using of single-channel electroencephalography (EEG) for sleep stage classification. EEG-based characterizations of sleep stage progression contribute the diagnosis and monitoring of the many pathologies of sleep. Several prior reports explored ways of automating the analysis of sleep EEG and of reducing the complexity of the data needed for reliable discrimination of sleep stages at lower cost in the home. However, these reports have involved recordings from electrodes placed on the cranial vertex or occiput, which are both uncomfortable and difficult to position. Previous studies of sleep stage scoring that used only frontal electrodes with a hierarchical decision tree motivated this paper, in which we have taken advantage of rectifier neural network for detecting hierarchical features and long short-term memory network for sequential data learning to optimize classification performance with single-channel recordings. After exploring alternative electrode placements, we found a comfortable configuration of a single-channel EEG on the forehead and have shown that it can be integrated with additional electrodes for simultaneous recording of the electro-oculogram. Evaluation of data from 62 people (with 494 hours sleep) demonstrated better performance of our analytical algorithm than is available from existing approaches with vertex or occipital electrode placements. Use of this recording configuration with neural network deconvolution promises to make clinically indicated home sleep studies practical. © 2001-2011 IEEE.","deep learning; EEG signal; electroencephalography; long short-term memory; Sleep stage classification","Algorithms; Electrodes; Electroencephalography; Electrooculography; Equipment Design; Forehead; Humans; Machine Learning; Memory, Short-Term; Neural Networks (Computer); Reference Standards; Reproducibility of Results; Sleep Stages; Brain; Decision trees; Deep learning; Electrodes; Electroencephalography; Electrooculography; Electrophysiology; Feature extraction; Sleep research; Standards; Trees (mathematics); Classification performance; EEG signals; Hierarchical decision trees; Hierarchical features; Simultaneous recording; Single channel recording; Sleep; Sleep stage; accuracy; Article; electroencephalography; forehead; Fourier transformation; human; long term memory; Markov chain; nerve cell network; nervous system; perception; short term memory; sleep stage; validation process; wakefulness; algorithm; artificial neural network; electrode; electrooculography; equipment design; forehead; machine learning; physiology; procedures; reproducibility; sleep stage; standard; Long short-term memory","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","28767373","Article","Scopus","2-s2.0-85028984119"
"Ashtawy H.M.; Mahapatra N.R.","Ashtawy, Hossam M. (54906194200); Mahapatra, Nihar R. (7004619881)","54906194200; 7004619881","Task-Specific Scoring Functions for Predicting Ligand Binding Poses and Affinity and for Screening Enrichment","2018","Journal of Chemical Information and Modeling","65","10.1021/acs.jcim.7b00309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040924553&doi=10.1021%2facs.jcim.7b00309&partnerID=40&md5=c532b85b1884d9bda5b8b953d04f3e12","Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824-1226, MI, United States","Ashtawy H.M., Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824-1226, MI, United States; Mahapatra N.R., Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824-1226, MI, United States","Molecular docking, scoring, and virtual screening play an increasingly important role in computer-aided drug discovery. Scoring functions (SFs) are typically employed to predict the binding conformation (docking task), binding affinity (scoring task), and binary activity level (screening task) of ligands against a critical protein target in a disease's pathway. In most molecular docking software packages available today, a generic binding affinity-based (BA-based) SF is invoked for all three tasks to solve three different, but related, prediction problems. The limited predictive accuracies of such SFs in these three tasks has been a major roadblock toward cost-effective drug discovery. Therefore, in this work, we develop BT-Score, an ensemble machine-learning (ML) SF of boosted decision trees and thousands of predictive descriptors to estimate BA. BT-Score reproduced BA of out-of-sample test complexes with correlation of 0.825. Even with this high accuracy in the scoring task, we demonstrate that the docking and screening performance of BT-Score and other BA-based SFs is far from ideal. This has motivated us to build two task-specific ML SFs for the docking and screening problems. We propose BT-Dock, a boosted-tree ensemble model trained on a large number of native and computer-generated ligand conformations and optimized to predict binding poses explicitly. This model has shown an average improvement of 25% over its BA-based counterparts in different ligand pose prediction scenarios. Similar improvement has also been obtained by our screening-based SF, BT-Screen, which directly models the ligand activity labeling task as a classification problem. BT-Screen is trained on thousands of active and inactive protein-ligand complexes to optimize it for finding real actives from databases of ligands not seen in its training set. In addition to the three task-specific SFs, we propose a novel multi-task deep neural network (MT-Net) that is trained on data from the three tasks to simultaneously predict binding poses, affinities, and activity levels. We show that the performance of MT-Net is superior to conventional SFs and on a par with or better than models based on single-task neural networks. © 2017 American Chemical Society.","","Databases, Protein; Drug Discovery; Ligands; Machine Learning; Models, Chemical; Molecular Docking Simulation; Neural Networks (Computer); Protein Binding; Proteins; Stochastic Processes; Binding energy; Complex networks; Complexation; Cost effectiveness; Decision trees; Deep neural networks; Diagnosis; Forecasting; Forestry; Molecular modeling; Neural networks; Proteins; ligand; protein; protein binding; Binding conformations; Boosted decision trees; Computer-aided drug discovery; Ligand conformations; Prediction problem; Predictive accuracy; Protein-ligand complexes; Screening performance; artificial neural network; chemical model; chemistry; drug development; machine learning; Markov chain; molecular docking; protein database; Ligands","American Chemical Society","15499596","","JCISD","29190087","Article","Scopus","2-s2.0-85040924553"
"Zhu S.; Xu Z.","Zhu, Shiping (8949002600); Xu, Ziyao (57872691400)","8949002600; 57872691400","Spatiotemporal visual saliency guided perceptual high efficiency video coding with neural network","2018","Neurocomputing","37","10.1016/j.neucom.2017.08.054","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029566947&doi=10.1016%2fj.neucom.2017.08.054&partnerID=40&md5=d2baf0b6908066e481b5f18435f67921","Department of Measurement Control and Information Technology, School of Instrumentation Science and Opto-electronics Engineering, Beihang University, Beijing, 100191, China","Zhu S., Department of Measurement Control and Information Technology, School of Instrumentation Science and Opto-electronics Engineering, Beihang University, Beijing, 100191, China; Xu Z., Department of Measurement Control and Information Technology, School of Instrumentation Science and Opto-electronics Engineering, Beihang University, Beijing, 100191, China","The perceptual video coding systems for optimization have been developed on the basis of different attributes of the human visual system. The attention-based coding system is considered as an important part of it. The saliency map method representing the region-of-interest (ROI) from the video signal has become a reliable method due to advances in the computer performance and the visual algorithms. In the present study, we propose a hybrid compression algorithm that uses the deep convolutional neural network to compute the spatial saliency followed by extraction of the temporal saliency from the compressed-domain motion information. The level of uncertainty is calculated to combine to form the video's saliency map. Afterwards, the QP search range is dynamically adjusted in HEVC, and a rate distortion calculation method is proposed to choose the pattern and guide the allocation of bits during the video compression process. Empirical reporting results proved the superiority of the proposed method over the state-of-the-art perceptual coding algorithms in terms of saliency detection and perceptual compression quality. © 2017 Elsevier B.V.","HD video; HEVC; Perception; Saliency; Video compression","Codes (symbols); Deep neural networks; Electric distortion; Image coding; Image segmentation; Network coding; Neural networks; Optimization; Sensory perception; Signal distortion; Signal encoding; Video signal processing; Convolutional neural network; HD videos; HEVC; High-efficiency video coding; Perceptual video coding; Saliency; The region of interest (ROI); Video compression process; analytic method; Article; artificial neural network; brain function; coding algorithm; empirical research; human; image analysis; machine learning; motivation; perception; priority journal; salience network; videorecording; vision; Image compression","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85029566947"
"Chen J.; Zhang X.; Cheng Y.; Xi N.","Chen, Jiangcheng (54973366400); Zhang, Xiaodong (56178837800); Cheng, Yu (56119442000); Xi, Ning (7103381558)","54973366400; 56178837800; 56119442000; 7103381558","Surface EMG based continuous estimation of human lower limb joint angles by using deep belief networks","2018","Biomedical Signal Processing and Control","129","10.1016/j.bspc.2017.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042662298&doi=10.1016%2fj.bspc.2017.10.002&partnerID=40&md5=c8864223367712e8ad8c7b9d30ed0b4c","School of Mechanical Engineering, Xi'an Jiaotong University, Shannxi, 710049, China; Department of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, Pokfulam, Hong Kong","Chen J., School of Mechanical Engineering, Xi'an Jiaotong University, Shannxi, 710049, China, Department of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, Pokfulam, Hong Kong; Zhang X., School of Mechanical Engineering, Xi'an Jiaotong University, Shannxi, 710049, China; Cheng Y., Department of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, Pokfulam, Hong Kong; Xi N., Department of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, Pokfulam, Hong Kong","Surface electromyography (EMG) signals have been widely used in locomotion studies and human-machine interface applications. In this paper, a regression model which relates the multichannel surface EMG signals to human lower limb flexion/extension (FE) joint angles is constructed. In the experimental paradigm, three dimensional trajectories of 16 external markers on the human lower limbs were recorded by optical motion capture system and surface EMG signals from 10 muscles directly concerned with the lower limb motion were recorded synchronously. With the raw data, the joint angles of hip, knee and ankle were calculated accurately and the time series of intensity for surface EMG signals were extracted. Then, a deep belief networks (DBN) that consists of restricted Boltzmann machines (RBM) was built, by which the multi-channel processed surface EMG signals were encoded in low dimensional space and the optimal features were extracted. Finally, a back propagation (BP) neural network was used to map the optimal surface EMG features to the FE joint angles. The results show that, the features extracted from multichannel surface EMG signals using DBN method proposed in this paper outperform principal components analysis (PCA), and the root mean square error (RMSE) between the estimated joint angles and calculated ones during human walking is reduced by about 50%. The proposed model is expected to develop human-machine interaction interface to achieve continuous bioelectric control and to improve motion stability between human and machine, especially for lower limb wearable intelligent equipment. © 2017","Back propagation network; Deep belief networks; Joint angle estimation; Multichannel surface EMG; Principal components analysis; Restricted boltzmann machines","Backpropagation; Man machine systems; Mean square error; Regression analysis; Backpropagation network; Deep belief networks; Joint angle; Multichannel surface EMG; Principal components analysis; Restricted boltzmann machine; adult; ankle; Article; back propagation; bioenergy; deep belief network; electromyography; hip; human; human experiment; joint; knee; lower limb; mathematical computing; motion; muscle; network learning; normal human; principal component analysis; priority journal; range of motion; walking; Joints (anatomy)","Elsevier Ltd","17468094","","","","Article","Scopus","2-s2.0-85042662298"
"Liu M.; Wu W.; Gu Z.; Yu Z.; Qi F.; Li Y.","Liu, Mingfei (57195672820); Wu, Wei (56529849100); Gu, Zhenghui (57204214680); Yu, Zhuliang (58266105300); Qi, FeiFei (56530145300); Li, Yuanqing (55936283000)","57195672820; 56529849100; 57204214680; 58266105300; 56530145300; 55936283000","Deep learning based on Batch Normalization for P300 signal detection","2018","Neurocomputing","180","10.1016/j.neucom.2017.08.039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029534055&doi=10.1016%2fj.neucom.2017.08.039&partnerID=40&md5=97fc17035463e8d728ff4888951e0863","School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China","Liu M., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Wu W., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Gu Z., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Yu Z., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Qi F., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Li Y., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China","Detecting P300 signals from electroencephalography (EEG) is the key to establishing a P300 speller, which is a type of brain–computer interface (BCI) system based on the oddball paradigm that allows users to type messages simply by controlling eye-gazes. The convolutional neural network (CNN) is an approach that has achieved good P300 detection performances. However, the standard CNN may be prone to overfitting and the convergence may be slow. To address these issues, we develop a novel CNN, termed BN3, for detecting P300 signals, where Batch Normalization is introduced in the input and convolutional layers to alleviate over-fitting, and the rectified linear unit (ReLU) is employed in the convolutional layers to accelerate training. Since our model is fully data-driven, it is capable of automatically capturing the discriminative spatio-temporal features of the P300 signal. The results obtained on previous BCI competition P300 data sets show that BN3 both achieves the state-of-the-art character recognition performance and that it outperforms existing detection approaches with small flashing epoch numbers. BN3 can be used to improve the character recognition performance in P300 speller systems. © 2017 Elsevier B.V.","Brain–computer interface (BCI); Convolutional neural network (CNN); Deep learning; P300","Biomedical signal processing; Character recognition; Convolution; Deep learning; Electroencephalography; Electrophysiology; Interfaces (computer); Neural networks; Signal detection; Convolutional neural network; Detection approach; Detection performance; Linear units; Oddball paradigms; P300; Spatio temporal features; State of the art; Article; artificial neural network; batch normalization; batch normalized neural network; brain computer interface; deep learning; electroencephalography; event related potential; machine learning; mathematical computing; mathematical model; priority journal; recognition; signal detection; Brain computer interface","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85029534055"
"Ubbens J.; Cieslak M.; Prusinkiewicz P.; Stavness I.","Ubbens, Jordan (56674735900); Cieslak, Mikolaj (23487794100); Prusinkiewicz, Przemyslaw (35607698000); Stavness, Ian (13105285000)","56674735900; 23487794100; 35607698000; 13105285000","The use of plant models in deep learning: An application to leaf counting in rosette plants","2018","Plant Methods","181","10.1186/s13007-018-0273-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040715789&doi=10.1186%2fs13007-018-0273-z&partnerID=40&md5=0ab511570db9893ff9724382ee6aa2ae","University of Saskatchewan, 105 Administration Place, Saskatoon, S7N 5C5, Canada; University of Calgary, 2500 University Dr NW, Calgary, T2N 1N4, Canada","Ubbens J., University of Saskatchewan, 105 Administration Place, Saskatoon, S7N 5C5, Canada; Cieslak M., University of Calgary, 2500 University Dr NW, Calgary, T2N 1N4, Canada; Prusinkiewicz P., University of Calgary, 2500 University Dr NW, Calgary, T2N 1N4, Canada; Stavness I., University of Saskatchewan, 105 Administration Place, Saskatoon, S7N 5C5, Canada","Deep learning presents many opportunities for image-based plant phenotyping. Here we consider the capability of deep convolutional neural networks to perform the leaf counting task. Deep learning techniques typically require large and diverse datasets to learn generalizable models without providing a priori an engineered algorithm for performing the task. This requirement is challenging, however, for applications in the plant phenotyping field, where available datasets are often small and the costs associated with generating new data are high. In this work we propose a new method for augmenting plant phenotyping datasets using rendered images of synthetic plants. We demonstrate that the use of high-quality 3D synthetic plants to augment a dataset can improve performance on the leaf counting task. We also show that the ability of the model to generate an arbitrary distribution of phenotypes mitigates the problem of dataset shift when training and testing on different datasets. Finally, we show that real and synthetic plants are significantly interchangeable when training a neural network on the leaf counting task. © 2018 The Author(s).","3D plant modeling; Deep learning; L-system; Machine learning; Phenotyping","","BioMed Central Ltd.","17464811","","","","Article","Scopus","2-s2.0-85040715789"
"Jia F.; Lei Y.; Guo L.; Lin J.; Xing S.","Jia, Feng (35190546800); Lei, Yaguo (8905846900); Guo, Liang (57216424083); Lin, Jing (55710008100); Xing, Saibo (57188864198)","35190546800; 8905846900; 57216424083; 55710008100; 57188864198","A neural network constructed by deep learning technique and its application to intelligent fault diagnosis of machines","2018","Neurocomputing","439","10.1016/j.neucom.2017.07.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025667855&doi=10.1016%2fj.neucom.2017.07.032&partnerID=40&md5=f80f90b99a12369770945b0b9e7554f4","State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, 710049, China","Jia F., State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Lei Y., State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Guo L., State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Lin J., State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Xing S., State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, 710049, China","In traditional intelligent fault diagnosis methods of machines, plenty of actual effort is taken for the manual design of fault features, which makes these methods less automatic. Among deep learning techniques, autoencoders may be a potential tool for automatic feature extraction of mechanical signals. However, traditional autoencoders have two following shortcomings. (1) They may learn similar features in mechanical feature extraction. (2) The learned features have shift variant properties, which leads to the misclassification of mechanical health conditions. To overcome the aforementioned shortcomings, a local connection network (LCN) constructed by normalized sparse autoencoder (NSAE), namely NSAE-LCN, is proposed for intelligent fault diagnosis. We construct LCN by input layer, local layer, feature layer and output layer. When raw vibration signals are fed to the input layer, LCN first uses NSAE to locally learn various meaningful features from input signals in the local layer, then obtains shift-invariant features in the feature layer and finally recognizes mechanical health conditions in the output layer. Thus, NSAE-LCN incorporates feature extraction and fault recognition into a general-purpose learning procedure. A gearbox dataset and a bearing dataset are used to validate the performance of the proposed NSAE-LCN. The results indicate that the learned features of NSAE are meaningful and dissimilar, and LCN helps to produce shift-invariant features and recognizes mechanical health conditions effectively. Through comparing with commonly used diagnosis methods, the superiority of the proposed NSAE-LCN is verified. © 2017 Elsevier B.V.","Deep learning; Intelligent fault diagnosis; Local connection network; Normalized sparse autoencoder","Deep neural networks; Education; Extraction; Failure analysis; Fault detection; Feature extraction; Health; Learning algorithms; Learning systems; Vibrations (mechanical); Auto encoders; Automatic feature extraction; Intelligent fault diagnosis; Learning procedures; Learning techniques; Local connections; Mechanical feature; Mechanical signals; area under the curve; Article; artificial neural network; automation; calculation; controlled study; information processing; intelligent fault diagnosis; learning algorithm; local connection network; machine learning; measurement accuracy; nonlinear system; principal component analysis; priority journal; receiver operating characteristic; support vector machine; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85025667855"
"Jiménez J.; Škalič M.; Martínez-Rosell G.; De Fabritiis G.","Jiménez, José (57202851960); Škalič, Miha (57200964233); Martínez-Rosell, Gerard (57195137038); De Fabritiis, Gianni (22134417700)","57202851960; 57200964233; 57195137038; 22134417700","KDEEP: Protein-Ligand Absolute Binding Affinity Prediction via 3D-Convolutional Neural Networks","2018","Journal of Chemical Information and Modeling","527","10.1021/acs.jcim.7b00650","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042374412&doi=10.1021%2facs.jcim.7b00650&partnerID=40&md5=7277ab6f9c02581f2a16c99e41556790","Computational Biophysics Laboratory, Universitat Pompeu Fabra, Parc de Recerca Biomèdica de Barcelona, Carrer del Dr. Aiguader 88, Barcelona, 08003, Spain; Institució Catalana de Recerca i Estudis Avançats (ICREA), Passeig Lluis Companys 23, Barcelona, 08010, Spain","Jiménez J., Computational Biophysics Laboratory, Universitat Pompeu Fabra, Parc de Recerca Biomèdica de Barcelona, Carrer del Dr. Aiguader 88, Barcelona, 08003, Spain; Škalič M., Computational Biophysics Laboratory, Universitat Pompeu Fabra, Parc de Recerca Biomèdica de Barcelona, Carrer del Dr. Aiguader 88, Barcelona, 08003, Spain; Martínez-Rosell G., Computational Biophysics Laboratory, Universitat Pompeu Fabra, Parc de Recerca Biomèdica de Barcelona, Carrer del Dr. Aiguader 88, Barcelona, 08003, Spain; De Fabritiis G., Computational Biophysics Laboratory, Universitat Pompeu Fabra, Parc de Recerca Biomèdica de Barcelona, Carrer del Dr. Aiguader 88, Barcelona, 08003, Spain, Institució Catalana de Recerca i Estudis Avançats (ICREA), Passeig Lluis Companys 23, Barcelona, 08010, Spain","Accurately predicting protein-ligand binding affinities is an important problem in computational chemistry since it can substantially accelerate drug discovery for virtual screening and lead optimization. We propose here a fast machine-learning approach for predicting binding affinities using state-of-the-art 3D-convolutional neural networks and compare this approach to other machine-learning and scoring methods using several diverse data sets. The results for the standard PDBbind (v.2016) core test-set are state-of-the-art with a Pearson's correlation coefficient of 0.82 and a RMSE of 1.27 in pK units between experimental and predicted affinity, but accuracy is still very sensitive to the specific protein used. KDEEP is made available via PlayMolecule.org for users to test easily their own protein-ligand complexes, with each prediction taking a fraction of a second. We believe that the speed, performance, and ease of use of KDEEP makes it already an attractive scoring function for modern computational chemistry pipelines. © 2018 American Chemical Society.","","Computational Biology; Databases, Protein; Deep Learning; Drug Discovery; Ligands; Models, Chemical; Protein Binding; Proteins; Structure-Activity Relationship; Binding energy; Complexation; Computational chemistry; Convolution; Correlation methods; Forecasting; Ligands; Machine learning; Proteins; ligand; protein; protein binding; Binding affinities; Diverse data sets; Lead optimization; Machine learning approaches; Pearson's correlation coefficients; Protein-ligand binding affinities; Protein-ligand complexes; Scoring functions; biology; chemical model; chemistry; drug development; procedures; protein database; structure activity relation; Convolutional neural networks","American Chemical Society","15499596","","JCISD","29309725","Article","Scopus","2-s2.0-85042374412"
"Kalantari A.; Kamsin A.; Shamshirband S.; Gani A.; Alinejad-Rokny H.; Chronopoulos A.T.","Kalantari, Ali (57195836404); Kamsin, Amirrudin (57200104818); Shamshirband, Shahaboddin (57221738247); Gani, Abdullah (57218294440); Alinejad-Rokny, Hamid (53871090400); Chronopoulos, Anthony T. (23126220800)","57195836404; 57200104818; 57221738247; 57218294440; 53871090400; 23126220800","Computational intelligence approaches for classification of medical data: State-of-the-art, future challenges and research directions","2018","Neurocomputing","92","10.1016/j.neucom.2017.01.126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029908853&doi=10.1016%2fj.neucom.2017.01.126&partnerID=40&md5=a51357ab9da2c75b6784b2041016f594","Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, 50603, Malaysia; Department for Management of Science and Technology Development, Ton Duc Thang University, Ho Chi Minh City, Viet Nam; Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Viet Nam; UNSW Australia, Australia; Department of Computer Science, University of Texas, San Antonio, 78249, TX, United States; Department of Computer Science (Visiting Faculty), University of Patras, Greece","Kalantari A., Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, 50603, Malaysia; Kamsin A., Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, 50603, Malaysia; Shamshirband S., Department for Management of Science and Technology Development, Ton Duc Thang University, Ho Chi Minh City, Viet Nam, Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Viet Nam; Gani A., Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, 50603, Malaysia; Alinejad-Rokny H., UNSW Australia, Australia; Chronopoulos A.T., Department of Computer Science, University of Texas, San Antonio, 78249, TX, United States, Department of Computer Science (Visiting Faculty), University of Patras, Greece","The explosive growth of data in volume, velocity and diversity that are produced by medical applications has contributed to abundance of big data. Current solutions for efficient data storage and management cannot fulfill the needs of heterogeneous data. Therefore, by applying computational intelligence (CI) approaches in medical data helps get better management, faster performance and higher level of accuracy in detection. This paper aims to investigate the state-of-the-art of computational intelligence approaches in medical data and to categorize the existing CI techniques, used in medical fields, as single and hybrid. In addition, the techniques and methodologies, their limitations and performances are presented in this study. The limitations are addressed as challenges to obtain a set of requirements for Computational Intelligence Medical Data (CIMD) in establishing an efficient CIMD architectural design. The results show that on the one hand Support Vector Machine (SVM) and Artificial Immune Recognition System (AIRS) as a single based computational intelligence approach were the best methods in medical applications. On the other hand, the hybridization of SVM with other methods such as SVM-Genetic Algorithm (SVM-GA), SVM-Artificial Immune System (SVM-AIS), SVM-AIRS and fuzzy support vector machine (FSVM) had great performances achieving better results in terms of accuracy, sensitivity and specificity. © 2017","Big data; Computational intelligence; Detection; Ensemble algorithm; Medical application","Artificial intelligence; Automatic identification; Big data; Digital storage; Error detection; Genetic algorithms; Information management; Infrared devices; Intelligent computing; Medical applications; Support vector machines; Artificial immune recognition system; Artificial Immune System; Ensemble algorithms; Explosive growth; Future challenges; Fuzzy support vector machine (FSVM); Heterogeneous data; Sensitivity and specificity; art; Article; artificial immune recognition system; artificial immune system; artificial neural network; biomedical engineering; classification; computational intelligence; Computational Intelligence Medical Data; controlled study; convolutional neural network; data analysis; deep learning; extreme learning machine; firefly algorithm; fuzzy c mean; fuzzy rule base; fuzzy support vector machine; fuzzy system; genetic algorithm; hybrid; kernel method; learning; mathematical model; measurement accuracy; medical informatics; medical research; neuro fuzzy; particle swarm optimization; perceptron; performance; priority journal; self organizing map; sensitivity and specificity; support vector machine; wavelet transformation; Medical computing","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85029908853"
"Fan J.; Cheng J.","Fan, Jicong (57194228850); Cheng, Jieyu (55492710000)","57194228850; 55492710000","Matrix completion by deep matrix factorization","2018","Neural Networks","117","10.1016/j.neunet.2017.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034051911&doi=10.1016%2fj.neunet.2017.10.007&partnerID=40&md5=f599a166d6ed2b6bc8ab84e546af7a60","Department of Electronic Engineering, City University of Hong Kong, Tat Chee Avenue, Kowloon, Hong Kong","Fan J., Department of Electronic Engineering, City University of Hong Kong, Tat Chee Avenue, Kowloon, Hong Kong; Cheng J., Department of Electronic Engineering, City University of Hong Kong, Tat Chee Avenue, Kowloon, Hong Kong","Conventional methods of matrix completion are linear methods that are not effective in handling data of nonlinear structures. Recently a few researchers attempted to incorporate nonlinear techniques into matrix completion but there still exists considerable limitations. In this paper, a novel method called deep matrix factorization (DMF) is proposed for nonlinear matrix completion. Different from conventional matrix completion methods that are based on linear latent variable models, DMF is on the basis of a nonlinear latent variable model. DMF is formulated as a deep-structure neural network, in which the inputs are the low-dimensional unknown latent variables and the outputs are the partially observed variables. In DMF, the inputs and the parameters of the multilayer neural network are simultaneously optimized to minimize the reconstruction errors for the observed entries. Then the missing entries can be readily recovered by propagating the latent variables to the output layer. DMF is compared with state-of-the-art methods of linear and nonlinear matrix completion in the tasks of toy matrix completion, image inpainting and collaborative filtering. The experimental results verify that DMF is able to provide higher matrix completion accuracy than existing methods do and DMF is applicable to large matrices. © 2017 Elsevier Ltd","Collaborative filtering; Deep learning; Image inpainting; Matrix completion; Matrix factorization","Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Case based reasoning; Collaborative filtering; Data handling; Deep learning; Equivalence classes; Factorization; Image processing; Multilayer neural networks; Conventional methods; Image Inpainting; Latent variable modeling; Linear latent variables; Matrix completion; Matrix factorizations; Nonlinear techniques; State-of-the-art methods; accuracy; art; Article; collarborative filtering; deep matrix factorization; error; group image inpainting; image analysis; image inpainting; linear system; matrix completion; multi layer neural network; nerve cell network; nonlinear system; priority journal; problem solving; process optimization; reconstruction error; signal processing; single image inpainting; single layer neural network; state of the art; task performance; artificial neural network; automated pattern recognition; machine learning; procedures; Matrix algebra","Elsevier Ltd","08936080","","NNETE","29154225","Article","Scopus","2-s2.0-85034051911"
"Esses S.J.; Lu X.; Zhao T.; Shanbhogue K.; Dane B.; Bruno M.; Chandarana H.","Esses, Steven J. (23093568600); Lu, Xiaoguang (57221057043); Zhao, Tiejun (54920599100); Shanbhogue, Krishna (26021491300); Dane, Bari (57156158900); Bruno, Mary (56415777500); Chandarana, Hersh (24480662500)","23093568600; 57221057043; 54920599100; 26021491300; 57156158900; 56415777500; 24480662500","                         Automated image quality evaluation of T                         2                         -weighted liver MRI utilizing deep learning architecture                     ","2018","Journal of Magnetic Resonance Imaging","86","10.1002/jmri.25779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020071856&doi=10.1002%2fjmri.25779&partnerID=40&md5=e82ff04dd69b4a0b623cb3f0bd4d71d3","Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States; Siemens Healthineers, New York, NY, United States","Esses S.J., Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States; Lu X., Siemens Healthineers, New York, NY, United States; Zhao T., Siemens Healthineers, New York, NY, United States; Shanbhogue K., Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States; Dane B., Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States; Bruno M., Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States; Chandarana H., Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine, New York, NY, United States","                             Purpose: To develop and test a deep learning approach named Convolutional Neural Network (CNN) for automated screening of T                             2                             -weighted (T                             2                             WI) liver acquisitions for nondiagnostic images, and compare this automated approach to evaluation by two radiologists. Materials and Methods: We evaluated 522 liver magnetic resonance imaging (MRI) exams performed at 1.5T and 3T at our institution between November 2014 and May 2016 for CNN training and validation. The CNN consisted of an input layer, convolutional layer, fully connected layer, and output layer. 351 T                             2                             WI were anonymized for training. Each case was annotated with a label of being diagnostic or nondiagnostic for detecting lesions and assessing liver morphology. Another independently collected 171 cases were sequestered for a blind test. These 171 T                             2                             WI were assessed independently by two radiologists and annotated as being diagnostic or nondiagnostic. These 171 T                             2                             WI were presented to the CNN algorithm and image quality (IQ) output of the algorithm was compared to that of two radiologists. Results: There was concordance in IQ label between Reader 1 and CNN in 79% of cases and between Reader 2 and CNN in 73%. The sensitivity and the specificity of the CNN algorithm in identifying nondiagnostic IQ was 67% and 81% with respect to Reader 1 and 47% and 80% with respect to Reader 2. The negative predictive value of the algorithm for identifying nondiagnostic IQ was 94% and 86% (relative to Readers 1 and 2). Conclusion: We demonstrate a CNN algorithm that yields a high negative predictive value when screening for nondiagnostic T                             2                             WI of the liver. Level of Evidence: 2. Technical Efficacy: Stage 2. J. Magn. Reson. Imaging 2018;47:723–728.                          © 2017 International Society for Magnetic Resonance in Medicine","convolutional neuronal network; deep learning; image quality; liver MRI; machine learning; T2 weighted imaging","Algorithms; Deep Learning; Female; Humans; Image Interpretation, Computer-Assisted; Liver; Liver Diseases; Magnetic Resonance Imaging; Male; Middle Aged; Observer Variation; Retrospective Studies; Sensitivity and Specificity; adult; algorithm; Article; artificial neural network; controlled study; convolutional neural network; female; hepatography; human; image analysis; image processing; image quality; laboratory automation; major clinical study; male; nuclear magnetic resonance imaging; predictive value; priority journal; radiologist; retrospective study; sensitivity and specificity; validation process; computer assisted diagnosis; diagnostic imaging; liver; liver disease; middle aged; nuclear magnetic resonance imaging; observer variation; procedures","John Wiley and Sons Inc.","10531807","","JMRIF","28577329","Article","Scopus","2-s2.0-85020071856"
"Alakwaa F.M.; Chaudhary K.; Garmire L.X.","Alakwaa, Fadhl M. (40560904400); Chaudhary, Kumardeep (57214346757); Garmire, Lana X. (22955585300)","40560904400; 57214346757; 22955585300","Deep Learning Accurately Predicts Estrogen Receptor Status in Breast Cancer Metabolomics Data","2018","Journal of Proteome Research","158","10.1021/acs.jproteome.7b00595","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040193110&doi=10.1021%2facs.jproteome.7b00595&partnerID=40&md5=97ebc86b4a1ed71566b59d61d4b0c42c","Epidemiology Program, University of Hawaii Cancer Center, Honolulu, 96813, HI, United States; Molecular Biosciences and Bioengineering Graduate Program, University of Hawaii at Manoa, Honolulu, 96822, HI, United States","Alakwaa F.M., Epidemiology Program, University of Hawaii Cancer Center, Honolulu, 96813, HI, United States; Chaudhary K., Epidemiology Program, University of Hawaii Cancer Center, Honolulu, 96813, HI, United States; Garmire L.X., Epidemiology Program, University of Hawaii Cancer Center, Honolulu, 96813, HI, United States, Molecular Biosciences and Bioengineering Graduate Program, University of Hawaii at Manoa, Honolulu, 96822, HI, United States","Metabolomics holds the promise as a new technology to diagnose highly heterogeneous diseases. Conventionally, metabolomics data analysis for diagnosis is done using various statistical and machine learning based classification methods. However, it remains unknown if deep neural network, a class of increasingly popular machine learning methods, is suitable to classify metabolomics data. Here we use a cohort of 271 breast cancer tissues, 204 positive estrogen receptor (ER+), and 67 negative estrogen receptor (ER-) to test the accuracies of feed-forward networks, a deep learning (DL) framework, as well as six widely used machine learning models, namely random forest (RF), support vector machines (SVM), recursive partitioning and regression trees (RPART), linear discriminant analysis (LDA), prediction analysis for microarrays (PAM), and generalized boosted models (GBM). DL framework has the highest area under the curve (AUC) of 0.93 in classifying ER+/ER- patients, compared to the other six machine learning algorithms. Furthermore, the biological interpretation of the first hidden layer reveals eight commonly enriched significant metabolomics pathways (adjusted P-value <0.05) that cannot be discovered by other machine learning methods. Among them, protein digestion and absorption and ATP-binding cassette (ABC) transporters pathways are also confirmed in integrated analysis between metabolomics and gene expression data in these samples. In summary, deep learning method shows advantages for metabolomics based breast cancer ER status classification, with both the highest prediction accuracy (AUC = 0.93) and better revelation of disease biology. We encourage the adoption of feed-forward networks based deep learning method in the metabolomics research community for classification. © 2017 American Chemical Society.","bioinformatics; breast cancer; deep learning; estrogen receptor; metabolomics","Area Under Curve; Breast Neoplasms; Female; Humans; Machine Learning; Metabolomics; Receptors, Estrogen; estrogen receptor; estrogen receptor; absorption; Article; breast cancer; comparative study; controlled study; discriminant analysis; gas chromatography; gene expression; generalized boosted models; human; human cell; human tissue; k nearest neighbor; linear discriminant analysis; machine learning; MCF-10A cell line; MCF-7 cell line; MDA-MB-231 cell line; metabolomics; prediction analysis for microarrays; priority journal; random forest; recursive partitioning and regression trees; support vector machine; area under the curve; breast tumor; classification; female; machine learning; metabolomics; procedures; standards","American Chemical Society","15353893","","JPROB","29110491","Article","Scopus","2-s2.0-85040193110"
"Arcos-García Á.; Álvarez-García J.A.; Soria-Morillo L.M.","Arcos-García, Álvaro (57191440061); Álvarez-García, Juan A. (36902641500); Soria-Morillo, Luis M. (36919178400)","57191440061; 36902641500; 36919178400","Deep neural network for traffic sign recognition systems: An analysis of spatial transformers and stochastic optimisation methods","2018","Neural Networks","166","10.1016/j.neunet.2018.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041386801&doi=10.1016%2fj.neunet.2018.01.005&partnerID=40&md5=735d5839f45e801e09576e1068e78de0","Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Sevilla, 41012, Spain","Arcos-García Á., Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Sevilla, 41012, Spain; Álvarez-García J.A., Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Sevilla, 41012, Spain; Soria-Morillo L.M., Dpto. de Lenguajes y Sistemas Informáticos, Universidad de Sevilla, Sevilla, 41012, Spain","This paper presents a Deep Learning approach for traffic sign recognition systems. Several classification experiments are conducted over publicly available traffic sign datasets from Germany and Belgium using a Deep Neural Network which comprises Convolutional layers and Spatial Transformer Networks. Such trials are built to measure the impact of diverse factors with the end goal of designing a Convolutional Neural Network that can improve the state-of-the-art of traffic sign classification task. First, different adaptive and non-adaptive stochastic gradient descent optimisation algorithms such as SGD, SGD-Nesterov, RMSprop and Adam are evaluated. Subsequently, multiple combinations of Spatial Transformer Networks placed at distinct positions within the main neural network are analysed. The recognition rate of the proposed Convolutional Neural Network reports an accuracy of 99.71% in the German Traffic Sign Recognition Benchmark, outperforming previous state-of-the-art methods and also being more efficient in terms of memory requirements. © 2018 Elsevier Ltd","Convolutional neural network; Deep learning; Spatial transformer network; Traffic sign","Algorithms; Automobile Driving; Benchmarking; Databases, Factual; Humans; Location Directories and Signs; Machine Learning; Neural Networks (Computer); Pattern Recognition, Visual; Stochastic Processes; Classification (of information); Convolution; Deep learning; Neural networks; Optimization; Pattern recognition; Stochastic systems; Traffic signs; Classification tasks; Convolutional neural network; Learning approach; Memory requirements; State-of-the-art methods; Stochastic gradient descent; Stochastic optimisation; Traffic sign recognition; Article; artificial neural network; Belgium; classification; deep neural network; Germany; information system; machine learning; mathematical analysis; priority journal; quality control; spatial analysis; stochastic model; traffic sign recognition system; algorithm; benchmarking; car driving; classification; construction work and architectural phenomena; factual database; human; machine learning; Markov chain; pattern recognition; physiology; trends; Deep neural networks","Elsevier Ltd","08936080","","NNETE","29427842","Article","Scopus","2-s2.0-85041386801"
"Terunuma T.; Tokui A.; Sakae T.","Terunuma, Toshiyuki (6602685086); Tokui, Aoi (57200099955); Sakae, Takeji (7006498188)","6602685086; 57200099955; 7006498188","Novel real-time tumor-contouring method using deep learning to prevent mistracking in X-ray fluoroscopy","2018","Radiological Physics and Technology","24","10.1007/s12194-017-0435-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039561393&doi=10.1007%2fs12194-017-0435-0&partnerID=40&md5=0df5e982866dc810cd16f9ac8b61d5cb","Faculty of Medicine, University of Tsukuba, Ten-nohdai 1-1-1, Tsukuba, 305-8575, Japan; Proton Medical Research Center (PMRC), University of Tsukuba Hospital, Amakubo 2-1-1, Tsukuba, 305-8576, Japan; Graduate School of Comprehensive Human Science, University of Tsukuba, Ten-nohdai 1-1-1, Tsukuba, 305-8575, Japan","Terunuma T., Faculty of Medicine, University of Tsukuba, Ten-nohdai 1-1-1, Tsukuba, 305-8575, Japan, Proton Medical Research Center (PMRC), University of Tsukuba Hospital, Amakubo 2-1-1, Tsukuba, 305-8576, Japan; Tokui A., Graduate School of Comprehensive Human Science, University of Tsukuba, Ten-nohdai 1-1-1, Tsukuba, 305-8575, Japan; Sakae T., Faculty of Medicine, University of Tsukuba, Ten-nohdai 1-1-1, Tsukuba, 305-8575, Japan, Proton Medical Research Center (PMRC), University of Tsukuba Hospital, Amakubo 2-1-1, Tsukuba, 305-8576, Japan","Robustness to obstacles is the most important factor necessary to achieve accurate tumor tracking without fiducial markers. Some high-density structures, such as bone, are enhanced on X-ray fluoroscopic images, which cause tumor mistracking. Tumor tracking should be performed by controlling “importance recognition”: the understanding that soft-tissue is an important tracking feature and bone structure is unimportant. We propose a new real-time tumor-contouring method that uses deep learning with importance recognition control. The novelty of the proposed method is the combination of the devised random overlay method and supervised deep learning to induce the recognition of structures in tumor contouring as important or unimportant. This method can be used for tumor contouring because it uses deep learning to perform image segmentation. Our results from a simulated fluoroscopy model showed accurate tracking of a low-visibility tumor with an error of approximately 1 mm, even if enhanced bone structure acted as an obstacle. A high similarity of approximately 0.95 on the Jaccard index was observed between the segmented and ground truth tumor regions. A short processing time of 25 ms was achieved. The results of this simulated fluoroscopy model support the feasibility of robust real-time tumor contouring with fluoroscopy. Further studies using clinical fluoroscopy are highly anticipated. © 2017, The Author(s).","Data augmentation; Image recognition; Markerless tumor tracking; Supervised deep learning; Tumor contouring; X-ray fluoroscopy","Algorithms; Fiducial Markers; Fluoroscopy; Humans; Lung Neoplasms; Machine Learning; Pattern Recognition, Automated; Radiographic Image Interpretation, Computer-Assisted; Tomography, X-Ray Computed; X-Rays; Article; bone structure; clinical article; controlled study; correlational study; diagnostic accuracy; diagnostic error; fluoroscopy; human; image enhancement; image segmentation; lung cancer; mathematical model; priority journal; radiodiagnosis; respiratory gated imaging; soft tissue; supervised machine learning; tumor classification; tumor contouring method; tumor localization; tumor volume; visibility; algorithm; automated pattern recognition; computer assisted diagnosis; diagnostic imaging; fiducial marker; fluoroscopy; lung tumor; machine learning; procedures; standards; X ray; x-ray computed tomography","Springer Tokyo","18650333","","","29285686","Article","Scopus","2-s2.0-85039561393"
"Zreik M.; Lessmann N.; van Hamersvelt R.W.; Wolterink J.M.; Voskuil M.; Viergever M.A.; Leiner T.; Išgum I.","Zreik, Majd (45861597300); Lessmann, Nikolas (56088955100); van Hamersvelt, Robbert W. (56182844700); Wolterink, Jelmer M. (56198388700); Voskuil, Michiel (7004042874); Viergever, Max A. (57203030739); Leiner, Tim (7004171845); Išgum, Ivana (6507874503)","45861597300; 56088955100; 56182844700; 56198388700; 7004042874; 57203030739; 7004171845; 6507874503","Deep learning analysis of the myocardium in coronary CT angiography for identification of patients with functionally significant coronary artery stenosis","2018","Medical Image Analysis","151","10.1016/j.media.2017.11.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037130569&doi=10.1016%2fj.media.2017.11.008&partnerID=40&md5=b664911044958759342c7fca2cb7b71d","Image Sciences Institute, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands; Department of Radiology, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands; Department of Cardiology, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands","Zreik M., Image Sciences Institute, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands; Lessmann N., Image Sciences Institute, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands; van Hamersvelt R.W., Department of Radiology, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands; Wolterink J.M., Image Sciences Institute, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands; Voskuil M., Department of Cardiology, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands; Viergever M.A., Image Sciences Institute, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands; Leiner T., Department of Radiology, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands; Išgum I., Image Sciences Institute, University Medical Center Utrecht and Utrecht University, Utrecht, Netherlands","In patients with coronary artery stenoses of intermediate severity, the functional significance needs to be determined. Fractional flow reserve (FFR) measurement, performed during invasive coronary angiography (ICA), is most often used in clinical practice. To reduce the number of ICA procedures, we present a method for automatic identification of patients with functionally significant coronary artery stenoses, employing deep learning analysis of the left ventricle (LV) myocardium in rest coronary CT angiography (CCTA). The study includes consecutively acquired CCTA scans of 166 patients who underwent invasive FFR measurements. To identify patients with a functionally significant coronary artery stenosis, analysis is performed in several stages. First, the LV myocardium is segmented using a multiscale convolutional neural network (CNN). To characterize the segmented LV myocardium, it is subsequently encoded using unsupervised convolutional autoencoder (CAE). As ischemic changes are expected to appear locally, the LV myocardium is divided into a number of spatially connected clusters, and statistics of the encodings are computed as features. Thereafter, patients are classified according to the presence of functionally significant stenosis using an SVM classifier based on the extracted features. Quantitative evaluation of LV myocardium segmentation in 20 images resulted in an average Dice coefficient of 0.91 and an average mean absolute distance between the segmented and reference LV boundaries of 0.7 mm. Twenty CCTA images were used to train the LV myocardium encoder. Classification of patients was evaluated in the remaining 126 CCTA scans in 50 10-fold cross-validation experiments and resulted in an area under the receiver operating characteristic curve of 0.74 ± 0.02. At sensitivity levels 0.60, 0.70 and 0.80, the corresponding specificity was 0.77, 0.71 and 0.59, respectively. The results demonstrate that automatic analysis of the LV myocardium in a single CCTA scan acquired at rest, without assessment of the anatomy of the coronary arteries, can be used to identify patients with functionally significant coronary artery stenosis. This might reduce the number of patients undergoing unnecessary invasive FFR measurements. © 2017 Elsevier B.V.","Convolutional autoencoder; Convolutional neural network; Coronary CT angiography; Deep learning; Fractional flow reserve; Functionally significant coronary artery stenosis","Algorithms; Cardiac-Gated Imaging Techniques; Computed Tomography Angiography; Contrast Media; Coronary Angiography; Coronary Stenosis; Deep Learning; Female; Heart Ventricles; Humans; Iohexol; Male; Middle Aged; Reproducibility of Results; Sensitivity and Specificity; Angiography; Automation; Blood vessels; Computerized tomography; Convolution; Heart; Hemodynamics; Image segmentation; Neural networks; iopromide; contrast medium; iohexol; Auto encoders; Convolutional neural network; Coronary artery stenosis; Coronary ct angiographies; Fractional flow reserves; adult; Article; artificial neural network; autoanalysis; cardiac muscle; computed tomographic angiography; coronary angiography; coronary artery obstruction; female; fractional flow reserve; heart left ventricle; human; major clinical study; male; middle aged; priority journal; quantitative analysis; retrospective study; sensitivity and specificity; support vector machine; algorithm; analogs and derivatives; cardiac gated imaging; computed tomographic angiography; coronary angiography; coronary artery obstruction; diagnostic imaging; heart ventricle; pathophysiology; procedures; reproducibility; Deep learning","Elsevier B.V.","13618415","","MIAEC","29197253","Article","Scopus","2-s2.0-85037130569"
"Treder M.; Lauermann J.L.; Eter N.","Treder, Maximilian (57192311362); Lauermann, Jost Lennart (57194019160); Eter, Nicole (6701536193)","57192311362; 57194019160; 6701536193","Automated detection of exudative age-related macular degeneration in spectral domain optical coherence tomography using deep learning","2018","Graefe's Archive for Clinical and Experimental Ophthalmology","167","10.1007/s00417-017-3850-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034588954&doi=10.1007%2fs00417-017-3850-3&partnerID=40&md5=5266daa48a8c6e5cb0c8a2ed361ed55b","Department of Ophthalmology, University of Muenster Medical Center, Domagkstraße 15, Muenster, 48149, Germany","Treder M., Department of Ophthalmology, University of Muenster Medical Center, Domagkstraße 15, Muenster, 48149, Germany; Lauermann J.L., Department of Ophthalmology, University of Muenster Medical Center, Domagkstraße 15, Muenster, 48149, Germany; Eter N., Department of Ophthalmology, University of Muenster Medical Center, Domagkstraße 15, Muenster, 48149, Germany","Purpose: Our purpose was to use deep learning for the automated detection of age-related macular degeneration (AMD) in spectral domain optical coherence tomography (SD-OCT). Methods: A total of 1112 cross-section SD-OCT images of patients with exudative AMD and a healthy control group were used for this study. In the first step, an open-source multi-layer deep convolutional neural network (DCNN), which was pretrained with 1.2 million images from ImageNet, was trained and validated with 1012 cross-section SD-OCT scans (AMD: 701; healthy: 311). During this procedure training accuracy, validation accuracy and cross-entropy were computed. The open-source deep learning framework TensorFlow™ (Google Inc., Mountain View, CA, USA) was used to accelerate the deep learning process. In the last step, a created DCNN classifier, using the information of the above mentioned deep learning process, was tested in detecting 100 untrained cross-section SD-OCT images (AMD: 50; healthy: 50). Therefore, an AMD testing score was computed: 0.98 or higher was presumed for AMD. Results: After an iteration of 500 training steps, the training accuracy and validation accuracies were 100%, and the cross-entropy was 0.005. The average AMD scores were 0.997 ± 0.003 in the AMD testing group and 0.9203 ± 0.085 in the healthy comparison group. The difference between the two groups was highly significant (p < 0.001). Conclusions: With a deep learning-based approach using TensorFlow™, it is possible to detect AMD in SD-OCT with high sensitivity and specificity. With more image data, an expansion of this classifier for other macular diseases or further details in AMD is possible, suggesting an application for this model as a support in clinical decisions. Another possible future application would involve the individual prediction of the progress and success of therapy for different diseases by automatically detecting hidden image information. © 2017, Springer-Verlag GmbH Germany, part of Springer Nature.","Age-related macular degeneration; Deep convolutional neural network; Deep learning; Machine learning; Optical coherence tomography","Humans; Machine Learning; Macula Lutea; Neural Networks (Computer); Reproducibility of Results; Tomography, Optical Coherence; Wet Macular Degeneration; Article; controlled study; diagnostic accuracy; human; machine learning; major clinical study; nerve cell network; priority journal; sensitivity and specificity; software; spectral domain optical coherence tomography; wet macular degeneration; artificial neural network; machine learning; optical coherence tomography; pathology; procedures; reproducibility; retina macula lutea; validation study; wet macular degeneration","Springer Verlag","0721832X","","GACOD","29159541","Article","Scopus","2-s2.0-85034588954"
"Giger M.L.","Giger, Maryellen L. (7103040897)","7103040897","Machine Learning in Medical Imaging","2018","Journal of the American College of Radiology","366","10.1016/j.jacr.2017.12.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041282278&doi=10.1016%2fj.jacr.2017.12.028&partnerID=40&md5=6940e1684e3652654a9bf15f565d0a42","Department of Radiology, The University of Chicago, Chicago, Illinois, United States","Giger M.L., Department of Radiology, The University of Chicago, Chicago, Illinois, United States","Advances in both imaging and computers have synergistically led to a rapid rise in the potential use of artificial intelligence in various radiological imaging tasks, such as risk assessment, detection, diagnosis, prognosis, and therapy response, as well as in multi-omics disease discovery. A brief overview of the field is given here, allowing the reader to recognize the terminology, the various subfields, and components of machine learning, as well as the clinical potential. Radiomics, an expansion of computer-aided diagnosis, has been defined as the conversion of images to minable data. The ultimate benefit of quantitative radiomics is to (1) yield predictive image-based phenotypes of disease for precision medicine or (2) yield quantitative image-based phenotypes for data mining with other -omics for discovery (ie, imaging genomics). For deep learning in radiology to succeed, note that well-annotated large data sets are needed since deep networks are complex, computer software and hardware are evolving constantly, and subtle differences in disease states are more difficult to perceive than differences in everyday objects. In the future, machine learning in radiology is expected to have a substantial clinical impact with imaging examinations being routinely obtained in clinical practice, providing an opportunity to improve decision support in medical image interpretation. The term of note is decision support, indicating that computers will augment human decision making, making it more effective and efficient. The clinical impact of having computers in the routine clinical practice may allow radiologists to further integrate their knowledge with their clinical colleagues in other medical specialties and allow for precision medicine. © 2018","computer-aided diagnosis; computer-assisted decision support; deep learning; Machine learning; radiomics","Data Mining; Decision Support Techniques; Deep Learning; Forecasting; Humans; Machine Learning; Precision Medicine; Radiology; Terminology as Topic; Article; computer aided design; computer assisted radiography; decision support system; diagnostic imaging; genomics; human; machine learning; omics; radiology; data mining; decision support system; forecasting; nomenclature; personalized medicine; trends","Elsevier B.V.","15461440","","","29398494","Article","Scopus","2-s2.0-85041282278"
"Cepeda M.S.; Reps J.; Fife D.; Blacketer C.; Stang P.; Ryan P.","Cepeda, M. Soledad (16427430700); Reps, Jenna (43061445600); Fife, Daniel (7005585461); Blacketer, Clair (57189849154); Stang, Paul (7102568960); Ryan, Patrick (36469223700)","16427430700; 43061445600; 7005585461; 57189849154; 7102568960; 36469223700","Finding treatment-resistant depression in real-world data: How a data-driven approach compares with expert-based heuristics","2018","Depression and Anxiety","35","10.1002/da.22705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038023814&doi=10.1002%2fda.22705&partnerID=40&md5=423120777b4c7569074f8642c079ad2e","Janssen Research and Development, Titusville, NJ, United States","Cepeda M.S., Janssen Research and Development, Titusville, NJ, United States; Reps J., Janssen Research and Development, Titusville, NJ, United States; Fife D., Janssen Research and Development, Titusville, NJ, United States; Blacketer C., Janssen Research and Development, Titusville, NJ, United States; Stang P., Janssen Research and Development, Titusville, NJ, United States; Ryan P., Janssen Research and Development, Titusville, NJ, United States","Background: Depression that does not respond to antidepressants is treatment-resistant depression (TRD). TRD definitions include assessments of treatment response, dose and duration, and implementing these definitions in claims databases can be challenging. We built a data-driven TRD definition and evaluated its performance. Methods: We included adults with depression, ≥1 antidepressant, and no diagnosis of mania, dementia, or psychosis. Subjects were stratified into those with and without proxy for TRD. Proxies for TRD were electroconvulsive therapy, deep brain, or vagus nerve stimulation. The index date for subjects with proxy for TRD was the procedure date, and for subjects without, the date of a randomly selected visit. We used three databases. We fit decision tree predictive models. We included number of distinct antidepressants, with and without adequate doses and duration, number of antipsychotics and psychotherapies, and expert-based definitions, 3, 6, and 12 months before index date. To assess performance, we calculated area under the curve (AUC) and transportability. Results: We analyzed 33,336 subjects with no proxy for TRD, and 3,566 with the proxy. Number of antidepressants and antipsychotics were selected in all periods. The best model was at 12 months with an AUC = 0.81. The rule transported well and states that a subject with ≥1 antipsychotic or ≥3 antidepressants in the last year has TRD. Applying this rule, 15.8% of subjects treated for depression had TRD. Conclusion: The definition that best discriminates between subjects with and without TRD considers number of distinct antidepressants (≥3) or antipsychotics (≥1) in the last year. © 2017 The Authors. Depression and Anxiety published by Wiley Periodicals, Inc.","databases; decision tree; epidemiology; machine learning; prevalence","Adult; Aged; Antidepressive Agents; Antipsychotic Agents; Depressive Disorder, Treatment-Resistant; Female; Heuristics; Humans; Male; Middle Aged; antidepressant agent; neuroleptic agent; antidepressant agent; neuroleptic agent; adult; Article; brain depth stimulation; controlled study; decision tree; depression; electroconvulsive therapy; female; human; major clinical study; male; priority journal; treatment duration; vagus nerve stimulation; aged; heuristics; middle aged; treatment resistant depression","Blackwell Publishing Inc.","10914269","","DEANF","29244906","Article","Scopus","2-s2.0-85038023814"
"Li J.; Yu Z.L.; Gu Z.; Wu W.; Li Y.; Jin L.","Li, Jingcong (57200533404); Yu, Zhu Liang (58266105300); Gu, Zhenghui (57204214680); Wu, Wei (56529849100); Li, Yuanqing (55936283000); Jin, Lianwen (7403329268)","57200533404; 58266105300; 57204214680; 56529849100; 55936283000; 7403329268","A hybrid network for ERP detection and analysis based on restricted boltzmann machine","2018","IEEE Transactions on Neural Systems and Rehabilitation Engineering","43","10.1109/TNSRE.2018.2803066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041495249&doi=10.1109%2fTNSRE.2018.2803066&partnerID=40&md5=d96a81c999fad991ff9abb390d70760d","School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, 510641, China","Li J., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Yu Z.L., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Gu Z., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Wu W., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Li Y., School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Jin L., School of Electronic and Information Engineering, South China University of Technology, Guangzhou, 510641, China","Detecting and Please provide the correct one analyzing the event-related potential (ERP) remains an important problem in neuroscience. Due to the low signal-to-noise ratio and complex spatio-temporal patterns of ERP signals, conventional methods usually rely on ensemble averaging technique for reliable detection, which may obliterate subtle but important information in each trial of ERP signals. Inspired by deep learning methods, we propose a novel hybrid network termed ERP-NET. With hybrid deep structure, the proposed network is able to learn complex spatial and temporal patterns from single-trial ERP signals. To verify the effectiveness of ERP-NET, we carried out a few ERP detection experiments that the proposed model achieved cutting-edge performance. The experimental results demonstrate that the patterns learned by the ERP-NET are discriminative ERP components in which the ERP signals are properly characterized. More importantly, as an effective approach to single-trial analysis, ERP-NET is able to discover new ERP patterns which are significant to neuroscience study as well as BCI applications. Therefore, the proposed ERP-NET is a promising tool for the research on ERP signals. © 2001-2011 IEEE.","deep learning; Event-related potential (ERP); neural network; spatial filter; temporal feature","Algorithms; Brain-Computer Interfaces; Electroencephalography; Event-Related Potentials, P300; Evoked Potentials; Humans; Neural Networks (Computer); Prosthesis Design; Signal Processing, Computer-Assisted; Signal-To-Noise Ratio; Complex networks; Neural networks; Neurology; Signal to noise ratio; Ensemble-averaging techniques; Event related potentials(ERP); Low signal-to-noise ratio; Restricted boltzmann machine; Spatial and temporal patterns; Spatial filters; Spatiotemporal patterns; Temporal features; adult; Article; brain mapping; clinical article; electroencephalography; electromagnetism; event related potential; female; human; image processing; learning; male; mathematical model; nerve cell network; neuroscience; performance; signal noise ratio; training; algorithm; artificial neural network; brain computer interface; devices; event related potential; evoked response; physiology; procedures; prosthesis design; signal processing; Deep learning","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","29522400","Article","Scopus","2-s2.0-85041495249"
"Date Y.; Kikuchi J.","Date, Yasuhiro (12243044000); Kikuchi, Jun (56423275500)","12243044000; 56423275500","Application of a Deep Neural Network to Metabolomics Studies and Its Performance in Determining Important Variables","2018","Analytical Chemistry","81","10.1021/acs.analchem.7b03795","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041427551&doi=10.1021%2facs.analchem.7b03795&partnerID=40&md5=5606a1ff6987bf29457ce376f3c09ebb","RIKEN Center for Sustainable Resource Science, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan; Graduate School of Medical Life Science, Yokohama City University, 1-7-29 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan; Graduate School of Bioagricultural Sciences, Nagoya University, 1 Furo-cho, Chikusa-ku, Nagoya, Aichi, 464-8601, Japan","Date Y., RIKEN Center for Sustainable Resource Science, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan, Graduate School of Medical Life Science, Yokohama City University, 1-7-29 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan; Kikuchi J., RIKEN Center for Sustainable Resource Science, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan, Graduate School of Medical Life Science, Yokohama City University, 1-7-29 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan, Graduate School of Bioagricultural Sciences, Nagoya University, 1 Furo-cho, Chikusa-ku, Nagoya, Aichi, 464-8601, Japan","Deep neural networks (DNNs), which are kinds of the machine learning approaches, are powerful tools for analyzing big sets of data derived from biological and environmental systems. However, DNNs are not applicable to metabolomics studies because they have difficulty in identifying contribution factors, e.g., biomarkers, in constructed classification and regression models. In this paper, we describe an improved DNN-based analytical approach that incorporates an importance estimation for each variable using a mean decrease accuracy (MDA) calculation, which is based on a permutation algorithm; this approach is called DNN-MDA. The performance of the DNN-MDA approach was evaluated using a data set of metabolic profiles derived from yellowfin goby that lived in various rivers throughout Japan. Its performance was compared with that of conventional multivariate and machine learning methods, and the DNN-MDA approach was found to have the best classification accuracy (97.8%) among the examined methods. In addition to this, the DNN-MDA approach facilitated the identification of important variables such as trimethylamine N-oxide, inosinic acid, and glycine, which were characteristic metabolites that contributed to the discrimination of the geographical differences between fish caught in the Kanto region and those caught in other regions. As a result, the DNN-MDA approach is a useful and powerful tool for determining the geographical origins of specimens and identifying their biomarkers in metabolomics studies that are conducted in biological and environmental systems. © 2017 American Chemical Society.","","Algorithms; Animals; Machine Learning; Metabolomics; Neural Networks (Computer); Perciformes; Amino acids; Artificial intelligence; Biomarkers; Deep learning; Geographical regions; Learning systems; Regression analysis; Software architecture; Analytical approach; Classification accuracy; Environmental systems; Geographical origins; Machine learning approaches; Machine learning methods; Metabolic profiles; Trimethylamine N oxides; algorithm; animal; artificial neural network; classification; machine learning; metabolism; metabolomics; Perciformes; procedures; Deep neural networks","American Chemical Society","00032700","","ANCHA","29278490","Article","Scopus","2-s2.0-85041427551"
"Padmashini M.; Manjusha R.; Parameswaran L.","Padmashini, M. (57215911580); Manjusha, R. (57363753100); Parameswaran, Latha (24473120800)","57215911580; 57363753100; 24473120800","Vision based algorithm for people counting using deep learning","2018","International Journal of Engineering and Technology(UAE)","6","10.14419/ijet.v7i3.6.14942","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082370706&doi=10.14419%2fijet.v7i3.6.14942&partnerID=40&md5=a1bfa772770c16718b8c7fbae75a4745","Department of Computer Science and Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India","Padmashini M., Department of Computer Science and Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India; Manjusha R., Department of Computer Science and Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India; Parameswaran L., Department of Computer Science and Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India","Estimating the number of people in a particular scene has always been an important topic of research in computer vision and digital image processing. People counting has wide applications in scenario ranging from analyzing the customer's choice and improving the quality of service in retail stores, supermarkets and shopping malls to managing human resources and optimizing the energy usage in office buildings. While there exists algorithms for counting people in a scene, some algorithm have set their benchmark in performance with respect to efficiency, flexibility and accuracy. In this paper, an attempt has been made to perform people counting using Deep Neural Networks (DNN) on comparison with existing image processing based algorithms like Histogram of Oriented Gradients with Support Vector Machine (HoG with SVM), Local Binary Pattern (LBP) based Adaboost classifier and contour based people detection. The proposed DNN based approach has higher accuracy at 90% and less false negatives. © 2018 Authors.","Deep neural network; HoG; LBP; People counting","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082370706"
"Uyar A.; Karamyan V.T.; Dickson A.","Uyar, A. (52164672700); Karamyan, V.T. (16047847200); Dickson, A. (26032508300)","52164672700; 16047847200; 26032508300","Long-Range Changes in Neurolysin Dynamics Upon Inhibitor Binding","2018","Journal of Chemical Theory and Computation","11","10.1021/acs.jctc.7b00944","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037861884&doi=10.1021%2facs.jctc.7b00944&partnerID=40&md5=f204fe9c1bcf6fb67aea21ed86f3fb06","Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, 48824, MI, United States; Department of Pharmaceutical Sciences, School of Pharmacy, Texas Tech University, Health Sciences Center, Amarillo, 79106, TX, United States; Department of Computational Mathematics Science and Engineering, Michigan State University, East Lansing, 48824, MI, United States","Uyar A., Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, 48824, MI, United States; Karamyan V.T., Department of Pharmaceutical Sciences, School of Pharmacy, Texas Tech University, Health Sciences Center, Amarillo, 79106, TX, United States; Dickson A., Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, 48824, MI, United States, Department of Computational Mathematics Science and Engineering, Michigan State University, East Lansing, 48824, MI, United States","Crystal structures of neurolysin, a zinc metallopeptidase, do not show a significant conformational change upon the binding of an allosteric inhibitor. Neurolysin has a deep channel where it hydrolyzes a short neuropeptide neurotensin to create inactive fragments and thus controls its level in the tissue. Neurolysin is of interest as a therapeutic target since changes in neurotensin level have been implicated in cardiovascular disorders, neurological disorders, and cancer, and inhibitors of neurolysin have been developed. An understanding of the dynamical and structural differences between apo and inhibitor-bound neurolysin will aid in further design of potent inhibitors and activators. For this purpose, we performed several molecular dynamics (MD) simulations for both apo and inhibitor-bound neurolysin. A machine learning method (Linear Discriminant Analysis) is applied to reveal differences between the apo and inhibitor-bound ensembles in an automated way, and large differences are observed on residues that are far from both the active site and the inhibitor binding site. The effects of inhibitor binding on the collective motions of neurolysin are extensively analyzed and compared using both Principal Component Analysis and Elastic Network Model calculations. We find that inhibitor binding induces additional low-frequency motions that are not observed in the apo form. ENM also reveals changes in inter- and intradomain communication upon binding. Furthermore, differences are observed in the inhibitor-bound neurolysin contact network that are far from the active site, revealing long-range allosteric behavior. This study also provides insight into the allosteric modulation of other neuropeptidases with similar folds. © 2017 American Chemical Society.","","","American Chemical Society","15499618","","JCTCC","29179556","Article","Scopus","2-s2.0-85037861884"
"Chen L.; Qu H.; Zhao J.","Chen, Liangjun (57273902200); Qu, Hua (36057317900); Zhao, Jihong (8307952300)","57273902200; 36057317900; 8307952300","Generalized Correntropy based deep learning in presence of non-Gaussian noises","2018","Neurocomputing","27","10.1016/j.neucom.2017.06.080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045168244&doi=10.1016%2fj.neucom.2017.06.080&partnerID=40&md5=6f14c91ce70490fa8ab2780f369c8e3e","School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; School of Telecommunication and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710061, China","Chen L., School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Qu H., School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, 710049, China; Zhao J., School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, 710049, China, School of Telecommunication and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710061, China","Deep learning algorithms are the hottest topics in machine learning area lately. Although deep learning has made great progress in many domains, the robustness of learning systems with deep architectures is still rarely studied and needs further investigation. For instance, the impulsive noises (or outliers) are pervasive in real world data and can badly influence the mean square error (MSE) cost function based deep learning algorithms. Correntropy based loss function, which uses Gaussian kernel, is widely utilized to reject the above noises, however, the effect is not satisfactory. Therefore, generalized Correntropy (GC) is put forward to further improve the robustness, which uses generalized Gaussian density (GGD) function as kernel. GC can achieve extra flexibility through the GC parameters, which control the behavior of the induced metric, and shows a markedly better robustness than Correntropy. Motivated by the enhanced robustness of GC, we propose a new robust algorithm named generalized Correntropy based stacked autoencoder (GC-SAE), which is developed by combining the GC and stacked autoencoder (SAE). The new algorithms can extract useful features from the data corrupted by impulsive noises (or outliers) in a more effective way. The good robustness of the proposed method is confirmed by the experimental results on MNIST benchmark dataset. Furthermore, we show how our model can be applied for robust network classification, based on Moore network data of 377,526 samples with 12 classes. © 2017 Elsevier B.V.","Deep learning; Generalized Correntropy; Network traffic classification; Non-Gaussian noise; Stacked autoencoders","Cost functions; Deep learning; Gaussian distribution; Gaussian noise (electronic); Impulse noise; Learning systems; Mean square error; Statistics; Telecommunication traffic; Autoencoders; Benchmark datasets; Correntropy; Deep architectures; Gaussian kernels; Generalized Gaussian density; Network traffic classification; Non-Gaussian noise; Article; intermethod comparison; learning algorithm; measurement accuracy; noise; priority journal; process optimization; simulation; Learning algorithms","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85045168244"
"Schaarschmidt J.; Monastyrskyy B.; Kryshtafovych A.; Bonvin A.M.J.J.","Schaarschmidt, Joerg (37102514000); Monastyrskyy, Bohdan (24399645600); Kryshtafovych, Andriy (55887853100); Bonvin, Alexandre M.J.J. (7003870500)","37102514000; 24399645600; 55887853100; 7003870500","Assessment of contact predictions in CASP12: Co-evolution and deep learning coming of age","2018","Proteins: Structure, Function and Bioinformatics","151","10.1002/prot.25407","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041767953&doi=10.1002%2fprot.25407&partnerID=40&md5=fd2184af9112d828e006d7bc241a5682","Faculty of Science - Chemistry, Computational Structural Biology Group, Bijvoet Center for Biomolecular Research, Utrecht University, Utrecht, Netherlands; Genome Center, University of California, Davis, CA, United States","Schaarschmidt J., Faculty of Science - Chemistry, Computational Structural Biology Group, Bijvoet Center for Biomolecular Research, Utrecht University, Utrecht, Netherlands; Monastyrskyy B., Genome Center, University of California, Davis, CA, United States; Kryshtafovych A., Genome Center, University of California, Davis, CA, United States; Bonvin A.M.J.J., Faculty of Science - Chemistry, Computational Structural Biology Group, Bijvoet Center for Biomolecular Research, Utrecht University, Utrecht, Netherlands","Following up on the encouraging results of residue-residue contact prediction in the CASP11 experiment, we present the analysis of predictions submitted for CASP12. The submissions include predictions of 34 groups for 38 domains classified as free modeling targets which are not accessible to homology-based modeling due to a lack of structural templates. CASP11 saw a rise of coevolution-based methods outperforming other approaches. The improvement of these methods coupled to machine learning and sequence database growth are most likely the main driver for a significant improvement in average precision from 27% in CASP11 to 47% in CASP12. In more than half of the targets, especially those with many homologous sequences accessible, precisions above 90% were achieved with the best predictors reaching a precision of 100% in some cases. We furthermore tested the impact of using these contacts as restraints in ab initio modeling of 14 single-domain free modeling targets using Rosetta. Adding contacts to the Rosetta calculations resulted in improvements of up to 26% in GDT_TS within the top five structures. © 2017 The Authors Proteins: Structure, Function and Bioinformatics Published by Wiley Periodicals, Inc.","CASP; co-variation; contact prediction; correlated mutations; de novo structure prediction; evolutionary coupling","Algorithms; Computational Biology; Crystallography, X-Ray; Databases, Protein; Humans; Machine Learning; Models, Molecular; Protein Conformation; Protein Folding; Protein Interaction Domains and Motifs; Proteins; Software; protein; amino acid sequence; Article; machine learning; priority journal; protein analysis; protein database; protein domain; protein structure; protein targeting; sequence analysis; structure analysis; algorithm; biology; chemistry; human; machine learning; molecular model; procedures; protein conformation; protein folding; software; X ray crystallography","John Wiley and Sons Inc.","08873585","","","29071738","Article","Scopus","2-s2.0-85041767953"
"Zeng Z.; Liang N.; Yang X.; Hoi S.","Zeng, Zeng (57194337704); Liang, Nanying (13610623400); Yang, Xulei (7406500681); Hoi, Steven (8710996600)","57194337704; 13610623400; 7406500681; 8710996600","Multi-target deep neural networks: Theoretical analysis and implementation","2018","Neurocomputing","27","10.1016/j.neucom.2017.08.044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029483100&doi=10.1016%2fj.neucom.2017.08.044&partnerID=40&md5=dae8e2ae01c6562bfb5226204bf3b82e","Institute for Infocomm Research, 1 Fusionopolis Way, #21-01 Connexis (South Tower), 138632, Singapore; Institute of High Performance Computing, 1 Fusionopolis Way, #16-16 Connexis, 138632, Singapore; Singapore Management University, 81 Victoria Street, 188065, Singapore","Zeng Z., Institute for Infocomm Research, 1 Fusionopolis Way, #21-01 Connexis (South Tower), 138632, Singapore; Liang N., Institute for Infocomm Research, 1 Fusionopolis Way, #21-01 Connexis (South Tower), 138632, Singapore; Yang X., Institute of High Performance Computing, 1 Fusionopolis Way, #16-16 Connexis, 138632, Singapore; Hoi S., Singapore Management University, 81 Victoria Street, 188065, Singapore","In this work, we propose a novel deep neural network referred to as Multi-Target Deep Neural Network (MT-DNN). We theoretically prove that different stable target models with shared learning paths are stable and can achieve optimal solutions respectively. Based on GoogleNet, we design a single model with three different targets, one for classification, one for regression, and one for masks that is composed of 256 × 256 sub-models. Unlike bounding boxes used in ImageNet, our single model can draw the shapes of target objects, and in the meanwhile, classify the objects and calculate their sizes. We validate our single MT-DNN model via rigorous experiments and prove that the multiple targets can boost each other to achieve optimization solutions. © 2017 Elsevier B.V.","Deep neural networks; Learning path; Multi-target deep learning; Object detection; Segmentation","Deep learning; Image segmentation; Object detection; Learning paths; Multi-targets; Multiple targets; Optimal solutions; Optimization solution; Single models; Target model; Target object; analysis; Article; artificial neural network; classification; controlled study; data extraction; experimental study; image processing; Internet; machine learning; multitarget deep neural network; object classification; online system; priority journal; process design; process optimization; shared learning; statistical concepts; statistical model; stochastic gradient descent; theoretical analysis; three dimensional imaging; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85029483100"
"Lin D.; Li L.; Cao D.; Lv Y.; Ke X.","Lin, Dazhen (14832949000); Li, Lingxiao (56313936400); Cao, Donglin (14832299900); Lv, Yanping (14826776300); Ke, Xiao (26029410700)","14832949000; 56313936400; 14832299900; 14826776300; 26029410700","Multi-modality weakly labeled sentiment learning based on Explicit Emotion Signal for Chinese microblog","2018","Neurocomputing","20","10.1016/j.neucom.2017.06.078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024483725&doi=10.1016%2fj.neucom.2017.06.078&partnerID=40&md5=d56fbca7fd086c41e49666f84c7c0786","Cognitive Science Department, Xiamen University, Xiamen, Fujian 361005, China; Fujian Key Laboratory of Brain-inspired Computing Technique and Applications, Xiamen University, Xiamen, Fujian 361005, China; Fujian Provincial Key Laboratory of Information Processing and Intelligent Control, Minjiang University, Fuzhou, Fujian 350121, China; College of Mathematics and Computer Science, Fuzhou University, Fuzhou, Fujian 350116, China","Lin D., Cognitive Science Department, Xiamen University, Xiamen, Fujian 361005, China, Fujian Key Laboratory of Brain-inspired Computing Technique and Applications, Xiamen University, Xiamen, Fujian 361005, China, Fujian Provincial Key Laboratory of Information Processing and Intelligent Control, Minjiang University, Fuzhou, Fujian 350121, China; Li L., Cognitive Science Department, Xiamen University, Xiamen, Fujian 361005, China, Fujian Key Laboratory of Brain-inspired Computing Technique and Applications, Xiamen University, Xiamen, Fujian 361005, China; Cao D., Cognitive Science Department, Xiamen University, Xiamen, Fujian 361005, China, Fujian Key Laboratory of Brain-inspired Computing Technique and Applications, Xiamen University, Xiamen, Fujian 361005, China, Fujian Provincial Key Laboratory of Information Processing and Intelligent Control, Minjiang University, Fuzhou, Fujian 350121, China; Lv Y., Cognitive Science Department, Xiamen University, Xiamen, Fujian 361005, China, Fujian Key Laboratory of Brain-inspired Computing Technique and Applications, Xiamen University, Xiamen, Fujian 361005, China; Ke X., College of Mathematics and Computer Science, Fuzhou University, Fuzhou, Fujian 350116, China","Understanding the sentiments of users from cross media contents which contain texts and images is an important task for many social network applications. However, due to the semantic gap between cross media features and sentiments, machine learning methods need a lot of human labeled samples. Furthermore, for each kind of media content, it is necessary to constantly add a lot of new human labeled samples because of new expressions of sentiments. Fortunately, there are some emotion signals, like emoticons, which denote users’ emotions in cross media contents. In order to use these weakly labels to build a unified multi-modality sentiment learning framework, we propose an Explicit Emotion Signal (EES) based multi-modality sentiment learning approach which uses huge number of weakly labeled samples in sentiment learning. There are three advantages in our approach. Firstly, only a few human labeled samples are needed to reach the same performance which can be obtained by the traditional machine learning based sentiment prediction approaches. Secondly, this approach is flexible and can easily combine text and vision based sentiment learning through deep neural networks. Thirdly, because a lot of weakly labeled samples can be used in EES, trained model is more robust in different domain transfer. In this paper, firstly, we investigate the correlation between sentiments and emoticons and choose emoticons as the Explicit Emotion Signals in our approach; secondly, we build a two stages multi-modality sentiment learning framework based on Explicit Emotion Signals. Our experiment results show that our approach not only achieves the best performance but also only needs 3% and 43% training samples to obtain the same performance of Visual Geometry Group (VGG) model and Long Short-Term Memory (LSTM) model in images and texts, respectively. © 2017 Elsevier B.V.","Cross media; Domain transfer; Explicit Emotion Signal; Multi-modality sentiment learning; Weakly labeled sample","Artificial intelligence; Deep neural networks; Education; Learning systems; Long short-term memory; Semantics; Cross-media; Different domains; Domain transfers; Learning approach; Learning frameworks; Machine learning methods; Multi modality; Network applications; Article; artificial neural network; Chinese; conceptual framework; emotion; Explicit Emotion Signal; human; long term memory; machine learning; priority journal; short term memory; signal processing; social media; social network; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85024483725"
"Lustberg T.; van Soest J.; Gooding M.; Peressutti D.; Aljabar P.; van der Stoep J.; van Elmpt W.; Dekker A.","Lustberg, Tim (55383500500); van Soest, Johan (56156330000); Gooding, Mark (7005661941); Peressutti, Devis (55332375600); Aljabar, Paul (6507793674); van der Stoep, Judith (56615889400); van Elmpt, Wouter (8888841100); Dekker, Andre (57225379184)","55383500500; 56156330000; 7005661941; 55332375600; 6507793674; 56615889400; 8888841100; 57225379184","Clinical evaluation of atlas and deep learning based automatic contouring for lung cancer","2018","Radiotherapy and Oncology","251","10.1016/j.radonc.2017.11.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036525486&doi=10.1016%2fj.radonc.2017.11.012&partnerID=40&md5=cc8a4c25c8ee73fc902d064be4f2ba78","Department of Radiation Oncology (MAASTRO), GROW School for Oncology and Developmental Biology, Maastricht University Medical Centre+, Netherlands; Mirada Medical Ltd., Oxford, United Kingdom","Lustberg T., Department of Radiation Oncology (MAASTRO), GROW School for Oncology and Developmental Biology, Maastricht University Medical Centre+, Netherlands; van Soest J., Department of Radiation Oncology (MAASTRO), GROW School for Oncology and Developmental Biology, Maastricht University Medical Centre+, Netherlands; Gooding M., Mirada Medical Ltd., Oxford, United Kingdom; Peressutti D., Mirada Medical Ltd., Oxford, United Kingdom; Aljabar P., Mirada Medical Ltd., Oxford, United Kingdom; van der Stoep J., Department of Radiation Oncology (MAASTRO), GROW School for Oncology and Developmental Biology, Maastricht University Medical Centre+, Netherlands; van Elmpt W., Department of Radiation Oncology (MAASTRO), GROW School for Oncology and Developmental Biology, Maastricht University Medical Centre+, Netherlands; Dekker A., Department of Radiation Oncology (MAASTRO), GROW School for Oncology and Developmental Biology, Maastricht University Medical Centre+, Netherlands","Background and purpose: Contouring of organs at risk (OARs) is an important but time consuming part of radiotherapy treatment planning. The aim of this study was to investigate whether using institutional created software-generated contouring will save time if used as a starting point for manual OAR contouring for lung cancer patients. Material and methods: Twenty CT scans of stage I–III NSCLC patients were used to compare user adjusted contours after an atlas-based and deep learning contour, against manual delineation. The lungs, esophagus, spinal cord, heart and mediastinum were contoured for this study. The time to perform the manual tasks was recorded. Results: With a median time of 20 min for manual contouring, the total median time saved was 7.8 min when using atlas-based contouring and 10 min for deep learning contouring. Both atlas based and deep learning adjustment times were significantly lower than manual contouring time for all OARs except for the left lung and esophagus of the atlas based contouring. Conclusions: User adjustment of software generated contours is a viable strategy to reduce contouring time of OARs for lung radiotherapy while conforming to local clinical standards. In addition, deep learning contouring shows promising results compared to existing solutions. © 2017 The Authors","Atlas contouring; Deep learning contouring; Lung cancer; Organs at risk; Radiotherapy","Carcinoma, Non-Small-Cell Lung; Esophagus; Heart; Humans; Lung; Lung Neoplasms; Machine Learning; Mediastinum; Neoplasm Staging; Organs at Risk; Radiotherapy Planning, Computer-Assisted; Software; Spinal Cord; Tomography, X-Ray Computed; Article; atlas contouring; clinical article; deep learning contouring; esophagus; heart; human; mediastinum; non small cell lung cancer; priority journal; software; spinal cord; treatment planning; x-ray computed tomography; anatomy and histology; cancer staging; diagnostic imaging; lung; lung tumor; machine learning; non small cell lung cancer; organs at risk; pathology; procedures; radiation response; radiotherapy planning system","Elsevier Ireland Ltd","01678140","","RAOND","29208513","Article","Scopus","2-s2.0-85036525486"
"Chen Z.; Cao Y.; He S.; Qiao Y.","Chen, Zhao (57200855249); Cao, Yanfeng (56080454600); He, Shuaibing (56978509300); Qiao, Yanjiang (55761552500)","57200855249; 56080454600; 56978509300; 55761552500","Development of models for classification of action between heat-clearing herbs and blood-activating stasis-resolving herbs based on theory of traditional Chinese medicine","2018","Chinese Medicine (United Kingdom)","21","10.1186/s13020-018-0169-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042534858&doi=10.1186%2fs13020-018-0169-x&partnerID=40&md5=d1aab48437144e032918f1390fadfe71","Beijing University of Chinese Medicine, School of Chines Materia Medica, Yangguang South Avenue, Beijing, Fangshan District, 102488, China; Beijing University of Chinese Medicine, Research Center of TCM Information Engineering, Yangguang South Avenue, Beijing, Fangshan District, 102488, China","Chen Z., Beijing University of Chinese Medicine, School of Chines Materia Medica, Yangguang South Avenue, Beijing, Fangshan District, 102488, China, Beijing University of Chinese Medicine, Research Center of TCM Information Engineering, Yangguang South Avenue, Beijing, Fangshan District, 102488, China; Cao Y., Beijing University of Chinese Medicine, School of Chines Materia Medica, Yangguang South Avenue, Beijing, Fangshan District, 102488, China, Beijing University of Chinese Medicine, Research Center of TCM Information Engineering, Yangguang South Avenue, Beijing, Fangshan District, 102488, China; He S., Beijing University of Chinese Medicine, School of Chines Materia Medica, Yangguang South Avenue, Beijing, Fangshan District, 102488, China; Qiao Y., Beijing University of Chinese Medicine, School of Chines Materia Medica, Yangguang South Avenue, Beijing, Fangshan District, 102488, China, Beijing University of Chinese Medicine, Research Center of TCM Information Engineering, Yangguang South Avenue, Beijing, Fangshan District, 102488, China","Background: Action (""gongxiao"" in Chinese) of traditional Chinese medicine (TCM) is the high recapitulation for therapeutic and health-preserving effects under the guidance of TCM theory. TCM-defined herbal properties (""yaoxing"" in Chinese) had been used in this research. TCM herbal property (TCM-HP) is the high generalization and summary for actions, both of which come from long-term effective clinical practice in two thousands of years in China. However, the specific relationship between TCM-HP and action of TCM is complex and unclear from a scientific perspective. The research about this is conducive to expound the connotation of TCM-HP theory and is of important significance for the development of the TCM-HP theory. Methods: One hundred and thirty-three herbs including 88 heat-clearing herbs (HCHs) and 45 blood-activating stasis-resolving herbs (BAHRHs) were collected from reputable TCM literatures, and their corresponding TCM-HPs/actions information were collected from Chinese pharmacopoeia (2015 edition). The Kennard-Stone (K-S) algorithm was used to split 133 herbs into 100 calibration samples and 33 validation samples. Then, machine learning methods including supported vector machine (SVM), k-nearest neighbor (kNN) and deep learning methods including deep belief network (DBN), convolutional neutral network (CNN) were adopted to develop action classification models based on TCM-HP theory, respectively. In order to ensure robustness, these four classification methods were evaluated by using the method of tenfold cross validation and 20 external validation samples for prediction. Results: As results, 72.7-100% of 33 validation samples including 17 HCHs and 16 BASRHs were correctly predicted by these four types of methods. Both of the DBN and CNN methods gave out the best results and their sensitivity, specificity, precision, accuracy were all 100.00%. Especially, the predicted results of external validation set showed that the performance of deep learning methods (DBN, CNN) were better than traditional machine learning methods (kNN, SVM) in terms of their sensitivity, specificity, precision, accuracy. Moreover, the distribution patterns of TCM-HPs of HCHs and BASRHs were also analyzed to detect the featured TCM-HPs of these two types of herbs. The result showed that the featured TCM-HPs of HCHs were cold, bitter, liver and stomach meridians entered, while those of BASRHs were warm, bitter and pungent, liver meridian entered. Conclusions: The performance on validation set and external validation set of deep learning methods (DBN, CNN) were better than machine learning models (kNN, SVM) in sensitivity, specificity, precision, accuracy when predicting the actions of heat-clearing and blood-activating stasis-resolving based on TCM-HP theory. The deep learning classification methods owned better generalization ability and accuracy when predicting the actions of heat-clearing and blood-activating stasis-resolving based on TCM-HP theory. Besides, the methods of deep learning would help us to improve our understanding about the relationship between herbal property and action, as well as to enrich and develop the theory of TCM-HP scientifically. © 2018 The Author(s).","Blood-activating stasis-resolving herbs (BASRHs); Deep learning; Heat-clearing herbs (HCHs); Herbal property; Machine learning; Traditional Chinese medicine (TCM)","article; bitter taste; blood; calibration; China; Chinese medicine; classification; clinical practice; cold stress; heat; herb; human; k nearest neighbor; liver meridian; machine learning; major clinical study; nonhuman; prediction; stomach meridian; theoretical study; validation process","BioMed Central Ltd.","17498546","","","","Article","Scopus","2-s2.0-85042534858"
"Yasaka K.; Akai H.; Abe O.; Kiryu S.","Yasaka, Koichiro (41762972600); Akai, Hiroyuki (55330259700); Abe, Osamu (7103189098); Kiryu, Shigeru (7004240410)","41762972600; 55330259700; 7103189098; 7004240410","Deep learning with convolutional neural network for differentiation of liver masses at dynamic contrast-enhanced CT: A preliminary study","2018","Radiology","429","10.1148/radiol.2017170706","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042428409&doi=10.1148%2fradiol.2017170706&partnerID=40&md5=4f17f6038cc37908723d488d5b5b4623","Department of Radiology, University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8655, Japan","Yasaka K., Department of Radiology, University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8655, Japan; Akai H., Department of Radiology, University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8655, Japan; Abe O., Department of Radiology, University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8655, Japan; Kiryu S., Department of Radiology, University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8655, Japan","Purpose: To investigate diagnostic performance by using a deep learning method with a convolutional neural network (CNN) for the differentiation of liver masses at dynamic contrast agent-enhanced computed tomography (CT). Materials and This clinical retrospective study used CT image sets of Methods: liver masses over three phases (noncontrast-agent enhanced, arterial, and delayed). Masses were diagnosed according to five categories (category A, classic hepatocellular carcinomas [HCCs]; category B, malignant liver tumors other than classic and early HCCs; category C, indeterminate masses or mass-like lesions [including early HCCs and dysplastic nodules] and rare benign liver masses other than hemangiomas and cysts; category D, hemangiomas; and category E, cysts). Supervised training was performed by using 55536 image sets obtained in 2013 (from 460 patients, 1068 sets were obtained and they were augmented by a factor of 52 [rotated, parallel-shifted, strongly enlarged, and noise-added images were generated from the original images]). The CNN was composed of six convolutional, three maximum pooling, and three fully connected layers. The CNN was tested with 100 liver mass image sets obtained in 2016 (74 men and 26 women; mean age, 66.4 years 6 10.6 [standard deviation]; mean mass size, 26.9 mm 6 25.9; 21, nine, 35, 20, and 15 liver masses for categories A, B, C, D, and E, respectively). Training and testing were performed five times. Accuracy for categorizing liver masses with CNN model and the area under receiver operating characteristic curve for differentiating categories A-B versus categories C-E were calculated. Results: Median accuracy of differential diagnosis of liver masses for test data were 0.84. Median area under the receiver operating characteristic curve for differentiating categories A-B from C-E was 0.92. Conclusion: Deep learning with CNN showed high diagnostic performance in differentiation of liver masses at dynamic CT. © RSNA, 2017.","","Aged; Aged, 80 and over; Bile Duct Neoplasms; Carcinoma, Hepatocellular; Cholangiocarcinoma; Contrast Media; Diagnosis, Differential; Female; Humans; Liver Neoplasms; Machine Learning; Middle Aged; Neural Networks (Computer); Retrospective Studies; ROC Curve; Sensitivity and Specificity; Tomography, X-Ray Computed; contrast medium; adult; Article; computer assisted tomography; contrast enhancement; controlled study; diagnostic value; differential diagnosis; female; human; image processing; learning algorithm; liver cell carcinoma; liver cyst; liver hemangioma; liver nodule; liver tumor; machine learning; major clinical study; male; priority journal; retrospective study; tumor classification; aged; artificial neural network; bile duct carcinoma; bile duct tumor; diagnostic imaging; differential diagnosis; liver cell carcinoma; liver tumor; middle aged; procedures; receiver operating characteristic; sensitivity and specificity; very elderly; x-ray computed tomography","Radiological Society of North America Inc.","00338419","","RADLA","29059036","Article","Scopus","2-s2.0-85042428409"
"Li F.; Shirahama K.; Nisar M.A.; Köping L.; Grzegorzek M.","Li, Frédéric (57218086812); Shirahama, Kimiaki (8886250600); Nisar, Muhammad Adeel (57200946047); Köping, Lukas (56211196000); Grzegorzek, Marcin (6504608152)","57218086812; 8886250600; 57200946047; 56211196000; 6504608152","Comparison of feature learning methods for human activity recognition using wearable sensors","2018","Sensors (Switzerland)","225","10.3390/s18020679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042673429&doi=10.3390%2fs18020679&partnerID=40&md5=69a52c1e3b726cc8bb99d1e1caed6334","Research Group for Pattern Recognition, University of Siegen, Hölderlinstr 3, Siegen, 57076, Germany; Department of Knowledge Engineering, University of Economics in Katowice, Bogucicka 3, Katowice, 40-226, Poland","Li F., Research Group for Pattern Recognition, University of Siegen, Hölderlinstr 3, Siegen, 57076, Germany; Shirahama K., Research Group for Pattern Recognition, University of Siegen, Hölderlinstr 3, Siegen, 57076, Germany; Nisar M.A., Research Group for Pattern Recognition, University of Siegen, Hölderlinstr 3, Siegen, 57076, Germany; Köping L., Research Group for Pattern Recognition, University of Siegen, Hölderlinstr 3, Siegen, 57076, Germany; Grzegorzek M., Research Group for Pattern Recognition, University of Siegen, Hölderlinstr 3, Siegen, 57076, Germany, Department of Knowledge Engineering, University of Economics in Katowice, Bogucicka 3, Katowice, 40-226, Poland","Getting a good feature representation of data is paramount for Human Activity Recognition (HAR) using wearable sensors. An increasing number of feature learning approaches-in particular deep-learning based-have been proposed to extract an effective feature representation by analyzing large amounts of data. However, getting an objective interpretation of their performances faces two problems: the lack of a baseline evaluation setup, which makes a strict comparison between them impossible, and the insufficiency of implementation details, which can hinder their use. In this paper, we attempt to address both issues: we firstly propose an evaluation framework allowing a rigorous comparison of features extracted by different methods, and use it to carry out extensive experiments with state-of-the-art feature learning approaches. We then provide all the codes and implementation details to make both the reproduction of the results reported in this paper and the re-use of our framework easier for other researchers. Our studies carried out on the OPPORTUNITY and UniMiB-SHAR datasets highlight the effectiveness of hybrid deep-learning architectures involving convolutional and Long-Short-Term-Memory (LSTM) to obtain features characterising both short- and long-term time dependencies in the data. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep neural networks; Evaluation framework; Feature learning; Human activity recognition; Multimodal time series processing","Human Activities; Humans; Machine Learning; Neural Networks (Computer); Wearable Electronic Devices; Deep neural networks; Long short-term memory; Pattern recognition; Wearable sensors; Wearable technology; Evaluation framework; Feature learning; Feature representation; Human activity recognition; Large amounts of data; Learning architectures; State of the art; Time series processing; artificial neural network; electronic device; human; human activities; machine learning; Deep learning","MDPI AG","14248220","","","29495310","Article","Scopus","2-s2.0-85042673429"
"Zhang C.; Yan J.; Li C.; Bie R.","Zhang, Chao (57191896692); Yan, Junchi (36026971200); Li, Changsheng (37017359200); Bie, Rongfang (8853874100)","57191896692; 36026971200; 37017359200; 8853874100","Contour detection via stacking random forest learning","2018","Neurocomputing","16","10.1016/j.neucom.2017.11.046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035351834&doi=10.1016%2fj.neucom.2017.11.046&partnerID=40&md5=71203455445367eb6f96f346e9560df1","College of Information Science and Technology, Beijing Normal University, China; Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, China; IBM Research, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, China","Zhang C., College of Information Science and Technology, Beijing Normal University, China; Yan J., Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, China, IBM Research, China; Li C., School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; Bie R., College of Information Science and Technology, Beijing Normal University, China","Contour detection is an important and fundamental problem in computer vision which finds numerous applications. Despite significant progress has been made in the past decades, contour detection from natural images remains a challenging task due to the difficulty of clearly distinguishing between edges of objects and surrounding backgrounds. To address this problem, we first capture multi-scale features from pixel-level to segment-level using local and global information. These features are mapped to a space where discriminative information is captured by computing posterior divergence of Gaussian mixture models and sufficient statistics based on deep Boltzmann machine. Then we introduce a stacking random forest learning framework for contour detection. We evaluate the proposed algorithm against leading methods in the literature on the Berkeley segmentation and Weizmann horse data sets. Experimental results demonstrate that the proposed contour detection algorithm performs favorably against state-of-the-art methods in terms of speed and accuracy. © 2017 Elsevier B.V.","Contour dectection; Feature mapping; Image processing","Image processing; Image segmentation; Contour dectection; Deep boltzmann machines; Feature mapping; Gaussian Mixture Model; Learning frameworks; Multi-scale features; State-of-the-art methods; Sufficient statistics; Article; artificial neural network; contour detection; deep Boltzmann machine; image processing; image segmentation; information processing; kernel method; machine learning; mathematical analysis; mathematical computing; priority journal; random forest; stacking random forest learning; visual information; Decision trees","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85035351834"
"Lessmann N.; Van Ginneken B.; Zreik M.; De Jong P.A.; De Vos B.D.; Viergever M.A.; Isgum I.","Lessmann, Nikolas (56088955100); Van Ginneken, Bram (57202688150); Zreik, Majd (45861597300); De Jong, Pim A. (57203053328); De Vos, Bob D. (56985750200); Viergever, Max A. (57203030739); Isgum, Ivana (6507874503)","56088955100; 57202688150; 45861597300; 57203053328; 56985750200; 57203030739; 6507874503","Automatic Calcium Scoring in Low-Dose Chest CT Using Deep Neural Networks with Dilated Convolutions","2018","IEEE Transactions on Medical Imaging","178","10.1109/TMI.2017.2769839","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034270655&doi=10.1109%2fTMI.2017.2769839&partnerID=40&md5=4e60e1434d0df7654b77ece373bb9eca","Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584, CX, Netherlands; Department of Radiology and Nuclear Medicine, Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands; Fraunhofer MEVIS, Bremen, 28359, Germany; Department of Radiology, University Medical Center Utrecht, Utrecht University, Utrecht, 3584, CX, Netherlands","Lessmann N., Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584, CX, Netherlands; Van Ginneken B., Department of Radiology and Nuclear Medicine, Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands, Fraunhofer MEVIS, Bremen, 28359, Germany; Zreik M., Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584, CX, Netherlands; De Jong P.A., Department of Radiology, University Medical Center Utrecht, Utrecht University, Utrecht, 3584, CX, Netherlands; De Vos B.D., Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584, CX, Netherlands; Viergever M.A., Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584, CX, Netherlands; Isgum I., Image Sciences Institute, University Medical Center Utrecht, Utrecht University, Utrecht, 3584, CX, Netherlands","Heavy smokers undergoing screening with low-dose chest CT are affected by cardiovascular disease as much as by lung cancer. Low-dose chest CT scans acquired in screening enable quantification of atherosclerotic calcifications and thus enable identification of subjects at increased cardiovascular risk. This paper presents a method for automatic detection of coronary artery, thoracic aorta, and cardiac valve calcifications in low-dose chest CT using two consecutive convolutional neural networks. The first network identifies and labels potential calcifications according to their anatomical location and the second network identifies true calcifications among the detected candidates. This method was trained and evaluated on a set of 1744 CT scans from the National Lung Screening Trial. To determine whether any reconstruction or only images reconstructed with soft tissue filters can be used for calcification detection, we evaluated the method on soft and medium/sharp filter reconstructions separately. On soft filter reconstructions, the method achieved F1 scores of 0.89, 0.89, 0.67, and 0.55 for coronary artery, thoracic aorta, aortic valve, and mitral valve calcifications, respectively. On sharp filter reconstructions, the F1 scores were 0.84, 0.81, 0.64, and 0.66, respectively. Linearly weighted kappa coefficients for risk category assignment based on per subject coronary artery calcium were 0.91 and 0.90 for soft and sharp filter reconstructions, respectively. These results demonstrate that the presented method enables reliable automatic cardiovascular risk assessment in all low-dose chest CT scans acquired for lung cancer screening. © 2017 IEEE.","Calcium scoring; convolutional neural networks; deep learning; dilated convolutions; low-dose chest CT; lung cancer screening","Aged; Algorithms; Aortic Valve; Aortic Valve Stenosis; Calcinosis; Coronary Artery Disease; Coronary Vessels; Humans; Lung Neoplasms; Middle Aged; Neural Networks (Computer); Radiography, Thoracic; Tomography, X-Ray Computed; Biological organs; Biomineralization; Blood vessels; Bone; Calcification (biochemistry); Calcium; Convolution; Deep learning; Deep neural networks; Diagnosis; Diseases; Heart; Image reconstruction; Neural networks; Repair; Risk assessment; Valves (mechanical); Arteries; Cancer; Chest CT; Convolutional neural network; Lung cancer screening; Lungs; Agatston score; Article; automation; calcification; cancer screening; cardiovascular risk; coronary artery calcification; deep neural network; false positive result; heart valve calcification; human; image quality; low energy radiation; lung cancer; machine learning; random forest; receptive field; risk assessment; sensitivity and specificity; thoracic aorta calcification; x-ray computed tomography; aged; algorithm; aortic valve; aortic valve stenosis; artificial neural network; calcinosis; coronary artery disease; coronary blood vessel; diagnostic imaging; lung tumor; middle aged; pathology; procedures; thorax radiography; x-ray computed tomography; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29408789","Article","Scopus","2-s2.0-85034270655"
"Wang X.; Gao L.; Song J.; Zhen X.; Sebe N.; Shen H.T.","Wang, Xuanhan (57195385627); Gao, Lianli (56611089900); Song, Jingkuan (56640117300); Zhen, Xiantong (55276656300); Sebe, Nicu (57204924633); Shen, Heng Tao (7404523209)","57195385627; 56611089900; 56640117300; 55276656300; 57204924633; 7404523209","Deep appearance and motion learning for egocentric activity recognition","2018","Neurocomputing","42","10.1016/j.neucom.2017.08.063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029502956&doi=10.1016%2fj.neucom.2017.08.063&partnerID=40&md5=62fae8c2f15088fe7571ac3420e0e3ac","School of Computer Science and Engineering, University of Electronic Science and Technology of China, 611731, China; School of Engineering and Applied Science, Columbia University, New York, 10027, NY, United States; Digital Imaging Group, University of Western Ontario, N6A4V2 London, Canada; Department of Information Engineering and Computer Science, University of Trento, Trento, 38100, Italy","Wang X., School of Computer Science and Engineering, University of Electronic Science and Technology of China, 611731, China; Gao L., School of Computer Science and Engineering, University of Electronic Science and Technology of China, 611731, China; Song J., School of Engineering and Applied Science, Columbia University, New York, 10027, NY, United States; Zhen X., Digital Imaging Group, University of Western Ontario, N6A4V2 London, Canada; Sebe N., Department of Information Engineering and Computer Science, University of Trento, Trento, 38100, Italy; Shen H.T., School of Computer Science and Engineering, University of Electronic Science and Technology of China, 611731, China","Egocentric activity recognition has recently generated great popularity in computer vision due to its widespread applications in egocentric video analysis. However, it poses new challenges comparing to the conventional third-person activity recognition tasks, which are caused by significant body shaking, varied lengths, and poor recoding quality, etc. To handle these challenges, in this paper, we propose deep appearance and motion learning (DAML) for egocentric activity recognition, which leverages the great strength of deep learning networks in feature learning. In contrast to hand-crafted visual features or pre-trained convolutional neural network (CNN) features with limited generality to new egocentric videos, the proposed DAML is built on the deep autoencoder (DAE), and directly extracts appearance and motion feature, the main cue of activities, from egocentric videos. The DAML takes advantages of the great effectiveness and efficiency of the DAE in unsupervised feature learning, which provides a new representation learning framework of egocentric videos. The learned appearance and motion features by the DAML are seamlessly fused to accomplish a rich informative egocentric activity representation which can be readily fed into any supervised learning models for activity recognition. Experimental results on two challenging benchmark datasets show that the DAML achieves high performance on both short- and long-term egocentric activity recognition tasks, which is comparable to or even better than the state-of-the-art counterparts. © 2017 Elsevier B.V.","Activity recognition; Autoencoder; Deep learning; Egocentric video; Multiple feature learning","Benchmarking; Deep learning; Learning systems; Neural networks; Activity recognition; Activity representation; Auto encoders; Convolutional neural network; Effectiveness and efficiencies; Egocentric video; Multiple features; Unsupervised feature learning; Article; artificial neural network; conceptual framework; convolutional neural network; correlation component manifold space learning; daily life activity; deep appearance and motion learning; egocentric activity recognition; histogram; mathematical analysis; medical parameters; molecular recognition; motivation; optic flow; priority journal; quality of life; support vector machine; Pattern recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85029502956"
"Raza M.; Chen Z.; Rehman S.-U.; Wang P.; Bao P.","Raza, Mudassar (56303305000); Chen, Zonghai (57203879679); Rehman, Saeed-Ur (7005331338); Wang, Peng (56198770900); Bao, Peng (56828974500)","56303305000; 57203879679; 7005331338; 56198770900; 56828974500","Appearance based pedestrians’ head pose and body orientation estimation using deep learning","2018","Neurocomputing","65","10.1016/j.neucom.2017.07.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025843318&doi=10.1016%2fj.neucom.2017.07.029&partnerID=40&md5=977c63469d0431b1eb9c3da3dfab7e4b","Department of Automation, University of Science and Technology of China (USTC), Hefei, 230027, China","Raza M., Department of Automation, University of Science and Technology of China (USTC), Hefei, 230027, China; Chen Z., Department of Automation, University of Science and Technology of China (USTC), Hefei, 230027, China; Rehman S.-U., Department of Automation, University of Science and Technology of China (USTC), Hefei, 230027, China; Wang P., Department of Automation, University of Science and Technology of China (USTC), Hefei, 230027, China; Bao P., Department of Automation, University of Science and Technology of China (USTC), Hefei, 230027, China","Pedestrian orientation recognition, including head and body directions, is a demanding task in human activity-recognition scenarios. While moving in one direction, a pedestrian may be focusing his visual attention in another direction. The analysis of such orientation estimation via computer-vision applications is sometimes desirable for automated pedestrian intention and behavior analysis. This paper highlights appearance-based pedestrian head-pose and full-body orientation prediction by employing a deep-learning mechanism. A supervised deep convolutional neural-network model is presented as a deep-learning building block for classification. Two separate datasets are prepared for head-pose and full-body orientation estimation. The proposed model is subsequently trained separately on the two prepared datasets with eight orientation bins. Testing of the proposed model is performed with publicly available datasets, as well as self-taken real-time image sequences. The experiments reveal mean accuracies of 0.91 for head-pose estimation and 0.92 for full-body orientation estimation. The performance results illustrate that the proposed approach effectively classifies head-poses and body orientations simultaneously in different setups. The comparison with existing state-of-the-art approaches demonstrates the effectiveness of the presented approach. © 2017","Convolutional neural network (CNN); Full-body orientation; Head-pose; Pedestrians; Proposed training dataset","Convolution; Deep neural networks; Education; Image recognition; Neural networks; Convolutional neural network; Full body; Head pose; Pedestrians; Training dataset; accuracy; Article; body position; classification; clinical effectiveness; convolutional neural network; data processing; head position; human; image analysis; learning; machine learning; mathematical analysis; pedestrian; physical appearance; prediction; priority journal; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85025843318"
"Biswas M.; Kuppili V.; Edla D.R.; Suri H.S.; Saba L.; Marinhoe R.T.; Sanches J.M.; Suri J.S.","Biswas, Mainak (57195430754); Kuppili, Venkatanareshbabu (54784668100); Edla, Damodar Reddy (55180602300); Suri, Harman S. (57189698139); Saba, Luca (16234937700); Marinhoe, Rui Tato (57195435503); Sanches, J. Miguel (7004263858); Suri, Jasjit S. (7005613223)","57195430754; 54784668100; 55180602300; 57189698139; 16234937700; 57195435503; 7004263858; 7005613223","Symtosis: A liver ultrasound tissue characterization and risk stratification in optimized deep learning paradigm","2018","Computer Methods and Programs in Biomedicine","147","10.1016/j.cmpb.2017.12.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038880889&doi=10.1016%2fj.cmpb.2017.12.016&partnerID=40&md5=c1d0b9373848146ed3a5c4edb270c8b3","Department of Computer Science and Engineering, NIT, Goa, India; Brown University, Providence, RI, United States; Monitoring and Diagnostic Division, AtheroPoint™, Roseville, CA, United States; Department of Radiology, A.O.U., Italy; Liver Unit, Department of Gastroenterology and Hepatology, Hospital de Santa Maria, Medical School of Lisbon, Lisbon, 1629-049, Portugal; Bioengineering Department, IST, University of Lisbon, Portugal; Advanced Knowledge Engineering Center, Global Biomedical Technologies, Inc., Roseville, CA, United States","Biswas M., Department of Computer Science and Engineering, NIT, Goa, India; Kuppili V., Department of Computer Science and Engineering, NIT, Goa, India; Edla D.R., Department of Computer Science and Engineering, NIT, Goa, India; Suri H.S., Brown University, Providence, RI, United States, Monitoring and Diagnostic Division, AtheroPoint™, Roseville, CA, United States; Saba L., Department of Radiology, A.O.U., Italy; Marinhoe R.T., Liver Unit, Department of Gastroenterology and Hepatology, Hospital de Santa Maria, Medical School of Lisbon, Lisbon, 1629-049, Portugal; Sanches J.M., Bioengineering Department, IST, University of Lisbon, Portugal; Suri J.S., Advanced Knowledge Engineering Center, Global Biomedical Technologies, Inc., Roseville, CA, United States","[No abstract available]","","Benchmarking; Computational Biology; Diagnosis, Computer-Assisted; Fatty Liver; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Reproducibility of Results; Risk Factors; ROC Curve; Support Vector Machine; Ultrasonography; Article; computer assisted tomography; dual energy computed tomography; fatty liver; human; liver; machine learning; major clinical study; nuclear magnetic resonance imaging; risk; support vector machine; tissue characterization; ultrasound; artificial neural network; benchmarking; biology; computer assisted diagnosis; diagnostic imaging; echography; evaluation study; fatty liver; receiver operating characteristic; reproducibility; risk factor","Elsevier Ireland Ltd","01692607","","CMPBE","29512496","Article","Scopus","2-s2.0-85038880889"
"Li Y.; Shen L.","Li, Yuexiang (57192647725); Shen, Linlin (7401704647)","57192647725; 7401704647","Skin lesion analysis towards melanoma detection using deep learning network","2018","Sensors (Switzerland)","431","10.3390/s18020556","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041966080&doi=10.3390%2fs18020556&partnerID=40&md5=ad96fc18bce0a634de60d661b12e8a4e","Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, 518060, China; Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, 518060, China","Li Y., Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, 518060, China, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, 518060, China; Shen L., Computer Vision Institute, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, 518060, China, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen, 518060, China","Skin lesions are a severe disease globally. Early detection of melanoma in dermoscopy images significantly increases the survival rate. However, the accurate recognition of melanoma is extremely challenging due to the following reasons: low contrast between lesions and skin, visual similarity between melanoma and non-melanoma lesions, etc. Hence, reliable automatic detection of skin tumors is very useful to increase the accuracy and efficiency of pathologists. In this paper, we proposed two deep learning methods to address three main tasks emerging in the area of skin lesion image processing, i.e., lesion segmentation (task 1), lesion dermoscopic feature extraction (task 2) and lesion classification (task 3). A deep learning framework consisting of two fully convolutional residual networks (FCRN) is proposed to simultaneously produce the segmentation result and the coarse classification result. A lesion index calculation unit (LICU) is developed to refine the coarse classification results by calculating the distance heat-map. A straight-forward CNN is proposed for the dermoscopic feature extraction task. The proposed deep learning frameworks were evaluated on the ISIC 2017 dataset. Experimental results show the promising accuracies of our frameworks, i.e., 0.753 for task 1, 0.848 for task 2 and 0.912 for task 3 were achieved. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep convolutional network; Fully-convolutional residual network; Melanoma recognition; Skin lesion classification","Dermoscopy; Humans; Image Processing, Computer-Assisted; Machine Learning; Melanoma; Skin Neoplasms; Convolution; Dermatology; Diagnosis; Extraction; Feature extraction; Image processing; Image segmentation; Learning systems; Oncology; Coarse classification; Convolutional networks; Learning frameworks; Lesion classification; Lesion segmentations; Melanoma recognition; Segmentation results; Skin lesion; epiluminescence microscopy; human; image processing; machine learning; melanoma; skin tumor; Deep learning","MDPI AG","14248220","","","29439500","Article","Scopus","2-s2.0-85041966080"
"Sun X.; Shi J.; Liu L.; Dong J.; Plant C.; Wang X.; Zhou H.","Sun, Xin (56366080900); Shi, Junyu (57193717104); Liu, Lipeng (57193087257); Dong, Junyu (22634069200); Plant, Claudia (9269477900); Wang, Xinhua (56693931600); Zhou, Huiyu (23062556900)","56366080900; 57193717104; 57193087257; 22634069200; 9269477900; 56693931600; 23062556900","Transferring deep knowledge for object recognition in Low-quality underwater videos","2018","Neurocomputing","66","10.1016/j.neucom.2017.09.044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030701582&doi=10.1016%2fj.neucom.2017.09.044&partnerID=40&md5=cef1f9b5f17ec5a7f3cbc450ad011807","College of Information Science and Engineering, Ocean University of China, Qingdao, 266100, China; State Key Laboratory of Applied Optics, Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, 130033, China; Faculty of computer science, University of Vienna, Vienna, Austria; School of Electronics, Electrical Engineering and Computer Science, Queen's University of Belfast, Belfast, United Kingdom","Sun X., College of Information Science and Engineering, Ocean University of China, Qingdao, 266100, China, State Key Laboratory of Applied Optics, Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, 130033, China; Shi J., College of Information Science and Engineering, Ocean University of China, Qingdao, 266100, China; Liu L., College of Information Science and Engineering, Ocean University of China, Qingdao, 266100, China; Dong J., College of Information Science and Engineering, Ocean University of China, Qingdao, 266100, China; Plant C., Faculty of computer science, University of Vienna, Vienna, Austria; Wang X., State Key Laboratory of Applied Optics, Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, 130033, China; Zhou H., School of Electronics, Electrical Engineering and Computer Science, Queen's University of Belfast, Belfast, United Kingdom","In recent years, underwater video technologies allow us to explore the ocean in scientific and noninvasive ways, such as environmental monitoring, marine ecology studies, and fisheries management. However the low-light and high-noise scenarios pose great challenges for the underwater image and video analysis. We here propose a CNN knowledge transfer framework for underwater object recognition and tackle the problem of extracting discriminative features from relatively low contrast images. Even with the insufficient training set, the transfer framework can well learn a recognition model for the special underwater object recognition task together with the help of data augmentation. For better identifying objects from an underwater video, a weighted probabilities decision mechanism is introduced to identify the object from a series of frames. The proposed framework can be implemented for real-time underwater object recognition on autonomous underwater vehicles and video monitoring systems. To verify the effectiveness of our method, experiments on a public dataset are carried out. The results show that the proposed method achieves promising results for underwater object recognition on both test image datasets and underwater videos. © 2017","Computer vision; Deep learning; Object detection; Transfer learning; Underwater video analysis","Autonomous underwater vehicles; Computer vision; Deep learning; Environmental management; Environmental technology; Knowledge management; Object detection; Real time systems; Discriminative features; Environmental Monitoring; Fisheries management; Transfer learning; Video analysis; Video monitoring systems; Video technologies; Weighted probability; analytic method; Article; artificial neural network; contrast enhancement; experimental study; image analysis; machine learning; marine environment; measurement accuracy; nonhuman; priority journal; problem solving; recognition index; training; transfer of learning; videorecording; Object recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85030701582"
"Lee K.; Kim B.; Choi Y.; Kim S.; Shin W.; Lee S.; Park S.; Kim S.; Tan A.C.; Kang J.","Lee, Kyubum (54585506800); Kim, Byounggun (57191633142); Choi, Yonghwa (57191633563); Kim, Sunkyu (37026402000); Shin, Wonho (57191627695); Lee, Sunwon (37108227300); Park, Sungjoon (58161443100); Kim, Seongsoon (54585556100); Tan, Aik Choon (8949996200); Kang, Jaewoo (8914056400)","54585506800; 57191633142; 57191633563; 37026402000; 57191627695; 37108227300; 58161443100; 54585556100; 8949996200; 8914056400","Deep learning of mutation-gene-drug relations from the literature","2018","BMC Bioinformatics","34","10.1186/s12859-018-2029-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041001490&doi=10.1186%2fs12859-018-2029-1&partnerID=40&md5=8b6b5b778e164cdba31e0fee838dbae5","Korea University, Department of Computer Science and Engineering, Seoul, South Korea; Korea University, Interdisciplinary Graduate Program in Bioinformatics, Seoul, South Korea; University of Colorado Anschutz Medical Campus, Translational Bioinformatics and Cancer Systems Biology Laboratory, Division of Medical Oncology, Department of Medicine, Aurora, 80045, CO, United States","Lee K., Korea University, Department of Computer Science and Engineering, Seoul, South Korea; Kim B., Korea University, Interdisciplinary Graduate Program in Bioinformatics, Seoul, South Korea; Choi Y., Korea University, Department of Computer Science and Engineering, Seoul, South Korea; Kim S., Korea University, Department of Computer Science and Engineering, Seoul, South Korea; Shin W., Korea University, Interdisciplinary Graduate Program in Bioinformatics, Seoul, South Korea; Lee S., Korea University, Department of Computer Science and Engineering, Seoul, South Korea; Park S., Korea University, Department of Computer Science and Engineering, Seoul, South Korea; Kim S., Korea University, Department of Computer Science and Engineering, Seoul, South Korea; Tan A.C., University of Colorado Anschutz Medical Campus, Translational Bioinformatics and Cancer Systems Biology Laboratory, Division of Medical Oncology, Department of Medicine, Aurora, 80045, CO, United States; Kang J., Korea University, Department of Computer Science and Engineering, Seoul, South Korea, Korea University, Interdisciplinary Graduate Program in Bioinformatics, Seoul, South Korea","Background: Molecular biomarkers that can predict drug efficacy in cancer patients are crucial components for the advancement of precision medicine. However, identifying these molecular biomarkers remains a laborious and challenging task. Next-generation sequencing of patients and preclinical models have increasingly led to the identification of novel gene-mutation-drug relations, and these results have been reported and published in the scientific literature. Results: Here, we present two new computational methods that utilize all the PubMed articles as domain specific background knowledge to assist in the extraction and curation of gene-mutation-drug relations from the literature. The first method uses the Biomedical Entity Search Tool (BEST) scoring results as some of the features to train the machine learning classifiers. The second method uses not only the BEST scoring results, but also word vectors in a deep convolutional neural network model that are constructed from and trained on numerous documents such as PubMed abstracts and Google News articles. Using the features obtained from both the BEST search engine scores and word vectors, we extract mutation-gene and mutation-drug relations from the literature using machine learning classifiers such as random forest and deep convolutional neural networks. Our methods achieved better results compared with the state-of-the-art methods. We used our proposed features in a simple machine learning model, and obtained F1-scores of 0.96 and 0.82 for mutation-gene and mutation-drug relation classification, respectively. We also developed a deep learning classification model using convolutional neural networks, BEST scores, and the word embeddings that are pre-trained on PubMed or Google News data. Using deep learning, the classification accuracy improved, and F1-scores of 0.96 and 0.86 were obtained for the mutation-gene and mutation-drug relations, respectively. Conclusion: We believe that our computational methods described in this research could be used as an important tool in identifying molecular biomarkers that predict drug responses in cancer patients. We also built a database of these mutation-gene-drug relations that were extracted from all the PubMed abstracts. We believe that our database can prove to be a valuable resource for precision medicine researchers. © 2018 The Author(s).","BioNLP; Convolutional neural networks; Deep learning; Information extraction; Mutation; NLP; Precision medicine; Text mining","Antineoplastic Agents; Databases, Factual; Drug Resistance, Neoplasm; Humans; Mutation; Neoplasms; Neural Networks (Computer); Precision Medicine; Search Engine; Abstracting; Artificial intelligence; Biomarkers; Computational methods; Convolution; Data mining; Decision trees; Deep neural networks; Diseases; Genes; Information retrieval; Learning systems; Machinery; Natural language processing systems; Neural networks; Search engines; antineoplastic agent; BioNLP; Classification accuracy; Convolutional neural network; Mutation; Next-generation sequencing; Relation classifications; State-of-the-art methods; Text mining; artificial neural network; drug resistance; factual database; genetics; human; mutation; neoplasm; pathology; personalized medicine; search engine; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","29368597","Article","Scopus","2-s2.0-85041001490"
"Wang Z.; Wang X.; Wang G.","Wang, Zhenhua (55924830000); Wang, Xingxing (57023080700); Wang, Gang (54957302700)","55924830000; 57023080700; 54957302700","Learning fine-grained features via a CNN Tree for Large-scale Classification","2018","Neurocomputing","40","10.1016/j.neucom.2017.09.061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030632484&doi=10.1016%2fj.neucom.2017.09.061&partnerID=40&md5=47ea547dcf0029a3794d904076344c4c","School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Alibaba AI Labs, Hangzhou, China","Wang Z., School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel; Wang X., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Wang G., Alibaba AI Labs, Hangzhou, China","We propose a novel approach to enhance the discriminability of Convolutional Neural Networks (CNN). The key idea is to build a tree structure that could progressively learn fine-grained features to distinguish a subset of classes, by learning features only among these classes. Such features are expected to be more discriminative, compared to features learned for all the classes. We develop a new algorithm to effectively learn the tree structure from a large number of classes. Experiments on large-scale image classification tasks demonstrate that our method could boost the performance of a given basic CNN model. Our method is quite general, hence it can potentially be used in combination with many other deep learning models. © 2017 Elsevier B.V.","Deep learning; Feature learning; Image classification; Tree model","Deep learning; Forestry; Image classification; Neural networks; Convolutional neural network; Discriminability; Feature learning; Large scale classifications; Learning models; Number of class; Tree modeling; Tree structures; Article; artificial neural network; classification; classifier; data base; discriminant analysis; discrimination learning; image analysis; learning algorithm; machine learning; mathematical analysis; mathematical computing; mathematical model; priority journal; Trees (mathematics)","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85030632484"
"Jia H.; Pang X.-C.; Zhao Y.; Wang H.-G.; Liu A.-L.; Du G.-H.","Jia, Hao (57193668944); Pang, Xiao-Cong (56443396300); Zhao, Ying (56113251100); Wang, Hai-Gang (57201686593); Liu, Ai-Lin (14048755600); Du, Guan-Hua (13103739800)","57193668944; 56443396300; 56113251100; 57201686593; 14048755600; 13103739800","Network pharmacology mechanism study on the effective constituents of Polygala Tenuifolia for anti-Alzheimer's disease","2018","Chinese Journal of New Drugs","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045766847&partnerID=40&md5=6633a3239bbe7ed339bfed1e0978540e","Institute of Materia Medica, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100050, China","Jia H., Institute of Materia Medica, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100050, China; Pang X.-C., Institute of Materia Medica, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100050, China; Zhao Y., Institute of Materia Medica, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100050, China; Wang H.-G., Institute of Materia Medica, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100050, China; Liu A.-L., Institute of Materia Medica, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100050, China; Du G.-H., Institute of Materia Medica, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100050, China","Objective: To clarify the network pharmacology mechanism of Polygala Tenuifolia against Alzheimer's disease. Methods: First, we collected the constituents of Polygala tenuifolia and key targets toward AD. Machine learning algorithms were applied to construct classifiers for predicting the effective constituents. Second, docking models were utilized for further evaluation. Finally, constituent-targetnetwork, target-target network and target-biology pathway network were built. Results: Through prediction of blood-brain penetration and validation, it was found that 36 chemical constituents could penetrate blood-brainbarrier among 100 collected compounds, thedominating targets of which involved AChE, COX-2, TNF-α, Insulin-degrading enzyme and APP. Chemical constituent-target network confirmed that polygala saponins, glycosides of polygalaceae, chromeno [4, 3-b] chromene-6, 7-dione, norharman(β-carbazoline), polygalaxanthone III and sterol consisted of the main chemical constituent structures, which highly aimed at AchE, APP, M-TAU, GSK3β and 5HT1A. GO (gene-ontology) and KEGG enrichment analysis showed that the main pathways of these constituents involve neurotransmitter release, synaptic conduction and synaptic plasticity, apoptosis regulation, phosphorylation pathway, Ca2+ signaling pathway and so on. Conclusion: Polygala Tenuifolia could play a network mechanism of anti-Alzheimer's disease by integrating multi-constituent, multi-target and multi-pathway. This study may offer a deep insight for clinical application, moreover, it may contribute to the further research on this mechanism. © 2018, Chinese Journal of New Drugs Co. Ltd. All right reserved.","Alzheimer's disease; Network pharmacology; Polygala Tenuifolia; Virtual screening","cyclooxygenase 2; glycoside; insulinase; neurotransmitter; plant extract; Polygala tenuifolia extract; saponin derivative; sterol; tumor necrosis factor; unclassified drug; xanthone derivative; algorithm; Alzheimer disease; Article; blood brain barrier; chemical composition; drug mechanism; drug penetration; machine learning; molecular docking; neurotransmitter release; nonhuman; Polygala tenuifolia","Chinese Journal of New Drugs Co. Ltd.","10033734","","","","Article","Scopus","2-s2.0-85045766847"
"Chen P.-J.; Lin M.-C.; Lai M.-J.; Lin J.-C.; Lu H.H.-S.; Tseng V.S.","Chen, Peng-Jen (57116757500); Lin, Meng-Chiung (56898302200); Lai, Mei-Ju (56975810300); Lin, Jung-Chun (55612375700); Lu, Henry Horng-Shing (34977061000); Tseng, Vincent S. (6507335623)","57116757500; 56898302200; 56975810300; 55612375700; 34977061000; 6507335623","Accurate Classification of Diminutive Colorectal Polyps Using Computer-Aided Analysis","2018","Gastroenterology","285","10.1053/j.gastro.2017.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044847443&doi=10.1053%2fj.gastro.2017.10.010&partnerID=40&md5=763bab624b92c834cc2b6aa1cd930414","Division of Gastroenterology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; Department of Biological Science and Technology, National Chiao Tung University, Hsinchu, Taiwan; Division of Gastroenterology, Taichung Armed Forces General Hospital, Taichung, Taiwan; Department of Pathology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; Big Data Research Center and Institute of Statistics, National Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan","Chen P.-J., Division of Gastroenterology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; Lin M.-C., Department of Biological Science and Technology, National Chiao Tung University, Hsinchu, Taiwan, Division of Gastroenterology, Taichung Armed Forces General Hospital, Taichung, Taiwan; Lai M.-J., Department of Pathology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; Lin J.-C., Division of Gastroenterology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; Lu H.H.-S., Big Data Research Center and Institute of Statistics, National Chiao Tung University, Hsinchu, Taiwan; Tseng V.S., Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan","Background & Aims: Narrow-band imaging is an image-enhanced form of endoscopy used to observed microstructures and capillaries of the mucosal epithelium which allows for real-time prediction of histologic features of colorectal polyps. However, narrow-band imaging expertise is required to differentiate hyperplastic from neoplastic polyps with high levels of accuracy. We developed and tested a system of computer-aided diagnosis with a deep neural network (DNN-CAD) to analyze narrow-band images of diminutive colorectal polyps. Methods: We collected 1476 images of neoplastic polyps and 681 images of hyperplastic polyps, obtained from the picture archiving and communications system database in a tertiary hospital in Taiwan. Histologic findings from the polyps were also collected and used as the reference standard. The images and data were used to train the DNN. A test set of images (96 hyperplastic and 188 neoplastic polyps, smaller than 5 mm), obtained from patients who underwent colonoscopies from March 2017 through August 2017, was then used to test the diagnostic ability of the DNN-CAD vs endoscopists (2 expert and 4 novice), who were asked to classify the images of the test set as neoplastic or hyperplastic. Their classifications were compared with findings from histologic analysis. The primary outcome measures were diagnostic accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and diagnostic time. The accuracy, sensitivity, specificity, PPV, NPV, and diagnostic time were compared among DNN-CAD, the novice endoscopists, and the expert endoscopists. The study was designed to detect a difference of 10% in accuracy by a 2-sided McNemar test. Results: In the test set, the DNN-CAD identified neoplastic or hyperplastic polyps with 96.3% sensitivity, 78.1% specificity, a PPV of 89.6%, and a NPV of 91.5%. Fewer than half of the novice endoscopists classified polyps with a NPV of 90% (their NPVs ranged from 73.9% to 84.0%). DNN-CAD classified polyps as neoplastic or hyperplastic in 0.45 ± 0.07 seconds—shorter than the time required by experts (1.54 ± 1.30 seconds) and nonexperts (1.77 ± 1.37 seconds) (both P < .001). DNN-CAD classified polyps with perfect intra-observer agreement (kappa score of 1). There was a low level of intra-observer and inter-observer agreement in classification among endoscopists. Conclusions: We developed a system called DNN-CAD to identify neoplastic or hyperplastic colorectal polyps less than 5 mm. The system classified polyps with a PPV of 89.6%, and a NPV of 91.5%, and in a shorter time than endoscopists. This deep-learning model has potential for not only endoscopic image recognition but for other forms of medical image analysis, including sonography, computed tomography, and magnetic resonance images. © 2018 AGA Institute","Colon Cancer Detection; Cost-effectiveness; Machine Learning; Magnifying","Automation; Colonic Polyps; Colonoscopy; Colorectal Neoplasms; Databases, Factual; Decision Support Techniques; Diagnosis, Computer-Assisted; Humans; Hyperplasia; Image Interpretation, Computer-Assisted; Narrow Band Imaging; Neural Networks (Computer); Observer Variation; Predictive Value of Tests; Reproducibility of Results; Retrospective Studies; Taiwan; Tumor Burden; adenomatous polyp; adult; Article; cancer mortality; colonoscopy; colorectal polyp; comparative study; computer assisted radiography; computer assisted tomography; deep neural network; descending colon; descending colon polyp; diagnostic accuracy; endoscopist; female; human; image analysis; image enhancement; intestine polyp; major clinical study; male; McNemar test; narrow band imaging; nerve cell network; nuclear magnetic resonance imaging; outcome assessment; prediction; predictive value; priority journal; prospective study; rectum polyp; sigmoid; sigmoid colon polyp; Taiwan; tertiary care center; transverse colon; transverse colon polyp; artificial neural network; automation; classification; colon polyp; colonoscopy; colorectal tumor; computer assisted diagnosis; decision support system; factual database; hyperplasia; narrow band imaging; observer variation; pathology; procedures; reproducibility; retrospective study; tumor volume","W.B. Saunders","00165085","","GASTA","29042219","Article","Scopus","2-s2.0-85044847443"
"Kim S.-K.; Kang H.-B.","Kim, Seul-Kee (57190019000); Kang, Hang-Bong (7404071482)","57190019000; 7404071482","An analysis of smartphone overuse recognition in terms of emotions using brainwaves and deep learning","2018","Neurocomputing","20","10.1016/j.neucom.2017.09.081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031325980&doi=10.1016%2fj.neucom.2017.09.081&partnerID=40&md5=2b14ad5334f54ca4d27749a08b61b202","Department of Digital Media, Catholic University of Korea, Wonmi-gu, Bucheon-si, Gyeonggi-do, South Korea","Kim S.-K., Department of Digital Media, Catholic University of Korea, Wonmi-gu, Bucheon-si, Gyeonggi-do, South Korea; Kang H.-B., Department of Digital Media, Catholic University of Korea, Wonmi-gu, Bucheon-si, Gyeonggi-do, South Korea","The overuse of smartphones is increasingly becoming a social problem. In this paper, we analyze smartphone overuse levels, according to emotion, by examining brainwaves and deep learning. We assessed the asymmetry power with respect to theta, alpha, beta, gamma, and total brainwave activity in 11 lobes. The deep belief network (DBN) was used as the deep learning method, along with k-nearest neighbor (kNN) and a support vector machine (SVM), to determine the smartphone addiction level. The risk group (13 subjects) and non-risk group (12 subjects) watched videos portraying the following concepts: relaxed, fear, joy, and sadness. We found that the risk group was more emotionally unstable than the non-risk group. In recognizing Fear, a clear difference appeared between the risk and non-risk group. The results showed that the gamma band was the most obviously different between the risk and non-risk groups. Moreover, we demonstrated that the measurements of activity in the frontal, parietal, and temporal lobes were indicators of emotion recognition. Through the DBN, we confirmed that these measurements were more accurate in the non-risk group than they were in the risk group. The risk group had higher accuracy in low valence and arousal; on the other hand, the non-risk group had higher accuracy in high valence and arousal. © 2017 Elsevier B.V.","Deep belief network; Electroencephalography (EEG); Emotion recognition; Smartphone overuse","Electroencephalography; Electrophysiology; Nearest neighbor search; Smartphones; Speech recognition; Support vector machines; Deep belief network (DBN); Deep belief networks; Emotion recognition; K nearest neighbor (KNN); Learning methods; Measurements of; Social problems; Temporal lobes; adult; algorithm; alpha rhythm; Article; beta rhythm; computer addiction; electroencephalogram; emotion; fear; female; frontal lobe; gamma rhythm; happiness; high risk population; human; human computer interaction; male; nerve cell network; parietal lobe; priority journal; questionnaire; recognition; sadness; self report; support vector machine; television viewing; temporal lobe; theta rhythm; young adult; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85031325980"
"Hu Z.; Zhang Z.; Yang H.; Chen Q.; Zhu R.; Zuo D.","Hu, Ze (57193441418); Zhang, Zhan (55606660000); Yang, Haiqin (13403893400); Chen, Qing (56287396200); Zhu, Rong (58595181600); Zuo, Decheng (11339633500)","57193441418; 55606660000; 13403893400; 56287396200; 58595181600; 11339633500","Predicting the quality of online health expert question-answering services with temporal features in a deep learning framework","2018","Neurocomputing","16","10.1016/j.neucom.2017.11.039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036658909&doi=10.1016%2fj.neucom.2017.11.039&partnerID=40&md5=23b36d9addadcd2b350c27c9a84273c2","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Department of Computing, Hang Seng Management College, Hong Kong; Research Center on Satellite Technology, Harbin Institute of Technology, Harbin, 150001, China","Hu Z., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Zhang Z., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Yang H., Department of Computing, Hang Seng Management College, Hong Kong; Chen Q., Research Center on Satellite Technology, Harbin Institute of Technology, Harbin, 150001, China; Zhu R., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Zuo D., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China","Currently, online health expert question-answering (HQA) services are the most popular services for health consumers to search online health information due to their convenience and the cost-effectiveness. However, one main challenge of these services is that the quality of the answers posted by physicians varies over a large spectrum. Physicians may not have sufficient time to answer the questions or just want to post advertisements in the answers. To determine high-quality answers, we can apply classification models on them. However, it is critical to include the corresponding features in the classification models. To further enhance the model performance, we propose a set of novel temporal features based on the characteristics of HQA services. Moreover, we propose a deep learning framework, referred to as a collaborative decision convolutional neural network (CDCNN), to learn the semantic non-linear features embedded in the data. By exploiting the learned non-linear semantic features, we can apply the factorization machines (FM) to obtain the quality score of an answer. Finally, we conduct extensive experiments to show the advantages of the proposed framework. © 2017","Collaborative decision; Convolutional neural networks; Factorization machines; Multimodal learning; Temporal features; Word embeddings","Convolution; Cost effectiveness; E-learning; Factorization; Health; Neural networks; Semantics; Collaborative decisions; Convolutional neural network; Embeddings; Factorization machines; Multi-modal learning; Temporal features; answering service; Article; artificial neural network; classification; collaborative decision convolutional neural network; conceptual framework; health care quality; health service; learning; online system; prediction; priority journal; questionnaire; semantics; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85036658909"
"Zhang L.; Lu L.; Summers R.M.; Kebebew E.; Yao J.","Zhang, Ling (55971484200); Lu, Le (55474685200); Summers, Ronald M. (7202364932); Kebebew, Electron (7003372219); Yao, Jianhua (57693843200)","55971484200; 55474685200; 7202364932; 7003372219; 57693843200","Convolutional Invasion and Expansion Networks for Tumor Growth Prediction","2018","IEEE Transactions on Medical Imaging","51","10.1109/TMI.2017.2774044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036577535&doi=10.1109%2fTMI.2017.2774044&partnerID=40&md5=ec7f862a8e5cfd2694043ed2781b9a5b","Radiology and Imaging Sciences Department, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and the Clinical Image Processing Service, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Endocrine Oncology Branch, National Cancer Institute, National Institutes of Health, Bethesda, 20892, MD, United States","Zhang L., Radiology and Imaging Sciences Department, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and the Clinical Image Processing Service, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Lu L., Radiology and Imaging Sciences Department, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and the Clinical Image Processing Service, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Summers R.M., Radiology and Imaging Sciences Department, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and the Clinical Image Processing Service, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Kebebew E., Endocrine Oncology Branch, National Cancer Institute, National Institutes of Health, Bethesda, 20892, MD, United States; Yao J., Radiology and Imaging Sciences Department, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and the Clinical Image Processing Service, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States","Tumor growth is associated with cell invasion and mass-effect, which are traditionally formulated by mathematical models, namely reaction-diffusion equations and biomechanics. Such models can be personalized based on clinical measurements to build the predictive models for tumor growth. In this paper, we investigate the possibility of using deep convolutional neural networks to directly represent and learn the cell invasion and mass-effect, and to predict the subsequent involvement regions of a tumor. The invasion network learns the cell invasion from information related to metabolic rate, cell density, and tumor boundary derived from multimodal imaging data. The expansion network models the mass-effect from the growing motion of tumor mass. We also study different architectures that fuse the invasion and expansion networks, in order to exploit the inherent correlations among them. Our network can easily be trained on population data and personalized to a target patient, unlike most previous mathematical modeling methods that fail to incorporate population data. Quantitative experiments on a pancreatic tumor data set show that the proposed method substantially outperforms a state-of-the-art mathematical model-based approach in both accuracy and efficiency, and that the information captured by each of the two subnetworks is complementary. © 1982-2012 IEEE.","Convolutional neural network; Deep learning; Model personalization; Tumor growth prediction","Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Male; Models, Biological; Multimodal Imaging; Neoplasm Invasiveness; Neoplasms; Neural Networks (Computer); Pancreatic Neoplasms; Precision Medicine; Cells; Computer architecture; Convolution; Cytology; Deep learning; Deep neural networks; Forecasting; Linear equations; Mathematical models; Microprocessor chips; Network architecture; Neural networks; Statistics; Tumors; Convolutional neural network; Personalizations; Predictive models; Sociology; Tumor growth; adult; Article; cancer growth; cancer staging; cancer surgery; cell count; cell density; cell invasion; clinical article; controlled study; correlational study; female; human; image processing; image segmentation; male; mathematical model; metabolic rate; middle aged; multimodal imaging; nerve cell network; optic flow; pancreas islet cell tumor; pancreas tumor; prediction; tumor doubling time; tumor growth; tumor volume; von Hippel Lindau disease; artificial neural network; biological model; diagnostic imaging; machine learning; neoplasm; pathophysiology; personalized medicine; procedures; tumor invasion; Population statistics","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29408791","Article","Scopus","2-s2.0-85036577535"
"Wu K.; Wei G.-W.","Wu, Kedi (57196481371); Wei, Guo-Wei (7402848203)","57196481371; 7402848203","Quantitative Toxicity Prediction Using Topology Based Multitask Deep Neural Networks","2018","Journal of Chemical Information and Modeling","107","10.1021/acs.jcim.7b00558","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042655704&doi=10.1021%2facs.jcim.7b00558&partnerID=40&md5=a6c5b329f1c73be58e43cf8ab10179e5","Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824, MI, United States; Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, 48824, MI, United States","Wu K., Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States; Wei G.-W., Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States, Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824, MI, United States, Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, 48824, MI, United States","The understanding of toxicity is of paramount importance to human health and environmental protection. Quantitative toxicity analysis has become a new standard in the field. This work introduces element specific persistent homology (ESPH), an algebraic topology approach, for quantitative toxicity prediction. ESPH retains crucial chemical information during the topological abstraction of geometric complexity and provides a representation of small molecules that cannot be obtained by any other method. To investigate the representability and predictive power of ESPH for small molecules, ancillary descriptors have also been developed based on physical models. Topological and physical descriptors are paired with advanced machine learning algorithms, such as the deep neural network (DNN), random forest (RF), and gradient boosting decision tree (GBDT), to facilitate their applications to quantitative toxicity predictions. A topology based multitask strategy is proposed to take the advantage of the availability of large data sets while dealing with small data sets. Four benchmark toxicity data sets that involve quantitative measurements are used to validate the proposed approaches. Extensive numerical studies indicate that the proposed topological learning methods are able to outperform the state-of-the-art methods in the literature for quantitative toxicity analysis. Our online server for computing element-specific topological descriptors (ESTDs) is available at http://weilab.math.msu.edu/TopTox/. © 2018 American Chemical Society.","","Algorithms; Machine Learning; Neural Networks (Computer); Toxicity Tests; Adaptive boosting; Decision trees; Deep learning; Deep neural networks; Forecasting; Learning systems; Molecules; Numerical methods; Topology; Toxicity; Algebraic topology; Chemical information; Geometric complexity; Persistent homology; Quantitative measurement; State-of-the-art methods; Topological descriptors; Toxicity predictions; algorithm; artificial neural network; machine learning; toxicity testing; Neural networks","American Chemical Society","15499596","","JCISD","29314829","Article","Scopus","2-s2.0-85042655704"
"Liu Y.; Zhao S.; Wang Q.; Gao Q.","Liu, Yang (57192566363); Zhao, Shuangshuang (57196186629); Wang, Qianqian (56179219700); Gao, Quanxue (7202743685)","57192566363; 57196186629; 56179219700; 7202743685","Learning more distinctive representation by enhanced PCA network","2018","Neurocomputing","22","10.1016/j.neucom.2017.09.041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032222035&doi=10.1016%2fj.neucom.2017.09.041&partnerID=40&md5=d0495f4921f6a09e492295827fea8985","State Key Laboratory of Integrated Services Network, Xidian University, China","Liu Y., State Key Laboratory of Integrated Services Network, Xidian University, China; Zhao S., State Key Laboratory of Integrated Services Network, Xidian University, China; Wang Q., State Key Laboratory of Integrated Services Network, Xidian University, China; Gao Q., State Key Laboratory of Integrated Services Network, Xidian University, China","Subspace learning approaches extract features by a simple linear transformation, which can viewed as a shallow network, and they cannot reveal the deep structure embedded in pixels of image. To solve this problem, a deep principal component analysis (PCA) network, namely enhanced PCA Network (EPCANet), is proposed to explore more distinctive representation for face images. EPCANet adds a spatial pooling layer between the first layer and second layer in the PCANet. The spatial pooling layer reveals more spatial and distinctive information by down-sampling or pixel offset for the first layer output and original images. Extensive experimental results in several databases illustrate the efficiency of our proposed methods. © 2017 Elsevier B.V.","Convolutional neural network (CNN); Deep learning; Face recognition; PCA","Deep learning; Face recognition; Image enhancement; Linear transformations; Mathematical transformations; Neural networks; Pixels; Convolutional neural network; Deep structure; Down sampling; Face images; Original images; Second layer; Subspace learning; Article; artificial neural network; classification algorithm; comparative effectiveness; convolutional neural network; data processing; face; facial recognition; histogram; image analysis; image processing; intermethod comparison; learning algorithm; machine learning; principal component analysis; priority journal; sampling; spatial analysis; Principal component analysis","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85032222035"
"Raman S.","Raman, Srivatsan (20434362500)","20434362500","Systems Approaches to Understanding and Designing Allosteric Proteins","2018","Biochemistry","16","10.1021/acs.biochem.7b01094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047769222&doi=10.1021%2facs.biochem.7b01094&partnerID=40&md5=c46b1844048ab61afe7892f150ef1c2b","Department of Biochemistry and Department of Bacteriology, University of Wisconsin - Madison, Madison, 53706, WI, United States","Raman S., Department of Biochemistry and Department of Bacteriology, University of Wisconsin - Madison, Madison, 53706, WI, United States","The study of allostery has a central place in biology because of the myriad roles of allosteric proteins in cellular function. As technologies for probing the spatiotemporal resolution of biomolecules have become increasingly sophisticated, so has our understanding of the diverse structural and molecular mechanisms of allosteric proteins. Studies have shown that the allosteric signal is transmitted a through a network of residue-residue interactions connecting distal sites on a protein. Linking structural and dynamical changes to the functional role of individual residues will give a more complete molecular view of allostery. In this work, we highlight new mutational technologies that enable a systems-level, quantitative description of allostery that dissect the role of individual residues through large-scale functional screens. A molecular model for predicting allosteric hot spots can be developed by applying statistical tools on the resulting large sequence-structure-function data sets. Design of allosteric proteins with new function is essential for engineering biological systems. Previous design efforts demonstrate that the allosteric network is a powerful functional constraint in the design of novel or enhanced allosteric proteins. We discuss how a priori knowledge of an allosteric network could improve rational design by facilitating better navigation of the design space. Understanding the molecular ""rules"" governing allostery would elucidate the molecular basis of dysfunction in disease-associated allosteric proteins, provide a means for designing tailored therapeutics, and enable the design of new sensors and enzymes for synthetic biology. © 2017 American Chemical Society.","","Allosteric Regulation; Allosteric Site; Machine Learning; Molecular Dynamics Simulation; Mutagenesis; Phylogeny; Protein Conformation; Protein Domains; Protein Engineering; Recombinant Fusion Proteins; Signal Transduction; Structure-Activity Relationship; Molecular biology; Statistical mechanics; fusion protein; Allosteric proteins; Allosteric signal; Cellular function; Functional constraints; Molecular mechanism; Quantitative description; Spatio-temporal resolution; Statistical tools; allosterism; amino acid sequence; amino acid substitution; Article; deep mutational scanning; human; machine learning; molecular dynamics; molecular model; mutational analysis; phylogeny; point mutation; priority journal; protein conformation; protein domain; protein structure; statistical analysis; statistical coupling analysis; allosteric site; chemistry; mutagenesis; protein engineering; signal transduction; structure activity relation; Proteins","American Chemical Society","00062960","","BICHA","29235352","Article","Scopus","2-s2.0-85047769222"
"Gehrmann S.; Dernoncourt F.; Li Y.; Carlson E.T.; Wu J.T.; Welt J.; Foote J.; Moseley E.T.; Grant D.W.; Tyler P.D.; Celi L.A.","Gehrmann, Sebastian (57055812200); Dernoncourt, Franck (55827671700); Li, Yeran (57200506882); Carlson, Eric T. (36926208500); Wu, Joy T. (57200497494); Welt, Jonathan (57200499757); Foote, John (57200691507); Moseley, Edward T. (57190007251); Grant, David W. (56599720700); Tyler, Patrick D. (55865737200); Celi, Leo A. (16033282700)","57055812200; 55827671700; 57200506882; 36926208500; 57200497494; 57200499757; 57200691507; 57190007251; 56599720700; 55865737200; 16033282700","Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives","2018","PLoS ONE","120","10.1371/journal.pone.0192360","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042178915&doi=10.1371%2fjournal.pone.0192360&partnerID=40&md5=46203eb049046923c857a7a4aa8ccbea","MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States; Harvard SEAS, Harvard University, Cambridge, MA, United States; Massachusetts Institute of Technology, Cambridge, MA, United States; Adobe Research, San Jose, CA, United States; Harvard T.H. Chan School of Public Health, Cambridge, MA, United States; Philips Research North America, Cambridge, MA, United States; Wellman Center for Photomedicine, Massachusetts General Hospital, Boston, MA, United States; Tufts University School of Medicine, Cambridge, MA, United States; College of Science and Mathematics, University of Massachusetts, Boston, MA, United States; Department of Surgery, Division of Plastic and Reconstructive Surgery, Washington University School of Medicine, St. Louis, MO, United States; Department of Internal Medicine, Beth Israel Deaconess Medical Center, Boston, MA, United States","Gehrmann S., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Harvard SEAS, Harvard University, Cambridge, MA, United States; Dernoncourt F., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Massachusetts Institute of Technology, Cambridge, MA, United States, Adobe Research, San Jose, CA, United States; Li Y., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Harvard T.H. Chan School of Public Health, Cambridge, MA, United States; Carlson E.T., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Philips Research North America, Cambridge, MA, United States; Wu J.T., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Harvard T.H. Chan School of Public Health, Cambridge, MA, United States; Welt J., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Wellman Center for Photomedicine, Massachusetts General Hospital, Boston, MA, United States; Foote J., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Tufts University School of Medicine, Cambridge, MA, United States; Moseley E.T., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, College of Science and Mathematics, University of Massachusetts, Boston, MA, United States; Grant D.W., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Department of Surgery, Division of Plastic and Reconstructive Surgery, Washington University School of Medicine, St. Louis, MO, United States; Tyler P.D., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Department of Internal Medicine, Beth Israel Deaconess Medical Center, Boston, MA, United States; Celi L.A., MIT Critical Data, Laboratory for Computational Physiology, Cambridge, MA, United States, Massachusetts Institute of Technology, Cambridge, MA, United States","In secondary analysis of electronic health records, a crucial task consists in correctly identifying the patient cohort under investigation. In many cases, the most valuable and relevant information for an accurate classification of medical conditions exist only in clinical narratives. Therefore, it is necessary to use natural language processing (NLP) techniques to extract and evaluate these narratives. The most commonly used approach to this problem relies on extracting a number of clinician-defined medical concepts from text and using machine learning techniques to identify whether a particular patient has a certain condition. However, recent advances in deep learning and NLP enable models to learn a rich representation of (medical) language. Convolutional neural networks (CNN) for text classification can augment the existing techniques by leveraging the representation of language to learn which phrases in a text are relevant for a given medical condition. In this work, we compare concept extraction based methods with CNNs and other commonly used models in NLP in ten phenotyping tasks using 1,610 discharge summaries from the MIMIC-III database. We show that CNNs outperform concept extraction based methods in almost all of the tasks, with an improvement in F1-score of up to 26 and up to 7 percentage points in area under the ROC curve (AUC). We additionally assess the interpretability of both approaches by presenting and evaluating methods that calculate and extract the most salient phrases for a prediction. The results indicate that CNNs are a valid alternative to existing approaches in patient phenotyping and cohort identification, and should be further investigated. Moreover, the deep learning approach presented in this paper can be used to assist clinicians during chart review or support the extraction of billing codes from text by identifying and highlighting relevant phrases for various medical conditions. © 2018 Gehrmann et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Humans; Language; Learning; Phenotype; adult; article; classification; cohort analysis; controlled study; extraction; female; human; machine learning; male; medical record review; narrative; natural language processing; nervous system; phenotype; prediction; receiver operating characteristic; comparative study; language; learning","Public Library of Science","19326203","","POLNC","29447188","Article","Scopus","2-s2.0-85042178915"
"Jia H.; Xia Y.; Song Y.; Cai W.; Fulham M.; Feng D.D.","Jia, Haozhe (57194833891); Xia, Yong (26427407400); Song, Yang (55722226800); Cai, Weidong (14022230800); Fulham, Michael (7005082387); Feng, David Dagan (7401981167)","57194833891; 26427407400; 55722226800; 14022230800; 7005082387; 7401981167","Atlas registration and ensemble deep convolutional neural network-based prostate segmentation using magnetic resonance imaging","2018","Neurocomputing","72","10.1016/j.neucom.2017.09.084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031329272&doi=10.1016%2fj.neucom.2017.09.084&partnerID=40&md5=902a7ecbfb4351d7f27003fed46b5621","Shaanxi Key Lab of Speech & Image Information Processing (SAIIP), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an, 710072, China; Centre for Multidisciplinary Convergence Computing (CMCC), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an, 710072, China; Biomedical and Multimedia Information Technology (BMIT) Research Group, School of Information Technologies, University of Sydney, 2006, NSW, Australia; Department of PET and Nuclear Medicine, Royal Prince Alfred Hospital, 2050, NSW, Australia; Sydney Medical School, University of Sydney, 2006, NSW, Australia","Jia H., Shaanxi Key Lab of Speech & Image Information Processing (SAIIP), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an, 710072, China, Centre for Multidisciplinary Convergence Computing (CMCC), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an, 710072, China, Biomedical and Multimedia Information Technology (BMIT) Research Group, School of Information Technologies, University of Sydney, 2006, NSW, Australia; Xia Y., Shaanxi Key Lab of Speech & Image Information Processing (SAIIP), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an, 710072, China, Centre for Multidisciplinary Convergence Computing (CMCC), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an, 710072, China; Song Y., Biomedical and Multimedia Information Technology (BMIT) Research Group, School of Information Technologies, University of Sydney, 2006, NSW, Australia; Cai W., Biomedical and Multimedia Information Technology (BMIT) Research Group, School of Information Technologies, University of Sydney, 2006, NSW, Australia; Fulham M., Centre for Multidisciplinary Convergence Computing (CMCC), School of Computer Science and Engineering, Northwestern Polytechnical University, Xi'an, 710072, China, Biomedical and Multimedia Information Technology (BMIT) Research Group, School of Information Technologies, University of Sydney, 2006, NSW, Australia, Department of PET and Nuclear Medicine, Royal Prince Alfred Hospital, 2050, NSW, Australia, Sydney Medical School, University of Sydney, 2006, NSW, Australia; Feng D.D., Biomedical and Multimedia Information Technology (BMIT) Research Group, School of Information Technologies, University of Sydney, 2006, NSW, Australia","Automatic segmentation of prostate in magnetic resonance (MR) images has been more and more applied to the diagnosis of prostate disease and various clinical applications. However, due to the inhomogeneous and varying anatomical appearance around prostate boundary, the segmentation of prostate MR images faces great challenges. Since deep learning shows superior performance in computer vision, we propose a coarse-to-fine segmentation strategy by using deep neural networks to tackle the segmentation problem of the endorectal coil prostate images and non-endorectal coil prostate images separately. First, we present a registration-based coarse segmentation to the pre-processed prostate MR images to get the potential boundary region. Second, we train deep neural networks as pixel-based classifier to predict whether the pixel in the potential boundary region is prostate pixel or not. To improve the discriminability of the algorithm, we further introduce ensemble learning for fine segmentation. Finally, a boundary refinement is used to eliminate the outlier and smooth the boundary. The proposed method has been extensively evaluated on the PROMIS12 challenge dataset and PROSTATEx17 challenge dataset. Experimental results show superior segmentation performance (0.910 ± 0.036 in dice ratio, 1.583 ± 0.441 in average boundary distance and 4.579 ± 1.791 in Hausdorff distance), which demonstrates the effectiveness of the proposed algorithm. © 2017 Elsevier B.V.","Deep neural network; Ensemble learning; MRI prostate segmentation; Pixel classification","Deep learning; Deep neural networks; Diagnosis; Magnetic levitation vehicles; Magnetic resonance imaging; Neural networks; Pixels; Urology; Automatic segmentations; Boundary refinements; Clinical application; Convolutional neural network; Ensemble learning; Pixel classification; Prostate segmentation; Segmentation performance; Article; artificial neural network; efficacy parameters; evaluation study; experimental study; human; image analysis; learning algorithm; machine learning; nuclear magnetic resonance imaging; prediction; priority journal; prostate; urogenital tract radiography; Image segmentation","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85031329272"
"Narasinga Rao M.R.; Venkatesh Prasad V.; Sai Teja P.; Zindavali M.; Phanindra Reddy O.","Narasinga Rao, M.R. (37112870900); Venkatesh Prasad, V. (57215916501); Sai Teja, P. (57277876200); Zindavali, Md. (57215915497); Phanindra Reddy, O. (57215911849)","37112870900; 57215916501; 57277876200; 57215915497; 57215911849","A survey on prevention of overfitting in convolution neural networks using machine learning techniques","2018","International Journal of Engineering and Technology(UAE)","20","10.14419/ijet.v7i1.1.9285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082367485&doi=10.14419%2fijet.v7i1.1.9285&partnerID=40&md5=f4ee6b8fc34c05c5d8621034aa3a1b9e","Department of CSE, K L E F, Guntur, India","Narasinga Rao M.R., Department of CSE, K L E F, Guntur, India; Venkatesh Prasad V., Department of CSE, K L E F, Guntur, India; Sai Teja P., Department of CSE, K L E F, Guntur, India; Zindavali M., Department of CSE, K L E F, Guntur, India; Phanindra Reddy O., Department of CSE, K L E F, Guntur, India","Deep neural nets with a vast quantity of parameters are very effective machine getting to know structures. However, overfitting is an extreme problem in such networks. Massive networks are also sluggish to use, making it difficult to cope with overfitting by combin-ing the predictions of many distinct large neural nets at test time. Dropout is a method for addressing this problem. The important thing concept is to randomly drop units (at the side of their connections) from the neural network for the duration of education. This prevents units from co-adapting an excessive amount of. during schooling, dropout samples from an exponential quantity of various ""thinned"" networks. At take a look at the time, it is simple to precise the impact of averaging the predictions of plenty of these thinned networks through in reality using a single unthinned network that has smaller weights. This considerably minimize overfitting and provides fun-damental enhancements over other regularization techniques. We show that dropout enhance the overall performance of neural net-works on manage gaining knowledge of obligations in imaginative and prescient, speech reputation, document type and computational biology, acquiring today's effects on many benchmark facts sets. © 2018 Authors.","Connvultion neural network; Dropout; Machine learning; Overfitting","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082367485"
"Becker A.S.; Blüthgen C.; Van Phi V.D.; Sekaggya-Wiltshire C.; Castelnuovo B.; Kambugu A.; Fehr J.; Frauenfelder T.","Becker, A.S. (55389064500); Blüthgen, C. (57196281818); Van Phi, V.D. (57201460138); Sekaggya-Wiltshire, C. (57193027559); Castelnuovo, B. (9335157500); Kambugu, A. (24080475700); Fehr, J. (57210092407); Frauenfelder, T. (6507832349)","55389064500; 57196281818; 57201460138; 57193027559; 9335157500; 24080475700; 57210092407; 6507832349","Detection of tuberculosis patterns in digital photographs of chest X-ray images using Deep Learning: Feasibility study","2018","International Journal of Tuberculosis and Lung Disease","43","10.5588/ijtld.17.0520","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040508258&doi=10.5588%2fijtld.17.0520&partnerID=40&md5=162fcaa392b0526bee386fae178884ee","Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Raemistrasse 100, Zurich, 8091, Switzerland; Infectious Disease Institute, College of Health Sciences, Makerere University, Kampala, Uganda; Division of Infectious Diseases and Hospital Epidemiology, University Hospital Zurich, Zurich, Switzerland","Becker A.S., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Raemistrasse 100, Zurich, 8091, Switzerland; Blüthgen C., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Raemistrasse 100, Zurich, 8091, Switzerland; Van Phi V.D., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Raemistrasse 100, Zurich, 8091, Switzerland; Sekaggya-Wiltshire C., Infectious Disease Institute, College of Health Sciences, Makerere University, Kampala, Uganda; Castelnuovo B., Infectious Disease Institute, College of Health Sciences, Makerere University, Kampala, Uganda; Kambugu A., Infectious Disease Institute, College of Health Sciences, Makerere University, Kampala, Uganda; Fehr J., Division of Infectious Diseases and Hospital Epidemiology, University Hospital Zurich, Zurich, Switzerland; Frauenfelder T., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Raemistrasse 100, Zurich, 8091, Switzerland","OBJECTIVE : To evaluate the feasibility of Deep Learning- based detection and classification of pathological patterns in a set of digital photographs of chest X-ray (CXR) images of tuberculosis (TB) patients. MAT ER IAL S AND MET HODS : In this prospective, observational study, patients with previously diagnosed TB were enrolled. Photographs of their CXRs were taken using a consumer-grade digital still camera. The images were stratified by pathological patterns into classes: cavity, consolidation, effusion, interstitial changes, miliary pattern or normal examination. Image analysis was performed with commercially available Deep Learning software in two steps. Pathological areas were first localised; detected areas were then classified. Detection was assessed using receiver operating characteristics (ROC) analysis, and classification using a confusion matrix. RESULT S : The study cohort was 138 patients with human immunodeficiency virus (HIV) and TB coinfection (median age 34 years, IQR 28-40); 54 patients were female. Localisation of pathological areas was excellent (area under the ROC curve 0.82). The software could perfectly distinguish pleural effusions from intraparenchymal changes. The most frequent misclassifications were consolidations as cavitations, and miliary patterns as interstitial patterns (and vice versa). CONCLUS ION: Deep Learning analysis of CXR photographs is a promising tool. Further efforts are needed to build larger, high-quality data sets to achieve better diagnostic performance. © 2018 The Union.","Chest radiograph; CXR; Deep learning; TB; Teleradiology","Adult; Coinfection; Deep Learning; Feasibility Studies; Female; HIV Infections; Humans; Male; Predictive Value of Tests; Prospective Studies; Radiography, Thoracic; ROC Curve; Software; Teleradiology; Tuberculosis, Pulmonary; Uganda; adult; area under the curve; Article; classification; controlled study; Deep Learning; diagnostic test accuracy study; feasibility study; female; human; Human immunodeficiency virus infection; image analysis; machine learning; major clinical study; male; medical photography; observational study; pleura effusion; predictive value; priority journal; prospective study; receiver operating characteristic; sensitivity and specificity; software; thorax radiography; tuberculosis; Uganda; devices; diagnostic imaging; lung tuberculosis; mixed infection; procedures; teleradiology; thorax radiography","International Union against Tubercul. and Lung Dis.","10273719","","IJTDF","29471912","Article","Scopus","2-s2.0-85040508258"
"Saha M.; Chakraborty C.; Racoceanu D.","Saha, Monjoy (56823066900); Chakraborty, Chandan (35509178500); Racoceanu, Daniel (6603452376)","56823066900; 35509178500; 6603452376","Efficient deep learning model for mitosis detection using breast histopathology images","2018","Computerized Medical Imaging and Graphics","149","10.1016/j.compmedimag.2017.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041563643&doi=10.1016%2fj.compmedimag.2017.12.001&partnerID=40&md5=e4514ec7bafdd06ac63f9a0e55110006","School of Medical Science and Technology, Indian Institute of Technology, Kharagpur, West Bengal, India; Sorbonne University, Paris, France; Pontifical Catholic University of Peru, Lima, Peru","Saha M., School of Medical Science and Technology, Indian Institute of Technology, Kharagpur, West Bengal, India; Chakraborty C., School of Medical Science and Technology, Indian Institute of Technology, Kharagpur, West Bengal, India; Racoceanu D., Sorbonne University, Paris, France, Pontifical Catholic University of Peru, Lima, Peru","Mitosis detection is one of the critical factors of cancer prognosis, carrying significant diagnostic information required for breast cancer grading. It provides vital clues to estimate the aggressiveness and the proliferation rate of the tumour. The manual mitosis quantification from whole slide images is a very labor-intensive and challenging task. The aim of this study is to propose a supervised model to detect mitosis signature from breast histopathology WSI images. The model has been designed using deep learning architecture with handcrafted features. We used handcrafted features issued from previous medical challenges MITOS @ ICPR 2012, AMIDA-13 and projects (MICO ANR TecSan) expertise. The deep learning architecture mainly consists of five convolution layers, four max-pooling layers, four rectified linear units (ReLU), and two fully connected layers. ReLU has been used after each convolution layer as an activation function. Dropout layer has been included after first fully connected layer to avoid overfitting. Handcrafted features mainly consist of morphological, textural and intensity features. The proposed architecture has shown to have an improved 92% precision, 88% recall and 90% F-score. Prospectively, the proposed model will be very beneficial in routine exam, providing pathologists with efficient and – as we will prove – effective second opinion for breast cancer grading from whole slide images. Last but not the least, this model could lead junior and senior pathologists, as medical researchers, to a superior understanding and evaluation of breast cancer stage and genesis. © 2017 Elsevier Ltd","Breast cancer; Convolution; Deep neural network; Handcrafted features; Hematoxylin and eosin; Mitosis","Algorithms; Breast Neoplasms; Coloring Agents; Eosine Yellowish-(YS); Female; Fluorescent Dyes; Hematoxylin; Humans; Image Processing, Computer-Assisted; Mitosis; Supervised Machine Learning; Convolution; Deep neural networks; Diagnosis; Diseases; Grading; Network architecture; coloring agent; eosin; fluorescent dye; hematoxylin; Breast Cancer; Breast cancer grading; Fully-connected layers; Handcrafted features; Hematoxylin and eosin; Learning architectures; Mitosis; Proposed architectures; Article; breast cancer; cancer grading; cancer staging; carcinogenesis; deep learning model; diagnostic accuracy; false negative result; human; machine learning; mitosis; priority journal; qualitative analysis; quantitative analysis; radiological parameters; algorithm; breast tumor; diagnostic imaging; female; image processing; pathology; supervised machine learning; Medical imaging","Elsevier Ltd","08956111","","CMIGE","29409716","Article","Scopus","2-s2.0-85041563643"
"Li M.; Ling C.; Xu Q.; Gao J.","Li, Man (57195962855); Ling, Cheng (56828742700); Xu, Qi (57197726769); Gao, Jingyang (55995325700)","57195962855; 56828742700; 57197726769; 55995325700","Classification of G-protein coupled receptors based on a rich generation of convolutional neural network, N-gram transformation and multiple sequence alignments","2018","Amino Acids","7","10.1007/s00726-017-2512-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034230537&doi=10.1007%2fs00726-017-2512-4&partnerID=40&md5=2b9f0583cd5a0dfcb09e6a6a3c3f704c","Department of Computer Science and Technology, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China","Li M., Department of Computer Science and Technology, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Ling C., Department of Computer Science and Technology, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Xu Q., Department of Computer Science and Technology, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Gao J., Department of Computer Science and Technology, College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China","Sequence classification is crucial in predicting the function of newly discovered sequences. In recent years, the prediction of the incremental large-scale and diversity of sequences has heavily relied on the involvement of machine-learning algorithms. To improve prediction accuracy, these algorithms must confront the key challenge of extracting valuable features. In this work, we propose a feature-enhanced protein classification approach, considering the rich generation of multiple sequence alignment algorithms, N-gram probabilistic language model and the deep learning technique. The essence behind the proposed method is that if each group of sequences can be represented by one feature sequence, composed of homologous sites, there should be less loss when the sequence is rebuilt, when a more relevant sequence is added to the group. On the basis of this consideration, the prediction becomes whether a query sequence belonging to a group of sequences can be transferred to calculate the probability that the new feature sequence evolves from the original one. The proposed work focuses on the hierarchical classification of G-protein Coupled Receptors (GPCRs), which begins by extracting the feature sequences from the multiple sequence alignment results of the GPCRs sub-subfamilies. The N-gram model is then applied to construct the input vectors. Finally, these vectors are imported into a convolutional neural network to make a prediction. The experimental results elucidate that the proposed method provides significant performance improvements. The classification error rate of the proposed method is reduced by at least 4.67% (family level I) and 5.75% (family Level II), in comparison with the current state-of-the-art methods. The implementation program of the proposed work is freely available at: https://github.com/alanFchina/CNN. © 2017, Springer-Verlag GmbH Austria, part of Springer Nature.","Convolutional neural network; Machine learning; Multiple sequence alignment; Sequence classification","Algorithms; Amino Acid Sequence; Databases, Protein; Machine Learning; Models, Theoretical; Neural Networks (Computer); Receptors, G-Protein-Coupled; Reproducibility of Results; Sequence Alignment; Sequence Analysis, Protein; G protein coupled receptor; G protein coupled receptor; algorithm; analytical error; Article; artificial neural network; classification algorithm; convolutional neural network; Internet; machine learning; multiple sequence alignment; n gram transformation; prediction; priority journal; probability; protein analysis; protein family; sequence alignment; sequence homology; amino acid sequence; chemistry; classification; genetics; protein database; reproducibility; sequence analysis; theoretical model","Springer-Verlag Wien","09394451","","AACIE","29151135","Article","Scopus","2-s2.0-85034230537"
"Wang H.; Wang J.; Chen W.; Xu L.","Wang, Hesheng (56183152100); Wang, Jingchuan (11638897300); Chen, Weidong (55716020300); Xu, Lifei (56729335000)","56183152100; 11638897300; 55716020300; 56729335000","Automatic illumination planning for robot vision inspection system","2018","Neurocomputing","22","10.1016/j.neucom.2017.05.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019620537&doi=10.1016%2fj.neucom.2017.05.015&partnerID=40&md5=f138e560808044ad2a73c96f8dea095c","Department of Automation, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, 200240, China","Wang H., Department of Automation, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, 200240, China; Wang J., Department of Automation, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, 200240, China; Chen W., Department of Automation, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, 200240, China; Xu L., Department of Automation, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, 200240, China","High-quality original image is very important in robot vision inspection system and illumination is a significant component that directly affect cameras optical imaging system and plays a decisive role on image quality. To guarantee camera imaging system for high-quality images and achieve automatic illumination control in the motion of inspection robot under dark environment, this paper proposes an optimal light intensity planning method based image quality analysis. It is mainly achieved by building a computational model to automatically predict optimal light intensity values for desired image quality when camera observation distances fluctuate. Before regression modeling, it is necessary to extract discriminative features representing image quality. We design feature extractor by deep learning instead of human engineers which required careful engineering and considerable domain expertise. Deep learning methods are representation-learning methods that allows a machine to be fed with raw data and to automatically discover the representations needed for regression or classification. Experimental results demonstrate the feasibility and efficiency of this method. © 2017 Elsevier B.V.","Automatic illumination; Feature learning; Image quality analysis; Robot vision inspection","Cameras; Computer vision; Deep learning; Image analysis; Image quality; Imaging systems; Inspection; Inspection equipment; Learning systems; Optical testing; Quality control; Robots; Visual servoing; Desired image qualities; Discriminative features; Feature learning; Illumination planning; Image quality analysis; Optical imaging system; Vision inspection; Vision inspection systems; Article; automated pattern recognition; automatic illumination; automation; classifier; control system; illumination; image quality; light intensity; machine learning; priority journal; regression analysis; robot vision inspection; robotics; Robot programming","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85019620537"
"Hakim A.; Mor Y.; Toker I.A.; Levine A.; Neuhof M.; Markovitz Y.; Rechavi O.","Hakim, Adam (57200298297); Mor, Yael (57200295137); Toker, Itai Antoine (57038814600); Levine, Amir (57194061908); Neuhof, Moran (56983031200); Markovitz, Yishai (57200292898); Rechavi, Oded (24173650400)","57200298297; 57200295137; 57038814600; 57194061908; 56983031200; 57200292898; 24173650400","WorMachine: Machine learning-based phenotypic analysis tool for worms","2018","BMC Biology","27","10.1186/s12915-017-0477-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040707688&doi=10.1186%2fs12915-017-0477-0&partnerID=40&md5=eeb93f7e8eaf33cadf73f7482ce7c2ff","Sagol School of Neuroscience, Tel Aviv University, Tel Aviv, Israel; Tel Aviv University, Department of Neurobiology, Wise Faculty of Life Sciences, Tel Aviv, Israel; School of Medicine, The Hebrew University of Jerusalem, Department of Biochemistry and Molecular Biology, Institute for Medical Research Israel-Canada (IMRIC), Jerusalem, Israel","Hakim A., Sagol School of Neuroscience, Tel Aviv University, Tel Aviv, Israel; Mor Y., Sagol School of Neuroscience, Tel Aviv University, Tel Aviv, Israel, Tel Aviv University, Department of Neurobiology, Wise Faculty of Life Sciences, Tel Aviv, Israel; Toker I.A., Tel Aviv University, Department of Neurobiology, Wise Faculty of Life Sciences, Tel Aviv, Israel; Levine A., School of Medicine, The Hebrew University of Jerusalem, Department of Biochemistry and Molecular Biology, Institute for Medical Research Israel-Canada (IMRIC), Jerusalem, Israel; Neuhof M., Tel Aviv University, Department of Neurobiology, Wise Faculty of Life Sciences, Tel Aviv, Israel; Markovitz Y., Tel Aviv University, Department of Neurobiology, Wise Faculty of Life Sciences, Tel Aviv, Israel; Rechavi O., Sagol School of Neuroscience, Tel Aviv University, Tel Aviv, Israel, Tel Aviv University, Department of Neurobiology, Wise Faculty of Life Sciences, Tel Aviv, Israel","Background: Caenorhabditis elegans nematodes are powerful model organisms, yet quantification of visible phenotypes is still often labor-intensive, biased, and error-prone. We developed WorMachine, a three-step MATLAB-based image analysis software that allows (1) automated identification of C. elegans worms, (2) extraction of morphological features and quantification of fluorescent signals, and (3) machine learning techniques for high-level analysis. Results: We examined the power of WorMachine using five separate representative assays: supervised classification of binary-sex phenotype, scoring continuous-sexual phenotypes, quantifying the effects of two different RNA interference treatments, and measuring intracellular protein aggregation. Conclusions: WorMachine is suitable for analysis of a variety of biological questions and provides an accurate and reproducible analysis tool for measuring diverse phenotypes. It serves as a ""quick and easy,"" convenient, high-throughput, and automated solution for nematode research. © 2018 Hakim et al.","Caenorhabditis elegans; Deep learning; Feature extraction; High-throughput image analysis; Image processing; Machine learning; Phenotype analysis","Animals; Caenorhabditis elegans; Female; Genetic Testing; Machine Learning; Male; Optical Imaging; Phenotype; anatomy and histology; animal; Caenorhabditis elegans; female; fluorescence imaging; genetic screening; genetics; machine learning; male; phenotype; procedures; trends","BioMed Central Ltd.","17417007","","","29338709","Article","Scopus","2-s2.0-85040707688"
"Krishna Chaitanya G.; Meka D.R.; Vamsi V.S.; Ravi Karthik M.V.S.","Krishna Chaitanya, G. (57196038244); Meka, Dinesh Reddy (57215916877); Vamsi, Vakalapudi Surya (57214432680); Ravi Karthik, M.V.S. (57215913859)","57196038244; 57215916877; 57214432680; 57215913859","A survey on twitter sentimental analysis with machine learning techniques","2018","International Journal of Engineering and Technology(UAE)","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082367527&partnerID=40&md5=91d3240fab09b410b941f3147dc6fcb9","Dept of Computer Science and Engineering, KLEF, Vaddeswaram, India","Krishna Chaitanya G., Dept of Computer Science and Engineering, KLEF, Vaddeswaram, India; Meka D.R., Dept of Computer Science and Engineering, KLEF, Vaddeswaram, India; Vamsi V.S., Dept of Computer Science and Engineering, KLEF, Vaddeswaram, India; Ravi Karthik M.V.S., Dept of Computer Science and Engineering, KLEF, Vaddeswaram, India","Sentiment or emotion behind a tweet from Twitter or a post from Facebook can help us answer what opinions or feedback a person has. With the advent of growing user-generated blogs, posts and reviews across various social media and online retails, calls for an understanding of these afore mentioned user data acts as a catalyst in building Recommender systems and drive business plans. User reviews on online retail stores influence buying behavior of customers and thus complements the ever-growing need of sentiment analysis. Machine Learning helps us to read between the lines of tweets by proving us with various algorithms like Naïve Bayes, SVM, etc. Sentiment Analysis uses Machine Learning and Natural Language Processing (NLP) to extract, classify and analyze tweets for sentiments (emotions). There are various packages and frameworks in R and Python that aid in Sentiment Analysis or Text Mining in general. © 2018 Authors.","Deep Learning; Machine learning; Natural Language Processing; Sentiment analysis; Twitter R Data","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082367527"
"Gopi K.; Selvakumar S.J.","Gopi, K. (57430641400); Selvakumar, Second J. (57210765845)","57430641400; 57210765845","Analysis of lung tumour detection and segmentation using level set method of active contour model","2018","International Journal of Engineering and Technology(UAE)","3","10.14419/ijet.v7i3.6.16014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082365902&doi=10.14419%2fijet.v7i3.6.16014&partnerID=40&md5=7874a154be9c8b73672b582dc6129ea4","Dept. of ECE, SRM University, Chennai, India","Gopi K., Dept. of ECE, SRM University, Chennai, India; Selvakumar S.J., Dept. of ECE, SRM University, Chennai, India","Lung cancer is the most common leading cancer in both men and women all over the world. Accurate image segmentation is an essential image analysis tool that is responsible for partitioning an image into several sub-regions. Active contour model have been widely used for effective image segmentation methods as this model produce sub-regions with continuous boundaries. It is used in the applications such as image analysis, deep learning, computer vision and machine learning. Advanced level set method helps to implement active contours for image segmentation with good boundary detection accuracy. This paper proposes a model based on active contour using level set methods for segmentation of such lung CT images and focusing 3D lesion refinement. The features were determined by applying a multiscale Gaussian filter. This proposed method is able to detect lung tumors in CT images with intensity, homogeneity and noise. The proposed method uses LIDC-IDRI dataset images to segment accurate 3D lesion of lung tumor CT images. © 2018 Authors.","Active contours; Image segmentation; Level set methods; LIDC-IDRI dataset; Multiscale Gaussian filter","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082365902"
"Olmos R.; Tabik S.; Herrera F.","Olmos, Roberto (57194388033); Tabik, Siham (55884151200); Herrera, Francisco (7102347190)","57194388033; 55884151200; 7102347190","Automatic handgun detection alarm in videos using deep learning","2018","Neurocomputing","141","10.1016/j.neucom.2017.05.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019947234&doi=10.1016%2fj.neucom.2017.05.012&partnerID=40&md5=e74598f026f6d7485aee108974cd2649","Soft Computing and Intelligent Information Systems research group, University of Granada, Granada, 18071, Spain; Faculty of Computing and Information Technology, King Abdulaziz University (KAU) Jeddah, Saudi Arabia","Olmos R., Soft Computing and Intelligent Information Systems research group, University of Granada, Granada, 18071, Spain; Tabik S., Soft Computing and Intelligent Information Systems research group, University of Granada, Granada, 18071, Spain; Herrera F., Soft Computing and Intelligent Information Systems research group, University of Granada, Granada, 18071, Spain, Faculty of Computing and Information Technology, King Abdulaziz University (KAU) Jeddah, Saudi Arabia","Current surveillance and control systems still require human supervision and intervention. This work presents a novel automatic handgun detection system in videos appropriate for both, surveillance and control purposes. We reformulate this detection problem into the problem of minimizing false positives and solve it by i) building the key training data-set guided by the results of a deep Convolutional Neural Networks (CNN) classifier and ii) assessing the best classification model under two approaches, the sliding window approach and region proposal approach. The most promising results are obtained by Faster R-CNN based model trained on our new database. The best detector shows a high potential even in low quality youtube videos and provides satisfactory results as automatic alarm system. Among 30 scenes, it successfully activates the alarm after five successive true positives in a time interval smaller than 0.2 s, in 27 scenes. We also define a new metric, Alarm Activation Time per Interval (AATpI), to assess the performance of a detection model as an automatic detection system in videos. © 2017 Elsevier B.V.","Alarm Activation Time per Interval; Classification; Convolutional Neural Networks; Deep learning; Detection; Faster R-CNN; VGG-16","Alarm systems; Chemical activation; Classification (of information); Convolution; Deep learning; Deep neural networks; Error detection; Neural networks; Activation time; Automatic detection systems; Classification models; Convolutional neural network; Detection problems; Faster R-CNN; Training data sets; VGG-16; accuracy; alarm activation time per interval; Article; artificial neural network; automatic handgun detection alarm; automation; classifier; controlled study; convolutional neural network; data base; data processing; deep learning; false negative result; false positive result; firearm; machine learning; monitoring; parameters; priority journal; process optimization; videorecording; Security systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85019947234"
"Adhikari B.; Hou J.; Cheng J.","Adhikari, Badri (56120455900); Hou, Jie (56673336000); Cheng, Jianlin (57203108630)","56120455900; 56673336000; 57203108630","Protein contact prediction by integrating deep multiple sequence alignments, coevolution and machine learning","2018","Proteins: Structure, Function and Bioinformatics","13","10.1002/prot.25405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032822749&doi=10.1002%2fprot.25405&partnerID=40&md5=c234b93448985a11beb7b75cce5385ce","Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, MO, United States; Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, United States","Adhikari B., Department of Mathematics and Computer Science, University of Missouri-St. Louis, St. Louis, MO, United States; Hou J., Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, United States; Cheng J., Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, United States","In this study, we report the evaluation of the residue-residue contacts predicted by our three different methods in the CASP12 experiment, focusing on studying the impact of multiple sequence alignment, residue coevolution, and machine learning on contact prediction. The first method (MULTICOM-NOVEL) uses only traditional features (sequence profile, secondary structure, and solvent accessibility) with deep learning to predict contacts and serves as a baseline. The second method (MULTICOM-CONSTRUCT) uses our new alignment algorithm to generate deep multiple sequence alignment to derive coevolution-based features, which are integrated by a neural network method to predict contacts. The third method (MULTICOM-CLUSTER) is a consensus combination of the predictions of the first two methods. We evaluated our methods on 94 CASP12 domains. On a subset of 38 free-modeling domains, our methods achieved an average precision of up to 41.7% for top L/5 long-range contact predictions. The comparison of the three methods shows that the quality and effective depth of multiple sequence alignments, coevolution-based features, and machine learning integration of coevolution-based features and traditional features drive the quality of predicted protein contacts. On the full CASP12 dataset, the coevolution-based features alone can improve the average precision from 28.4% to 41.6%, and the machine learning integration of all the features further raises the precision to 56.3%, when top L/5 predicted long-range contacts are evaluated. And the correlation between the precision of contact prediction and the logarithm of the number of effective sequences in alignments is 0.66. © 2017 Wiley Periodicals, Inc.","CASP; coevolution; deep learning; machine learning; multiple sequence alignment; protein contact prediction","Algorithms; Computational Biology; Crystallography, X-Ray; Databases, Protein; Datasets as Topic; Humans; Machine Learning; Models, Molecular; Protein Conformation; Protein Folding; Proteins; Sequence Alignment; Sequence Analysis, Protein; solvent; protein; accuracy; algorithm; Article; artificial neural network; coevolution; computer prediction; contact prediction; correlational study; machine learning; MULICOM NOVEL method; MULTICOM CLUSTER method; MULTICOM CONSTRUCT method; priority journal; protein analysis; protein domain; protein secondary structure; protein structure; quality control; sequence alignment; biology; chemistry; human; information processing; molecular model; procedures; protein conformation; protein database; protein folding; sequence alignment; sequence analysis; X ray crystallography","John Wiley and Sons Inc.","08873585","","","29047157","Article","Scopus","2-s2.0-85032822749"
"Masood A.; Sheng B.; Li P.; Hou X.; Wei X.; Qin J.; Feng D.","Masood, Anum (57213374479); Sheng, Bin (7004699346); Li, Ping (55268425500); Hou, Xuhong (25653889700); Wei, Xiaoer (43761775900); Qin, Jing (35339855100); Feng, Dagan (7401981167)","57213374479; 7004699346; 55268425500; 25653889700; 43761775900; 35339855100; 7401981167","Computer-Assisted Decision Support System in Pulmonary Cancer detection and stage classification on CT images","2018","Journal of Biomedical Informatics","187","10.1016/j.jbi.2018.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040686779&doi=10.1016%2fj.jbi.2018.01.005&partnerID=40&md5=47d37605644db9dd116bf96abd9341e4","Dept. of Computer Science and Engineering, Shanghai Jiao Tong University, China; Dept. of Computer Science, COMSATS Institute of Information Technology, Pakistan; Faculty of Information Technology, Macau University of Science and Technology, Macao; Shanghai Jiao Tong University Affiliated Sixth People's Hospital, China; School of Nursing, The Hong Kong Polytechnic University, Hong Kong; School of Information Technologies, The University of Sydney, Australia","Masood A., Dept. of Computer Science and Engineering, Shanghai Jiao Tong University, China, Dept. of Computer Science, COMSATS Institute of Information Technology, Pakistan; Sheng B., Dept. of Computer Science and Engineering, Shanghai Jiao Tong University, China; Li P., Faculty of Information Technology, Macau University of Science and Technology, Macao; Hou X., Shanghai Jiao Tong University Affiliated Sixth People's Hospital, China; Wei X., Shanghai Jiao Tong University Affiliated Sixth People's Hospital, China; Qin J., School of Nursing, The Hong Kong Polytechnic University, Hong Kong; Feng D., School of Information Technologies, The University of Sydney, Australia","Pulmonary cancer is considered as one of the major causes of death worldwide. For the detection of lung cancer, computer-assisted diagnosis (CADx) systems have been designed. Internet-of-Things (IoT) has enabled ubiquitous internet access to biomedical datasets and techniques; in result, the progress in CADx is significant. Unlike the conventional CADx, deep learning techniques have the basic advantage of an automatic exploitation feature as they have the ability to learn mid and high level image representations. We proposed a Computer-Assisted Decision Support System in Pulmonary Cancer by using the novel deep learning based model and metastasis information obtained from MBAN (Medical Body Area Network). The proposed model, DFCNet, is based on the deep fully convolutional neural network (FCNN) which is used for classification of each detected pulmonary nodule into four lung cancer stages. The performance of proposed work is evaluated on different datasets with varying scan conditions. Comparison of proposed classifier is done with the existing CNN techniques. Overall accuracy of CNN and DFCNet was 77.6% and 84.58%, respectively. Experimental results illustrate the effectiveness of proposed method for the detection and classification of lung cancer nodules. These results demonstrate the potential for the proposed technique in helping the radiologists in improving nodule detection accuracy with efficiency. © 2018 Elsevier Inc.","Convolutional neural networks (CNN); Deep learning; Lung cancer stages; MBAN (Medical Body Area Network); mIoT (medical Internet of Things); Nodule detection","Algorithms; Databases, Factual; Decision Making; Decision Support Systems, Clinical; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Internet; Lung; Lung Neoplasms; Machine Learning; Neoplasm Staging; Neural Networks (Computer); Pattern Recognition, Automated; Software; Solitary Pulmonary Nodule; Symptom Assessment; Tomography, X-Ray Computed; Biological organs; Computer aided instruction; Computerized tomography; Convolution; Decision support systems; Deep learning; Diseases; Image classification; Internet of things; Medical information systems; Neural networks; Body Area Network; Convolutional Neural Networks (CNN); Lung Cancer; mIoT (medical Internet of Things); Nodule detection; analytic method; Article; artificial neural network; cancer classification; cancer diagnosis; cancer staging; clinical article; clinical effectiveness; computer assisted diagnosis; computer assisted tomography; controlled study; decision support system; diagnostic accuracy; diagnostic test accuracy study; false positive result; fully convolutional neural network; human; Internet; lung cancer; lung nodule; machine learning; Medical Body Area Network; medical Internet of Thing; priority journal; retrospective study; sensitivity and specificity; algorithm; automated pattern recognition; cancer staging; clinical decision support system; computer assisted diagnosis; decision making; diagnostic imaging; factual database; image processing; lung; lung nodule; lung tumor; procedures; software; symptom assessment; x-ray computed tomography; Computer aided diagnosis","Academic Press Inc.","15320464","","JBIOB","29366586","Article","Scopus","2-s2.0-85040686779"
"Xie Z.; Schwartz O.; Prasad A.","Xie, Ziqian (57224848099); Schwartz, Odelia (7006284113); Prasad, Abhishek (15760702200)","57224848099; 7006284113; 15760702200","Decoding of finger trajectory from ECoG using deep learning","2018","Journal of Neural Engineering","50","10.1088/1741-2552/aa9dbe","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047334183&doi=10.1088%2f1741-2552%2faa9dbe&partnerID=40&md5=8b1109e070f326c294981d11b98193b9","Department of Biomedical Engineering, University of Miami, Coral Gables, FL, United States; Department of Computer Science, University of Miami, Coral Gables, FL, United States","Xie Z., Department of Biomedical Engineering, University of Miami, Coral Gables, FL, United States; Schwartz O., Department of Computer Science, University of Miami, Coral Gables, FL, United States; Prasad A., Department of Biomedical Engineering, University of Miami, Coral Gables, FL, United States","Objective. Conventional decoding pipeline for brain-machine interfaces (BMIs) consists of chained different stages of feature extraction, time-frequency analysis and statistical learning models. Each of these stages uses a different algorithm trained in a sequential manner, which makes it difficult to make the whole system adaptive. The goal was to create an adaptive online system with a single objective function and a single learning algorithm so that the whole system can be trained in parallel to increase the decoding performance. Here, we used deep neural networks consisting of convolutional neural networks (CNN) and a special kind of recurrent neural network (RNN) called long short term memory (LSTM) to address these needs. Approach. We used electrocorticography (ECoG) data collected by Kubanek et al. The task consisted of individual finger flexions upon a visual cue. Our model combined a hierarchical feature extractor CNN and a RNN that was able to process sequential data and recognize temporal dynamics in the neural data. CNN was used as the feature extractor and LSTM was used as the regression algorithm to capture the temporal dynamics of the signal. Main results. We predicted the finger trajectory using ECoG signals and compared results for the least angle regression (LARS), CNN-LSTM, random forest, LSTM model (LSTM-HC, for using hard-coded features) and a decoding pipeline consisting of band-pass filtering, energy extraction, feature selection and linear regression. The results showed that the deep learning models performed better than the commonly used linear model. The deep learning models not only gave smoother and more realistic trajectories but also learned the transition between movement and rest state. Significance. This study demonstrated a decoding network for BMI that involved a convolutional and recurrent neural network model. It integrated the feature extraction pipeline into the convolution and pooling layer and used LSTM layer to capture the state transitions. The discussed network eliminated the need to separately train the model at each step in the decoding pipeline. The whole system can be jointly optimized using stochastic gradient descent and is capable of online learning. © 2018 IOP Publishing Ltd.","brain machine interface; convolutional neural network; decoding; deep learning; ECoG; long short term memory","Brain-Computer Interfaces; Deep Learning; Electrocorticography; Fingers; Humans; Movement; Photic Stimulation; Sensorimotor Cortex; Brain; Brain computer interface; Convolution; Decision trees; Decoding; Deep learning; Deep neural networks; Electroencephalography; Electrophysiology; Extraction; Feature extraction; Learning algorithms; Pipelines; Regression analysis; Stochastic systems; Trajectories; Brain machine interface; Brain machine interface (BMIs); Convolutional neural network; Convolutional Neural Networks (CNN); ECoG; Recurrent neural network (RNN); Recurrent neural network model; Stochastic gradient descent; algorithm; Article; artificial neural network; association; brain computer interface; comparative study; dynamics; electrocorticography; energy; feature extraction; finger; human; index finger; kinematics; little finger; middle finger; motion; prediction; priority journal; random forest; rest; ring finger; sensorimotor cortex; short term memory; thumb; brain computer interface; electrocorticography; finger; movement (physiology); photostimulation; physiology; procedures; Long short-term memory","Institute of Physics Publishing","17412560","","","29182152","Article","Scopus","2-s2.0-85047334183"
"Lin H.; Liu T.; Shi C.; Petillion S.; Kindts I.; Weltens C.; Depuydt T.; Song Y.; Saleh Z.; Xu X.G.; Tang X.","Lin, Hui (56877918500); Liu, Tianyu (55507194100); Shi, Chengyu (14625443400); Petillion, Saskia (41862339200); Kindts, Isabelle (56090847500); Weltens, Caroline (6701790710); Depuydt, Tom (6506434846); Song, Yulin (55371707500); Saleh, Ziad (9940239300); Xu, Xie George (35263307500); Tang, Xiaoli (9639739700)","56877918500; 55507194100; 14625443400; 41862339200; 56090847500; 6701790710; 6506434846; 55371707500; 9940239300; 35263307500; 9639739700","Feasibility study of individualized optimal positioning selection for left-sided whole breast radiotherapy: DIBH or prone","2018","Journal of Applied Clinical Medical Physics","10","10.1002/acm2.12283","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041893481&doi=10.1002%2facm2.12283&partnerID=40&md5=bb8158321025643df7ce53a9cbc4a836","Nuclear Engineering and Engineering Physics, Rensselaer Polytechnic Institute, Troy, United States; Department of Medical Physics, Memorial Sloan-Kettering Cancer Center, New York, United States; Department of Radiation Oncology, University Hospitals of Leuven, Leuven, Belgium","Lin H., Nuclear Engineering and Engineering Physics, Rensselaer Polytechnic Institute, Troy, United States; Liu T., Nuclear Engineering and Engineering Physics, Rensselaer Polytechnic Institute, Troy, United States; Shi C., Department of Medical Physics, Memorial Sloan-Kettering Cancer Center, New York, United States; Petillion S., Department of Radiation Oncology, University Hospitals of Leuven, Leuven, Belgium; Kindts I., Department of Radiation Oncology, University Hospitals of Leuven, Leuven, Belgium; Weltens C., Department of Radiation Oncology, University Hospitals of Leuven, Leuven, Belgium; Depuydt T., Department of Radiation Oncology, University Hospitals of Leuven, Leuven, Belgium; Song Y., Department of Medical Physics, Memorial Sloan-Kettering Cancer Center, New York, United States; Saleh Z., Department of Medical Physics, Memorial Sloan-Kettering Cancer Center, New York, United States; Xu X.G., Nuclear Engineering and Engineering Physics, Rensselaer Polytechnic Institute, Troy, United States; Tang X., Department of Medical Physics, Memorial Sloan-Kettering Cancer Center, New York, United States","The deep inspiration breath hold (DIBH) and prone (P) position are two common heart-sparing techniques for external-beam radiation treatment of left-sided breast cancer patients. Clinicians select the position that is deemed to be better for tissue sparing based on their experience. This approach, however, is not always optimum and consistent. In response to this, we develop a quantitative tool that predicts the optimal positioning for the sake of organs at risk (OAR) sparing. Sixteen left-sided breast cancer patients were considered in the study, each received CT scans in the supine free breathing, supine DIBH, and prone positions. Treatment plans were generated for all positions. A patient was classified as DIBH or P using two different criteria: if that position yielded (1) lower heart dose, or (2) lower weighted OAR dose. Ten anatomical features were extracted from each patient's data, followed by the principal component analysis. Sequential forward feature selection was implemented to identify features that give the best classification performance. Nine statistical models were then applied to predict the optimal positioning and were evaluated using stratified k-fold cross-validation, predictive accuracy and receiver operating characteristic (AUROC). For heart toxicity-based classification, the support vector machine with radial basis function kernel yielded the highest accuracy (0.88) and AUROC (0.80). For OAR overall toxicities-based classification, the quadratic discriminant analysis achieved the highest accuracy (0.90) and AUROC (0.84). For heart toxicity-based classification, Breast volume and the distance between Heart and Breast were the most frequently selected features. For OAR overall toxicities-based classification, Heart volume, Breast volume and the distance between ipsilateral lung and breast were frequently selected. Given the patient data considered in this study, the proposed statistical model is feasible to provide predictions for DIBH and prone position selection as well as indicate important clinical features that affect the position selection. © 2018 American Association of Physicists in Medicine.","Breast cancer; DIBH; Machine learning; OAR sparing; Prone","Breath Holding; Feasibility Studies; Female; Humans; Inhalation; Models, Statistical; Organs at Risk; Patient Positioning; Precision Medicine; Prognosis; Prone Position; Radiotherapy Dosage; Radiotherapy Planning, Computer-Assisted; Radiotherapy, Intensity-Modulated; Unilateral Breast Neoplasms; breast tumor; breath holding; comparative study; feasibility study; female; human; inhalation; intensity modulated radiation therapy; organs at risk; patient positioning; personalized medicine; procedures; prognosis; prone position; radiation response; radiotherapy dosage; radiotherapy planning system; standards; statistical model","John Wiley and Sons Ltd","15269914","","","29436168","Article","Scopus","2-s2.0-85041893481"
"Zhang W.; Chen Q.; Zhang W.; He X.","Zhang, Wei (57201591153); Chen, Qi (57195776733); Zhang, Weidong (56435071600); He, Xuanyu (57194717391)","57201591153; 57195776733; 56435071600; 57194717391","Long-range terrain perception using convolutional neural networks","2018","Neurocomputing","50","10.1016/j.neucom.2017.09.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029800756&doi=10.1016%2fj.neucom.2017.09.012&partnerID=40&md5=17843260102f9bf4df2ea83a074b560e","School of Control Science and Engineering, Shandong University, Jinan, 250061, Shandong, China","Zhang W., School of Control Science and Engineering, Shandong University, Jinan, 250061, Shandong, China; Chen Q., School of Control Science and Engineering, Shandong University, Jinan, 250061, Shandong, China; Zhang W., School of Control Science and Engineering, Shandong University, Jinan, 250061, Shandong, China; He X., School of Control Science and Engineering, Shandong University, Jinan, 250061, Shandong, China","Autonomous robot navigation in wild environments is still an open problem and relies heavily on accurate terrain perception. Traditional machine learning techniques have achieved good performance for terrain perception; however, most of them require manually designed classifiers, meaning they have a poor generalization ability for learning new unknown environments. In this work, we integrate a deep convolutional neural network (CNN) model with a near-to-far learning strategy to improve the accuracy of terrain segmentation and make it more robust against wild environments. The proposed deep CNN model consists of an encoder and a decoder, which perform downsampling and upsampling for terrain feature extraction, respectively. The near-field terrain information obtained directly from the stereo disparity maps is fed into the CNNs as reference to aid in learning the far-field terrain information. Experimental results on a benchmark dataset demonstrate the effectiveness of the proposed terrain perception method. © 2017 Elsevier B.V.","Convolutional neural networks; Disparity information; Robot navigation; Terrain perception","Convolution; Deep neural networks; Learning systems; Neural networks; Robots; Signal sampling; Stereo image processing; Autonomous robot navigation; Convolutional neural network; Disparity information; Generalization ability; Machine learning techniques; Robot navigation; Terrain perception; Terrain segmentations; accuracy; Article; automated pattern recognition; convolutional neural network; image quality; intermethod comparison; learning algorithm; machine learning; online system; priority journal; three dimensional imaging; wilderness; Landforms","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85029800756"
"Zhao F.; Liu Y.; Huo K.; Zhang S.; Zhang Z.","Zhao, Feixiang (57208685453); Liu, Yongxiang (36067864000); Huo, Kai (35774225800); Zhang, Shuanghui (55954195700); Zhang, Zhongshuai (57200907425)","57208685453; 36067864000; 35774225800; 55954195700; 57200907425","Radar HRRP target recognition based on stacked autoencoder and extreme learning machine","2018","Sensors (Switzerland)","63","10.3390/s18010173","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040784496&doi=10.3390%2fs18010173&partnerID=40&md5=132eaa121131133896d53840bb3fb12a","College of Electronic Science, National University of Defense Technology, Changsha, 410073, China","Zhao F., College of Electronic Science, National University of Defense Technology, Changsha, 410073, China; Liu Y., College of Electronic Science, National University of Defense Technology, Changsha, 410073, China; Huo K., College of Electronic Science, National University of Defense Technology, Changsha, 410073, China; Zhang S., College of Electronic Science, National University of Defense Technology, Changsha, 410073, China; Zhang Z., College of Electronic Science, National University of Defense Technology, Changsha, 410073, China","A novel radar high-resolution range profile (HRRP) target recognition method based on a stacked autoencoder (SAE) and extreme learning machine (ELM) is presented in this paper. As a key component of deep structure, the SAE does not only learn features by making use of data, it also obtains feature expressions at different levels of data. However, with the deep structure, it is hard to achieve good generalization performance with a fast learning speed. ELM, as a new learning algorithm for single hidden layer feedforward neural networks (SLFNs), has attracted great interest from various fields for its fast learning speed and good generalization performance. However, ELM needs more hidden nodes than conventional tuning-based learning algorithms due to the random set of input weights and hidden biases. In addition, the existing ELM methods cannot utilize the class information of targets well. To solve this problem, a regularized ELM method based on the class information of the target is proposed. In this paper, SAE and the regularized ELM are combined to make full use of their advantages and make up for each of their shortcomings. The effectiveness of the proposed method is demonstrated by experiments with measured radar HRRP data. The experimental results show that the proposed method can achieve good performance in the two aspects of real-time and accuracy, especially when only a few training samples are available. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Extreme learning machine; High-resolution range profile; Radar target recognition; Stacked autoencoder","Deep learning; Feedforward neural networks; Image resolution; Knowledge acquisition; Learning systems; Network layers; Radar; Radar measurement; Radar target recognition; Auto encoders; Class information; Extreme learning machine; Feature expression; Generalization performance; High resolution range profiles; Single-hidden layer feedforward neural networks; Target recognition; algorithm; article; deep learning; learning algorithm; single hidden layer feedforward neural network; stacked autoencoder; telecommunication; velocity; Learning algorithms","MDPI AG","14248220","","","29320453","Article","Scopus","2-s2.0-85040784496"
"Kinghorn P.; Zhang L.; Shao L.","Kinghorn, Philip (57192910266); Zhang, Li (56290594900); Shao, Ling (55643855000)","57192910266; 56290594900; 55643855000","A region-based image caption generator with refined descriptions","2018","Neurocomputing","78","10.1016/j.neucom.2017.07.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024365975&doi=10.1016%2fj.neucom.2017.07.014&partnerID=40&md5=6957e955d767ad5b86b94857a07648bf","Computational Intelligence Research Group, Department of Computing Science and Digital Technologies, Faculty of Engineering and Environment, University of Northumbria, Newcastle, NE1 8ST, United Kingdom; School of Computing Sciences, University of East Anglia, Norwich, United Kingdom","Kinghorn P., Computational Intelligence Research Group, Department of Computing Science and Digital Technologies, Faculty of Engineering and Environment, University of Northumbria, Newcastle, NE1 8ST, United Kingdom; Zhang L., Computational Intelligence Research Group, Department of Computing Science and Digital Technologies, Faculty of Engineering and Environment, University of Northumbria, Newcastle, NE1 8ST, United Kingdom; Shao L., School of Computing Sciences, University of East Anglia, Norwich, United Kingdom","Describing the content of an image is a challenging task. To enable detailed description, it requires the detection and recognition of objects, people, relationships and associated attributes. Currently, the majority of the existing research relies on holistic techniques, which may lose details relating to important aspects in a scene. In order to deal with such a challenge, we propose a novel region-based deep learning architecture for image description generation. It employs a regional object detector, recurrent neural network (RNN)-based attribute prediction, and an encoder–decoder language generator embedded with two RNNs to produce refined and detailed descriptions of a given image. Most importantly, the proposed system focuses on a local based approach to further improve upon existing holistic methods, which relates specifically to image regions of people and objects in an image. Evaluated with the IAPR TC-12 dataset, the proposed system shows impressive performance and outperforms state-of-the-art methods using various evaluation metrics. In particular, the proposed system shows superiority over existing methods when dealing with cross-domain indoor scene images. © 2017 Elsevier B.V.","Convolutional and recurrent neural networks; Description generation; Image description generation","Deep learning; Object detection; Description generation; Evaluation metrics; Image descriptions; Language generators; Learning architectures; Recognition of objects; Recurrent neural network (RNN); State-of-the-art methods; adaptive attention; algorithm; Article; artificial neural network; attention; human; image analysis; image caption generator; image processing; language processing; long term memory; measurement accuracy; prediction; priority journal; probability; recurrent neural network; Selective Search algorithm; short term memory; support vector machine; validation process; Recurrent neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85024365975"
"Zimmermann T.; Taetz B.; Bleser G.","Zimmermann, Tobias (7103341642); Taetz, Bertram (37006091800); Bleser, Gabriele (22950167800)","7103341642; 37006091800; 22950167800","IMU-to-segment assignment and orientation alignment for the lower body using deep learning","2018","Sensors (Switzerland)","66","10.3390/s18010302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040931637&doi=10.3390%2fs18010302&partnerID=40&md5=184e5c8e507847e9a952cd9b93f80d25","Junior Research Group wearHEALTH, University of Kaiserslautern, Gottlieb-Daimler-Str. 48, Kaiserslautern, 67663, Germany; Augmented Vision Department, DFKI, Trippstadter Str. 122, Kaiserslautern, 67663, Germany","Zimmermann T., Junior Research Group wearHEALTH, University of Kaiserslautern, Gottlieb-Daimler-Str. 48, Kaiserslautern, 67663, Germany, Augmented Vision Department, DFKI, Trippstadter Str. 122, Kaiserslautern, 67663, Germany; Taetz B., Junior Research Group wearHEALTH, University of Kaiserslautern, Gottlieb-Daimler-Str. 48, Kaiserslautern, 67663, Germany, Augmented Vision Department, DFKI, Trippstadter Str. 122, Kaiserslautern, 67663, Germany; Bleser G., Junior Research Group wearHEALTH, University of Kaiserslautern, Gottlieb-Daimler-Str. 48, Kaiserslautern, 67663, Germany, Augmented Vision Department, DFKI, Trippstadter Str. 122, Kaiserslautern, 67663, Germany","Human body motion analysis based on wearable inertial measurement units (IMUs) receives a lot of attention from both the research community and the and industrial community. This is due to the significant role in, for instance, mobile health systems, sports and human computer interaction. In sensor based activity recognition, one of the major issues for obtaining reliable results is the sensor placement/assignment on the body. For inertial motion capture (joint kinematics estimation) and analysis, the IMU-to-segment (I2S) assignment and alignment are central issues to obtain biomechanical joint angles. Existing approaches for I2S assignment usually rely on hand crafted features and shallow classification approaches (e.g., support vector machines), with no agreement regarding the most suitable features for the assignment task. Moreover, estimating the complete orientation alignment of an IMU relative to the segment it is attached to using a machine learning approach has not been shown in literature so far. This is likely due to the high amount of training data that have to be recorded to suitably represent possible IMU alignment variations. In this work, we propose online approaches for solving the assignment and alignment tasks for an arbitrary amount of IMUs with respect to a biomechanical lower body model using a deep learning architecture and windows of 128 gyroscope and accelerometer data samples. For this, we combine convolutional neural networks (CNNs) for local filter learning with long-short-term memory (LSTM) recurrent networks as well as generalized recurrent units (GRUs) for learning time dynamic features. The assignment task is casted as a classification problem, while the alignment task is casted as a regression problem. In this framework, we demonstrate the feasibility of augmenting a limited amount of real IMU training data with simulated alignment variations and IMU data for improving the recognition/estimation accuracies. With the proposed approaches and final models we achieved 98.57% average accuracy over all segments for the I2S assignment task (100% when excluding left/right switches) and an average median angle error over all segments and axes of 2.91° for the I2S alignment task. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Automatic sensor alignment; Automatic sensor placement; CNN; Deep learning; Inertial sensors; LSTM; Neural networks","Biomechanical Phenomena; Humans; Machine Learning; Motion; Neural Networks (Computer); Biomechanics; Human computer interaction; Industrial research; Learning systems; Long short-term memory; Neural networks; Recurrent neural networks; Units of measurement; Wearable sensors; Automatic sensor placement; Convolutional neural network; Inertial measurement unit; Inertial sensor; Joint kinematics estimation; LSTM; Machine learning approaches; Sensor alignment; artificial neural network; biomechanics; human; machine learning; motion; Deep learning","MDPI AG","14248220","","","29351262","Article","Scopus","2-s2.0-85040931637"
"Duan M.; Li K.; Yang C.; Li K.","Duan, Mingxing (56644095000); Li, Kenli (7404988992); Yang, Canqun (13408914200); Li, Keqin (7404989623)","56644095000; 7404988992; 13408914200; 7404989623","A hybrid deep learning CNN–ELM for age and gender classification","2018","Neurocomputing","200","10.1016/j.neucom.2017.08.062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029522915&doi=10.1016%2fj.neucom.2017.08.062&partnerID=40&md5=d11dc29bcd78c9ac79dd2f7627519894","College of Computer Science, National University of Defense Technology, Changsha, 410073, China; College of Information Science and Engineering, Hunan University, Changsha, 410082, Hunan, China; National Supercomputing Center in Changsha, Changsha, 410082, Hunan, China","Duan M., College of Computer Science, National University of Defense Technology, Changsha, 410073, China; Li K., College of Information Science and Engineering, Hunan University, Changsha, 410082, Hunan, China, National Supercomputing Center in Changsha, Changsha, 410082, Hunan, China; Yang C., College of Computer Science, National University of Defense Technology, Changsha, 410073, China; Li K., College of Information Science and Engineering, Hunan University, Changsha, 410082, Hunan, China, National Supercomputing Center in Changsha, Changsha, 410082, Hunan, China","Automatic age and gender classification has been widely used in a large amount of applications, particularly in human-computer interaction, biometrics, visual surveillance, electronic customer, and commercial applications. In this paper, we introduce a hybrid structure which includes Convolutional Neural Network (CNN) and Extreme Learning Machine (ELM), and integrates the synergy of two classifiers to deal with age and gender classification. The hybrid architecture makes the most of their advantages: CNN is used to extract the features from the input images while ELM classifies the intermediate results. We not only give the detailed deployment of our structure including design of parameters and layers, analysis of the hybrid architecture, and the derivation of back-propagation in this system during the iterations, but also adopt several measures to limit the risk of overfitting. After that, two popular datasets, such as, MORPH-II and Adience Benchmark, are used to verify our hybrid structure. Experimental results show that our hybrid architecture outperforms other studies on the same datasets by exhibiting significant performance improvement in terms of accuracy and efficiency. © 2017 Elsevier B.V.","Classification; Convolutional Neural Network; Extreme Learning Machine; Image; Overfitting","Backpropagation; Classification (of information); Convolution; Deep learning; Human computer interaction; Knowledge acquisition; Network architecture; Neural networks; Risk assessment; Commercial applications; Convolutional neural network; Extreme learning machine; Gender classification; Hybrid architectures; Image; Intermediate results; Overfitting; algorithm; Article; artificial neural network; back propagation; Bayesian learning; classification; classifier; convolutional neural network; data base; extraction; extreme machine learning; fuzzy system; gender; groups by age; image analysis; machine learning; mathematical analysis; mathematical computing; measurement accuracy; pattern recognition; priority journal; risk reduction; support vector machine; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85029522915"
"Wu Y.; Yuan M.; Dong S.; Lin L.; Liu Y.","Wu, Yuting (56178801300); Yuan, Mei (57204145323); Dong, Shaopeng (15834142800); Lin, Li (57192542403); Liu, Yingqi (57195240724)","56178801300; 57204145323; 15834142800; 57192542403; 57195240724","Remaining useful life estimation of engineered systems using vanilla LSTM neural networks","2018","Neurocomputing","601","10.1016/j.neucom.2017.05.063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026488243&doi=10.1016%2fj.neucom.2017.05.063&partnerID=40&md5=d0a232b254bc6621752aaee538c54dbc","School of Energy and Power Engineering, Beihang University, Beijing, 100191, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, 100191, China; Collaborative Innovation Center for Advanced Aero-Engine, Beihang University, Beijing, 100191, China","Wu Y., School of Energy and Power Engineering, Beihang University, Beijing, 100191, China, Collaborative Innovation Center for Advanced Aero-Engine, Beihang University, Beijing, 100191, China; Yuan M., School of Automation Science and Electrical Engineering, Beihang University, Beijing, 100191, China, Collaborative Innovation Center for Advanced Aero-Engine, Beihang University, Beijing, 100191, China; Dong S., School of Automation Science and Electrical Engineering, Beihang University, Beijing, 100191, China; Lin L., School of Energy and Power Engineering, Beihang University, Beijing, 100191, China, Collaborative Innovation Center for Advanced Aero-Engine, Beihang University, Beijing, 100191, China; Liu Y., School of Automation Science and Electrical Engineering, Beihang University, Beijing, 100191, China","Long Short-Term Memory (LSTM) networks are a significant branch of Recurrent Neural Networks (RNN), capable of learning long-term dependencies. In recent years, vanilla LSTM (a variation of original LSTM above) has become the state-of-the-art model for a variety of machine learning problems, especially Natural Language Processing (NLP). However, in industry, this powerful Deep Neural Network (DNN) has not aroused wide concern. In research focusing on Prognostics and Health Management (PHM) technology for complex engineered systems, Remaining Useful Life (RUL) estimation is one of the most challenging problems, which can lead to appropriate maintenance actions to be scheduled proactively to avoid catastrophic failures and minimize economic losses of the systems. Following that, this paper aims to propose utilizing vanilla LSTM neural networks to get good RUL prediction accuracy which makes the most of long short-term memory ability, in the cases of complicated operations, working conditions, model degradations and strong noises. In addition, to promote cognition ability about model degradation processes, a dynamic differential technology was proposed to extract inter-frame information. The whole proposition is illustrated and discussed by performing tests on a case of the health monitoring of aircraft turbofan engines which have four different issues. Performances of vanilla LSTM are benchmarked with standard RNN and Gated Recurrent Unit (GRU) LSTM. Results show the significance of performance improvement achieved by vanilla LSTM. © 2017","Dynamic differential feature; Long short-term memory neural network; Prognostics and health management; Remaining useful life estimation","Aircraft engines; Brain; Complex networks; Deep neural networks; Education; Health; Learning algorithms; Losses; Natural language processing systems; Recurrent neural networks; Systems engineering; Turbofan engines; Aircraft turbofan engines; Complex engineered systems; Differential technology; Inter-frame information; Machine learning problem; Prognostics and health managements; Recurrent neural network (RNN); Remaining useful lives; accuracy; aircraft; aircraft turbofan engine; analytical error; Article; artificial neural network; cognition; engineering; Gated Recurrent Unit Neural Network; general health status assessment; information processing; lifespan; long term memory; mathematical analysis; noise; prediction; priority journal; quantitative analysis; Recurrent Neural Network; short term memory; surgery; vanilla long short term memory neural network; work capacity; Long short-term memory","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85026488243"
"Albadawy E.A.; Saha A.; Mazurowski M.A.","Albadawy, Ehab A. (57200524987); Saha, Ashirbani (57190307394); Mazurowski, Maciej A. (21742977700)","57200524987; 57190307394; 21742977700","Deep learning for segmentation of brain tumors: Impact of cross-institutional training and testing: Impact","2018","Medical Physics","141","10.1002/mp.12752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041528929&doi=10.1002%2fmp.12752&partnerID=40&md5=59bd62dc3e4658f45fe2d3abb128f3a3","Department of Radiology, Duke University School of Medicine, Durham, NC, United States; Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States; Duke University Medical Physics Program, Durham, NC, United States","Albadawy E.A., Department of Radiology, Duke University School of Medicine, Durham, NC, United States; Saha A., Department of Radiology, Duke University School of Medicine, Durham, NC, United States; Mazurowski M.A., Department of Radiology, Duke University School of Medicine, Durham, NC, United States, Department of Electrical and Computer Engineering, Duke University, Durham, NC, United States, Duke University Medical Physics Program, Durham, NC, United States","Background and purpose: Convolutional neural networks (CNNs) are commonly used for segmentation of brain tumors. In this work, we assess the effect of cross-institutional training on the performance of CNNs. Methods: We selected 44 glioblastoma (GBM) patients from two institutions in The Cancer Imaging Archive dataset. The images were manually annotated by outlining each tumor component to form ground truth. To automatically segment the tumors in each patient, we trained three CNNs: (a) one using data for patients from the same institution as the test data, (b) one using data for the patients from the other institution and (c) one using data for the patients from both of the institutions. The performance of the trained models was evaluated using Dice similarity coefficients as well as Average Hausdorff Distance between the ground truth and automatic segmentations. The 10-fold cross-validation scheme was used to compare the performance of different approaches. Results: Performance of the model significantly decreased (P < 0.0001) when it was trained on data from a different institution (dice coefficients: 0.68 ± 0.19 and 0.59 ± 0.19) as compared to training with data from the same institution (dice coefficients: 0.72 ± 0.17 and 0.76 ± 0.12). This trend persisted for segmentation of the entire tumor as well as its individual components. Conclusions: There is a very strong effect of selecting data for training on performance of CNNs in a multi-institutional setting. Determination of the reasons behind this effect requires additional comprehensive investigation. © 2018 American Association of Physicists in Medicine.","brain tumor segmentation; CNN; glioblastoma; impact of cross-institutional training; magnetic resonance imaging","Brain Neoplasms; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Brain; Deep learning; Magnetic levitation vehicles; Medical imaging; Neural networks; Tumors; Brain tumor segmentation; Brain tumors; Cancer imaging; Convolutional neural network; Dice coefficient; Glioblastomas; Ground truth; Impact of cross-institutional training; Performance; Training and testing; Article; clinical article; convolutional neural network; false negative result; glioblastoma; human; image analysis; predictive value; artificial neural network; brain tumor; diagnostic imaging; image processing; machine learning; nuclear magnetic resonance imaging; procedures; Magnetic resonance imaging","John Wiley and Sons Ltd","00942405","","MPHYA","29356028","Article","Scopus","2-s2.0-85041528929"
"Ding M.Q.; Chen L.; Cooper G.F.; Young J.D.; Lu X.","Ding, Michael Q. (56145920000); Chen, Lujia (57192614491); Cooper, Gregory F. (7402356187); Young, Jonathan D. (57195944996); Lu, Xinghua (12799008300)","56145920000; 57192614491; 7402356187; 57195944996; 12799008300","Precision Oncology beyond Targeted Therapy: Combining Omics Data with Machine Learning Matches the Majority of Cancer Cells to Effective Therapeutics","2018","Molecular Cancer Research","108","10.1158/1541-7786.MCR-17-0378","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041467843&doi=10.1158%2f1541-7786.MCR-17-0378&partnerID=40&md5=683221ea2422ab65e579d7d7e960a83c","Department of Biomedical Informatics, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Center for Translational Bioinformatics, University of Pittsburgh, Pittsburgh, PA, United States","Ding M.Q., Department of Biomedical Informatics, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Chen L., Department of Biomedical Informatics, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Cooper G.F., Department of Biomedical Informatics, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Young J.D., Department of Biomedical Informatics, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Lu X., Department of Biomedical Informatics, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States, Center for Translational Bioinformatics, University of Pittsburgh, Pittsburgh, PA, United States","Precision oncology involves identifying drugs that will effectively treat a tumor and then prescribing an optimal clinical treatment regimen. However, most first-line chemotherapy drugs do not have biomarkers to guide their application. For molecularly targeted drugs, using the genomic status of a drug target as a therapeutic indicator has limitations. In this study, machine learning methods (e.g., deep learning) were used to identify informative features from genome-scale omics data and to train classifiers for predicting the effectiveness of drugs in cancer cell lines. The methodology introduced here can accurately predict the efficacy of drugs, regardless of whether they are molecularly targeted or nonspecific chemotherapy drugs. This approach, on a per-drug basis, can identify sensitive cancer cells with an average sensitivity of 0.82 and specificity of 0.82; on a per-cell line basis, it can identify effective drugs with an average sensitivity of 0.80 and specificity of 0.82. This report describes a data-driven precision medicine approach that is not only generalizable but also optimizes therapeutic efficacy. The framework detailed herein, when successfully translated to clinical environments, could significantly broaden the scope of precision oncology beyond targeted therapies, benefiting an expanded proportion of cancer patients. 2017 American Association for Cancer Research.","","Cell Line, Tumor; Computational Biology; Genetic Markers; Genomics; Humans; Machine Learning; Molecular Targeted Therapy; Neoplasms; Pharmacogenomic Variants; Precision Medicine; antiinfective agent; Article; cancer cell line; deep learning; drug efficacy; external validity; gene expression; gene mutation; human; machine learning; molecularly targeted therapy; omics; personalized medicine; pharmacogenomics; priority journal; sensitivity and specificity; biology; genetic marker; genetics; genomics; machine learning; molecularly targeted therapy; neoplasm; personalized medicine; pharmacogenetic variant; procedures; tumor cell line","American Association for Cancer Research Inc.","15417786","","MCROC","29133589","Article","Scopus","2-s2.0-85041467843"
"Fatahi M.; Shahsavari M.; Ahmadi M.; Ahmadi A.; Boulet P.; Devienne P.","Fatahi, Mazdak (57193128120); Shahsavari, Mahyar (56500339800); Ahmadi, Mahmood (24479432000); Ahmadi, Arash (36117624400); Boulet, Pierre (57213967957); Devienne, Philippe (55957117600)","57193128120; 56500339800; 24479432000; 36117624400; 57213967957; 55957117600","Rate-coded DBN: An online strategy for spike-based deep belief networks","2018","Biologically Inspired Cognitive Architectures","8","10.1016/j.bica.2018.04.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120503286&doi=10.1016%2fj.bica.2018.04.009&partnerID=40&md5=e127fe0969a554d352cadddfa7e3f771","Computer and Electrical Engineering Department, Razi University, Kermanshah, Iran; Univ. Lille, CNRS, Centrale Lille, UMR 9189, CRIStAL, Centre de Recherche en Informatique Signal et Automatique de Lille, Lille, F-59000, France; Sogeti Netherlands BV, Lange Dreef 17, Vianen, 4131 NJ, Netherlands","Fatahi M., Computer and Electrical Engineering Department, Razi University, Kermanshah, Iran; Shahsavari M., Univ. Lille, CNRS, Centrale Lille, UMR 9189, CRIStAL, Centre de Recherche en Informatique Signal et Automatique de Lille, Lille, F-59000, France, Sogeti Netherlands BV, Lange Dreef 17, Vianen, 4131 NJ, Netherlands; Ahmadi M., Computer and Electrical Engineering Department, Razi University, Kermanshah, Iran; Ahmadi A., Computer and Electrical Engineering Department, Razi University, Kermanshah, Iran; Boulet P., Univ. Lille, CNRS, Centrale Lille, UMR 9189, CRIStAL, Centre de Recherche en Informatique Signal et Automatique de Lille, Lille, F-59000, France; Devienne P., Univ. Lille, CNRS, Centrale Lille, UMR 9189, CRIStAL, Centre de Recherche en Informatique Signal et Automatique de Lille, Lille, F-59000, France","The memory wall or Von Neumann memory bottleneck decreases the speed of computation in conventional digital platforms. It is due to disharmony of communication speed as well as physical distance between the CPU and memory. In Spiking Neural Network (SNN), both memory and computational elements are integrated into the body of each neuron which provides the possibility of cognitive computing with learning ability in a platform without memory bottleneck. The way of updating the synaptic weights is one of the significant challenges in implementing machine learning methods using spiking model of neurons. Deep Belief learning method recently is used in several state-of-the-art studies due to its potential in robustness computation, pattern recognition, and data classification. In this paper, we use a rate based version of Contrastive Divergence (CD) updating weight rule. Respecting the rate aspect of neural coding, we develop a Spike-Based Deep Belief Network (S-DBN) using Leaky Integrate-and-Fire (LIF) neurons. In experimental evaluations, a two stacked RBMs model is validated using MNIST hand-written digit dataset. The learning accuracy of this architecture is 94.9% yet less than stateof- the-art of Artificial Neural Network (ANN) accuracy, however, quite promising with SNN architecture suitable for hardware implementation. To enhance the accuracy of the network recognition rate, we studied the impacts of notable network parameters for both learning as well as neuron models. Based on the experimental results in this work, choosing optimized parameters for learning rate between 0.008 and 0.01, a frequency of input spikes 18 Hz, the sizes of mini-batches between 25 and 50, and two different membrane voltage thresholds for hidden and visible layers leads to the optimum results in the accuracy rate of the network recognition.  © 2018 Elsevier B.V. All rights reserved.","Contrastive divergence; Deep belief networks; Neuromorphic accelerator; Online training; Spiking neural network","Deep learning; E-learning; Learning algorithms; Network architecture; Network coding; Neural networks; Online systems; Pattern recognition; Contrastive divergence; Deep belief networks; Memory bottleneck; Neural-networks; Neuromorphic; Neuromorphic accelerator; Online Strategy; Online training; Spiking neural network; State of the art; Neurons","Elsevier B.V.","2212683X","","","","Article","Scopus","2-s2.0-85120503286"
"Liu Y.; Palmedo P.; Ye Q.; Berger B.; Peng J.","Liu, Yang (57196034720); Palmedo, Perry (56133480000); Ye, Qing (57201324283); Berger, Bonnie (7201838430); Peng, Jian (27267770800)","57196034720; 56133480000; 57201324283; 7201838430; 27267770800","Enhancing Evolutionary Couplings with Deep Convolutional Neural Networks","2018","Cell Systems","88","10.1016/j.cels.2017.11.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038903223&doi=10.1016%2fj.cels.2017.11.014&partnerID=40&md5=e454aee0e2ad51d27cc58f451761370c","Department of Computer Science, University of Illinois at Urbana-Champaign, Champaign, 61801, IL, United States; Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, 02139, MA, United States; Department of Mathematics, MIT, Cambridge, 02139, MA, United States; Division of Medical Sciences, Harvard University, Cambridge, 02138, MA, United States","Liu Y., Department of Computer Science, University of Illinois at Urbana-Champaign, Champaign, 61801, IL, United States; Palmedo P., Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, 02139, MA, United States, Department of Mathematics, MIT, Cambridge, 02139, MA, United States, Division of Medical Sciences, Harvard University, Cambridge, 02138, MA, United States; Ye Q., Department of Computer Science, University of Illinois at Urbana-Champaign, Champaign, 61801, IL, United States; Berger B., Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, 02139, MA, United States, Department of Mathematics, MIT, Cambridge, 02139, MA, United States; Peng J., Department of Computer Science, University of Illinois at Urbana-Champaign, Champaign, 61801, IL, United States","While genes are defined by sequence, in biological systems a protein's function is largely determined by its three-dimensional structure. Evolutionary information embedded within multiple sequence alignments provides a rich source of data for inferring structural constraints on macromolecules. Still, many proteins of interest lack sufficient numbers of related sequences, leading to noisy, error-prone residue-residue contact predictions. Here we introduce DeepContact, a convolutional neural network (CNN)-based approach that discovers co-evolutionary motifs and leverages these patterns to enable accurate inference of contact probabilities, particularly when few related sequences are available. DeepContact significantly improves performance over previous methods, including in the CASP12 blind contact prediction task where we achieved top performance with another CNN-based approach. Moreover, our tool converts hard-to-interpret coupling scores into probabilities, moving the field toward a consistent metric to assess contact prediction across diverse proteins. Through substantially improving the precision-recall behavior of contact prediction, DeepContact suggests we are near a paradigm shift in template-free modeling for protein structure prediction. Many protein structures of interest remain out of reach for both computational prediction and experimental determination. DeepContact learns patterns of co-evolution across thousands of experimentally determined structures, identifying conserved local motifs and leveraging this information to improve protein residue-residue contact predictions. DeepContact extracts additional information from the evolutionary couplings using its knowledge of co-evolution and structural space, while also converting coupling scores into probabilities that are comparable across protein sequences and alignments. © 2017 The Authors","co-evolution; contact prediction; convolutional neural networks; deep learning; evolutionary couplings; protein structure prediction; structure prediction","Algorithms; Animals; Computational Biology; Databases, Protein; Forecasting; Humans; Machine Learning; Models, Molecular; Neural Networks (Computer); Probability; Protein Conformation; Protein Folding; Proteins; Sequence Alignment; membrane protein; protein; algorithm; amino acid sequence; Article; convolutional neural network; entropy; false positive result; machine learning; molecular recognition; molecular weight; nerve cell network; priority journal; protein secondary structure; animal; artificial neural network; biology; chemistry; forecasting; human; molecular model; probability; procedures; protein conformation; protein database; protein folding; sequence alignment","Cell Press","24054712","","","29275173","Article","Scopus","2-s2.0-85038903223"
"Sathish Kumar R.; Chandrasekaran M.","Sathish Kumar, R. (57220078491); Chandrasekaran, M. (15060993600)","57220078491; 15060993600","Inducing and refining topics for web query classification using a semantic network","2018","Journal of Computational and Theoretical Nanoscience","0","10.1166/jctn.2018.7127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042800949&doi=10.1166%2fjctn.2018.7127&partnerID=40&md5=0ce88d96c95dc90e1ff44d7bcc7c77d5","Department of Electronics and Communication Engineering, Government College of Engineering, Salem, 636011, Tamil Nadu, India","Sathish Kumar R., Department of Electronics and Communication Engineering, Government College of Engineering, Salem, 636011, Tamil Nadu, India; Chandrasekaran M., Department of Electronics and Communication Engineering, Government College of Engineering, Salem, 636011, Tamil Nadu, India","Web query classification, the task of inferring topical categories from a web search query is a non-trivial problem in Information Retrieval domain. The topic categories inferred by a Web query classification system may provide a rich set of features for improving query expansion and web advertising. Conventional methods for Web query classification derive corpus statistics from the web and employ machine-learning techniques to infer Open Directory Project categories. But they suffer from two major drawbacks, the computational overhead to derive corpus statistics and inferring topic categories that are too abstract for semantic discrimination due to polysemy. Concepts too shallow or too deep in the semantic gradient are produced due to the wrong senses of the query terms coalescing with the correct senses. This paper proposes and demonstrates a succinct solution to these problems through a method based on the Tree cut model and Wordnet Thesarus to infer fine-grained topic categories for Web query classification, and also suggests an enhancement to the Tree Cut Model to resolve sense ambiguities. Copyright © 2018 American Scientific Publishers All rights reserved.","Machine learning; Minimum description length; Text mining; Tree cut model; Web query classification; Wordnet","","American Scientific Publishers","15461955","","","","Article","Scopus","2-s2.0-85042800949"
"Liu F.; Jang H.; Kijowski R.; Bradshaw T.; McMillan A.B.","Liu, Fang (55877583300); Jang, Hyungseok (55806832500); Kijowski, Richard (8680578300); Bradshaw, Tyler (55987286000); McMillan, Alan B. (35196501700)","55877583300; 55806832500; 8680578300; 55987286000; 35196501700","Deep learning MR imaging-based attenuation correction for PET/MR imaging","2018","Radiology","301","10.1148/radiol.2017170700","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041472518&doi=10.1148%2fradiol.2017170700&partnerID=40&md5=62cf48fa0133dd4d0e18ee0fbfb2358e","Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Ave, Madison, 53705-2275, WI, United States","Liu F., Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Ave, Madison, 53705-2275, WI, United States; Jang H., Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Ave, Madison, 53705-2275, WI, United States; Kijowski R., Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Ave, Madison, 53705-2275, WI, United States; Bradshaw T., Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Ave, Madison, 53705-2275, WI, United States; McMillan A.B., Department of Radiology, University of Wisconsin School of Medicine and Public Health, 600 Highland Ave, Madison, 53705-2275, WI, United States","Purpose: To develop and evaluate the feasibility of deep learning approaches for magnetic resonance (MR) imaging-based attenuation correction (AC) (termed deep MRAC) in brain positron emission tomography (PET)/MR imaging. Materials and Methods: A PET/MR imaging AC pipeline was built by using a deep learning approach to generate pseudo computed tomographic (CT) scans from MR images. A deep convolutional auto-encoder network was trained to identify air, bone, and soft tissue in volumetric head MR images coregistered to CT data for training. A set of 30 retrospective three-dimensional T1-weighted head images was used to train the model, which was then evaluated in 10 patients by comparing the generated pseudo CT scan to an acquired CT scan. A prospective study was carried out for utilizing simultaneous PET/MR imaging for five subjects by using the proposed approach. Analysis of covariance and paired-sample t tests were used for statistical analysis to compare PET reconstruction error with deep MRAC and two existing MR imaging-based AC approaches with CT-based AC. Results: Deep MRAC provides an accurate pseudo CT scan with a mean Dice coefficient of 0.971 6 0.005 for air, 0.936 6 0.011 for soft tissue, and 0.803 6 0.021 for bone. Furthermore, deep MRAC provides good PET results, with average errors of less than 1% in most brain regions. Significantly lower PET reconstruction errors were realized with deep MRAC (20.7% 6 1.1) compared with Dixon-based soft-tissue and air segmentation (25.8% 6 3.1) and anatomic CT-based template registration (24.8% 6 2.2). Conclusion: The authors developed an automated approach that allows generation of discrete-valued pseudo CT scans (soft tissue, bone, and air) from a single high-spatial-resolution diagnostic-quality three-dimensional MR image and evaluated it in brain PET/MR imaging. This deep learning approach for MR imaging-based AC provided reduced PET reconstruction error relative to a CT-based standard within the brain compared with current MR imaging- based AC approaches.","","Adult; Aged; Aged, 80 and over; Air; Bone and Bones; Brain; Connective Tissue; Feasibility Studies; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Middle Aged; Multimodal Imaging; Photons; Positron-Emission Tomography; Prospective Studies; Retrospective Studies; Stroke; Young Adult; adult; aged; analytical error; Article; automation; bone; computer assisted tomography; controlled study; feasibility study; female; human; human experiment; image analysis; image reconstruction; image segmentation; male; neuroimaging; nuclear magnetic resonance imaging; positron emission tomography; priority journal; prospective study; retrospective study; soft tissue; three dimensional imaging; volumetry; air; anatomy and histology; brain; cerebrovascular accident; connective tissue; evaluation study; image processing; machine learning; middle aged; multimodal imaging; nuclear magnetic resonance imaging; pathology; photon; positron emission tomography; procedures; standards; very elderly; young adult","Radiological Society of North America Inc.","00338419","","RADLA","28925823","Article","Scopus","2-s2.0-85041472518"
"Jain S.; Kedia S.; Sethi T.; Bopanna S.; Yadav D.P.; Goyal S.; Padhan R.; Venigalla P.M.; Sahni P.; Dash N.R.; Pal S.; Makharia G.; Travis S.P.L.; Ahuja V.","Jain, Saransh (57194027276); Kedia, Saurabh (36113944300); Sethi, Tavpritesh (36991690700); Bopanna, Sawan (56928349100); Yadav, Dawesh Prakash (57192374569); Goyal, Sandeep (56372764700); Padhan, Rajesh (57089071000); Venigalla, Pratap Mouli (56087704500); Sahni, Peush (7004330671); Dash, Nihar Ranjan (57201269297); Pal, Sujoy (9244708200); Makharia, Govind (6701885809); Travis, Simon P L (23483262600); Ahuja, Vineet (24176922100)","57194027276; 36113944300; 36991690700; 56928349100; 57192374569; 56372764700; 57089071000; 56087704500; 7004330671; 57201269297; 9244708200; 6701885809; 23483262600; 24176922100","Predictors of long-term outcomes in patients with acute severe colitis: A northern Indian cohort study","2018","Journal of Gastroenterology and Hepatology (Australia)","23","10.1111/jgh.13921","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042281280&doi=10.1111%2fjgh.13921&partnerID=40&md5=ea322aaef472471a0ce61c2039f2be55","Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India; Department of Gastrointestinal Surgery, All India Institute of Medical Sciences, New Delhi, India; Indraprastha Institute of Information Technology, New Delhi, India; Translational Gastroenterology Unit, Oxford University Hospitals, Oxford, United Kingdom","Jain S., Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India; Kedia S., Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India; Sethi T., Indraprastha Institute of Information Technology, New Delhi, India; Bopanna S., Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India; Yadav D.P., Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India; Goyal S., Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India; Padhan R., Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India; Venigalla P.M., Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India; Sahni P., Department of Gastrointestinal Surgery, All India Institute of Medical Sciences, New Delhi, India; Dash N.R., Department of Gastrointestinal Surgery, All India Institute of Medical Sciences, New Delhi, India; Pal S., Department of Gastrointestinal Surgery, All India Institute of Medical Sciences, New Delhi, India; Makharia G., Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India; Travis S.P.L., Translational Gastroenterology Unit, Oxford University Hospitals, Oxford, United Kingdom; Ahuja V., Department of Gastroenterology, All India Institute of Medical Sciences, New Delhi, India","Background and Aim: Knowledge of long-term outcomes following an index episode of acute severe colitis (ASC) can help informed decision making at a time of acute exacerbation especially when colectomy is an option. We aimed to identify long-term outcomes and their predictors after a first episode of ASC in a large North Indian cohort. Methods: Hospitalized patients satisfying Truelove and Witts' criteria under follow-up at a single center from January 2003 to December 2013 were included. Patients avoiding colectomy at index admission were categorized as complete (≤ 3 non bloody stool per day) or incomplete responders, based upon response to corticosteroids at day 7. Random Forest-based machine learning models were constructed to predict the long-term risk of colectomy or steroid dependence following an index episode of ASC. Results: Of 1731 patients with ulcerative colitis, 179 (10%) had an index episode of ASC. Nineteen (11%) patients underwent colectomy at index admission and 42 (26%) over a median follow-up of 56 (1–159) months. Hazard ratio for colectomy for incomplete responder was 3.6 (1.7–7.5, P = 0.001) compared with complete responder. Modeling based on four variables, response at day 7 of hospitalization, steroid use during the first year of diagnosis, longer disease duration before ASC, and number of extra-intestinal manifestations, was able to predict colectomy with an accuracy of 77%. Conclusions: Disease behavior of ASC in India is similar to the West, with a third undergoing colectomy at 10 years. Clinical features, especially response at day 7 hospitalization for index ASC, can predict both colectomy and steroid dependence with reasonable accuracy. © 2017 Journal of Gastroenterology and Hepatology Foundation and John Wiley & Sons Australia, Ltd","acute severe colitis; colectomy; prediction","Acute Disease; Adrenal Cortex Hormones; Adult; Cohort Studies; Colectomy; Colitis, Ulcerative; Female; Follow-Up Studies; Humans; India; Male; Middle Aged; Severity of Illness Index; Time Factors; Treatment Outcome; Young Adult; corticosteroid; cyclosporine; hydrocortisone; mercaptopurine; methotrexate; prednisolone; tumor necrosis factor inhibitor; corticosteroid; acute disease; acute severe colitis; adult; ankylosing spondylitis; arthralgia; Article; cohort analysis; colitis; colon resection; deep vein thrombosis; disease duration; drug response; female; follow up; hospital readmission; hospitalization; human; immunomodulation; length of stay; machine learning; major clinical study; male; outcome assessment; patient satisfaction; priority journal; pyoderma gangrenosum; rectum hemorrhage; recurrent disease; relapse; retrospective study; ulcerative colitis; acute disease; colon resection; India; middle aged; severity of illness index; time factor; treatment outcome; ulcerative colitis; young adult","Blackwell Publishing","08159319","","JGHEE","28801987","Article","Scopus","2-s2.0-85042281280"
"Aviles-Rivero A.I.; Alsaleh S.M.; Casals A.","Aviles-Rivero, Angelica I. (57200300191); Alsaleh, Samar M. (56809209300); Casals, Alicia (55388675500)","57200300191; 56809209300; 55388675500","Sliding to predict: vision-based beating heart motion estimation by modeling temporal interactions","2018","International Journal of Computer Assisted Radiology and Surgery","2","10.1007/s11548-018-1702-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040677862&doi=10.1007%2fs11548-018-1702-1&partnerID=40&md5=8d4e49e47a6ca316afc2c29c66ccb303","Department of Pure Mathematics & Mathematical Statistics, University of Cambridge, Cambridge, United Kingdom; Department of Computer Science, The Institute for Biomedical Engineering, George Washington University, Washington, DC, United States; The Research Center of Biomedical Engineering (CREB), Universitat Politècnica de Cataluya, Barcelona, Spain","Aviles-Rivero A.I., Department of Pure Mathematics & Mathematical Statistics, University of Cambridge, Cambridge, United Kingdom; Alsaleh S.M., Department of Computer Science, The Institute for Biomedical Engineering, George Washington University, Washington, DC, United States; Casals A., The Research Center of Biomedical Engineering (CREB), Universitat Politècnica de Cataluya, Barcelona, Spain","Purpose: Technical advancements have been part of modern medical solutions as they promote better surgical alternatives that serve to the benefit of patients. Particularly with cardiovascular surgeries, robotic surgical systems enable surgeons to perform delicate procedures on a beating heart, avoiding the complications of cardiac arrest. This advantage comes with the price of having to deal with a dynamic target which presents technical challenges for the surgical system. In this work, we propose a solution for cardiac motion estimation. Methods: Our estimation approach uses a variational framework that guarantees preservation of the complex anatomy of the heart. An advantage of our approach is that it takes into account different disturbances, such as specular reflections and occlusion events. This is achieved by performing a preprocessing step that eliminates the specular highlights and a predicting step, based on a conditional restricted Boltzmann machine, that recovers missing information caused by partial occlusions. Results: We carried out exhaustive experimentations on two datasets, one from a phantom and the other from an in vivo procedure. The results show that our visual approach reaches an average minima in the order of magnitude of 10 - 7 while preserving the heart’s anatomical structure and providing stable values for the Jacobian determinant ranging from 0.917 to 1.015. We also show that our specular elimination approach reaches an accuracy of 99% compared to a ground truth. In terms of prediction, our approach compared favorably against two well-known predictors, NARX and EKF, giving the lowest average RMSE of 0.071. Conclusion: Our approach avoids the risks of using mechanical stabilizers and can also be effective for acquiring the motion of organs other than the heart, such as the lung or other deformable objects. © 2018, The Author(s).","Deep learning; Motion estimation and prediction; Robotic surgery","Algorithms; Cardiac Surgical Procedures; Diagnostic Techniques, Cardiovascular; Heart Diseases; Humans; Imaging, Three-Dimensional; Motion; Myocardial Contraction; Phantoms, Imaging; Robotics; anatomical concepts; Article; controlled study; heart beat; heart movement; machine learning; prediction; priority journal; probability; quantitative analysis; signal noise ratio; algorithm; cardiovascular system examination; heart contraction; heart disease; heart surgery; human; imaging phantom; motion; pathophysiology; physiology; procedures; robotics; three dimensional imaging","Springer Verlag","18616410","","","29350321","Article","Scopus","2-s2.0-85040677862"
"Hu T.-H.; Huo Z.; Liu T.-A.; Wang F.; Wan L.; Wang M.-W.; Chen T.; Wang Y.-H.","Hu, Ting-Hong (57201474728); Huo, Zhong (57203119642); Liu, Tai-Ang (23393259700); Wang, Fei (57202331003); Wan, Lei (57203799720); Wang, Mao-Wen (57201475976); Chen, Teng (35236150000); Wang, Ya-Hui (55954511800)","57201474728; 57203119642; 23393259700; 57202331003; 57203799720; 57201475976; 35236150000; 55954511800","Automated Assessment for Bone Age of Left Wrist Joint in Uyghur Teenagers by Deep Learning","2018","Journal of Forensic Medicine","14","10.3969/j.issn.1004-5619.2018.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047949578&doi=10.3969%2fj.issn.1004-5619.2018.01.006&partnerID=40&md5=1bb6fc4671c2972115350da33bf05068","Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai, 200063, China; Department of Forensic Science, Xi'an Jiaotong University Health Science Center, Xi'an, 710061, China; People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi, 830000, China; Shanghai Fanyang Information Technology Co., LTD., Shanghai, 200444, China","Hu T.-H., Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai, 200063, China, Department of Forensic Science, Xi'an Jiaotong University Health Science Center, Xi'an, 710061, China; Huo Z., People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi, 830000, China; Liu T.-A., Shanghai Fanyang Information Technology Co., LTD., Shanghai, 200444, China; Wang F., People's Hospital of Xinjiang Uygur Autonomous Region, Urumqi, 830000, China; Wan L., Department of Forensic Science, Xi'an Jiaotong University Health Science Center, Xi'an, 710061, China; Wang M.-W., Department of Forensic Science, Xi'an Jiaotong University Health Science Center, Xi'an, 710061, China; Chen T., Shanghai Key Laboratory of Forensic Medicine, Shanghai Forensic Service Platform, Academy of Forensic Science, Shanghai, 200063, China; Wang Y.-H., Department of Forensic Science, Xi'an Jiaotong University Health Science Center, Xi'an, 710061, China","Objective: To realize the automated bone age assessment by applying deep learning to digital radiography (DR) image recognition of left wrist joint in Uyghur teenagers, and explore its practical application value in forensic medicine bone age assessment. Methods: The X-ray films of left wrist joint after pretreatment, which were taken from 245 male and 227 female Uyghur nationality teenagers in Uygur Autonomous Region aged from 13.0 to 19.0 years old, were chosen as subjects. And AlexNet was as a regression model of image recognition. From the total samples above, 60% of male and female DR images of left wrist joint were selected as net train set, and 10% of samples were selected as validation set. As test set, the rest 30% were used to obtain the image recognition accuracy with an error range in ±1.0 and ±0.7 age respectively, compared to the real age. Results: The modelling results of deep learning algorithm showed that when the error range was in ±1.0 and ±0.7 age respectively, the accuracy of the net train set was 81.4% and 75.6% in male, and 80.5% and 74.8% in female, respectively. When the error range was in ±1.0 and ±0.7 age respectively, the accuracy of the test set was 79.5% and 71.2% in male, and 79.4% and 66.2% in female, respectively. Conclusion: The combination of bone age research on teenagers'left wrist joint and deep learning, which has high accuracy and good feasibility, can be the research basis of bone age automatic assessment system for the rest joints of body. © 2018 by the Editorial Department of Journal of Forensic Medicine.","Adolescent; Age determination by skeleton; Carpal joints; Deep learning; Forensic anthropology; Image recognition; Tomography, X-ray; Uyghur nationality","Adolescent; Age Determination by Skeleton; Algorithms; Artificial Intelligence; Asian Continental Ancestry Group; China; Female; Forensic Medicine; Humans; Image Processing, Computer-Assisted; Machine Learning; Male; Neural Networks (Computer); Wrist Joint; X-Ray Film; adolescent; algorithm; artificial intelligence; artificial neural network; Asian continental ancestry group; bone age determination; China; diagnostic imaging; ethnology; female; forensic medicine; human; image processing; machine learning; male; pathology; procedures; wrist; X ray film","Journal of Forensic Medicine","10045619","","","29577701","Article","Scopus","2-s2.0-85047949578"
"Lakhani P.; Prater A.B.; Hutson R.K.; Andriole K.P.; Dreyer K.J.; Morey J.; Prevedello L.M.; Clark T.J.; Geis J.R.; Itri J.N.; Hawkins C.M.","Lakhani, Paras (8763051900); Prater, Adam B. (35741725700); Hutson, R. Kent (57225820139); Andriole, Kathy P. (7004435253); Dreyer, Keith J. (7006172475); Morey, Jose (56054061300); Prevedello, Luciano M. (25641974000); Clark, Toshi J. (56883716800); Geis, J. Raymond (6602850280); Itri, Jason N. (36974023300); Hawkins, C. Matthew (24335283800)","8763051900; 35741725700; 57225820139; 7004435253; 7006172475; 56054061300; 25641974000; 56883716800; 6602850280; 36974023300; 24335283800","Machine Learning in Radiology: Applications Beyond Image Interpretation","2018","Journal of the American College of Radiology","159","10.1016/j.jacr.2017.09.044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034062256&doi=10.1016%2fj.jacr.2017.09.044&partnerID=40&md5=cde8be6761f6b789a876176869a06a11","Department of Radiology, Thomas Jefferson University Hospital, Sidney Kimmel Jefferson Medical College, Philadelphia, PA, United States; Department of Radiology and Imaging Sciences, Emory University School of Medicine, Atlanta, United States; Radiology Alliance, Colorado Springs, CO, United States; Department of Radiology, Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States; Department of Radiology, Massachusetts General Hospital, Harvard Medical School Boston, MA, United States; I.B.M. Watson Research, Yorktown Heights, New York, United States; Department of Radiology, University of Virginia, Charlottesville, VA, United States; Medical Center Radiologists, Virginia Beach, VA, United States; Department of Radiology, Ohio State University Medical Center, Columbus, OH, United States; University of Colorado Medical Center, Denver, CO, United States","Lakhani P., Department of Radiology, Thomas Jefferson University Hospital, Sidney Kimmel Jefferson Medical College, Philadelphia, PA, United States; Prater A.B., Department of Radiology and Imaging Sciences, Emory University School of Medicine, Atlanta, United States; Hutson R.K., Radiology Alliance, Colorado Springs, CO, United States, Medical Center Radiologists, Virginia Beach, VA, United States; Andriole K.P., Department of Radiology, Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States; Dreyer K.J., Department of Radiology, Massachusetts General Hospital, Harvard Medical School Boston, MA, United States; Morey J., I.B.M. Watson Research, Yorktown Heights, New York, United States, Department of Radiology, University of Virginia, Charlottesville, VA, United States, Medical Center Radiologists, Virginia Beach, VA, United States; Prevedello L.M., Department of Radiology, Ohio State University Medical Center, Columbus, OH, United States; Clark T.J., University of Colorado Medical Center, Denver, CO, United States; Geis J.R., University of Colorado Medical Center, Denver, CO, United States; Itri J.N., Department of Radiology, University of Virginia, Charlottesville, VA, United States; Hawkins C.M., Department of Radiology and Imaging Sciences, Emory University School of Medicine, Atlanta, United States","Much attention has been given to machine learning and its perceived impact in radiology, particularly in light of recent success with image classification in international competitions. However, machine learning is likely to impact radiology outside of image interpretation long before a fully functional “machine radiologist” is implemented in practice. Here, we describe an overview of machine learning, its application to radiology and other domains, and many cases of use that do not involve image interpretation. We hope that better understanding of these potential applications will help radiology practices prepare for the future and realize performance improvement and efficiency gains. © 2017 American College of Radiology","Artificial intelligence; deep learning; machine learning; radiology; workflows","Algorithms; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Machine Learning; Pattern Recognition, Automated; Radiology; Workflow; artificial intelligence; human; machine learning; radiology; workflow; algorithm; automated pattern recognition; computer assisted diagnosis; image enhancement; procedures; workflow","Elsevier B.V.","15461440","","","29158061","Article","Scopus","2-s2.0-85034062256"
"Erickson B.J.; Korfiatis P.; Kline T.L.; Akkus Z.; Philbrick K.; Weston A.D.","Erickson, Bradley J. (7201472755); Korfiatis, Panagiotis (23397073600); Kline, Timothy L. (26648884000); Akkus, Zeynettin (41560908300); Philbrick, Kenneth (25959278600); Weston, Alexander D. (57200394792)","7201472755; 23397073600; 26648884000; 41560908300; 25959278600; 57200394792","Deep Learning in Radiology: Does One Size Fit All?","2018","Journal of the American College of Radiology","102","10.1016/j.jacr.2017.12.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041133227&doi=10.1016%2fj.jacr.2017.12.027&partnerID=40&md5=e2eb7351eb33a3d4e832d6011c503b6b","Radiology Informatics Laboratory, Department of Radiology, Mayo Clinic, Rochester, Minnesota, United States","Erickson B.J., Radiology Informatics Laboratory, Department of Radiology, Mayo Clinic, Rochester, Minnesota, United States; Korfiatis P., Radiology Informatics Laboratory, Department of Radiology, Mayo Clinic, Rochester, Minnesota, United States; Kline T.L., Radiology Informatics Laboratory, Department of Radiology, Mayo Clinic, Rochester, Minnesota, United States; Akkus Z., Radiology Informatics Laboratory, Department of Radiology, Mayo Clinic, Rochester, Minnesota, United States; Philbrick K., Radiology Informatics Laboratory, Department of Radiology, Mayo Clinic, Rochester, Minnesota, United States; Weston A.D., Radiology Informatics Laboratory, Department of Radiology, Mayo Clinic, Rochester, Minnesota, United States","Deep learning (DL) is a popular method that is used to perform many important tasks in radiology and medical imaging. Some forms of DL are able to accurately segment organs (essentially, trace the boundaries, enabling volume measurements or calculation of other properties). Other DL networks are able to predict important properties from regions of an image—for instance, whether something is malignant, molecular markers for tissue in a region, even prognostic markers. DL is easier to train than traditional machine learning methods, but requires more data and much more care in analyzing results. It will automatically find the features of importance, but understanding what those features are can be a challenge. This article describes the basic concepts of DL systems and some of the traps that exist in building DL systems and how to identify those traps. © 2018 American College of Radiology","computer-aided diagnosis; Deep learning; machine learning","Deep Learning; Diagnosis, Computer-Assisted; Humans; Machine Learning; Radiology; article; calculation; diagnostic imaging; genetic marker; human; machine learning; radiology; computer assisted diagnosis; machine learning; procedures; radiology","Elsevier B.V.","15461440","","","29396120","Article","Scopus","2-s2.0-85041133227"
"Baxter J.S.H.; Gibson E.; Eagleson R.; Peters T.M.","Baxter, John S.H. (38561011800); Gibson, Eli (36026807300); Eagleson, Roy (6603343533); Peters, Terry M. (7402962614)","38561011800; 36026807300; 6603343533; 7402962614","The semiotics of medical image Segmentation","2018","Medical Image Analysis","24","10.1016/j.media.2017.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034959542&doi=10.1016%2fj.media.2017.11.007&partnerID=40&md5=4a6653d1493c845f1f0f26feb9830459","Robarts Research Institute, London, Ontario, Canada; Western University, London, Ontario, Canada; University College, London, United Kingdom","Baxter J.S.H., Robarts Research Institute, London, Ontario, Canada, Western University, London, Ontario, Canada; Gibson E., University College, London, United Kingdom; Eagleson R., Western University, London, Ontario, Canada; Peters T.M., Robarts Research Institute, London, Ontario, Canada, Western University, London, Ontario, Canada","As the interaction between clinicians and computational processes increases in complexity, more nuanced mechanisms are required to describe how their communication is mediated. Medical image segmentation in particular affords a large number of distinct loci for interaction which can act on a deep, knowledge-driven level which complicates the naive interpretation of the computer as a symbol processing machine. Using the perspective of the computer as dialogue partner, we can motivate the semiotic understanding of medical image segmentation. Taking advantage of Peircean semiotic traditions and new philosophical inquiry into the structure and quality of metaphors, we can construct a unified framework for the interpretation of medical image segmentation as a sign exchange in which each sign acts as an interface metaphor. This allows for a notion of finite semiosis, described through a schematic medium, that can rigorously describe how clinicians and computers interpret the signs mediating their interaction. Altogether, this framework provides a unified approach to the understanding and development of medical image segmentation interfaces. © 2017 Elsevier B.V.","Human computer interaction; Interface metaphors; Medical image segmentation; Peircean semiotics","Algorithms; Image Processing, Computer-Assisted; Machine Learning; Models, Theoretical; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Systems Integration; User-Computer Interface; Human computer interaction; Image segmentation; Medical imaging; Philosophical aspects; Semiotics; Computational process; Interface metaphor; Processing machines; Semiosis; Unified approach; Unified framework; algorithm; Article; brain computer interface; diagnostic imaging; human; human computer interaction; image processing; image segmentation; pattern recognition; priority journal; software; taxonomy; algorithm; automated pattern recognition; computer interface; image processing; machine learning; procedures; reproducibility; sensitivity and specificity; system analysis; theoretical model; Medical image processing","Elsevier B.V.","13618415","","MIAEC","29190576","Article","Scopus","2-s2.0-85034959542"
"Kharazmi P.; Zheng J.; Lui H.; Jane Wang Z.; Lee T.K.","Kharazmi, Pegah (56152735100); Zheng, Jiannan (56645279900); Lui, Harvey (7006856360); Jane Wang, Z. (16068404100); Lee, Tim K. (55560463300)","56152735100; 56645279900; 7006856360; 16068404100; 55560463300","A Computer-Aided Decision Support System for Detection and Localization of Cutaneous Vasculature in Dermoscopy Images Via Deep Feature Learning","2018","Journal of Medical Systems","30","10.1007/s10916-017-0885-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040375669&doi=10.1007%2fs10916-017-0885-2&partnerID=40&md5=f9d6c38fc7dc3a300d466a2efbcfb683","Biomedical Engineering Program, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Dermatology and Skin Science, University of British Columbia, Vancouver, BC, Canada; Departments of Cancer Control Research and Integrative Oncology, British Columbia Cancer Agency, Vancouver, BC, Canada","Kharazmi P., Biomedical Engineering Program, University of British Columbia, Vancouver, BC, Canada; Zheng J., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Lui H., Department of Dermatology and Skin Science, University of British Columbia, Vancouver, BC, Canada, Departments of Cancer Control Research and Integrative Oncology, British Columbia Cancer Agency, Vancouver, BC, Canada; Jane Wang Z., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Lee T.K., Biomedical Engineering Program, University of British Columbia, Vancouver, BC, Canada, Department of Dermatology and Skin Science, University of British Columbia, Vancouver, BC, Canada, Departments of Cancer Control Research and Integrative Oncology, British Columbia Cancer Agency, Vancouver, BC, Canada","Vascular structures of skin are important biomarkers in diagnosis and assessment of cutaneous conditions. Presence and distribution of lesional vessels are associated with specific abnormalities. Therefore, detection and localization of cutaneous vessels provide critical information towards diagnosis and stage status of diseases. However, cutaneous vessels are highly variable in shape, size, color and architecture, which complicate the detection task. Considering the large variability of these structures, conventional vessel detection techniques lack the generalizability to detect different vessel types and require separate algorithms to be designed for each type. Furthermore, such techniques are highly dependent on precise hand-crafted features which are time-consuming and computationally inefficient. As a solution, we propose a data-driven feature learning framework based on stacked sparse auto-encoders (SSAE) for comprehensive detection of cutaneous vessels. Each training image is divided into small patches of either containing or non-containing vasculature. A multilayer SSAE is designed to learn hidden features of the data in hierarchical layers in an unsupervised manner. The high-level learned features are subsequently fed into a classifier which categorizes each patch into absence or presence of vasculature and localizes vessels within the lesion. Over a test set of 3095 patches derived from 200 images, the proposed framework demonstrated superior performance of 95.4% detection accuracy over a variety of vessel patterns; outperforming other techniques by achieving the highest positive predictive value of 94.7%. The proposed Computer-Aided Diagnosis (CAD) framework can serve as a decision support system assisting dermatologists for more accurate diagnosis, especially in teledermatology applications in remote areas. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Automated skin vessel detection; Deep learning; Dermoscopy; Stacked sparse autoencoders","Biomarkers; Dermoscopy; Diagnosis, Computer-Assisted; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Pattern Recognition, Automated; Skin; hemoglobin; melanin; biological marker; Article; computer aided design; controlled study; decision support system; deep feature learning; differential diagnosis; epiluminescence microscopy; erythema; human; learning algorithm; predictive value; skin blood vessel; skin color; automated pattern recognition; computer assisted diagnosis; diagnostic imaging; epiluminescence microscopy; machine learning; procedures; skin; vascularization","Springer New York LLC","01485598","","JMSYD","29318397","Article","Scopus","2-s2.0-85040375669"
"Li Y.; Jiang W.; Yang L.; Wu T.","Li, Yawen (53982966700); Jiang, Weifeng (57195952530); Yang, Liu (57776881200); Wu, Tian (57190745271)","53982966700; 57195952530; 57776881200; 57190745271","On neural networks and learning systems for business computing","2018","Neurocomputing","55","10.1016/j.neucom.2017.09.054","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030479313&doi=10.1016%2fj.neucom.2017.09.054&partnerID=40&md5=573c1a494944ea0050e228ef5f262719","School of Economics and Management, Tsinghua University, China, China; Department of Computer Science and Technology, Tsinghua University, China, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Academy of Mathematics and Systems Sciences, Chinese Academy of Sciences, China, China; School of Economics and Management, University of Chinese Academy of Sciences, China, China; Key Laboratory of Big Data Mining and Knowledge Management, Chinese Academy of Sciences, China, China","Li Y., School of Economics and Management, Tsinghua University, China, China; Jiang W., Department of Computer Science and Technology, Tsinghua University, China, China; Yang L., Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Wu T., Academy of Mathematics and Systems Sciences, Chinese Academy of Sciences, China, China, School of Economics and Management, University of Chinese Academy of Sciences, China, China, Key Laboratory of Big Data Mining and Knowledge Management, Chinese Academy of Sciences, China, China","Artificial intelligence, including neural networks, deep learning and machine learning, has made numerous progress and offered new opportunity for academic research and applications in many fields, especially for business activities and firm development. This paper summarizes different applications of artificial intelligence technologies in several domains of business administration. Finance, retail industry, manufacturing industry, and enterprise management are all included. In spite of all the existing challenges, we conclude that the rapid development of artificial intelligence will show its great impact on more fields. © 2017 Elsevier B.V.","Business activities; Deep learning; Machine learning; Neural networks","Artificial intelligence; Learning systems; Neural networks; Academic research; Artificial intelligence technologies; Business activities; Business administration; Business computing; Enterprise management; Manufacturing industries; Retail industry; Article; artificial intelligence; artificial neural network; commercial phenomena; economic development; industry; learning; manufacturing industry; mathematical computing; perceptron; priority journal; technology; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85030479313"
"Wang S.; Sun S.; Xu J.","Wang, Sheng (58428221300); Sun, Siqi (57056718200); Xu, Jinbo (57203521425)","58428221300; 57056718200; 57203521425","Analysis of deep learning methods for blind protein contact prediction in CASP12","2018","Proteins: Structure, Function and Bioinformatics","70","10.1002/prot.25377","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028918361&doi=10.1002%2fprot.25377&partnerID=40&md5=ac07f5df59dd9567b98b926a69a7db07","Toyota Technological Institute at Chicago, Chicago, IL, United States","Wang S., Toyota Technological Institute at Chicago, Chicago, IL, United States; Sun S., Toyota Technological Institute at Chicago, Chicago, IL, United States; Xu J., Toyota Technological Institute at Chicago, Chicago, IL, United States","Here we present the results of protein contact prediction achieved in CASP12 by our RaptorX-Contact server, which is an early implementation of our deep learning method for contact prediction. On a set of 38 free-modeling target domains with a median family size of around 58 effective sequences, our server obtained an average top L/5 long- and medium-range contact accuracy of 47% and 44%, respectively (L = length). A complete implementation has an average accuracy of 59% and 57%, respectively. Our deep learning method formulates contact prediction as a pixel-level image labeling problem and simultaneously predicts all residue pairs of a protein using a combination of two deep residual neural networks, taking as input the residue conservation information, predicted secondary structure and solvent accessibility, contact potential, and coevolution information. Our approach differs from existing methods mainly in (1) formulating contact prediction as a pixel-level image labeling problem instead of an image-level classification problem; (2) simultaneously predicting all contacts of an individual protein to make effective use of contact occurrence patterns; and (3) integrating both one-dimensional and two-dimensional deep convolutional neural networks to effectively learn complex sequence-structure relationship including high-order residue correlation. This paper discusses the RaptorX-Contact pipeline, both contact prediction and contact-based folding results, and finally the strength and weakness of our method. © 2017 Wiley Periodicals, Inc.","CASP; coevolution analysis; deep learning; protein contact prediction; protein folding","Algorithms; Computational Biology; Crystallography, X-Ray; Deep Learning; Humans; Models, Molecular; Neural Networks (Computer); Protein Conformation; Protein Folding; Proteins; Software; protein; accuracy; amino acid sequence; Article; artificial neural network; Baker GREMLIN method; Baker human method; Baker server method; CCMpred method; classification; computer prediction; contact prediction; correlational study; deep learning method; image analysis; information processing; machine learning; MetaPSICOV standalone method; MetaPSICOV submit method; priority journal; protein analysis; protein domain; protein folding; protein secondary structure; protein structure; RaptorX postdict method; RaptorX rebuild method; RaptorX submit method; RaptorX TBM method; software; Zhang human method; Zhang server method; algorithm; artificial neural network; biology; chemistry; human; molecular model; procedures; protein conformation; protein folding; X ray crystallography","John Wiley and Sons Inc.","08873585","","","28845538","Article","Scopus","2-s2.0-85028918361"
"Schlemper J.; Caballero J.; Hajnal J.V.; Price A.N.; Rueckert D.","Schlemper, Jo (57194525872); Caballero, Jose (56410493800); Hajnal, Joseph V. (35430060900); Price, Anthony N. (35335108200); Rueckert, Daniel (7004895812)","57194525872; 56410493800; 35430060900; 35335108200; 7004895812","A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction","2018","IEEE Transactions on Medical Imaging","821","10.1109/TMI.2017.2760978","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041890026&doi=10.1109%2fTMI.2017.2760978&partnerID=40&md5=0b2f01583929255d286b7a90133008e2","Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Biomedical Engineering Department, Division of Imaging Sciences, King's College London, London, SE1 7EH, United Kingdom","Schlemper J., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Caballero J., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Hajnal J.V., Biomedical Engineering Department, Division of Imaging Sciences, King's College London, London, SE1 7EH, United Kingdom; Price A.N., Biomedical Engineering Department, Division of Imaging Sciences, King's College London, London, SE1 7EH, United Kingdom; Rueckert D., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom","Inspired by recent advances in deep learning, we propose a framework for reconstructing dynamic sequences of 2-D cardiac magnetic resonance (MR) images from undersampled data using a deep cascade of convolutional neural networks (CNNs) to accelerate the data acquisition process. In particular, we address the case where data are acquired using aggressive Cartesian undersampling. First, we show that when each 2-D image frame is reconstructed independently, the proposed method outperforms state-of-the-art 2-D compressed sensing approaches, such as dictionary learning-based MR image reconstruction, in terms of reconstruction error and reconstruction speed. Second, when reconstructing the frames of the sequences jointly, we demonstrate that CNNs can learn spatio-temporal correlations efficiently by combining convolution and data sharing approaches. We show that the proposed method consistently outperforms state-of-the-art methods and is capable of preserving anatomical structure more faithfully up to 11-fold undersampling. Moreover, reconstruction is very fast: each complete dynamic sequence can be reconstructed in less than 10 s and, for the 2-D case, each image frame can be reconstructed in 23 ms, enabling real-time applications. © 2018 IEEE.","compressed sensing; convolutional neural network; Deep learning; dynamic magnetic resonance imaging; image reconstruction","Algorithms; Databases, Factual; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging, Cine; Neural Networks (Computer); Compressed sensing; Convolution; Data acquisition; Deep learning; Imaging techniques; Learning systems; Magnetic resonance imaging; Neural networks; Redundancy; Anatomical structures; Cardiac magnetic resonance images; Convolutional neural network; Dynamic magnetic resonance imaging; Real-time application; Spatiotemporal correlation; State-of-the-art methods; Two-dimensional displays; image reconstruction; machine learning; nervous system; nuclear magnetic resonance imaging; velocity; algorithm; artificial neural network; cine magnetic resonance imaging; diagnostic imaging; factual database; heart; human; image processing; procedures; Image reconstruction","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29035212","Article","Scopus","2-s2.0-85041890026"
"Rigla M.; García-Sáez G.; Pons B.; Hernando M.E.","Rigla, Mercedes (6603627533); García-Sáez, Gema (24179398500); Pons, Belén (24178287000); Hernando, Maria Elena (7004989922)","6603627533; 24179398500; 24178287000; 7004989922","Artificial Intelligence Methodologies and Their Application to Diabetes","2018","Journal of Diabetes Science and Technology","75","10.1177/1932296817710475","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035021972&doi=10.1177%2f1932296817710475&partnerID=40&md5=9bcbe4faecb9160fc0d31549cba108e9","Endocrinology and Nutrition Department, Parc Tauli University Hospital, Sabadell, Spain; Bioengineering and Telemedicine Centre, Universidad Politécnica de Madrid, Spain; CIBER-BBN: Networking Research Centre for Bioengineering, Biomaterials and Nanomedicine, Madrid, Spain","Rigla M., Endocrinology and Nutrition Department, Parc Tauli University Hospital, Sabadell, Spain; García-Sáez G., Bioengineering and Telemedicine Centre, Universidad Politécnica de Madrid, Spain, CIBER-BBN: Networking Research Centre for Bioengineering, Biomaterials and Nanomedicine, Madrid, Spain; Pons B., Endocrinology and Nutrition Department, Parc Tauli University Hospital, Sabadell, Spain; Hernando M.E., Bioengineering and Telemedicine Centre, Universidad Politécnica de Madrid, Spain, CIBER-BBN: Networking Research Centre for Bioengineering, Biomaterials and Nanomedicine, Madrid, Spain","In the past decade diabetes management has been transformed by the addition of continuous glucose monitoring and insulin pump data. More recently, a wide variety of functions and physiologic variables, such as heart rate, hours of sleep, number of steps walked and movement, have been available through wristbands or watches. New data, hydration, geolocation, and barometric pressure, among others, will be incorporated in the future. All these parameters, when analyzed, can be helpful for patients and doctors’ decision support. Similar new scenarios have appeared in most medical fields, in such a way that in recent years, there has been an increased interest in the development and application of the methods of artificial intelligence (AI) to decision support and knowledge acquisition. Multidisciplinary research teams integrated by computer engineers and doctors are more and more frequent, mirroring the need of cooperation in this new topic. AI, as a science, can be defined as the ability to make computers do things that would require intelligence if done by humans. Increasingly, diabetes-related journals have been incorporating publications focused on AI tools applied to diabetes. In summary, diabetes management scenarios have suffered a deep transformation that forces diabetologists to incorporate skills from new areas. This recently needed knowledge includes AI tools, which have become part of the diabetes health care. The aim of this article is to explain in an easy and plane way the most used AI methodologies to promote the implication of health care providers—doctors and nurses—in this field. © 2017, © 2017 Diabetes Technology Society.","artificial intelligence; decision support; diabetes; machine learning","Artificial Intelligence; Decision Support Systems, Clinical; Diabetes Mellitus; Humans; Machine Learning; Article; artificial intelligence; blood glucose monitoring; decision support system; diabetes mellitus; expert system; glucose blood level; health care; heart rate; human; hydration; interdisciplinary research; learning; machine learning; retinopathy; clinical decision support system; machine learning","SAGE Publications Inc.","19322968","","","28539087","Article","Scopus","2-s2.0-85035021972"
"Kamalanaban E.; Gopinath M.; Premkumar S.","Kamalanaban, E. (56565509500); Gopinath, M. (57215916076); Premkumar, S. (57215917195)","56565509500; 57215916076; 57215917195","Medicine box: Doctor's prescription recognition using deep machine learning","2018","International Journal of Engineering and Technology(UAE)","11","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082367351&partnerID=40&md5=6ed637ca47c94cec07a101364bf2fdf6","Department of Computer Science and Engineering, Vel Tech High Tech Dr.Rangarajan Dr.Sakunthala Engineering College, Avadi, Chennai, 600062, India; Department of Information Techonology, Vel Tech High Tech Dr.Rangarajan Dr.Sakunthala Engineering College, Avadi, Chennai, 600062, India; Vel Tech High Tech Dr.Rangarajan Dr.Sakunthala Engineering College, Avadi, Chennai, 600062, India","Kamalanaban E., Department of Computer Science and Engineering, Vel Tech High Tech Dr.Rangarajan Dr.Sakunthala Engineering College, Avadi, Chennai, 600062, India; Gopinath M., Department of Information Techonology, Vel Tech High Tech Dr.Rangarajan Dr.Sakunthala Engineering College, Avadi, Chennai, 600062, India; Premkumar S., Vel Tech High Tech Dr.Rangarajan Dr.Sakunthala Engineering College, Avadi, Chennai, 600062, India","A Doctor's prescription is a handwritten document written by doctors in the form of instructions that describes list of drugs for patients in time sickness, injuries and other disability problems. While we receiving a new prescription from doctor, it is unable to understand what drug name is prescribed on it. In most cases, however, we wouldn't be able to read it anyway because doctors use Latin abbreviations and medical terminologies on prescriptions that are not understandable by the general persons which make reading it very difficult. According to the National Academy of Sciences estimates that at least 1.5 million peoples are sickened, injured or killed each year by errors while reading prescription. This paper resolves the problems in doctor?s prescriptions through Medicine Box, and Smart phone application that uses Conventional Neural Network (CNN) to recognize handwritten medicine names and return readable digital text. This mobile application uses TensorFlow as the machine learning library, and Custom Repository to match the partial string with the drug name. With Medicine Box, cases of misinterpretation of medicine names can be decreased. This makes the ordinary persons to understand what doctor is prescribed in the prescription and also help for pharmacists. © 2018 Authors.","Conventional Neural Network (CNN); Histogram; Recurrent Neural Network (RNN); Smart phone application; Tensorflow","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082367351"
"Chen M.C.; Ball R.L.; Yang L.; Moradzadeh N.; Chapman B.E.; Larson D.B.; Langlotz C.P.; Amrhein T.J.; Lungren M.P.","Chen, Matthew C. (57197876745); Ball, Robyn L. (57194281693); Yang, Lingyao (57200789321); Moradzadeh, Nathaniel (57192109622); Chapman, Brian E. (7202837704); Larson, David (35725554000); Langlotz, Curtis P. (20134955200); Amrhein, Timothy J. (55480415900); Lungren, Matthew P. (36729660500)","57197876745; 57194281693; 57200789321; 57192109622; 7202837704; 35725554000; 20134955200; 55480415900; 36729660500","Deep learning to classify radiology free-text reports","2018","Radiology","145","10.1148/radiol.2017171115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042446924&doi=10.1148%2fradiol.2017171115&partnerID=40&md5=20f4a4ee145bab940fed486c64952a51","Department of Radiology, Stanford University School of Medicine, Stanford University Medical Center, 725 Welch Rd, Stanford, 94305-5913, CA, United States; Stanford Center for Biomedical Informatics Research, Stanford University, Stanford, CA, United States; Department of Bioinformat-ics, University of Utah Medical Center, Salt Lake City, UT, United States; Department of Radiology, Duke University Medical Center, Durham, NC, United States","Chen M.C., Department of Radiology, Stanford University School of Medicine, Stanford University Medical Center, 725 Welch Rd, Stanford, 94305-5913, CA, United States; Ball R.L., Stanford Center for Biomedical Informatics Research, Stanford University, Stanford, CA, United States; Yang L., Stanford Center for Biomedical Informatics Research, Stanford University, Stanford, CA, United States; Moradzadeh N., Department of Radiology, Stanford University School of Medicine, Stanford University Medical Center, 725 Welch Rd, Stanford, 94305-5913, CA, United States; Chapman B.E., Department of Bioinformat-ics, University of Utah Medical Center, Salt Lake City, UT, United States; Larson D.B., Department of Radiology, Stanford University School of Medicine, Stanford University Medical Center, 725 Welch Rd, Stanford, 94305-5913, CA, United States; Langlotz C.P., Department of Radiology, Stanford University School of Medicine, Stanford University Medical Center, 725 Welch Rd, Stanford, 94305-5913, CA, United States; Amrhein T.J., Department of Radiology, Duke University Medical Center, Durham, NC, United States; Lungren M.P., Department of Radiology, Stanford University School of Medicine, Stanford University Medical Center, 725 Welch Rd, Stanford, 94305-5913, CA, United States","Purpose: To evaluate the performance of a deep learning convolutional neural network (CNN) model compared with a traditional natural language processing (NLP) model in extracting pulmonary embolism (PE) findings from thoracic computed tomography (CT) reports from two institutions. Materials and Contrast material-enhanced CT examinations of the Methods: chest performed between January 1, 1998, and January 1, 2016, were selected. Annotations by two human radiologists were made for three categories: the presence, chronicity, and location of PE. Classification of performance of a CNN model with an unsupervised learning algorithm for obtaining vector representations of words was compared with the open-source application PeFinder. Sensitivity, specificity, accuracy, and F1 scores for both the CNN model and PeFinder in the internal and external validation sets were determined. Results: The CNN model demonstrated an accuracy of 99% and an area under the curve value of 0.97. For internal validation report data, the CNN model had a statistically significant larger F1 score (0.938) than did PeFinder (0.867) when classifying findings as either PE positive or PE negative, but no significant difference in sensitivity, specificity, or accuracy was found. For external validation report data, no statistical difference between the performance of the CNN model and PeFinder was found. Conclusion: A deep learning CNN model can classify radiology free-text reports with accuracy equivalent to or beyond that of an existing traditional NLP model. © RSNA, 2017.","","Algorithms; Humans; Machine Learning; Natural Language Processing; Neural Networks (Computer); Pulmonary Embolism; Radiography, Thoracic; Reproducibility of Results; ROC Curve; Sensitivity and Specificity; Tomography, X-Ray Computed; area under the curve; Article; artificial neural network; computer assisted tomography; contrast enhancement; controlled study; deep learning convolutional neural network; diagnostic accuracy; external validity; human; internal validity; interrater reliability; learning algorithm; lung embolism; measurement precision; natural language processing; priority journal; scoring system; sensitivity and specificity; unsupervised learning algorithm; algorithm; clinical trial; comparative study; diagnostic imaging; evaluation study; lung embolism; machine learning; multicenter study; procedures; receiver operating characteristic; reproducibility; thorax radiography; x-ray computed tomography","Radiological Society of North America Inc.","00338419","","RADLA","29135365","Article","Scopus","2-s2.0-85042446924"
"Chao H.; Zhi H.; Dong L.; Liu Y.","Chao, Hao (57191590444); Zhi, Huilai (35801572500); Dong, Liang (57204574034); Liu, Yongli (24802382300)","57191590444; 35801572500; 57204574034; 24802382300","Recognition of Emotions Using Multichannel EEG Data and DBN-GC-Based Ensemble Deep Learning Framework","2018","Computational Intelligence and Neuroscience","52","10.1155/2018/9750904","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059872461&doi=10.1155%2f2018%2f9750904&partnerID=40&md5=115073c48b52201ec6bd9f1a5fa44419","School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China","Chao H., School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China; Zhi H., School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China; Dong L., School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China; Liu Y., School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China","Fusing multichannel neurophysiological signals to recognize human emotion states becomes increasingly attractive. The conventional methods ignore the complementarity between time domain characteristics, frequency domain characteristics, and time-frequency characteristics of electroencephalogram (EEG) signals and cannot fully capture the correlation information between different channels. In this paper, an integrated deep learning framework based on improved deep belief networks with glia chains (DBN-GCs) is proposed. In the framework, the member DBN-GCs are employed for extracting intermediate representations of EEG raw features from multiple domains separately, as well as mining interchannel correlation information by glia chains. Then, the higher level features describing time domain characteristics, frequency domain characteristics, and time-frequency characteristics are fused by a discriminative restricted Boltzmann machine (RBM) to implement emotion recognition task. Experiments conducted on the DEAP benchmarking dataset achieve averaged accuracy of 75.92% and 76.83% for arousal and valence states classification, respectively. The results show that the proposed framework outperforms most of the above deep classifiers. Thus, potential of the proposed framework is demonstrated. © 2018 Hao Chao et al.","","Algorithms; Arousal; Deep Learning; Electroencephalography; Emotions; Humans; Support Vector Machine; Biomedical signal processing; Classification (of information); Electroencephalography; Frequency domain analysis; Time domain analysis; Deep belief networks; Electroencephalogram signals; Interchannel correlations; Intermediate representations; Recognition of emotion; Restricted boltzmann machine; Time domain characteristics; Time frequency characteristics; algorithm; arousal; electroencephalography; emotion; human; physiology; procedures; support vector machine; Deep learning","Hindawi Limited","16875265","","","30647727","Article","Scopus","2-s2.0-85059872461"
"Mayr A.; Klambauer G.; Unterthiner T.; Steijaert M.; Wegner J.K.; Ceulemans H.; Clevert D.-A.; Hochreiter S.","Mayr, Andreas (36509022000); Klambauer, Günter (6507603426); Unterthiner, Thomas (37078167900); Steijaert, Marvin (56829492400); Wegner, Jörg K. (57216675113); Ceulemans, Hugo (6603583751); Clevert, Djork-Arné (56653669800); Hochreiter, Sepp (6602873810)","36509022000; 6507603426; 37078167900; 56829492400; 57216675113; 6603583751; 56653669800; 6602873810","Large-scale comparison of machine learning methods for drug target prediction on ChEMBL","2018","Chemical Science","323","10.1039/c8sc00148k","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048973903&doi=10.1039%2fc8sc00148k&partnerID=40&md5=de4ef709cc76622d642ff1726879ef56","LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University Linz, Austria; Open Analytics NV, Belgium; Janssen Pharmaceutica NV, Belgium; Bayer AG, Germany","Mayr A., LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University Linz, Austria; Klambauer G., LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University Linz, Austria; Unterthiner T., LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University Linz, Austria; Steijaert M., Open Analytics NV, Belgium; Wegner J.K., Janssen Pharmaceutica NV, Belgium; Ceulemans H., Janssen Pharmaceutica NV, Belgium; Clevert D.-A., Bayer AG, Germany; Hochreiter S., LIT AI Lab and Institute of Bioinformatics, Johannes Kepler University Linz, Austria","Deep learning is currently the most successful machine learning technique in a wide range of application areas and has recently been applied successfully in drug discovery research to predict potential drug targets and to screen for active molecules. However, due to (1) the lack of large-scale studies, (2) the compound series bias that is characteristic of drug discovery datasets and (3) the hyperparameter selection bias that comes with the high number of potential deep learning architectures, it remains unclear whether deep learning can indeed outperform existing computational methods in drug discovery tasks. We therefore assessed the performance of several deep learning methods on a large-scale drug discovery dataset and compared the results with those of other machine learning and target prediction methods. To avoid potential biases from hyperparameter selection or compound series, we used a nested cluster-cross-validation strategy. We found (1) that deep learning methods significantly outperform all competing methods and (2) that the predictive performance of deep learning is in many cases comparable to that of tests performed in wet labs (i.e., in vitro assays). © 2018 The Royal Society of Chemistry.","","Artificial intelligence; Forecasting; Drug discovery researches; Large-scale studies; Learning architectures; Machine learning methods; Machine learning techniques; Potential drug targets; Predictive performance; Target prediction; Deep learning","Royal Society of Chemistry","20416520","","CSHCC","","Article","Scopus","2-s2.0-85048973903"
"Wang H.; Zhao T.; Li L.C.; Pan H.; Liu W.; Gao H.; Han F.; Wang Y.; Qi Y.; Liang Z.","Wang, Huafeng (36783787700); Zhao, Tingting (57195772110); Li, Lihong Connie (57259581700); Pan, Haixia (55366540700); Liu, Wanquan (7407343628); Gao, Haoqi (57218118377); Han, Fangfang (36644083600); Wang, Yuehai (57194466632); Qi, Yifan (57204066604); Liang, Zhengrong (7402178394)","36783787700; 57195772110; 57259581700; 55366540700; 7407343628; 57218118377; 36644083600; 57194466632; 57204066604; 7402178394","A hybrid CNN feature model for pulmonary nodule malignancy risk differentiation","2018","Journal of X-Ray Science and Technology","53","10.3233/XST-17302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054395929&doi=10.3233%2fXST-17302&partnerID=40&md5=e11d78e567985d2f97c5ae955f15cdc2","North China University of Technology, School of Electrical Information, Beijing, 100000, China; School of Software Engineering, Beihang University, Beijing, China; Department of Engineering Science and Physics, City University of New York at CSI, Staten Island, NY, United States; Department of Biomedical, Northeast University, Shenyan, China; Department of Radiology, State University of New York at Stony Brook, NY, United States","Wang H., North China University of Technology, School of Electrical Information, Beijing, 100000, China, School of Software Engineering, Beihang University, Beijing, China; Zhao T., School of Software Engineering, Beihang University, Beijing, China; Li L.C., Department of Engineering Science and Physics, City University of New York at CSI, Staten Island, NY, United States; Pan H., School of Software Engineering, Beihang University, Beijing, China; Liu W., North China University of Technology, School of Electrical Information, Beijing, 100000, China; Gao H., School of Software Engineering, Beihang University, Beijing, China; Han F., Department of Biomedical, Northeast University, Shenyan, China; Wang Y., North China University of Technology, School of Electrical Information, Beijing, 100000, China; Qi Y., School of Software Engineering, Beihang University, Beijing, China; Liang Z., Department of Radiology, State University of New York at Stony Brook, NY, United States","The malignancy risk differentiation of pulmonary nodule is one of the most challenge tasks of computer-aided diagnosis (CADx). Most recently reported CADx methods or schemes based on texture and shape estimation have shown relatively satisfactory on differentiating the risk level of malignancy among the nodules detected in lung cancer screening. However, the existing CADx schemes tend to detect and analyze characteristics of pulmonary nodules from a statistical perspective according to local features only. Enlightened by the currently prevailing learning ability of convolutional neural network (CNN), which simulates human neural network for target recognition and our previously research on texture features, we present a hybrid model that takes into consideration of both global and local features for pulmonary nodule differentiation using the largest public database founded by the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI). By comparing three types of CNN models in which two of them were newly proposed by us, we observed that the multi-channel CNN model yielded the best discrimination in capacity of differentiating malignancy risk of the nodules based on the projection of distributions of extracted features. Moreover, CADx scheme using the new multi-channel CNN model outperformed our previously developed CADx scheme using the 3D texture feature analysis method, which increased the computed area under a receiver operating characteristic curve (AUC) from 0.9441 to 0.9702. © 2018 - IOS Press and the authors. All rights reserved.","computer-aided diagnosis (CADx); Convolutional neural network (CNN); deep learning; multi-channel CNN; pulmonary nodule differentiation; texture","Algorithms; Diagnosis, Computer-Assisted; Early Detection of Cancer; Humans; Lung; Lung Neoplasms; Machine Learning; Neural Networks (Computer); Risk; 3D modeling; Biological organs; Computer aided instruction; Computerized tomography; Convolution; Database systems; Deep learning; Neural networks; Positron emission tomography; Risk perception; Textures; Computeraided diagnoses (CADx); Convolutional neural network; Learning abilities; Lung cancer screening; Multi channel; Pulmonary nodules; Receiver operating characteristic curves; Risk differentiation; algorithm; artificial neural network; computer assisted diagnosis; diagnostic imaging; early cancer diagnosis; human; lung; lung tumor; machine learning; procedures; risk; Computer aided diagnosis","IOS Press","08953996","","JXSTE","29036877","Article","Scopus","2-s2.0-85054395929"
"Delforouzi A.; Pamarthi B.; Grzegorzek M.","Delforouzi, Ahmad (57203654998); Pamarthi, Bhargav (57204696101); Grzegorzek, Marcin (6504608152)","57203654998; 57204696101; 6504608152","Training-based methods for comparison of object detection methods for visual object tracking","2018","Sensors (Switzerland)","7","10.3390/s18113994","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056706031&doi=10.3390%2fs18113994&partnerID=40&md5=6b170622646d3ccf71f020afaec12d65","Research Group for Pattern Recognition, University of Siegen, Hölderlinstr. 3, Siegen, 57076, Germany","Delforouzi A., Research Group for Pattern Recognition, University of Siegen, Hölderlinstr. 3, Siegen, 57076, Germany; Pamarthi B., Research Group for Pattern Recognition, University of Siegen, Hölderlinstr. 3, Siegen, 57076, Germany; Grzegorzek M., Research Group for Pattern Recognition, University of Siegen, Hölderlinstr. 3, Siegen, 57076, Germany","Object tracking in challenging videos is a hot topic in machine vision. Recently, novel training-based detectors, especially using the powerful deep learning schemes, have been proposed to detect objects in still images. However, there is still a semantic gap between the object detectors and higher level applications like object tracking in videos. This paper presents a comparative study of outstanding learning-based object detectors such as ACF, Region-Based Convolutional Neural Network (RCNN), FastRCNN, FasterRCNN and You Only Look Once (YOLO) for object tracking. We use an online and offline training method for tracking. The online tracker trains the detectors with a generated synthetic set of images from the object of interest in the first frame. Then, the detectors detect the objects of interest in the next frames. The detector is updated online by using the detected objects from the last frames of the video. The offline tracker uses the detector for object detection in still images and then a tracker based on Kalman filter associates the objects among video frames. Our research is performed on a TLD dataset which contains challenging situations for tracking. Source codes and implementation details for the trackers are published to make both the reproduction of the results reported in this paper and the re-use and further development of the trackers for other researchers. The results demonstrate that ACF and YOLO trackers show more stability than the other trackers. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Kalman filter; Object detection; Object tracking; Online training","Cell proliferation; Deep learning; E-learning; Kalman filters; Neural networks; Object recognition; Semantics; Tracking (position); Comparative studies; Convolutional neural network; Learning schemes; Object detection method; Object Tracking; Off-line training; Online training; Visual object tracking; Object detection","MDPI AG","14248220","","","30453520","Article","Scopus","2-s2.0-85056706031"
"Reddy J.S.K.; Pereira C.","Reddy, J. Shashi Kiran (57194043045); Pereira, Contzen (9737909600)","57194043045; 9737909600","The emergence of mind as a quantum field phenomenon","2018","NeuroQuantology","2","10.14704/nq.2018.16.11.1846","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062816282&doi=10.14704%2fnq.2018.16.11.1846&partnerID=40&md5=d28c66e97097565b2077c491842e7cf2","Bangalore, 560064, India; Mumbai, India","Reddy J.S.K., Bangalore, 560064, India; Pereira C., Mumbai, India","A ‘field’ according to quantum pilot-wave theory (Bush 2015) and quantum field theory (QFT) (Griffiths 2009) when applied to the working of the universe is a fluid that is spread across the universe with a value taken in that space which can change in time. New observations in the fields of quantum fluid mechanics, artificial intelligence (AI) and deep learning in machines are providing us novel insights into how quantum processing, memory creation and storage work using the laws that governs the quantum world and quantum field theories. Such an understanding can be extrapolated to the workings of the mind to see if similar processes underlie the functioning of living systems. This paper hypothesizes that the construct of the mind is the resultant of chaotic system of interacting subatomic fields driven by force fields that intersperse with the quantum vacuum; a mechanism which has not yet been fully understood. We propose that this integrated phenomenon also gives rise to the subtle mechanisms that help in the formation of memories and also the structures which store these memories as reservoirs. The future of our evolution is the mind which evolves in these boundless intermingling quantum fields and their force fields within the quantum vacuum. With computers getting intelligent we are instantaneously but naively evolving our minds, and in the future, working together with these intelligent machines will augment it further. In fact, the design and working of these AI systems are resultant of the proof of the intelligence of conscious mind. This way the working of mind is always superior to those of the artificial systems that emerge from it. © 2018, Anka Publishers. All rights reserved.","Artificial intelligence; Brain; Fields; Machine learning; Memory; Mind; Quantum biology; Quantum field theory; Quantum vacuum","action potential; Article; artificial intelligence; bioluminescence; biomechanics; cell differentiation; cell proliferation; chaotic dynamics; chemical interaction; deep learning; electrochemical detection; electroencephalography; electromagnetic radiation; electromagnetism; gene expression; genetic analysis; human; information processing; learning algorithm; machine learning; modulation; quantum mechanics; signal transduction","Anka Publishers","13035150","","","","Article","Scopus","2-s2.0-85062816282"
"Seymour B.; Mano H.; Kotecha G.; Leibnitz K.; Matsubara T.; Sprenger C.; Nakae A.; Shenker N.; Shibata M.; Voon V.; Yoshida W.; Lee M.; Yanagida T.; Kawato M.; Rosa M.J.","Seymour, Ben (8609317000); Mano, Hiroaki (56503230500); Kotecha, Gopal (56598580900); Leibnitz, Kenji (6603463737); Matsubara, Takashi (53863900700); Sprenger, Christian (10045603900); Nakae, Aya (16646657200); Shenker, Nicholas (6603040265); Shibata, Masahiko (35448606100); Voon, Valerie (8449219500); Yoshida, Wako (7006358579); Lee, Michael (55716898800); Yanagida, Toshio (7201744811); Kawato, Mitsuo (57192911319); Rosa, Maria Joao (34882137100)","8609317000; 56503230500; 56598580900; 6603463737; 53863900700; 10045603900; 16646657200; 6603040265; 35448606100; 8449219500; 7006358579; 55716898800; 7201744811; 57192911319; 34882137100","Classification and characterisation of brain network changes in chronic back pain: A multicenter study","2018","Wellcome Open Research","35","10.12688/wellcomeopenres.14069.2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058621841&doi=10.12688%2fwellcomeopenres.14069.2&partnerID=40&md5=39f0ce12c7e172109b08d9c51a2c92fd","Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan; Cambridge University Hospitals NHS Foundation Trust, Cambridge, United Kingdom; Graduate School of System Informatics, Kobe University, Kobe, Japan; Computational and Biological Learning Laboratory, Department of Engineering, University of Cambridge, Cambridge, United Kingdom; Osaka University School of Medicine, Osaka, Japan; Immunology Frontiers Research Center, Osaka University, Osaka, Japan; School of Clinical Medicine, University of Cambridge, Cambridge, United Kingdom; Advanced Telecommunications Research Center International, Kyoto, Japan; Max-Planck UCL Centre for Computational Psychiatry and Ageing Research, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom","Seymour B., Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan, Computational and Biological Learning Laboratory, Department of Engineering, University of Cambridge, Cambridge, United Kingdom, Immunology Frontiers Research Center, Osaka University, Osaka, Japan, Advanced Telecommunications Research Center International, Kyoto, Japan; Mano H., Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan; Kotecha G., Cambridge University Hospitals NHS Foundation Trust, Cambridge, United Kingdom; Leibnitz K., Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan; Matsubara T., Graduate School of System Informatics, Kobe University, Kobe, Japan; Sprenger C., Computational and Biological Learning Laboratory, Department of Engineering, University of Cambridge, Cambridge, United Kingdom; Nakae A., Osaka University School of Medicine, Osaka, Japan, Immunology Frontiers Research Center, Osaka University, Osaka, Japan; Shenker N., Cambridge University Hospitals NHS Foundation Trust, Cambridge, United Kingdom; Shibata M., Osaka University School of Medicine, Osaka, Japan; Voon V., School of Clinical Medicine, University of Cambridge, Cambridge, United Kingdom; Yoshida W., Advanced Telecommunications Research Center International, Kyoto, Japan; Lee M., School of Clinical Medicine, University of Cambridge, Cambridge, United Kingdom; Yanagida T., Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan; Kawato M., Advanced Telecommunications Research Center International, Kyoto, Japan; Rosa M.J., Max-Planck UCL Centre for Computational Psychiatry and Ageing Research, University College London, London, United Kingdom, Department of Computer Science, University College London, London, United Kingdom","Background. Chronic pain is a common, often disabling condition thought to involve a combination of peripheral and central neurobiological factors. However, the extent and nature of changes in the brain is poorly understood. Methods. We investigated brain network architecture using resting-state fMRI data in chronic back pain patients in the UK and Japan (41 patients, 56 controls), as well as open data from USA. We applied machine learning and deep learning (conditional variational autoencoder architecture) methods to explore classification of patients/controls based on network connectivity. We then studied the network topology of the data, and developed a multislice modularity method to look for consensus evidence of modular reorganisation in chronic back pain. Results. Machine learning and deep learning allowed reliable classification of patients in a third, independent open data set with an accuracy of 63%, with 68% in cross validation of all data. We identified robust evidence of network hub disruption in chronic pain, most consistently with respect to clustering coefficient and betweenness centrality. We found a consensus pattern of modular reorganisation involving extensive, bilateral regions of sensorimotor cortex, and characterised primarily by negative reorganisation - a tendency for sensorimotor cortex nodes to be less inclined to form pairwise modular links with other brain nodes. Furthermore, these regions were found to display increased connectivity with the pregenual anterior cingulate cortex, a region known to be involved in endogenous pain control. In contrast, intraparietal sulcus displayed a propensity towards positive modular reorganisation, suggesting that it might have a role in forming modules associated with the chronic pain state. Conclusion. The results provide evidence of consistent and characteristic brain network changes in chronic pain, characterised primarily by extensive reorganisation of the network architecture of the sensorimotor cortex. © 2018 Mano H et al.","Arthritis; Chronic pain; Connectomics; Deep learning; Endogenous modulation; Graph theory; Hub disruption; Multislice modularity; Nociception; Osteoarthritis; Rostral ACC; Sensorimotor","","F1000 Research Ltd","2398502X","","","","Article","Scopus","2-s2.0-85058621841"
"Fukaya E.; Flores A.M.; Lindholm D.; Gustafsson S.; Zanetti D.; Ingelsson E.; Leeper N.J.","Fukaya, Eri (16416487500); Flores, Alyssa M. (57202453361); Lindholm, Daniel (36700047500); Gustafsson, Stefan (55801204900); Zanetti, Daniela (56159634200); Ingelsson, Erik (6506552509); Leeper, Nicholas J. (55882699900)","16416487500; 57202453361; 36700047500; 55801204900; 56159634200; 6506552509; 55882699900","Clinical and genetic determinants of varicose veins: Prospective, community-based study of ≈500 000 individuals","2018","Circulation","87","10.1161/CIRCULATIONAHA.118.035584","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058892132&doi=10.1161%2fCIRCULATIONAHA.118.035584&partnerID=40&md5=e6e7dae70d2399ad14ec657fc7307bb9","Division of Vascular Surgery, Stanford University, School of Medicine, CA, United States; Division of Cardiovascular Medicine, Stanford University, School of Medicine, CA, United States; Department of Medical Sciences Cardiology, Uppsala University, Uppsala, Sweden; Department of Medical Sciences, Molecular Epidemiology and Science for Life Laboratory, Uppsala University, Uppsala, Sweden; Uppsala Clinical Research Center, Sweden; Stanford Cardiovascular Institute, CA, United States","Fukaya E., Division of Vascular Surgery, Stanford University, School of Medicine, CA, United States; Flores A.M., Division of Vascular Surgery, Stanford University, School of Medicine, CA, United States; Lindholm D., Department of Medical Sciences Cardiology, Uppsala University, Uppsala, Sweden, Uppsala Clinical Research Center, Sweden; Gustafsson S., Department of Medical Sciences, Molecular Epidemiology and Science for Life Laboratory, Uppsala University, Uppsala, Sweden; Zanetti D., Division of Cardiovascular Medicine, Stanford University, School of Medicine, CA, United States; Ingelsson E., Division of Cardiovascular Medicine, Stanford University, School of Medicine, CA, United States, Stanford Cardiovascular Institute, CA, United States; Leeper N.J., Division of Vascular Surgery, Stanford University, School of Medicine, CA, United States, Division of Cardiovascular Medicine, Stanford University, School of Medicine, CA, United States, Stanford Cardiovascular Institute, CA, United States","BACKGROUND: Varicose veins are a common problem with no approved medical therapies. Although it is believed that varicose vein pathogenesis is multifactorial, there is limited understanding of the genetic and environmental factors that contribute to their formation. Large-scale studies of risk factors for varicose veins may highlight important aspects of pathophysiology and identify groups at increased risk for disease. METHODS: We applied machine learning to agnostically search for risk factors of varicose veins in 493 519 individuals in the UK Biobank. Predictors were further studied with univariable and multivariable Cox regression analyses (2441 incident events). A genome-wide association study of varicose veins was also performed among 337 536 unrelated individuals (9577 cases) of white British descent, followed by expression quantitative loci and pathway analyses. Because height emerged as a new candidate risk factor, we performed mendelian randomization analyses to assess a potential causal role for height in varicose vein development. RESULTS: Machine learning confirmed several known (age, sex, obesity, pregnancy, history of deep vein thrombosis) and identified several new risk factors for varicose vein disease, including height. After adjustment for traditional risk factors in Cox regression, greater height remained independently associated with varicose veins (hazard ratio for upper versus lower quartile, 1.74; 95% CI, 1.51-2.01; P<0.0001). A genomewide association study identified 30 new genome-wide significant loci, identifying pathways involved in vascular development and skeletal/ limb biology. Mendelian randomization analysis provided evidence that increased height is causally related to varicose veins (inverse-variance weighted: Odds ratio, 1.26; P=2.07×10-16). CONCLUSIONS: Using data from nearly a half-million individuals, we present a comprehensive genetic and epidemiological study of varicose veins. We identified novel clinical and genetic risk factors that provide pathophysiological insights and could help future improvements of treatment of varicose vein disease. © 2018 American Heart Association, Inc.","Epidemiology; Genetics; Genome-wide association study; Varicose veins","Adult; Aged; Blood Vessels; Body Height; Bone and Bones; Cohort Studies; Female; Follow-Up Studies; Gene-Environment Interaction; Genetic Loci; Genome-Wide Association Study; Humans; Male; Mendelian Randomization Analysis; Middle Aged; Neovascularization, Pathologic; Proportional Hazards Models; Risk Factors; United Kingdom; Varicose Veins; adult; angiogenesis; Article; biobank; clinical outcome; decision tree; environmental factor; female; follow up; gene expression; genetic analysis; genetic correlation; genetic profile; genetic risk; genome-wide association study; heredity; human; lifestyle; machine learning; major clinical study; male; Mendelian randomization analysis; obesity; pathophysiology; phenotype; prediction; prevalence; priority journal; quantitative trait locus; questionnaire; risk factor; single nucleotide polymorphism; smoking; varicosis; aged; blood vessel; body height; bone; clinical trial; cohort analysis; gene locus; genetics; genotype environment interaction; middle aged; multicenter study; neovascularization (pathology); physiology; proportional hazards model; United Kingdom; varicosis","Lippincott Williams and Wilkins","00097322","","CIRCA","30566020","Article","Scopus","2-s2.0-85058892132"
"Yu L.; Sun X.; Tian S.; Shi X.; Yan Y.","Yu, Long (55272883600); Sun, Xia (57202683401); Tian, Shengwei (35119846500); Shi, Xinyu (57191409632); Yan, Yilin (57195054996)","55272883600; 57202683401; 35119846500; 57191409632; 57195054996","Drug and nondrug classification based on deep learning with various feature selection strategies","2018","Current Bioinformatics","58","10.2174/1574893612666170125124538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049011818&doi=10.2174%2f1574893612666170125124538&partnerID=40&md5=76ca4ce522b4b428945bec34f555d1ff","Network Center, Xinjiang University, Urumqi, 830046, China; School of Software, Xinjiang University, Urumqi, 830046, China","Yu L., Network Center, Xinjiang University, Urumqi, 830046, China; Sun X., School of Software, Xinjiang University, Urumqi, 830046, China; Tian S., School of Software, Xinjiang University, Urumqi, 830046, China; Shi X., School of Software, Xinjiang University, Urumqi, 830046, China; Yan Y., School of Software, Xinjiang University, Urumqi, 830046, China","Background: In the past decades, a number of methods are proposed for dealing with the classification of molecular data. Supervised ML methods such as linear discriminant analysis and decision trees were used to predict structural properties of molecules. Furthermore, logistic regression, Bayesian networks and artificial neural networks have been used to distinguish drugs and non-drugs. However, most of them can not hierarchically extract deep features. Objective: The feature extracted by the SAEs based model is useful for classification of molecules. Method: In this study, the model is a mix of deep learning architecture and softmax classifier. Firstly, the molecular data was preprocessed by the feature selection strategies. Secondly, the applicability of stacked auto-encoders was verified by information-based molecular classification. Then, another method of classifying based on multi-dimensional features was proposed. Finally, we proposed a new deep learning model, from which a higher classification accuracy could be gained. Results: The deep learning model AE mentioned above which is used to classify the data of molecule, and SAEs as the corresponding deep architecture have been practiced. Therefore, we combined the SAEs and softmax by taking the output of the last SAE as the input of softmax. That is, classifying drug and nondrug by using outstanding features can be learned from SAEs. Conclusion: Experimental results show that the performance of classifiers in this deep learning-based model is competitive. In addition, the proposition of joint multi-dimensional deep neural network is a breakthrough for future research. Also it presents the potential of deep learning-based methods on accurate drug and nondrug classification. © 2018 Bentham Science Publishers.","Auto-encoder (AE); Deep learning; Feature extraction; Molecular data classification; Softmax classifier; Stacked auto-encoder (SAE)","algorithm; Article; artificial neural network; calculation; classifier; drug classification; entropy; feature extraction; learning algorithm; machine learning; network learning; perceptron; priority journal","Bentham Science Publishers B.V.","15748936","","","","Article","Scopus","2-s2.0-85049011818"
"Weng Y.; Zheng K.; Sun G.","Weng, Yu (57206484920); Zheng, Kun (57072537200); Sun, Guangmin (8431278000)","57206484920; 57072537200; 8431278000","An optimization design for pedestrian detection based on deep learning","2018","IPPTA: Quarterly Journal of Indian Pulp and Paper Technical Association","2","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061742508&partnerID=40&md5=f51088f134f0a0780eb53562bbd92153","Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China","Weng Y., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; Zheng K., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; Sun G., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China","In the field of machine vision, deep learning has become a foremost method to perform target detection. Although suitable detection results have been published, the feasibility of using deep learning in practice to detect complex targets requires further research. This paper explores the use of the Faster R-CNN model for pedestrian detection. We design different network structures and study their effects to determine the optimal solution for pedestrian detection. We propose two methods to improve the effectiveness of detection for this application. Our optimization achieves a 5%-18% increase in the detection accuracy, reaching a rate of 88%. To optimize the detection area for a driving scenario, we include a speed factor for the target region of interest of the driver. We collected the areas of interest for 30 drivers and verified that the matching rate was 60%-70%. We propose two solutions for complex detection scenarios (involving rotation factors) and conduct comparative experiments. We use the post-rotation factor method to improve the detection accuracy by 6%. We thus explore the influence of different network structures on recognition performance and propose accuracy optimization methods for the application of pedestrian detection. © Indian Pulp and Paper Technical Association 2018. All rights reserved.","Deep Learning; Faster R-CNN; Pedestrian Detection","Accuracy; Application; Detection; Interest; Methods; Optimization; Rotation; Structures; Complex networks; Complexation; Image segmentation; Object recognition; Comparative experiments; Detection accuracy; Faster R-CNN; Network structures; Optimal solutions; Optimization design; Optimization method; Pedestrian detection; Deep learning","Indian Pulp and Paper Technical Association","03795462","","IPPTD","","Article","Scopus","2-s2.0-85061742508"
"Segal E.S.; Gritsenko V.; Levitan A.; Yadav B.; Dror N.; Steenwyk J.L.; Silberberg Y.; Mielich K.; Rokas A.; Gow N.A.R.; Kunze R.; Sharan R.; Berman J.","Segal, Ella Shtifman (54793480900); Gritsenko, Vladimir (57204462290); Levitan, Anton (57204461335); Yadav, Bhawna (35104015300); Dror, Naama (57479392500); Steenwyk, Jacob L. (57190980501); Silberberg, Yael (36349572100); Mielich, Kevin (57201428708); Rokas, Antonis (6701584095); Gow, Neil A. R. (7004418840); Kunze, Reinhard (7005079643); Sharan, Roded (7005271135); Berman, Judith (7202774025)","54793480900; 57204462290; 57204461335; 35104015300; 57479392500; 57190980501; 36349572100; 57201428708; 6701584095; 7004418840; 7005079643; 7005271135; 7202774025","Gene essentiality analyzed by in vivo transposon mutagenesis and machine learning in a stable haploid isolate of candida albicans","2018","mBio","87","10.1128/mBio.02048-18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055666758&doi=10.1128%2fmBio.02048-18&partnerID=40&md5=76350cee64498898fcf8d8d27af97cad","School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel; School of Medical Sciences, Institute of Medical Sciences, University of Aberdeen, Aberdeen, United Kingdom; Department of Biological Sciences, Vanderbilt University, Nashville, TN, United States; Institute of Biology, Dahlem Centre of Plant Sciences, Freie Universität Berlin, Berlin, Germany; The Blavatnik School of Computer Science, Raymond & Beverly Sackler Faculty of Exact Sciences, Tel Aviv University, Tel Aviv, Israel","Segal E.S., School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel; Gritsenko V., School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel; Levitan A., School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel; Yadav B., School of Medical Sciences, Institute of Medical Sciences, University of Aberdeen, Aberdeen, United Kingdom; Dror N., School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel; Steenwyk J.L., Department of Biological Sciences, Vanderbilt University, Nashville, TN, United States; Silberberg Y., School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel; Mielich K., Institute of Biology, Dahlem Centre of Plant Sciences, Freie Universität Berlin, Berlin, Germany; Rokas A., Department of Biological Sciences, Vanderbilt University, Nashville, TN, United States; Gow N.A.R., School of Medical Sciences, Institute of Medical Sciences, University of Aberdeen, Aberdeen, United Kingdom; Kunze R., Institute of Biology, Dahlem Centre of Plant Sciences, Freie Universität Berlin, Berlin, Germany; Sharan R., The Blavatnik School of Computer Science, Raymond & Beverly Sackler Faculty of Exact Sciences, Tel Aviv University, Tel Aviv, Israel; Berman J., School of Molecular Cell Biology and Biotechnology, Department of Molecular Microbiology and Biotechnology, George Wise Faculty of Life Sciences, Tel Aviv University, Ramat Aviv, Israel","Knowing the full set of essential genes for a given organism provides important information about ways to promote, and to limit, its growth and survival. For many non-model organisms, the lack of a stable haploid state and low transformation efficiencies impede the use of conventional approaches to generate a genome-wide comprehensive set of mutant strains and the identification of the genes essential for growth. Here we report on the isolation and utilization of a highly stable haploid derivative of the human pathogenic fungus Candida albicans, together with a modified heterologous transposon and machine learning (ML) analysis method, to predict the degree to which all of the open reading frames are required for growth under standard laboratory conditions. We identified 1,610 C. albicans essential genes, including 1,195 with high “essentiality confidence” scores, thereby increasing the number of essential genes (currently 66 in the Candida Genome Database) by >20-fold and providing an unbiased approach to determine the degree of confidence in the determination of essentiality. Among the genes essential in C. albicans were 602 genes also essential in the model budding and fission yeasts analyzed by both deletion and transposon mutagenesis. We also identified essential genes conserved among the four major human pathogens C. albicans, Aspergillus fumigatus, Cryptococcus neoformans, and Histoplasma capsulatum and highlight those that lack homologs in humans and that thus could serve as potential targets for the design of antifungal therapies. IMPORTANCE Comprehensive understanding of an organism requires that we understand the contributions of most, if not all, of its genes. Classical genetic approaches to this issue have involved systematic deletion of each gene in the genome, with comprehensive sets of mutants available only for very-well-studied model organisms. We took a different approach, harnessing the power of in vivo transposition coupled with deep sequencing to identify >500,000 different mutations, one per cell, in the prevalent human fungal pathogen Candida albicans and to map their positions across the genome. The transposition approach is efficient and less labor-intensive than classic approaches. Here, we describe the production and analysis (aided by machine learning) of a large collection of mutants and the comprehensive identification of 1,610 C. albicans genes that are essential for growth under standard laboratory conditions. Among these C. albicans essential genes, we identify those that are also essential in two distantly related model yeasts as well as those that are conserved in all four major human fungal pathogens and that are not conserved in the human genome. This list of genes with functions important for the survival of the pathogen provides a good starting point for the development of new antifungal drugs, which are greatly needed because of the emergence of fungal pathogens with elevated resistance and/or tolerance of the currently limited set of available antifungal drugs. © 2018 Segal et al.","Candida albicans; Genome analysis; Genomics; Machine learning; Phenotypic identification; Transposons","Aspergillus fumigatus; Candida albicans; Cryptococcus neoformans; DNA Transposable Elements; Genes, Essential; Genes, Fungal; Genetics, Microbial; Haploidy; Histoplasma; Machine Learning; Mutagenesis, Insertional; Aspergillus fumigatus; Candida albicans; Cryptococcus neoformans; essential gene; fungal gene; gene expression regulation; genetics; growth, development and aging; haploidy; Histoplasma; machine learning; microbial genetics; procedures; transposon","American Society for Microbiology","21612129","","","30377286","Article","Scopus","2-s2.0-85055666758"
"Abajian A.; Murali N.; Savic L.J.; Laage-Gaupp F.M.; Nezami N.; Duncan J.S.; Schlachter T.; Lin M.; Geschwind J.-F.; Chapiro J.","Abajian, Aaron (55358465200); Murali, Nikitha (57196193736); Savic, Lynn Jeanette (56368286200); Laage-Gaupp, Fabian Max (56193161900); Nezami, Nariman (23470391900); Duncan, James S. (57203363835); Schlachter, Todd (54394210000); Lin, Mingde (7404817617); Geschwind, Jean-François (26643089700); Chapiro, Julius (35487070000)","55358465200; 57196193736; 56368286200; 56193161900; 23470391900; 57203363835; 54394210000; 7404817617; 26643089700; 35487070000","Predicting treatment response to image-guided therapies using machine learning: An example for trans-arterial treatment of hepatocellular carcinoma","2018","Journal of Visualized Experiments","10","10.3791/58382","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055617475&doi=10.3791%2f58382&partnerID=40&md5=a3646a4c3059647160082773ecce72b8","Department of Radiology and Biomedical Imaging, Yale School of Medicine, United States; Department of Diagnostic and Interventional Radiology, Universitätsmedizin Charité Berlin, Germany; Department of Biomedical Engineering, Yale School of Engineering and Applied Science, United States; Philips Research North America, United States; Prescience Labs, United States","Abajian A., Department of Radiology and Biomedical Imaging, Yale School of Medicine, United States; Murali N., Department of Radiology and Biomedical Imaging, Yale School of Medicine, United States; Savic L.J., Department of Radiology and Biomedical Imaging, Yale School of Medicine, United States, Department of Diagnostic and Interventional Radiology, Universitätsmedizin Charité Berlin, Germany; Laage-Gaupp F.M., Department of Radiology and Biomedical Imaging, Yale School of Medicine, United States; Nezami N., Department of Radiology and Biomedical Imaging, Yale School of Medicine, United States; Duncan J.S., Department of Biomedical Engineering, Yale School of Engineering and Applied Science, United States; Schlachter T., Department of Radiology and Biomedical Imaging, Yale School of Medicine, United States; Lin M., Philips Research North America, United States; Geschwind J.-F., Prescience Labs, United States; Chapiro J., Department of Radiology and Biomedical Imaging, Yale School of Medicine, United States","Intra-arterial therapies are the standard of care for patients with hepatocellular carcinoma who cannot undergo surgical resection. The objective of this study was to develop a method to predict response to intra-arterial treatment prior to intervention. The method provides a general framework for predicting outcomes prior to intra-arterial therapy. It involves pooling clinical, demographic and imaging data across a cohort of patients and using these data to train a machine learning model. The trained model is applied to new patients in order to predict their likelihood of response to intra-arterial therapy. The method entails the acquisition and parsing of clinical, demographic and imaging data from N patients who have already undergone transarterial therapies. These data are parsed into discrete features (age, sex, cirrhosis, degree of tumor enhancement, etc.) and binarized into true/ false values (e.g., age over 60, male gender, tumor enhancement beyond a set threshold, etc.). Low-variance features and features with low univariate associations with the outcome are removed. Each treated patient is labeled according to whether they responded or did not respond to treatment. Each training patient is thus represented by a set of binary features and an outcome label. Machine learning models are trained using N-1 patients with testing on the left-out patient. This process is repeated for each of the N patients. The N models are averaged to arrive at a final model. The technique is extensible and enables inclusion of additional features in the future. It is also a generalizable process that may be applied to clinical research questions outside of interventional radiology. The main limitation is the need to derive features manually from each patient. A popular modern form of machine learning called deep learning does not suffer from this limitation, but requires larger datasets. © 2018 Journal of Visualized Experiments.","Artificial intelligence; Hepatocellular carcinoma; Interventional radiology; Issue 140; Machine learning; Medicine; Pre-procedure planning; Predicting outcomes; Predictive modeling; Supervised machine learning; Trans-arterial chemoembolization","Carcinoma, Hepatocellular; Humans; Injections, Intra-Arterial; Liver Neoplasms; Machine Learning; Male; Middle Aged; Surgery, Computer-Assisted; computer assisted surgery; diagnostic imaging; human; intraarterial drug administration; liver cell carcinoma; liver tumor; machine learning; male; middle aged; pathology; procedures; trends","Journal of Visualized Experiments","1940087X","","","30371657","Article","Scopus","2-s2.0-85055617475"
"Lai Z.; Deng H.","Lai, Zhifei (57200690733); Deng, Huifang (7401775498)","57200690733; 7401775498","Medical image classification based on deep features extracted by deep model and statistic feature fusion with multilayer perceptron","2018","Computational Intelligence and Neuroscience","110","10.1155/2018/2061516","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053866352&doi=10.1155%2f2018%2f2061516&partnerID=40&md5=913cad8d4a5703f0704b1a0ec7c6b966","Department of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China","Lai Z., Department of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Deng H., Department of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China","Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods. © 2018 ZhiFei Lai and HuiFang Deng.","","Connective Tissue; Diagnosis, Computer-Assisted; Epithelium; Humans; Image Processing, Computer-Assisted; Keratosis, Seborrheic; Machine Learning; Melanoma; Muscles; Nerve Tissue; Neural Networks (Computer); Nevus; Statistics as Topic; Codes (symbols); Computer aided diagnosis; Convolution; Deep neural networks; Image coding; Medical imaging; Multilayers; Network coding; Neural networks; Pixels; Problem solving; Back-ground knowledge; Classification accuracy; Classification labels; Computational costs; Computer Aided Diagnosis(CAD); Deep convolutional neural networks; High-level features; Model generalization; artificial neural network; computer assisted diagnosis; connective tissue; epithelium; evaluation study; human; image processing; machine learning; melanoma; muscle; nervous tissue; nevus; pathology; procedures; seborrheic keratosis; statistics; Image classification","Hindawi Limited","16875265","","","30298088","Article","Scopus","2-s2.0-85053866352"
"Zeng J.; Zhao X.; Gan J.; Mai C.; Zhai Y.; Wang F.","Zeng, Junying (55695155000); Zhao, Xiaoxiao (57198354097); Gan, Junying (35902507700); Mai, Chaoyun (56048222200); Zhai, Yikui (57198524573); Wang, Fan (57226172605)","55695155000; 57198354097; 35902507700; 56048222200; 57198524573; 57226172605","Deep Convolutional Neural Network Used in Single Sample per Person Face Recognition","2018","Computational Intelligence and Neuroscience","31","10.1155/2018/3803627","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053119428&doi=10.1155%2f2018%2f3803627&partnerID=40&md5=a5079dfa47a84e6b5e257016489654b8","School of Information Engineering, Wuyi University, Jiangmen, 529020, China","Zeng J., School of Information Engineering, Wuyi University, Jiangmen, 529020, China; Zhao X., School of Information Engineering, Wuyi University, Jiangmen, 529020, China; Gan J., School of Information Engineering, Wuyi University, Jiangmen, 529020, China; Mai C., School of Information Engineering, Wuyi University, Jiangmen, 529020, China; Zhai Y., School of Information Engineering, Wuyi University, Jiangmen, 529020, China; Wang F., School of Information Engineering, Wuyi University, Jiangmen, 529020, China","Face recognition (FR) with single sample per person (SSPP) is a challenge in computer vision. Since there is only one sample to be trained, it makes facial variation such as pose, illumination, and disguise difficult to be predicted. To overcome this problem, this paper proposes a scheme combined traditional and deep learning (TDL) method to process the task. First, it proposes an expanding sample method based on traditional approach. Compared with other expanding sample methods, the method can be used easily and conveniently. Besides, it can generate samples such as disguise, expression, and mixed variation. Second, it uses transfer learning and introduces a well-Trained deep convolutional neural network (DCNN) model and then selects some expanding samples to fine-Tune the DCNN model. Third, the fine-Tuned model is used to implement experiment. Experimental results on AR face database, Extend Yale B face database, FERET face database, and LFW database demonstrate that TDL achieves the state-of-The-Art performance in SSPP FR. © 2018 Junying Zeng et al.","","Face; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Convolution; Database systems; Deep neural networks; Digital to analog conversion; Neural networks; Deep convolutional neural networks; Face database; FERET face database; Single sample; State-of-the-art performance; Traditional approaches; Transfer learning; artificial neural network; automated pattern recognition; face; human; image processing; machine learning; procedures; Face recognition","Hindawi Limited","16875265","","","30210533","Article","Scopus","2-s2.0-85053119428"
"Li F.; Wang C.; Liu X.; Peng Y.; Jin S.","Li, Fangzhao (56710738700); Wang, Changjian (55766741400); Liu, Xiaohui (57202239224); Peng, Yuxing (55257095800); Jin, Shiyao (7401822532)","56710738700; 55766741400; 57202239224; 55257095800; 7401822532","A Composite Model of Wound Segmentation Based on Traditional Methods and Deep Neural Networks","2018","Computational Intelligence and Neuroscience","55","10.1155/2018/4149103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048535050&doi=10.1155%2f2018%2f4149103&partnerID=40&md5=e15424ba0313d1248131048bdc05b206","Science and Technology on Parallel and Distributed Laboratory, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China","Li F., Science and Technology on Parallel and Distributed Laboratory, Changsha, China; Wang C., College of Computer, National University of Defense Technology, Changsha, China; Liu X., Science and Technology on Parallel and Distributed Laboratory, Changsha, China; Peng Y., Science and Technology on Parallel and Distributed Laboratory, Changsha, China; Jin S., Science and Technology on Parallel and Distributed Laboratory, Changsha, China","Wound segmentation plays an important supporting role in the wound observation and wound healing. Current methods of image segmentation include those based on traditional process of image and those based on deep neural networks. The traditional methods use the artificial image features to complete the task without large amounts of labeled data. Meanwhile, the methods based on deep neural networks can extract the image features effectively without the artificial design, but lots of training data are required. Combined with the advantages of them, this paper presents a composite model of wound segmentation. The model uses the skin with wound detection algorithm we designed in the paper to highlight image features. Then, the preprocessed images are segmented by deep neural networks. And semantic corrections are applied to the segmentation results at last. The model shows a good performance in our experiment. © 2018 Fangzhao Li et al.","","Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Skin; Wound Healing; Wounds and Injuries; Image segmentation; Semantics; Artificial image; Composite modeling; Detection algorithm; Image features; Segmentation results; Supporting role; Training data; Wound healing; artificial neural network; computer assisted diagnosis; human; injury; machine learning; pathology; procedures; skin; wound healing; Deep neural networks","Hindawi Limited","16875265","","","29955227","Article","Scopus","2-s2.0-85048535050"
"Yoon S.; Odlum M.; Lee Y.; Choi T.; Kronish I.M.; Davidson K.W.; Finkelstein J.","Yoon, Sunmoo (35072135900); Odlum, Michelle (9640449600); Lee, Yeonsuk (57203798951); Choi, Thomas (58381627000); Kronish, Ian M. (13006307000); Davidson, Karina W. (7203032183); Finkelstein, Joseph (7201815643)","35072135900; 9640449600; 57203798951; 58381627000; 13006307000; 7203032183; 7201815643","Applying Deep Learning to Understand Predictors of Tooth Mobility among Urban Latinos","2018","Studies in Health Technology and Informatics","8","10.3233/978-1-61499-880-8-241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049566314&doi=10.3233%2f978-1-61499-880-8-241&partnerID=40&md5=8cc75bdb0be89f167cf40d0737700fb1","School of Nursing, Columbia University, 630W 168 street, mail code 6, New York, 10032, NY, United States; College of Dental Medicine, Columbia University, New York, NY, United States; Department of Medicine, College of Physicians and Surg., Columbia University, New York, NY, United States","Yoon S., School of Nursing, Columbia University, 630W 168 street, mail code 6, New York, 10032, NY, United States; Odlum M., School of Nursing, Columbia University, 630W 168 street, mail code 6, New York, 10032, NY, United States; Lee Y., School of Nursing, Columbia University, 630W 168 street, mail code 6, New York, 10032, NY, United States; Choi T., College of Dental Medicine, Columbia University, New York, NY, United States; Kronish I.M., Department of Medicine, College of Physicians and Surg., Columbia University, New York, NY, United States; Davidson K.W., Department of Medicine, College of Physicians and Surg., Columbia University, New York, NY, United States; Finkelstein J., College of Dental Medicine, Columbia University, New York, NY, United States","We applied deep learning algorithms to build correlate models that predict tooth mobility in a convenience sample of urban Latinos. Our application of deep learning identified age, general health, soda consumption, flossing, financial stress, and years living in the US as the strongest correlates of self-reported tooth mobility among 78 variables entered. The application of deep learning was useful for gaining insights into the most important modifiable and non-modifiable factors predicting tooth mobility, and maybe useful for guiding targeted interventions in urban Latinos. © 2018 The authors and IOS Press. All rights reserved.","aging; deep learning; Latinos; symptom science; Tooth mobility","Algorithms; Forecasting; Health Behavior; Hispanic Americans; Humans; Machine Learning; Self Report; Tooth Mobility; Urban Population; Aging of materials; Learning algorithms; Financial stress; Gaining insights; Latinos; symptom science; Tooth mobility; algorithm; forecasting; health behavior; Hispanic; human; machine learning; periodontal disease; self report; urban population; Deep learning","IOS Press","09269630","978-161499879-2","","29968648","Article","Scopus","2-s2.0-85049566314"
"Song Y.; Gao S.; Tan W.; Qiu Z.; Zhou H.; Zhao Y.","Song, Yiyan (57193899257); Gao, Shaowei (57190666500); Tan, Wulin (57190674506); Qiu, Zeting (57190666475); Zhou, Huaqiang (57190659723); Zhao, Yue (57253823500)","57193899257; 57190666500; 57190674506; 57190666475; 57190659723; 57253823500","Multiple machine learnings revealed similar predictive accuracy for prognosis of PNETs from the surveillance, epidemiology, and end result database","2018","Journal of Cancer","25","10.7150/jca.26649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056270489&doi=10.7150%2fjca.26649&partnerID=40&md5=24f20a0f2950b48cbb525c7f01506790","Department of General Surgery, Guangdong Second Provincial General Hospital, No.466 Middle Xingang Road Haizhu District, Guangzhou City, Guangdong, 510310, China; Department of Anesthesia, First Affiliated Hospital of Sun Yat-Sen University, Guangzhou, China; Zhongshan School of Medicine, Sun Yat-Sen University, Guangzhou, China","Song Y., Department of General Surgery, Guangdong Second Provincial General Hospital, No.466 Middle Xingang Road Haizhu District, Guangzhou City, Guangdong, 510310, China, Department of Anesthesia, First Affiliated Hospital of Sun Yat-Sen University, Guangzhou, China; Gao S., Department of Anesthesia, First Affiliated Hospital of Sun Yat-Sen University, Guangzhou, China; Tan W., Department of Anesthesia, First Affiliated Hospital of Sun Yat-Sen University, Guangzhou, China; Qiu Z., Zhongshan School of Medicine, Sun Yat-Sen University, Guangzhou, China; Zhou H., Zhongshan School of Medicine, Sun Yat-Sen University, Guangzhou, China; Zhao Y., Department of General Surgery, Guangdong Second Provincial General Hospital, No.466 Middle Xingang Road Haizhu District, Guangzhou City, Guangdong, 510310, China","Background: Prognosis prediction is indispensable in clinical practice and machine learning has been proved to be helpful. We expected to predict survival of pancreatic neuroendocrine tumors (PNETs) with machine learning, and compared it with the American Joint Committee on Cancer (AJCC) staging system. Methods: Data of PNETs cases were extracted from The Surveillance, Epidemiology, and End Result (SEER) database. Statistic description, multivariate survival analysis and preprocessing were done before machine learning. Four different algorithms (logistic regression (LR), support vector machines (SVM), random forest (RF) and deep learning (DL)) were used to train the model. We used proper imputations to manage missing data in the database and sensitive analysis was performed to evaluate the imputation. The model with the best predictive accuracy was compared with the AJCC staging system using the SEER cases. Results: The four models had similar predictive accuracy with no significant difference existed (p = 0.664). The DL model showed a slightly better predictive accuracy than others (81.6% (± 1.9%)), thus it was used for further comparison with the AJCC staging system and revealed a better performance for PNETs cases in SEER database (Area under receiver operating characteristic curve: 0.87 vs 0.76). The validity of missing data imputation was supported by sensitivity analysis. Conclusions: The models developed with machine learning performed well in survival prediction of PNETs, and the DL model have a better accuracy and specificity than the AJCC staging system in SEER data. The DL model has potential for clinical application but external validation is needed. © Ivyspring International Publisher.","Machine learning; Pancreatic neuroendocrine tumor; Prognostic prediction; SEER database","adult; Article; cancer diagnosis; cancer prognosis; cancer survival; data base; diagnostic accuracy; female; human; machine learning; major clinical study; male; pancreas islet cell tumor; random forest; sensitivity and specificity; support vector machine; survival analysis; survival prediction","Ivyspring International Publisher","18379664","","","","Article","Scopus","2-s2.0-85056270489"
"Gao G.; Shang L.; Xiong K.; Fang J.; Zhang C.; Gu X.","Gao, Guangchun (26639337100); Shang, Lina (36481946900); Xiong, Kai (24473680600); Fang, Jian (57199464252); Zhang, Cui (55617236200); Gu, Xuejun (57202925210)","26639337100; 36481946900; 24473680600; 57199464252; 55617236200; 57202925210","Eeg classification based on sparse representation and deep learning","2018","NeuroQuantology","11","10.14704/nq.2018.16.6.1666","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049829823&doi=10.14704%2fnq.2018.16.6.1666&partnerID=40&md5=4aef09eda7ac41a3ce184350e314aab4","School of Information Science & Electronic Engineering, Zhejiang University City College, Hangzhou, 310015, China; Ningbo Women & Children's Hospital, Ningbo, 315012, China","Gao G., School of Information Science & Electronic Engineering, Zhejiang University City College, Hangzhou, 310015, China; Shang L., School of Information Science & Electronic Engineering, Zhejiang University City College, Hangzhou, 310015, China; Xiong K., School of Information Science & Electronic Engineering, Zhejiang University City College, Hangzhou, 310015, China; Fang J., School of Information Science & Electronic Engineering, Zhejiang University City College, Hangzhou, 310015, China; Zhang C., School of Information Science & Electronic Engineering, Zhejiang University City College, Hangzhou, 310015, China; Gu X., Ningbo Women & Children's Hospital, Ningbo, 315012, China","For brain computer interfaces (BCIs) research, the classification of motor imagery brain signals is a major and challenging step. Based on the traditional sparse representation classification, a classification algorithm of electroencephalogram (EEG) based on sparse representation and convolution neural network is proposed by this paper. For the EEG signal, firstly, the features of the signal are obtained through the common spatial pattern (CSP) algorithm, and then the redundant dictionary with sparse representation is constructed based on these features. The sparse representation of the EEG signal is completed and the sparse features can be obtained. Finally, the sparse features are transformed into two dimensional signals, and the convolution neural network is used to complete the classification of EEG signals. Using the dataset downloaded from the website of BCI competition III (dataset IVa), for two types of EEG signals, the experiments show that the recognition accuracy of the method is over 80, and the recognition accuracy is better than that of the traditional SRC algorithm. © 2018, Anka Publishers. All rights reserved.","Convolution Neural Network; Deep Learning; EEG; Sparse Representation Classification","Article; brain computer interface; classification algorithm; data processing; electroencephalogram; electromyogram; electrooculogram; human; image processing; learning; mathematical computing; measurement accuracy; measurement precision; nerve cell network; signal processing; support vector machine; training","Anka Publishers","13035150","","","","Article","Scopus","2-s2.0-85049829823"
"Kamaleswaran R.; Akbilgic O.; Hallman M.A.; West A.N.; Davis R.L.; Shah S.H.","Kamaleswaran, Rishikesan (35761072500); Akbilgic, Oguz (28567583700); Hallman, Madhura A. (57207531638); West, Alina N. (14008477100); Davis, Robert L. (7410192927); Shah, Samir H. (7403888647)","35761072500; 28567583700; 57207531638; 14008477100; 7410192927; 7403888647","Applying artificial intelligence to identify physiomarkers predicting severe sepsis in the PICU","2018","Pediatric Critical Care Medicine","86","10.1097/PCC.0000000000001666","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054397306&doi=10.1097%2fPCC.0000000000001666&partnerID=40&md5=ed5771b3d736d7a8fde5cfc0b791b55d","Center for Biomedical Informatics, Department of Pediatrics, University of Tennessee Health Science Center, Memphis, TN, United States; Division of Pediatric Critical Care Medicine, Department of Pediatrics, University of Tennessee Health Science Center, Memphis, TN, United States","Kamaleswaran R., Center for Biomedical Informatics, Department of Pediatrics, University of Tennessee Health Science Center, Memphis, TN, United States, Division of Pediatric Critical Care Medicine, Department of Pediatrics, University of Tennessee Health Science Center, Memphis, TN, United States; Akbilgic O., Center for Biomedical Informatics, Department of Pediatrics, University of Tennessee Health Science Center, Memphis, TN, United States; Hallman M.A., Division of Pediatric Critical Care Medicine, Department of Pediatrics, University of Tennessee Health Science Center, Memphis, TN, United States; West A.N., Division of Pediatric Critical Care Medicine, Department of Pediatrics, University of Tennessee Health Science Center, Memphis, TN, United States; Davis R.L., Center for Biomedical Informatics, Department of Pediatrics, University of Tennessee Health Science Center, Memphis, TN, United States; Shah S.H., Division of Pediatric Critical Care Medicine, Department of Pediatrics, University of Tennessee Health Science Center, Memphis, TN, United States","Objectives: We used artificial intelligence to develop a novel algorithm using physiomarkers to predict the onset of severe sepsis in critically ill children. Design: Observational cohort study. Setting: PICU. Patients: Children age between 6 and 18 years old. Interventions: None. Measurements and Main Results: Continuous minute-by-minute physiologic data were available for a total of 493 critically ill children admitted to a tertiary care PICU over an 8-month period, 20 of whom developed severe sepsis. Using an alert time stamp generated by an electronic screening algorithm as a reference point, we studied up to 24 prior hours of continuous physiologic data. We identified physiomarkers, including sd of heart rate, systolic and diastolic blood pressure, and symbolic transitions probabilities of those variables that discriminated severe sepsis patients from controls (all other patients admitted to the PICU who did not meet severe sepsis criteria). We used logistic regression, random forests, and deep Convolutional Neural Network methods to derive our models. Analysis was performed using data generated in two windows prior to the firing of the electronic screening algorithm, namely, 2-8 and 8-24 hours. When analyzing the physiomarkers present in the 2-8 hours analysis window, logistic regression performed with specificity of 87.4% and sensitivity of 55.0%, random forest performed with 79.6% specificity and 80.0% sensitivity, and the Convolutional Neural Network performed with 83.0% specificity and 75.0% sensitivity. When analyzing physiomarkers from the 8-24 hours window, logistic regression resulted in 77.1% specificity and 39.3% sensitivity, random forest performed with 82.3% specificity and 61.1% sensitivity, whereas the Convolutional Neural Network method achieved 81% specificity and 76% sensitivity. Conclusions: Artificial intelligence can be used to predict the onset of severe sepsis using physiomarkers in critically ill children. Further, it may detect severe sepsis as early as 8 hours prior to a real-time electronic severe sepsis screening algorithm. Copyright © 2018 by the Society of Critical Care Medicine and the World Federation of Pediatric Intensive and Critical Care Societies.","Artificial intelligence; Deep learning; Machine learning; Physiologic data; Predictive analytics; Severe sepsis screening","Adolescent; Artificial Intelligence; Case-Control Studies; Child; Female; Heart Rate; Humans; Intensive Care Units, Pediatric; Logistic Models; Machine Learning; Male; Monitoring, Physiologic; Organ Dysfunction Scores; Predictive Value of Tests; Prospective Studies; Respiratory Rate; Sepsis; Article; artificial intelligence; artificial neural network; child; cohort analysis; critically ill patient; deep learning; diastolic blood pressure; heart rate; human; logistic regression analysis; machine learning; mean arterial pressure; observational study; pediatric intensive care unit; predictive value; priority journal; random forest; sepsis; systemic inflammatory response syndrome; systolic blood pressure; adolescent; artificial intelligence; breathing rate; case control study; female; machine learning; male; organ dysfunction score; pediatric intensive care unit; physiologic monitoring; physiology; procedures; prospective study; sepsis; statistical model","Lippincott Williams and Wilkins","15297535","","","30052552","Article","Scopus","2-s2.0-85054397306"
"Rahul S.","Rahul, S. (57215915423)","57215915423","Analysis and presenting the educational techniques in Machine and Deep Learning short communication","2018","International Journal of Engineering and Technology(UAE)","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082345917&partnerID=40&md5=e7c360837113941ec327c655b099b0f9","Research Scholar at KL Deemed to be University, Vaddeswaram, Green Fields, Guntur, India","Rahul S., Research Scholar at KL Deemed to be University, Vaddeswaram, Green Fields, Guntur, India","This paper gives a present of general learning of deep methodology and its applications to a variety of signal and data processing sched-ules. It is discussed about Machine learning vs. Deep Learning a brief and which is best suited in the market, Dissimilarities, Problem handling, Interpretability, Comparative and different options between cubic centimeter and metric capacity unit and concluded by justify-ing deep learning is a part of Machine learning and Machine learning is a part of Artificial intelligence. © 2016 Authors.","Artificial intelligence; Cubic centimeter; Deep Learning; Machine learning; Metric capacity","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082345917"
"Treppner M.; Lenz S.; Binder H.; Zöller D.","Treppner, Martin (57204585238); Lenz, Stefan (57196094468); Binder, Harald (7202460535); Zöller, Daniela (56993195000)","57204585238; 57196094468; 7202460535; 56993195000","Modeling Activity Tracker Data Using Deep Boltzmann Machines","2018","Studies in health technology and informatics","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056286262&partnerID=40&md5=992640540d7a6f72eb0428c7260eecbf","Institute of Medical Biometry and Statistics, Faculty of Medicine and Medical Center - University of Freiburg","Treppner M., Institute of Medical Biometry and Statistics, Faculty of Medicine and Medical Center - University of Freiburg; Lenz S., Institute of Medical Biometry and Statistics, Faculty of Medicine and Medical Center - University of Freiburg; Binder H., Institute of Medical Biometry and Statistics, Faculty of Medicine and Medical Center - University of Freiburg; Zöller D., Institute of Medical Biometry and Statistics, Faculty of Medicine and Medical Center - University of Freiburg","Commercial activity trackers are set to become an essential tool in health research, due to increasing availability in the general population. The corresponding vast amounts of mostly unlabeled data pose a challenge to statistical modeling approaches. To investigate the feasibility of deep learning approaches for unsupervised learning with such data, we examine weekly usage patterns of Fitbit activity trackers with deep Boltzmann machines (DBMs). This method is particularly suitable for modeling complex joint distributions via latent variables. We also chose this specific procedure because it is a generative approach, i.e., artificial samples can be generated to explore the learned structure. We describe how the data can be preprocessed to be compatible with binary DBMs. The results reveal two distinct usage patterns in which one group frequently uses trackers on Mondays and Tuesdays, whereas the other uses trackers during the entire week. This exemplary result shows that DBMs are feasible and can be useful for modeling activity tracker data.","Activity Trackers; Deep Boltzmann Machines; Deep Learning","Fitness Trackers; Models, Statistical; Statistics as Topic; activity tracker; statistical model; statistics","","09269630","","","30147063","Article","Scopus","2-s2.0-85056286262"
"Zheng J.; Li J.; Li Y.; Peng L.","Zheng, Jin (56441882000); Li, Jinku (57204519085); Li, Yi (7502079542); Peng, Lihui (7201574360)","56441882000; 57204519085; 7502079542; 7201574360","A benchmark dataset and deep learning-based image reconstruction for electrical capacitance tomography","2018","Sensors (Switzerland)","36","10.3390/s18113701","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055911959&doi=10.3390%2fs18113701&partnerID=40&md5=7ea09ab3b14d5f084b1900fb58caaba5","Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, 100084, China; Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055, China","Zheng J., Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, 100084, China; Li J., Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, 100084, China; Li Y., Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055, China; Peng L., Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing, 100084, China","Electrical Capacitance Tomography (ECT) image reconstruction has developed for decades and made great achievements, but there is still a need to find a new theoretical framework to make it better and faster. In recent years, machine learning theory has been introduced in the ECT area to solve the image reconstruction problem. However, there is still no public benchmark dataset in the ECT field for the training and testing of machine learning-based image reconstruction algorithms. On the other hand, a public benchmark dataset can provide a standard framework to evaluate and compare the results of different image reconstruction methods. In this paper, a benchmark dataset for ECT image reconstruction is presented. Like the great contribution of ImageNet that transformed machine learning research, this benchmark dataset is hoped to be helpful for society to investigate new image reconstruction algorithms since the relationship between permittivity distribution and capacitance can be better mapped. In addition, different machine learning-based image reconstruction algorithms can be trained and tested by the unified dataset, and the results can be evaluated and compared under the same standard, thus, making the ECT image reconstruction study more open and causing a breakthrough. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Benchmark dataset; Electrical capacitance tomography; Image reconstruction; Machine learning","Capacitance; Deep learning; Electric impedance tomography; Learning algorithms; Learning systems; Machine learning; Statistical tests; Benchmark datasets; Electrical Capacitance Tomography; Image reconstruction algorithm; Image reconstruction methods; Machine learning research; Permittivity distributions; Reconstruction problems; Theoretical framework; Image reconstruction","MDPI AG","14248220","","","30384432","Article","Scopus","2-s2.0-85055911959"
"Aldahoul N.; Md Sabri A.Q.; Mansoor A.M.","Aldahoul, Nouar (56656478800); Md Sabri, Aznul Qalid (56150450300); Mansoor, Ali Mohammed (26421574400)","56656478800; 56150450300; 26421574400","Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models","2018","Computational Intelligence and Neuroscience","34","10.1155/2018/1639561","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053062289&doi=10.1155%2f2018%2f1639561&partnerID=40&md5=6dd564dc4c69468d0a9ae717045cad34","Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia","Aldahoul N., Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Md Sabri A.Q., Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Mansoor A.M., Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia","Human detection in videos plays an important role in various real life applications. Most of traditional approaches depend on utilizing handcrafted features which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for human detection task. Pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with soft-max and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high performance Graphical Processing Unit (GPU). © 2018 Nouar AlDahoul et al.","","Humans; Image Processing, Computer-Assisted; Machine Learning; Motion; Motor Activity; Neural Networks (Computer); Pattern Recognition, Automated; Time Factors; Video Recording; Antennas; Cameras; Convolutional neural networks; Graphics processing unit; Optical flows; Program processors; Support vector machines; Discriminative features; Extreme learning machine; Feature extractor; Graphical processing units; Illumination changes; Real-life applications; Testing accuracy; Traditional approaches; artificial neural network; automated pattern recognition; human; image processing; machine learning; motion; motor activity; procedures; time factor; videorecording; Learning systems","Hindawi Limited","16875265","","","29623089","Article","Scopus","2-s2.0-85053062289"
"Talai A.S.; Sedlacik J.; Boelmans K.; Forkert N.D.","Talai, Aron S. (57203904214); Sedlacik, Jan (8302879200); Boelmans, Kai (6506205536); Forkert, Nils D. (16549854100)","57203904214; 8302879200; 6506205536; 16549854100","Widespread diffusion changes differentiate Parkinson's disease and progressive supranuclear palsy","2018","NeuroImage: Clinical","18","10.1016/j.nicl.2018.09.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054920317&doi=10.1016%2fj.nicl.2018.09.028&partnerID=40&md5=f0b99d8d0521c846e59b13afd14c5b7d","Department of Radiology, Hotchkiss Brain Institute, University of Calgary, Canada; Department of Diagnostic and Interventional Neuroradiology, University Medical Center Hamburg-Eppendorf, Germany; Department of Neurology, University Hospital Würzburg, Germany","Talai A.S., Department of Radiology, Hotchkiss Brain Institute, University of Calgary, Canada; Sedlacik J., Department of Diagnostic and Interventional Neuroradiology, University Medical Center Hamburg-Eppendorf, Germany; Boelmans K., Department of Neurology, University Hospital Würzburg, Germany; Forkert N.D., Department of Radiology, Hotchkiss Brain Institute, University of Calgary, Canada","Background: Parkinson's disease (PD) and progressive supranuclear palsy – Richardson's syndrome (PSP-RS) are often represented by similar clinical symptoms, which may challenge diagnostic accuracy. The objective of this study was to investigate and compare regional cerebral diffusion properties in PD and PSP-RS subjects and evaluate the use of these metrics for an automatic classification framework. Material and methods: Diffusion-tensor MRI datasets from 52 PD and 21 PSP-RS subjects were employed for this study. Using an atlas-based approach, regional median values of mean diffusivity (MD), fractional anisotropy (FA), radial diffusivity (RD), and axial diffusivity (AD) were measured and employed for feature selection using RELIEFF and subsequent classification using a support vector machine. Results: According to RELIEFF, the top 17 diffusion values consisting of deep gray matter structures, the brainstem, and frontal cortex were found to be especially informative for an automatic classification. A MANCOVA analysis performed on these diffusion values as dependent variables revealed that PSP-RS and PD subjects differ significantly (p <.001). Generally, PSP-RS subjects exhibit reduced FA, and increased MD, RD, and AD values in nearly all brain structures analyzed compared to PD subjects. The leave-one-out cross-validation of the support vector machine classifier revealed that the classifier can differentiate PD and PSP-RS subjects with an accuracy of 87.7%. More precisely, six PD subjects were wrongly classified as PSP-RS and three PSP-RS subjects were wrongly classified as PD. Conclusion: The results of this study demonstrate that PSP-RS subjects exhibit widespread and more severe diffusion alterations compared to PD patients, which appears valuable for an automatic computer-aided diagnosis approach. © 2018 The Authors","Computer-Assisted Image Analysis; Diffusion-tensor magnetic resonance imaging; Parkinson's disease; Progressive supranuclear palsy; Support vector machines","Adult; Aged; Brain Stem; Diffusion Magnetic Resonance Imaging; Diffusion Tensor Imaging; Female; Gray Matter; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Parkinson Disease; Supranuclear Palsy, Progressive; adult; aged; Article; axial diffusivity; brain stem; controlled study; diagnostic accuracy; diagnostic test accuracy study; differential diagnosis; diffusion tensor imaging; disease classification; echo planar imaging; female; fractional anisotropy; frontal cortex; gray matter; human; image processing; machine learning; major clinical study; male; mean diffusivity; Parkinson disease; priority journal; progressive supranuclear palsy; radial diffusivity; support vector machine; diffusion tensor imaging; diffusion weighted imaging; middle aged; Parkinson disease; pathology; procedures; progressive supranuclear palsy","Elsevier Inc.","22131582","","","30342392","Article","Scopus","2-s2.0-85054920317"
"Sustika R.; Subekti A.; Pardede H.F.; Suryawati E.; Mahendra O.; Yuwana S.","Sustika, Rika (56523358200); Subekti, Agus (56387694900); Pardede, Hilman F. (55351397700); Suryawati, Endang (57201688510); Mahendra, Oka (56412034000); Yuwana, Sandra (54791621400)","56523358200; 56387694900; 55351397700; 57201688510; 56412034000; 54791621400","Evaluation of deep convolutional neural network architectures for strawberry quality inspection","2018","International Journal of Engineering and Technology(UAE)","34","10.14419/ijet.v7i4.40.24080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059275662&doi=10.14419%2fijet.v7i4.40.24080&partnerID=40&md5=7b8a6cb3226b639e4a03770799d47ac3","Research Center for Informatics (P2I), Indonesia Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Electronics and Telecommunications (PPET), Indonesia Institute of Sciences (LIPI), Bandung, Indonesia","Sustika R., Research Center for Informatics (P2I), Indonesia Institute of Sciences (LIPI), Bandung, Indonesia; Subekti A., Research Center for Electronics and Telecommunications (PPET), Indonesia Institute of Sciences (LIPI), Bandung, Indonesia; Pardede H.F., Research Center for Informatics (P2I), Indonesia Institute of Sciences (LIPI), Bandung, Indonesia; Suryawati E., Research Center for Informatics (P2I), Indonesia Institute of Sciences (LIPI), Bandung, Indonesia; Mahendra O., Research Center for Informatics (P2I), Indonesia Institute of Sciences (LIPI), Bandung, Indonesia; Yuwana S., Research Center for Informatics (P2I), Indonesia Institute of Sciences (LIPI), Bandung, Indonesia","Fruits quality inspection is important task on agriculture industry. Automated inspection using machine and vision technology have been widely used for increasing accuracy and decreasing working cost. Convolutional Neural Network (CNN) is a type of deep learning that had a great success in large scale image and video recognition. In this research, we investigate the effect of different deep convolutional neural network architectures on its accuracy in strawberry grading system (quality inspection). We evaluate different types of existing deep CNN architectures such as AlexNet, MobileNet, GoogLeNet, VGGNet, and Xception, and we compare them with two layers CNN architecture as our baseline. Here, we have done two experiments, the first is two classes strawberry classification and the second is four classes strawberry classification. Results show that VGGNet achieves the best accuracy, while GoogLeNet achieves the most computational efficient architecture. The results are consistent on both two classes classification and four classes classification. © 2018 Authors.","CNN; Deep learning; Quality inspection; Strawberry","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85059275662"
"Zhang J.; Gajjala S.; Agrawal P.; Tison G.H.; Hallock L.A.; Beussink-Nelson L.; Lassen M.H.; Fan E.; Aras M.A.; Jordan C.R.; Fleischmann K.E.; Melisko M.; Qasim A.; Shah S.J.; Bajcsy R.; Deo R.C.","Zhang, Jeffrey (57204440385); Gajjala, Sravani (57204438542); Agrawal, Pulkit (56333469300); Tison, Geoffrey H. (6505822175); Hallock, Laura A. (57204438697); Beussink-Nelson, Lauren (56766204800); Lassen, Mats H. (57192316204); Fan, Eugene (57204440533); Aras, Mandar A. (57189089582); Jordan, Cha Randle (57204439910); Fleischmann, Kirsten E. (57212012836); Melisko, Michelle (8593665600); Qasim, Atif (8894699700); Shah, Sanjiv J. (12545068000); Bajcsy, Ruzena (7006078015); Deo, Rahul C. (57200410290)","57204440385; 57204438542; 56333469300; 6505822175; 57204438697; 56766204800; 57192316204; 57204440533; 57189089582; 57204439910; 57212012836; 8593665600; 8894699700; 12545068000; 7006078015; 57200410290","Fully automated echocardiogram interpretation in clinical practice: Feasibility and diagnostic accuracy","2018","Circulation","522","10.1161/CIRCULATIONAHA.118.034338","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055611001&doi=10.1161%2fCIRCULATIONAHA.118.034338&partnerID=40&md5=c5591b710c5be38fe44dd036ddef28b1","Cardiovascular Research Institute, San Francisco, CA, United States; Department of Medicine, San Francisco, CA, United States; Institute for Human Genetics, San Francisco, CA, United States; Institute for Computational Health Sciences, San Francisco, CA, United States; Center for Digital Health Innovation, San Francisco, CA, United States; University of California, San Francisco, CA, United States; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, United States; Department of Medicine, Feinberg Cardiovascular Research Institute, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; California Institute for Quantitative Biosciences, San Francisco, CA, United States","Zhang J., Cardiovascular Research Institute, San Francisco, CA, United States, Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, United States; Gajjala S., University of California, San Francisco, CA, United States; Agrawal P., Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, United States; Tison G.H., Department of Medicine, San Francisco, CA, United States; Hallock L.A., Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, United States; Beussink-Nelson L., Department of Medicine, Feinberg Cardiovascular Research Institute, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Lassen M.H., Department of Medicine, San Francisco, CA, United States; Fan E., Department of Medicine, San Francisco, CA, United States; Aras M.A., Department of Medicine, San Francisco, CA, United States; Jordan C.R., Department of Medicine, San Francisco, CA, United States; Fleischmann K.E., Department of Medicine, San Francisco, CA, United States; Melisko M., Department of Medicine, Feinberg Cardiovascular Research Institute, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Qasim A., Department of Medicine, Feinberg Cardiovascular Research Institute, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Shah S.J., Department of Medicine, Feinberg Cardiovascular Research Institute, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Bajcsy R., Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, United States; Deo R.C., Cardiovascular Research Institute, San Francisco, CA, United States, Department of Medicine, San Francisco, CA, United States, Institute for Human Genetics, San Francisco, CA, United States, Institute for Computational Health Sciences, San Francisco, CA, United States, Center for Digital Health Innovation, San Francisco, CA, United States, California Institute for Quantitative Biosciences, San Francisco, CA, United States","BACKGROUND: Automated cardiac image interpretation has the potential to transform clinical practice in multiple ways, including enabling serial assessment of cardiac function by nonexperts in primary care and rural settings. We hypothesized that advances in computer vision could enable building a fully automated, scalable analysis pipeline for echocardiogram interpretation, including (1) view identification, (2) image segmentation, (3) quantification of structure and function, and (4) disease detection. METHODS: Using 14 035 echocardiograms spanning a 10-year period, we trained and evaluated convolutional neural network models for multiple tasks, including automated identification of 23 viewpoints and segmentation of cardiac chambers across 5 common views. The segmentation output was used to quantify chamber volumes and left ventricular mass, determine ejection fraction, and facilitate automated determination of longitudinal strain through speckle tracking. Results were evaluated through comparison to manual segmentation and measurements from 8666 echocardiograms obtained during the routine clinical workflow. Finally, we developed models to detect 3 diseases: Hypertrophic cardiomyopathy, cardiac amyloid, and pulmonary arterial hypertension. RESULTS: Convolutional neural networks accurately identified views (eg, 96% for parasternal long axis), including flagging partially obscured cardiac chambers, and enabled the segmentation of individual cardiac chambers. The resulting cardiac structure measurements agreed with study report values (eg, median absolute deviations of 15% to 17% of observed values for left ventricular mass, left ventricular diastolic volume, and left atrial volume). In terms of function, we computed automated ejection fraction and longitudinal strain measurements (within 2 cohorts), which agreed with commercial software-derived values (for ejection fraction, median absolute deviation=9.7% of observed, N=6407 studies; for strain, median absolute deviation=7.5%, n=419, and 9.0%, n=110) and demonstrated applicability to serial monitoring of patients with breast cancer for trastuzumab cardiotoxicity. Overall, we found automated measurements to be comparable or superior to manual measurements across 11 internal consistency metrics (eg, the correlation of left atrial and ventricular volumes). Finally, we trained convolutional neural networks to detect hypertrophic cardiomyopathy, cardiac amyloidosis, and pulmonary arterial hypertension with C statistics of 0.93, 0.87, and 0.85, respectively. CONCLUSIONS: Our pipeline lays the groundwork for using automated interpretation to support serial patient tracking and scalable analysis of millions of echocardiograms archived within healthcare systems. © 2018 The Authors.","diagnosis; echocardiography; machine learning","Amyloidosis; Automation; Cardiomyopathy, Hypertrophic; Deep Learning; Echocardiography; Humans; Hypertension, Pulmonary; Image Interpretation, Computer-Assisted; Predictive Value of Tests; Reproducibility of Results; Stroke Volume; Ventricular Function, Left; cyclophosphamide; doxorubicin; trastuzumab; adult; algorithm; architecture; Article; artificial neural network; automation; cardiotoxicity; chemotherapy; clinical practice; cohort analysis; defibrillation; diagnostic accuracy; echocardiography; feasibility study; female; heart amyloidosis; heart disease; heart function; heart left ventricle ejection fraction; heart left ventricle enddiastolic volume; heart left ventricle endsystolic volume; heart left ventricle mass; heart rate; heart ventricle hypertrophy; human; hypertrophic cardiomyopathy; image analysis; image segmentation; lung pressure; major clinical study; male; priority journal; pulmonary hypertension; receiver operating characteristic; amyloidosis; automation; computer assisted diagnosis; diagnostic imaging; echocardiography; heart left ventricle function; heart stroke volume; pathophysiology; predictive value; procedures; reproducibility; validation study","Lippincott Williams and Wilkins","00097322","","CIRCA","30354459","Article","Scopus","2-s2.0-85055611001"
"Xiao T.; Liu L.; Li K.; Qin W.; Yu S.; Li Z.","Xiao, Ting (57202712561); Liu, Lei (57196287305); Li, Kai (26643590600); Qin, Wenjian (57213096760); Yu, Shaode (55848924700); Li, Zhicheng (55707186500)","57202712561; 57196287305; 26643590600; 57213096760; 55848924700; 55707186500","Comparison of Transferred Deep Neural Networks in Ultrasonic Breast Masses Discrimination","2018","BioMed Research International","120","10.1155/2018/4605191","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053266711&doi=10.1155%2f2018%2f4605191&partnerID=40&md5=ea6fbf3755d2bbb3e1b6ded95f7f1dac","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China; College of Communication Engineering, Chongqing University, Chongqing, 400044, China; Department of Medical Ultrasonics, Third Affiliated Hospital, Sun Yat-sen University, Guangdong, 510630, China; University of Chinese Academy of Sciences, Beijing, 100049, China","Xiao T., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China, College of Communication Engineering, Chongqing University, Chongqing, 400044, China; Liu L., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China; Li K., Department of Medical Ultrasonics, Third Affiliated Hospital, Sun Yat-sen University, Guangdong, 510630, China; Qin W., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Yu S., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China; Li Z., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China","This research aims to address the problem of discriminating benign cysts from malignant masses in breast ultrasound (BUS) images based on Convolutional Neural Networks (CNNs). The biopsy-proven benchmarking dataset was built from 1422 patient cases containing a total of 2058 breast ultrasound masses, comprising 1370 benign and 688 malignant lesions. Three transferred models, InceptionV3, ResNet50, and Xception, a CNN model with three convolutional layers (CNN3), and traditional machine learning-based model with hand-crafted features were developed for differentiating benign and malignant tumors from BUS data. Cross-validation results have demonstrated that the transfer learning method outperformed the traditional machine learning model and the CNN3 model, where the transferred InceptionV3 achieved the best performance with an accuracy of 85.13% and an AUC of 0.91. Moreover, classification models based on deep features extracted from the transferred models were also built, where the model with combined features extracted from all three transferred models achieved the best performance with an accuracy of 89.44% and an AUC of 0.93 on an independent test set. © 2018 Ting Xiao et al.","","Biopsy; Breast Diseases; Breast Neoplasms; Cysts; Diagnosis, Computer-Assisted; Female; Humans; Machine Learning; Neural Networks (Computer); Retrospective Studies; accuracy; Article; breast tumor; cancer diagnosis; clinical feature; comparative study; controlled study; convolutional neural network; diagnostic test accuracy study; echomammography; human; human tissue; machine learning; major clinical study; retrospective study; sensitivity and specificity; transfer of learning; tumor classification; artificial neural network; biopsy; breast disease; breast tumor; computer assisted diagnosis; cyst; diagnostic imaging; female","Hindawi Limited","23146133","","","30035122","Article","Scopus","2-s2.0-85053266711"
"Sharma S.; Maheshwari S.; Shukla A.","Sharma, Sunil (57202742853); Maheshwari, Saumil (57200268867); Shukla, Anupam (57188965158)","57202742853; 57200268867; 57188965158","An intelligible deep convolution neural network based approach for classification of diabetic retinopathy","2018","Bio-Algorithms and Med-Systems","16","10.1515/bams-2018-0011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049185430&doi=10.1515%2fbams-2018-0011&partnerID=40&md5=3a499eba9103d1282b89f06b048400d1","ABV-Indian Institute of Information Technology and Management, Gwalior, Madhya Pradesh, 474015, India","Sharma S., ABV-Indian Institute of Information Technology and Management, Gwalior, Madhya Pradesh, 474015, India; Maheshwari S., ABV-Indian Institute of Information Technology and Management, Gwalior, Madhya Pradesh, 474015, India; Shukla A., ABV-Indian Institute of Information Technology and Management, Gwalior, Madhya Pradesh, 474015, India","Deep convolution neural networks (CNNs) have demonstrated their capabilities in modern-day medical image classification and analysis. The vital edge of deep CNN over other techniques is their ability to train without expert knowledge. Time bound detection is very beneficial for the early cure of disease. In this paper, a deep CNN architecture is proposed to classify nondiabetic retinopathy and diabetic retinopathy fundus eye images. Kaggle 2015 diabetic retinopathy competition dataset and messier experiment dataset are used in this study. The proposed deep CNN algorithm produces significant results with 93% area under the curve (AUC) for the Kaggle dataset and 91% AUC for the Messidor dataset. The sensitivity and specificity for the Kaggle dataset are 90.22% and 85.13%, respectively; the corresponding values of the Messidor dataset are 91.07% and 80.23%, respectively. The results outperformed many existing studies. The present architecture is a promising tool for diabetic retinopathy image classification. © 2018 Walter de Gruyter GmbH, Berlin/Boston 2018.","Deep convolution neural network; Diabetic retinopathy; Image classification; Image processing; Machine learning","Convolution; Deep neural networks; Eye protection; Medical imaging; Network architecture; Areas under the curves; Convolution neural network; Deep convolution neural network; Diabetic retinopathy; Images classification; Images processing; Machine-learning; Medical image analysis; Medical image classification; Network-based approach; accuracy; Article; artificial neural network; classification algorithm; diabetic retinopathy; eye fundus; image analysis; image processing; priority journal; sensitivity and specificity; Image classification","Walter de Gruyter GmbH","18959091","","","","Article","Scopus","2-s2.0-85049185430"
"Gheisari S.; Catchpoole D.; Charlton A.; Kennedy P.","Gheisari, Soheila (57190374903); Catchpoole, Daniel (6701637669); Charlton, Amanda (12766990500); Kennedy, Paul (55510406500)","57190374903; 6701637669; 12766990500; 55510406500","Convolutional deep belief network with feature encoding for classification of neuroblastoma histological images","2018","Journal of Pathology Informatics","12","10.4103/jpi.jpi_73_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053381270&doi=10.4103%2fjpi.jpi_73_17&partnerID=40&md5=ee2ebc41e8d6f8b60905a617c67c20f5","Centre for Artificial Intelligence, Faculty of Engineering and Information Technology, University of Technology, Sydney, Ultimo, 2007, NSW, Australia; Tumour Bank, Children's Cancer Research Unit, Kids Research Institute, Children's Hospital at Westmead, Locked Bag 4001, Westmead, NSW, Australia; LabPLUS, Department of Histopathology, Auckland District Health Board, Auckland City Hospital Grafton, New Zealand","Gheisari S., Centre for Artificial Intelligence, Faculty of Engineering and Information Technology, University of Technology, Sydney, Ultimo, 2007, NSW, Australia; Catchpoole D., Tumour Bank, Children's Cancer Research Unit, Kids Research Institute, Children's Hospital at Westmead, Locked Bag 4001, Westmead, NSW, Australia; Charlton A., LabPLUS, Department of Histopathology, Auckland District Health Board, Auckland City Hospital Grafton, New Zealand; Kennedy P., Centre for Artificial Intelligence, Faculty of Engineering and Information Technology, University of Technology, Sydney, Ultimo, 2007, NSW, Australia","Background: Neuroblastoma is the most common extracranial solid tumor in children younger than 5 years old. Optimal management of neuroblastic tumors depends on many factors including histopathological classification. The gold standard for classification of neuroblastoma histological images is visual microscopic assessment. In this study, we propose and evaluate a deep learning approach to classify high-resolution digital images of neuroblastoma histology into five different classes determined by the Shimada classification. Subjects and Methods: We apply a combination of convolutional deep belief network (CDBN) with feature encoding algorithm that automatically classifies digital images of neuroblastoma histology into five different classes. We design a three-layer CDBN to extract high-level features from neuroblastoma histological images and combine with a feature encoding model to extract features that are highly discriminative in the classification task. The extracted features are classified into five different classes using a support vector machine classifier. Data: We constructed a dataset of 1043 neuroblastoma histological images derived from Aperio scanner from 125 patients representing different classes of neuroblastoma tumors. Results: The weighted average F-measure of 86.01% was obtained from the selected high-level features, outperforming state-of-the-art methods. Conclusion: The proposed computer-aided classification system, which uses the combination of deep architecture and feature encoding to learn high-level features, is highly effective in the classification of neuroblastoma histological images. © 2018 Journal of Pathology Informatics.","Convolutional deep belief network; feature encoding; histological images; neuroblastoma","","Wolters Kluwer Medknow Publications","22295089","","","","Article","Scopus","2-s2.0-85053381270"
"Jaworek-Korjakowska J.","Jaworek-Korjakowska, Joanna (55255311300)","55255311300","A deep learning approach to vascular structure segmentation in dermoscopy colour images","2018","BioMed Research International","17","10.1155/2018/5049390","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062858736&doi=10.1155%2f2018%2f5049390&partnerID=40&md5=adddb2d849d6717c68735556fedba172","Department of Automatic Control and Robotics, AGH University of Science and Technology, Cracow, Poland","Jaworek-Korjakowska J., Department of Automatic Control and Robotics, AGH University of Science and Technology, Cracow, Poland","Background. Atypical vascular pattern is one of the most important features by differentiating between benign and malignant pigmented skin lesions. Detection and analysis of vascular structures is a necessary initial step for skin mole assessment; it is a prerequisite step to provide an accurate outcome for the widely used 7-point checklist diagnostic algorithm. Methods. In this research we present a fully automated machine learning approach for segmenting vascular structures in dermoscopy colour images. The U-Net architecture is based on convolutional networks and designed for fast and precise segmentation of images. After preprocessing the images are randomly divided into 146516 patches of 64 × 64 pixels each. Results. On the independent validation dataset including 74 images our implemented method showed high segmentation accuracy. For the U-Net convolutional neural network, an average DSC of 0.84, sensitivity 0.85, and specificity 0.81 has been achieved. Conclusion. Vascular structures due to small size and similarity to other local structures create enormous difficulties during the segmentation and assessment process. The use of advanced segmentation methods like deep learning, especially convolutional neural networks, has the potential to improve the accuracy of advanced local structure detection. Copyright © 2018 Joanna Jaworek-Korjakowska. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.","","Blood Vessels; Deep Learning; Dermoscopy; Humans; Image Processing, Computer-Assisted; Machine Learning; Neoplasms; Nevus; Specimen Handling; area under the curve; Article; artificial neural network; color; deep learning; dermoscopy colour image; epiluminescence microscopy; human; image analysis; image processing; image segmentation; machine learning; outcome assessment; receiver operating characteristic; sensitivity and specificity; skin blood vessel; validation process; blood vessel; diagnostic imaging; epiluminescence microscopy; neoplasm; nevus; pathophysiology; procedures; specimen handling","Hindawi Limited","23146133","","","30515404","Article","Scopus","2-s2.0-85062858736"
"Akimov D.A.; Pavelyev S.A.; Ivchenko V.D.","Akimov, Dmitry Aleksandrovich (55531854400); Pavelyev, Sergey Aleksandrovich (56664390400); Ivchenko, Valery Dmitrievich (56664128900)","55531854400; 56664390400; 56664128900","Automated prediction of critical states of turbogenerators during thermal expansion of a rotor and a stator based on a recurrent neural network","2018","International Journal of Engineering and Technology(UAE)","0","10.14419/ijet.v7i4.38.24316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059012363&doi=10.14419%2fijet.v7i4.38.24316&partnerID=40&md5=8d9ca137533364e8e9f86fc1840a0f6f","Russian Technological University (MIREA), Vernadsky Avenue, 78, Moscow, 119454, Russian Federation","Akimov D.A., Russian Technological University (MIREA), Vernadsky Avenue, 78, Moscow, 119454, Russian Federation; Pavelyev S.A., Russian Technological University (MIREA), Vernadsky Avenue, 78, Moscow, 119454, Russian Federation; Ivchenko V.D., Russian Technological University (MIREA), Vernadsky Avenue, 78, Moscow, 119454, Russian Federation","The present article is devoted to the development of a method and its software implementation for forecasting the critical states of a turbogenerator and its design elements that arise during starting-up & adjustment works and stopping a turbine. The method is based on a short-term prediction of the image of the spectrogram of vibrations during thermal expansion of the rotor and stator. The dependence of the increase in the vibration level in the spectrum with the failure of the turbogenerator design element is substantiated. The model takes into account the influence of thermal expansion on critical states. The technique of training a deep neural network is given in the classification of thermal influences on the level of vibration while a spectrogram receiving. For machine learning of a neural network in software, a recurrent autoencoder is used. The technique of operation is with a time sequence of spectrograms. To test the model is introduced the concept of semantic quality of clustering. Semantic quality, determined as the degree of correspondence between the information that can be extracted from the obtained cluster structure and the formalized presentation of the user. The interpretation of the results of the discovery of turbine generator defects is presented. © 2018 Authors.","Critical state; Deep machine training; Forecasting; Heat effects assessment; Neural network; Recurrent neural network; Rnn; Rotor vibrations; Thermal expansion; Thermal influence; Trouble effects evaluation; Troubleshooting; Turbogenerators; Vibrodiagnostics","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85059012363"
"Nagasawa T.; Tabuchi H.; Masumoto H.; Enno H.; Niki M.; Ohsugi H.; Mitamura Y.","Nagasawa, Toshihiko (35311235900); Tabuchi, Hitoshi (36810783800); Masumoto, Hiroki (57201984138); Enno, Hiroki (57195449818); Niki, Masanori (55211236100); Ohsugi, Hideharu (14060992900); Mitamura, Yoshinori (34572364500)","35311235900; 36810783800; 57201984138; 57195449818; 55211236100; 14060992900; 34572364500","Accuracy of deep learning, a machine learning technology, using ultra-wide-field fundus ophthalmoscopy for detecting idiopathic macular holes","2018","PeerJ","31","10.7717/peerj.5696","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055711232&doi=10.7717%2fpeerj.5696&partnerID=40&md5=77f1c6cf5002d451cd124a8e5f4daec3","Department of Ophthalmology, Tsukazaki Hospital, Himeji City, Hyogo Prefecture, Japan; Rist Inc., Tokyo, Japan; Department of Ophthalmology, Institute of Biomedical Sciences, Tokushima University, Tokushima City, Tokushima Prefecture, Japan","Nagasawa T., Department of Ophthalmology, Tsukazaki Hospital, Himeji City, Hyogo Prefecture, Japan; Tabuchi H., Department of Ophthalmology, Tsukazaki Hospital, Himeji City, Hyogo Prefecture, Japan; Masumoto H., Department of Ophthalmology, Tsukazaki Hospital, Himeji City, Hyogo Prefecture, Japan; Enno H., Rist Inc., Tokyo, Japan; Niki M., Department of Ophthalmology, Institute of Biomedical Sciences, Tokushima University, Tokushima City, Tokushima Prefecture, Japan; Ohsugi H., Department of Ophthalmology, Tsukazaki Hospital, Himeji City, Hyogo Prefecture, Japan; Mitamura Y., Department of Ophthalmology, Institute of Biomedical Sciences, Tokushima University, Tokushima City, Tokushima Prefecture, Japan","We aimed to investigate the detection of idiopathic macular holes (MHs) using ultra-wide-field fundus images (Optos) with deep learning, which is a machine learning technology. The study included 910 Optos color images (715 normal images, 195 MH images). Of these 910 images, 637 were learning images (501 normal images, 136 MH images) and 273 were test images (214 normal images and 59 MH images). We conducted training with a deep convolutional neural network (CNN) using the images and constructed a deep-learning model. The CNN exhibited high sensitivity of 100% (95% confidence interval CI [93.5–100%]) and high specificity of 99.5% (95% CI [97.1–99.9%]). The area under the curve was 0.9993 (95% CI [0.9993–0.9994]). Our findings suggest that MHs could be diagnosed using an approach involving wide angle camera images and deep learning. Copyright 2018 Nagasawa et al.","Algorithm; Convolutional neural network; Deep learning; Macular holes; Optos; Wide- angle camera; Wide-angle ocular fundus camera","Article; convolutional neural network; machine learning; measurement accuracy; ophthalmologist; ophthalmoscopy; optical coherence tomography; outcome assessment; retina image; retina macula hole; sensitivity and specificity; swept source optical coherence tomography; training","PeerJ Inc.","21678359","","","","Article","Scopus","2-s2.0-85055711232"
"Kiran Kumar M.; Sreedevi M.; Reddy Y.C.A.P.","Kiran Kumar, M. (57714013400); Sreedevi, M. (56582077000); Reddy, Y.C.A. Padmanabha (56629063900)","57714013400; 56582077000; 56629063900","Survey on machine learning algorithms for liver disease diagnosis and prediction","2018","International Journal of Engineering and Technology(UAE)","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075219640&partnerID=40&md5=759fe3b2b18b019381cf9da2a6a114a7","Department of CSE, Madanapalle Institute of Technology and Science, India","Kiran Kumar M., Department of CSE, Madanapalle Institute of Technology and Science, India; Sreedevi M., Department of CSE, Madanapalle Institute of Technology and Science, India; Reddy Y.C.A.P., Department of CSE, Madanapalle Institute of Technology and Science, India","Machine learning plays a vital role in health care industry. It is very important in Computer Aided Diagnosis. Computer Aided Diagnosis is a quickly developing dynamic region of research in medicinal industry. The current specialists in machine learning guarantee the enhanced precision of discernment and analysis of diseases. The computers are empowered to think by creating knowledge by learning. This procedure enables the computers to self-learn individually without being explicitly programed by the programmer. There are numerous sorts of Machine Learning Techniques and which are utilized to classify the data sets. They are Supervised, Unsupervised and Semi-Supervised, Reinforcement, deep learning algorithms. The principle point of this paper is to give comparative analysis of supervised learning algorithms in medicinal area and few of the techniques utilized as a part of liver disease prediction. © 2018 M. Kiran Kumar et al.","Liver disease; Machine learning techniques; Medical data mining; Supervised learning","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85075219640"
"Song Q.; Zhang P.; Qi C.","Song, Qing (55501700000); Zhang, Pengzhou (55433896700); Qi, Chenglin (57206474545)","55501700000; 55433896700; 57206474545","Chinese relation extraction method based on dependency parsing and sentence segmentation","2018","IPPTA: Quarterly Journal of Indian Pulp and Paper Technical Association","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061755929&partnerID=40&md5=296033c3249b6bcb0a6b86e97d612215","New Media Institute, Communication University of China, Beijing, 100024, China; Science School, Communication University of China, Beijing, 100024, China","Song Q., New Media Institute, Communication University of China, Beijing, 100024, China; Zhang P., Science School, Communication University of China, Beijing, 100024, China; Qi C., New Media Institute, Communication University of China, Beijing, 100024, China","Relation extraction is the key process of information extraction. The primary goal is to identify and extract the semantic relations between named entities from the sentence. In the earlier stage, the knowledge-based methods have been widely used, hand-crafted extraction patterns were made by experts. At present, the supervised approach is the most commonly used. This kind of approach mainly used in particular field, and use artificially annotation corpora as training data. Turning the problem of extraction into a classification problem, using traditional machine learning methods or the Deep Neural Networks to complete the identification and extraction of specific types of relations. However, for the relationship extraction in the open field, the establishment of relational system and the artificial annotation training corpora have become very difficult. Therefore, open relation extraction has become a research hotspot in recent years. Most of the existing open relation extraction systems are mainly focus on the field of English. The research is rare in Chinese. Therefore, this paper proposes a new approach of the open Chinese relation extraction. Firstly, judging and completing the segmentation of complex sentences based on punctuation, then the error rates of using syntactic parsing tool for complex sentence will be reduced; Secondly, based on the dependency analysis tools, we use an automatic seed set generation method of bootstrapping to obtain entity extraction results. © Indian Pulp and Paper Technical Association 2018. All rights reserved.","Complex sentence segmentation; Open Chinese Relation extraction; Syntactic Analysis","Artificial Intelligence; Chinese; Classification; Education; Extraction; Methods; Research; Segmentation; Artificial intelligence; Complex networks; Context free grammars; Deep neural networks; Knowledge based systems; Semantics; Syntactics; Complex sentences; Extraction patterns; Knowledge-based methods; Machine learning methods; Relation extraction; Relationship extraction; Sentence segmentation; Syntactic analysis; Data mining","Indian Pulp and Paper Technical Association","03795462","","IPPTD","","Article","Scopus","2-s2.0-85061755929"
"Chandni K.; Pandya M.; Jardosh S.","Chandni, Khatri (57203949466); Pandya, Mrudang (57188555740); Jardosh, Sunil (24479536500)","57203949466; 57188555740; 24479536500","Deep learning approaches for protein structure prediction","2018","International Journal of Engineering and Technology(UAE)","1","10.14419/ijet.v7i4.5.20037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053716782&doi=10.14419%2fijet.v7i4.5.20037&partnerID=40&md5=5429d66d1caccf435e9ed0683f639908","Department of Information Technology, CSPIT Charusat, Anand, India; Information Technology Department, CSPIT Charusat, Anand, India; Principal Software Engineer Progress Software, Hyderabad, India","Chandni K., Department of Information Technology, CSPIT Charusat, Anand, India; Pandya M., Information Technology Department, CSPIT Charusat, Anand, India; Jardosh S., Principal Software Engineer Progress Software, Hyderabad, India","In recent years, Machine Learning techniques that are based on Deep Learning networks that show a great promise in research communities.Successful methods for deep learning involve Artificial Neural Networks and Machine Learning. Deep Learning solves severa problems in bioinformatics. Protein Structure Prediction is one of the most important fields that can be solving using Deep Learning approaches.These protein are categorized on basis of occurrence of amino acid patterns occur to extract the feature. In these paper aimed to review work based on protein structure prediction solve using Deep Learning Networks. Objective is to review motivate and facilitatethese deep learn the network for predicting protein sequences using Deep Learning. © 2018 Authors.","Bioinformatics; DeepLearning; Protein contact mapping; Protein docking; Protein folding; Protein structure prediction; Protein-protein interactions","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85053716782"
"Alom M.Z.; Sidike P.; Hasan M.; Taha T.M.; Asari V.K.","Alom, Md Zahangir (35566178100); Sidike, Paheding (56585990900); Hasan, Mahmudul (57217487575); Taha, Tarek M. (23013518500); Asari, Vijayan K. (6701420692)","35566178100; 56585990900; 57217487575; 23013518500; 6701420692","Handwritten Bangla Character Recognition Using the State-of-the-Art Deep Convolutional Neural Networks","2018","Computational Intelligence and Neuroscience","61","10.1155/2018/6747098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053386863&doi=10.1155%2f2018%2f6747098&partnerID=40&md5=226e72af1f3e7ffd28d557585b57e5e4","Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, United States; Department of Earth and Atmospheric Sciences, Saint Louis University, St. Louis, MO, United States; Comcast Labs, Washington, DC, United States","Alom M.Z., Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, United States; Sidike P., Department of Earth and Atmospheric Sciences, Saint Louis University, St. Louis, MO, United States; Hasan M., Comcast Labs, Washington, DC, United States; Taha T.M., Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, United States; Asari V.K., Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, United States","In spite of advances in object recognition technology, handwritten Bangla character recognition (HBCR) remains largely unsolved due to the presence of many ambiguous handwritten characters and excessively cursive Bangla handwritings. Even many advanced existing methods do not lead to satisfactory performance in practice that related to HBCR. In this paper, a set of the state-of-the-art deep convolutional neural networks (DCNNs) is discussed and their performance on the application of HBCR is systematically evaluated. The main advantage of DCNN approaches is that they can extract discriminative features from raw data and represent them with a high degree of invariance to object distortions. The experimental results show the superior performance of DCNN models compared with the other popular object recognition approaches, which implies DCNN can be a good candidate for building an automatic HBCR system for practical applications. © 2018 Md Zahangir Alom et al.","","Handwriting; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Convolution; Deep neural networks; Neural networks; Object recognition; Deep convolutional neural networks; Discriminative features; Hand-written characters; Handwritten bangla; State of the art; artificial neural network; automated pattern recognition; evaluation study; handwriting; human; image processing; machine learning; procedures; Character recognition","Hindawi Limited","16875265","","","30224913","Article","Scopus","2-s2.0-85053386863"
"Diggins K.E.; Gandelman J.S.; Roe C.E.; Irish J.M.","Diggins, Kirsten E. (56659349700); Gandelman, Jocelyn S. (57201983531); Roe, Caroline E. (57204176340); Irish, Jonathan M. (7101847425)","56659349700; 57201983531; 57204176340; 7101847425","Generating Quantitative Cell Identity Labels with Marker Enrichment Modeling (MEM)","2018","Current Protocols in Cytometry","13","10.1002/cpcy.34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054888494&doi=10.1002%2fcpcy.34&partnerID=40&md5=2dce9cb3ec636e35c866fd4af9d1f11f","Department of Cell and Developmental Biology, Vanderbilt University, Nashville, TN, United States; Vanderbilt-Ingram Cancer Center, Vanderbilt University Medical Center, Nashville, TN, United States; Department of Pathology, Microbiology and Immunology, Vanderbilt University Medical Center, Nashville, TN, United States","Diggins K.E., Department of Cell and Developmental Biology, Vanderbilt University, Nashville, TN, United States, Vanderbilt-Ingram Cancer Center, Vanderbilt University Medical Center, Nashville, TN, United States; Gandelman J.S., Vanderbilt-Ingram Cancer Center, Vanderbilt University Medical Center, Nashville, TN, United States, Department of Pathology, Microbiology and Immunology, Vanderbilt University Medical Center, Nashville, TN, United States; Roe C.E., Department of Cell and Developmental Biology, Vanderbilt University, Nashville, TN, United States, Vanderbilt-Ingram Cancer Center, Vanderbilt University Medical Center, Nashville, TN, United States; Irish J.M., Department of Cell and Developmental Biology, Vanderbilt University, Nashville, TN, United States, Vanderbilt-Ingram Cancer Center, Vanderbilt University Medical Center, Nashville, TN, United States, Department of Pathology, Microbiology and Immunology, Vanderbilt University Medical Center, Nashville, TN, United States","Multiplexed single-cell experimental techniques like mass cytometry measure 40 or more features and enable deep characterization of well-known and novel cell populations. However, traditional data analysis techniques rely extensively on human experts or prior knowledge, and novel machine learning algorithms may generate unexpected population groupings. Marker enrichment modeling (MEM) creates quantitative identity labels based on features enriched in a population relative to a reference. While developed for cell type analysis, MEM labels can be generated for a wide range of multidimensional data types, and MEM works effectively with output from expert analysis and diverse machine learning algorithms. MEM is implemented as an R package and includes three steps: (1) calculation of MEM values that quantify each feature's relative enrichment in the population, (2) reporting of MEM labels as a heatmap or as a text label, and (3) quantification of MEM label similarity between populations. The protocols here show MEM analysis using datasets from immunology and oncology. These MEM implementations provide a way to characterize population identity and novelty in the context of computational and expert analyses. © 2018 by John Wiley & Sons, Inc. Copyright © 2018 John Wiley & Sons, Inc.","bioinformatics; cell identity; computational biology; cytotype; flow cytometry; machine learning; marker enrichment modeling; mass cytometry; MEM; single cell","Animals; Electronic Data Processing; Flow Cytometry; Humans; Machine Learning; Models, Theoretical; article; bioinformatics; biology; calculation; cancer model; cell population; cytotype; data analysis; flow cytometry; human; human experiment; immunology; machine learning; mass cytometry; animal; flow cytometry; information processing; procedures; theoretical model","John Wiley and Sons Inc.","19349297","","","29345329","Article","Scopus","2-s2.0-85054888494"
"Keshavarzi M.; Goehring T.; Zakis J.; Turner R.E.; Moore B.C.J.","Keshavarzi, Mahmoud (55657249300); Goehring, Tobias (57189595633); Zakis, Justin (15844607200); Turner, Richard E. (57214257840); Moore, Brian C. J. (57203291320)","55657249300; 57189595633; 15844607200; 57214257840; 57203291320","Use of a Deep Recurrent Neural Network to Reduce Wind Noise: Effects on Judged Speech Intelligibility and Sound Quality","2018","Trends in Hearing","15","10.1177/2331216518770964","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054646886&doi=10.1177%2f2331216518770964&partnerID=40&md5=cadb25a68d3b22c215f4292f3d6ed940","Department of Psychology, University of Cambridge, United Kingdom; MRC Cognition and Brain Sciences Unit, University of Cambridge, United Kingdom; Blamey and Saunders Hearing Pty Ltd, Australia; Department of Engineering, University of Cambridge, Cambridge, United Kingdom","Keshavarzi M., Department of Psychology, University of Cambridge, United Kingdom; Goehring T., MRC Cognition and Brain Sciences Unit, University of Cambridge, United Kingdom; Zakis J., Blamey and Saunders Hearing Pty Ltd, Australia; Turner R.E., Department of Engineering, University of Cambridge, Cambridge, United Kingdom; Moore B.C.J., Department of Psychology, University of Cambridge, United Kingdom","Despite great advances in hearing-aid technology, users still experience problems with noise in windy environments. The potential benefits of using a deep recurrent neural network (RNN) for reducing wind noise were assessed. The RNN was trained using recordings of the output of the two microphones of a behind-the-ear hearing aid in response to male and female speech at various azimuths in the presence of noise produced by wind from various azimuths with a velocity of 3 m/s, using the “clean” speech as a reference. A paired-comparison procedure was used to compare all possible combinations of three conditions for subjective intelligibility and for sound quality or comfort. The conditions were unprocessed noisy speech, noisy speech processed using the RNN, and noisy speech that was high-pass filtered (which also reduced wind noise). Eighteen native English-speaking participants were tested, nine with normal hearing and nine with mild-to-moderate hearing impairment. Frequency-dependent linear amplification was provided for the latter. Processing using the RNN was significantly preferred over no processing by both subject groups for both subjective intelligibility and sound quality, although the magnitude of the preferences was small. High-pass filtering (HPF) was not significantly preferred over no processing. Although RNN was significantly preferred over HPF only for sound quality for the hearing-impaired participants, for the results as a whole, there was a preference for RNN over HPF. Overall, the results suggest that reduction of wind noise using an RNN is possible and might have beneficial effects when used in hearing aids. © The Author(s) 2018.","hearing aids; machine learning; neural networks; speech intelligibility and sound quality; wind noise","Acoustics; Auditory Threshold; Female; Hearing Aids; Hearing Loss; Humans; Male; Neural Networks (Computer); Noise; Random Allocation; Speech Acoustics; Speech Intelligibility; Speech Perception; Wind; Young Adult; acoustics; artificial neural network; auditory threshold; female; hearing aid; hearing impairment; human; male; noise; prevention and control; randomization; speech; speech intelligibility; speech perception; wind; young adult","SAGE Publications Inc.","23312165","","","29708061","Article","Scopus","2-s2.0-85054646886"
"Anandan R.; Bhyrapuneni S.; Kalaivani K.; Swaminathan P.","Anandan, R. (55418360900); Bhyrapuneni, Srikanth (57202505540); Kalaivani, K. (57356275100); Swaminathan, P. (55327535300)","55418360900; 57202505540; 57356275100; 55327535300","A survey on big data analytics with deep learning in text using machine learning mechanisms","2018","International Journal of Engineering and Technology(UAE)","2","10.14419/ijet.v7i2.21.12398","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048521256&doi=10.14419%2fijet.v7i2.21.12398&partnerID=40&md5=55af44bf37be960dec1773601e148ff7","Department of Computer Science and Engineering, Vels Institute of Science, Technology and Advanced Studies(VISTAS), Chennai, India","Anandan R., Department of Computer Science and Engineering, Vels Institute of Science, Technology and Advanced Studies(VISTAS), Chennai, India; Bhyrapuneni S., Department of Computer Science and Engineering, Vels Institute of Science, Technology and Advanced Studies(VISTAS), Chennai, India; Kalaivani K., Department of Computer Science and Engineering, Vels Institute of Science, Technology and Advanced Studies(VISTAS), Chennai, India; Swaminathan P., Department of Computer Science and Engineering, Vels Institute of Science, Technology and Advanced Studies(VISTAS), Chennai, India","Big Data Analytics and Deep Learning are two immense purpose of meeting of data science. Big Data has ended up being major a tantamount number of affiliations both open and private have been gathering huge measures of room specific information, which can contain enduring information about issues, for instance, national cognizance, motorized security, coercion presentation, advancing, and healing informatics. Relationship, for instance, Microsoft and Google are researching wide volumes of data for business examination and decisions, influencing existing and future progression. Critical Learning figuring's isolate odd state, complex reflections as data outlines through another levelled learning practice. Complex reflections are learnt at a given level in setting of all around less asking for thoughts figured in the past level in the dynamic framework. An indispensable favoured perspective of Profound Learning is the examination and culture of beast measures of unconfirmed data, making it a fundamental contraption for Great Statistics Analytics where offensive data is, everything seen as, unlabelled and un-arranged. In the present examination, we investigate how Deep Learning can be used for keeping an eye out for some essential issues in Big Data Analytics, including removing complex cases from Big volumes of information, semantic asking for, information naming, smart data recovery, and streamlining discriminative errands. Deep learning using Machine Learning(ML) is continuously unleashing its power in a wide range of applications. It has been pushed to the front line as of late mostly attributable to the advert of huge information. ML counts have never been remarkable ensured while tried by gigantic data. Gigantic data engages ML counts to uncover more fine-grained cases and make more advantageous and correct gauges than whenever in late memory with deep learning; on the other hand, it exhibits genuine challenges to deep learning in ML, for instance, show adaptability and appropriated enlisting. In this paper, we introduce a framework of Deep learning in ML on big data (DLiMLBiD) to guide the discussion of its opportunities and challenges. In this paper, different machine learning algorithms have been talked about. These calculations are utilized for different purposes like information mining, picture handling, prescient examination, and so forth to give some examples. The fundamental favourable position of utilizing machine learning is that, once a calculation realizes what to do with information, it can do its work consequently. In this paper we are providing the review of different Deep learning in text using Machine Learning and Big data methods. © 2018 Authors.","Big data; Deep learning; Machine learning; Text extraction","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85048521256"
"Liang L.; Liu M.; Martin C.; Sun W.","Liang, Liang (36622308500); Liu, Minliang (57193857565); Martin, Caitlin (55483470300); Sun, Wei (27467836000)","36622308500; 57193857565; 55483470300; 27467836000","A deep learning approach to estimate stress distribution: a fast and accurate surrogate of finite-element analysis","2018","Journal of the Royal Society Interface","273","10.1098/rsif.2017.0844","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046446006&doi=10.1098%2frsif.2017.0844&partnerID=40&md5=b59bf68511cf1c195f938d768dbd31bf","Tissue Mechanics Laboratory, Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology, Emory University, Technology Enterprise Park, Room 206, 387 Technology Circle, Atlanta, 30313-2412, GA, United States","Liang L., Tissue Mechanics Laboratory, Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology, Emory University, Technology Enterprise Park, Room 206, 387 Technology Circle, Atlanta, 30313-2412, GA, United States; Liu M., Tissue Mechanics Laboratory, Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology, Emory University, Technology Enterprise Park, Room 206, 387 Technology Circle, Atlanta, 30313-2412, GA, United States; Martin C., Tissue Mechanics Laboratory, Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology, Emory University, Technology Enterprise Park, Room 206, 387 Technology Circle, Atlanta, 30313-2412, GA, United States; Sun W., Tissue Mechanics Laboratory, Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology, Emory University, Technology Enterprise Park, Room 206, 387 Technology Circle, Atlanta, 30313-2412, GA, United States","Structural finite-element analysis (FEA) has been widely used to study the biomechanics of human tissues and organs, as well as tissue–medical device interactions, and treatment strategies. However, patient-specific FEA models usually require complex procedures to set up and long computing times to obtain final simulation results, preventing prompt feedback to clinicians in time-sensitive clinical applications. In this study, by using machine learning techniques, we developed a deep learning (DL) model to directly estimate the stress distributions of the aorta. The DL model was designed and trained to take the input of FEA and directly output the aortic wall stress distributions, bypassing the FEA calculation process. The trained DL model is capable of predicting the stress distributions with average errors of 0.492% and 0.891% in the Von Mises stress distribution and peak Von Mises stress, respectively. This study marks, to our knowledge, the first study that demonstrates the feasibility and great potential of using the DL technique as a fast and accurate surrogate of FEA for stress analysis. © 2018 The Author(s) Published by the Royal Society. All rights reserved.","Deep learning; Finite-element analysis; Neural network; Stress analysis","Aorta; Computer Simulation; Deep Learning; Finite Element Analysis; Humans; Models, Cardiovascular; Stress, Mechanical; Biomedical equipment; Blood vessels; Computer aided engineering; Deep learning; Neural networks; Stress analysis; Stress concentration; Tissue; Tissue engineering; Clinical application; Complex procedure; FEA calculations; Learning approach; Machine learning techniques; Patient specific; Structural finite elements; Von Mises stress distribution; aortic wall; article; calculation; error; feasibility study; finite element analysis; human; machine learning; nervous system; wall stress; aorta; biological model; computer simulation; finite element analysis; mechanical stress; pathophysiology; Finite element method","Royal Society Publishing","17425689","","","29367242","Article","Scopus","2-s2.0-85046446006"
"Ojha R.K.; Nayak B.","Ojha, Rajesh Kumar (57205196584); Nayak, Bhagirathi (57205198391)","57205196584; 57205198391","Application of machine learning in collaborative filtering recommender systems","2018","International Journal of Engineering and Technology(UAE)","2","10.14419/ijet.v7i4.38.24445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058982559&doi=10.14419%2fijet.v7i4.38.24445&partnerID=40&md5=ef610e5940baa71a1d31f4618daf61fb","Sri Sri University, Odisha, India","Ojha R.K., Sri Sri University, Odisha, India; Nayak B., Sri Sri University, Odisha, India","Recommender systems are one of the important methodologies in machine learning technologies, which is using in current business scenario. This article proposes a book recommender system using deep learning technique and k-Nearest Neighbors (k-NN) classification. Deep learning technique is one of the most effective techniques in the field of recommender systems. Recommender systems are intelligent systems in Machine Learning that can make difference from other algorithms. This article considers application of Machine Learning Technology and we present an approach based a recommender system. We used k-Nearest Neighbors classification algorithm of deep learning technique to classify users based book recommender system. We analyze the traditional collaborative filtering with our methodology and also to compare with them. Our outcomes display the projected algorithm is more precise over the existing algorithm, it also consumes less time and reliable than the existing methods. © 2018 Authors.","Classification; Collaborative filtering; K-Nearest Neighbors; Recommender systems (RS)","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85058982559"
"Khan M.A.; Karim M.R.; Kim Y.","Khan, Muhammad Ashfaq (57203924131); Karim, Md. Rezaul (57549413100); Kim, Yangwoo (22333904700)","57203924131; 57549413100; 22333904700","A two-stage big data analytics framework with real world applications using spark machine learning and long short-term memory network","2018","Symmetry","44","10.3390/sym10100485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055729049&doi=10.3390%2fsym10100485&partnerID=40&md5=245fbf9a952eb462edcb47b8898e0906","Department of Information and Communication Engineering, Dongguk University, 30 Pildong-ro1-gil, Jung-gu, Seoul, 100-715, South Korea; Fraunhofer FIT, Birlinghoven, Sankt Augustin, 53754, Germany; Chair of Computer Science 5: Information Systems, RWTH Aachen University, Aachen, 52074, Germany","Khan M.A., Department of Information and Communication Engineering, Dongguk University, 30 Pildong-ro1-gil, Jung-gu, Seoul, 100-715, South Korea; Karim M.R., Fraunhofer FIT, Birlinghoven, Sankt Augustin, 53754, Germany, Chair of Computer Science 5: Information Systems, RWTH Aachen University, Aachen, 52074, Germany; Kim Y., Department of Information and Communication Engineering, Dongguk University, 30 Pildong-ro1-gil, Jung-gu, Seoul, 100-715, South Korea","Every day we experience unprecedented data growth from numerous sources, which contribute to big data in terms of volume, velocity, and variability. These datasets again impose great challenges to analytics framework and computational resources, making the overall analysis difficult for extracting meaningful information in a timely manner. Thus, to harness these kinds of challenges, developing an efficient big data analytics framework is an important research topic. Consequently, to address these challenges by exploiting non-linear relationships from very large and high-dimensional datasets, machine learning (ML) and deep learning (DL) algorithms are being used in analytics frameworks. Apache Spark has been in use as the fastest big data processing arsenal, which helps to solve iterative ML tasks, using distributed ML library called Spark MLlib. Considering real-world research problems, DL architectures such as Long Short-Term Memory (LSTM) is an effective approach to overcoming practical issues such as reduced accuracy, long-term sequence dependency, and vanishing and exploding gradient in conventional deep architectures. In this paper, we propose an efficient analytics framework, which is technically a progressive machine learning technique merged with Spark-based linear models, Multilayer Perceptron (MLP) and LSTM, using a two-stage cascade structure in order to enhance the predictive accuracy. Our proposed architecture enables us to organize big data analytics in a scalable and efficient way. To show the effectiveness of our framework, we applied the cascading structure to two different real-life datasets to solve a multiclass and a binary classification problem, respectively. Experimental results show that our analytical framework outperforms state-of-the-art approaches with a high-level of classification accuracy. © 2018 by the authors.","Big data; Big data analytics; Deep learning; Long short-term memory; Machine learning; Multilayer perceptron; Spark MLlib","","MDPI AG","20738994","","","","Article","Scopus","2-s2.0-85055729049"
"Bandi R.; Amudhavel J.","Bandi, Raswitha (57195681690); Amudhavel, J. (36781870300)","57195681690; 36781870300","Object recognition using Keras with backend tensor flow","2018","International Journal of Engineering and Technology(UAE)","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049632921&partnerID=40&md5=c569ca231948c54e48d5cfd9303e5469","Department of Computer Science and Engineering, K L University, Guntur, Andhra Pradesh, India; Department of Information Technology, MLR Institute of Technology, Hyderabad, India","Bandi R., Department of Computer Science and Engineering, K L University, Guntur, Andhra Pradesh, India, Department of Information Technology, MLR Institute of Technology, Hyderabad, India; Amudhavel J., Department of Computer Science and Engineering, K L University, Guntur, Andhra Pradesh, India","Now a day's Machine Learning Plays an important role in computer vision, object recognition and image classification. Recognizing objects in images is an interesting thing, this recognization can be done easily by human beings but the computer cannot. The Problem with traditional neural networks is object recognition. So, to avoid difficulties in recognition of objects in images the deep neural networks especially Tensor flow under Keras Library is used and it will improve the Accuracy while recognizing objects. In this paper we present object recognition using Keras Library with backend Tensor flow. © 2018 Authors.","Deep neural networks; Keras Library; Machine learning; Tensor flow","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85049632921"
"Naga Bushanam V.; Reddy C.S.","Naga Bushanam, V. (57201425437); Reddy, Ch. Satyananda (36806533900)","57201425437; 36806533900","An Efficient CNN a deep learning approach applied on the image matching context","2018","International Journal of Engineering and Technology(UAE)","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082343375&partnerID=40&md5=0685aedba71cf4b07513f019fc4d07bb","Department of CSSE, Andhra University, A.P, India","Naga Bushanam V., Department of CSSE, Andhra University, A.P, India; Reddy C.S., Department of CSSE, Andhra University, A.P, India","Image matching is a quite challenging task to identify matching images in the data. There are multiple methods in computer vision techniques such as histogram-based algorithms, colour or edge based algorithms, textual based features, SIFT and Surf algorithms which will help to identify similar images. Here in our paper we are addressing an industrial problem to provide the better solution where US multinational courier delivery service facing challenges in delivering the products where labels/tags and bar codes of the products are missed while delivering to the customers and customers comes with the product image and with some information about the product. The job is to map the user or customer product information with the existing missed products. The advances in computer science and availability of GPU Machines, the problem will be addressed, and solutions can be automated using deep learning approaches. The paper describes the solution of matching the solution accurately and comparing the solution with the existing classical computer vision algorithms. © 2018 Authors.","Computer vision; Deep learning; Image matching; Image search","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082343375"
"Yu Y.; Liu F.","Yu, Yunlong (57188735471); Liu, Fuxian (55553732044)","57188735471; 55553732044","A Two-Stream Deep Fusion Framework for High-Resolution Aerial Scene Classification","2018","Computational Intelligence and Neuroscience","114","10.1155/2018/8639367","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045903239&doi=10.1155%2f2018%2f8639367&partnerID=40&md5=8d94cbd9a8c217baf8eaa7a209a0e03b","Air Defense and Anti-Missile College, Air Force Engineering University, Xi'an, 710051, China","Yu Y., Air Defense and Anti-Missile College, Air Force Engineering University, Xi'an, 710051, China; Liu F., Air Defense and Anti-Missile College, Air Force Engineering University, Xi'an, 710051, China","One of the challenging problems in understanding high-resolution remote sensing images is aerial scene classification. A well-designed feature representation method and classifier can improve classification accuracy. In this paper, we construct a new two-stream deep architecture for aerial scene classification. First, we use two pretrained convolutional neural networks (CNNs) as feature extractor to learn deep features from the original aerial image and the processed aerial image through saliency detection, respectively. Second, two feature fusion strategies are adopted to fuse the two different types of deep convolutional features extracted by the original RGB stream and the saliency stream. Finally, we use the extreme learning machine (ELM) classifier for final classification with the fused features. The effectiveness of the proposed architecture is tested on four challenging datasets: UC-Merced dataset with 21 scene categories, WHU-RS dataset with 19 scene categories, AID dataset with 30 scene categories, and NWPU-RESISC45 dataset with 45 challenging scene categories. The experimental results demonstrate that our architecture gets a significant classification accuracy improvement over all state-of-The-Art references. © 2018 Yunlong Yu and Fuxian Liu.","","Algorithms; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Remote Sensing Technology; Antennas; Architecture; Classifiers; Convolution; Learning systems; Network architecture; Neural networks; Remote sensing; Uranium compounds; Classification accuracy; Convolutional neural network; Deep architectures; Extreme learning machine; Feature representation; High resolution remote sensing images; Proposed architectures; Scene classification; algorithm; artificial neural network; image processing; machine learning; procedures; remote sensing; Classification (of information)","Hindawi Limited","16875265","","","29581722","Article","Scopus","2-s2.0-85045903239"
"Kalscheur M.M.; Kipp R.T.; Tattersall M.C.; Mei C.; Buhr K.A.; Demets D.L.; Field M.E.; Eckhardt L.L.; Page C.D.","Kalscheur, Matthew M. (49861470500); Kipp, Ryan T. (36803269000); Tattersall, Matthew C. (50961777500); Mei, Chaoqun (57189891548); Buhr, Kevin A. (16401063300); Demets, David L. (55167554400); Field, Michael E. (36759613400); Eckhardt, Lee L. (8362056800); Page, C. David (36922487700)","49861470500; 36803269000; 50961777500; 57189891548; 16401063300; 55167554400; 36759613400; 8362056800; 36922487700","Machine Learning Algorithm Predicts Cardiac Resynchronization Therapy Outcomes: Lessons from the COMPANION Trial","2018","Circulation: Arrhythmia and Electrophysiology","77","10.1161/CIRCEP.117.005499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055168796&doi=10.1161%2fCIRCEP.117.005499&partnerID=40&md5=7de72b656fb2b7cedbbd1dbbaa49659f","Division of Cardiovascular Medicine, Department of Medicine, School of Medicine and Public Health, Mail Code 3248, 600 Highland Ave, Madison, 53792, WI, United States; Department of Biostatistics and Medical Informatics; University of Wisconsin, Institute for Clinical and Translational Research, United States; Department of Computer Sciences, University of Wisconsin-Madison, United States","Kalscheur M.M., Division of Cardiovascular Medicine, Department of Medicine, School of Medicine and Public Health, Mail Code 3248, 600 Highland Ave, Madison, 53792, WI, United States; Kipp R.T., Division of Cardiovascular Medicine, Department of Medicine, School of Medicine and Public Health, Mail Code 3248, 600 Highland Ave, Madison, 53792, WI, United States; Tattersall M.C., Division of Cardiovascular Medicine, Department of Medicine, School of Medicine and Public Health, Mail Code 3248, 600 Highland Ave, Madison, 53792, WI, United States; Mei C., Department of Biostatistics and Medical Informatics, University of Wisconsin, Institute for Clinical and Translational Research, United States; Buhr K.A., Department of Biostatistics and Medical Informatics; Demets D.L., Department of Biostatistics and Medical Informatics; Field M.E., Division of Cardiovascular Medicine, Department of Medicine, School of Medicine and Public Health, Mail Code 3248, 600 Highland Ave, Madison, 53792, WI, United States; Eckhardt L.L., Division of Cardiovascular Medicine, Department of Medicine, School of Medicine and Public Health, Mail Code 3248, 600 Highland Ave, Madison, 53792, WI, United States; Page C.D., Department of Biostatistics and Medical Informatics, Department of Computer Sciences, University of Wisconsin-Madison, United States","Background: Cardiac resynchronization therapy (CRT) reduces morbidity and mortality in heart failure patients with reduced left ventricular function and intraventricular conduction delay. However, individual outcomes vary significantly. This study sought to use a machine learning algorithm to develop a model to predict outcomes after CRT. Methods and Results: Models were developed with machine learning algorithms to predict all-cause mortality or heart failure hospitalization at 12 months post-CRT in the COMPANION trial (Comparison of Medical Therapy, Pacing, and Defibrillation in Heart Failure). The best performing model was developed with the random forest algorithm. The ability of this model to predict all-cause mortality or heart failure hospitalization and all-cause mortality alone was compared with discrimination obtained using a combination of bundle branch block morphology and QRS duration. In the 595 patients with CRT-defibrillator in the COMPANION trial, 105 deaths occurred (median follow-up, 15.7 months). The survival difference across subgroups differentiated by bundle branch block morphology and QRS duration did not reach significance (P=0.08). The random forest model produced quartiles of patients with an 8-fold difference in survival between those with the highest and lowest predicted probability for events (hazard ratio, 7.96; P<0.0001). The model also discriminated the risk of the composite end point of all-cause mortality or heart failure hospitalization better than subgroups based on bundle branch block morphology and QRS duration. Conclusions: In the COMPANION trial, a machine learning algorithm produced a model that predicted clinical outcomes after CRT. Applied before device implant, this model may better differentiate outcomes over current clinical discriminators and improve shared decision-making with patients. © 2018 American Heart Association, Inc.","algorithms; cardiac resynchronization therapy; heart failure; hospitalization; machine learning","Aged; Algorithms; Cardiac Resynchronization Therapy; Decision Making; Deep Learning; Female; Heart Conduction System; Heart Failure; Humans; Machine Learning; Male; Middle Aged; Predictive Value of Tests; Stroke Volume; Ventricular Function, Left; all cause mortality; Article; Bayesian learning; cardiac resynchronization therapy; cohort analysis; decision tree; female; follow up; heart bundle branch block; heart failure; hospitalization; human; learning algorithm; machine learning; major clinical study; male; priority journal; QRS interval; random forest; support vector machine; treatment outcome; aged; algorithm; cardiac resynchronization therapy; clinical trial; controlled study; decision making; heart failure; heart left ventricle function; heart muscle conduction system; heart stroke volume; middle aged; multicenter study; pathophysiology; physiology; predictive value; procedures; randomized controlled trial","Lippincott Williams and Wilkins","19413149","","","29326129","Article","Scopus","2-s2.0-85055168796"
"Wu Y.; Yang X.; Bian J.; Guo Y.; Xu H.; Hogan W.","Wu, Yonghui (55645924700); Yang, Xi (57203172777); Bian, Jiang (7103200005); Guo, Yi (57216597174); Xu, Hua (55493876700); Hogan, William (7101782257)","55645924700; 57203172777; 7103200005; 57216597174; 55493876700; 7101782257","Combine Factual Medical Knowledge and Distributed Word Representation to Improve Clinical Named Entity Recognition","2018","AMIA ... Annual Symposium proceedings. AMIA Symposium","24","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062376980&partnerID=40&md5=c6871d2e99711b0d802a1b1f322af136","Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, United States; School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States","Wu Y., Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, United States; Yang X., Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, United States; Bian J., Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, United States; Guo Y., Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, United States; Xu H., School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States; Hogan W., Departments of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, United States","There has been an increasing interest in developing deep learning methods to recognize clinical concepts from narrative clinical text. Recently, several studies have reported that Recurrent Neural Networks (RNNs) outperformed traditional machine learning methods such as Conditional Random Fields (CRFs). Deep learning-based Named Entity Recognition (NER) systems often use statistical language models to learn word embeddings from unlabeled corpora. However, current word embedding methods have limitations to learn decent representations for low-frequency words. Medicine is a knowledge-extensive domain; existing medical knowledge has the potential to improve feature representations for less frequent yet important words. However, it is still not clear how existing medical knowledge can help deep learning models in clinical NER tasks. In this study, we integrated medical knowledge from the Unified Medical Language System with word embeddings trained from an unlabeled clinical corpus in RNNs for detection of problems, treatments and lab tests. We examined three different ways to generate medical knowledge features, including a dictionary lookup program, the KnowledgeMap system, and the MedLEE system. We also compared representing medical knowledge as one-hot vectors versus representing medical knowledge as embedding layers. The evaluation results showed that the RNN with medical knowledge as embedding layers achieved new state-of-the-art performance (a strict F1 score of 86.21% and a relaxed F1 score of 92.80%) on the 2010 i2b2 corpus, outperforming an RNN with only word embeddings and RNNs with medical knowledge as one-hot vectors. This study demonstrated an efficient way of integrating medical knowledge with distributed word representations for clinical NER.","","Deep Learning; Humans; Natural Language Processing; Neural Networks (Computer); Unified Medical Language System; artificial neural network; human; natural language processing; Unified Medical Language System","NLM (Medline)","1942597X","","","30815153","Article","Scopus","2-s2.0-85062376980"
"Dubey R.K.; Nizar Banu P.K.","Dubey, Rahul K. (57205721061); Nizar Banu, P.K. (55263618900)","57205721061; 55263618900","Analysis of supervised and unsupervised technique for authentication dataset","2018","International Journal of Engineering and Technology(UAE)","2","10.14419/ijet.v7i4.9564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057806369&doi=10.14419%2fijet.v7i4.9564&partnerID=40&md5=75c22c079386a1fd5056f64e1965de83","Department of computer science, CHRIST (Deemed to be University), Bengaluru, India","Dubey R.K., Department of computer science, CHRIST (Deemed to be University), Bengaluru, India; Nizar Banu P.K., Department of computer science, CHRIST (Deemed to be University), Bengaluru, India","Traditional methods of data storage vary from the present. These days data has become more unstructured and requires to be read contextually. Data Science provides a platform for the community to perform artificial intelligence and deep learning methodologies on large volumes of structured and unstructured data. In the era of artificial intelligence, AI is showing it's true potential by addressing social causes and automation in various industries such as automobile, medicine and smart buildings, healthcare, retail, banking, and finance service are some of the deliverables. From a variety of sources and flooding data, AI and machine learning are finding real-world adoption and applications. The nature of the data models is trial and error and is prone to change with their discoveries for the specific problem and this is the case with the different algorithms used. In this paper, we apply machine learning algorithms such as unsupervised learning k-means, bat k-means and supervised learning decision tree, k-NN, support vector machine, regression, discriminant analysis, ensemble classification for data set taken from UCI repository, phishing website, website phishing, Z- Alizadeh Sani and authentication datasets. Authentication dataset is generated for testing Single Sign-on which learns from data by training to make predictions. © 2018Rahul K. Dubey, P. K. Nizar Banu.","Authentication; Classification; Clustering; Supervised learning; Unsupervised learning","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85057806369"
"Krishna M.M.; Neelima M.; Harshali M.; Rao M.V.G.","Krishna, M. Manoj (57204503295); Neelima, M. (58450617200); Harshali, M. (57206638535); Rao, M. Venu Gopala (57205357909)","57204503295; 58450617200; 57206638535; 57205357909","Image classification using Deep learning","2018","International Journal of Engineering and Technology(UAE)","56","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073096213&partnerID=40&md5=b97b71f04de44b557f19236b3553bc13","Dept. of ECE, K L E F, India","Krishna M.M., Dept. of ECE, K L E F, India; Neelima M., Dept. of ECE, K L E F, India; Harshali M., Dept. of ECE, K L E F, India; Rao M.V.G., Dept. of ECE, K L E F, India","The image classification is a classical problem of image processing, computer vision and machine learning fields. In this paper we study the image classification using deep learning. We use AlexNet architecture with convolutional neural networks for this purpose. Four test images are selected from the ImageNet database for the classification purpose. We cropped the images for various portion areas and conducted experiments. The results show the effectiveness of deep learning based image classification using AlexNet. © 2018 Authors.","AlexNet; Convolutional neural networks; Deep learning; Image classification; ImageNet; Machine learning","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85073096213"
"Kim Y.; Heider P.; Meystre S.","Kim, Youngjun (55604239700); Heider, Paul (57207267919); Meystre, Stéphane (55912123700)","55604239700; 57207267919; 55912123700","Ensemble-based Methods to Improve De-identification of Electronic Health Record Narratives","2018","AMIA ... Annual Symposium proceedings. AMIA Symposium","17","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062380957&partnerID=40&md5=fe0eef501d26212cd78a1dbdf2a1a828","Medical University of South Carolina, Charleston, SC, United States; Charleston, SC, United States","Kim Y., Medical University of South Carolina, Charleston, SC, United States; Heider P., Medical University of South Carolina, Charleston, SC, United States; Meystre S., Medical University of South Carolina, Charleston, SC, United States, Charleston, SC, United States","Text de-identification is an application of clinical natural language processing that offers significant efficiency and scalability advantages. Hence, various learning algorithms have been applied to this task to yield better performance. Instead of choosing the best individual learning algorithm, we aim to improve de-identification by constructing ensembles that lead to more accurate classification. We present three different ensemble methods that combine multiple de-identification models trained from deep learning, shallow learning, and rule-based approaches. Each model is capable of automated de-identification without manual medical expertise. Our experimental results show that the stacked learning ensemble is more effective than other ensemble methods, producing the highest recall, the most important metric for de-identification. The stacked ensemble achieved state-of-the-art performance on the 2014 i2b2 dataset with 97.04% precision, 94.45% recall, and 95.73% F1 score.","","Algorithms; Data Anonymization; Electronic Health Records; Humans; Machine Learning; Methods; Natural Language Processing; algorithm; anonymization; electronic health record; human; machine learning; natural language processing; procedures","NLM (Medline)","1942597X","","","30815108","Article","Scopus","2-s2.0-85062380957"
"Choi H.; Na K.J.","Choi, Hongyoon (45760940100); Na, Kwon Joong (55861796100)","45760940100; 55861796100","A Risk Stratification Model for Lung Cancer Based on Gene Coexpression Network and Deep Learning","2018","BioMed Research International","20","10.1155/2018/2914280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045918394&doi=10.1155%2f2018%2f2914280&partnerID=40&md5=460e04a7b0a15622f38dc8589c1db953","Cheonan Public Health Center, Chungnam, South Korea; Department of Community Health, Korea Health Promotion Institute, Seoul, South Korea; Department of Clinical Medical Sciences, Seoul National University, College of Medicine, Seoul, South Korea","Choi H., Cheonan Public Health Center, Chungnam, South Korea; Na K.J., Department of Community Health, Korea Health Promotion Institute, Seoul, South Korea, Department of Clinical Medical Sciences, Seoul National University, College of Medicine, Seoul, South Korea","Risk stratification model for lung cancer with gene expression profile is of great interest. Instead of previous models based on individual prognostic genes, we aimed to develop a novel system-level risk stratification model for lung adenocarcinoma based on gene coexpression network. Using multiple microarray, gene coexpression network analysis was performed to identify survival-related networks. A deep learning based risk stratification model was constructed with representative genes of these networks. The model was validated in two test sets. Survival analysis was performed using the output of the model to evaluate whether it could predict patients' survival independent of clinicopathological variables. Five networks were significantly associated with patients' survival. Considering prognostic significance and representativeness, genes of the two survival-related networks were selected for input of the model. The output of the model was significantly associated with patients' survival in two test sets and training set (p<0.00001, p<0.0001 and p=0.02 for training and test sets 1 and 2, resp.). In multivariate analyses, the model was associated with patients' prognosis independent of other clinicopathological features. Our study presents a new perspective on incorporating gene coexpression networks into the gene expression signature and clinical application of deep learning in genomic data science for prognosis prediction. © 2018 Hongyoon Choi and Kwon Joong Na.","","Adenocarcinoma; Gene Expression Regulation, Neoplastic; Gene Regulatory Networks; Humans; Lung Neoplasms; Machine Learning; Models, Biological; Risk Assessment; adult; Article; cancer prognosis; cancer risk; cancer survival; female; gene expression profiling; gene regulatory network; genetic risk; human; lung adenocarcinoma; machine learning; major clinical study; male; microarray analysis; middle aged; model; overall survival; predictive value; risk assessment; survival analysis; adenocarcinoma; biological model; gene expression regulation; lung tumor; metabolism; mortality; pathology; risk assessment","Hindawi Limited","23146133","","","29581968","Article","Scopus","2-s2.0-85045918394"
"Seymour B.; Mano H.; Kotecha G.; Leibnitz K.; Matsubara T.; Nakae A.; Shenker N.; Shibata M.; Voon V.; Yoshida W.; Lee M.; Yanagida T.; Kawato M.; Rosa M.J.","Seymour, Ben (8609317000); Mano, Hiroaki (56503230500); Kotecha, Gopal (56598580900); Leibnitz, Kenji (6603463737); Matsubara, Takashi (53863900700); Nakae, Aya (16646657200); Shenker, Nicholas (6603040265); Shibata, Masahiko (35448606100); Voon, Valerie (8449219500); Yoshida, Wako (7006358579); Lee, Michael (55716898800); Yanagida, Toshio (7201744811); Kawato, Mitsuo (57192911319); Rosa, Maria Joao (34882137100)","8609317000; 56503230500; 56598580900; 6603463737; 53863900700; 16646657200; 6603040265; 35448606100; 8449219500; 7006358579; 55716898800; 7201744811; 57192911319; 34882137100","Classification and characterisation of brain network changes in chronic back pain: A multicenter study.","2018","Wellcome Open Research","17","10.12688/wellcomeopenres.14069.1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048278474&doi=10.12688%2fwellcomeopenres.14069.1&partnerID=40&md5=47095588bcfd5f426a930c7aa4d85570","Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan; Cambridge University Hospitals NHS Foundation Trust, Cambridge, United Kingdom; Graduate School of System Informatics, Kobe University, Kobe, Japan; Osaka University School of Medicine, Osaka, Japan; Immunology Frontiers Research Center, Osaka University, Osaka, Japan; School of Clinical Medicine, University of Cambridge, Cambridge, United Kingdom; Advanced Telecommunications Research Center International, Kyoto, Japan; Max-Planck UCL Centre for Computational Psychiatry and Ageing Research, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom; Computational and Biological Learning Laboratory, Department of Engineering, University of Cambridge, Cambridge, United Kingdom","Seymour B., Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan, Immunology Frontiers Research Center, Osaka University, Osaka, Japan, Advanced Telecommunications Research Center International, Kyoto, Japan, Computational and Biological Learning Laboratory, Department of Engineering, University of Cambridge, Cambridge, United Kingdom; Mano H., Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan; Kotecha G., Cambridge University Hospitals NHS Foundation Trust, Cambridge, United Kingdom; Leibnitz K., Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan; Matsubara T., Graduate School of System Informatics, Kobe University, Kobe, Japan; Nakae A., Osaka University School of Medicine, Osaka, Japan, Immunology Frontiers Research Center, Osaka University, Osaka, Japan; Shenker N., Cambridge University Hospitals NHS Foundation Trust, Cambridge, United Kingdom; Shibata M., Osaka University School of Medicine, Osaka, Japan; Voon V., School of Clinical Medicine, University of Cambridge, Cambridge, United Kingdom; Yoshida W., Advanced Telecommunications Research Center International, Kyoto, Japan; Lee M., School of Clinical Medicine, University of Cambridge, Cambridge, United Kingdom; Yanagida T., Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, Japan; Kawato M., Advanced Telecommunications Research Center International, Kyoto, Japan; Rosa M.J., Max-Planck UCL Centre for Computational Psychiatry and Ageing Research, University College London, London, United Kingdom, Department of Computer Science, University College London, London, United Kingdom","Background. Chronic pain is a common, often disabling condition thought to involve a combination of peripheral and central neurobiological factors. However, the extent and nature of changes in the brain is poorly understood. Methods. We investigated brain network architecture using resting-state fMRI data in chronic back pain patients in the UK and Japan (41 patients, 56 controls), as well as open data from USA. We applied machine learning and deep learning (conditional variational autoencoder architecture) methods to explore classification of patients/controls based on network connectivity. We then studied the network topology of the data, and developed a multislice modularity method to look for consensus evidence of modular reorganisation in chronic back pain. Results. Machine learning and deep learning allowed reliable classification of patients in a third, independent open data set with an accuracy of 63%, with 68% in cross validation of all data. We identified robust evidence of network hub disruption in chronic pain, most consistently with respect to clustering coefficient and betweenness centrality. We found a consensus pattern of modular reorganisation involving extensive, bilateral regions of sensorimotor cortex, and characterised primarily by negative reorganisation - a tendency for sensorimotor cortex nodes to be less inclined to form pairwise modular links with other brain nodes. In contrast, intraparietal sulcus displayed a propensity towards positive modular reorganisation, suggesting that it might have a role in forming modules associated with the chronic pain state. Conclusion. The results provide evidence of consistent and characteristic brain network changes in chronic pain, characterised primarily by extensive reorganisation of the network architecture of the sensorimotor cortex. © 2018 Mano H et al.","Arthritis.; Chronic pain; Connectomics; Deep learning; Graph theory; Hub disruption; Multislice modularity; Nociception; Osteoarthritis; Sensorimotor","","F1000 Research Ltd","2398502X","","","","Article","Scopus","2-s2.0-85048278474"
"Cardoso I.; Almeida E.; Allende-Cid H.; Frery A.C.; Rangayyan R.M.; Azevedo-Marques P.M.; Ramos H.S.","Cardoso, Isadora (57191339334); Almeida, Eliana (8295156100); Allende-Cid, Hector (57208732887); Frery, Alejandro C. (7003561251); Rangayyan, Rangaraj M. (7005319550); Azevedo-Marques, Paulo M. (57218760488); Ramos, Heitor S. (25655377800)","57191339334; 8295156100; 57208732887; 7003561251; 7005319550; 57218760488; 25655377800","Analysis of Machine Learning Algorithms for Diagnosis of Diffuse Lung Diseases","2018","Methods of Information in Medicine","11","10.1055/s-0039-1681086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062992252&doi=10.1055%2fs-0039-1681086&partnerID=40&md5=d012875b4843abe14c00b5e756e5098f","Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil; Escuela de Ingeniería Informatica, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile; Department of Electrical and Computer Engineering, Schulich School of Engineering, University of Calgary, Calgary, AB, Canada; Department of Internal Medicine, Ribeirão Preto Medical School, University of São Paulo, Ribeirão Preto, Brazil","Cardoso I., Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil; Almeida E., Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil; Allende-Cid H., Escuela de Ingeniería Informatica, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile; Frery A.C., Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil; Rangayyan R.M., Department of Electrical and Computer Engineering, Schulich School of Engineering, University of Calgary, Calgary, AB, Canada; Azevedo-Marques P.M., Department of Internal Medicine, Ribeirão Preto Medical School, University of São Paulo, Ribeirão Preto, Brazil; Ramos H.S., Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil","Computational Intelligence Re-meets Medical Image Processing A Comparison of Some Nature-Inspired Optimization Metaheuristics Applied in Biomedical Image Registration Summary Background Diffuse lung diseases (DLDs) are a diverse group of pulmonary disorders, characterized by inflammation of lung tissue, which may lead to permanent loss of the ability to breathe and death. Distinguishing among these diseases is challenging to physicians due their wide variety and unknown causes. Computer-aided diagnosis (CAD) is a useful approach to improve diagnostic accuracy, by combining information provided by experts with Machine Learning (ML) methods. Objectives Exploring the potential of dimensionality reduction combined with ML methods for diagnosis of DLDs; improving the classification accuracy over state-of-the-art methods. Methods A data set composed of 3252 regions of interest (ROIs) was used, from which 28 features were extracted per ROI. We used Principal Component Analysis, Linear Discriminant Analysis, and Stepwise Selection - Forward, Backward, and Forward-Backward to reduce feature dimensionality. The feature subsets obtained were used as input to the following ML methods: Support Vector Machine, Gaussian Mixture Model, k-Nearest Neighbor, and Deep Feedforward Neural Network. We also applied a Deep Convolutional Neural Network directly to the ROIs. Results We achieved the maximum reduction from 28 to 5 dimensions using LDA. The best classification results were obtained by DFNN, with 99.60% of overall accuracy. Conclusions This work contributes to the analysis and selection of features that can efficiently characterize the DLDs studied. © 2018 Georg Thieme Verlag KG Stuttgart. New York.","Deep learning; diffuse lung diseases; dimensionality reduction; machine learning","Algorithms; Diagnosis, Computer-Assisted; Discriminant Analysis; Humans; Lung Diseases; Machine Learning; Principal Component Analysis; Time Factors; algorithm; computer assisted diagnosis; discriminant analysis; human; lung disease; machine learning; principal component analysis; time factor","Georg Thieme Verlag","00261270","","MIMCA","30875707","Article","Scopus","2-s2.0-85062992252"
"Lee J.; An J.Y.; Choi M.G.; Park S.H.; Kim S.T.; Lee J.H.; Sohn T.S.; Bae J.M.; Kim S.; Lee H.; Min B.-H.; Kim J.J.; Jeong W.K.; Choi D.-I.; Kim K.-M.; Kang W.K.; Kim M.; Seo S.W.","Lee, Jeeyun (55899617000); An, Ji Yeong (7202509644); Choi, Min Gew (7402093519); Park, Se Hoon (25960261300); Kim, Seung Tae (8638723100); Lee, Jun Ho (57269012900); Sohn, Tae Sung (7005062103); Bae, Jae Moon (57199910551); Kim, Sung (35285969600); Lee, Hyuk (54896123100); Min, Byung-Hoon (7202932034); Kim, Jae J. (36067967700); Jeong, Woo Kyoung (14012468500); Choi, Dong-Il (7401643579); Kim, Kyoung-Mee (56155892100); Kang, Won Ki (7202402198); Kim, Mijung (57202224671); Seo, Sung Wook (16403082900)","55899617000; 7202509644; 7402093519; 25960261300; 8638723100; 57269012900; 7005062103; 57199910551; 35285969600; 54896123100; 7202932034; 36067967700; 14012468500; 7401643579; 56155892100; 7202402198; 57202224671; 16403082900","Deep learning-based survival analysis identified associations between molecular subtype and optimal adjuvant treatment of patients with Gastric cancer","2018","JCO Clinical Cancer Informatics","20","10.1200/CCI.17.00065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071900548&doi=10.1200%2fCCI.17.00065&partnerID=40&md5=441f590191bfc422b6878064c4e3d2b1","Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Ghent University, Ghent, Belgium","Lee J., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; An J.Y., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Choi M.G., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Park S.H., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Kim S.T., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Lee J.H., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Sohn T.S., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Bae J.M., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Kim S., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Lee H., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Min B.-H., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Kim J.J., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Jeong W.K., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Choi D.-I., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Kim K.-M., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Kang W.K., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea; Kim M., Ghent University, Ghent, Belgium; Seo S.W., Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, South Korea","Purpose Gastric cancer (GC) is the third-leading cause of cancer-related deaths. Several pivotal clinical trials of adjuvant treatments were performed during the previous decade; however, the optimal regimen for adjuvant treatment of GC remains controversial. Patients and Methods We developed a novel deep learning-based survival model (survival recurrent network [SRN]) in patients with GC by including all available clinical and pathologic data and treatment regimens. This model uses time-sequential data only in the training step, and upon being trained, it receives the initial data from the first visit and then sequentially predicts the outcome at each time point until it reaches 5 years. In total, 1,190 patients from three cohorts (the Asian Cancer Research Group cohort, n = 300; the fluorouracil, leucovorin, and radiotherapy cohort, n = 432; and the Adjuvant Chemoradiation Therapy in Stomach Cancer cohort, n = 458) were included in the analysis. In addition, we added Asian Cancer Research Group molecular classifications into the prediction model. SRN simulated the sequential learning process of clinicians in the outpatient clinic using a recurrent neural network and time-sequential outcome data. Results The mean area under the receiver operating characteristics curve was 0.92 ± 0.049 at the fifth year. The SRN demonstrated that GC with a mesenchymal subtype should elicit a more risk-adapted postoperative treatment strategy as a result of its high recurrence rate. In addition, the SRN found that GCs with microsatellite instability and GCs of the papillary type exhibited significantly more favorable survival outcomes after capecitabine plus cisplatin chemotherapy alone. Conclusion Our SRN predicted survival at a high rate, reaching 92% at postoperative year 5. Our findings suggest that SRN-based clinical trials or risk-adapted adjuvant trials could be considered for patients with GC to investigate more individualized adjuvant treatments after curative gastrectomy. © 2018 American Society of Clinical Oncology.","","capecitabine; cisplatin; fluorouracil; folinic acid; adult; aged; Article; artificial neural network; cancer adjuvant therapy; cancer classification; cancer patient; cancer prognosis; cancer radiotherapy; cancer recurrence; cancer research; cancer survival; cancer therapy; clinical outcome; clinical trial (topic); cohort analysis; controlled study; data processing; disease association; false positive result; female; gastrectomy; histopathology; human; human cell; human tissue; machine learning; major clinical study; male; mathematical model; medical information; mesenchyme; microsatellite instability; outpatient department; personalized medicine; physician; postoperative care; postoperative period; prediction; priority journal; receiver operating characteristic; sequence learning; simulation; statistical analysis; stomach cancer; survival analysis","American Society of Clinical Oncology","24734276","","","30652558","Article","Scopus","2-s2.0-85071900548"
"Li C.; Rao Z.; Zheng Q.; Zhang X.","Li, Chen (57765324800); Rao, Zhiqiang (57204539984); Zheng, Qinghua (56113889000); Zhang, Xiangrong (55802358000)","57765324800; 57204539984; 56113889000; 55802358000","A set of domain rules and a deep network for protein coreference resolution","2018","Database","5","10.1093/database/bay065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056070150&doi=10.1093%2fdatabase%2fbay065&partnerID=40&md5=e408b560af55ca7a8a0062d1ad6c780a","MOEKLINNS Laboratory, Department of Computer Science and Technology, Xi'an Jiaotong University, 28 Xianning West Road, Xi'an, Shaanxi, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, 2 Taibai South Road, P.O. Box 224, Xi'an, China","Li C., MOEKLINNS Laboratory, Department of Computer Science and Technology, Xi'an Jiaotong University, 28 Xianning West Road, Xi'an, Shaanxi, China; Rao Z., Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, 2 Taibai South Road, P.O. Box 224, Xi'an, China; Zheng Q., MOEKLINNS Laboratory, Department of Computer Science and Technology, Xi'an Jiaotong University, 28 Xianning West Road, Xi'an, Shaanxi, China; Zhang X., Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, 2 Taibai South Road, P.O. Box 224, Xi'an, China","Current research of bio-text mining mainly focuses on event extractions. Biological networks present much richer and meaningful information to biologists than events. Bio-entity coreference resolution (CR) is a very important method to complete a bio-event's attributes and interconnect events into bio-networks. Though general CR methods have been studies for a long time, they could not produce a practically useful result when applied to a special domain. Therefore, bio-entity CR needs attention to better assist biological network extraction. In this article, we present two methods for bio-entity CR. The first is a rule-based method, which creates a set of syntactic rules or semantic constraints for CR. It obtains a state-of-the-art performance (an F1-score of 62.0%) on the community supported dataset. We also present a machine learning-based method, which takes use of a recurrent neural network model, a long-short term memory network. It automatically learns global discriminative representations of all kinds of coreferences without hand-crafted features. The model outperforms the previously best machine leaning-based method. © The Author(s) 2018. Published by Oxford University Press.","","Databases, Protein; Learning Curve; Models, Theoretical; Protein Interaction Maps; Proteins; Semantics; protein; chemistry; learning curve; protein analysis; protein database; semantics; theoretical model","Oxford University Press","17580463","","","30010737","Article","Scopus","2-s2.0-85056070150"
"Aksenov S.V.; Kostin K.A.; Ivanova A.V.; Liang J.; Zamyatin A.V.","Aksenov, S.V. (57194339702); Kostin, K.A. (57202426405); Ivanova, A.V. (57202419356); Liang, J. (7404541897); Zamyatin, Alexander V. (7004114028)","57194339702; 57202426405; 57202419356; 7404541897; 7004114028","An ensemble of convolutional neural networks for the use in video endoscopy","2018","Sovremennye Tehnologii v Medicine","4","10.17691/stm2018.10.2.01","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048282452&doi=10.17691%2fstm2018.10.2.01&partnerID=40&md5=ebb496b7bf43779d3e71bea7e27736b9","Department of Theoretical Foundations of Informatics, National Research Tomsk State University, 36 Lenin Avenue, Tomsk, 634050, Russian Federation; Scientific and Educational Center of Computer Science and Technology, National Research Tomsk State University, 36 Lenin Avenue, Tomsk, 634050, Russian Federation; Department of Information Technologies, National Research Tomsk Polytechnic University, 30 Lenin Avenue, Tomsk, 634050, Russian Federation; Department of Information Processing Automation, Tomsk State University of Control Systems and Radioelectronics, 40 Lenin Avenue, Tomsk, 634050, Russian Federation; Biodesign Center for Biosignatures Discovery Automation, Arizona State University, University Center, 411 N Central Avenue, Phoenix, 85004, AZ, United States","Aksenov S.V., Department of Theoretical Foundations of Informatics, National Research Tomsk State University, 36 Lenin Avenue, Tomsk, 634050, Russian Federation, Department of Information Technologies, National Research Tomsk Polytechnic University, 30 Lenin Avenue, Tomsk, 634050, Russian Federation, Department of Information Processing Automation, Tomsk State University of Control Systems and Radioelectronics, 40 Lenin Avenue, Tomsk, 634050, Russian Federation; Kostin K.A., Scientific and Educational Center of Computer Science and Technology, National Research Tomsk State University, 36 Lenin Avenue, Tomsk, 634050, Russian Federation, Department of Information Technologies, National Research Tomsk Polytechnic University, 30 Lenin Avenue, Tomsk, 634050, Russian Federation; Ivanova A.V., Scientific and Educational Center of Computer Science and Technology, National Research Tomsk State University, 36 Lenin Avenue, Tomsk, 634050, Russian Federation; Liang J., Biodesign Center for Biosignatures Discovery Automation, Arizona State University, University Center, 411 N Central Avenue, Phoenix, 85004, AZ, United States; Zamyatin A.V., Department of Theoretical Foundations of Informatics, National Research Tomsk State University, 36 Lenin Avenue, Tomsk, 634050, Russian Federation, Scientific and Educational Center of Computer Science and Technology, National Research Tomsk State University, 36 Lenin Avenue, Tomsk, 634050, Russian Federation","In this study, a technology for creating a classifier able to identify pathological formations in images obtained with video endoscopy using the methods of deep learning is proposed. For the training and testing of neural network models, images from the CVC-ColonDB open database and 20 colonoscopy video records from the University of Arizona (Phoenix, USA) were used. To improve the performance of the proposed classification model, noise effects inherent to video cameras were considered. In addition, a study on building the model using small data samples was conducted. In building the classifier, we utilized the results of recent studies on convolutional neural networks used in medical diagnostics, which allows us to apply the proposed approach to designing the architecture of a convolutional neural network adapted to a given task. By generalizing the features of the successful models, we developed an approach towards creating a non-excessive convolutional neural network. According to the proposed approach, the network architecture is divided into blocks, which alternate to enable composing the most efficient architecture. Using the proposed approach based on the recommended selection strategy and then ranking the most significant parameters, a second approach towards building an adaptive model of classifier has been proposed. It is based on the formation of an ensemble of classifiers such as the “convolutional neural network”. To ensure the stability of the model and its insensitivity to changes in the input data as well as its applicability to different classification tasks, a set of networks with different major parameters are incorporated into the ensemble. Our experimental studies have shown that the proposed classifier can be improved by developing an ensemble of convolutional neural networks, which considers the functions proposed in the present approach. The results imply the prospective application of the developed approach for building classification models not only for medical diagnostics but also for general problems of machine vision based on small samples. © 2018, Nizhny Novgorod State Medical Academy. All rights reserved.","Classifier of pathologies; Convolutional neural network; Deep learning; Medical diagnostics","Arizona; article; classifier; colonoscopy; experimental study; learning; machine; nervous system; noise; videorecording; vision","Privolzhsky Research Medical University","20764243","","","","Article","Scopus","2-s2.0-85048282452"
"Leyh-Bannurah S.-R.; Tian Z.; Karakiewicz P.I.; Wolffgang U.; Sauter G.; Fisch M.; Pehrke D.; Huland H.; Graefen M.; Budäus L.","Leyh-Bannurah, Sami-Ramzi (56262193900); Tian, Zhe (57226503162); Karakiewicz, Pierre I. (6701725847); Wolffgang, Ulrich (49964961800); Sauter, Guido (55828366200); Fisch, Margit (55952211500); Pehrke, Dirk (56520355800); Huland, Hartwig (36040724900); Graefen, Markus (26642918300); Budäus, Lars (24328505900)","56262193900; 57226503162; 6701725847; 49964961800; 55828366200; 55952211500; 56520355800; 36040724900; 26642918300; 24328505900","Deep learning for natural language processing in urology: State-of-the- art automated extraction of detailed pathologic prostate cancer data from narratively written electronic health records","2018","JCO Clinical Cancer Informatics","27","10.1200/CCI.18.00080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067211164&doi=10.1200%2fCCI.18.00080&partnerID=40&md5=99ad13a2af3a49f1360bca6ad0713e82","Prostate Cancer Center Hamburg-Eppendorf, Germany; University Medical Center Hamburg- Eppendorf, Hamburg, Germany; University of Muenster, Muenster, Germany; University of Montreal Health Center, Montreal, Canada","Leyh-Bannurah S.-R., Prostate Cancer Center Hamburg-Eppendorf, Germany, University Medical Center Hamburg- Eppendorf, Hamburg, Germany; Tian Z., University of Montreal Health Center, Montreal, Canada; Karakiewicz P.I., University of Montreal Health Center, Montreal, Canada; Wolffgang U., University of Muenster, Muenster, Germany; Sauter G., University Medical Center Hamburg- Eppendorf, Hamburg, Germany; Fisch M., University Medical Center Hamburg- Eppendorf, Hamburg, Germany; Pehrke D., Prostate Cancer Center Hamburg-Eppendorf, Germany; Huland H., Prostate Cancer Center Hamburg-Eppendorf, Germany; Graefen M., Prostate Cancer Center Hamburg-Eppendorf, Germany; Budäus L., Prostate Cancer Center Hamburg-Eppendorf, Germany","Purpose Entering all information from narrative documentation for clinical research into databases is time consuming, costly, and nearly impossible. Even high-volume databases do not cover all patient characteristics and drawn results may be limited. A new viable automated solution is machine learning based on deep neural networks applied to natural language processing (NLP), extracting detailed information from narratively written (eg, pathologic radical prostatectomy [RP]) electronic health records (EHRs). Methods Within an RP pathologic database, 3,679 RP EHRs were randomly split into 70% training and 30% test data sets. Training EHRs were automatically annotated, providing a semiautomatically annotated corpus of narratively written pathologic reports with initially context-free gold standard encodings. Primary and secondary Gleason pattern, corresponding percentages, tumor stage, nodal stage, total volume, tumor volume and diameter, and surgical margin were variables of interest. Second, state-of-the-art NLP techniques were used to train an industry-standard language model for pathologic EHRs by transfer learning. Finally, accuracy of the named entity extractors was compared with the gold standard encodings. Results Agreement rates (95% confidence interval) for primary and secondary Gleason patterns each were 91.3% (89.4 to 93.0), corresponding to the following: Gleason percentages, 70.5% (67.6 to 73.3) and 80.9% (78.4 to 83.3); tumor stage, 99.3% (98.6 to 99.7); nodal stage, 98.7% (97.8 to 99.3); total volume, 98.3% (97.3 to 99.0); tumor volume, 93.3% (91.6 to 94.8); maximum diameter, 96.3% (94.9 to 97.3); and surgical margin, 98.7% (97.8 to 99.3). Cumulative agreement was 91.3%. Conclusion Our proposed NLP pipeline offers new abilities for precise and efficient data management from narrative documentation for clinical research. The scalable approach potentially allows the NLP pipeline to be generalized to other genitourinary EHRs, tumor entities, and other medical disciplines. © 2019 American Society of Clinical Oncology.","","","American Society of Clinical Oncology","24734276","","","30652616","Article","Scopus","2-s2.0-85067211164"
"Satyanarayana P.; Charishma Devi V.; Sowjanya P.; Satish Babu N.; Syam Kumar M.N.V.S.","Satyanarayana, P. (57216887489); Charishma Devi, V. (57202236884); Sowjanya, P. (56565487100); Satish Babu, N. (57202232707); Syam Kumar, M.N.V.S. (57202234041)","57216887489; 57202236884; 56565487100; 57202232707; 57202234041","Implementation of conventional communication system in deep learning","2018","International Journal of Engineering and Technology(UAE)","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047548628&partnerID=40&md5=84d92036806d535f62efd037fbf89a67","Department of Electronics and Communication Engineering, KLEF, India","Satyanarayana P., Department of Electronics and Communication Engineering, KLEF, India; Charishma Devi V., Department of Electronics and Communication Engineering, KLEF, India; Sowjanya P., Department of Electronics and Communication Engineering, KLEF, India; Satish Babu N., Department of Electronics and Communication Engineering, KLEF, India; Syam Kumar M.N.V.S., Department of Electronics and Communication Engineering, KLEF, India","Machine learning (ML) has been broadly connected to the upper layers of communication systems for different purposes, for example, arrangement of cognitive radio and communication network. Nevertheless, its application to the physical layer is hindered by complex channel conditions and constrained learning capacity of regular ML algorithms. Deep learning (DL) has been as of late connected for some fields, for example, computer vision and normal dialect preparing, given its expressive limit and advantageous enhancement ability. This paper describes about a novel use of DL for the physical layer. By deciphering a communication system as an auto encoder, we build up an essential better approach to consider communication system outline as a conclusion to-end reproduction undertaking that tries to together enhance transmitter and receiver in a solitary procedure. This DL based technique demonstrates promising execution change than traditional communication system. © 2018 Satyanarayana. P et al.","Auto encoder; Deep learning; Machine learning; Neural networks","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85047548628"
"Kim Y.; Sa J.; Chung Y.; Park D.; Lee S.","Kim, Yunbin (57204695396); Sa, Jaewon (57189347451); Chung, Yongwha (7404387981); Park, Daihee (8987444600); Lee, Sungju (57194190442)","57204695396; 57189347451; 7404387981; 8987444600; 57194190442","Resource-efficient pet dog sound events classification using LSTM-FCN based on time-series data","2018","Sensors (Switzerland)","14","10.3390/s18114019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056736848&doi=10.3390%2fs18114019&partnerID=40&md5=b757120d0b958ebb7aede789a1cbe43f","Department of Computer Convergence Software, Korea University, Sejong City, 30019, South Korea","Kim Y., Department of Computer Convergence Software, Korea University, Sejong City, 30019, South Korea; Sa J., Department of Computer Convergence Software, Korea University, Sejong City, 30019, South Korea; Chung Y., Department of Computer Convergence Software, Korea University, Sejong City, 30019, South Korea; Park D., Department of Computer Convergence Software, Korea University, Sejong City, 30019, South Korea; Lee S., Department of Computer Convergence Software, Korea University, Sejong City, 30019, South Korea","The use of IoT (Internet of Things) technology for the management of pet dogs left alone at home is increasing. This includes tasks such as automatic feeding, operation of play equipment, and location detection. Classification of the vocalizations of pet dogs using information from a sound sensor is an important method to analyze the behavior or emotions of dogs that are left alone. These sounds should be acquired by attaching the IoT sound sensor to the dog, and then classifying the sound events (e.g., barking, growling, howling, and whining). However, sound sensors tend to transmit large amounts of data and consume considerable amounts of power, which presents issues in the case of resource-constrained IoT sensor devices. In this paper, we propose a way to classify pet dog sound events and improve resource efficiency without significant degradation of accuracy. To achieve this, we only acquire the intensity data of sounds by using a relatively resource-efficient noise sensor. This presents issues as well, since it is difficult to achieve sufficient classification accuracy using only intensity data due to the loss of information from the sound events. To address this problem and avoid significant degradation of classification accuracy, we apply long short-term memory-fully convolutional network (LSTM-FCN), which is a deep learning method, to analyze time-series data, and exploit bicubic interpolation. Based on experimental results, the proposed method based on noise sensors (i.e., Shapelet and LSTM-FCN for time-series) was found to improve energy efficiency by 10 times without significant degradation of accuracy compared to typical methods based on sound sensors (i.e., mel-frequency cepstrum coefficient (MFCC), spectrogram, and mel-spectrum for feature extraction, and support vector machine (SVM) and k-nearest neighbor (K-NN) for classification). © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","IoT sensor; LSTM-FCN; Pet dogs; Resource efficiency; Separation anxiety; Sound events processing","Algorithms; Animals; Behavior, Animal; Dogs; Neural Networks (Computer); Vocalization, Animal; Acoustic noise; Acoustic signal processing; Classification (of information); Deep learning; Energy efficiency; Long short-term memory; Nearest neighbor search; Support vector machines; Time series; Bicubic interpolation; Classification accuracy; Convolutional networks; LSTM-FCN; Mel frequency cepstrum coefficients; Pet dogs; Resource efficiencies; Sound events; algorithm; animal; animal behavior; artificial neural network; classification; dog; vocalization; Internet of things","MDPI AG","14248220","","","30453674","Article","Scopus","2-s2.0-85056736848"
"Pham T.D.; Nguyen D.T.; Kang J.K.; Park K.R.","Pham, Tuyen Danh (55808639500); Nguyen, Dat Tien (35608738000); Kang, Jin Kyu (57202771289); Park, Kang Ryoung (8983316300)","55808639500; 35608738000; 57202771289; 8983316300","Deep learning-based multinational banknote fitness classification with a combination of visible-light reflection and infrared-light transmission images","2018","Symmetry","2","10.3390/sym10100431","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055754223&doi=10.3390%2fsym10100431&partnerID=40&md5=2af4c565530eca77543c0f56dac0e1e6","Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea","Pham T.D., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Nguyen D.T., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Kang J.K., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea; Park K.R., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil, Jung-gu, Seoul, 100-715, South Korea","The fitness classification of a banknote is important as it assesses the quality of banknotes in automated banknote sorting facilities, such as counting or automated teller machines. The popular approaches are primarily based on image processing, with banknote images acquired by various sensors. However, most of these methods assume that the currency type, denomination, and exposed direction of the banknote are known. In other words, not only is a pre-classification of the type of input banknote required, but in some cases, the type of currency is required to be manually selected. To address this problem, we propose a multinational banknote fitness-classification method that simultaneously determines the fitness level of a banknote from multiple countries. This is achieved without the pre-classification of input direction and denomination of the banknote, using visible-light reflection and infrared-light transmission images of banknotes, and a convolutional neural network. The experimental results on the combined banknote image database consisting of the Indian rupee and Korean won with three fitness levels, and the United States dollar with two fitness levels, show that the proposed method achieves better accuracy than other fitness classification methods. © 2018 by the authors.","Convolutional neural network; Deep learning; Infrared-light transmission image; Multinational banknote fitness classification; Visible-light reflection image","","MDPI AG","20738994","","","","Article","Scopus","2-s2.0-85055754223"
"Gao F.; Lin T.","Gao, Fengmei (57202587611); Lin, Tao (56074846300)","57202587611; 56074846300","Application of computer-aided diagnosis technology in brain tumour detection","2018","NeuroQuantology","0","10.14704/nq.2018.16.5.1275","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048821773&doi=10.14704%2fnq.2018.16.5.1275&partnerID=40&md5=46a6c285b71d169021d0fcc70f1c21b1","Xinxiang Medical University, Xinxiang, 453003, China; Chongqing College of Electronic Engineering, Chongqing, 401331, China","Gao F., Xinxiang Medical University, Xinxiang, 453003, China; Lin T., Chongqing College of Electronic Engineering, Chongqing, 401331, China","Accurate segmentation of brain tumour means that surgeons accurately remove the tumour without damaging other healthy tissues. At present, due to the differences in human brains, the widely used manual brain tumour segmentation method cannot guarantee its accuracy and reliability. Therefore, it is of great social and practical significance to work out an automatic and accurate brain tumour segmentation method based on the computer-aided technology. This paper proposes a novel brain tumour segmentation method based on the deep learning model of stacked de-noising auto-coder. Firstly, by model training, it obtains the parameters of the deep learning network, and then it extracts high-level abstract features of the input image data through the network and uses these features to translate the segmentation of brain tumour to the classification of image blocks. Finally, this paper applies the proposed method for the MRI images of real brain tumour patients to carry out segmentation of brain tumours, and then compares it with the manual brain tumour segmentation method. The results show that the computer-aided brain tumour segmentation method is more effective and accurate and can provide reliable basis for the removal of brain tumours by surgeons without damaging normal tissues. © 2018, Anka Publishers. All rights reserved.","Brain tumour detection; Brain tumour segmentation; Computer-aided","algorithm; Article; artificial neural network; brain tumor; child; comparative study; computer assisted diagnosis; computer assisted radiography; diagnostic accuracy; histogram; human; image analysis; image processing; image segmentation; learning; machine learning; mathematical model; nuclear magnetic resonance imaging; simulation","Anka Publishers","13035150","","","","Article","Scopus","2-s2.0-85048821773"
"Nagasato D.; Tabuchi H.; Ohsugi H.; Masumoto H.; Enno H.; Ishitobi N.; Sonobe T.; Kameoka M.; Niki M.; Hayashi K.; Mitamura Y.","Nagasato, Daisuke (55747481100); Tabuchi, Hitoshi (36810783800); Ohsugi, Hideharu (14060992900); Masumoto, Hiroki (57201984138); Enno, Hiroki (57195449818); Ishitobi, Naofumi (57195472024); Sonobe, Tomoaki (57203923559); Kameoka, Masahiro (57196370728); Niki, Masanori (55211236100); Hayashi, Ken (57008559700); Mitamura, Yoshinori (34572364500)","55747481100; 36810783800; 14060992900; 57201984138; 57195449818; 57195472024; 57203923559; 57196370728; 55211236100; 57008559700; 34572364500","Deep neural network-based method for detecting central retinal vein occlusion using ultrawide-field fundus ophthalmoscopy","2018","Journal of Ophthalmology","48","10.1155/2018/1875431","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062785006&doi=10.1155%2f2018%2f1875431&partnerID=40&md5=12d01c0ee4d6598c71b48b9172ea87e4","Department of Ophthalmology, Tsukazaki Hospital, Himeji, Japan; Rist Inc., Tokyo, Japan; Department of Ophthalmology, Institute of Biomedical Sciences, Tokushima University Graduate School, Tokushima, Japan; Hayashi Eye Hospital, Fukuoka, Japan","Nagasato D., Department of Ophthalmology, Tsukazaki Hospital, Himeji, Japan; Tabuchi H., Department of Ophthalmology, Tsukazaki Hospital, Himeji, Japan; Ohsugi H., Department of Ophthalmology, Tsukazaki Hospital, Himeji, Japan; Masumoto H., Department of Ophthalmology, Tsukazaki Hospital, Himeji, Japan; Enno H., Rist Inc., Tokyo, Japan; Ishitobi N., Department of Ophthalmology, Tsukazaki Hospital, Himeji, Japan; Sonobe T., Department of Ophthalmology, Tsukazaki Hospital, Himeji, Japan; Kameoka M., Department of Ophthalmology, Tsukazaki Hospital, Himeji, Japan; Niki M., Department of Ophthalmology, Institute of Biomedical Sciences, Tokushima University Graduate School, Tokushima, Japan; Hayashi K., Hayashi Eye Hospital, Fukuoka, Japan; Mitamura Y., Department of Ophthalmology, Institute of Biomedical Sciences, Tokushima University Graduate School, Tokushima, Japan","The aim of this study is to assess the performance of two machine-learning technologies, namely, deep learning (DL) and support vector machine (SVM) algorithms, for detecting central retinal vein occlusion (CRVO) in ultrawide-field fundus images. Images from 125 CRVO patients (n = 125 images) and 202 non-CRVO normal subjects (n = 238 images) were included in this study. Training to construct the DL model using deep convolutional neural network algorithms was provided using ultrawide-field fundus images. The SVM uses scikit-learn library with a radial basis function kernel. The diagnostic abilities of DL and the SVM were compared by assessing their sensitivity, specificity, and area under the curve (AUC) of the receiver operating characteristic curve for CRVO. For diagnosing CRVO, the DL model had a sensitivity of 98.4% (95% confidence interval (CI), 94.3-99.8%) and a specificity of 97.9% (95% CI, 94.6-99.1%) with an AUC of 0.989 (95% CI, 0.980-0.999). In contrast, the SVM model had a sensitivity of 84.0% (95% CI, 76.3-89.3%) and a specificity of 87.5% (95% CI, 82.7-91.1%) with an AUC of 0.895 (95% CI, 0.859-0.931). Thus, the DL model outperformed the SVM model in all indices assessed (P < 0.001 for all). Our data suggest that a DL model derived using ultrawide-field fundus images could distinguish between normal and CRVO images with a high level of accuracy and that automatic CRVO detection in ultrawide-field fundus ophthalmoscopy is possible. This proposed DL-based model can also be used in ultrawide-field fundus ophthalmoscopy to accurately diagnose CRVO and improve medical care in remote locations where it is difficult for patients to attend an ophthalmic medical center. © 2018 Daisuke Nagasato et al.","","","Hindawi Limited","2090004X","","","","Article","Scopus","2-s2.0-85062785006"
"Sadouk L.; Gadi T.; Essoufi E.H.","Sadouk, Lamyaa (57193485809); Gadi, Taoufiq (36801708100); Essoufi, El Hassan (6504162169)","57193485809; 36801708100; 6504162169","A Novel Deep Learning Approach for Recognizing Stereotypical Motor Movements within and across Subjects on the Autism Spectrum Disorder","2018","Computational Intelligence and Neuroscience","27","10.1155/2018/7186762","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050932398&doi=10.1155%2f2018%2f7186762&partnerID=40&md5=6c6bcfb0c2480501976fe9c5892a3d81","Faculty of Science and Technology, University Hassan 1st, Settat, Morocco","Sadouk L., Faculty of Science and Technology, University Hassan 1st, Settat, Morocco; Gadi T., Faculty of Science and Technology, University Hassan 1st, Settat, Morocco; Essoufi E.H., Faculty of Science and Technology, University Hassan 1st, Settat, Morocco","Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by persistent difficulties including repetitive patterns of behavior known as stereotypical motor movements (SMM). So far, several techniques have been implemented to track and identify SMMs. In this context, we propose a deep learning approach for SMM recognition, namely, convolutional neural networks (CNN) in time and frequency-domains. To solve the intrasubject SMM variability, we propose a robust CNN model for SMM detection within subjects, whose parameters are set according to a proper analysis of SMM signals, thereby outperforming state-of-the-art SMM classification works. And, to solve the intersubject variability, we propose a global, fast, and light-weight framework for SMM detection across subjects which combines a knowledge transfer technique with an SVM classifier, therefore resolving the ""real-life"" medical issue associated with the lack of supervised SMMs per testing subject in particular. We further show that applying transfer learning across domains instead of transfer learning within the same domain also generalizes to the SMM target domain, thus alleviating the problem of the lack of supervised SMMs in general. © 2018 Lamyaa Sadouk et al.","","Accelerometry; Autism Spectrum Disorder; Biomechanical Phenomena; Diagnosis, Computer-Assisted; Humans; Movement; Neural Networks (Computer); Pattern Recognition, Automated; Periodicity; Stereotyped Behavior; Support Vector Machine; Wireless Technology; Diseases; Knowledge management; Neural networks; Signal analysis; Autism spectrum disorders; Convolutional Neural Networks (CNN); Knowledge transfer; Learning approach; Repetitive pattern; State of the art; Time and frequency domains; Transfer learning; accelerometry; artificial neural network; autism; automated pattern recognition; biomechanics; computer assisted diagnosis; devices; human; movement (physiology); pathophysiology; periodicity; procedures; stereotypy; support vector machine; wireless communication; Deep learning","Hindawi Limited","16875265","","","30111994","Article","Scopus","2-s2.0-85050932398"
"Al-Sarayreh M.; Reis M.M.; Yan W.Q.; Klette R.","Al-Sarayreh, Mahmoud (57193112848); Reis, Marlon M. (7005981992); Yan, Wei Qi (56004310900); Klette, Reinhard (7003908797)","57193112848; 7005981992; 56004310900; 7003908797","Detection of Red-Meat Adulteration by Deep Spectral–Spatial Features in Hyperspectral Images","2018","Journal of Imaging","72","10.3390/jimaging4050063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049653841&doi=10.3390%2fjimaging4050063&partnerID=40&md5=1003f41012989a6fb8ee95d4f1883439","School of Engineering, Computer and Mathematical Sciences, Auckland University of Technology, Auckland, 1010, New Zealand; AgResearch, Palmerston North, 4442, New Zealand","Al-Sarayreh M., School of Engineering, Computer and Mathematical Sciences, Auckland University of Technology, Auckland, 1010, New Zealand, AgResearch, Palmerston North, 4442, New Zealand; Reis M.M., AgResearch, Palmerston North, 4442, New Zealand; Yan W.Q., School of Engineering, Computer and Mathematical Sciences, Auckland University of Technology, Auckland, 1010, New Zealand; Klette R., School of Engineering, Computer and Mathematical Sciences, Auckland University of Technology, Auckland, 1010, New Zealand","This paper provides a comprehensive analysis of the performance of hyperspectral imaging for detecting adulteration in red-meat products. A dataset of line-scanning images of lamb, beef, or pork muscles was collected taking into account the state of the meat (fresh, frozen, thawed, and packing and unpacking the sample with a transparent bag). For simulating the adulteration problem, meat muscles were defined as either a class of lamb or a class of beef or pork. We investigated handcrafted spectral and spatial features by using the support vector machines (SVM) model and self-extraction spectral and spatial features by using a deep convolution neural networks (CNN) model. Results showed that the CNN model achieves the best performance with a 94.4% overall classification accuracy independent of the state of the products. The CNN model provides a high and balanced F-score for all classes at all stages. The resulting CNN model is considered as being simple and fairly invariant to the condition of the meat. This paper shows that hyperspectral imaging systems can be used as powerful tools for rapid, reliable, and non-destructive detection of adulteration in red-meat products. Also, this study confirms that deep-learning approaches such as CNN networks provide robust features for classifying the hyperspectral data of meat products; this opens the door for more research in the area of practical applications (i.e., in meat processing). © 2018 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license","3D CNN; Adulteration detection; Deep learning; Hyperspectral imaging; Meat classification; Meat processing; Spectral-spatial features","","MDPI Multidisciplinary Digital Publishing Institute","2313433X","","","","Article","Scopus","2-s2.0-85049653841"
"Zhang E.; Thurier Q.; Boyle L.","Zhang, Edmond (57214655946); Thurier, Quentin (57204622198); Boyle, Luke (57213134082)","57214655946; 57204622198; 57213134082","Improving Clinical Named-Entity Recognition with Transfer Learning","2018","Studies in health technology and informatics","4","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056426579&partnerID=40&md5=1c488bf3384dfa2b61b39216dd97f52a","Orion Health, New Zealand","Zhang E., Orion Health, New Zealand; Thurier Q., Orion Health, New Zealand; Boyle L., Orion Health, New Zealand","Transfer learning is a powerful machine learning technique that enables the internalizing and reuse of prior knowledge to new tasks. Transfer learning is currently the starting point for recognition tasks such as computer vision. However, in natural language processing (NLP), the application of this technique is less prevalent. Our research investigates how, through the application of transfer learning, existing knowledge can be used to build more accurate NLP models. We subsequently applied these models to a named-entity recognition (NER) task. Our experimental results show significantly better recognition performance can be obtained through leveraging knowledge from a base model, trained using poorly annotated data.","Deep Learning; NER; Neural Networks; RNN; Transfer Learning","Data Curation; Machine Learning; Natural Language Processing; information processing; machine learning; natural language processing","","09269630","","","30040703","Article","Scopus","2-s2.0-85056426579"
"Rajaraman S.; Antani S.K.; Poostchi M.; Silamut K.; Hossain M.A.; Maude R.J.; Jaeger S.; Thoma G.R.","Rajaraman, Sivaramakrishnan (51764361200); Antani, Sameer K. (6701355570); Poostchi, Mahdieh (26421326000); Silamut, Kamolrat (57208458283); Hossain, Md. A. (7402472823); Maude, Richard J. (25625222500); Jaeger, Stefan (55516608100); Thoma, George R. (7005141497)","51764361200; 6701355570; 26421326000; 57208458283; 7402472823; 25625222500; 55516608100; 7005141497","Pre-trained convolutional neural networks as feature extractors toward improved malaria parasite detection in thin blood smear images","2018","PeerJ","324","10.7717/peerj.4568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045518625&doi=10.7717%2fpeerj.4568&partnerID=40&md5=646329587f2133b4e617f62d2ff3a3ad","Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD, United States; Mahidol-Oxford Tropical Medicine Research Unit, Mahidol University, Bangkok, Thailand; Department of Medicine, Chittagong Medical Hospital, Chittagong, Bangladesh; Centre for Tropical Medicine and Global Health, Nuffield Department of Medicine, University of Oxford, Oxford, United Kingdom; Harvard TH Chan School of Public Health, Harvard University, Boston, MA, United States","Rajaraman S., Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD, United States; Antani S.K., Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD, United States; Poostchi M., Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD, United States; Silamut K., Mahidol-Oxford Tropical Medicine Research Unit, Mahidol University, Bangkok, Thailand; Hossain M.A., Department of Medicine, Chittagong Medical Hospital, Chittagong, Bangladesh; Maude R.J., Mahidol-Oxford Tropical Medicine Research Unit, Mahidol University, Bangkok, Thailand, Centre for Tropical Medicine and Global Health, Nuffield Department of Medicine, University of Oxford, Oxford, United Kingdom, Harvard TH Chan School of Public Health, Harvard University, Boston, MA, United States; Jaeger S., Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD, United States; Thoma G.R., Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD, United States","Malaria is a blood disease caused by the Plasmodium parasites transmitted through the bite of female Anopheles mosquito. Microscopists commonly examine thick and thin blood smears to diagnose disease and compute parasitemia. However, their accuracy depends on smear quality and expertise in classifying and counting parasitized and uninfected cells. Such an examination could be arduous for large-scale diagnoses resulting in poor quality. State-of-the-art image-analysis based computer- aided diagnosis (CADx) methods using machine learning (ML) techniques, applied to microscopic images of the smears using hand-engineered features demand expertise in analyzing morphological, textural, and positional variations of the region of interest (ROI). In contrast, Convolutional Neural Networks (CNN), a class of deep learning (DL) models promise highly scalable and superior results with end-to-end feature extraction and classification. Automated malaria screening using DL techniques could, therefore, serve as an effective diagnostic aid. In this study, we evaluate the performance of pre-trainedCNNbased DL models as feature extractors toward classifying parasitized and uninfected cells to aid in improved disease screening. We experimentally determine the optimal model layers for feature extraction from the underlying data. Statistical validation of the results demonstrates the use of pre-trained CNNs as a promising tool for feature extraction for this purpose. © 2018 Rajaraman et al.","Blood smear; Computer-aided diagnosis; Convolutional Neural Networks; Deep learning; Feature extraction; Machine learning; Malaria; Pre-trained models; Screening","area under the curve; Article; artificial neural network; blood smear; computer assisted diagnosis; controlled study; convolutional neural network; diagnostic accuracy; feature extraction; human; major clinical study; malaria falciparum; mobile application; parasite identification; Plasmodium; sensitivity and specificity; software","PeerJ Inc.","21678359","","","","Article","Scopus","2-s2.0-85045518625"
"Eminaga O.; Eminaga N.; Semjonow A.; Breil B.","Eminaga, Okyaz (36659252500); Eminaga, Nurettin (57215357755); Semjonow, Axel (7005948572); Breil, Bernhard (26321338500)","36659252500; 57215357755; 7005948572; 26321338500","Diagnostic classification of cystoscopic images using deep convolutional neural networks","2018","JCO Clinical Cancer Informatics","38","10.1200/CCI.17.00126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072159164&doi=10.1200%2fCCI.17.00126&partnerID=40&md5=44ed2ab75841348ff130ac07cb075127","Stanford Medical School, Stanford, CA, United States; University Hospital of Cologne, Cologne, France; St Mauritius Therapy Clinic, Meerbusch, Germany; University Hospital Muenster, Germany; Niederrhein University of Applied Sciences, Krefeld, Germany","Eminaga O., Stanford Medical School, Stanford, CA, United States, University Hospital of Cologne, Cologne, France; Eminaga N., St Mauritius Therapy Clinic, Meerbusch, Germany; Semjonow A., University Hospital Muenster, Germany; Breil B., Niederrhein University of Applied Sciences, Krefeld, Germany","Purpose The recognition of cystoscopic findings remains challenging for young colleagues and depends on the examiner's skills. Computer-aided diagnosis tools using feature extraction and deep learning show promise as instruments to perform diagnostic classification. Materials and Methods Our study considered 479 patient cases that represented 44 urologic findings. Image color was linearly normalized and was equalized by applying contrast-limited adaptive histogram equalization. Because these findings can be viewed via cystoscopy from every possible angle and side, we ultimately generated images rotated in 10-degree grades and flipped them vertically or horizontally, which resulted in 18,681 images. After image preprocessing, we developed deep convolutional neural network (CNN) models (ResNet50, VGG-19, VGG-16, InceptionV3, and Xception) and evaluated these models using F1 scores. Furthermore, we proposed two CNN concepts: 90%-previous-layer filter size and harmonic-series filter size. A training set (60%), a validation set (10%), and a test set (30%) were randomly generated from the study data set. All models were trained on the training set, validated on the validation set, and evaluated on the test set. Results The Xception-based model achieved the highest F1 score (99.52%), followed by models that were based on ResNet50 (99.48%) and the harmonic-series concept (99.45%). All images with cancer lesions were correctly determined by these models. When the focus was on the images misclassified by the model with the best performance, 7.86% of images that showed bladder stones with indwelling catheter and 1.43% of images that showed bladder diverticulum were falsely classified. Conclusion The results of this study show the potential of deep learning for the diagnostic classification of cystoscopic images. Future work will focus on integration of artificial intelligence-aided cystoscopy into clinical routines and possibly expansion to other clinical endoscopy applications. © 2018 American Society of Clinical Oncology.","","Article; artificial neural network; bladder cancer; bladder diverticulum; bladder stone; cancer diagnosis; cancer patient; computer assisted diagnosis; controlled study; cystoscopy; data analysis; data processing; deep convolutional neural network; diagnostic error; disease classification; human; image analysis; image processing; intermethod comparison; machine learning; performance; priority journal; scoring system; validation study","American Society of Clinical Oncology","24734276","","","30652604","Article","Scopus","2-s2.0-85072159164"
"Catherine Tamilarasi F.; Shanmugam J.","Catherine Tamilarasi, F. (57203995643); Shanmugam, J. (7003544236)","57203995643; 7003544236","Artificial intelligence - A perspective on applicability of Deep learning, Computer Vision and semantic web technologies in Medical Informatics","2018","International Journal of Engineering and Technology(UAE)","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082344000&partnerID=40&md5=fd2d547076360205f65b4017c3fc6751","BIHER, India","Catherine Tamilarasi F., BIHER, India; Shanmugam J., BIHER, India","The main purpose of this paper is to Introduce Basic concepts related to Machine Learning, explore relationship between Machine learning, Deep learning and Computer Vision, understand few Deep learning models and evaluate few frequently used Deep models for computer vision. Recently Deep learning has penetrated its presence in all fields and Medical Informatics has promising applications in future. In this paper we touch base few areas of applications of Deep learning algorithms and their usage in Computer Vision. © 2018 Authors.","Artificial intelligence; Computer Vision; Deep learning; Machine Learning; Neural networks; Ontology","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082344000"
"Mehryary F.; Björne J.; Salakoski T.; Ginter F.","Mehryary, Farrokh (57191054318); Björne, Jari (16027873300); Salakoski, Tapio (6602620645); Ginter, Filip (8537001100)","57191054318; 16027873300; 6602620645; 8537001100","Potent pairing: ensemble of long short-term memory networks and support vector machine for chemical-protein relation extraction","2018","Database : the journal of biological databases and curation","9","10.1093/database/bay120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058912022&doi=10.1093%2fdatabase%2fbay120&partnerID=40&md5=da1c97870a5e34f0a79d9a3541a52d6b","TurkuNLP group, Department of Future Technologies, University of Turku, Turku, Finland; University of Turku Graduate School, Turku, Finland; Turku Centre for Computer Science, Turku, Finland","Mehryary F., TurkuNLP group, Department of Future Technologies, University of Turku, Turku, Finland, University of Turku Graduate School, Turku, Finland; Björne J., TurkuNLP group, Department of Future Technologies, University of Turku, Turku, Finland, Turku Centre for Computer Science, Turku, Finland; Salakoski T., TurkuNLP group, Department of Future Technologies, University of Turku, Turku, Finland, Turku Centre for Computer Science, Turku, Finland; Ginter F., TurkuNLP group, Department of Future Technologies, University of Turku, Turku, Finland","Biomedical researchers regularly discover new interactions between chemical compounds/drugs and genes/proteins, and report them in research literature. Having knowledge about these interactions is crucially important in many research areas such as precision medicine and drug discovery. The BioCreative VI Task 5 (CHEMPROT) challenge promotes the development and evaluation of computer systems that can automatically recognize and extract statements of such interactions from biomedical literature. We participated in this challenge with a Support Vector Machine (SVM) system and a deep learning-based system (ST-ANN), and achieved an F-score of 60.99 for the task. After the shared task, we have significantly improved the performance of the ST-ANN system. Additionally, we have developed a new deep learning-based system (I-ANN) that considerably outperforms the ST-ANN system. Both ST-ANN and I-ANN systems are centered around training an ensemble of artificial neural networks and utilizing different bidirectional Long Short-Term Memory (LSTM) chains for representing the shortest dependency path and/or the full sentence. By combining the predictions of the SVM and the I-ANN systems, we achieved an F-score of 63.10 for the task, improving our previous F-score by 2.11 percentage points. Our systems are fully open-source and publicly available. We highlight that the systems we present in this study are not applicable only to the BioCreative VI Task 5, but can be effortlessly re-trained to extract any types of relations of interest, with no modifications of the source code required, if a manually annotated corpus is provided as training data in a specific file format.","","Data Mining; Databases, Chemical; Databases, Protein; Deep Learning; Drug Discovery; Neural Networks (Computer); Pharmaceutical Preparations; Protein Binding; Proteins; Support Vector Machine; drug; protein; protein binding; artificial neural network; chemical database; chemistry; data mining; drug development; metabolism; procedures; protein database; support vector machine","NLM (Medline)","17580463","","","30576487","Article","Scopus","2-s2.0-85058912022"
"Ching T.; Himmelstein D.S.; Beaulieu-Jones B.K.; Kalinin A.A.; Do B.T.; Way G.P.; Ferrero E.; Agapow P.-M.; Zietz M.; Hoffman M.M.; Xie W.; Rosen G.L.; Lengerich B.J.; Israeli J.; Lanchantin J.; Woloszynek S.; Carpenter A.E.; Shrikumar A.; Xu J.; Cofer E.M.; Lavender C.A.; Turaga S.C.; Alexandari A.M.; Lu Z.; Harris D.J.; Decaprio D.; Qi Y.; Kundaje A.; Peng Y.; Wiley L.K.; Segler M.H.S.; Boca S.M.; Swamidass S.J.; Huang A.; Gitter A.; Greene C.S.","Ching, Travers (56375181900); Himmelstein, Daniel S. (36089852400); Beaulieu-Jones, Brett K. (57191613442); Kalinin, Alexandr A. (56701977200); Do, Brian T. (57221341388); Way, Gregory P. (56487417600); Ferrero, Enrico (57195493651); Agapow, Paul-Michael (36914410600); Zietz, Michael (57201525789); Hoffman, Michael M. (57203496086); Xie, Wei (57191583099); Rosen, Gail L. (9335288900); Lengerich, Benjamin J. (56132063200); Israeli, Johnny (57201526180); Lanchantin, Jack (57191491253); Woloszynek, Stephen (54400504600); Carpenter, Anne E. (8063969900); Shrikumar, Avanti (55353539500); Xu, Jinbo (57203521425); Cofer, Evan M. (57201519518); Lavender, Christopher A. (57203070991); Turaga, Srinivas C. (24823119500); Alexandari, Amr M. (57201522407); Lu, Zhiyong (23474115300); Harris, David J. (57052021500); Decaprio, Dave (8773007600); Qi, Yanjun (8324721600); Kundaje, Anshul (57207801534); Peng, Yifan (55561453200); Wiley, Laura K. (55831993000); Segler, Marwin H. S. (37081859100); Boca, Simina M. (21740680900); Swamidass, S. Joshua (10045433000); Huang, Austin (15757372000); Gitter, Anthony (27867713200); Greene, Casey S. (12141512300)","56375181900; 36089852400; 57191613442; 56701977200; 57221341388; 56487417600; 57195493651; 36914410600; 57201525789; 57203496086; 57191583099; 9335288900; 56132063200; 57201526180; 57191491253; 54400504600; 8063969900; 55353539500; 57203521425; 57201519518; 57203070991; 24823119500; 57201522407; 23474115300; 57052021500; 8773007600; 8324721600; 57207801534; 55561453200; 55831993000; 37081859100; 21740680900; 10045433000; 15757372000; 27867713200; 12141512300","Opportunities and obstacles for deep learning in biology and medicine","2018","Journal of the Royal Society Interface","1174","10.1098/rsif.2017.0387","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045190865&doi=10.1098%2frsif.2017.0387&partnerID=40&md5=7819fb5a55c7648fe86ee5936fd9454e","Molecular Biosciences and Bioengineering Graduate Program, University of Hawaii at Manoa, Honolulu, HI, United States; Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Genomics and Computational Biology Graduate Group, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Department of Computational Medicine and Bioinformatics, University of Michigan Medical School, Ann Arbor, MI, United States; Harvard Medical School, Boston, MA, United States; Computational Biology and Stats, Target Sciences, GlaxoSmithKline, Stevenage, United Kingdom; Data Science Institute, Imperial College London, London, United Kingdom; Princess Margaret Cancer Centre, Toronto, ON, Canada; Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Department of Electrical and Computer Engineering, Ecological and Evolutionary Signal-processing and Informatics Laboratory, Drexel University, Philadelphia, PA, United States; Computational Biology Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States; Biophysics Program, Stanford, CA, United States; Department of Computer Science, Stanford, CA, United States; Department of Genetics, Stanford University, Stanford, CA, United States; Department of Computer Science, University of Virginia, Charlottesville, VA, United States; Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Toyota Technological Institute at Chicago, Chicago, IL, United States; Department of Computer Science, Trinity University, San Antonio, TX, United States; Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, United States; Integrative Bioinformatics, National Institute of Environmental Health Sciences, Research Triangle Park, NC, United States; Janelia Research Campus, Howard Hughes Medical Institute, Ashburn, VA, United States; National Center for Biotechnology Information and National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; Department of Wildlife Ecology and Conservation, University of Florida, Gainesville, FL, United States; ClosedLoop.ai, Austin, TX, United States; Division of Biomedical Informatics and Personalized Medicine, University of Colorado School of Medicine, Aurora, CO, United States; Institute of Organic Chemistry, Westfälische Wilhelms-Universität Münster, Münster, Germany; Innovation Center for Biomedical Informatics, Washington, DC, United States; Department of Pathology and Immunology, Washington University in Saint Louis, St Louis, MO, United States; Department of Medicine, Brown University, Providence, RI, United States; Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison, Madison, WI, United States; Morgridge Institute for Research, Madison, WI, United States","Ching T., Molecular Biosciences and Bioengineering Graduate Program, University of Hawaii at Manoa, Honolulu, HI, United States; Himmelstein D.S., Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Beaulieu-Jones B.K., Genomics and Computational Biology Graduate Group, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Kalinin A.A., Department of Computational Medicine and Bioinformatics, University of Michigan Medical School, Ann Arbor, MI, United States; Do B.T., Harvard Medical School, Boston, MA, United States; Way G.P., Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Ferrero E., Computational Biology and Stats, Target Sciences, GlaxoSmithKline, Stevenage, United Kingdom; Agapow P.-M., Data Science Institute, Imperial College London, London, United Kingdom; Zietz M., Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Hoffman M.M., Princess Margaret Cancer Centre, Toronto, ON, Canada, Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada, Department of Computer Science, University of Toronto, Toronto, ON, Canada; Xie W., Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Rosen G.L., Department of Electrical and Computer Engineering, Ecological and Evolutionary Signal-processing and Informatics Laboratory, Drexel University, Philadelphia, PA, United States; Lengerich B.J., Computational Biology Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States; Israeli J., Biophysics Program, Stanford, CA, United States; Lanchantin J., Department of Computer Science, University of Virginia, Charlottesville, VA, United States; Woloszynek S., Department of Electrical and Computer Engineering, Ecological and Evolutionary Signal-processing and Informatics Laboratory, Drexel University, Philadelphia, PA, United States; Carpenter A.E., Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Shrikumar A., Department of Computer Science, Stanford, CA, United States; Xu J., Toyota Technological Institute at Chicago, Chicago, IL, United States; Cofer E.M., Department of Computer Science, Trinity University, San Antonio, TX, United States, Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, United States; Lavender C.A., Integrative Bioinformatics, National Institute of Environmental Health Sciences, Research Triangle Park, NC, United States; Turaga S.C., Janelia Research Campus, Howard Hughes Medical Institute, Ashburn, VA, United States; Alexandari A.M., Department of Computer Science, Stanford, CA, United States; Lu Z., National Center for Biotechnology Information and National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; Harris D.J., Department of Wildlife Ecology and Conservation, University of Florida, Gainesville, FL, United States; Decaprio D., ClosedLoop.ai, Austin, TX, United States; Qi Y., Department of Computer Science, University of Virginia, Charlottesville, VA, United States; Kundaje A., Department of Computer Science, Stanford, CA, United States, Department of Genetics, Stanford University, Stanford, CA, United States; Peng Y., Janelia Research Campus, Howard Hughes Medical Institute, Ashburn, VA, United States; Wiley L.K., Division of Biomedical Informatics and Personalized Medicine, University of Colorado School of Medicine, Aurora, CO, United States; Segler M.H.S., Institute of Organic Chemistry, Westfälische Wilhelms-Universität Münster, Münster, Germany; Boca S.M., Innovation Center for Biomedical Informatics, Washington, DC, United States; Swamidass S.J., Department of Pathology and Immunology, Washington University in Saint Louis, St Louis, MO, United States; Huang A., Department of Medicine, Brown University, Providence, RI, United States; Gitter A., Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison, Madison, WI, United States, Morgridge Institute for Research, Madison, WI, United States; Greene C.S., Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States","Deep learning describes a class of machine learning algorithms that are capable of combining raw inputs into layers of intermediate features. These algorithms have recentlyshown impressive results across avarietyof domains. Biology and medicine are data-rich disciplines, but the data are complex and often ill-understood.Hence, deep learning techniques may be particularly well suited to solve problems of these fields. We examine applications of deep learning to a variety of biomedical problems-patient classification, fundamental biological processes and treatment of patients-And discuss whether deep learning will be able to transform these tasks or if the biomedical sphere poses unique challenges. Following from an extensive literature review, we find that deep learning has yet to revolutionize biomedicine or definitively resolve any of the most pressing challenges in the field, but promising advances have been made on the prior state of the art. Even though improvements over previous baselines have been modest in general, the recent progress indicates that deep learning methods will provide valuable means for speeding up or aiding human investigation. Though progress has been made linking a specific neural network's prediction to input features, understanding how users should interpret these models to make testable hypotheses about the system under study remains an open challenge. Furthermore, the limited amount of labelled data for training presents problems in some domains, as do legal and privacy constraints on work with sensitive health records. Nonetheless, we foresee deep learning enabling changes at both bench and bedside with the potential to transform several areas of biology and medicine. © 2018 The Authors.","","Algorithms; Biomedical Research; Biomedical Technology; Decision Making; Deep Learning; Delivery of Health Care; Disease; Drug Design; Electronic Health Records; Humans; Terminology as Topic; Biology; Learning algorithms; Patient treatment; Problem solving; ligand; microRNA; transcription factor; Biological process; Biology and medicine; Biomedical problems; Learning methods; Learning techniques; Literature reviews; Privacy constraints; State of the art; Article; biological activity; biomedicine; clinical decision making; clinical trial (topic); cryoelectron microscopy; deep learning; disease classification; diseases; drug design; drug repositioning; electronic health record; enhancer region; gene expression; gene sequence; health care; human; illness trajectory; imaging; law; longitudinal study; machine learning; major histocompatibility complex; metagenomics; morphology; neuroscience; patient coding; phenotype; prediction; privacy; promoter region; protein binding; protein protein interaction; protein secondary structure; protein tertiary structure; RNA binding; RNA splicing; single cell analysis; standardization; algorithm; decision making; genetics; health care delivery; medical research; medical technology; nomenclature; procedures; Deep learning","Royal Society Publishing","17425689","","","29618526","Article","Scopus","2-s2.0-85045190865"
"Bhavya Sai V.; Narasimha Rao G.; Ramya M.; Sujana Sree Y.; Anuradha T.","Bhavya Sai, V. (57215911936); Narasimha Rao, G. (57215917541); Ramya, M. (57192594312); Sujana Sree, Y. (57215917552); Anuradha, T. (57201579175)","57215911936; 57215917541; 57192594312; 57215917552; 57201579175","Classification of skin cancer images using tensorflow and inception V3","2018","International Journal of Engineering and Technology(UAE)","19","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074418423&partnerID=40&md5=bbc1693699dae945dc42543004f5514c","V R Siddhartha Engineering College, Kanuru, Vijayawada, India","Bhavya Sai V., V R Siddhartha Engineering College, Kanuru, Vijayawada, India; Narasimha Rao G., V R Siddhartha Engineering College, Kanuru, Vijayawada, India; Ramya M., V R Siddhartha Engineering College, Kanuru, Vijayawada, India; Sujana Sree Y., V R Siddhartha Engineering College, Kanuru, Vijayawada, India; Anuradha T., V R Siddhartha Engineering College, Kanuru, Vijayawada, India","It is easy for a human eye to distinguish the images of similar appearance but classifying the images like that of cancer affected skin requires more expertise. And as the skin cancer cases are increasing globally, it requires more number of human experts. To overcome this problem, many people are working on constructing machine learning classifiers which can detect skin cancer automatically by classifying skin images. This paper concentrates on developing an approach for predicting skin cancer by classifying images using deep convolution neural network. The proposed work is tested on standard cancer dataset and obtained more than 85% accuracy. © 2018 Authors.","Classification; Deep convolution neural network; Inception-V3; Machine learning; Tensor flow","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85074418423"
"Krishna Y.H.; Kumar K.B.; Maharshi D.; Amudhavel J.","Krishna, Yaram Hari (57215911633); Kumar, Kanagala Bharath (57215913812); Maharshi, Dasari (57217951270); Amudhavel, J. (36781870300)","57215911633; 57215913812; 57217951270; 36781870300","Image processing and restriction of video downloads using cloud","2018","International Journal of Engineering and Technology(UAE)","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082353982&partnerID=40&md5=cf8cd87311f13e313084c5958f2ba4fc","Computer Science Engineering, K L E F, Guntur, India","Krishna Y.H., Computer Science Engineering, K L E F, Guntur, India; Kumar K.B., Computer Science Engineering, K L E F, Guntur, India; Maharshi D., Computer Science Engineering, K L E F, Guntur, India; Amudhavel J., Computer Science Engineering, K L E F, Guntur, India","Flower image classification using deep learning and convolutional neural network (CNN) based on machine learning in Tensor flow. Tensor flow IDE is used to implement machine learning algorithms. Flower image processing is based on supervised learning which detects the parameters of image. Parameters of the image were compared by decision algorithms. These images are classified by neurons in convolutional neural network. Video processing based on machine learning is used in restriction of downloading the videos by preventing the second response from the server and enabling the debugging of the video by removing the request from the user. © 2018 Authors.","Convolutional neural network (CNN); Debugging; Deep neural network; Image detection; Machine learning; Video restriction","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082353982"
"Zeng Y.; Qian L.; Ren J.","Zeng, Yujun (56567100100); Qian, Lilin (57191201112); Ren, Junkai (57190883598)","56567100100; 57191201112; 57190883598","Evolutionary hierarchical sparse extreme learning autoencoder network for object recognition","2018","Symmetry","5","10.3390/sym10100474","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055742009&doi=10.3390%2fsym10100474&partnerID=40&md5=e79fb44ae536c3857130e7cb20b37791","College of Intelligence Science, National University of Defense Technology, Changsha, 410073, China","Zeng Y., College of Intelligence Science, National University of Defense Technology, Changsha, 410073, China; Qian L., College of Intelligence Science, National University of Defense Technology, Changsha, 410073, China; Ren J., College of Intelligence Science, National University of Defense Technology, Changsha, 410073, China","Extreme learning machine (ELM), characterized by its fast learning efficiency and great generalization ability, has been applied to various object recognition tasks. When extended to the stacked autoencoder network, which is a typical symmetrical representation learning model architecture, ELM manages to realize hierarchical feature extraction and classification, which is what deep neural networks usually do, but with much less training time. Nevertheless, the input weights and biases of the hidden nodes in ELM are generated according to a random distribution and may lead to the occurrence of non-optimal and redundant parameters that deteriorate discriminative features, which will have a bad influence on the final classification effect. In this paper, a novel sparse autoencoder derived from ELM and differential evolution is proposed and integrated into a hierarchical hybrid autoencoder network to accomplish the end-to-end learning with raw visible light camera sensor images and applied to several typical object recognition problems. Experimental results show that the proposed method is able to obtain competitive or better performance than current relevant methods with acceptable or less time consumption. © 2018 by the authors.","Autoencoder; Differential evolution; Hierarchical extreme learning machine","","MDPI AG","20738994","","","","Article","Scopus","2-s2.0-85055742009"
"Lee C.K.; Hofer I.; Gabel E.; Baldi P.; Cannesson M.","Lee, Christine K. (57210953577); Hofer, Ira (56156183800); Gabel, Eilon (56481519100); Baldi, Pierre (7101759672); Cannesson, Maxime (23003420800)","57210953577; 56156183800; 56481519100; 7101759672; 23003420800","Development and Validation of a Deep Neural Network Model for Prediction of Postoperative In-hospital Mortality","2018","Anesthesiology","119","10.1097/ALN.0000000000002186","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059973621&doi=10.1097%2fALN.0000000000002186&partnerID=40&md5=b341d0e32028e9f3cb55f8581ff27a71","Department of Anesthesiology and Perioperative Care, University of California Irvine, Irvine, CA, United States; Department of Computer Sciences, University of California Irvine, Irvine, CA, United States; Department of Bioengineering, University of California Irvine, Irvine, CA, United States; Department of Anesthesiology and Perioperative Medicine, University of California Los Angeles, 757 Westwood Plaza, Los Angeles, 90095, CA, United States","Lee C.K., Department of Anesthesiology and Perioperative Care, University of California Irvine, Irvine, CA, United States, Department of Computer Sciences, University of California Irvine, Irvine, CA, United States; Hofer I., Department of Anesthesiology and Perioperative Medicine, University of California Los Angeles, 757 Westwood Plaza, Los Angeles, 90095, CA, United States; Gabel E., Department of Anesthesiology and Perioperative Medicine, University of California Los Angeles, 757 Westwood Plaza, Los Angeles, 90095, CA, United States; Baldi P., Department of Computer Sciences, University of California Irvine, Irvine, CA, United States; Cannesson M., Department of Anesthesiology and Perioperative Care, University of California Irvine, Irvine, CA, United States, Department of Bioengineering, University of California Irvine, Irvine, CA, United States, Department of Anesthesiology and Perioperative Medicine, University of California Los Angeles, 757 Westwood Plaza, Los Angeles, 90095, CA, United States","Background: The authors tested the hypothesis that deep neural networks trained on intraoperative features can predict postoperative in-hospital mortality. Methods: The data used to train and validate the algorithm consists of 59,985 patients with 87 features extracted at the end of surgery. Feed-forward networks with a logistic output were trained using stochastic gradient descent with momentum. The deep neural networks were trained on 80% of the data, with 20% reserved for testing. The authors assessed improvement of the deep neural network by adding American Society of Anesthesiologists (ASA) Physical Status Classification and robustness of the deep neural network to a reduced feature set. The networks were then compared to ASA Physical Status, logistic regression, and other published clinical scores including the Surgical Apgar, Preoperative Score to Predict Postoperative Mortality, Risk Quantification Index, and the Risk Stratification Index. Results: In-hospital mortality in the training and test sets were 0.81% and 0.73%. The deep neural network with a reduced feature set and ASA Physical Status classification had the highest area under the receiver operating characteristics curve, 0.91 (95% CI, 0.88 to 0.93). The highest logistic regression area under the curve was found with a reduced feature set and ASA Physical Status (0.90, 95% CI, 0.87 to 0.93). The Risk Stratification Index had the highest area under the receiver operating characteristics curve, at 0.97 (95% CI, 0.94 to 0.99). Conclusions: Deep neural networks can predict in-hospital mortality based on automatically extractable intraoperative data, but are not (yet) superior to existing methods. Copyright © 2018, the American Society of Anesthesiologists, Inc. Wolters Kluwer Health, Inc. All Rights Reserved. Anesthesiology 2018; 129:649-62","","Adult; Aged; Female; Hospital Mortality; Humans; Machine Learning; Male; Middle Aged; Neural Networks (Computer); Postoperative Complications; Predictive Value of Tests; ROC Curve; adult; anesthesiologist; area under the curve; article; controlled study; female; hospital mortality; human; major clinical study; male; prediction; preoperative evaluation; receiver operating characteristic; stochastic model; stratification; surgical mortality; validation process; aged; artificial neural network; hospital mortality; machine learning; middle aged; mortality; postoperative complication; predictive value; trends; validation study","Lippincott Williams and Wilkins","00033022","","ANESA","29664888","Article","Scopus","2-s2.0-85059973621"
"Abiyev R.H.; Ma'aitah M.K.S.","Abiyev, Rahib H. (14631704300); Ma'aitah, Mohammad Khaleel Sallam (57201307351)","14631704300; 57201307351","Deep Convolutional Neural Networks for Chest Diseases Detection","2018","Journal of Healthcare Engineering","227","10.1155/2018/4168538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051578955&doi=10.1155%2f2018%2f4168538&partnerID=40&md5=752344f9de3e516ac385252f6cd27338","Department of Computer Engineering, Near East University, North Cyprus, Mersin-10, Turkey","Abiyev R.H., Department of Computer Engineering, Near East University, North Cyprus, Mersin-10, Turkey; Ma'aitah M.K.S., Department of Computer Engineering, Near East University, North Cyprus, Mersin-10, Turkey","Chest diseases are very serious health problems in the life of people. These diseases include chronic obstructive pulmonary disease, pneumonia, asthma, tuberculosis, and lung diseases. The timely diagnosis of chest diseases is very important. Many methods have been developed for this purpose. In this paper, we demonstrate the feasibility of classifying the chest pathologies in chest X-rays using conventional and deep learning approaches. In the paper, convolutional neural networks (CNNs) are presented for the diagnosis of chest diseases. The architecture of CNN and its design principle are presented. For comparative purpose, backpropagation neural networks (BPNNs) with supervised learning, competitive neural networks (CpNNs) with unsupervised learning are also constructed for diagnosis chest diseases. All the considered networks CNN, BPNN, and CpNN are trained and tested on the same chest X-ray database, and the performance of each network is discussed. Comparative results in terms of accuracy, error rate, and training time between the networks are presented. © 2018 Rahib H. Abiyev and Mohammad Khaleel Sallam Ma'aitah.","","Algorithms; Deep Learning; Humans; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Respiratory Tract Diseases; Backpropagation; Convolution; Diagnosis; Neural networks; Pulmonary diseases; X rays; Back propagation neural networks; Chronic obstructive pulmonary disease; Competitive neural network; Convolutional neural network; Deep convolutional neural networks; Design Principles; Learning approach; Training time; Article; artificial neural network; comparative study; convolutional neural network; diagnostic value; disease classification; feasibility study; human; major clinical study; mathematical computing; supervised machine learning; thorax disease; thorax radiography; algorithm; computer assisted diagnosis; diagnostic imaging; procedures; respiratory tract disease; Deep neural networks","Hindawi Limited","20402295","","","30154989","Article","Scopus","2-s2.0-85051578955"
"Yepes A.J.; MacKinlay A.; Gunn N.; Schieber C.; Faux N.; Downton M.; Goudey B.; Martin R.L.","Yepes, Antonio Jimeno (57190230099); MacKinlay, Andrew (35559028000); Gunn, Natalie (56405671700); Schieber, Christine (26638453900); Faux, Noel (55976959000); Downton, Matthew (8693320500); Goudey, Benjamin (54393054300); Martin, Richard L. (57201382783)","57190230099; 35559028000; 56405671700; 26638453900; 55976959000; 8693320500; 54393054300; 57201382783","A hybrid approach for automated mutation annotation of the extended human mutation landscape in scientific literature","2018","AMIA ... Annual Symposium proceedings. AMIA Symposium","4","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062376514&partnerID=40&md5=c83c0e60650ea13e636e66a0f5b3346c","IBM Research, VIC, Australia; IBM Watson Health, MA, Cambridge, United States","Yepes A.J., IBM Research, VIC, Australia; MacKinlay A., IBM Research, VIC, Australia; Gunn N., IBM Research, VIC, Australia; Schieber C., IBM Research, VIC, Australia; Faux N., IBM Research, VIC, Australia; Downton M., IBM Research, VIC, Australia; Goudey B., IBM Research, VIC, Australia; Martin R.L., IBM Watson Health, MA, Cambridge, United States","As the cost of DNA sequencing continues to fall, an increasing amount of information on human genetic variation is being produced that could help progress precision medicine. However, information about such mutations is typically first made available in the scientific literature, and is then later manually curated into more standardized genomic databases. This curation process is expensive, time-consuming and many variants do not end up being fully curated, if at all. Detecting mutations in the literature is the first key step towards automating this process. However, most of the current methods have focused on identifying mutations that follow existing nomenclatures. In this work, we show that there is a large number of mutations that are missed by using this standard approach. Furthermore, we implement the first mutation annotator to cover an extended mutation landscape, and we show that its F1 performance is the same performance as human annotation (F1 78.29 for manual annotation vs F1 79.56 for automatic annotation).","","Data Mining; Databases, Genetic; Deep Learning; DNA Mutational Analysis; Humans; Machine Learning; Mutation; comparative study; data mining; dna mutational analysis; genetic database; human; machine learning; mutation; procedures","NLM (Medline)","1942597X","","","30815103","Article","Scopus","2-s2.0-85062376514"
"Nahid A.-A.; Mikaelian A.; Kong Y.","Nahid, Abdullah-Al (35732264400); Mikaelian, Aaron (57202738075); Kong, Yinan (55413643500)","35732264400; 57202738075; 55413643500","Histopathological breast-image classification with restricted Boltzmann machine along with backpropagation","2018","Biomedical Research (India)","31","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049160406&partnerID=40&md5=72153f37ff29bf2188a6a20898950c44","School of Engineering, Macquarie University, Sydney, Australia","Nahid A.-A., School of Engineering, Macquarie University, Sydney, Australia; Mikaelian A., School of Engineering, Macquarie University, Sydney, Australia; Kong Y., School of Engineering, Macquarie University, Sydney, Australia","Deaths due to cancer have increased rapidly in recent years. Among all the cancer diseases, breast cancer causes many deaths in women. A digital medical photography technique has been used for the detection of breast cancer by physicians and doctors, however, they need to give more attention and spend more time to reliably detect the cancer information from the images. Doctors are heavily reliant upon Computer Aided Diagnosis (CAD) for cancer detection and monitoring of cancer. Because of the dependence on CAD for cancer diagnosis, researchers always pay extra attention to designing an automatic CAD system for the identification and monitoring of cancer. Various methods have been used for the breast-cancer image-classification task, however, state-of-the-art deep learning techniques have been utilised for cancer image classification with success due to its self-learning and hierarchical feature-extraction ability. In this paper we have developed a Deep Neural Network (DNN) model utilising a restricted Boltzmann machine with “scaled conjugate gradient” backpropagation to classify a set of Histopathological breast-cancer images. Our experiments have been conducted on the Histopathological images collected from the BreakHis dataset. © 2018, Scientific Publishers of India. All rights reserved.","Accuracy; Classification; Deep neural network; Restricted Boltzmann machine; Tamura","Article; artificial neural network; back propagation; breast cancer; cancer classification; cancer diagnosis; computer assisted diagnosis; contrast enhancement; controlled study; Deep Neural Network model; histopathology; image analysis; image classification; image processing; image quality; machine learning; mathematical computing; noise reduction; patient monitoring; receiver operating characteristic; Restricted Boltzmann Machine","Scientific Publishers of India","0970938X","","BIRSE","","Article","Scopus","2-s2.0-85049160406"
"Thomas M.; Latha C.A.","Thomas, Merin (57209749476); Latha, C.A. (36600643300)","57209749476; 36600643300","Sentimental analysis using recurrent neural network","2018","International Journal of Engineering and Technology(UAE)","13","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079998289&partnerID=40&md5=ae2359d675703e26e8b54da9e2cfd4a8","Regional Research Center, Visvesvaraya Technological University, India; Department (CSE), AMCEngineering College, Affiliated to Visvesvaraya Technological University, Bengaluru, India","Thomas M., Regional Research Center, Visvesvaraya Technological University, India; Latha C.A., Department (CSE), AMCEngineering College, Affiliated to Visvesvaraya Technological University, Bengaluru, India","Sentiment analysis has been an important topic of discussion from two decades since Lee published his first paper on the sentimental analysis in 2002. Apart from the sentimental analysis in English, it has spread its wing to other natural languages whose significance is very important in a multi linguistic country like India. The traditional approaches in machine learning have paved better accuracy for the Analysis. Deep Learning approaches have gained its momentum in recent years in sentimental analysis. Deep learning mimics the human learning so expectations are to meet higher levels of accuracy. In this paper we have implemented sentimental analysis of tweets in South Indian language Malayalam. The model used is Recurrent Neural Networks Long Short-Term Memory, a deep learning technique to predict the sentiments analysis. Achieved accuracy was found increasing with quality and depth of the datasets. © 2018 Merin Thomas, Latha C. A.","Deep learning; Neural network; Recurrent neural network; Sentimental analysis","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85079998289"
"Wang Q.; Liu F.; Xing S.; Zhao X.","Wang, Qianqian (57200391487); Liu, Fang'ai (7406211593); Xing, Shuning (57146591900); Zhao, Xiaohui (55547111770)","57200391487; 7406211593; 57146591900; 55547111770","A new approach for advertising ctr prediction based on deep neural network via attention mechanism","2018","Computational and Mathematical Methods in Medicine","17","10.1155/2018/8056541","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054012829&doi=10.1155%2f2018%2f8056541&partnerID=40&md5=fa87c5ee581e1b50f5f803cb6c710091","School of Information Science and Engineering, Shandong Normal University, Jinan, China; School of Mathematical Science, Shandong Normal University, Jinan, China","Wang Q., School of Information Science and Engineering, Shandong Normal University, Jinan, China; Liu F., School of Information Science and Engineering, Shandong Normal University, Jinan, China; Xing S., School of Information Science and Engineering, Shandong Normal University, Jinan, China; Zhao X., School of Mathematical Science, Shandong Normal University, Jinan, China","Click-through rate prediction is critical in Internet advertising and affects web publisher's profits and advertiser's payment.The traditional method of obtaining features using feature extraction did not consider the sparseness of advertising data and the highly nonlinear association between features. To reduce the sparseness of data and to mine the hidden features in advertising data,a method that learns the sparse features is proposed. Our method exploits dimension reduction based on decomposition, takes advantage of the attention mechanism in neural network modelling,and improves FM to make feature interactions contribute differently to the prediction. We utilize stack autoencoder to explore high-order feature interactions and use improved FM for low-order feature interactions to portray the nonlinear associated relationship of features. The experiment shows that our method improves the effect of CTR prediction and produces economic benefits in Internet advertising. ©2018 Qianqian Wang et al.","","Advertising as Topic; Algorithms; Area Under Curve; Attention; Humans; Informatics; Internet; Machine Learning; Models, Statistical; Neural Networks (Computer); Reproducibility of Results; Deep neural networks; Forecasting; Marketing; Attention mechanisms; Click-through rate; Dimension reduction; Economic benefits; Feature interactions; Internet advertising; Neural network modelling; Prediction-based; advertising; article; attention; decomposition; feature extraction; Internet; prediction; profit; algorithm; area under the curve; artificial neural network; attention; human; information science; Internet; machine learning; reproducibility; statistical model; Neural networks","Hindawi Limited","1748670X","","","30302123","Article","Scopus","2-s2.0-85054012829"
"Afify H.M.; Al-Masni M.A.","Afify, Heba M. (57194277762); Al-Masni, Mohammed A. (57192575678)","57194277762; 57192575678","Taxonomy metagenomic analysis for microbial sequences in three domains system via machine learning approaches","2018","Informatics in Medicine Unlocked","2","10.1016/j.imu.2018.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047644814&doi=10.1016%2fj.imu.2018.05.004&partnerID=40&md5=0b3a43915561f621ff3fbd60c121466c","Department of Bioelectronics Engineering, MTI University, Cairo, Egypt; Department of Biomedical Engineering, Kyung Hee University, Yongin, South Korea","Afify H.M., Department of Bioelectronics Engineering, MTI University, Cairo, Egypt; Al-Masni M.A., Department of Biomedical Engineering, Kyung Hee University, Yongin, South Korea","The rapid advancements of using clinical microbiology and genome sequences encourage several taxonomic approaches, based upon both genome classification and bioinformatics surveys. This taxonomy arranges the tree of life among different organism databases and exploits the high similarly in biological information to access the best representation of genome sequences. However, there is still a challenge to find the entire hierarchy of this tree, due to the existence of the biodiversity databases, and the different classifiers, according to evolutionary or phylogenetic relationships. This paper presents the classification of three domains of microorganisms including Bacteria, Archaea, and Eukarya using two algorithms: the supper vector machine (SVM) and the deep belief network (DBN). The proposed approach utilized the alignment method and the code generation process as preprocessing steps on the EzBioCloud 16S rRNA database. In addition, this study accommodated the issue of choosing the proper reference sequence (RefSeq) and the appropriate code generation process of the genome sequences. Our results showed that the proposed method classifies the genome sequences with an overall classification accuracy of 99.99% and 99.93% for SVM and DBN classifiers using the standard RefSeq of each class, respectively. This paper enhanced the area of microbiological scientific classification through progress in using the character-based arrangement that will help in future evolutionary frameworks. © 2018","Bioinformatics; Deep belief network (DBN); Genome sequences; Supper vector machine (SVM); Taxonomy","RNA 16S; archaeon; Article; bacterium; classification; controlled study; deep belief network; eukaryote; gene sequence; machine learning; measurement accuracy; metagenomics; microbial genome; molecular evolution; nonhuman; sequence database; support vector machine; taxonomy","Elsevier Ltd","23529148","","","","Article","Scopus","2-s2.0-85047644814"
"Tran T.; Kavuluru R.","Tran, Tung (57193316218); Kavuluru, Ramakanth (23467019200)","57193316218; 23467019200","An end-to-end deep learning architecture for extracting protein-protein interactions affected by genetic mutations","2018","Database","10","10.1093/database/bay092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057262452&doi=10.1093%2fdatabase%2fbay092&partnerID=40&md5=d8524fabcab03b0e5382772d5ee88af0","Department of Computer Science, University of Kentucky, Lexington, KY, United States; Division of Biomedical Informatics, Department of Internal Medicine, University of Kentucky, Lexington, KY, United States","Tran T., Department of Computer Science, University of Kentucky, Lexington, KY, United States; Kavuluru R., Department of Computer Science, University of Kentucky, Lexington, KY, United States, Division of Biomedical Informatics, Department of Internal Medicine, University of Kentucky, Lexington, KY, United States","The BioCreative VI Track IV (mining protein interactions and mutations for precision medicine) challenge was organized in 2017 with the goal of applying biomedical text mining methods to support advancements in precision medicine approaches. As part of the challenge, a new dataset was introduced for the purpose of building a supervised relation extraction model capable of taking a test article and returning a list of interacting protein pairs identified by their Entrez Gene IDs. Specifically, such pairs represent proteins participating in a binary protein-protein interaction relation where the interaction is additionally affected by a genetic mutation - referred to as a PPIm relation. In this study, we explore an end-to-end approach for PPIm relation extraction by deploying a three-component pipeline involving deep learning-based named-entity recognition and relation classification models along with a knowledge-based approach for gene normalization. We propose several recall-focused improvements to our original challenge entry that placed second when matching on Entrez Gene ID (exact matching) and on HomoloGene ID. On exact matching, the improved system achieved new competitive test results of 37.78% micro-F1 with a precision of 38.22% and recall of 37.34% that corresponds to an improvement from the prior best system by approximately three micro-F1 points. When matching on HomoloGene IDs, we report similarly competitive test results at 46.17% micro-F1 with a precision and recall of 46.67 and 45.59%, respectively, corresponding to an improvement of more than eight micro-F1 points over the prior best result. The code for our deep learning system is made publicly available at https://github.com/bionlproc/biocppi-extraction. © The Author(s) 2018. Published by Oxford University Press.","","Algorithms; Databases, Protein; Machine Learning; Mutation; Neural Networks (Computer); Protein Interaction Maps; algorithm; artificial neural network; genetics; machine learning; mutation; protein analysis; protein database","Oxford University Press","17580463","","","30239680","Article","Scopus","2-s2.0-85057262452"
"Vasuki P.; Sesu Priya A.; Soundarya R.","Vasuki, P. (55222096300); Sesu Priya, A. (57215911541); Soundarya, R. (57215916898)","55222096300; 57215911541; 57215916898","A smart watchdog - intruder detection system","2018","International Journal of Engineering and Technology(UAE)","0","10.14419/ijet.v7i2.31.13449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082351741&doi=10.14419%2fijet.v7i2.31.13449&partnerID=40&md5=c944e850bcf9094f44115982bf754a99","Department of IT, SSN College of Engineering, Chennai, 603110, India","Vasuki P., Department of IT, SSN College of Engineering, Chennai, 603110, India; Sesu Priya A., Department of IT, SSN College of Engineering, Chennai, 603110, India; Soundarya R., Department of IT, SSN College of Engineering, Chennai, 603110, India","In todays world, Security is a matter of great concern. Security controls play a vital role in protecting resources from espionage, sabotage, damage and theft. Our proposed system is to develop a security system with improved facilities, which tries to eliminate the limitations posed by the existing security systems. The current manual security system depends mostly on human involvement, which is prone to error, and the security is concentrated only at the front door which requires subjects cooperation. To solve these issues we have proposed a Smart Watchdog System. The system watches the environment, and if there is a human activity, the system captures it. The system automatically detects faces of the individual from the activity using firmware. We have planned to maintain the database of authorised inmates and workers of a place and verifies of every individual arriver. This feature enables the system to automatically recognises the unauthorised users and gives an alert when it encounters entry of unauthorised users even without the human assistance. The system also detects the unauthorised entry in the mass. The entire system is planned to be ported to Raspberry-Pi based Embedded System supported with DC power back up. This method can be employed in ladies hostels as well as to the secured places like the data centre, atomic research centre and military where the unauthorised entry is restricted. © 2018 Authors.","Biometrics; Deep neural network; Face recognition; Image processing; Machine learning; Security system","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082351741"
"Peng X.; Ding Y.; Wihl D.; Gottesman O.; Komorowski M.; Lehman L.-W.H.; Ross A.; Faisal A.; Doshi-Velez F.","Peng, Xuefeng (57207268895); Ding, Yi (57207272608); Wihl, David (57207268778); Gottesman, Omer (55055866100); Komorowski, Matthieu (55639773100); Lehman, Li-Wei H (8416287300); Ross, Andrew (57196121909); Faisal, Aldo (6602900233); Doshi-Velez, Finale (34874672900)","57207268895; 57207272608; 57207268778; 55055866100; 55639773100; 8416287300; 57196121909; 6602900233; 34874672900","Improving Sepsis Treatment Strategies by Combining Deep and Kernel-Based Reinforcement Learning","2018","AMIA ... Annual Symposium proceedings. AMIA Symposium","42","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062378702&partnerID=40&md5=4b42267d18793a2a33a87dee831d047e","Harvard University, Paulson School of Engineering and Applied Sciences, MA, Cambridge; Harvard University, T.H. Chan School of Public Health, MA, Cambridge; Imperial College London, London, United Kingdom; MIT, Institute for Medical Engineering & Science, MA, Cambridge","Peng X., Harvard University, Paulson School of Engineering and Applied Sciences, MA, Cambridge; Ding Y., Harvard University, T.H. Chan School of Public Health, MA, Cambridge; Wihl D., Harvard University, Paulson School of Engineering and Applied Sciences, MA, Cambridge; Gottesman O., Harvard University, Paulson School of Engineering and Applied Sciences, MA, Cambridge; Komorowski M., Imperial College London, London, United Kingdom; Lehman L.-W.H., MIT, Institute for Medical Engineering & Science, MA, Cambridge; Ross A., Harvard University, Paulson School of Engineering and Applied Sciences, MA, Cambridge; Faisal A., Imperial College London, London, United Kingdom; Doshi-Velez F., Harvard University, Paulson School of Engineering and Applied Sciences, MA, Cambridge","Sepsis is the leading cause of mortality in the ICU. It is challenging to manage because individual patients respond differently to treatment. Thus, tailoring treatment to the individual patient is essential for the best outcomes. In this paper, we take steps toward this goal by applying a mixture-of-experts framework to personalize sepsis treatment. The mixture model selectively alternates between neighbor-based (kernel) and deep reinforcement learning (DRL) experts depending on patient's current history. On a large retrospective cohort, this mixture-based approach outperforms physician, kernel only, and DRL-only experts.","","Deep Learning; Fluid Therapy; Humans; Infusions, Intravenous; Intensive Care Units; Machine Learning; Medical History Taking; Observation; Retrospective Studies; Sepsis; Vasoconstrictor Agents; vasoconstrictor agent; adverse event; anamnesis; fluid therapy; human; intensive care unit; intravenous drug administration; machine learning; observation; retrospective study; sepsis","NLM (Medline)","1942597X","","","30815131","Article","Scopus","2-s2.0-85062378702"
"Li Q.; Xu Y.; Chen Z.; Liu D.; Feng S.-T.; Law M.; Ye Y.; Huang B.","Li, Qiaoliang (55552126700); Xu, Yuzhen (57204599422); Chen, Zhewei (57194406939); Liu, Dexiang (56707753700); Feng, Shi-Ting (15022257300); Law, Martin (8663654000); Ye, Yufeng (57192987451); Huang, Bingsheng (36087446500)","55552126700; 57204599422; 57194406939; 56707753700; 15022257300; 8663654000; 57192987451; 36087446500","Tumor segmentation in contrast-enhanced magnetic resonance imaging for nasopharyngeal carcinoma: Deep learning with convolutional neural network","2018","BioMed Research International","45","10.1155/2018/9128527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056322507&doi=10.1155%2f2018%2f9128527&partnerID=40&md5=1625b933a46a4189f871df7904c4627a","School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China; Department of Radiology, Guangzhou Panyu Central Hospital, Guangzhou, China; Medical Imaging Institute of Panyu, Guangzhou, China; Department of Radiology, First Affiliated Hospital, Sun Yat-Sen University, Guangzhou, China; Department of Radiology, Queen Mary Hospital, Hong Kong","Li Q., School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China; Xu Y., School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China; Chen Z., School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China; Liu D., Department of Radiology, Guangzhou Panyu Central Hospital, Guangzhou, China, Medical Imaging Institute of Panyu, Guangzhou, China; Feng S.-T., Department of Radiology, First Affiliated Hospital, Sun Yat-Sen University, Guangzhou, China; Law M., Department of Radiology, Queen Mary Hospital, Hong Kong; Ye Y., Department of Radiology, Guangzhou Panyu Central Hospital, Guangzhou, China, Medical Imaging Institute of Panyu, Guangzhou, China; Huang B., School of Biomedical Engineering, Health Science Centre, Shenzhen University, Shenzhen, China","Objectives. To evaluate the application of a deep learning architecture, based on the convolutional neural network (CNN) technique, to perform automatic tumor segmentation of magnetic resonance imaging (MRI) for nasopharyngeal carcinoma (NPC). Materials and Methods. In this prospective study, 87 MRI containing tumor regions were acquired from newly diagnosed NPC patients. These 87 MRI were augmented to >60,000 images. The proposed CNN network is composed of two phases: feature representation and scores map reconstruction. We designed a stepwise scheme to train our CNN network. To evaluate the performance of our method, we used case-by-case leave-one-out cross-validation (LOOCV). The ground truth of tumor contouring was acquired by the consensus of two experienced radiologists. Results. The mean values of dice similarity coefficient, percent match, and their corresponding ratio with our method were 0.89±0.05, 0.90±0.04, and 0.84±0.06, respectively, all of which were better than reported values in the similar studies. Conclusions. We successfully established a segmentation method for NPC based on deep learning in contrast-enhanced magnetic resonance imaging. Further clinical trials with dedicated algorithms are warranted. © 2018 Qiaoliang Li et al.","","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Nasopharyngeal Carcinoma; Neural Networks (Computer); Prospective Studies; gadodiamide; gadolinium pentetate; Article; artificial neural network; cancer patient; clinical article; comparative study; contrast enhancement; controlled study; convolutional neural network; deep learning; dynamic contrast-enhanced magnetic resonance imaging; human; image processing; image reconstruction; image segmentation; nasopharynx carcinoma; prospective study; radiologist; tumor volume; algorithm; artificial neural network; machine learning; nasopharynx carcinoma; nuclear magnetic resonance imaging; pathology; procedures","Hindawi Limited","23146133","","","30417017","Article","Scopus","2-s2.0-85056322507"
"Oliveira F.H.M.; MacHado A.R.P.; Andrade A.O.","Oliveira, Fábio Henrique M. (57192692315); MacHado, Alessandro R.P. (56425034700); Andrade, Adriano O. (7101975915)","57192692315; 56425034700; 7101975915","On the Use of t -Distributed Stochastic Neighbor Embedding for Data Visualization and Classification of Individuals with Parkinson's Disease","2018","Computational and Mathematical Methods in Medicine","30","10.1155/2018/8019232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057138380&doi=10.1155%2f2018%2f8019232&partnerID=40&md5=9cb586a3774b1e7248a21d36c15ac3de","Centre for Innovation and Technology Assessment in Health, Postgraduate Program in Electrical and Biomedical Engineering, Faculty of Electrical Engineering, Federal University of Uberlândia, Uberlândia, Brazil; Federal Institute of Science and Technology-Campus Brasília, Brasília, Brazil","Oliveira F.H.M., Centre for Innovation and Technology Assessment in Health, Postgraduate Program in Electrical and Biomedical Engineering, Faculty of Electrical Engineering, Federal University of Uberlândia, Uberlândia, Brazil, Federal Institute of Science and Technology-Campus Brasília, Brasília, Brazil; MacHado A.R.P., Centre for Innovation and Technology Assessment in Health, Postgraduate Program in Electrical and Biomedical Engineering, Faculty of Electrical Engineering, Federal University of Uberlândia, Uberlândia, Brazil; Andrade A.O., Centre for Innovation and Technology Assessment in Health, Postgraduate Program in Electrical and Biomedical Engineering, Faculty of Electrical Engineering, Federal University of Uberlândia, Uberlândia, Brazil","Parkinson's disease (PD) is a neurodegenerative disorder that remains incurable. The available treatments for the disorder include pharmacologic therapies and deep brain stimulation (DBS). These approaches may cause distinct side effects and motor responses. This work presents the application of t-distributed stochastic neighbor embedding (t-SNE), which is a machine learning algorithm for nonlinear dimensionality reduction and data visualization, for the problem of discriminating neurologically healthy individuals from those suffering from PD (treated with levodopa and DBS). Furthermore, the assessment of classification methods is presented. Inertial and electromyographic data were collected while the subjects executed a sequence of four motor tasks. The results were focused on the comparison of the classification performance of a support vector machine (SVM) while discriminating two-dimensional feature sets estimated from Principal Component Analysis (PCA), Sammon's mapping, and t-SNE. The results showed visual and statistical differences for all three investigated groups. Classification accuracy for PCA, Sammon's mapping, and t-SNE was, respectively, 73.5%, 78.6%, and 96.9% for the training set and 67.8%, 74.1%, and 76.6% for the test set. The possibility of discriminating healthy individuals from those with PD treated with levodopa and DBS highlights the fact that each treatment method produces distinct motor behavior. The scatter plots resulting from t-SNE could be used in the clinical practice as an objective tool for measuring the discrepancy between normal and abnormal motor behaviors, being thus useful for the adjustment of treatments and the follow-up of the disorder. © 2018 Fábio Henrique M. Oliveira et al.","","Algorithms; Antiparkinson Agents; Data Visualization; Deep Brain Stimulation; Electromyography; Humans; Levodopa; Machine Learning; Motor Skills; Nonlinear Dynamics; Parkinson Disease; Principal Component Analysis; Stochastic Processes; Support Vector Machine; Classification (of information); Data visualization; Dimensionality reduction; Embeddings; Learning algorithms; Mapping; Neurodegenerative diseases; Neurosurgery; Stochastic systems; Turing machines; Visualization; levodopa; antiparkinson agent; Classification accuracy; Classification methods; Classification performance; Neurodegenerative disorders; Nonlinear dimensionality reduction; Statistical differences; Stochastic neighbor embedding; Two-dimensional features; aged; algorithm; Article; artificial neural network; brain depth stimulation; clinical article; clinical practice; comparative study; controlled study; disease classification; feature extraction; follow up; Hoehn and Yahr scale; human; locomotion; machine learning; Parkinson disease; principal component analysis; stochastic model; support vector machine; t distributed stochastic neighbor embedding; task performance; visual discrimination; algorithm; classification; electromyography; machine learning; Markov chain; motor performance; nonlinear system; Parkinson disease; pathophysiology; physiology; Support vector machines","Hindawi Limited","1748670X","","","30532798","Article","Scopus","2-s2.0-85057138380"
"Sirisha G.N.V.G.; Raju G.V.P.; Amruta G.","Sirisha, G.N.V.G. (55941395000); Raju, G.V. Padma (36344046700); Amruta, G. (57215914085)","55941395000; 36344046700; 57215914085","Spam detection on online social media networks","2018","International Journal of Engineering and Technology(UAE)","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082350259&partnerID=40&md5=c61fc7cd35abf550859622bc0feed3d4","Dept. of CSE, S.R.K.R. Engineering College, Bhimavaram, India","Sirisha G.N.V.G., Dept. of CSE, S.R.K.R. Engineering College, Bhimavaram, India; Raju G.V.P., Dept. of CSE, S.R.K.R. Engineering College, Bhimavaram, India; Amruta G., Dept. of CSE, S.R.K.R. Engineering College, Bhimavaram, India","Now-a-days people are generally using social networking sites for communicating with the other users and for sharing information across the world. The online social networking sites are becoming the significant tools and are providing a common medium for number of users to communicate with each other. The large amount of information that is accessible on the social networking sites retain the cyber attackers, who generally exploit the information available for their benefits. They generally infect the user's system, appeal the victims to click on malicious links, advertise some products only to gain money. Spam profiles are becoming major security threat used by cyber criminals and also a source of unwanted ads. Twitter is one among several social networking sites which are expanding on daily basis. Spam detection in twitter has become one of the major problems these days. A twitter spam account user nature is analyzed with a target to improve detection of social spam. An innovative technique based on deep learning technology is used for the identification of spam accounts in twitter. These techniques have an advantage that they use raw data to learn high level features on their own, unlike the traditional machine learning algorithms which require native features for the application of classification model. © 2018 Authors.","Cyber criminals; Deep learning; Malicious links; Spam account","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85082350259"
"Li H.; Gong X.-J.; Yu H.; Zhou C.","Li, Hang (58607057500); Gong, Xiu-Jun (17343586700); Yu, Hua (56822179300); Zhou, Chang (57195315799)","58607057500; 17343586700; 56822179300; 57195315799","Deep neural network based predictions of protein interactions using primary sequences","2018","Molecules","89","10.3390/molecules23081923","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052707306&doi=10.3390%2fmolecules23081923&partnerID=40&md5=ec1ab30fdbd464bb127c70038136ed1f","School of Computer Science and Technology, Tianjin University, Nankai District, Tianjin, 300072, China; Tianjin Key Laboratory of Cognitive Computing and Application, Nankai District, Tianjin, 300072, China","Li H., School of Computer Science and Technology, Tianjin University, Nankai District, Tianjin, 300072, China, Tianjin Key Laboratory of Cognitive Computing and Application, Nankai District, Tianjin, 300072, China; Gong X.-J., School of Computer Science and Technology, Tianjin University, Nankai District, Tianjin, 300072, China, Tianjin Key Laboratory of Cognitive Computing and Application, Nankai District, Tianjin, 300072, China; Yu H., School of Computer Science and Technology, Tianjin University, Nankai District, Tianjin, 300072, China, Tianjin Key Laboratory of Cognitive Computing and Application, Nankai District, Tianjin, 300072, China; Zhou C., School of Computer Science and Technology, Tianjin University, Nankai District, Tianjin, 300072, China, Tianjin Key Laboratory of Cognitive Computing and Application, Nankai District, Tianjin, 300072, China","Machine learning based predictions of protein–protein interactions (PPIs) could provide valuable insights into protein functions, disease occurrence, and therapy design on a large scale. The intensive feature engineering in most of these methods makes the prediction task more tedious and trivial. The emerging deep learning technology enabling automatic feature engineering is gaining great success in various fields. However, the over-fitting and generalization of its models are not yet well investigated in most scenarios. Here, we present a deep neural network framework (DNN-PPI) for predicting PPIs using features learned automatically only from protein primary sequences. Within the framework, the sequences of two interacting proteins are sequentially fed into the encoding, embedding, convolution neural network (CNN), and long short-term memory (LSTM) neural network layers. Then, a concatenated vector of the two outputs from the previous layer is wired as the input of the fully connected neural network. Finally, the Adam optimizer is applied to learn the network weights in a back-propagation fashion. The different types of features, including semantic associations between amino acids, position-related sequence segments (motif), and their long- and short-term dependencies, are captured in the embedding, CNN and LSTM layers, respectively. When the model was trained on Pan’s human PPI dataset, it achieved a prediction accuracy of 98.78% at the Matthew’s correlation coefficient (MCC) of 97.57%. The prediction accuracies for six external datasets ranged from 92.80% to 97.89%, making them superior to those achieved with previous methods. When performed on Escherichia coli, Drosophila, and Caenorhabditis elegans datasets, DNN-PPI obtained prediction accuracies of 95.949%, 98.389%, and 98.669%, respectively. The performances in cross-species testing among the four species above coincided in their evolutionary distances. However, when testing Mus Musculus using the models from those species, they all obtained prediction accuracies of over 92.43%, which is difficult to achieve and worthy of note for further study. These results suggest that DNN-PPI has remarkable generalization and is a promising tool for identifying protein interactions. © 2018 by the authors.","Convolution neural networks; Long short-term memory neural networks; Model generalization; Protein–protein interaction","Amino Acid Sequence; Animals; Humans; Memory, Short-Term; Neural Networks (Computer); Protein Binding; Protein Interaction Mapping; protein binding; amino acid sequence; animal; artificial neural network; human; protein analysis; short term memory","MDPI AG","14203049","","MOLEF","30071670","Article","Scopus","2-s2.0-85052707306"
"Seng D.; Lin B.; Chen J.","Seng, Dewen (16556479400); Lin, Bin (57202930847); Chen, Jing (57189994414)","16556479400; 57202930847; 57189994414","Convolutional neural network and the recognition of vehicle types","2018","NeuroQuantology","2","10.14704/nq.2018.16.6.1641","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049825400&doi=10.14704%2fnq.2018.16.6.1641&partnerID=40&md5=7f9721610da5ad8d33645f670c771d26","Key Laboratory of Complex Systems Modeling and Simulation Ministry of Education, Hangzhou Dianzi University, Hangzhou, 310018, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China","Seng D., Key Laboratory of Complex Systems Modeling and Simulation Ministry of Education, Hangzhou Dianzi University, Hangzhou, 310018, China, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China; Lin B., Key Laboratory of Complex Systems Modeling and Simulation Ministry of Education, Hangzhou Dianzi University, Hangzhou, 310018, China, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China; Chen J., Key Laboratory of Complex Systems Modeling and Simulation Ministry of Education, Hangzhou Dianzi University, Hangzhou, 310018, China, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China","In machine learning, a convolutional neural network (ConvNet) is a class of deep, feed-forward artificial neural networks. Featured by low computing load and fast convergence, the network has been successfully applied to pattern recognition. This paper gives a detailed introduction to the structure, working principles and advantages of ConvNet, and applies it to the recognition of vehicle types. In reference to previous research, two deep neural networks were created, namely VGG 16 and AlexNet. The experimental results show that our methods have performed well in vehicle classification in complex background images. © 2018, Anka Publishers. All rights reserved.","Convolutional Neural Network (ConvNet); Pattern Recognition; Pooling Layer; Recognition Algorithm; Vehicle Recognition","article; nervous system; pattern recognition","Anka Publishers","13035150","","","","Article","Scopus","2-s2.0-85049825400"
"Hu G.; Wang K.; Peng Y.; Qiu M.; Shi J.; Liu L.","Hu, Gang (56949589500); Wang, Kejun (7501399380); Peng, Yuan (7403419294); Qiu, Mengran (57188845125); Shi, Jianfei (57201655577); Liu, Liangliang (57201659828)","56949589500; 7501399380; 7403419294; 57188845125; 57201655577; 57201659828","Deep Learning Methods for Underwater Target Feature Extraction and Recognition","2018","Computational Intelligence and Neuroscience","100","10.1155/2018/1214301","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045547582&doi=10.1155%2f2018%2f1214301&partnerID=40&md5=dc0498ff962283f7977df162ff2da754","College of Automation, Harbin Engineering University, Harbin, 150001, China; College of Business, Anshan Normal University, Anshan, 114007, China; 760 Research Institute of China Shipbuilding Industry, Liaoning, Anshan, China","Hu G., College of Automation, Harbin Engineering University, Harbin, 150001, China, College of Business, Anshan Normal University, Anshan, 114007, China; Wang K., College of Automation, Harbin Engineering University, Harbin, 150001, China; Peng Y., 760 Research Institute of China Shipbuilding Industry, Liaoning, Anshan, China; Qiu M., 760 Research Institute of China Shipbuilding Industry, Liaoning, Anshan, China; Shi J., College of Automation, Harbin Engineering University, Harbin, 150001, China; Liu L., College of Automation, Harbin Engineering University, Harbin, 150001, China","The classification and recognition technology of underwater acoustic signal were always an important research content in the field of underwater acoustic signal processing. Currently, wavelet transform, Hilbert-Huang transform, and Mel frequency cepstral coefficients are used as a method of underwater acoustic signal feature extraction. In this paper, a method for feature extraction and identification of underwater noise data based on CNN and ELM is proposed. An automatic feature extraction method of underwater acoustic signals is proposed using depth convolution network. An underwater target recognition classifier is based on extreme learning machine. Although convolution neural networks can execute both feature extraction and classification, their function mainly relies on a full connection layer, which is trained by gradient descent-based; the generalization ability is limited and suboptimal, so an extreme learning machine (ELM) was used in classification stage. Firstly, CNN learns deep and robust features, followed by the removing of the fully connected layers. Then ELM fed with the CNN features is used as the classifier to conduct an excellent classification. Experiments on the actual data set of civil ships obtained 93.04% recognition rate; compared to the traditional Mel frequency cepstral coefficients and Hilbert-Huang feature, recognition rate greatly improved. © 2018 Gang Hu et al.","","Acoustics; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Signal Processing, Computer-Assisted; Water; Acoustic waves; Classification (of information); Convolution; Deep learning; Extraction; Feature extraction; Knowledge acquisition; Signal processing; Speech recognition; Wavelet transforms; water; Automatic feature extraction; Classification and recognition; Convolution neural network; Feature extraction and classification; Hilbert Huang transforms; Mel frequency cepstral co-efficient; Underwater acoustic signal; Underwater target recognition; acoustics; artificial neural network; automated pattern recognition; machine learning; procedures; signal processing; Underwater acoustics","Hindawi Limited","16875265","","","29780407","Article","Scopus","2-s2.0-85045547582"
"Zakaria N.J.; Zamzuri H.; Ariff M.H.; Shapiai M.I.; Saruchi S.A.; Hassan N.","Zakaria, N.J. (57204065059); Zamzuri, H. (24779043000); Ariff, M.H. (55442983700); Shapiai, M.I. (36662724200); Saruchi, S.A. (56274638900); Hassan, N. (54938678600)","57204065059; 24779043000; 55442983700; 36662724200; 56274638900; 54938678600","Fully convolutional neural network for Malaysian road lane detection","2018","International Journal of Engineering and Technology(UAE)","4","10.14419/ijet.v7i4.11.20792","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054393603&doi=10.14419%2fijet.v7i4.11.20792&partnerID=40&md5=6d7c0664a3a55fbe9e275e4b0156a730","Faculty of Malaysia-Japan International Institute of Technology, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia; Vehicle System Engineering Ikohza, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia","Zakaria N.J., Faculty of Malaysia-Japan International Institute of Technology, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia, Vehicle System Engineering Ikohza, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia; Zamzuri H., Faculty of Malaysia-Japan International Institute of Technology, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia, Vehicle System Engineering Ikohza, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia; Ariff M.H., Faculty of Malaysia-Japan International Institute of Technology, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia, Vehicle System Engineering Ikohza, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia; Shapiai M.I., Faculty of Malaysia-Japan International Institute of Technology, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia; Saruchi S.A., Faculty of Malaysia-Japan International Institute of Technology, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia, Vehicle System Engineering Ikohza, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia; Hassan N., Faculty of Malaysia-Japan International Institute of Technology, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia, Vehicle System Engineering Ikohza, Universiti Teknologi Malaysia, Kuala Lumpur, 54100, Malaysia","Recently, a deep learning, Fully Convolutional Neural Network (FCN) has been widely studied because it can demonstrate promising results in the application of detection of objects in an image or video. Hence, the FCN approach has been proposed as one of the solution methods in mitigating the issues pertinent to Malaysia's road lane detection. Previously, FCN model for lane detection has not been tested in Malaysian road conditions. Therefore, this study investigates the further performance of this model in the Malaysia. The network model is trained and validated using the datasets obtained from Machine Learning NanoDegree. In addition, the real-time data collection has been conducted to collect the data sets for the testing at the highway and urban areas in Malaysia. Then, the collected data is used to test the performance of the FCN network in detecting the lane markings on Malaysia road. The results demonstrated that the FCN method is achieving 99% of the training and validation accuracy. © 2018 Authors.","Deep learning; Fully Convolutional Neural Network (FCN); Lane detection","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85054393603"
"Zhao L.; Wang J.; Nabil M.M.; Zhang J.","Zhao, Lingling (55340856700); Wang, Junjie (57555475000); Nabil, Mahieddine Mohammed (57204651170); Zhang, Jun (57192954311)","55340856700; 57555475000; 57204651170; 57192954311","Deep forest-based prediction of protein subcellular localization","2018","Current Gene Therapy","13","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056612090&partnerID=40&md5=848c4edf5a2f7d3068a9a1481c6da715","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Rehabilitation, Heilongjiang Province Land Reclamation Headquarters General Hospital, Harbin, China","Zhao L., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Wang J., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Nabil M.M., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Zhang J., Department of Rehabilitation, Heilongjiang Province Land Reclamation Headquarters General Hospital, Harbin, China","Motivation: Knowledge of the correct protein subcellular localization is necessary for understanding the function of a protein and revealing the mechanism of many human diseases due to protein subcellular mislocalization, which is required before approaching gene therapy to treat a disease. In addition, it is well-known that the gene therapy is an effective way to overcome disease by targeting a gene therapy product to a specific subcellular compartment. Deep neural networks to predict protein function have become increasingly popular due to large increases in the available genomics data due to its strong superiority in the non-linear classification ability. However, they still have some drawbacks such as too many hyper-parameters and sufficient amount of labeled data. Results: We present a deep forest-based protein location algorithm relying on sequence information. The prediction model uses a random forest network with a multi-layered structure to identify the subcellular regions of protein. The model was trained and tested on a latest UniProt releases protein dataset, and we demonstrate that our deep forest predict the subcellular location of proteins given only the protein sequence with high accuracy, outperforming the current state-of-art algorithms. Meanwhile, unlike the deep neural networks, it has a significantly smaller number of parameters and is much easier to train. © 2018, Bentham Science Publishers.","Algorithm’s; Deep forest; Machine learning; Protein subcellular location; Sequence information; UniProt","Algorithms; Computational Biology; Deep Learning; Genetic Therapy; Humans; Intracellular Space; Neural Networks (Computer); Protein Transport; Proteins; Reproducibility of Results; protein; accuracy; algorithm; amino acid sequence; Article; cellular distribution; computer model; decision tree; gene sequence; gene therapy; genetic algorithm; genetic variability; genomics; human; information processing; machine learning; mathematical model; nerve cell network; protein function; protein localization; protein motif; protein protein interaction; random forest; sequence analysis; algorithm; artificial neural network; biology; genetics; intracellular space; metabolism; procedures; protein transport; reproducibility","Bentham Science Publishers","15665232","","CGTUA","30209998","Article","Scopus","2-s2.0-85056612090"
"Li C.; Wang J.; Ye X.","Li, Chaopeng (57212831813); Wang, Jinlin (7701312457); Ye, Xiaozhou (57190034417)","57212831813; 7701312457; 57190034417","Using a recurrent neural network and restricted boltzmann machines for malicious traffic detection","2018","NeuroQuantology","36","10.14704/nq.2018.16.5.1391","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048764758&doi=10.14704%2fnq.2018.16.5.1391&partnerID=40&md5=758c283869aea9a30c641aac1c506642","National Network New Media Engineering Research Center, Institute of Acoustics, Chinese Academy of Sciences, Beijing, 100190, China; University of Chinese Academy of Sciences, Beijing, 100049, China","Li C., National Network New Media Engineering Research Center, Institute of Acoustics, Chinese Academy of Sciences, Beijing, 100190, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Wang J., National Network New Media Engineering Research Center, Institute of Acoustics, Chinese Academy of Sciences, Beijing, 100190, China; Ye X., National Network New Media Engineering Research Center, Institute of Acoustics, Chinese Academy of Sciences, Beijing, 100190, China","In the studies of intrusion detection/prevention systems (IDS/IPS) and network security situational awareness, malicious traffic detection has been given significantly more attention to prevent malicious traffic. Meanwhile, with the development of machine learning technology, an increasing number of algorithms and models have been employed for attack detection. Previous studies generally used common and typical machine learning models such as SVM, KNN, or a random forest. However, the bottleneck of these types of approaches is two-fold. The input of the model is constructed using the feature engineering method of artificially designed representation, which requires a substantial amounts expertise. Additionally, most detection methods ignore the temporal information between network packets in one micro-flow. In this paper, we regard malicious traffic detection as a classification task and propose a hybrid model that combines a recurrent neural network (RNN) with restricted Boltzmann machines (RBM) which take byte-level raw data as input without feature engineering. Specifically, distributed embedding is utilized to pre-process network data to make it more suitable for deep neural network models. Subsequently, an RBM model is used to extract the feature vectors of the network packets and an RNN model is used to extract the flow feature vector. Finally, the flow vectors are sent to the Softmax layer to obtain the detection result. Experiments based on the ISCX-2012 and DARPA-1998 published datasets show that our proposed RNN-RBM model has a greater detection accuracy, recall rate, and lower false alarm rate than most traditional machine learning models. This proves the effectiveness of the proposed RNN-RBM model in malicious traffic detection. © 2018, Anka Publishers. All rights reserved.","Malicious traffic detection; Recurrent neural network; Restricted boltzmann machine","article; embedding; machine learning; nervous system; recall","Anka Publishers","13035150","","","","Article","Scopus","2-s2.0-85048764758"
"Peng Y.; Rios A.; Kavuluru R.; Lu Z.","Peng, Yifan (55561453200); Rios, Anthony (57196060356); Kavuluru, Ramakanth (23467019200); Lu, Zhiyong (23474115300)","55561453200; 57196060356; 23467019200; 23474115300","Extracting chemical-protein relations with ensembles of SVM and deep learning models","2018","Database","64","10.1093/database/bay073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056073558&doi=10.1093%2fdatabase%2fbay073&partnerID=40&md5=7dc26755b9ab9d376cebe05030cd885e","National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; Department of Computer Science, University of Kentucky, Lexington, KY, United States; Division of Biomedical Informatics Department of Internal Medicine, University of Kentucky, Lexington, KY, United States","Peng Y., National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; Rios A., National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States, Department of Computer Science, University of Kentucky, Lexington, KY, United States; Kavuluru R., Department of Computer Science, University of Kentucky, Lexington, KY, United States, Division of Biomedical Informatics Department of Internal Medicine, University of Kentucky, Lexington, KY, United States; Lu Z., National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States","Mining relations between chemicals and proteins from the biomedical literature is an increasingly important task. The CHEMPROT track at BioCreative VI aims to promote the development and evaluation of systems that can automatically detect the chemical- protein relations in running text (PubMed abstracts). This work describes our CHEMPROT track entry, which is an ensemble of three systems, including a support vector machine, a convolutional neural network, and a recurrent neural network. Their output is combined using majority voting or stacking for final predictions. Our CHEMPROT system obtained 0.7266 in precision and 0.5735 in recall for an F-score of 0.6410 during the challenge, demonstrating the effectiveness of machine learning-based approaches for automatic relation extraction from biomedical literature and achieving the highest performance in the task during the 2017 challenge. © 2018 Oxford University Press. All rights reserved.","","Data Curation; Databases, Chemical; Databases, Protein; Machine Learning; Models, Theoretical; Neural Networks (Computer); Proteins; Reproducibility of Results; Support Vector Machine; protein; artificial neural network; chemical database; chemistry; information processing; machine learning; protein database; reproducibility; support vector machine; theoretical model","Oxford University Press","17580463","","","30020437","Article","Scopus","2-s2.0-85056073558"
"Maruyama T.; Hayashi N.; Sato Y.; Hyuga S.; Wakayama Y.; Watanabe H.; Ogura A.; Ogura T.","Maruyama, Tomoko (57216334057); Hayashi, Norio (58277261200); Sato, Yusuke (57216379549); Hyuga, Shingo (57205249244); Wakayama, Yuta (57205247855); Watanabe, Haruyuki (57192169158); Ogura, Akio (7101788617); Ogura, Toshihiro (7402985408)","57216334057; 58277261200; 57216379549; 57205249244; 57205247855; 57192169158; 7101788617; 7402985408","Comparison of medical image classification accuracy among three machine learning methods","2018","Journal of X-Ray Science and Technology","25","10.3233/XST-18386","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059273667&doi=10.3233%2fXST-18386&partnerID=40&md5=92f1599d105ecbda92e35eb4cd786af0","Department of Radiological Technology, Gunma Prefectural College of Health Sciences, 323-1 Kamioki, Maebashi, Gunma, 371-0052, Japan; Graduate School of Radiological Technology, Gunma Prefectural College of Health Sciences, Maebashi, Japan","Maruyama T., Department of Radiological Technology, Gunma Prefectural College of Health Sciences, 323-1 Kamioki, Maebashi, Gunma, 371-0052, Japan; Hayashi N., Department of Radiological Technology, Gunma Prefectural College of Health Sciences, 323-1 Kamioki, Maebashi, Gunma, 371-0052, Japan; Sato Y., Graduate School of Radiological Technology, Gunma Prefectural College of Health Sciences, Maebashi, Japan; Hyuga S., Department of Radiological Technology, Gunma Prefectural College of Health Sciences, 323-1 Kamioki, Maebashi, Gunma, 371-0052, Japan; Wakayama Y., Department of Radiological Technology, Gunma Prefectural College of Health Sciences, 323-1 Kamioki, Maebashi, Gunma, 371-0052, Japan; Watanabe H., Department of Radiological Technology, Gunma Prefectural College of Health Sciences, 323-1 Kamioki, Maebashi, Gunma, 371-0052, Japan; Ogura A., Department of Radiological Technology, Gunma Prefectural College of Health Sciences, 323-1 Kamioki, Maebashi, Gunma, 371-0052, Japan; Ogura T., Department of Radiological Technology, Gunma Prefectural College of Health Sciences, 323-1 Kamioki, Maebashi, Gunma, 371-0052, Japan","BACKGROUND: Low-quality medical images may influence the accuracy of the machine learning process. OBJECTIVE: This study was undertaken to compare accuracy of medical image classification among machine learning methods, as classification is a basic aspect of clinical image inspection. METHODS: Three types of machine learning methods were used, which include Support Vector Machine (SVM), Artificial Neural Network (ANN), and Convolution Neural Network (CNN). To investigate changes in accuracy related to image quality, we constructed a single dataset using two different file formats of DICOM (Digital Imaging and Communications in Medicine) and JPEG (Joint Photographic Experts Group). RESULTS: The JPEG format contains less color information and data capacity than the DICOM format. CNN classification was accurate for both datasets, whereas SVM and ANN accuracy decreased with the loss of data from DICOM to JPEG formats. CONCLUSIONS: CNN is more accurate than conventional machine learning methods that utilize the manual feature extraction. © 2018 - IOS Press and the authors. All rights reserved.","CNN; Deep learning; DICOM; JPEG","Databases, Factual; Deep Learning; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Support Vector Machine; Classification (of information); Deep learning; Digital Imaging and Communications in Medicine (DICOM); Medical imaging; Neural networks; Support vector machines; Color information; Conventional machines; Convolution neural network; DICOM; Joint photographic experts group; JPEG; Machine learning methods; Three machine learning methods; article; artificial neural network; diagnostic test accuracy study; digital imaging and communications in medicine; feature extraction; human; image quality; joint; machine learning; support vector machine; classification; diagnostic imaging; factual database; image processing; procedures; Image classification","IOS Press","08953996","","JXSTE","30223423","Article","Scopus","2-s2.0-85059273667"
"Lu P.; Guo S.; Zhang H.; Li Q.; Wang Y.; Wang Y.; Qi L.","Lu, Peng (57199892253); Guo, Saidi (57226632037); Zhang, Hongpo (57202249884); Li, Qihang (57202249286); Wang, Yuchen (57202254959); Wang, Yingying (36070927800); Qi, Lianxin (57202248685)","57199892253; 57226632037; 57202249884; 57202249286; 57202254959; 36070927800; 57202248685","Research on Improved Depth Belief Network-Based Prediction of Cardiovascular Diseases","2018","Journal of Healthcare Engineering","32","10.1155/2018/8954878","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047636542&doi=10.1155%2f2018%2f8954878&partnerID=40&md5=aed8ac3c1e82206253e221e728d5d823","School of Electrical Engineering, Zhengzhou University, Zhengzhou, 450001, China; Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, 450001, China; Industrial Technology Research Institute, Zhengzhou University, Zhengzhou, 450001, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou Science and Technology Institute, Zhengzhou, 450003, China","Lu P., School of Electrical Engineering, Zhengzhou University, Zhengzhou, 450001, China, Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, 450001, China; Guo S., Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, 450001, China, Industrial Technology Research Institute, Zhengzhou University, Zhengzhou, 450001, China; Zhang H., Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, 450001, China, State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou Science and Technology Institute, Zhengzhou, 450003, China; Li Q., School of Electrical Engineering, Zhengzhou University, Zhengzhou, 450001, China, Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, 450001, China; Wang Y., School of Electrical Engineering, Zhengzhou University, Zhengzhou, 450001, China; Wang Y., Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, 450001, China, Industrial Technology Research Institute, Zhengzhou University, Zhengzhou, 450001, China; Qi L., Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, 450001, China, Industrial Technology Research Institute, Zhengzhou University, Zhengzhou, 450001, China","Quantitative analysis and prediction can help to reduce the risk of cardiovascular disease. Quantitative prediction based on traditional model has low accuracy. The variance of model prediction based on shallow neural network is larger. In this paper, cardiovascular disease prediction model based on improved deep belief network (DBN) is proposed. Using the reconstruction error, the network depth is determined independently, and unsupervised training and supervised optimization are combined. It ensures the accuracy of model prediction while guaranteeing stability. Thirty experiments were performed independently on the Statlog (Heart) and Heart Disease Database data sets in the UCI database. Experimental results showed that the mean of prediction accuracy was 91.26% and 89.78%, respectively. The variance of prediction accuracy was 5.78 and 4.46, respectively. © 2018 Peng Lu et al.","","Cardiovascular Diseases; Diagnosis, Computer-Assisted; Female; Humans; Male; Models, Statistical; Neural Networks (Computer); Predictive Value of Tests; Cardiology; Forecasting; Risk assessment; Cardio-vascular disease; Deep belief network (DBN); Prediction accuracy; Prediction model; Quantitative prediction; Reconstruction error; Traditional models; Unsupervised training; Article; cardiovascular disease; deep belief network; forecasting; machine learning; prediction; artificial neural network; cardiovascular disease; computer assisted diagnosis; female; human; male; pathophysiology; predictive value; procedures; statistical model; Diseases","Hindawi Limited","20402295","","","29854369","Article","Scopus","2-s2.0-85047636542"
"Ezpeleta D.","Ezpeleta, David (6602219843)","6602219843","Artificial intelligence in neurology; [Inteligencia artificial en neurología]","2018","Kranion","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075967547&partnerID=40&md5=799cf80a8dd85a05d0ce2f1212aedcb5","Servicio de Neurología Hospital, Universitario Quirónsalud, Madrid Pozuelo de Alarcón Madrid, Spain","Ezpeleta D., Servicio de Neurología Hospital, Universitario Quirónsalud, Madrid Pozuelo de Alarcón Madrid, Spain","The concept of artificial intelligence (AI) was coined in the mid-50s. It is defined as the ability of digital environments to perform tasks usually associated with intelligent beings. AI has emulated the nervous system from its origins and applications of strong biological inspiration continue to be developed, such as deep learning or natural language processing. Medicine is not alien to these advances and the use of AI is growing, especially in the field of diseases of the nervous system, only behind neoplasms. The applications of AI in the processing and analysis of radiological and anatomopathological data, clinical and imaging diagnosis, the study of predictive/predictive factors and the optimization of therapeutic decisions stand out. This article briefly reviews some papers on AI and related technologies applied to our specialty. © 2018 Publicaciones Permanyer. All rights reserved.","Artificial intelligence; Cyberdiagnosis; Deep learning; Machine learning; Neurology","Article; artificial intelligence; human; neurology","Publicaciones Permanyer","15778843","","","","Article","Scopus","2-s2.0-85075967547"
"Nie L.; Deng L.; Fan C.; Zhan W.; Tang Y.","Nie, Lulu (57203838168); Deng, Lei (35329533000); Fan, Chao (56288406700); Zhan, Weihua (57201308229); Tang, Yongjun (56161739100)","57203838168; 35329533000; 56288406700; 57201308229; 56161739100","Prediction of protein S-sulfenylation sites using a deep belief network","2018","Current Bioinformatics","23","10.2174/1574893612666171122152208","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053132262&doi=10.2174%2f1574893612666171122152208&partnerID=40&md5=b7608563eea0cd932e4427d9ae19d86c","School of Software, Central South University, Changsha, 410075, China; School of Electronics and Computer Science, Zhejiang Wanli University, Ningbo, 315100, China; Department of Clinical Pharmacology, Xiangya Hospital, Central South University, Changsha, 410008, China; Department of Pediatrics, Xiangya Hospital, Central South University, Changsha, 410008, China","Nie L., School of Software, Central South University, Changsha, 410075, China; Deng L., School of Software, Central South University, Changsha, 410075, China; Fan C., School of Software, Central South University, Changsha, 410075, China; Zhan W., School of Electronics and Computer Science, Zhejiang Wanli University, Ningbo, 315100, China; Tang Y., Department of Clinical Pharmacology, Xiangya Hospital, Central South University, Changsha, 410008, China, Department of Pediatrics, Xiangya Hospital, Central South University, Changsha, 410008, China","Background: Protein S-Sulfenylation, the reversible oxidative modification of cysteine thiol groups to cysteine S-Sulfenic acids, is a post-translational modification (PTM) that plays a critical role in regulating protein function and signal transduction. The identification of specific protein S-sulfenylation sites is crucial to understand the underlying molecular mechanisms. Objective: We sought to develop a computational method that can effectively predict S-sulfenylation sites by using optimally extracted properties. Method: We propose DBN-Sulf, which uses a Deep Belief Network (DBN) with Restricted Boltzmann Machines (RBMs) to reduce the feature dimensions from a combination of heterogeneous information, including amino acid related features, evolutionary features, and structure-based features. Then a support vector machine (SVM) based predictor is built with the optimal features. Results: We evaluate the DBN-Sulf classifier using a training dataset including 1007 positive sites and 7837 negative sites with 5-fold cross validation, and get an AUC score of 0.80, an ACC of 0.85 and a MCC of 0.53, which are significantly better than that of the existing methods. We further validate our method on the independent test set and obtain promising results. Conclusion: The superior performance over existing S-sulfenylation site prediction approaches indicates the importance of the deep belief network-based feature extracting procedure. © 2018 Bentham Science Publishers.","Deep belief network; Restricted boltzmann machines; S-sulfenylation sites; Support vector machine","amino acid; protein S; algorithm; Article; classifier; controlled study; deep belief network; feature extraction; machine learning; priority journal; protein modification; protein s sulfenylation; support vector machine","Bentham Science Publishers B.V.","15748936","","","","Article","Scopus","2-s2.0-85053132262"
"Jang Y.; Kim S.; Kim K.; Lee D.","Jang, Yongwon (23984969700); Kim, Seunghwan (57023058300); Kim, Kiseong (55261198700); Lee, Doheon (7406661433)","23984969700; 57023058300; 55261198700; 7406661433","Deep learning-based classification with improved time resolution for physical activities of children","2018","PeerJ","11","10.7717/peerj.5764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066250141&doi=10.7717%2fpeerj.5764&partnerID=40&md5=ecdda5638c8c2e63b80d53eb90b05bed","Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Bio-medical IT Research Department, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea; BioBrain Inc., Daejeon, South Korea","Jang Y., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea, Bio-medical IT Research Department, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea; Kim S., Bio-medical IT Research Department, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea; Kim K., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea, BioBrain Inc., Daejeon, South Korea; Lee D., Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea","Background. The proportion of overweight and obese people has increased tremendously in a short period, culminating in a worldwide trend of obesity that is reaching epidemic proportions. Overweight and obesity are serious issues, especially with regard to children. This is because obese children have twice the risk of becoming obese as adults, as compared to non-obese children. Nowadays, many methods for maintaining a caloric balance exist; however, these methods are not applicable to children. In this study, a new approach for helping children monitor their activities using a convolutional neural network (CNN) is proposed, which is applicable for real-time scenarios requiring high accuracy. Methods. A total of 136 participants (86 boys and 50 girls), aged between 8.5 years and 12.5 years (mean 10.5, standard deviation 1.1), took part in this study. The participants performed various movement while wearing custom-made three-axis accelerometer modules around their waists. The data acquired by the accelerometer module was preprocessed by dividing them into small sets (128 sample points for 2.8 s). Approximately 183,600 data samples were used by the developed CNN for learning to classify ten physical activities: slow walking, fast walking, slow running, fast running, walking up the stairs, walking down the stairs, jumping rope, standing up, sitting down, and remaining still. Results. The developed CNN classified the ten activities with an overall accuracy of 81.2%. When similar activities were merged, leading to seven merged activities, the CNN classified activities with an overall accuracy of 91.1%. Activity merging also improved performance indicators, for the maximum case of 66.4% in recall, 48.5% in precision, and 57.4% in f1 score. The developed CNN classifier was compared to conventional machine learning algorithms such as the support vector machine, decision tree, and k-nearest neighbor algorithms, and the proposed CNN classifier performed the best: CNN (81.2%) > SVM (64.8%) > DT (63.9%) > kNN (55.4%) (for ten activities); CNN (91.1%) > SVM (74.4%) > DT (73.2%) > kNN (65.3%) (for the merged seven activities). Discussion. The developed algorithm distinguished physical activities with improved time resolution using short-time acceleration signals from the physical activities performed by children. This study involved algorithm development, participant recruitment, IRB approval, custom-design of a data acquisition module, and data collection. The self-selected moving speeds for walking and running (slow and fast) and the structure of staircase degraded the performance of the algorithm. However, after similar activities were merged, the effects caused by the self-selection of speed were reduced. The experimental results show that the proposed algorithm performed better than conventional algorithms. Owing to its simplicity, the proposed algorithm could be applied to real-time applicaitons. Copyright © 2018 Jang et al.","Children; Classification; Convolutional neural network; Physical activity; Time resolution","accuracy; Article; artificial neural network; body mass; body movement; body weight gain; child; decision tree; deep learning; electroencephalography; female; gait; human; human experiment; jumping; learning algorithm; machine learning; male; mathematical analysis; mathematical model; measurement accuracy; mental disease; obesity; physical activity; running; school child; sensitivity and specificity; sitting; standing; support vector machine; training; walking","PeerJ Inc.","21678359","","","","Article","Scopus","2-s2.0-85066250141"
"Yoon S.; Choi T.; Odlum M.; Mitchell D.A.; Kronish I.M.; Davidson K.W.; Finkelstein J.","Yoon, Sunmoo (35072135900); Choi, Thomas (58381627000); Odlum, Michelle (9640449600); Mitchell, Dennis A. (7403871631); Kronish, Ian M. (13006307000); Davidson, Karina W. (7203032183); Finkelstein, Joseph (7201815643)","35072135900; 58381627000; 9640449600; 7403871631; 13006307000; 7203032183; 7201815643","Machine Learning to Identify Behavioral Determinants of Oral Health in Inner City Older Hispanic Adults","2018","Studies in Health Technology and Informatics","8","10.3233/978-1-61499-880-8-253","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049565593&doi=10.3233%2f978-1-61499-880-8-253&partnerID=40&md5=29eb684441f51c3e698de86eea30ff5b","School of Nursing, Columbia University, 630W 168 street, mail code 6, New York, 10032, NY, United States; College of Dental Medicine, Columbia University, New York, NY, United States; Department of Medicine, College of Physicians and Surg., Columbia University, New York, NY, United States","Yoon S., School of Nursing, Columbia University, 630W 168 street, mail code 6, New York, 10032, NY, United States; Choi T., College of Dental Medicine, Columbia University, New York, NY, United States; Odlum M., School of Nursing, Columbia University, 630W 168 street, mail code 6, New York, 10032, NY, United States; Mitchell D.A., College of Dental Medicine, Columbia University, New York, NY, United States; Kronish I.M., Department of Medicine, College of Physicians and Surg., Columbia University, New York, NY, United States; Davidson K.W., Department of Medicine, College of Physicians and Surg., Columbia University, New York, NY, United States; Finkelstein J., College of Dental Medicine, Columbia University, New York, NY, United States","We applied machine learning techniques to a community-based behavioral dataset to build prediction models to gain insights about minority dental health and population aging as the foundation for future interventions for urban Hispanics. Our application of machine learning techniques identified emotional and systemic factors such as chronic stress and health literacy as the strongest predictors of self-reported dental health among hundreds of possible variables. Application of machine learning algorithms was useful to build prediction models to gain insights about dental health and minority population aging. © 2018 The authors and IOS Press. All rights reserved.","deep learning; Dental health; Hispanics; population aging","Aged; Algorithms; Hispanic Americans; Humans; Machine Learning; Middle Aged; Oral Health; Self Report; Artificial intelligence; Deep learning; Health; Applied machine learning; Community-based; Health literacy; Hispanics; Machine learning techniques; Population aging; Prediction model; Systemic factors; adult; aging; article; chronic stress; dental health; female; health literacy; Hispanic; human; human experiment; machine learning; male; prediction; aged; algorithm; health; middle aged; self report; Learning algorithms","IOS Press","09269630","978-161499879-2","","29968651","Article","Scopus","2-s2.0-85049565593"
"Pinto A.; McKinley R.; Alves V.; Wiest R.; Silva C.A.; Reyes M.","Pinto, Adriano (56642291100); McKinley, Richard (24178652500); Alves, Victor (7006627528); Wiest, Roland (6603714583); Silva, Carlos A. (56325790600); Reyes, Mauricio (16550617900)","56642291100; 24178652500; 7006627528; 6603714583; 56325790600; 16550617900","Stroke lesion outcome prediction based on MRI imaging combined with clinical information","2018","Frontiers in Neurology","61","10.3389/fneur.2018.01060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064505202&doi=10.3389%2ffneur.2018.01060&partnerID=40&md5=c26a74e44c2f72219e0677e2cc4ca346","CMEMS-UMinho Research Unit, University of Minho, Guimarães, Portugal; Centro Algoritmi, University of Minho, Braga, Portugal; Support Center for Advanced Neuroimaging, University Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, Bern, Switzerland; Institute for Surgical Technology and Biomechanics, University of Bern, Bern, Switzerland","Pinto A., CMEMS-UMinho Research Unit, University of Minho, Guimarães, Portugal, Centro Algoritmi, University of Minho, Braga, Portugal; McKinley R., Support Center for Advanced Neuroimaging, University Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, Bern, Switzerland; Alves V., Centro Algoritmi, University of Minho, Braga, Portugal; Wiest R., Support Center for Advanced Neuroimaging, University Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, Bern, Switzerland; Silva C.A., CMEMS-UMinho Research Unit, University of Minho, Guimarães, Portugal; Reyes M., Institute for Surgical Technology and Biomechanics, University of Bern, Bern, Switzerland","In developed countries, the second leading cause of death is stroke, which has the ischemic stroke as the most common type. The preferred diagnosis procedure involves the acquisition of multi-modal Magnetic Resonance Imaging. Besides detecting and locating the stroke lesion, Magnetic Resonance Imaging captures blood flow dynamics that guides the physician in evaluating the risks and benefits of the reperfusion procedure. However, the decision process is an intricate task due to the variability of lesion size, shape, and location, as well as the complexity of the underlying cerebral hemodynamic process. Therefore, an automatic method that predicts the stroke lesion outcome, at a 3-month follow-up, would provide an important support to the physicians’ decision process. In this work, we propose an automatic deep learning-based method for stroke lesion outcome prediction. Our main contribution resides in the combination of multi-modal Magnetic Resonance Imaging maps with non-imaging clinical meta-data: the thrombolysis in cerebral infarction scale, which categorizes the success of recanalization, achieved through mechanical thrombectomy. In our proposal, this clinical information is considered at two levels. First, at a population level by embedding the clinical information in a custom loss function used during training of our deep learning architecture. Second, at a patient-level through an extra input channel of the neural network used at testing time for a given patient case. By merging imaging with non-imaging clinical information, we aim to obtain a model aware of the principal and collateral blood flow dynamics for cases where there is no perfusion beyond the point of occlusion and for cases where the perfusion is complete after the occlusion point. © 2018 Pinto, Mckinley, Alves, Wiest, Silva and Reyes.","Deep learning; Machine learning; MRI; Prediction; Stroke","Article; automation; blood clot lysis; brain blood flow; cerebrovascular accident; clinical feature; controlled study; disease severity; dynamics; human; machine learning; major clinical study; neuroimaging; nuclear magnetic resonance imaging; prediction","Frontiers Media S.A.","16642295","","","","Article","Scopus","2-s2.0-85064505202"
"Prasad M.V.D.; Lakshmamma B.J.; Chandana A.H.; Komali K.; Manoja M.V.N.; Kumar P.R.; Prasad C.R.; Inthiyaz S.; Kiran P.S.","Prasad, M.V.D. (56006886000); Lakshmamma, B. Jwala (57215912164); Chandana, A. Hari (57807210300); Komali, K. (36622236500); Manoja, M.V.N. (57215916384); Kumar, P. Rajesh (57824087800); Prasad, Ch. Raghava (56045786300); Inthiyaz, Syed (57189375435); Kiran, P. Sasi (57215412435)","56006886000; 57215912164; 57807210300; 36622236500; 57215916384; 57824087800; 56045786300; 57189375435; 57215412435","An efficient classification of flower images with convolutional neural networks","2018","International Journal of Engineering and Technology(UAE)","31","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067271051&partnerID=40&md5=e5273047bd2802f8e57d64a2bc697c79","Department of ECE, KLEF-Deemed to be University, Guntur, A.P., India; Department of ECE, AU College of Engineering, Andhra University, Visakhapatnam, A.P., India; Department of EEE, Raghu College of Engineering, Visakhapatnam, A.P., India","Prasad M.V.D., Department of ECE, KLEF-Deemed to be University, Guntur, A.P., India; Lakshmamma B.J., Department of ECE, KLEF-Deemed to be University, Guntur, A.P., India; Chandana A.H., Department of ECE, KLEF-Deemed to be University, Guntur, A.P., India; Komali K., Department of ECE, KLEF-Deemed to be University, Guntur, A.P., India; Manoja M.V.N., Department of ECE, KLEF-Deemed to be University, Guntur, A.P., India; Kumar P.R., Department of ECE, AU College of Engineering, Andhra University, Visakhapatnam, A.P., India; Prasad C.R., Department of ECE, KLEF-Deemed to be University, Guntur, A.P., India; Inthiyaz S., Department of ECE, KLEF-Deemed to be University, Guntur, A.P., India; Kiran P.S., Department of EEE, Raghu College of Engineering, Visakhapatnam, A.P., India","Machine learning is penetrating most of the classification and recognition tasks performed by a computer. This paper proposes the classi-fication of flower images using a powerful artificial intelligence tool, convolutional neural networks (CNN). A flower image database with 9500 images is considered for the experimentation. The entire database is sub categorized into 4. The CNN training is initiated in five batches and the testing is carried out on all the for datasets. Different CNN architectures were designed and tested with our flower image data to obtain better accuracy in recognition. Various pooling schemes were implemented to improve the classification rates. We achieved 97.78% recognition rate compared to other classifier models reported on the same dataset. © 2018 M. V. D. Prasad et al.","Artificial Neural Networks (ANN); Convolutional Neural Networks (CNN); Deep learning; Flower classification; Stochastic pooling","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85067271051"
"Mamoshina P.; Ojomoko L.; Yanovich Y.; Ostrovski A.; Botezatu A.; Prikhodko P.; Izumchenko E.; Aliper A.; Romantsov K.; Zhebrak A.; Ogu I.O.; Zhavoronkov A.","Mamoshina, Polina (56893719500); Ojomoko, Lucy (55984712500); Yanovich, Yury (57003326000); Ostrovski, Alex (55557149300); Botezatu, Alex (57200288306); Prikhodko, Pavel (56352289000); Izumchenko, Eugene (57204784236); Aliper, Alexander (54889030500); Romantsov, Konstantin (57200295055); Zhebrak, Alexander (57200299926); Ogu, Iraneus Obioma (57200288218); Zhavoronkov, Alex (39862415800)","56893719500; 55984712500; 57003326000; 55557149300; 57200288306; 56352289000; 57204784236; 54889030500; 57200295055; 57200299926; 57200288218; 39862415800","Converging blockchain and next-generation artificial intelligence technologies to decentralize and accelerate biomedical research and healthcare","2018","Oncotarget","319","10.18632/oncotarget.22345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040648310&doi=10.18632%2foncotarget.22345&partnerID=40&md5=58de81bd1d718ca628bbeac5acf284dc","Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Department of Computer Science, University of Oxford, Oxford, United Kingdom; The Bitfury Group, Amsterdam, Netherlands; Department of Otolaryngology-Head and Neck Surgery, Johns Hopkins University School of Medicine, Baltimore, MD, United States; Africa Blockchain Artificial Intelligence for Healthcare Initiative, Insilico Medicine, Inc, Abuja, Nigeria; The Biogerontology Research Foundation, London, United Kingdom","Mamoshina P., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Department of Computer Science, University of Oxford, Oxford, United Kingdom; Ojomoko L., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Yanovich Y., The Bitfury Group, Amsterdam, Netherlands; Ostrovski A., The Bitfury Group, Amsterdam, Netherlands; Botezatu A., The Bitfury Group, Amsterdam, Netherlands; Prikhodko P., The Bitfury Group, Amsterdam, Netherlands; Izumchenko E., Department of Otolaryngology-Head and Neck Surgery, Johns Hopkins University School of Medicine, Baltimore, MD, United States; Aliper A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Romantsov K., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Zhebrak A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Ogu I.O., Africa Blockchain Artificial Intelligence for Healthcare Initiative, Insilico Medicine, Inc, Abuja, Nigeria; Zhavoronkov A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, The Biogerontology Research Foundation, London, United Kingdom","The increased availability of data and recent advancements in artificial intelligence present the unprecedented opportunities in healthcare and major challenges for the patients, developers, providers and regulators. The novel deep learning and transfer learning techniques are turning any data about the person into medical data transforming simple facial pictures and videos into powerful sources of data for predictive analytics. Presently, the patients do not have control over the access privileges to their medical records and remain unaware of the true value of the data they have. In this paper, we provide an overview of the next-generation artificial intelligence and blockchain technologies and present innovative solutions that may be used to accelerate the biomedical research and enable patients with new tools to control and profit from their personal data as well with the incentives to undergo constant health monitoring. We introduce new concepts to appraise and evaluate personal records, including the combination-, time- and relationship-value of the data. We also present a roadmap for a blockchain-enabled decentralized personal health data ecosystem to enable novel approaches for drug discovery, biomarker development, and preventative healthcare. A secure and transparent distributed personal data marketplace utilizing blockchain and deep learning technologies may be able to resolve the challenges faced by the regulators and return the control over personal data including medical records back to the individuals. © Mamoshina et al.","Artificial intelligence; Blockchain; Data management; Deep learning; Digital health; Health data marketplace","Article; artificial intelligence; artificial neural network; computer security; conceptual framework; consensus; data analysis; drug development; economic evaluation; groups by age; health care; health care system; information processing; learning algorithm; machine learning; medical record; medical research; medical technology; patient monitoring; prediction; predictive value; preventive medicine; profit; reimbursement; validation process","Impact Journals LLC","19492553","","","29464026","Article","Scopus","2-s2.0-85040648310"
"Yoo Y.; Tang L.Y.W.; Brosch T.; Li D.K.B.; Kolind S.; Vavasour I.; Rauscher A.; MacKay A.L.; Traboulsee A.; Tam R.C.","Yoo, Youngjin (56047857100); Tang, Lisa Y.W. (24336549500); Brosch, Tom (55892057300); Li, David K.B. (7405320868); Kolind, Shannon (13104405000); Vavasour, Irene (6603428749); Rauscher, Alexander (23390344400); MacKay, Alex L. (7202400980); Traboulsee, Anthony (6602953194); Tam, Roger C. (7006808600)","56047857100; 24336549500; 55892057300; 7405320868; 13104405000; 6603428749; 23390344400; 7202400980; 6602953194; 7006808600","Deep learning of joint myelin and T1w MRI features in normal-appearing brain tissue to distinguish between multiple sclerosis patients and healthy controls","2018","NeuroImage: Clinical","61","10.1016/j.nicl.2017.10.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031800913&doi=10.1016%2fj.nicl.2017.10.015&partnerID=40&md5=db12c5a4502e601349f243925dea08d7","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Biomedical Engineering Program, University of British Columbia, Vancouver, BC, Canada; Department of Radiology, University of British Columbia, Vancouver, BC, Canada; Division of Neurology, University of British Columbia, Department of Medicine, Vancouver, BC, Canada; MS/MRI Research Group, University of British Columbia, Djavad Mowafaghian Centre for Brain Health, Vancouver, BC, Canada; Division of Neurology, University of British Columbia, Department of Pediatrics, Vancouver, BC, Canada; Department of Physics and Astronomy, University of British Columbia, Vancouver, BC, Canada","Yoo Y., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada, Biomedical Engineering Program, University of British Columbia, Vancouver, BC, Canada, MS/MRI Research Group, University of British Columbia, Djavad Mowafaghian Centre for Brain Health, Vancouver, BC, Canada; Tang L.Y.W., Department of Radiology, University of British Columbia, Vancouver, BC, Canada, MS/MRI Research Group, University of British Columbia, Djavad Mowafaghian Centre for Brain Health, Vancouver, BC, Canada; Brosch T., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada, Biomedical Engineering Program, University of British Columbia, Vancouver, BC, Canada, MS/MRI Research Group, University of British Columbia, Djavad Mowafaghian Centre for Brain Health, Vancouver, BC, Canada; Li D.K.B., Department of Radiology, University of British Columbia, Vancouver, BC, Canada, MS/MRI Research Group, University of British Columbia, Djavad Mowafaghian Centre for Brain Health, Vancouver, BC, Canada; Kolind S., Department of Radiology, University of British Columbia, Vancouver, BC, Canada, Division of Neurology, University of British Columbia, Department of Medicine, Vancouver, BC, Canada, MS/MRI Research Group, University of British Columbia, Djavad Mowafaghian Centre for Brain Health, Vancouver, BC, Canada, Department of Physics and Astronomy, University of British Columbia, Vancouver, BC, Canada; Vavasour I., Department of Radiology, University of British Columbia, Vancouver, BC, Canada; Rauscher A., Division of Neurology, University of British Columbia, Department of Pediatrics, Vancouver, BC, Canada; MacKay A.L., Department of Radiology, University of British Columbia, Vancouver, BC, Canada, Department of Physics and Astronomy, University of British Columbia, Vancouver, BC, Canada; Traboulsee A., Division of Neurology, University of British Columbia, Department of Medicine, Vancouver, BC, Canada, MS/MRI Research Group, University of British Columbia, Djavad Mowafaghian Centre for Brain Health, Vancouver, BC, Canada; Tam R.C., Biomedical Engineering Program, University of British Columbia, Vancouver, BC, Canada, Department of Radiology, University of British Columbia, Vancouver, BC, Canada, MS/MRI Research Group, University of British Columbia, Djavad Mowafaghian Centre for Brain Health, Vancouver, BC, Canada","Myelin imaging is a form of quantitative magnetic resonance imaging (MRI) that measures myelin content and can potentially allow demyelinating diseases such as multiple sclerosis (MS) to be detected earlier. Although focal lesions are the most visible signs of MS pathology on conventional MRI, it has been shown that even tissues that appear normal may exhibit decreased myelin content as revealed by myelin-specific images (i.e., myelin maps). Current methods for analyzing myelin maps typically use global or regional mean myelin measurements to detect abnormalities, but ignore finer spatial patterns that may be characteristic of MS. In this paper, we present a machine learning method to automatically learn, from multimodal MR images, latent spatial features that can potentially improve the detection of MS pathology at early stage. More specifically, 3D image patches are extracted from myelin maps and the corresponding T1-weighted (T1w) MRIs, and are used to learn a latent joint myelin-T1w feature representation via unsupervised deep learning. Using a data set of images from MS patients and healthy controls, a common set of patches are selected via a voxel-wise t-test performed between the two groups. In each MS image, any patches overlapping with focal lesions are excluded, and a feature imputation method is used to fill in the missing values. A feature selection process (LASSO) is then utilized to construct a sparse representation. The resulting normal-appearing features are used to train a random forest classifier. Using the myelin and T1w images of 55 relapse-remitting MS patients and 44 healthy controls in an 11-fold cross-validation experiment, the proposed method achieved an average classification accuracy of 87.9% (SD = 8.4%), which is higher and more consistent across folds than those attained by regional mean myelin (73.7%, SD = 13.7%) and T1w measurements (66.7%, SD = 10.6%), or deep-learned features in either the myelin (83.8%, SD = 11.0%) or T1w (70.1%, SD = 13.6%) images alone, suggesting that the proposed method has strong potential for identifying image features that are more sensitive and specific to MS pathology in normal-appearing brain tissues. © 2017 The Authors","Deep learning; Machine learning; Magnetic resonance imaging; Multiple sclerosis; Myelin water imaging","Adult; Brain; Brain Mapping; Case-Control Studies; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Middle Aged; Multiple Sclerosis; Myelin Sheath; myelin; Article; brain tissue; clinical article; cohort analysis; controlled study; deep belief network; deep learning; demyelinating disease; female; gray matter; human; image processing; machine learning; male; multiple sclerosis; myelin water imaging; neuroimaging; nuclear magnetic resonance imaging; priority journal; three dimensional imaging; white matter; adult; brain; brain mapping; case control study; diagnostic imaging; machine learning; middle aged; multiple sclerosis; myelin sheath; pathology","Elsevier Inc.","22131582","","","29071211","Article","Scopus","2-s2.0-85031800913"
"Qiu J.X.; Yoon H.-J.; Fearn P.A.; Tourassi G.D.","Qiu, John X. (57200219582); Yoon, Hong-Jun (34874205500); Fearn, Paul A. (57217963699); Tourassi, Georgia D. (7003845683)","57200219582; 34874205500; 57217963699; 7003845683","Deep Learning for Automated Extraction of Primary Sites from Cancer Pathology Reports","2018","IEEE Journal of Biomedical and Health Informatics","94","10.1109/JBHI.2017.2700722","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040310995&doi=10.1109%2fJBHI.2017.2700722&partnerID=40&md5=99a4f92f2deab30d094677081e307d48","University of Tennessee, Knoxville, 37996, TN, United States; Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, 37831, TN, United States; National Cancer Institute, Surveillance Research Program, Bethesda, 20850, MD, United States; Biomedical Sciences Engineering, and Computing Group, Computational Sciences and Engineering Division, Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, 37831, TN, United States","Qiu J.X., University of Tennessee, Knoxville, 37996, TN, United States, Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, 37831, TN, United States; Yoon H.-J., Biomedical Sciences Engineering, and Computing Group, Computational Sciences and Engineering Division, Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, 37831, TN, United States; Fearn P.A., National Cancer Institute, Surveillance Research Program, Bethesda, 20850, MD, United States; Tourassi G.D., Biomedical Sciences Engineering, and Computing Group, Computational Sciences and Engineering Division, Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, 37831, TN, United States","Pathology reports are a primary source of information for cancer registries which process high volumes of free-text reports annually. Information extraction and coding is a manual, labor-intensive process. In this study, we investigated deep learning and a convolutional neural network (CNN), for extracting ICD-O-3 topographic codes from a corpus of breast and lung cancer pathology reports. We performed two experiments, using a CNN and a more conventional term frequency vector approach, to assess the effects of class prevalence and inter-class transfer learning. The experiments were based on a set of 942 pathology reports with human expert annotations as the gold standard. CNN performance was compared against a more conventional term frequency vector space approach. We observed that the deep learning models consistently outperformed the conventional approaches in the class prevalence experiment, resulting in micro- and macro-F score increases of up to 0.132 and 0.226, respectively, when class labels were well populated. Specifically, the best performing CNN achieved a micro-F score of 0.722 over 12 ICD-O-3 topography codes. Transfer learning provided a consistent but modest performance boost for the deep learning methods but trends were contingent on the CNN method and cancer site. These encouraging results demonstrate the potential of deep learning for automated abstraction of pathology reports. © 2013 IEEE.","Convolutional neural network; deep learning; information extraction; natural language processing; pathology reports; primary cancer site","Artificial Intelligence; Diagnosis, Computer-Assisted; Electronic Health Records; Humans; Neoplasms; Support Vector Machine; Convolution; Convolutional neural networks; Deep neural networks; Diseases; Information retrieval; Learning systems; Natural language processing systems; Pathology; Topography; Transfer learning; Vector spaces; Automated extraction; Cancer registries; Conventional approach; Labor intensive process; Learning methods; Learning models; NAtural language processing; primary cancer site; Article; Bayesian learning; bootstrapping; breast cancer; cancer epidemiology; cancer localization; cancer of unknown primary site; cancer registry; human; ICD-O-3; logistic regression analysis; lung cancer; malignant neoplasm; metric system; natural language processing; nerve cell network; network learning; pathology; support vector machine; topography; training; artificial intelligence; classification; computer assisted diagnosis; electronic health record; neoplasm; procedures; Deep learning","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28475069","Article","Scopus","2-s2.0-85040310995"
"Bipin Nair B.J.; Joy L.","Bipin Nair, B.J. (56595285000); Joy, Lijo (57200992907)","56595285000; 57200992907","A hybrid approach for hot spot prediction and deep representation of hematological protein - drug interactions","2018","International Journal of Engineering and Technology(UAE)","1","10.14419/ijet.v7i1.9.9752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042801864&doi=10.14419%2fijet.v7i1.9.9752&partnerID=40&md5=eaadf39bd7ed7e07aa25650a145ed04c","Department of Computer Science, Amrita School of Arts and Science, Mysore Campus Amrita Vishwa Vidyapeetham, India","Bipin Nair B.J., Department of Computer Science, Amrita School of Arts and Science, Mysore Campus Amrita Vishwa Vidyapeetham, India; Joy L., Department of Computer Science, Amrita School of Arts and Science, Mysore Campus Amrita Vishwa Vidyapeetham, India","In our research work we will collect the data of drugs as well as protein regarding hematic diseases, then applying feature extraction as well as classification, predict hot spot and non-hot spot then we are predicting the hot region using prediction algorithm. Parallelly from the hematological drug we are extracting the feature using molecular finger print then classifying using a classifier and applying deep learning concept to reduce the dimensionality then finally using machine learning algorithm predicting which drug will interact with the help of a hybrid approach. © 2018 Bipin Nair B. J, Lijo Joy.","Deep learning; Drug prediction; Hot region; Hot spots","","Science Publishing Corporation Inc","2227524X","","","","Article","Scopus","2-s2.0-85042801864"
"West M.D.; Labat I.; Sternberg H.; Larocca D.; Nasonkin I.; Chapman K.B.; Singh R.; Makarev E.; Aliper A.; Kazennov A.; Alekseenko A.; Shuvalov N.; Cheskidova E.; Alekseev A.; Artemov A.; Putin E.; Mamoshina P.; Pryanichnikov N.; Larocca J.; Copeland K.; Izumchenko E.; Korzinkin M.; Zhavoronkov A.","West, Michael D. (57198186874); Labat, Ivan (6508137664); Sternberg, Hal (7004046930); Larocca, Dana (7003619737); Nasonkin, Igor (6602075791); Chapman, Karen B. (7201682848); Singh, Ratnesh (55385693100); Makarev, Eugene (56893766300); Aliper, Alex (54889030500); Kazennov, Andrey (56626862100); Alekseenko, Andrey (56734255800); Shuvalov, Nikolai (54956166700); Cheskidova, Evgenia (57200410069); Alekseev, Aleksandr (57200415565); Artemov, Artem (56919393200); Putin, Evgeny (57189310406); Mamoshina, Polina (56893719500); Pryanichnikov, Nikita (57200421079); Larocca, Jacob (57200409979); Copeland, Karen (58385825400); Izumchenko, Evgeny (56269842100); Korzinkin, Mikhail (56108465700); Zhavoronkov, Alex (39862415800)","57198186874; 6508137664; 7004046930; 7003619737; 6602075791; 7201682848; 55385693100; 56893766300; 54889030500; 56626862100; 56734255800; 54956166700; 57200410069; 57200415565; 56919393200; 57189310406; 56893719500; 57200421079; 57200409979; 58385825400; 56269842100; 56108465700; 39862415800","Use of deep neural network ensembles to identify embryonicfetal transition markers: Repression of COX7A1 in embryonic and cancer cells","2018","Oncotarget","28","10.18632/oncotarget.23748","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041200676&doi=10.18632%2foncotarget.23748&partnerID=40&md5=8cee924e9c2fb4e2878735286279e351","AgeX Therapeutics, Inc., Alameda, CA, United States; BioTime, Inc., Alameda, CA, United States; Johns Hopkins University, Baltimore, MD, United States; Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation; Computer Technologies Lab, ITMO University, St. Petersburg, Russian Federation; Boulder Statistics, Boulder, CO, United States; Johns Hopkins University, School of Medicine, Department of Otolaryngology-Head and Neck Cancer Research, Baltimore, MD, United States; The Biogerontology Research Foundation, Trevissome Park, Truro, United Kingdom; Innopolis University, Innoplis, Russian Federation","West M.D., AgeX Therapeutics, Inc., Alameda, CA, United States; Labat I., AgeX Therapeutics, Inc., Alameda, CA, United States; Sternberg H., AgeX Therapeutics, Inc., Alameda, CA, United States; Larocca D., AgeX Therapeutics, Inc., Alameda, CA, United States; Nasonkin I., BioTime, Inc., Alameda, CA, United States; Chapman K.B., Johns Hopkins University, Baltimore, MD, United States; Singh R., BioTime, Inc., Alameda, CA, United States; Makarev E., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Aliper A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Kazennov A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation; Alekseenko A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Innopolis University, Innoplis, Russian Federation; Shuvalov N., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation; Cheskidova E., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation; Alekseev A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation; Artemov A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Putin E., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Computer Technologies Lab, ITMO University, St. Petersburg, Russian Federation; Mamoshina P., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Pryanichnikov N., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Larocca J., AgeX Therapeutics, Inc., Alameda, CA, United States; Copeland K., Boulder Statistics, Boulder, CO, United States; Izumchenko E., Johns Hopkins University, School of Medicine, Department of Otolaryngology-Head and Neck Cancer Research, Baltimore, MD, United States; Korzinkin M., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Zhavoronkov A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine, Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, The Biogerontology Research Foundation, Trevissome Park, Truro, United Kingdom","Here we present the application of deep neural network (DNN) ensembles trained on transcriptomic data to identify the novel markers associated with the mammalian embryonic-fetal transition (EFT). Molecular markers of this process could provide important insights into regulatory mechanisms of normal development, epimorphic tissue regeneration and cancer. Subsequent analysis of the most significant genes behind the DNNs classifier on an independent dataset of adult-derived and human embryonic stem cell (hESC)-derived progenitor cell lines led to the identification of COX7A1 gene as a potential EFT marker. COX7A1, encoding a cytochrome C oxidase subunit, was up-regulated in post-EFT murine and human cells including adult stem cells, but was not expressed in pre-EFT pluripotent embryonic stem cells or their in vitro-derived progeny. COX7A1 expression level was observed to be undetectable or low in multiple sarcoma and carcinoma cell lines as compared to normal controls. The knockout of the gene in mice led to a marked glycolytic shift reminiscent of the Warburg effect that occurs in cancer cells. The DNN approach facilitated the elucidation of a potentially new biomarker of cancer and pre-EFT cells, the embryoonco phenotype, which may potentially be used as a target for controlling the embryonic-fetal transition. © West et al.","Cancer marker; Deep neural network; Embryonic-fetal transition; Stem cells; Warburg effect","cytochrome c oxidase; cytochrome c oxidase 7A1; tumor marker; unclassified drug; adult stem cell; animal cell; Article; artificial neural network; cancer cell; carcinogenesis; classifier; controlled study; deep neural network; embryo; embryo cell; embryo development; embryonic fetal transition; embryonic stem cell; fetus; fetus development; gene identification; gene silencing; glycolysis; human; human cell; human tissue; in vitro study; machine learning; mouse; nonhuman; phase transition; phenotype; protein expression; regulatory mechanism; sarcoma cell line; support vector machine; tissue regeneration; transcriptomics","Impact Journals LLC","19492553","","","29487692","Article","Scopus","2-s2.0-85041200676"
"Manivannan S.; Li W.; Zhang J.; Trucco E.; McKenna S.J.","Manivannan, Siyamalan (55823409100); Li, Wenqi (55823995400); Zhang, Jianguo (57419074700); Trucco, Emanuele (57201786780); McKenna, Stephen J. (56781068200)","55823409100; 55823995400; 57419074700; 57201786780; 56781068200","Structure Prediction for Gland Segmentation with Hand-Crafted and Deep Convolutional Features","2018","IEEE Transactions on Medical Imaging","37","10.1109/TMI.2017.2750210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040683314&doi=10.1109%2fTMI.2017.2750210&partnerID=40&md5=e9bd5b79e94b923a3d1d737bb3f6424f","Computer Vision and Image Processing, School of Science and Engineering, University of Dundee, Dundee, DD1 4HN, United Kingdom; University of Jaffna, Jaffna, 44000, Sri Lanka; University College London, London, WC1E 6BT, United Kingdom","Manivannan S., Computer Vision and Image Processing, School of Science and Engineering, University of Dundee, Dundee, DD1 4HN, United Kingdom, University of Jaffna, Jaffna, 44000, Sri Lanka; Li W., Computer Vision and Image Processing, School of Science and Engineering, University of Dundee, Dundee, DD1 4HN, United Kingdom, University College London, London, WC1E 6BT, United Kingdom; Zhang J., Computer Vision and Image Processing, School of Science and Engineering, University of Dundee, Dundee, DD1 4HN, United Kingdom; Trucco E., Computer Vision and Image Processing, School of Science and Engineering, University of Dundee, Dundee, DD1 4HN, United Kingdom; McKenna S.J., Computer Vision and Image Processing, School of Science and Engineering, University of Dundee, Dundee, DD1 4HN, United Kingdom","We present a novel method to segment instances of glandular structures from colon histopathology images. We use a structure learning approach which represents local spatial configurations of class labels, capturing structural information normally ignored by sliding-window methods. This allows us to reveal different spatial structures of pixel labels (e.g., locations between adjacent glands, or far from glands), and to identify correctly neighboring glandular structures as separate instances. Exemplars of label structures are obtained via clustering and used to train support vector machine classifiers. The label structures predicted are then combined and post-processed to obtain segmentation maps. We combine hand-crafted, multi-scale image features with features computed by a deep convolutional network trained to map images to segmentation maps. We evaluate the proposed method on the public domain GlaS data set, which allows extensive comparisons with recent, alternative methods. Using the GlaS contest protocol, our method achieves the overall best performance. © 2017 IEEE.","gastrointestinal tract; Molecular and cellular imaging; segmentation","Adenocarcinoma; Colon; Colorectal Neoplasms; Histocytochemistry; Humans; Image Processing, Computer-Assisted; Intestinal Mucosa; Molecular Imaging; Support Vector Machine; Convolution; Support vector machines; Cellular imaging; Convolutional networks; Gastrointestinal tract; Glandular structures; Sliding window methods; Spatial configuration; Structural information; Support vector machine classifiers; article; colon; gastrointestinal tract; histopathology; learning; prediction; support vector machine; adenocarcinoma; colorectal tumor; cytochemistry; diagnostic imaging; human; image processing; intestine mucosa; molecular imaging; procedures; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28910760","Article","Scopus","2-s2.0-85040683314"
"Cang Z.; Mu L.; Wei G.-W.","Cang, Zixuan (57195259931); Mu, Lin (39762364300); Wei, Guo-Wei (7402848203)","57195259931; 39762364300; 7402848203","Representability of algebraic topology for biomolecules in machine learning based scoring and virtual screening","2018","PLoS Computational Biology","158","10.1371/journal.pcbi.1005929","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041388995&doi=10.1371%2fjournal.pcbi.1005929&partnerID=40&md5=ca62125432892df9899cafbb46215e58","Department of Mathematics, Michigan State University, East Lansing, MI, United States; Computer Science and Mathematics Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, MI, United States; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, United States","Cang Z., Department of Mathematics, Michigan State University, East Lansing, MI, United States; Mu L., Computer Science and Mathematics Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States; Wei G.-W., Department of Mathematics, Michigan State University, East Lansing, MI, United States, Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, MI, United States, Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, United States","This work introduces a number of algebraic topology approaches, including multi-component persistent homology, multi-level persistent homology, and electrostatic persistence for the representation, characterization, and description of small molecules and biomolecular complexes. In contrast to the conventional persistent homology, multi-component persistent homology retains critical chemical and biological information during the topological simplification of biomolecular geometric complexity. Multi-level persistent homology enables a tailored topological description of inter- and/or intra-molecular interactions of interest. Electrostatic persistence incorporates partial charge information into topological invariants. These topological methods are paired with Wasserstein distance to characterize similarities between molecules and are further integrated with a variety of machine learning algorithms, including k-nearest neighbors, ensemble of trees, and deep convolutional neural networks, to manifest their descriptive and predictive powers for protein-ligand binding analysis and virtual screening of small molecules. Extensive numerical experiments involving 4,414 protein-ligand complexes from the PDBBind database and 128,374 ligand-target and decoy-target pairs in the DUD database are performed to test respectively the scoring power and the discriminatory power of the proposed topological learning strategies. It is demonstrated that the present topological learning outperforms other existing methods in protein-ligand binding affinity prediction and ligand-decoy discrimination. © 2018 Cang et al.","","Algorithms; Area Under Curve; Computational Biology; Databases, Protein; Humans; Ligands; Machine Learning; Models, Neurological; Molecular Dynamics Simulation; Neural Networks (Computer); Nucleic Acids; Protein Binding; Protein Interaction Mapping; Proteins; Static Electricity; Complex networks; Deep neural networks; E-learning; Electrostatics; Learning algorithms; Molecular biology; Molecules; Nearest neighbor search; Proteins; Topology; drug; ligand; nucleic acid; protein; protein binding; Algebraic topology; Biomolecular complexes; Chemical and biologicals; Machine-learning; Multicomponents; Multilevels; Persistent homology; Representability; Small molecules; Virtual Screening; algorithm; Article; artificial neural network; binding affinity; convolutional neural network; drug screening; extra tree; gradient boosting tree; k nearest neighbor; ligand binding; machine learning; macromolecule; mutation; prediction; protein stability; random forest; area under the curve; biological model; biology; chemistry; human; molecular dynamics; procedures; protein analysis; protein database; static electricity; Ligands","Public Library of Science","1553734X","","","29309403","Article","Scopus","2-s2.0-85041388995"
"Xiao Y.; Wu J.; Lin Z.; Zhao X.","Xiao, Yawen (57195772156); Wu, Jun (56377181800); Lin, Zongli (7404229141); Zhao, Xiaodong (55472192700)","57195772156; 56377181800; 7404229141; 55472192700","A deep learning-based multi-model ensemble method for cancer prediction","2018","Computer Methods and Programs in Biomedicine","337","10.1016/j.cmpb.2017.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030330677&doi=10.1016%2fj.cmpb.2017.09.005&partnerID=40&md5=8db9734a18127c7d7bde0c5008d9136e","Department of Automation, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing of Ministry of Education, Shanghai, 200240, China; School of Biomedical Engineering Shanghai Jiao Tong University, Shanghai, 200240, China; Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, P.O. Box 400743, Charlottesville, 22904-4743, VA, United States","Xiao Y., Department of Automation, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing of Ministry of Education, Shanghai, 200240, China; Wu J., School of Biomedical Engineering Shanghai Jiao Tong University, Shanghai, 200240, China; Lin Z., Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, P.O. Box 400743, Charlottesville, 22904-4743, VA, United States; Zhao X., School of Biomedical Engineering Shanghai Jiao Tong University, Shanghai, 200240, China","Background and Objective: Cancer is a complex worldwide health problem associated with high mortality. With the rapid development of the high-throughput sequencing technology and the application of various machine learning methods that have emerged in recent years, progress in cancer prediction has been increasingly made based on gene expression, providing insight into effective and accurate treatment decision making. Thus, developing machine learning methods, which can successfully distinguish cancer patients from healthy persons, is of great current interest. However, among the classification methods applied to cancer prediction so far, no one method outperforms all the others. Methods: In this paper, we demonstrate a new strategy, which applies deep learning to an ensemble approach that incorporates multiple different machine learning models. We supply informative gene data selected by differential gene expression analysis to five different classification models. Then, a deep learning method is employed to ensemble the outputs of the five classifiers. Results: The proposed deep learning-based multi-model ensemble method was tested on three public RNA-seq data sets of three kinds of cancers, Lung Adenocarcinoma, Stomach Adenocarcinoma and Breast Invasive Carcinoma. The test results indicate that it increases the prediction accuracy of cancer for all the tested RNA-seq data sets as compared to using a single classifier or the majority voting algorithm. Conclusions: By taking full advantage of different classifiers, the proposed deep learning-based multi-model ensemble method is shown to be accurate and effective for cancer prediction. © 2017 Elsevier B.V.","Cancer prediction; Deep learning; Feature selection; Gene expression; Multi-model ensemble","Gene Expression; Humans; Machine Learning; Models, Theoretical; Neoplasms; Neural Networks (Computer); Artificial intelligence; Bioinformatics; Classification (of information); Decision making; Diseases; Feature extraction; Forecasting; Gene expression; RNA; Cancer prediction; Differential gene expressions; High-throughput sequencing; Machine learning methods; Machine learning models; Majority voting algorithm; Multi-model ensemble; Treatment decision makings; Article; breast carcinoma; cancer staging; classification algorithm; classifier; computer model; computer prediction; decision tree; gene expression; human; k nearest neighbor; lung adenocarcinoma; machine learning; malignant neoplasm; random forest; RNA sequence; stomach adenocarcinoma; support vector machine; artificial neural network; genetics; neoplasm; theoretical model; validation study; Deep learning","Elsevier Ireland Ltd","01692607","","CMPBE","29157442","Article","Scopus","2-s2.0-85030330677"
"Lőrincz A.; Csákvári M.; Fóthi Á.; Milacski Z.Á.; Sárkány A.; Tősér Z.","Lőrincz, A. (26643373200); Csákvári, M. (57197709542); Fóthi, Á. (6507202754); Milacski, Z.Á. (56578585500); Sárkány, A. (56177938600); Tősér, Z. (56298422000)","26643373200; 57197709542; 6507202754; 56578585500; 56177938600; 56298422000","Towards reasoning based representations: Deep Consistence Seeking Machine","2018","Cognitive Systems Research","4","10.1016/j.cogsys.2017.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034101865&doi=10.1016%2fj.cogsys.2017.08.004&partnerID=40&md5=d549bca6dc992df23220746d15992106","Department of Software Technology and Methodology, Faculty of Informatics, Eötvös Loránd University, Pázmány Péter sétány 1/C, Budapest, H-1117, Hungary","Lőrincz A., Department of Software Technology and Methodology, Faculty of Informatics, Eötvös Loránd University, Pázmány Péter sétány 1/C, Budapest, H-1117, Hungary; Csákvári M., Department of Software Technology and Methodology, Faculty of Informatics, Eötvös Loránd University, Pázmány Péter sétány 1/C, Budapest, H-1117, Hungary; Fóthi Á., Department of Software Technology and Methodology, Faculty of Informatics, Eötvös Loránd University, Pázmány Péter sétány 1/C, Budapest, H-1117, Hungary; Milacski Z.Á., Department of Software Technology and Methodology, Faculty of Informatics, Eötvös Loránd University, Pázmány Péter sétány 1/C, Budapest, H-1117, Hungary; Sárkány A., Department of Software Technology and Methodology, Faculty of Informatics, Eötvös Loránd University, Pázmány Péter sétány 1/C, Budapest, H-1117, Hungary; Tősér Z., Department of Software Technology and Methodology, Faculty of Informatics, Eötvös Loránd University, Pázmány Péter sétány 1/C, Budapest, H-1117, Hungary","Machine learning is making substantial progress in diverse applications. The success is mostly due to advances in deep learning. However, deep learning can make mistakes and its generalization abilities to new tasks are questionable. We ask when and how one can combine network outputs, when (i) details of the observations are evaluated by learned deep components and (ii) facts and rules are available. The Deep Consistence Seeking (DCS) machine seeks for consistent and deterministic event descriptions and improves the representation accordingly. The machine has an anomaly detection component that may trigger coherence seeking. Coherence seeking resolves conflicts between computational modules by preferring components with higher scores. We illustrate that context can help in correcting recognitions and in deriving training samples for self-training. We put these concepts into a general framework of cognition, by distinguishing creativity, rule extraction, verification, and symbol grounding. We demonstrate our approach in a driving scenario. © 2017 Elsevier B.V.","Communication; Complexity; Deep learning; Episodic description; Recognition by components; Rule-based system","Communication; Knowledge based systems; Learning systems; Anomaly detection; Complexity; Diverse applications; Episodic description; Event description; Generalization ability; Recognition by components; Symbol grounding; Article; artificial neural network; cognition; information processing; machine learning; mathematical analysis; principal component analysis; priority journal; problem solving; Deep learning","Elsevier B.V.","13890417","","CSROA","","Article","Scopus","2-s2.0-85034101865"
"Gupta A.; Müller A.T.; Huisman B.J.H.; Fuchs J.A.; Schneider P.; Schneider G.","Gupta, Anvita (57200656886); Müller, Alex T. (57164240800); Huisman, Berend J. H. (57200649947); Fuchs, Jens A. (57200646774); Schneider, Petra (55156775800); Schneider, Gisbert (7402466014)","57200656886; 57164240800; 57200649947; 57200646774; 55156775800; 7402466014","Generative Recurrent Networks for De Novo Drug Design","2018","Molecular Informatics","314","10.1002/minf.201700111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042111944&doi=10.1002%2fminf.201700111&partnerID=40&md5=a66d4d9132194ebb22ede8272be95e68","Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir–Prelog–Weg 4, Zurich, 8093, Switzerland; Stanford University, Department of Computer Science, 450 Sierra Mall, Stanford, 94305, CA, United States; inSili.com GmbH, Zurich, 8049, Switzerland","Gupta A., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir–Prelog–Weg 4, Zurich, 8093, Switzerland, Stanford University, Department of Computer Science, 450 Sierra Mall, Stanford, 94305, CA, United States; Müller A.T., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir–Prelog–Weg 4, Zurich, 8093, Switzerland; Huisman B.J.H., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir–Prelog–Weg 4, Zurich, 8093, Switzerland; Fuchs J.A., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir–Prelog–Weg 4, Zurich, 8093, Switzerland; Schneider P., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir–Prelog–Weg 4, Zurich, 8093, Switzerland, inSili.com GmbH, Zurich, 8049, Switzerland; Schneider G., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir–Prelog–Weg 4, Zurich, 8093, Switzerland","Generative artificial intelligence models present a fresh approach to chemogenomics and de novo drug design, as they provide researchers with the ability to narrow down their search of the chemical space and focus on regions of interest. We present a method for molecular de novo design that utilizes generative recurrent neural networks (RNN) containing long short-term memory (LSTM) cells. This computational model captured the syntax of molecular representation in terms of SMILES strings with close to perfect accuracy. The learned pattern probabilities can be used for de novo SMILES generation. This molecular design concept eliminates the need for virtual compound library enumeration. By employing transfer learning, we fine-tuned the RNN′s predictions for specific molecular targets. This approach enables virtual compound design without requiring secondary or external activity prediction, which could introduce error or unwanted bias. The results obtained advocate this generative RNN-LSTM system for high-impact use cases, such as low-data drug discovery, fragment based molecular design, and hit-to-lead optimization for diverse drug targets. © 2017 The Authors. Published by Wiley-VCH Verlag GmbH & Co. KGaA.","Chemogenomics; deep learning; drug discovery; machine learning; medicinal chemistry","Drug Design; Drug Discovery; Models, Chemical; Neural Networks (Computer); Quantitative Structure-Activity Relationship; nucleic acid; peroxisome proliferator activated receptor gamma; Article; artificial intelligence; chemical structure; drug design; drug development; drug targeting; generative recurrent neural network; high throughput screening; molecular library; nerve cell network; priority journal; process optimization; short term memory; transfer of learning; artificial neural network; chemical model; procedures; quantitative structure activity relation","Wiley-VCH Verlag","18681743","","MIONB","29095571","Article","Scopus","2-s2.0-85042111944"
"Xu L.; Tetteh G.; Lipkova J.; Zhao Y.; Li H.; Christ P.; Piraud M.; Buck A.; Shi K.; Menze B.H.","Xu, Lina (57199908028); Tetteh, Giles (57195716939); Lipkova, Jana (57192228929); Zhao, Yu (57195715718); Li, Hongwei (57007362000); Christ, Patrick (57192064500); Piraud, Marie (57195720890); Buck, Andreas (57203048917); Shi, Kuangyu (57215413568); Menze, Bjoern H. (35299840300)","57199908028; 57195716939; 57192228929; 57195715718; 57007362000; 57192064500; 57195720890; 57203048917; 57215413568; 35299840300","                         Automated Whole-Body Bone Lesion Detection for Multiple Myeloma on                          68                         Ga-Pentixafor PET/CT Imaging Using Deep Learning Methods                     ","2018","Contrast Media and Molecular Imaging","95","10.1155/2018/2391925","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042662090&doi=10.1155%2f2018%2f2391925&partnerID=40&md5=897bb9c7239189c5c533bfadf3a162ea","Department of Informatics, Technische Universität München, Munich, Germany; Department of Nuclear Medicine, Klinikum Rechts der Isar, TU München, Munich, Germany; Institute of Medical Engineering, Technische Universität München, Munich, Germany; Department of Nuclear Medicine, Universität Würzburg, Würzburg, Germany","Xu L., Department of Informatics, Technische Universität München, Munich, Germany, Department of Nuclear Medicine, Klinikum Rechts der Isar, TU München, Munich, Germany; Tetteh G., Department of Informatics, Technische Universität München, Munich, Germany, Institute of Medical Engineering, Technische Universität München, Munich, Germany; Lipkova J., Department of Informatics, Technische Universität München, Munich, Germany, Institute of Medical Engineering, Technische Universität München, Munich, Germany; Zhao Y., Department of Informatics, Technische Universität München, Munich, Germany, Institute of Medical Engineering, Technische Universität München, Munich, Germany; Li H., Department of Informatics, Technische Universität München, Munich, Germany, Institute of Medical Engineering, Technische Universität München, Munich, Germany; Christ P., Department of Informatics, Technische Universität München, Munich, Germany, Institute of Medical Engineering, Technische Universität München, Munich, Germany; Piraud M., Department of Informatics, Technische Universität München, Munich, Germany, Institute of Medical Engineering, Technische Universität München, Munich, Germany; Buck A., Department of Nuclear Medicine, Universität Würzburg, Würzburg, Germany; Shi K., Department of Nuclear Medicine, Klinikum Rechts der Isar, TU München, Munich, Germany; Menze B.H., Department of Informatics, Technische Universität München, Munich, Germany, Institute of Medical Engineering, Technische Universität München, Munich, Germany","                             The identification of bone lesions is crucial in the diagnostic assessment of multiple myeloma (MM).                              68                             Ga-Pentixafor PET/CT can capture the abnormal molecular expression of CXCR-4 in addition to anatomical changes. However, whole-body detection of dozens of lesions on hybrid imaging is tedious and error prone. It is even more difficult to identify lesions with a large heterogeneity. This study employed deep learning methods to automatically combine characteristics of PET and CT for whole-body MM bone lesion detection in a 3D manner. Two convolutional neural networks (CNNs), V-Net and W-Net, were adopted to segment and detect the lesions. The feasibility of deep learning for lesion detection on                              68                             Ga-Pentixafor PET/CT was first verified on digital phantoms generated using realistic PET simulation methods. Then the proposed methods were evaluated on real                              68                             Ga-Pentixafor PET/CT scans of MM patients. The preliminary results showed that deep learning method can leverage multimodal information for spatial feature representation, and W-Net obtained the best result for segmentation and lesion detection. It also outperformed traditional machine learning methods such as random forest classifier (RF), k-Nearest Neighbors (k-NN), and support vector machine (SVM). The proof-of-concept study encourages further development of deep learning approach for MM lesion detection in population study.                          © 2018 Lina Xu et al.","","Bone Neoplasms; Coordination Complexes; Deep Learning; Gallium Radioisotopes; Humans; Multiple Myeloma; Neural Networks (Computer); Peptides, Cyclic; Phantoms, Imaging; Positron Emission Tomography Computed Tomography; Receptors, CXCR4; Whole Body Imaging; gallium 68; gallium 68 pentixafor; unclassified drug; 68Ga-pentixafor; chemokine receptor CXCR4; coordination compound; CXCR4 protein, human; cyclopeptide; gallium; Article; artificial neural network; autoanalysis; bone lesion; classifier; convolutional neural network; feasibility study; human; image analysis; k nearest neighbor; machine learning; measurement precision; multiple myeloma; positron emission tomography-computed tomography; priority journal; sensitivity and specificity; spatial analysis; support vector machine; three dimensional imaging; whole body PET; bone tumor; complication; diagnostic imaging; imaging phantom; multiple myeloma; positron emission tomography-computed tomography; procedures; whole body imaging","Hindawi Limited","15554309","","","29531504","Article","Scopus","2-s2.0-85042662090"
"Lam C.; Yu C.; Huang L.; Rubin D.","Lam, Carson (57192709655); Yu, Caroline (57191911651); Huang, Laura (57200395299); Rubin, Daniel (7202307112)","57192709655; 57191911651; 57200395299; 7202307112","Retinal lesion detection with deep learning using image patches","2018","Investigative Ophthalmology and Visual Science","150","10.1167/iovs.17-22721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041127026&doi=10.1167%2fiovs.17-22721&partnerID=40&md5=409598d762828ee96af0382641d2a168","Department of Biomedical Data Science, Stanford University, Stanford, CA, United States; Department of Ophthalmology, Santa Clara Valley Medical Center, San Jose, CA, United States; Stanford University School of Medicine, Stanford, CA, United States; Department of Ophthalmology, Stanford University School of Medicine, Stanford, CA, United States; Department of Radiology, Stanford University School of Medicine, Stanford, CA, United States","Lam C., Department of Biomedical Data Science, Stanford University, Stanford, CA, United States, Department of Ophthalmology, Santa Clara Valley Medical Center, San Jose, CA, United States; Yu C., Stanford University School of Medicine, Stanford, CA, United States; Huang L., Department of Ophthalmology, Stanford University School of Medicine, Stanford, CA, United States; Rubin D., Department of Biomedical Data Science, Stanford University, Stanford, CA, United States, Department of Ophthalmology, Stanford University School of Medicine, Stanford, CA, United States, Department of Radiology, Stanford University School of Medicine, Stanford, CA, United States","PURPOSE. To develop an automated method of localizing and discerning multiple types of findings in retinal images using a limited set of training data without hard-coded feature extraction as a step toward generalizing these methods to rare disease detection in which a limited number of training data are available. METHODS. Two ophthalmologists verified 243 retinal images, labeling important subsections of the image to generate 1324 image patches containing either hemorrhages, microaneurysms, exudates, retinal neovascularization, or normal-appearing structures from the Kaggle dataset. These image patches were used to train one standard convolutional neural network to predict the presence of these five classes. A sliding window method was used to generate probability maps across the entire image. RESULTS. The method was validated on the eOphta dataset of 148 whole retinal images for microaneurysms and 47 for exudates. A pixel-wise classification of the area under the curve of the receiver operating characteristic of 0.94 and 0.95, as well as a lesion-wise area under the precision recall curve of 0.86 and 0.64, was achieved for microaneurysms and exudates, respectively. CONCLUSIONS. Regionally trained convolutional neural networks can generate lesion-specific probability maps able to detect and distinguish between subtle pathologic lesions with only a few hundred training examples per lesion. © 2018 The Authors.","Computer vision; Deep learning; Detection; Machine learning; Retina","Algorithms; Exudates and Transudates; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Probability; Reproducibility of Results; Retinal Diseases; ROC Curve; area under the curve; Article; controlled study; eye fundus; human; image quality; learning; machine learning; major clinical study; microaneurysm; ophthalmologist; predictive value; receiver operating characteristic; retina image; retina neovascularization; algorithm; artificial neural network; computer assisted diagnosis; diagnostic imaging; exudate; probability; reproducibility; retina disease","Association for Research in Vision and Ophthalmology Inc.","01460404","","IOVSD","29372258","Article","Scopus","2-s2.0-85041127026"
"Berg E.; Cherry S.R.","Berg, Eric (57210707961); Cherry, Simon R. (7102783935)","57210707961; 7102783935","Using convolutional neural networks to estimate time-of-flight from PET detector waveforms","2018","Physics in Medicine and Biology","60","10.1088/1361-6560/aa9dc5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040906349&doi=10.1088%2f1361-6560%2faa9dc5&partnerID=40&md5=e47e27a1b917aa07a2e1c00e2c09c655","Department of Biomedical Engineering, University of California-Davis, Davis, CA, United States; Department of Radiology, University of California-Davis, Sacramento, CA, United States","Berg E., Department of Biomedical Engineering, University of California-Davis, Davis, CA, United States; Cherry S.R., Department of Biomedical Engineering, University of California-Davis, Davis, CA, United States, Department of Radiology, University of California-Davis, Sacramento, CA, United States","Although there have been impressive strides in detector development for time-of-flight positron emission tomography, most detectors still make use of simple signal processing methods to extract the time-of-flight information from the detector signals. In most cases, the timing pick-off for each waveform is computed using leading edge discrimination or constant fraction discrimination, as these were historically easily implemented with analog pulse processing electronics. However, now with the availability of fast waveform digitizers, there is opportunity to make use of more of the timing information contained in the coincident detector waveforms with advanced signal processing techniques. Here we describe the application of deep convolutional neural networks (CNNs), a type of machine learning, to estimate time-of-flight directly from the pair of digitized detector waveforms for a coincident event. One of the key features of this approach is the simplicity in obtaining ground-truth-labeled data needed to train the CNN: the true time-of-flight is determined from the difference in path length between the positron emission and each of the coincident detectors, which can be easily controlled experimentally. The experimental setup used here made use of two photomultiplier tube-based scintillation detectors, and a point source, stepped in 5 mm increments over a 15 cm range between the two detectors. The detector waveforms were digitized at 10 GS s-1 using a bench-top oscilloscope. The results shown here demonstrate that CNN-based time-of-flight estimation improves timing resolution by 20% compared to leading edge discrimination (231 ps versus 185 ps), and 23% compared to constant fraction discrimination (242 ps versus 185 ps). By comparing several different CNN architectures, we also showed that CNN depth (number of convolutional and fully connected layers) had the largest impact on timing resolution, while the exact network parameters, such as convolutional filter size and number of feature maps, had only a minor influence. © 2018 Institute of Physics and Engineering in Medicine.","convolutional neural network; machine learning; positron emission tomography (PET); scintillation detector; time-of-flight (TOF)","Electronics; Electrons; Equipment Design; Humans; Machine Learning; Neural Networks (Computer); Positron-Emission Tomography; Scintillation Counting; Signal-To-Noise Ratio; Artificial intelligence; Convolution; Deep neural networks; Discriminators; Electrons; Learning systems; Neural networks; Neutron detectors; Photomultipliers; Positrons; Processing; Scintillation; Scintillation counters; Signal detection; Signal processing; Advanced signal processing; Constant fraction discriminations; Convolutional neural network; Detector development; Photo multiplier tube; Positron emission tomography (PET); Time of flight; Time of flight estimation; artificial neural network; devices; electron; electronics; equipment design; human; machine learning; positron emission tomography; procedures; scintillation counting; signal noise ratio; Positron emission tomography","Institute of Physics Publishing","00319155","","PHMBA","29182151","Article","Scopus","2-s2.0-85040906349"
"Xie J.; Liu X.; Zeng D.D.","Xie, Jiaheng (57197836923); Liu, Xiao (55813915100); Zeng, Daniel Dajun (7102694556)","57197836923; 55813915100; 7102694556","Mining e-cigarette adverse events in social media using Bi-LSTM recurrent neural network with word embedding representation","2018","Journal of the American Medical Informatics Association","36","10.1093/jamia/ocx045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040535426&doi=10.1093%2fjamia%2focx045&partnerID=40&md5=2d0c6ba0cac9176ddca9908a4158c19a","Department of Management Information Systems, University of Arizona, Tucson, AZ, United States; Department of Operation and Information Systems, University of Utah, Salt Lake City, UT, United States; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","Xie J., Department of Management Information Systems, University of Arizona, Tucson, AZ, United States; Liu X., Department of Operation and Information Systems, University of Utah, Salt Lake City, UT, United States; Zeng D.D., Department of Management Information Systems, University of Arizona, Tucson, AZ, United States, State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","Objective: Recent years have seen increased worldwide popularity of e-cigarette use. However, the risks of e-cigarettes are underexamined. Most e-cigarette adverse event studies have achieved low detection rates due to limited subject sample sizes in the experiments and surveys. Social media provides a large data repository of consumers' e-cigarette feedback and experiences, which are useful for e-cigarette safety surveillance. However, it is difficult to automatically interpret the informal and nontechnical consumer vocabulary about e-cigarettes in social media. This issue hinders the use of social media content for e-cigarette safety surveillance. Recent developments in deep neural network methods have shown promise for named entity extraction from noisy text. Motivated by these observations, we aimed to design a deep neural network approach to extract e-cigarette safety information in social media. Methods: Our deep neural language model utilizes word embedding as the representation of text input and recognizes named entity types with the state-of-the-art Bidirectional Long Short-Term Memory (Bi-LSTM) Recurrent Neural Network. Results: Our Bi-LSTM model achieved the best performance compared to 3 baseline models, with a precision of 94.10%, a recall of 91.80%, and an F-measure of 92.94%. We identified 1591 unique adverse events and 9930 unique e-cigarette components (ie, chemicals, flavors, and devices) from our research testbed. Conclusion: Although the conditional random field baseline model had slightly better precision than our approach, our Bi-LSTM model achieved much higher recall, resulting in the best F-measure. Our method can be generalized to extract medical concepts from social media for other medical applications. © The Author 2017. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.","Bi-LSTM; Deep neural network; E-cigarette adverse event; Recurrent neural network; Word embedding","Data Mining; Electronic Nicotine Delivery Systems; Humans; Neural Networks (Computer); Semantics; Social Media; Vaping; adverse device effect; Article; bidirectional long short term memory recurrent neural network; data mining; device safety; electronic cigarette; embedding; food and drug administration; human; machine learning; medical information; postmarketing surveillance; social media; artificial neural network; data mining; procedures; semantics; vaping","Oxford University Press","10675027","","JAMAF","28505280","Article","Scopus","2-s2.0-85040535426"
"Kiral-Kornek I.; Roy S.; Nurse E.; Mashford B.; Karoly P.; Carroll T.; Payne D.; Saha S.; Baldassano S.; O'Brien T.; Grayden D.; Cook M.; Freestone D.; Harrer S.","Kiral-Kornek, Isabell (55354888700); Roy, Subhrajit (36722286200); Nurse, Ewan (56763638900); Mashford, Benjamin (35751075100); Karoly, Philippa (56472523100); Carroll, Thomas (57199397223); Payne, Daniel (57199421660); Saha, Susmita (57204174017); Baldassano, Steven (57090568000); O'Brien, Terence (35518362200); Grayden, David (6507031713); Cook, Mark (7403191468); Freestone, Dean (35408997900); Harrer, Stefan (24314589900)","55354888700; 36722286200; 56763638900; 35751075100; 56472523100; 57199397223; 57199421660; 57204174017; 57090568000; 35518362200; 6507031713; 7403191468; 35408997900; 24314589900","Epileptic Seizure Prediction Using Big Data and Deep Learning: Toward a Mobile System","2018","EBioMedicine","195","10.1016/j.ebiom.2017.11.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037980011&doi=10.1016%2fj.ebiom.2017.11.032&partnerID=40&md5=7ca0a3378524bc768f69587e05916d03","IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia; The University of Melbourne, Parkville, 3010, VIC, Australia; Department of Biomedical Engineering, The University of Melbourne, Parkville, 3010, VIC, Australia","Kiral-Kornek I., IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia; Roy S., IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia; Nurse E., IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia, The University of Melbourne, Parkville, 3010, VIC, Australia; Mashford B., IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia; Karoly P., IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia, The University of Melbourne, Parkville, 3010, VIC, Australia; Carroll T., IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia, The University of Melbourne, Parkville, 3010, VIC, Australia; Payne D., IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia, The University of Melbourne, Parkville, 3010, VIC, Australia; Saha S., IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia; Baldassano S., The University of Melbourne, Parkville, 3010, VIC, Australia; O'Brien T., The University of Melbourne, Parkville, 3010, VIC, Australia; Grayden D., Department of Biomedical Engineering, The University of Melbourne, Parkville, 3010, VIC, Australia; Cook M., The University of Melbourne, Parkville, 3010, VIC, Australia; Freestone D., The University of Melbourne, Parkville, 3010, VIC, Australia; Harrer S., IBM Research – Australia, 204 Lygon Street, Carlton, 3053, VIC, Australia","Background: Seizure prediction can increase independence and allow preventative treatment for patients with epilepsy. We present a proof-of-concept for a seizure prediction system that is accurate, fully automated, patient-specific, and tunable to an individual's needs. Methods: Intracranial electroencephalography (iEEG) data of ten patients obtained from a seizure advisory system were analyzed as part of a pseudoprospective seizure prediction study. First, a deep learning classifier was trained to distinguish between preictal and interictal signals. Second, classifier performance was tested on held-out iEEG data from all patients and benchmarked against the performance of a random predictor. Third, the prediction system was tuned so sensitivity or time in warning could be prioritized by the patient. Finally, a demonstration of the feasibility of deployment of the prediction system onto an ultra-low power neuromorphic chip for autonomous operation on a wearable device is provided. Results: The prediction system achieved mean sensitivity of 69% and mean time in warning of 27%, significantly surpassing an equivalent random predictor for all patients by 42%. Conclusion: This study demonstrates that deep learning in combination with neuromorphic hardware can provide the basis for a wearable, real-time, always-on, patient-specific seizure warning system with low power consumption and reliable long-term performance. © 2017 The Authors","Artificial intelligence; Deep neural networks; Epilepsy; Mobile medical devices; Precision medicine; Seizure prediction","Benchmarking; Epilepsy; Humans; Machine Learning; Seizures; Statistics as Topic; Time Factors; Article; case report; clinical article; electroencephalography; human; machine learning; personalized medicine; priority journal; seizure; benchmarking; epilepsy; seizure; statistics; time factor","Elsevier B.V.","23523964","","","29262989","Article","Scopus","2-s2.0-85037980011"
"Heinsfeld A.S.; Franco A.R.; Craddock R.C.; Buchweitz A.; Meneguzzi F.","Heinsfeld, Anibal Sólon (57191568003); Franco, Alexandre Rosa (19640049400); Craddock, R. Cameron (36909040100); Buchweitz, Augusto (35309413000); Meneguzzi, Felipe (23393252900)","57191568003; 19640049400; 36909040100; 35309413000; 23393252900","Identification of autism spectrum disorder using deep learning and the ABIDE dataset","2018","NeuroImage: Clinical","585","10.1016/j.nicl.2017.08.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030322624&doi=10.1016%2fj.nicl.2017.08.017&partnerID=40&md5=067270091f820e03bde9308a668b396d","PUCRS, School of Computer Science, Porto Alegre, 90619, Rio Grande do Sul, Brazil; PUCRS, Brain Institute of Rio Grande do Sul (BraIns), Porto Alegre, 90619, Rio Grande do Sul, Brazil; PUCRS, School of Engineering, Porto Alegre, 90619, Rio Grande do Sul, Brazil; PUCRS, School of Medicine, Porto Alegre, 90619, Rio Grande do Sul, Brazil; PUCRS, School of Humanities, Porto Alegre, 90619, Rio Grande do Sul, Brazil; Center for the Developing Brain, Child Mind Institute, New York, 10022, New York, United States; Nathan Kline Institute for Psychiatric Research, Orangeburg, 10962, New York, United States","Heinsfeld A.S., PUCRS, School of Computer Science, Porto Alegre, 90619, Rio Grande do Sul, Brazil; Franco A.R., PUCRS, Brain Institute of Rio Grande do Sul (BraIns), Porto Alegre, 90619, Rio Grande do Sul, Brazil, PUCRS, School of Engineering, Porto Alegre, 90619, Rio Grande do Sul, Brazil, PUCRS, School of Medicine, Porto Alegre, 90619, Rio Grande do Sul, Brazil; Craddock R.C., Center for the Developing Brain, Child Mind Institute, New York, 10022, New York, United States, Nathan Kline Institute for Psychiatric Research, Orangeburg, 10962, New York, United States; Buchweitz A., PUCRS, Brain Institute of Rio Grande do Sul (BraIns), Porto Alegre, 90619, Rio Grande do Sul, Brazil, PUCRS, School of Medicine, Porto Alegre, 90619, Rio Grande do Sul, Brazil, PUCRS, School of Humanities, Porto Alegre, 90619, Rio Grande do Sul, Brazil; Meneguzzi F., PUCRS, School of Computer Science, Porto Alegre, 90619, Rio Grande do Sul, Brazil, PUCRS, Brain Institute of Rio Grande do Sul (BraIns), Porto Alegre, 90619, Rio Grande do Sul, Brazil","The goal of the present study was to apply deep learning algorithms to identify autism spectrum disorder (ASD) patients from large brain imaging dataset, based solely on the patients brain activation patterns. We investigated ASD patients brain imaging data from a world-wide multi-site database known as ABIDE (Autism Brain Imaging Data Exchange). ASD is a brain-based disorder characterized by social deficits and repetitive behaviors. According to recent Centers for Disease Control data, ASD affects one in 68 children in the United States. We investigated patterns of functional connectivity that objectively identify ASD participants from functional brain imaging data, and attempted to unveil the neural patterns that emerged from the classification. The results improved the state-of-the-art by achieving 70% accuracy in identification of ASD versus control patients in the dataset. The patterns that emerged from the classification show an anticorrelation of brain function between anterior and posterior areas of the brain; the anticorrelation corroborates current empirical evidence of anterior-posterior disruption in brain connectivity in ASD. We present the results and identify the areas of the brain that contributed most to differentiating ASD from typically developing controls as per our deep learning model. © 2017","ABIDE; Autism; Deep learning; fMRI; Resting state","Adolescent; Adult; Autism Spectrum Disorder; Brain; Brain Mapping; Case-Control Studies; Child; Datasets as Topic; Female; Functional Neuroimaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Male; Neural Networks (Computer); Neural Pathways; Rest; Young Adult; accuracy; Article; autism; brain function; clinical classification; compulsion; data base; electroencephalogram; functional connectivity; functional magnetic resonance imaging; learning algorithm; neuroimaging; prediction; priority journal; sensitivity and specificity; training; adolescent; adult; artificial neural network; autism; brain; brain mapping; case control study; child; classification; diagnostic imaging; female; functional neuroimaging; human; image processing; information processing; machine learning; male; nerve tract; rest; young adult","Elsevier Inc.","22131582","","","29034163","Article","Scopus","2-s2.0-85030322624"
"Jianqiang Z.; Weijuan L.; Huaihui Z.; Ying H.; Panpan Y.; Changyu L.; Yanmei Y.; Ming L.","Jianqiang, Zhang (57201462159); Weijuan, Liu (55867028700); Huaihui, Zhang (57201464224); Ying, Hou (57200114418); Panpan, Yang (57190164649); Changyu, Li (57190881517); Yanmei, Yang (36018066000); Ming, Li (57201467010)","57201462159; 55867028700; 57201464224; 57200114418; 57190164649; 57190881517; 36018066000; 57201467010","Automatic classification of tobacco leaves based on near infrared spectroscopy and nonnegative least squares","2018","Journal of Near Infrared Spectroscopy","11","10.1177/0967033518762617","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044935908&doi=10.1177%2f0967033518762617&partnerID=40&md5=05206503ed2758ed2a2d5d42e437d846","Yunnan Reascend Tobacco Technology (Group) Co., Ltd, Kunming, China; Yunnan Comtestor Co., Ltd, Kunming, China; Yunnan Vocational and Technical College of Agriculture, Kunming, China","Jianqiang Z., Yunnan Reascend Tobacco Technology (Group) Co., Ltd, Kunming, China, Yunnan Comtestor Co., Ltd, Kunming, China; Weijuan L., Yunnan Reascend Tobacco Technology (Group) Co., Ltd, Kunming, China; Huaihui Z., Yunnan Vocational and Technical College of Agriculture, Kunming, China; Ying H., Yunnan Comtestor Co., Ltd, Kunming, China; Panpan Y., Yunnan Comtestor Co., Ltd, Kunming, China; Changyu L., Yunnan Reascend Tobacco Technology (Group) Co., Ltd, Kunming, China; Yanmei Y., Yunnan Reascend Tobacco Technology (Group) Co., Ltd, Kunming, China; Ming L., Yunnan Reascend Tobacco Technology (Group) Co., Ltd, Kunming, China","A nonnegative least squares classifier was proposed in this paper to classify near infrared spectral data. The method used near infrared spectral data of training samples to make up a data dictionary of the sparse representation. By adopting the nonnegative least squares sparse coding algorithm, the near infrared spectral data of test samples would be expressed via the sparsest linear combinations of the dictionary. The regression residual of the test sample of each class was computed, and finally it was assigned to the class with the minimum residual. The method was compared with the other classifying approaches, including the well-performing principal component analysis-linear discriminant analysis and principal component analysis-particle swarm optimization-support vector machine. Experimental results showed that the approach was faster and generally achieved a better prediction performance over compared methods. The method can accurately recognize different classes of tobacco leaves and it provides a new technology for quality evaluation of tobacco leaf in its purchasing activities. © The Author(s) 2018.","Deep learning; Near infrared spectroscopy; Nonnegative least squares; Sparse representation classification","Deep learning; Discriminant analysis; Near infrared spectroscopy; Particle swarm optimization (PSO); Principal component analysis; Quality control; Support vector machines; Tobacco; Automatic classification; Linear combinations; Linear discriminant analysis; Near infrared spectral; Nonnegative least squares; Prediction performance; Regression residuals; Sparse representation; Infrared devices","SAGE Publications Ltd","09670335","","","","Article","Scopus","2-s2.0-85044935908"
"Wang F.; Liu H.; Cheng J.","Wang, Feng (56267514900); Liu, Haijun (56087965100); Cheng, Jian (55338983400)","56267514900; 56087965100; 55338983400","Visualizing deep neural network by alternately image blurring and deblurring","2018","Neural Networks","31","10.1016/j.neunet.2017.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032949861&doi=10.1016%2fj.neunet.2017.09.007&partnerID=40&md5=534a9b3b95c92e27de9caf5e1584af10","School of Electronic Engineering, University of Electronic Science and Technology of China, China","Wang F., School of Electronic Engineering, University of Electronic Science and Technology of China, China; Liu H., School of Electronic Engineering, University of Electronic Science and Technology of China, China; Cheng J., School of Electronic Engineering, University of Electronic Science and Technology of China, China","Visualization from trained deep neural networks has drawn massive public attention in recent. One of the visualization approaches is to train images maximizing the activation of specific neurons. However, directly maximizing the activation would lead to unrecognizable images, which cannot provide any meaningful information. In this paper, we introduce a simple but effective technique to constrain the optimization route of the visualization. By adding two totally inverse transformations, image blurring and deblurring, to the optimization procedure, recognizable images can be created. Our algorithm is good at extracting the details in the images, which are usually filtered by previous methods in the visualizations. Extensive experiments on AlexNet, VGGNet and GoogLeNet illustrate that we can better understand the neural networks utilizing the knowledge obtained by the visualization. © 2017 Elsevier Ltd","Deep neural network; Image blurring and deblurring; Visualization","Algorithms; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Neurons; Chemical activation; Deep neural networks; Flow visualization; Inverse problems; Visualization; Deblurring; Image blurring; Inverse transformations; Optimization procedures; algorithm; Article; artificial neural network; image blurring; image deblurring; image processing; priority journal; process optimization; image processing; machine learning; nerve cell; physiology; procedures; Image enhancement","Elsevier Ltd","08936080","","NNETE","29126069","Article","Scopus","2-s2.0-85032949861"
"Marateb H.R.; Mohebian M.R.; Javanmard S.H.; Tavallaei A.A.; Tajadini M.H.; Heidari-Beni M.; Mañanas M.A.; Motlagh M.E.; Heshmat R.; Mansourian M.; Kelishadi R.","Marateb, Hamid R. (35759194200); Mohebian, Mohammad Reza (57188972637); Javanmard, Shaghayegh Haghjooy (25960083700); Tavallaei, Amir Ali (57201362483); Tajadini, Mohammad Hasan (57189342308); Heidari-Beni, Motahar (55227378600); Mañanas, Miguel Angel (6602192659); Motlagh, Mohammad Esmaeil (24367173700); Heshmat, Ramin (8530023300); Mansourian, Marjan (26027945700); Kelishadi, Roya (6602583920)","35759194200; 57188972637; 25960083700; 57201362483; 57189342308; 55227378600; 6602192659; 24367173700; 8530023300; 26027945700; 6602583920","Prediction of dyslipidemia using gene mutations, family history of diseases and anthropometric indicators in children and adolescents: The CASPIAN-III study","2018","Computational and Structural Biotechnology Journal","15","10.1016/j.csbj.2018.02.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044447411&doi=10.1016%2fj.csbj.2018.02.009&partnerID=40&md5=b6ff6315952a2dfc400d4af6253865ae","Department of Biomedical Engineering, Facultyof Engineering, University of Isfahan, Isfahan, Iran; Department of Automatic Control, Biomedical Engineering Research Center, Universitat Politècnica de Catalunya, BarcelonaTech (UPC), Barcelona, Spain; Applied physiology researchcenter, Isfahan cardiovascular research institute, Isfahan University of Medical Sciences, Isfahan, Iran; Department of Clinical Biochemistry, Tarbiat Modares University, Tehran, Iran; Nutrition Department, Child Growth and Development Research Center, Research Institute for Primordial Prevention of Non-Communicable Disease, Isfahan University of Medical Sciences, Isfahan, Iran; Biomedical Research Networking Center in Bioengineering, Biomaterialsand Nanomedicine (CIBER-BBN), Barcelona, Spain; Department of Pediatrics, Ahvaz Jundishapur University of Medical Sciences, Ahvaz, Iran; Department of Epidemiology, Chronic Diseases Research Center, Endocrinology and MetabolismPopulation Sciences Institute, Tehran University of Medical Sciences, Tehran, Iran; Biostatistics and Epidemiology Department, Faculty of Health, Isfahan University of Medical Sciences, Isfahan, Iran; Pediatrics Department, Child Growth and Development Research Center, Research Institute for Primordial Prevention of Non-Communicable Disease, Isfahan University of Medical Sciences, Isfahan, Iran","Marateb H.R., Department of Biomedical Engineering, Facultyof Engineering, University of Isfahan, Isfahan, Iran, Department of Automatic Control, Biomedical Engineering Research Center, Universitat Politècnica de Catalunya, BarcelonaTech (UPC), Barcelona, Spain; Mohebian M.R., Department of Biomedical Engineering, Facultyof Engineering, University of Isfahan, Isfahan, Iran; Javanmard S.H., Applied physiology researchcenter, Isfahan cardiovascular research institute, Isfahan University of Medical Sciences, Isfahan, Iran; Tavallaei A.A., Department of Biomedical Engineering, Facultyof Engineering, University of Isfahan, Isfahan, Iran; Tajadini M.H., Department of Clinical Biochemistry, Tarbiat Modares University, Tehran, Iran; Heidari-Beni M., Nutrition Department, Child Growth and Development Research Center, Research Institute for Primordial Prevention of Non-Communicable Disease, Isfahan University of Medical Sciences, Isfahan, Iran; Mañanas M.A., Department of Automatic Control, Biomedical Engineering Research Center, Universitat Politècnica de Catalunya, BarcelonaTech (UPC), Barcelona, Spain, Biomedical Research Networking Center in Bioengineering, Biomaterialsand Nanomedicine (CIBER-BBN), Barcelona, Spain; Motlagh M.E., Department of Pediatrics, Ahvaz Jundishapur University of Medical Sciences, Ahvaz, Iran; Heshmat R., Department of Epidemiology, Chronic Diseases Research Center, Endocrinology and MetabolismPopulation Sciences Institute, Tehran University of Medical Sciences, Tehran, Iran; Mansourian M., Applied physiology researchcenter, Isfahan cardiovascular research institute, Isfahan University of Medical Sciences, Isfahan, Iran, Biostatistics and Epidemiology Department, Faculty of Health, Isfahan University of Medical Sciences, Isfahan, Iran; Kelishadi R., Pediatrics Department, Child Growth and Development Research Center, Research Institute for Primordial Prevention of Non-Communicable Disease, Isfahan University of Medical Sciences, Isfahan, Iran","Dyslipidemia, the disorder of lipoprotein metabolism resulting in high lipid profile, is an important modifiable risk factor for coronary heart diseases. It is associated with more than four million worldwide deaths per year. Half of the children with dyslipidemia have hyperlipidemia during adulthood, and its prediction and screening are thus critical. We designed a new dyslipidemia diagnosis system. The sample size of 725 subjects (age 14.66 ± 2.61 years; 48% male; dyslipidemia prevalence of 42%) was selected by multistage random cluster sampling in Iran. Single nucleotide polymorphisms (rs1801177, rs708272, rs320, rs328, rs2066718, rs2230808, rs5880, rs5128, rs2893157, rs662799, and Apolipoprotein-E2/E3/E4), and anthropometric, life-style attributes, and family history of diseases were analyzed. A framework for classifying mixed-type data in imbalanced datasets was proposed. It included internal feature mapping and selection, re-sampling, optimized group method of data handling using convex and stochastic optimizations, a new cost function for imbalanced data and an internal validation. Its performance was assessed using hold-out and 4-foldcross-validation. Four other classifiers namely as supported vector machines, decision tree, and multilayer perceptron neural network and multiple logistic regression were also used. The average sensitivity, specificity, precision and accuracy of the proposed system were 93%, 94%, 94% and 92%, respectively in cross validation. It significantly outperformed the other classifiers and also showed excellent agreement and high correlation with the gold standard. A non-invasive economical version of the algorithm was also implemented suitable for low- and middle-income countries. It is thus a promising new tool for the prediction of dyslipidemia. © 2018 The Authors","Computer-assisted diagnosis; Deep learning; Dyslipidemia; Genomics; Health promotion; Machine learning","Classification (of information); Computer aided diagnosis; Cost functions; Data handling; Deep learning; Forecasting; Genes; Learning algorithms; Lipoproteins; Multilayer neural networks; Optimization; apolipoprotein E2; apolipoprotein E3; apolipoprotein E4; Anthropometrics; Children and adolescents; Computer assisted diagnosis; Deep learning; Dyslipidemias; Genes mutation; Genomics; Health promotion; Lipoprotein metabolism; Machine-learning; abdominal obesity; accuracy; adolescent; age; algorithm; anthropometry; Article; birth weight; body mass; cardiovascular disease; child; decision tree; diabetes mellitus; dyslipidemia; family history; female; gene frequency; gene mutation; human; lifestyle; major clinical study; male; malignant neoplasm; obesity; perceptron; physical activity; prediction; priority journal; sensitivity and specificity; single nucleotide polymorphism; support vector machine; Genome","Elsevier B.V.","20010370","","","","Article","Scopus","2-s2.0-85044447411"
"Park B.-Y.; Lee M.J.; Lee S.-H.; Cha J.; Chung C.-S.; Kim S.T.; Park H.","Park, Bo-yong (56975729200); Lee, Mi Ji (56011161600); Lee, Seung-hak (56123410600); Cha, Jihoon (23476481000); Chung, Chin-Sang (7403613322); Kim, Sung Tae (55718820800); Park, Hyunjin (56512679000)","56975729200; 56011161600; 56123410600; 23476481000; 7403613322; 55718820800; 56512679000","DEWS (DEep White matter hyperintensity Segmentation framework): A fully automated pipeline for detecting small deep white matter hyperintensities in migraineurs","2018","NeuroImage: Clinical","14","10.1016/j.nicl.2018.02.033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042924125&doi=10.1016%2fj.nicl.2018.02.033&partnerID=40&md5=fb1122e6bb1b1870401ef5389734fb2d","Department of Electronic, Electrical and Computer Engineering, Sungkyunkwan University, Suwon, 16419, South Korea; Center for Neuroscience Imaging Research, Institute for Basic Science (IBS), Suwon, 16419, South Korea; Department of Neurology, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, 06351, South Korea; Department of Radiology, Severance Hospital, Research Institute of Radiological Science, Yonsei University College of Medicine, Seoul, 03722, South Korea; Department of Radiology, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, 06351, South Korea; School of Electronic and Electrical Engineering, Sungkyunkwan University, Suwon, 16419, South Korea","Park B.-Y., Department of Electronic, Electrical and Computer Engineering, Sungkyunkwan University, Suwon, 16419, South Korea, Center for Neuroscience Imaging Research, Institute for Basic Science (IBS), Suwon, 16419, South Korea; Lee M.J., Department of Neurology, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, 06351, South Korea; Lee S.-H., Department of Electronic, Electrical and Computer Engineering, Sungkyunkwan University, Suwon, 16419, South Korea, Center for Neuroscience Imaging Research, Institute for Basic Science (IBS), Suwon, 16419, South Korea; Cha J., Department of Radiology, Severance Hospital, Research Institute of Radiological Science, Yonsei University College of Medicine, Seoul, 03722, South Korea; Chung C.-S., Department of Neurology, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, 06351, South Korea; Kim S.T., Department of Radiology, Samsung Medical Center, Sungkyunkwan University School of Medicine, Seoul, 06351, South Korea; Park H., Center for Neuroscience Imaging Research, Institute for Basic Science (IBS), Suwon, 16419, South Korea, School of Electronic and Electrical Engineering, Sungkyunkwan University, Suwon, 16419, South Korea","Migraineurs show an increased load of white matter hyperintensities (WMHs) and more rapid deep WMH progression. Previous methods for WMH segmentation have limited efficacy to detect small deep WMHs. We developed a new fully automated detection pipeline, DEWS (DEep White matter hyperintensity Segmentation framework), for small and superficially-located deep WMHs. A total of 148 non-elderly subjects with migraine were included in this study. The pipeline consists of three components: 1) white matter (WM) extraction, 2) WMH detection, and 3) false positive reduction. In WM extraction, we adjusted the WM mask to re-assign misclassified WMHs back to WM using many sequential low-level image processing steps. In WMH detection, the potential WMH clusters were detected using an intensity based threshold and region growing approach. For false positive reduction, the detected WMH clusters were classified into final WMHs and non-WMHs using the random forest (RF) classifier. Size, texture, and multi-scale deep features were used to train the RF classifier. DEWS successfully detected small deep WMHs with a high positive predictive value (PPV) of 0.98 and true positive rate (TPR) of 0.70 in the training and test sets. Similar performance of PPV (0.96) and TPR (0.68) was attained in the validation set. DEWS showed a superior performance in comparison with other methods. Our proposed pipeline is freely available online to help the research community in quantifying deep WMHs in non-elderly adults. © 2018 The Authors","Automated detection; Deep white matter hyperintensity; Migraine","Adult; Brain; Female; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Migraine Disorders; White Matter; adolescent; adult; aged; Article; automation; deep white matter hyperintensity segmentation framework; female; human; image processing; intermethod comparison; machine learning; major clinical study; male; migraine; predictive value; priority journal; prospective study; random forest; white matter; brain; computer assisted diagnosis; diagnostic imaging; image processing; middle aged; migraine; nuclear magnetic resonance imaging; white matter","Elsevier Inc.","22131582","","","29845012","Article","Scopus","2-s2.0-85042924125"
"Devalla S.K.; Chin K.S.; Mari J.-M.; Tun T.A.; Strouthidis N.; Aung T.; Thiéry A.H.; Girard M.J.A.","Devalla, Sripad Krishna (57200332008); Chin, Khai Sing (57183637200); Mari, Jean-Martial (24344561500); Tun, Tin A. (36103116300); Strouthidis, Nicholas (57220392234); Aung, Tin (26643141900); Thiéry, Alexandre H. (55780359100); Girard, Michaël J. A. (24721263100)","57200332008; 57183637200; 24344561500; 36103116300; 57220392234; 26643141900; 55780359100; 24721263100","A deep learning approach to digitally stain optical coherence tomography images of the optic nerve head","2018","Investigative Ophthalmology and Visual Science","82","10.1167/iovs.17-22617","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040931431&doi=10.1167%2fiovs.17-22617&partnerID=40&md5=69ef263f0fcdf4b27e96fc8a9f67d2de","Ophthalmic Engineering and Innovation Laboratory, Department of Biomedical Engineering, Faculty of Engineering, National University of Singapore, Singapore; Department of Statistics and Applied Probability, National University of Singapore, Singapore; GePaSud, Université de la Polynésie Française, Tahiti, France; Singapore Eye Research Institute, Singapore National Eye Centre, Singapore; NIHR Biomedical Research Centre, Moorfields Eye Hospital, NHS Foundation Trust, UCL Institute of Ophthalmology, London, United Kingdom; Discipline of Clinical Ophthalmology and Eye Health, University of Sydney, Sydney, NSW, Australia; Yong Loo Lin School of Medicine, National University of Singapore, Singapore","Devalla S.K., Ophthalmic Engineering and Innovation Laboratory, Department of Biomedical Engineering, Faculty of Engineering, National University of Singapore, Singapore; Chin K.S., Department of Statistics and Applied Probability, National University of Singapore, Singapore; Mari J.-M., GePaSud, Université de la Polynésie Française, Tahiti, France; Tun T.A., Singapore Eye Research Institute, Singapore National Eye Centre, Singapore; Strouthidis N., Singapore Eye Research Institute, Singapore National Eye Centre, Singapore, NIHR Biomedical Research Centre, Moorfields Eye Hospital, NHS Foundation Trust, UCL Institute of Ophthalmology, London, United Kingdom, Discipline of Clinical Ophthalmology and Eye Health, University of Sydney, Sydney, NSW, Australia; Aung T., Singapore Eye Research Institute, Singapore National Eye Centre, Singapore, Yong Loo Lin School of Medicine, National University of Singapore, Singapore; Thiéry A.H., Department of Statistics and Applied Probability, National University of Singapore, Singapore; Girard M.J.A., Ophthalmic Engineering and Innovation Laboratory, Department of Biomedical Engineering, Faculty of Engineering, National University of Singapore, Singapore, Singapore Eye Research Institute, Singapore National Eye Centre, Singapore","PURPOSE. To develop a deep learning approach to digitally stain optical coherence tomography (OCT) images of the optic nerve head (ONH). METHODS. A horizontal B-scan was acquired through the center of the ONH using OCT (Spectralis) for one eye of each of 100 subjects (40 healthy and 60 glaucoma). All images were enhanced using adaptive compensation. A custom deep learning network was then designed and trained with the compensated images to digitally stain (i.e., highlight) six tissue layers of the ONH. The accuracy of our algorithm was assessed (against manual segmentations) using the dice coefficient, sensitivity, specificity, intersection over union (IU), and accuracy. We studied the effect of compensation, number of training images, and performance comparison between glaucoma and healthy subjects. RESULTS. For images it had not yet assessed, our algorithm was able to digitally stain the retinal nerve fiber layer + prelamina, the RPE, all other retinal layers, the choroid, and the peripapillary sclera and lamina cribrosa. For all tissues, the dice coefficient, sensitivity, specificity, IU, and accuracy (mean) were 0.84 ± 0.03, 0.92 ± 0.03, 0.99 ± 0.00, 0.89 ± 0.03, and 0.94 ± 0.02, respectively. Our algorithm performed significantly better when compensated images were used for training (P & LT; 0.001). Besides offering a good reliability, digital staining also performed well on OCT images of both glaucoma and healthy individuals. CONCLUSIONS. Our deep learning algorithm can simultaneously stain the neural and connective tissues of the ONH, offering a framework to automatically measure multiple key structural parameters of the ONH that may be critical to improve glaucoma management. © 2018 The Authors.","Adaptive compensation; Artificial intelligence; Deep learning; Digital staining; Glaucoma; Optic nerve head; Optical coherence tomography","Adult; Algorithms; Female; Glaucoma; Humans; Machine Learning; Male; Middle Aged; Nerve Fibers; Optic Disk; Reproducibility of Results; Retinal Ganglion Cells; Tomography, Optical Coherence; Visual Fields; Article; artificial intelligence; B scan; case control study; closed angle glaucoma; controlled study; diagnostic accuracy; diagnostic test accuracy study; digital staining; glaucoma; glaucomatous optic neuropathy; human; image analysis; intraocular pressure; learning algorithm; machine learning; macular edema; major clinical study; nuclear magnetic resonance imaging; observational study; open angle glaucoma; optic nerve; optic nerve head; optical coherence tomography; priority journal; reliability; retinal nerve fiber layer; adult; algorithm; female; glaucoma; machine learning; male; middle aged; nerve fiber; optic disk; optical coherence tomography; pathology; procedures; reproducibility; retina ganglion cell; visual field","Association for Research in Vision and Ophthalmology Inc.","01460404","","IOVSD","29313052","Article","Scopus","2-s2.0-85040931431"
"Szalkai B.; Grolmusz V.","Szalkai, Balázs (36728479700); Grolmusz, Vince (7003519592)","36728479700; 7003519592","Near perfect protein multi-label classification with deep neural networks","2018","Methods","33","10.1016/j.ymeth.2017.06.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023605092&doi=10.1016%2fj.ymeth.2017.06.034&partnerID=40&md5=5e84c5aab644d02cc8faab7ff0321006","PIT Bioinformatics Group, Eötvös University, Budapest, H-1117, Hungary; Uratim Ltd., Budapest, H-1118, Hungary","Szalkai B., PIT Bioinformatics Group, Eötvös University, Budapest, H-1117, Hungary; Grolmusz V., PIT Bioinformatics Group, Eötvös University, Budapest, H-1117, Hungary, Uratim Ltd., Budapest, H-1118, Hungary","Biological sequences can be considered as data items of high-, non-fixed dimensions, corresponding to the length of those sequences. The comparison and the classification of biological sequences in their relations to large databases are important areas of research today. Artificial neural networks (ANNs) have gained a well-deserved popularity among machine learning tools upon their recent successful applications in image- and sound processing and classification problems. ANNs have also been applied for predicting the family or function of a protein, knowing its residue sequence. Here we present two new ANNs with multi-label classification ability, showing impressive accuracy when classifying protein sequences into 698 UniProt families (AUC = 99.99%) and 983 Gene Ontology classes (AUC = 99.45%). © 2017 Elsevier Inc.","","Algorithms; Area Under Curve; Gene Ontology; Molecular Sequence Annotation; Neural Networks (Computer); Proteins; Proteogenomics; protein; protein; amino acid sequence; area under the curve; Article; artificial neural network; calculation; classification algorithm; gene activation; gene ontology; human; hypothesis; priority journal; protein analysis; protein function; publication; sequence analysis; algorithm; artificial neural network; genetics; metabolism; molecular genetics; procedures; proteogenomics","Academic Press Inc.","10462023","","MTHDE","28684341","Article","Scopus","2-s2.0-85023605092"
"Kim S.; Park D.; Choi Y.; Lee K.; Kim B.; Jeon M.; Kim J.; Tan A.C.; Kang J.","Kim, Seongsoon (54585556100); Park, Donghyeon (57200379263); Choi, Yonghwa (57191633563); Lee, Kyubum (54585506800); Kim, Byounggun (57191633142); Jeon, Minji (55561994100); Kim, Jihye (25958077600); Tan, Aik Choon (8949996200); Kang, Jaewoo (8914056400)","54585556100; 57200379263; 57191633563; 54585506800; 57191633142; 55561994100; 25958077600; 8949996200; 8914056400","A pilot study of biomedical text comprehension using an attention-based deep neural reader: Design and experimental analysis","2018","JMIR Medical Informatics","16","10.2196/medinform.8751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041050744&doi=10.2196%2fmedinform.8751&partnerID=40&md5=c2ff2d3a2958447eb9173593bed86395","Department of Computer Science and Engineering, College of Informatics, Korea University, 145 Anam-ro, Seongbuk-Gu, Seoul, 02841, South Korea; Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, South Korea; Division of Medical Oncology, Department of Medicine, University of Colorado Anschutz Medical Campus, Aurora, CO, United States","Kim S., Department of Computer Science and Engineering, College of Informatics, Korea University, 145 Anam-ro, Seongbuk-Gu, Seoul, 02841, South Korea; Park D., Department of Computer Science and Engineering, College of Informatics, Korea University, 145 Anam-ro, Seongbuk-Gu, Seoul, 02841, South Korea; Choi Y., Department of Computer Science and Engineering, College of Informatics, Korea University, 145 Anam-ro, Seongbuk-Gu, Seoul, 02841, South Korea; Lee K., Department of Computer Science and Engineering, College of Informatics, Korea University, 145 Anam-ro, Seongbuk-Gu, Seoul, 02841, South Korea; Kim B., Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul, South Korea; Jeon M., Department of Computer Science and Engineering, College of Informatics, Korea University, 145 Anam-ro, Seongbuk-Gu, Seoul, 02841, South Korea; Kim J., Division of Medical Oncology, Department of Medicine, University of Colorado Anschutz Medical Campus, Aurora, CO, United States; Tan A.C., Division of Medical Oncology, Department of Medicine, University of Colorado Anschutz Medical Campus, Aurora, CO, United States; Kang J., Department of Computer Science and Engineering, College of Informatics, Korea University, 145 Anam-ro, Seongbuk-Gu, Seoul, 02841, South Korea","Background: With the development of artificial intelligence (AI) technology centered on deep-learning, the computer has evolved to a point where it can read a given text and answer a question based on the context of the text. Such a specific task is known as the task of machine comprehension. Existing machine comprehension tasks mostly use datasets of general texts, such as news articles or elementary school-level storybooks. However, no attempt has been made to determine whether an up-To-date deep learning-based machine comprehension model can also process scientific literature containing expert-level knowledge, especially in the biomedical domain. Objective: This study aims to investigate whether a machine comprehension model can process biomedical articles as well as general texts. Since there is no dataset for the biomedical literature comprehension task, our work includes generating a large-scale question answering dataset using PubMed and manually evaluating the generated dataset. Methods: We present an attention-based deep neural model tailored to the biomedical domain. To further enhance the performance of our model, we used a pretrained word vector and biomedical entity type embedding. We also developed an ensemble method of combining the results of several independent models to reduce the variance of the answers from the models. Results: The experimental results showed that our proposed deep neural network model outperformed the baseline model by more than 7% on the new dataset. We also evaluated human performance on the new dataset. The human evaluation result showed that our deep neural model outperformed humans in comprehension by 22% on average. Conclusions: In this work, we introduced a new task of machine comprehension in the biomedical domain using a deep neural model. Since there was no large-scale dataset for training deep neural models in the biomedical domain, we created the new cloze-style datasets Biomedical Knowledge Comprehension Title (BMKC-T) and Biomedical Knowledge Comprehension Last Sentence (BMKC-LS) (together referred to as BioMedical Knowledge Comprehension) using the PubMed corpus. The experimental results showed that the performance of our model is much higher than that of humans. We observed that our model performed consistently better regardless of the degree of difficulty of a text, whereas humans have difficulty when performing biomedical literature comprehension tasks that require expert level knowledge.","","article; attention; comprehension; embedding; human; human experiment; machine; Medline; nervous system; pilot study; scientific literature","","22919694","","","","Article","Scopus","2-s2.0-85041050744"
"Hoffman A.F.; Nolan J.; Gebhard D.F.; Nickischer D.; Omta W.; Cooper S.; Presnell S.; Wardwell-Swanson J.; Fennell M.","Hoffman, Ann F. (23569363300); Nolan, John (7201399893); Gebhard, David F. (7003573128); Nickischer, Debra (8506471300); Omta, Wienand (56225739400); Cooper, Sam (56167913500); Presnell, Sharon (7004148594); Wardwell-Swanson, Judi (6507485948); Fennell, Myles (7004854025)","23569363300; 7201399893; 7003573128; 8506471300; 56225739400; 56167913500; 7004148594; 6507485948; 7004854025","Society of Biomolecular Imaging and Informatics High-Content Screening/High-Content Analysis Emerging Technologies in Biological Models, When and Why?","2018","Assay and Drug Development Technologies","2","10.1089/adt.2017.29070.afh","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040928708&doi=10.1089%2fadt.2017.29070.afh&partnerID=40&md5=07a830db3b0c3ff15c4b382887d89bfb","Department of Drug Design and Selection, GlaxoSmithKline, 1250 S. Collegeville Road, Collegeville, 19426-0989, PA, United States; Scintillon Institute, San Diego, CA, United States; Pfizer, Inc., Groton, CT, United States; Core Life Analytics B.V., Utrecht, Netherlands; Imperial College London, Institute of Cancer Research, London, United Kingdom; Organovo, Inc., Samsara Sciences, Inc., San Diego, CA, United States; InSphero, Inc., Brunswick, ME, United States; Memorial Sloan Kettering Cancer Center, New York, NY, United States","Hoffman A.F., Department of Drug Design and Selection, GlaxoSmithKline, 1250 S. Collegeville Road, Collegeville, 19426-0989, PA, United States; Nolan J., Scintillon Institute, San Diego, CA, United States; Gebhard D.F., Pfizer, Inc., Groton, CT, United States; Nickischer D., Pfizer, Inc., Groton, CT, United States; Omta W., Core Life Analytics B.V., Utrecht, Netherlands; Cooper S., Imperial College London, Institute of Cancer Research, London, United Kingdom; Presnell S., Organovo, Inc., Samsara Sciences, Inc., San Diego, CA, United States; Wardwell-Swanson J., InSphero, Inc., Brunswick, ME, United States; Fennell M., Memorial Sloan Kettering Cancer Center, New York, NY, United States","[No abstract available]","","Computational Biology; Flow Cytometry; High-Throughput Screening Assays; Humans; Mass Spectrometry; Models, Biological; Molecular Imaging; algorithm; Article; biological model; bioprinting; cell nucleus; content analysis; deep learning; flow cytometry; fluorescence microscopy; high throughput screening; human; image analysis; information science; learning; live cell imaging; machine learning; mass spectrometry; phenotype; three dimensional imaging; biology; high throughput screening; molecular imaging","Mary Ann Liebert Inc.","1540658X","","ADDTA","29345980","Article","Scopus","2-s2.0-85040928708"
"Koohy H.","Koohy, Hashem (36056900500)","36056900500","The rise and fall of machine learning methods in biomedical research","2018","F1000Research","25","10.12688/f1000research.13016.2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040741788&doi=10.12688%2ff1000research.13016.2&partnerID=40&md5=d485595460ae7f65dbf60ba4463b9aac","MRC Human Immunology Unit, Weatherall Institute of Molecular Medicine, University of Oxford, Oxford, United Kingdom; Honorary Research Fellow in Computational Biology, Zeeman Institute, University of Warwick, Coventry, United Kingdom","Koohy H., MRC Human Immunology Unit, Weatherall Institute of Molecular Medicine, University of Oxford, Oxford, United Kingdom, Honorary Research Fellow in Computational Biology, Zeeman Institute, University of Warwick, Coventry, United Kingdom","In the era of explosion in biological data, machine learning techniques are becoming more popular in life sciences, including biology and medicine. This research note examines the rise and fall of the most commonly used machine learning techniques in life sciences over the past three decades. © 2018 Koohy H.","Deep neural network; Hierarchical clustering; Linear regression; Machine learning; Principal component; Random forest; Support vector machine; T-SNE","article; biomedicine; linear regression analysis; medical research; nervous system; random forest; support vector machine","Faculty of 1000 Ltd","20461402","","","29375816","Article","Scopus","2-s2.0-85040741788"
"López-De-Ipiña K.; Martinez-De-Lizarduy U.; Calvo P.M.; Mekyska J.; Beitia B.; Barroso N.; Estanga A.; Tainta M.; Ecay-Torres M.","López-De-Ipiña, Karmele (56263484400); Martinez-De-Lizarduy, Unai (56888713600); Calvo, Pilar M. (56513541100); Mekyska, Jiri (35746344400); Beitia, Blanca (56433495500); Barroso, Nora (23392059500); Estanga, Ainara (35199573400); Tainta, Milkel (24777334300); Ecay-Torres, Mirian (55765237800)","56263484400; 56888713600; 56513541100; 35746344400; 56433495500; 23392059500; 35199573400; 24777334300; 55765237800","Advances on automatic speech analysis for early detection of alzheimer disease: A non-linear multi-task approach","2018","Current Alzheimer Research","58","10.2174/1567205014666171120143800","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042557141&doi=10.2174%2f1567205014666171120143800&partnerID=40&md5=ef13eda656195e18478270a3578f642d","Department of Systems Engineering and Automation, Faculty of Engineering-Gipuzkoa, Universidad del País Vasco/Euskal Herriko Unibertsitatea (UPV/EHU), Donostia, Spain; Department of Electronic Technology, Faculty of Engineering-Gipuzkoa, Universidad del País Vasco/Euskal Herriko Unibertsitatea (UPV/EHU), Donostia, Spain; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Department of Applied Mathematics, Faculty of Engineering-Vitoria, Universidad del País Vasco/Euskal Herriko Unibertsitatea(UPV/EHU), Donostia, Spain; Department of Neurology, CITA-Alzheimer Foundation, Donostia, Spain","López-De-Ipiña K., Department of Systems Engineering and Automation, Faculty of Engineering-Gipuzkoa, Universidad del País Vasco/Euskal Herriko Unibertsitatea (UPV/EHU), Donostia, Spain; Martinez-De-Lizarduy U., Department of Electronic Technology, Faculty of Engineering-Gipuzkoa, Universidad del País Vasco/Euskal Herriko Unibertsitatea (UPV/EHU), Donostia, Spain; Calvo P.M., Department of Systems Engineering and Automation, Faculty of Engineering-Gipuzkoa, Universidad del País Vasco/Euskal Herriko Unibertsitatea (UPV/EHU), Donostia, Spain; Mekyska J., Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Beitia B., Department of Applied Mathematics, Faculty of Engineering-Vitoria, Universidad del País Vasco/Euskal Herriko Unibertsitatea(UPV/EHU), Donostia, Spain; Barroso N., Department of Systems Engineering and Automation, Faculty of Engineering-Gipuzkoa, Universidad del País Vasco/Euskal Herriko Unibertsitatea (UPV/EHU), Donostia, Spain; Estanga A., Department of Neurology, CITA-Alzheimer Foundation, Donostia, Spain; Tainta M., Department of Neurology, CITA-Alzheimer Foundation, Donostia, Spain; Ecay-Torres M., Department of Neurology, CITA-Alzheimer Foundation, Donostia, Spain","Objective: Nowadays proper detection of cognitive impairment has become a challenge for the scientific community. Alzheimer’s Disease (AD), the most common cause of dementia, has a high prevalence that is increasing at a fast pace towards epidemic level. In the not-so-distant future this fact could have a dramatic social and economic impact. In this scenario, an early and accurate diagnosis of AD could help to decrease its effects on patients, relatives and society. Over the last decades there have been useful advances not only in classic assessment techniques, but also in novel non-invasive screening methodologies. Methods: Among these methods, automatic analysis of speech-one of the first damaged skills in AD patients-is a natural and useful low cost tool for diagnosis. Results: In this paper a non-linear multi-task approach based on automatic speech analysis is presented. Three tasks with different language complexity levels are analyzed, and promising results that encourage a deeper assessment are obtained. Automatic classification was carried out by using classic Multilayer Perceptron (MLP) and Deep Learning by means of Convolutional Neural Networks (CNN) (biologically-inspired variants of MLPs) over the tasks with classic linear features, perceptual features, Castiglioni fractal dimension and Multiscale Permutation Entropy. Conclusion: Finally, the most relevant features are selected by means of the non-parametric Mann-Whitney U-test. © 2018 Bentham Science Publishers.","Alzheimer’s disease; Deep learning; Emotion analysis; Innovative tools; Multi-tasks; Speech processing; Spontaneous speech","Adult; Aged; Alzheimer Disease; Cognitive Dysfunction; Cohort Studies; Deep Learning; Diagnosis, Computer-Assisted; Early Diagnosis; Female; Humans; Male; Middle Aged; Neuropsychological Tests; Nonlinear Dynamics; Pattern Recognition, Automated; Speech; Speech Production Measurement; Speech Recognition Software; adult; aged; Alzheimer disease; Article; automatic speech analysis; clinical article; clinical assessment; cognition assessment; cohort analysis; controlled study; convolutional neural network; deep learning; diagnostic accuracy; disease classification; early diagnosis; female; human; machine learning; male; multiscale permutation entropy; non invasive procedure; nonlinear multitask approach; perceptron; pilot study; priority journal; screening test; speech analysis; speech test; task performance; verbal communication; Alzheimer disease; automated pattern recognition; automatic speech recognition; cognitive defect; computer assisted diagnosis; early diagnosis; middle aged; neuropsychological test; nonlinear system; procedures; speech; speech analysis","Bentham Science Publishers B.V.","15672050","","","29165084","Article","Scopus","2-s2.0-85042557141"
"Xue W.; Brahm G.; Pandey S.; Leung S.; Li S.","Xue, Wufeng (36457947300); Brahm, Gary (56943497600); Pandey, Sachin (57169490000); Leung, Stephanie (57194460168); Li, Shuo (57189925356)","36457947300; 56943497600; 57169490000; 57194460168; 57189925356","Full left ventricle quantification via deep multitask relationships learning","2018","Medical Image Analysis","112","10.1016/j.media.2017.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030449769&doi=10.1016%2fj.media.2017.09.005&partnerID=40&md5=94a2fd604e1a1f1232395edba9b82a0c","Department of Medical Imaging, Western University, London, ON, Canada; Digital Image Group (DIG), London, ON, Canada","Xue W., Department of Medical Imaging, Western University, London, ON, Canada, Digital Image Group (DIG), London, ON, Canada; Brahm G., Department of Medical Imaging, Western University, London, ON, Canada, Digital Image Group (DIG), London, ON, Canada; Pandey S., Department of Medical Imaging, Western University, London, ON, Canada, Digital Image Group (DIG), London, ON, Canada; Leung S., Department of Medical Imaging, Western University, London, ON, Canada, Digital Image Group (DIG), London, ON, Canada; Li S., Department of Medical Imaging, Western University, London, ON, Canada, Digital Image Group (DIG), London, ON, Canada","Cardiac left ventricle (LV) quantification is among the most clinically important tasks for identification and diagnosis of cardiac disease. However, it is still a task of great challenge due to the high variability of cardiac structure across subjects and the complexity of temporal dynamics of cardiac sequences. Full quantification, i.e., to simultaneously quantify all LV indices including two areas (cavity and myocardium), six regional wall thicknesses (RWT), three LV dimensions, and one phase (Diastole or Systole), is even more challenging since the ambiguous correlations existing among these indices may impinge upon the convergence and generalization of the learning procedure. In this paper, we propose a deep multitask relationship learning network (DMTRL) for full LV quantification. The proposed DMTRL first obtains expressive and robust cardiac representations with a deep convolution neural network (CNN); then models the temporal dynamics of cardiac sequences effectively with two parallel recurrent neural network (RNN) modules. After that, it estimates the three types of LV indices under a Bayesian framework that is capable of learning multitask relationships automatically, and estimates the cardiac phase with a softmax classifier. The CNN representation, RNN temporal modeling, Bayesian multitask relationship learning, and softmax classifier establish an effective and integrated network which can be learned in an end-to-end manner. The obtained task covariance matrix captures the correlations existing among these indices, therefore leads to accurate estimation of LV indices and cardiac phase. Experiments on MR sequences of 145 subjects show that DMTRL achieves high accurate prediction, with average mean absolute error of 180 mm2, 1.39 mm, 2.51 mm for areas, RWT, dimensions and error rate of 8.2% for the phase classification. This endows our method a great potential in comprehensive clinical assessment of global, regional and dynamic cardiac function. © 2017 Elsevier B.V.","Bayesian framework; Left ventricle quantification; Multitask learning; Multitask relationship","Adolescent; Adult; Aged; Aged, 80 and over; Algorithms; Bayes Theorem; Heart Ventricles; Humans; Middle Aged; Models, Theoretical; Neural Networks (Computer); Ventricular Function; Barium compounds; Covariance matrix; Diagnosis; Heart; Knowledge based systems; Recurrent neural networks; Accurate prediction; Bayesian frameworks; Clinical assessments; Convolution neural network; Left ventricles; Multitask learning; Phase classification; Recurrent neural network (RNN); adolescent; adult; aged; algorithm; Article; artificial neural network; Bayesian learning; cardiac imaging; cardiovascular parameters; clinical assessment; convolution neural network; deep multitask relationship learning; heart function; heart left ventricle; heart left ventricle dimension; heart left ventricle index; human; machine learning; nuclear magnetic resonance imaging; priority journal; recurrent neural network; regional wall thickness; anatomy and histology; Bayes theorem; comparative study; heart ventricle; heart ventricle function; middle aged; physiology; theoretical model; very elderly; Deep learning","Elsevier B.V.","13618415","","MIAEC","28987903","Article","Scopus","2-s2.0-85030449769"
"Pesteie M.; Lessoway V.; Abolmaesumi P.; Rohling R.N.","Pesteie, Mehran (56604282700); Lessoway, Victoria (16145363600); Abolmaesumi, Purang (6602170125); Rohling, Robert N. (7004322927)","56604282700; 16145363600; 6602170125; 7004322927","Automatic Localization of the Needle Target for Ultrasound-Guided Epidural Injections","2018","IEEE Transactions on Medical Imaging","46","10.1109/TMI.2017.2739110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028958330&doi=10.1109%2fTMI.2017.2739110&partnerID=40&md5=10662315095e2a5e2e8ec8444340be64","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Department of Ultrasound, Women's Hospital, Vancouver, V6H 3N1, BC, Canada; Department of Mechanical Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada","Pesteie M., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Lessoway V., Department of Ultrasound, Women's Hospital, Vancouver, V6H 3N1, BC, Canada; Abolmaesumi P., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Rohling R.N., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada, Department of Mechanical Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada","Accurate identification of the needle target is crucial for effective epidural anesthesia. Currently, epidural needle placement is administered by a manual technique, relying on the sense of feel, which has a significant failure rate. Moreover, misleading the needle may lead to inadequate anesthesia, post dural puncture headaches, and other potential complications. Ultrasound offers guidance to the physician for identification of the needle target, but accurate interpretation and localization remain challenges. A hybrid machine learning system is proposed to automatically localize the needle target for epidural needle placement in ultrasound images of the spine. In particular, a deep network architecture along with a feature augmentation technique is proposed for automatic identification of the anatomical landmarks of the epidural space in ultrasound images. Experimental results of the target localization on planes of 3-D as well as 2-D images have been compared against an expert sonographer. When compared with the expert annotations, the average lateral and vertical errors on the planes of 3-D test data were 1 and 0.4 mm, respectively. On 2-D test data set, an average lateral error of 1.7 mm and vertical error of 0.8 mm were acquired. © 2017 IEEE.","3D ultrasound; deep learning; Epidural injection; prepuncture scan; target localization","Adult; Algorithms; Anesthesia, Epidural; Deep Learning; Epidural Space; Humans; Image Processing, Computer-Assisted; Lumbosacral Region; Needles; Ultrasonography, Interventional; Young Adult; Anesthesiology; Automation; Deep learning; Errors; Failure analysis; Needles; Network architecture; Statistical tests; 3-D ultrasound; Anatomical landmarks; Augmentation techniques; Automatic identification; Automatic localization; Hybrid machine learning systems; prepuncture scan; Target localization; adult; algorithm; anatomic landmark; Article; artificial neural network; augmentation index; automation; controlled study; convolutional neural network; diagnostic accuracy; diagnostic error; diagnostic test accuracy study; epidural anesthesia; epidural space; human; human experiment; hybrid; image analysis; image enhancement; interventional ultrasonography; machine learning; normal human; radiologist; three dimensional imaging; two-dimensional imaging; ultrasound; diagnostic imaging; epidural anesthesia; image processing; interventional ultrasonography; lumbosacral region; needle; procedures; young adult; Ultrasonic applications","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28809679","Article","Scopus","2-s2.0-85028958330"
"Bodin C.; Takerkart S.; Belin P.; Coulon O.","Bodin, C. (56646259300); Takerkart, S. (6506808297); Belin, P. (7004230885); Coulon, O. (6602175894)","56646259300; 6506808297; 7004230885; 6602175894","Anatomo-functional correspondence in the superior temporal sulcus","2018","Brain Structure and Function","23","10.1007/s00429-017-1483-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026443297&doi=10.1007%2fs00429-017-1483-2&partnerID=40&md5=d7c93fd2cd0b9a2c6bd259cf773c2ce4","Institut de Neurosciences de la Timone, CNRS UMR7289, Aix-Marseille Université, Marseille, France; Institute for Language, Communication and the Brain, Aix-Marseille Université, Marseille, France; Centre for Cognitive Neuroimaging, Institute of Neuroscience and Psychology, University of Glasgow, Glasgow, United Kingdom; International Laboratories for Brain, Music and Sound, Department of Psychology, University of Montréal, McGill University, Montreal, QC, Canada","Bodin C., Institut de Neurosciences de la Timone, CNRS UMR7289, Aix-Marseille Université, Marseille, France, Institute for Language, Communication and the Brain, Aix-Marseille Université, Marseille, France; Takerkart S., Institut de Neurosciences de la Timone, CNRS UMR7289, Aix-Marseille Université, Marseille, France; Belin P., Institut de Neurosciences de la Timone, CNRS UMR7289, Aix-Marseille Université, Marseille, France, Institute for Language, Communication and the Brain, Aix-Marseille Université, Marseille, France, Centre for Cognitive Neuroimaging, Institute of Neuroscience and Psychology, University of Glasgow, Glasgow, United Kingdom, International Laboratories for Brain, Music and Sound, Department of Psychology, University of Montréal, McGill University, Montreal, QC, Canada; Coulon O., Institut de Neurosciences de la Timone, CNRS UMR7289, Aix-Marseille Université, Marseille, France, Institute for Language, Communication and the Brain, Aix-Marseille Université, Marseille, France","The superior temporal sulcus (STS) is an intriguing region both for its complex anatomy and for the multiple functions that it hosts. Unfortunately, most studies explored either the functional organization or the anatomy of the STS only. Here, we link these two aspects by investigating anatomo-functional correspondences between the voice-sensitive cortex (Temporal Voice Areas) and the STS depth. To do so, anatomical and functional scans of 116 subjects were processed such as to generate individual surface maps on which both depth and functional voice activity can be analyzed. Individual depth profiles of manually drawn STS and functional profiles from a voice localizer (voice > non-voice) maps were extracted and compared to assess anatomo-functional correspondences. Three major results were obtained: first, the STS exhibits a highly significant rightward depth asymmetry in its middle part. Second, there is an anatomo-functional correspondence between the location of the voice-sensitive peak and the deepest point inside this asymmetrical region bilaterally. Finally, we showed that this correspondence was independent of the gender and, using a machine learning approach, that it existed at the individual level. These findings offer new perspectives for the understanding of anatomo-functional correspondences in this complex cortical region. © 2017, Springer-Verlag GmbH Germany.","Anatomo-functional; STS; Sulcal depth; Temporal voice areas","Adolescent; Adult; Brain Mapping; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Sex Characteristics; Statistics, Nonparametric; Temporal Lobe; Voice; Young Adult; adult; Article; brain function; brain size; female; functional anatomy; human; human experiment; machine learning; male; normal human; nuclear magnetic resonance imaging; priority journal; superior temporal sulcus; temporal cortex; voice analysis; young adult; adolescent; brain mapping; diagnostic imaging; image processing; nonparametric test; physiology; sexual characteristics; temporal lobe; voice","Springer Verlag","18632653","","","28756487","Article","Scopus","2-s2.0-85026443297"
"Tran N.H.; Zhang X.; Li M.","Tran, Ngoc Hieu (57220748822); Zhang, Xianglilan (55369590200); Li, Ming (55719518600)","57220748822; 55369590200; 55719518600","Deep Omics","2018","Proteomics","8","10.1002/pmic.201700319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040865680&doi=10.1002%2fpmic.201700319&partnerID=40&md5=6f4a848b42cb7a45a1be95875bbe746c","David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; State Key Laboratory of Pathogen and Biosecurity, Beijing Institute of Microbiology and Epidemiology, Beijing, China","Tran N.H., David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; Zhang X., David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada, State Key Laboratory of Pathogen and Biosecurity, Beijing Institute of Microbiology and Epidemiology, Beijing, China; Li M., David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada","Deep learning has revolutionized research in image processing, speech recognition, natural language processing, game playing, and will soon revolutionize research in proteomics and genomics. Through three examples in genomics, protein structure prediction, and proteomics, we demonstrate that deep learning is changing bioinformatics research, shifting from algorithm-centric to data-centric approaches. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","big data; bioinformatics; deep learning; genomics; neural networks; proteomics","Algorithms; Computational Biology; Genomics; Humans; Machine Learning; Natural Language Processing; Proteins; Proteomics; protein; Article; bioinformatics; genomics; learning; prediction; priority journal; protein structure; proteomics; algorithm; biology; genetics; genomics; human; machine learning; metabolism; natural language processing; procedures; proteomics","Wiley-VCH Verlag","16159853","","PROTC","29239117","Article","Scopus","2-s2.0-85040865680"
"Orlando J.I.; Prokofyeva E.; del Fresno M.; Blaschko M.B.","Orlando, José Ignacio (56352187400); Prokofyeva, Elena (26221927200); del Fresno, Mariana (13005137100); Blaschko, Matthew B. (24829297300)","56352187400; 26221927200; 13005137100; 24829297300","An ensemble deep learning based approach for red lesion detection in fundus images","2018","Computer Methods and Programs in Biomedicine","222","10.1016/j.cmpb.2017.10.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031774716&doi=10.1016%2fj.cmpb.2017.10.017&partnerID=40&md5=e7968151bce8d8d26468e95751395743","Pladema Institute, UNCPBA, Gral. Pinto 399, Tandil, Argentina; Consejo Nacional de Investigaciones Científicas y Técnicas, CONICET, Argentina; Comisión de Investigaciones Científicas de la Provincia de Buenos Aires, CIC-PBA, Buenos Aires, Argentina; Scientific Institute of Public Health (WIV-ISP), Brussels, Belgium; Federal Agency for Medicines and Health Products (FAMHP), Brussels, Belgium; ESAT-PSI, KU Leuven, Kasteelpark Arenberg 10, B-3001 Leuven, Belgium","Orlando J.I., Pladema Institute, UNCPBA, Gral. Pinto 399, Tandil, Argentina, Consejo Nacional de Investigaciones Científicas y Técnicas, CONICET, Argentina; Prokofyeva E., Scientific Institute of Public Health (WIV-ISP), Brussels, Belgium, Federal Agency for Medicines and Health Products (FAMHP), Brussels, Belgium; del Fresno M., Pladema Institute, UNCPBA, Gral. Pinto 399, Tandil, Argentina, Comisión de Investigaciones Científicas de la Provincia de Buenos Aires, CIC-PBA, Buenos Aires, Argentina; Blaschko M.B., ESAT-PSI, KU Leuven, Kasteelpark Arenberg 10, B-3001 Leuven, Belgium","Background and objectives: Diabetic retinopathy (DR) is one of the leading causes of preventable blindness in the world. Its earliest sign are red lesions, a general term that groups both microaneurysms (MAs) and hemorrhages (HEs). In daily clinical practice, these lesions are manually detected by physicians using fundus photographs. However, this task is tedious and time consuming, and requires an intensive effort due to the small size of the lesions and their lack of contrast. Computer-assisted diagnosis of DR based on red lesion detection is being actively explored due to its improvement effects both in clinicians consistency and accuracy. Moreover, it provides comprehensive feedback that is easy to assess by the physicians. Several methods for detecting red lesions have been proposed in the literature, most of them based on characterizing lesion candidates using hand crafted features, and classifying them into true or false positive detections. Deep learning based approaches, by contrast, are scarce in this domain due to the high expense of annotating the lesions manually. Methods: In this paper we propose a novel method for red lesion detection based on combining both deep learned and domain knowledge. Features learned by a convolutional neural network (CNN) are augmented by incorporating hand crafted features. Such ensemble vector of descriptors is used afterwards to identify true lesion candidates using a Random Forest classifier. Results: We empirically observed that combining both sources of information significantly improve results with respect to using each approach separately. Furthermore, our method reported the highest performance on a per-lesion basis on DIARETDB1 and e-ophtha, and for screening and need for referral on MESSIDOR compared to a second human expert. Conclusions: Results highlight the fact that integrating manually engineered approaches with deep learned features is relevant to improve results when the networks are trained from lesion-level annotated data. An open source implementation of our system is publicly available at https://github.com/ignaciorlando/red-lesion-detection. © 2017 Elsevier B.V.","Deep learning; Diabetic retinopathy; Fundus images; Red lesion detection","Diabetic Retinopathy; Fundus Oculi; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Microaneurysm; Neural Networks (Computer); Computer aided diagnosis; Decision trees; Eye protection; Neural networks; Open systems; Computer assisted diagnosis; Convolutional Neural Networks (CNN); Diabetic retinopathy; False positive detection; Fundus image; Open source implementation; Random forest classifier; Red lesions; area under the curve; Article; bleeding; controlled study; diabetic retinopathy; eye fundus; microaneurysm; random forest; receiver operating characteristic; retina image; sensitivity and specificity; artificial neural network; computer assisted diagnosis; diabetic retinopathy; diagnostic imaging; human; machine learning; pathology; Deep learning","Elsevier Ireland Ltd","01692607","","CMPBE","29157445","Article","Scopus","2-s2.0-85031774716"
"Kalsi S.; Kaur H.; Chang V.","Kalsi, Shruti (57199176281); Kaur, Harleen (57213128851); Chang, Victor (56926234700)","57199176281; 57213128851; 56926234700","DNA Cryptography and Deep Learning using Genetic Algorithm with NW algorithm for Key Generation","2018","Journal of Medical Systems","68","10.1007/s10916-017-0851-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037640800&doi=10.1007%2fs10916-017-0851-z&partnerID=40&md5=0783471a077f6469a8716d777656a5f7","Department of Computer Science and Engineering, School of Engineering Sciences and Technology, Jamia Hamdard, New Delhi, India; Xerox Technology Ltd, 5th-6th Floor, Vatika Business Park, Gurugram, Haryana, India; International Business School Suzhou, Xi’an Jiaotong Liverpool University, Suzhou, China","Kalsi S., Department of Computer Science and Engineering, School of Engineering Sciences and Technology, Jamia Hamdard, New Delhi, India, Xerox Technology Ltd, 5th-6th Floor, Vatika Business Park, Gurugram, Haryana, India; Kaur H., Department of Computer Science and Engineering, School of Engineering Sciences and Technology, Jamia Hamdard, New Delhi, India; Chang V., International Business School Suzhou, Xi’an Jiaotong Liverpool University, Suzhou, China","Cryptography is not only a science of applying complex mathematics and logic to design strong methods to hide data called as encryption, but also to retrieve the original data back, called decryption. The purpose of cryptography is to transmit a message between a sender and receiver such that an eavesdropper is unable to comprehend it. To accomplish this, not only we need a strong algorithm, but a strong key and a strong concept for encryption and decryption process. We have introduced a concept of DNA Deep Learning Cryptography which is defined as a technique of concealing data in terms of DNA sequence and deep learning. In the cryptographic technique, each alphabet of a letter is converted into a different combination of the four bases, namely; Adenine (A), Cytosine (C), Guanine (G) and Thymine (T), which make up the human deoxyribonucleic acid (DNA). Actual implementations with the DNA don’t exceed laboratory level and are expensive. To bring DNA computing on a digital level, easy and effective algorithms are proposed in this paper. In proposed work we have introduced firstly, a method and its implementation for key generation based on the theory of natural selection using Genetic Algorithm with Needleman-Wunsch (NW) algorithm and Secondly, a method for implementation of encryption and decryption based on DNA computing using biological operations Transcription, Translation, DNA Sequencing and Deep Learning. © 2017, Springer Science+Business Media, LLC.","Cryptography; Deep learning; DNA computing; DNA cryptography; Genetic algorithm; Needleman-Wunsch algorithm (NW) algorithm","Algorithms; Computer Security; DNA; Humans; Machine Learning; adenine; cytosine; DNA; guanine; thymine; Article; DNA deep learning cryptography; DNA determination; DNA sequence; genetic algorithm; human; mathematical computing; natural selection; Needleman Wunsch algorithm; algorithm; computer security; machine learning","Springer New York LLC","01485598","","JMSYD","29204890","Article","Scopus","2-s2.0-85037640800"
"Zhao X.; Wu Y.; Song G.; Li Z.; Zhang Y.; Fan Y.","Zhao, Xiaomei (57194090890); Wu, Yihong (15137486000); Song, Guidong (57161817300); Li, Zhenye (55984021300); Zhang, Yazhuo (57217248510); Fan, Yong (55687203900)","57194090890; 15137486000; 57161817300; 55984021300; 57217248510; 55687203900","A deep learning model integrating FCNNs and CRFs for brain tumor segmentation","2018","Medical Image Analysis","597","10.1016/j.media.2017.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041389548&doi=10.1016%2fj.media.2017.10.002&partnerID=40&md5=029614a50c584c694897c607c96c5f3f","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; University of Chinese Academy of Sciences, Beijing, China; Beijing Neurosurgical Institute, Capital Medical University, Beijing, China; Department of Neurosurgery, Beijing Tiantan Hospital, Capital Medical University, Beijing, China; Beijing Institute for Brain Disorders Brain Tumor Center, Beijing, China; China National Clinical Research Center for Neurological Diseases, Beijing, China; Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States","Zhao X., National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China, University of Chinese Academy of Sciences, Beijing, China; Wu Y., National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; Song G., Beijing Neurosurgical Institute, Capital Medical University, Beijing, China; Li Z., Department of Neurosurgery, Beijing Tiantan Hospital, Capital Medical University, Beijing, China; Zhang Y., Beijing Neurosurgical Institute, Capital Medical University, Beijing, China, Department of Neurosurgery, Beijing Tiantan Hospital, Capital Medical University, Beijing, China, Beijing Institute for Brain Disorders Brain Tumor Center, Beijing, China, China National Clinical Research Center for Neurological Diseases, Beijing, China; Fan Y., Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States","Accurate and reliable brain tumor segmentation is a critical component in cancer diagnosis, treatment planning, and treatment outcome evaluation. Build upon successful deep learning techniques, a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks (FCNNs) and Conditional Random Fields (CRFs) in a unified framework to obtain segmentation results with appearance and spatial consistency. We train a deep learning based segmentation model using 2D image patches and image slices in following steps: 1) training FCNNs using image patches; 2) training CRFs as Recurrent Neural Networks (CRF-RNN) using image slices with parameters of FCNNs fixed; and 3) fine-tuning the FCNNs and the CRF-RNN using image slices. Particularly, we train 3 segmentation models using 2D image patches and slices obtained in axial, coronal and sagittal views respectively, and combine them to segment brain tumors using a voting based fusion strategy. Our method could segment brain images slice-by-slice, much faster than those based on image patches. We have evaluated our method based on imaging data provided by the Multimodal Brain Tumor Image Segmentation Challenge (BRATS) 2013, BRATS 2015 and BRATS 2016. The experimental results have demonstrated that our method could build a segmentation model with Flair, T1c, and T2 scans and achieve competitive performance as those built with Flair, T1, T1c, and T2 scans. © 2017 Elsevier B.V.","Brain tumor segmentation; Conditional random fields; Deep learning; Fully convolutional neural networks","Brain Neoplasms; Glioma; Histological Techniques; Humans; Models, Neurological; Nerve Net; Brain; Brain mapping; Convolution; Deep learning; Diagnosis; Random processes; Recurrent neural networks; Tumors; Brain tumor segmentation; Competitive performance; Conditional random field; Conditional Random Fields(CRFs); Convolutional neural network; Learning-based segmentation; Segmentation models; Segmentation results; Article; artificial neural network; brain tumor; cancer diagnosis; conditional random field; diagnostic accuracy; fully convolutional neural network; image analysis; image display; image segmentation; machine learning; neuroimaging; priority journal; biological model; brain tumor; comparative study; glioma; histology; human; nerve cell network; pathology; Image segmentation","Elsevier B.V.","13618415","","MIAEC","29040911","Article","Scopus","2-s2.0-85041389548"
"Shi J.; Zheng X.; Li Y.; Zhang Q.; Ying S.","Shi, Jun (7404495816); Zheng, Xiao (57190219047); Li, Yan (55900053900); Zhang, Qi (56841055400); Ying, Shihui (24451523300)","7404495816; 57190219047; 55900053900; 56841055400; 24451523300","Multimodal Neuroimaging Feature Learning with Multimodal Stacked Deep Polynomial Networks for Diagnosis of Alzheimer's Disease","2018","IEEE Journal of Biomedical and Health Informatics","321","10.1109/JBHI.2017.2655720","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040340661&doi=10.1109%2fJBHI.2017.2655720&partnerID=40&md5=2cced6c4ac248474cb9bbfbdc0ba2de2","Institute of Biomedical Engineering, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Shenzhen City Key Laboratory of Embedded System Design, Shenzhen Laboratory of IC Design for Internet of Things, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, 518060, China; Department of Mathematics, School of Science, Shanghai University, Shanghai, 200444, China","Shi J., Institute of Biomedical Engineering, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Zheng X., Institute of Biomedical Engineering, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Li Y., Shenzhen City Key Laboratory of Embedded System Design, Shenzhen Laboratory of IC Design for Internet of Things, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, 518060, China; Zhang Q., Institute of Biomedical Engineering, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Ying S., Department of Mathematics, School of Science, Shanghai University, Shanghai, 200444, China","The accurate diagnosis of Alzheimer's disease (AD) and its early stage, i.e., mild cognitive impairment, is essential for timely treatment and possible delay of AD. Fusion of multimodal neuroimaging data, such as magnetic resonance imaging (MRI) and positron emission tomography (PET), has shown its effectiveness for AD diagnosis. The deep polynomial networks (DPN) is a recently proposed deep learning algorithm, which performs well on both large-scale and small-size datasets. In this study, a multimodal stacked DPN (MM-SDPN) algorithm, which MM-SDPN consists of two-stage SDPNs, is proposed to fuse and learn feature representation from multimodal neuroimaging data for AD diagnosis. Specifically speaking, two SDPNs are first used to learn high-level features of MRI and PET, respectively, which are then fed to another SDPN to fuse multimodal neuroimaging information. The proposed MM-SDPN algorithm is applied to the ADNI dataset to conduct both binary classification and multiclass classification tasks. Experimental results indicate that MM-SDPN is superior over the state-of-the-art multimodal feature-learning-based algorithms for AD diagnosis. © 2013 IEEE.","Alzheimer's disease; deep learning; deep polynomial networks; multimodal neuroimaging; multimodal stacked deep polynomial networks","Algorithms; Alzheimer Disease; Humans; Machine Learning; Multimodal Imaging; Neural Networks (Computer); Neuroimaging; ROC Curve; Classification (of information); Deep learning; Diagnosis; Large dataset; Magnetic resonance imaging; Neurodegenerative diseases; Neuroimaging; Polynomials; Positron emission tomography; Alzheimer's disease; Binary classification; Feature representation; Mild cognitive impairments; Multi-class classification; Multi-modal; Polynomial networks; Positron emission tomography (PET); Alzheimer disease; Article; cerebrospinal fluid; classification; cognitive defect; deep polynomial network algorithm; gray matter; learning algorithm; multimodal imaging; neuroimaging; nuclear magnetic resonance imaging; positron emission tomography; receiver operating characteristic; support vector machine; algorithm; Alzheimer disease; artificial neural network; diagnostic imaging; human; machine learning; multimodal imaging; neuroimaging; procedures; Learning algorithms","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28113353","Article","Scopus","2-s2.0-85040340661"
"Cruz-Barbosa R.; Ramos-Pérez E.-G.; Giraldo J.","Cruz-Barbosa, Raúl (56013556200); Ramos-Pérez, Erik-German (57201309646); Giraldo, Jesús (7003797712)","56013556200; 57201309646; 7003797712","Representation learning for class C G protein-coupled receptors classification","2018","Molecules","3","10.3390/molecules23030690","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044321515&doi=10.3390%2fmolecules23030690&partnerID=40&md5=a526da1a013153b55e7f8a7dcf0da106","Computer Science Institute, Technological University of the Mixteca Region, Huajuapan, Oaxaca, 69000, Mexico; Laboratory of Molecular Neuropharmacology and Bioinformatics, Institut de Neurociències and Unitat de Bioestadística, Universitat Autònoma de Barcelona, Bellaterra, 08193, Spain; Network Biomedical Research Center on Mental Health (CIBERSAM), Universitat Autònoma de Barcelona, Bellaterra, 08193, Spain","Cruz-Barbosa R., Computer Science Institute, Technological University of the Mixteca Region, Huajuapan, Oaxaca, 69000, Mexico; Ramos-Pérez E.-G., Computer Science Institute, Technological University of the Mixteca Region, Huajuapan, Oaxaca, 69000, Mexico; Giraldo J., Laboratory of Molecular Neuropharmacology and Bioinformatics, Institut de Neurociències and Unitat de Bioestadística, Universitat Autònoma de Barcelona, Bellaterra, 08193, Spain, Network Biomedical Research Center on Mental Health (CIBERSAM), Universitat Autònoma de Barcelona, Bellaterra, 08193, Spain","G protein-coupled receptors (GPCRs) are integral cell membrane proteins of relevance for pharmacology. The complete tertiary structure including both extracellular and transmembrane domains has not been determined for any member of class C GPCRs. An alternative way to work on GPCR structural models is the investigation of their functionality through the analysis of their primary structure. For this, sequence representation is a key factor for the GPCRs' classification context, where usually, feature engineering is carried out. In this paper, we propose the use of representation learning to acquire the features that best represent the class C GPCR sequences and at the same time to obtain a model for classification automatically. Deep learning methods in conjunction with amino acid physicochemical property indices are then used for this purpose. Experimental results assessed by the classification accuracy, Matthews' correlation coefficient and the balanced error rate show that using a hydrophobicity index and a restricted Boltzmann machine (RBM) can achieve performance results (accuracy of 92.9%) similar to those reported in the literature. As a second proposal, we combine two or more physicochemical property indices instead of only one as the input for a deep architecture in order to add information from the sequences. Experimental results show that using three hydrophobicity-related index combinations helps to improve the classification performance (accuracy of 94.1%) of an RBM better than those reported in the literature for class C GPCRs without using feature selection methods. © 2018 by the authors.","Deep learning; G protein-coupled receptors; Pattern classification; Representation learning","Algorithms; Amino Acid Sequence; Amino Acids; Hydrophobic and Hydrophilic Interactions; Receptors, G-Protein-Coupled; Sequence Alignment; amino acid; G protein coupled receptor; algorithm; amino acid sequence; chemical phenomena; chemistry; classification; metabolism; sequence alignment","MDPI AG","14203049","","MOLEF","29562690","Article","Scopus","2-s2.0-85044321515"
"Fukushima K.","Fukushima, Kunihiko (56199742700)","56199742700","Margined winner-take-all: New learning rule for pattern recognition","2018","Neural Networks","5","10.1016/j.neunet.2017.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032963766&doi=10.1016%2fj.neunet.2017.10.005&partnerID=40&md5=dbc85aff77d66de087eef1ff15d12e77","Fuzzy Logic Systems Institute, Fukuoka, 820–0067, Iizuka, Japan","Fukushima K., Fuzzy Logic Systems Institute, Fukuoka, 820–0067, Iizuka, Japan","The neocognitron is a deep (multi-layered) convolutional neural network that can be trained to recognize visual patterns robustly. In the intermediate layers of the neocognitron, local features are extracted from input patterns. In the deepest layer, based on the features extracted in the intermediate layers, input patterns are classified into classes. A method called IntVec (interpolating-vector) is used for this purpose. This paper proposes a new learning rule called margined Winner-Take-All (mWTA) for training the deepest layer. Every time when a training pattern is presented during the learning, if the result of recognition by WTA (Winner-Take-All) is an error, a new cell is generated in the deepest layer. Here we put a certain amount of margin to the WTA. In other words, only during the learning, a certain amount of handicap is given to cells of classes other than that of the training vector, and the winner is chosen under this handicap. By introducing the margin to the WTA, we can generate a compact set of cells, with which a high recognition rate can be obtained with a small computational cost. The ability of this mWTA is demonstrated by computer simulation. © 2017 Elsevier Ltd","Deep CNN; Interpolating-vector; Learning rule; Margined WTA; Neocognitron; Pattern recognition","Algorithms; Cognition; Computer Simulation; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Interpolation; Neural networks; Computational costs; Convolutional neural network; Deep CNN; Intermediate layers; Learning rules; Margined WTA; Neocognitron; Training patterns; Article; artificial neural network; computer simulation; controlled study; convolutional neural network; feedback system; information processing; interpolating vector; learning algorithm; margined Winner Take All; measurement accuracy; measurement precision; pattern recognition; priority journal; algorithm; automated pattern recognition; cognition; machine learning; procedures; Pattern recognition","Elsevier Ltd","08936080","","NNETE","29126068","Article","Scopus","2-s2.0-85032963766"
"Fu Y.; Aldrich C.","Fu, Yihao (57191974224); Aldrich, Chris (7103255150)","57191974224; 7103255150","Froth image analysis by use of transfer learning and convolutional neural networks","2018","Minerals Engineering","95","10.1016/j.mineng.2017.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032011905&doi=10.1016%2fj.mineng.2017.10.005&partnerID=40&md5=f8e4a27405cff241bd7acf471a937e33","Department of Mining Engineering and Metallurgical Engineering, Western Australian School of Mines, Curtin University, GPO Box U1987, 6845, WA, Australia; Department of Process Engineering, Stellenbosch University, Private Bag X1, Matieland, Stellenbosch, 7602, South Africa","Fu Y., Department of Mining Engineering and Metallurgical Engineering, Western Australian School of Mines, Curtin University, GPO Box U1987, 6845, WA, Australia; Aldrich C., Department of Mining Engineering and Metallurgical Engineering, Western Australian School of Mines, Curtin University, GPO Box U1987, 6845, WA, Australia, Department of Process Engineering, Stellenbosch University, Private Bag X1, Matieland, Stellenbosch, 7602, South Africa","Deep learning constitutes a significant recent advance in machine learning and has been particularly successful in applications related to image processing, where it can already surpass human accuracy in some cases. In this paper, the use of a convolutional neural network, AlexNet, pretrained on a database of images of common objects was used as is to extract features from flotation froth images. These features could subsequently be used to predict the conditions or performance of the flotation systems. Two case studies are considered. In the first, froth regimes in an industrial flotation plant could be identified significantly more reliably with the features generated by AlexNet than with previous state-of-the-art approaches, such as wavelets, grey level co-occurrence matrices or local binary patterns. In the second case study, the arsenic concentration in the batch flotation of realgar-orpiment-quartz mixtures could be predicted more accurately than was possible with features extracted by wavelets, grey level co-occurrence matrices, local binary patterns or by use of colour. These results suggest that feature extraction with convolutional neural networks trained on complex data sets from other domains can serve as more reliable methods than previous state-of-the-art approaches to froth image analysis. © 2017 Elsevier Ltd","AlexNet; Convolution Neural Networks; Deep learning; Froth flotation; Image analysis; Machine vision","Binary mixtures; Bins; Computer vision; Convolution; Deep learning; Froth flotation; Image processing; Learning systems; Neural networks; AlexNet; Arsenic concentration; Co-occurrence-matrix; Convolution neural network; Convolutional neural network; Local binary patterns; State-of-the-art approach; Transfer learning; Image analysis","Elsevier Ltd","08926875","","MENGE","","Article","Scopus","2-s2.0-85032011905"
"Wang Z.; Liu C.; Cheng D.; Wang L.; Yang X.; Cheng K.-T.","Wang, Zhiwei (57216175393); Liu, Chaoyue (57193898373); Cheng, Danpeng (57197846305); Wang, Liang (57221649435); Yang, Xin (57203539516); Cheng, Kwang-Ting (7402997957)","57216175393; 57193898373; 57197846305; 57221649435; 57203539516; 7402997957","Automated detection of clinically significant prostate cancer in mp-MRI images based on an end-to-end deep neural network","2018","IEEE Transactions on Medical Imaging","110","10.1109/TMI.2017.2789181","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040059398&doi=10.1109%2fTMI.2017.2789181&partnerID=40&md5=f9a30a366e1b901af8331ea1e25d483d","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; University of Bridgeport, Bridgeport, 06604, CT, United States; Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, Wuhan, 430030, China; School of Engineering, Hong Kong University of Science and Technology, Hong Kong","Wang Z., School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Liu C., School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Cheng D., University of Bridgeport, Bridgeport, 06604, CT, United States; Wang L., Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, Wuhan, 430030, China; Yang X., School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Cheng K.-T., School of Engineering, Hong Kong University of Science and Technology, Hong Kong","Automated methods for detecting clinically significant (CS) prostate cancer (PCa) in multi-parameter magnetic resonance images (mp-MRI) are of high demand. Existing methods typically employ several separate steps, each of which is optimized individually without considering the error tolerance of other steps. As a result, they could either involve unnecessary computational cost or suffer from errors accumulated over steps. In this paper, we present an automated CS PCa detection system, where all steps are optimized jointly in an end-to-end trainable deep neural network. The proposed neural network consists of concatenated subnets: 1) a novel tissue deformation network (TDN) for automated prostate detection and multimodal registration and 2) a dual-path convolutional neural network (CNN) for CS PCa detection. Three types of loss functions, i.e., classification loss, inconsistency loss, and overlap loss, are employed for optimizing all parameters of the proposed TDN and CNN. In the training phase, the two nets mutually affect each other and effectively guide registration and extraction of representative CS PCa-relevant features to achieve results with sufficient accuracy. The entire network is trained in a weakly supervised manner by providing only image-level annotations (i.e., presence/absence of PCa) without exact priors of lesions' locations. Compared with most existing systems which require supervised labels, e.g., manual delineation of PCa lesions, it is much more convenient for clinical usage. Comprehensive evaluation based on fivefold cross validation using 360 patient data demonstrates that our system achieves a high accuracy for CS PCa detection, i.e., a sensitivity of 0.6374 and 0.8978 at 0.1 and 1 false positives per normal/benign patient. © 1982-2012 IEEE.","CS PCA detection; joint optimization; multimodal registration; neural network","Algorithms; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Neural Networks (Computer); Prostate; Prostatic Neoplasms; ROC Curve; Automation; Deep neural networks; Diseases; Extraction; Feature extraction; Hospital data processing; Magnetic levitation vehicles; Magnetic resonance; Magnetic resonance imaging; Neural networks; Principal component analysis; Urology; Cancer; Joint optimization; Lesions; Manuals; Multimodal registration; adult; aged; Article; automation; cancer diagnosis; controlled study; deep neural network; false positive result; human; image processing; machine learning; major clinical study; male; multiparametric magnetic resonance imaging; prostate; prostate biopsy; prostate cancer; sensitivity and specificity; algorithm; artificial neural network; computer assisted diagnosis; diagnostic imaging; nuclear magnetic resonance imaging; procedures; prostate tumor; receiver operating characteristic; Calcium compounds","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","29727276","Article","Scopus","2-s2.0-85040059398"
"Antropova N.; Abe H.; Giger M.L.","Antropova, Natalia (57190279968); Abe, Hiroyuki (36044023400); Giger, Maryellen L. (7103040897)","57190279968; 36044023400; 7103040897","Use of clinical MRI maximum intensity projections for improved breast lesion classification with deep convolutional neural networks","2018","Journal of Medical Imaging","71","10.1117/1.JMI.5.1.014503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041671891&doi=10.1117%2f1.JMI.5.1.014503&partnerID=40&md5=ebc25752d4cbd444ccec212be108ee17","University of Chicago, Department of Radiology, Chicago, IL, United States","Antropova N., University of Chicago, Department of Radiology, Chicago, IL, United States; Abe H., University of Chicago, Department of Radiology, Chicago, IL, United States; Giger M.L., University of Chicago, Department of Radiology, Chicago, IL, United States","Deep learning methods have been shown to improve breast cancer diagnostic and prognostic decisions based on selected slices of dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI). However, incorporation of volumetric and temporal components into DCE-MRIs has not been well studied. We propose maximum intensity projection (MIP) images of subtraction MRI as a way to simultaneously include four-dimensional (4-D) images into lesion classification using convolutional neural networks (CNN). The study was performed on a dataset of 690 cases. Regions of interest were selected around each lesion on three MRI presentations: (i) the MIP image generated on the second postcontrast subtraction MRI, (ii) the central slice of the second postcontrast MRI, and (iii) the central slice of the second postcontrast subtraction MRI. CNN features were extracted from the ROIs using pretrained VGGNet. The features were utilized in the training of three support vector machine classifiers to characterize lesions as malignant or benign. Classifier performances were evaluated with fivefold cross-validation and compared based on area under the ROC curve (AUC). The approach using MIPs [AUC=0.88(se=0.01)] outperformed that using central-slices of either second postcontrast MRIs [0.80(se=0.02)] or second postcontrast subtraction MRIs [AUC=0.84(se=0.02)], at statistically significant levels. © 2018 Society of Photo-Optical Instrumentation Engineers (SPIE).","breast cancer; convolutional neural networks; dynamic contrast-enhanced magnetic resonance imaging; four-dimensional data; maximum intensity projection","gadobenate dimeglumine; gadodiamide; adult; Article; breast cancer molecular subtype; breast carcinoma; breast fibroadenoma; breast lesion; breast papilloma; cancer classification; contrast enhancement; convolutional neural network; diagnostic test accuracy study; disease classification; dynamic contrast-enhanced magnetic resonance imaging; estrogen receptor negative breast cancer; estrogen receptor positive breast cancer; evaluation study; fibrocystic breast disease; four dimensional imaging; human; human epidermal growth factor receptor 2 negative breast cancer; human epidermal growth factor receptor 2 positive breast cancer; image analysis; image subtraction; imaging and display; intermethod comparison; intraductal carcinoma; lobular carcinoma; machine learning; major clinical study; maximum intensity projection; middle aged; progesterone receptor negative breast cancer; progesterone receptor positive breast cancer; receiver operating characteristic; retrospective study; sensitivity and specificity; support vector machine; three dimensional imaging; tumor differentiation","SPIE","23294302","","","","Article","Scopus","2-s2.0-85041671891"
"Mohamed A.A.; Berg W.A.; Peng H.; Luo Y.; Jankowitz R.C.; Wu S.","Mohamed, Aly A. (57195713537); Berg, Wendie A. (7102328695); Peng, Hong (57195719956); Luo, Yahong (34768718500); Jankowitz, Rachel C. (23469707400); Wu, Shandong (24451518600)","57195713537; 7102328695; 57195719956; 34768718500; 23469707400; 24451518600","A deep learning method for classifying mammographic breast density categories","2018","Medical Physics","200","10.1002/mp.12683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037984128&doi=10.1002%2fmp.12683&partnerID=40&md5=da53e5a44e3dd8d4c684087444ac1dd2","Department of Radiology, University of Pittsburgh, School of Medicine, 4200 Fifth Ave, Pittsburgh, 15260, PA, United States; Magee-Womens Hospital, University of Pittsburgh Medical Center, 300 Halket St, Pittsburgh, 15213, PA, United States; Department of Radiology, Chinese PLA General Hospital, 28 Fuxing Rd, Haidian District, Beijing, 100853, China; Department of Radiology, Liaoning Cancer Hospital and Institute, 44 Xiaoheyan Rd, Dadong District, Shenyang City, Liaoning, 110042, China; Department of Medicine, School of Medicine, University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, 15260, PA, United States; Departments of Radiology, Biomedical Informatics, Bioengineering, and Computer Science, University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, 15260, PA, United States","Mohamed A.A., Department of Radiology, University of Pittsburgh, School of Medicine, 4200 Fifth Ave, Pittsburgh, 15260, PA, United States; Berg W.A., Department of Radiology, University of Pittsburgh, School of Medicine, 4200 Fifth Ave, Pittsburgh, 15260, PA, United States, Magee-Womens Hospital, University of Pittsburgh Medical Center, 300 Halket St, Pittsburgh, 15213, PA, United States; Peng H., Department of Radiology, Chinese PLA General Hospital, 28 Fuxing Rd, Haidian District, Beijing, 100853, China; Luo Y., Department of Radiology, Liaoning Cancer Hospital and Institute, 44 Xiaoheyan Rd, Dadong District, Shenyang City, Liaoning, 110042, China; Jankowitz R.C., Magee-Womens Hospital, University of Pittsburgh Medical Center, 300 Halket St, Pittsburgh, 15213, PA, United States, Department of Medicine, School of Medicine, University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, 15260, PA, United States; Wu S., Departments of Radiology, Biomedical Informatics, Bioengineering, and Computer Science, University of Pittsburgh, 4200 Fifth Ave, Pittsburgh, 15260, PA, United States","Purpose: Mammographic breast density is an established risk marker for breast cancer and is visually assessed by radiologists in routine mammogram image reading, using four qualitative Breast Imaging and Reporting Data System (BI-RADS) breast density categories. It is particularly difficult for radiologists to consistently distinguish the two most common and most variably assigned BI-RADS categories, i.e., ""scattered density"" and ""heterogeneously dense"". The aim of this work was to investigate a deep learning-based breast density classifier to consistently distinguish these two categories, aiming at providing a potential computerized tool to assist radiologists in assigning a BI-RADS category in current clinical workflow. Methods: In this study, we constructed a convolutional neural network (CNN)-based model coupled with a large (i.e., 22,000 images) digital mammogram imaging dataset to evaluate the classification performance between the two aforementioned breast density categories. All images were collected from a cohort of 1,427 women who underwent standard digital mammography screening from 2005 to 2016 at our institution. The truths of the density categories were based on standard clinical assessment made by board-certified breast imaging radiologists. Effects of direct training from scratch solely using digital mammogram images and transfer learning of a pretrained model on a large nonmedical imaging dataset were evaluated for the specific task of breast density classification. In order to measure the classification performance, the CNN classifier was also tested on a refined version of the mammogram image dataset by removing some potentially inaccurately labeled images. Receiver operating characteristic (ROC) curves and the area under the curve (AUC) were used to measure the accuracy of the classifier. Results: The AUC was 0.9421 when the CNN-model was trained from scratch on our own mammogram images, and the accuracy increased gradually along with an increased size of training samples. Using the pretrained model followed by a fine-tuning process with as few as 500 mammogram images led to an AUC of 0.9265. After removing the potentially inaccurately labeled images, AUC was increased to 0.9882 and 0.9857 for without and with the pretrained model, respectively, both significantly higher (P < 0.001) than when using the full imaging dataset. Conclusions: Our study demonstrated high classification accuracies between two difficult to distinguish breast density categories that are routinely assessed by radiologists. We anticipate that our approach will help enhance current clinical assessment of breast density and better support consistent density notification to patients in breast cancer screening. © 2017 American Association of Physicists in Medicine.","BI-RADS; breast density; convolutional neural network (CNN); deep learning; digital mammography; transfer learning","Area Under Curve; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Mammography; Neural Networks (Computer); Retrospective Studies; ROC Curve; Classification (of information); Data visualization; Deep neural networks; E-learning; Mammography; Risk assessment; X ray screens; Areas under the curves; BI-RADS; Breast density; Convolutional neural network; Deep learning; Digital mammography; Mammogram images; Mammographic breast densities; Transfer learning; accuracy; Article; breast density; classifier; clinical assessment; cohort analysis; digital mammography; female; human; image analysis; noise; quantitative analysis; retrospective study; area under the curve; artificial neural network; computer assisted diagnosis; machine learning; mammography; procedures; receiver operating characteristic; Convolution","John Wiley and Sons Ltd","00942405","","MPHYA","29159811","Article","Scopus","2-s2.0-85037984128"
"Ahmad A.; Asif A.; Rajpoot N.; Arif M.; Minhas F.A.A.","Ahmad, Asif (56032575400); Asif, Amina (57191980389); Rajpoot, Nasir (8042017200); Arif, Muhammad (58966280500); Minhas, Fayyaz ul Amir Afsar (24399575300)","56032575400; 57191980389; 8042017200; 58966280500; 24399575300","Correlation Filters for Detection of Cellular Nuclei in Histopathology Images","2018","Journal of Medical Systems","10","10.1007/s10916-017-0863-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037031973&doi=10.1007%2fs10916-017-0863-8&partnerID=40&md5=78f398963773a39180b0ea5c07047dea","Biomedical Informatics Research Laboratory, Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan; Department of Computer Science, University of Warwick, Coventry, United Kingdom; Department of Electrical Engineering, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan","Ahmad A., Biomedical Informatics Research Laboratory, Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan; Asif A., Biomedical Informatics Research Laboratory, Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan; Rajpoot N., Department of Computer Science, University of Warwick, Coventry, United Kingdom; Arif M., Department of Electrical Engineering, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan; Minhas F.A.A., Biomedical Informatics Research Laboratory, Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences, PO Nilore, Islamabad, Pakistan","Nuclei detection in histology images is an essential part of computer aided diagnosis of cancers and tumors. It is a challenging task due to diverse and complicated structures of cells. In this work, we present an automated technique for detection of cellular nuclei in hematoxylin and eosin stained histopathology images. Our proposed approach is based on kernelized correlation filters. Correlation filters have been widely used in object detection and tracking applications but their strength has not been explored in the medical imaging domain up till now. Our experimental results show that the proposed scheme gives state of the art accuracy and can learn complex nuclear morphologies. Like deep learning approaches, the proposed filters do not require engineering of image features as they can operate directly on histopathology images without significant preprocessing. However, unlike deep learning methods, the large-margin correlation filters developed in this work are interpretable, computationally efficient and do not require specialized or expensive computing hardware. Availability: A cloud based webserver of the proposed method and its python implementation can be accessed at the following URL: http://faculty.pieas.edu.pk/fayyaz/software.html#corehist. © 2017, Springer Science+Business Media, LLC, part of Springer Nature.","Cell detection; Correlation filters; Histopathology images; Kernelized correlation filters; Nuclei detection","Cell Nucleus; Fourier Analysis; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Article; autoanalysis; cell nucleus; cell structure; cell tracking; classifier; comparative study; controlled study; histopathology; image analysis; image processing; kernelized correlation filter; mathematical computing; web browser; cell nucleus; computer assisted diagnosis; Fourier analysis; human; machine learning; pathology; procedures","Springer New York LLC","01485598","","JMSYD","29164340","Article","Scopus","2-s2.0-85037031973"
"Liu M.; Zhang J.; Adeli E.; Shen D.","Liu, Mingxia (36677833300); Zhang, Jun (57022097100); Adeli, Ehsan (57205548034); Shen, Dinggang (7401738392)","36677833300; 57022097100; 57205548034; 7401738392","Landmark-based deep multi-instance learning for brain disease diagnosis","2018","Medical Image Analysis","298","10.1016/j.media.2017.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032831440&doi=10.1016%2fj.media.2017.10.005&partnerID=40&md5=55466a211250e39f07e6f981baecaa6b","Department of Radiology and BRIC, University of North Carolina at Chapel Hill, North Carolina 27599, United States; Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, South Korea","Liu M., Department of Radiology and BRIC, University of North Carolina at Chapel Hill, North Carolina 27599, United States; Zhang J., Department of Radiology and BRIC, University of North Carolina at Chapel Hill, North Carolina 27599, United States; Adeli E., Department of Radiology and BRIC, University of North Carolina at Chapel Hill, North Carolina 27599, United States; Shen D., Department of Radiology and BRIC, University of North Carolina at Chapel Hill, North Carolina 27599, United States, Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, South Korea","In conventional Magnetic Resonance (MR) image based methods, two stages are often involved to capture brain structural information for disease diagnosis, i.e., 1) manually partitioning each MR image into a number of regions-of-interest (ROIs), and 2) extracting pre-defined features from each ROI for diagnosis with a certain classifier. However, these pre-defined features often limit the performance of the diagnosis, due to challenges in 1) defining the ROIs and 2) extracting effective disease-related features. In this paper, we propose a landmark-based deep multi-instance learning (LDMIL) framework for brain disease diagnosis. Specifically, we first adopt a data-driven learning approach to discover disease-related anatomical landmarks in the brain MR images, along with their nearby image patches. Then, our LDMIL framework learns an end-to-end MR image classifier for capturing both the local structural information conveyed by image patches located by landmarks and the global structural information derived from all detected landmarks. We have evaluated our proposed framework on 1526 subjects from three public datasets (i.e., ADNI-1, ADNI-2, and MIRIAD), and the experimental results show that our framework can achieve superior performance over state-of-the-art approaches. © 2017 Elsevier B.V.","Brain disease; Convolutional neural network; Landmark; Multi-instance learning","Aged; Alzheimer Disease; Brain Diseases; Female; Humans; Learning; Magnetic Resonance Imaging; Male; Classification (of information); Deep learning; Magnetic resonance; Magnetic resonance imaging; Navigation; Neural networks; Anatomical landmarks; Brain disease; Convolutional neural network; Image-based methods; Landmark; Multi-instance learning; State-of-the-art approach; Structural information; aged; Alzheimer disease; anatomic landmark; Article; classification algorithm; classifier; Clinical Dementia Rating; diagnostic test accuracy study; female; human; image analysis; image processing; intermethod comparison; landmark based deep multi instance learning; learning algorithm; machine learning; major clinical study; male; Mini Mental State Examination; neuroanatomy; neuroimaging; nuclear magnetic resonance imaging; predictive value; priority journal; receiver operating characteristic; sensitivity and specificity; signal noise ratio; voxel based morphometry; Alzheimer disease; brain disease; learning; procedures; Computer aided diagnosis","Elsevier B.V.","13618415","","MIAEC","29107865","Article","Scopus","2-s2.0-85032831440"
"BeCkeR A.S.; MuelleR M.; StOFFel E.; MARCOn M.; ghAFOOR S.; Boss A.","BeCkeR, AntOn S (55389064500); MuelleR, MiChAel (57201545604); StOFFel, elinA (57201062154); MARCOn, MAgDA (56334882300); ghAFOOR, SOleen (57076294200); Boss, AnDReAS (9737288900)","55389064500; 57201545604; 57201062154; 56334882300; 57076294200; 9737288900","Classification of breast cancer in ultrasound imaging using a generic deep learning analysis software: a pilot study","2018","British Journal of Radiology","115","10.1259/bjr.20170576","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043286827&doi=10.1259%2fbjr.20170576&partnerID=40&md5=f033c7e3f70c44c7ff847ddf833106e9","Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Zurich, Switzerland","BeCkeR A.S., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Zurich, Switzerland; MuelleR M., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Zurich, Switzerland; StOFFel E., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Zurich, Switzerland; MARCOn M., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Zurich, Switzerland; ghAFOOR S., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Zurich, Switzerland; Boss A., Institute of Diagnostic and Interventional Radiology, University Hospital of Zurich, Zurich, Switzerland","Objective: To train a generic deep learning software (DLS) to classify breast cancer on ultrasound images and to compare its performance to human readers with variable breast imaging experience. Methods: In this retrospective study, all breast ultrasound examinations from January 1, 2014 to December 31, 2014 at our institution were reviewed. Patients with post-surgical scars, initially indeterminate, or malignant lesions with histological diagnoses or 2-year follow-up were included. The DLS was trained with 70% of the images, and the remaining 30% were used to validate the performance. Three readers with variable expertise also evaluated the validation set (radiologist, resident, medical student). Diagnostic accuracy was assessed with a receiver operating characteristic analysis. Results: 82 patients with malignant and 550 with benign lesions were included. Time needed for training was 7min (DLS). Evaluation time for the test data set were 3.7s (DLS) and 28, 22 and 25min for human readers (decreasing experience). Receiver operating characteristic analysis revealed non-significant differences (p-values 0.45–0.47) in the area under the curve of 0.84 (DLS), 0.88 (experienced and intermediate readers) and 0.79 (inexperienced reader). Conclusion: DLS may aid diagnosing cancer on breast ultrasound images with an accuracy comparable to radiologists, and learns better and faster than a human reader with no prior experience. Further clinical trials with dedicated algorithms are warranted.Advances in knowledge: DLS can be trained classify cancer on breast ultrasound images high accuracy even with comparably few training cases. The fast evaluation speed makes real-time image analysis feasible. © 2018 The Authors.","","Adolescent; Adult; Aged; Aged, 80 and over; Algorithms; Breast Neoplasms; Clinical Competence; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Middle Aged; Observer Variation; Retrospective Studies; Software; Switzerland; Ultrasonography, Mammary; adolescent; adult; aged; Article; benign neoplasm; breast cancer; breast carcinoma; classification; cohort analysis; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; echomammography; female; human; learning algorithm; major clinical study; malignant neoplasm; predictive value; radiologist; retrospective study; sensitivity and specificity; algorithm; breast tumor; clinical competence; computer assisted diagnosis; diagnostic imaging; echomammography; machine learning; middle aged; observer variation; pathology; procedures; software; Switzerland; very elderly","British Institute of Radiology","00071285","","BJRAA","29215311","Article","Scopus","2-s2.0-85043286827"
"Merk D.; Friedrich L.; Grisoni F.; Schneider G.","Merk, Daniel (53868203200); Friedrich, Lukas (57188921458); Grisoni, Francesca (56020972100); Schneider, Gisbert (7402466014)","53868203200; 57188921458; 56020972100; 7402466014","De Novo Design of Bioactive Small Molecules by Artificial Intelligence","2018","Molecular Informatics","236","10.1002/minf.201700153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042067622&doi=10.1002%2fminf.201700153&partnerID=40&md5=8ca7ad38100f973a376332341dfef398","Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Department of Earth and Environmental Sciences, University of Milano-Bicocca, P.za della Scienza, 1, Milan, IT-20126, Italy","Merk D., Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Friedrich L., Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Grisoni F., Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland, Department of Earth and Environmental Sciences, University of Milano-Bicocca, P.za della Scienza, 1, Milan, IT-20126, Italy; Schneider G., Department of Chemistry and Applied Biosciences, Swiss Federal Institute of Technology (ETH), Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland","Generative artificial intelligence offers a fresh view on molecular design. We present the first-time prospective application of a deep learning model for designing new druglike compounds with desired activities. For this purpose, we trained a recurrent neural network to capture the constitution of a large set of known bioactive compounds represented as SMILES strings. By transfer learning, this general model was fine-tuned on recognizing retinoid X and peroxisome proliferator-activated receptor agonists. We synthesized five top-ranking compounds designed by the generative model. Four of the compounds revealed nanomolar to low-micromolar receptor modulatory activity in cell-based assays. Apparently, the computational model intrinsically captured relevant chemical and biological knowledge without the need for explicit rules. The results of this study advocate generative artificial intelligence for prospective de novo molecular design, and demonstrate the potential of these methods for future medicinal chemistry. © 2018 The Authors. Published by Wiley-VCH Verlag GmbH & Co. KGaA.","Automation; drug discovery; machine learning; medicinal chemistry; nuclear receptor","Deep Learning; Drug Design; HEK293 Cells; Humans; Molecular Docking Simulation; Peroxisome Proliferator-Activated Receptors; Quantitative Structure-Activity Relationship; Retinoid X Receptors; Small Molecule Libraries; peroxisome proliferator activated receptor agonist; peroxisome proliferator activated receptor; retinoid X receptor; Article; artificial intelligence; priority journal; transfer of learning; agonists; chemistry; drug design; HEK293 cell line; human; molecular docking; molecular library; pharmacology; quantitative structure activity relation; synthesis","Wiley-VCH Verlag","18681743","","MIONB","29319225","Article","Scopus","2-s2.0-85042067622"
"Chen X.; Gong Y.; Zhang D.-H.; You Z.-H.; Li Z.-W.","Chen, Xing (57191252607); Gong, Yao (57189601132); Zhang, De-Hong (57200043586); You, Zhu-Hong (23062542900); Li, Zheng-Wei (57192308339)","57191252607; 57189601132; 57200043586; 23062542900; 57192308339","DRMDA: deep representations-based miRNA–disease association prediction","2018","Journal of Cellular and Molecular Medicine","67","10.1111/jcmm.13336","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038942532&doi=10.1111%2fjcmm.13336&partnerID=40&md5=36709107673127d0e62e52136ae0322c","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Life Science, Peking University, Beijing, China; Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Ürümqi, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China","Chen X., School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; Gong Y., School of Life Science, Peking University, Beijing, China; Zhang D.-H., School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; You Z.-H., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, Ürümqi, China; Li Z.-W., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China","Recently, microRNAs (miRNAs) are confirmed to be important molecules within many crucial biological processes and therefore related to various complex human diseases. However, previous methods of predicting miRNA–disease associations have their own deficiencies. Under this circumstance, we developed a prediction method called deep representations-based miRNA–disease association (DRMDA) prediction. The original miRNA–disease association data were extracted from HDMM database. Meanwhile, stacked auto-encoder, greedy layer-wise unsupervised pre-training algorithm and support vector machine were implemented to predict potential associations. We compared DRMDA with five previous classical prediction models (HGIMDA, RLSMDA, HDMP, WBSMDA and RWRMDA) in global leave-one-out cross-validation (LOOCV), local LOOCV and fivefold cross-validation, respectively. The AUCs achieved by DRMDA were 0.9177, 08339 and 0.9156 ± 0.0006 in the three tests above, respectively. In further case studies, we predicted the top 50 potential miRNAs for colon neoplasms, lymphoma and prostate neoplasms, and 88%, 90% and 86% of the predicted miRNA can be verified by experimental evidence, respectively. In conclusion, DRMDA is a promising prediction method which could identify potential and novel miRNA–disease associations. © 2017 The Authors. Journal of Cellular and Molecular Medicine published by John Wiley & Sons Ltd and Foundation for Cellular and Molecular Medicine.","auto-encoder; deep representation; disease; miRNA; miRNA–disease association","Algorithms; Computational Biology; Deep Learning; Genetic Association Studies; Humans; MicroRNAs; Neoplasms; microRNA; microRNA; accuracy; Article; assessment of humans; bibliographic database; biological functions; colon tumor; data base; deep representation based miRNA disease association; disease association; disease model; disease semantic similarity model 1; disease semantic similarity model 2; genetic algorithm; genetic similarity; human; kernel method; lymphoma; non small cell lung cancer; prediction; priority journal; prostate tumor; semantics; algorithm; biology; genetic association study; genetics; metabolism; neoplasm; procedures","Blackwell Publishing Inc.","15821838","","","28857494","Article","Scopus","2-s2.0-85038942532"
"Paul R.; Hawkins S.H.; Schabath M.B.; Gillies R.J.; Hall L.O.; Goldgof D.B.","Paul, Rahul (57193679977); Hawkins, Samuel H. (56525449500); Schabath, Matthew B. (6603452555); Gillies, Robert J. (7102089341); Hall, Lawrence O. (57203365478); Goldgof, Dmitry B. (35572085000)","57193679977; 56525449500; 6603452555; 7102089341; 57203365478; 35572085000","Predicting malignant nodules by fusing deep features with classical radiomics features","2018","Journal of Medical Imaging","79","10.1117/1.JMI.5.1.011021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044656253&doi=10.1117%2f1.JMI.5.1.011021&partnerID=40&md5=7f09d5ad2bff84bc29edb5fe787bb8d0","Department of Computer Science and Engineering, University of South Florida, Tampa, FL, United States; Department of Cancer Epidemiology, H. Lee Moffitt Cancer Center and Research Institute, Tampa, FL, United States; H. Lee Moffitt Cancer Center and Research Institute, Department of Cancer Physiology, Tampa, FL, United States","Paul R., Department of Computer Science and Engineering, University of South Florida, Tampa, FL, United States; Hawkins S.H., Department of Computer Science and Engineering, University of South Florida, Tampa, FL, United States; Schabath M.B., Department of Cancer Epidemiology, H. Lee Moffitt Cancer Center and Research Institute, Tampa, FL, United States; Gillies R.J., H. Lee Moffitt Cancer Center and Research Institute, Department of Cancer Physiology, Tampa, FL, United States; Hall L.O., Department of Computer Science and Engineering, University of South Florida, Tampa, FL, United States; Goldgof D.B., Department of Computer Science and Engineering, University of South Florida, Tampa, FL, United States","Lung cancer has a high incidence and mortality rate. Early detection and diagnosis of lung cancers is best achieved with low-dose computed tomography (CT). Classical radiomics features extracted from lung CT images have been shown as able to predict cancer incidence and prognosis. With the advancement of deep learning and convolutional neural networks (CNNs), deep features can be identified to analyze lung CTs for prognosis prediction and diagnosis. Due to a limited number of available images in the medical field, the transfer learning concept can be helpful. Using subsets of participants from the National Lung Screening Trial (NLST), we utilized a transfer learning approach to differentiate lung cancer nodules versus positive controls. We experimented with three different pretrained CNNs for extracting deep features and used five different classifiers. Experiments were also conducted with deep features from different color channels of a pretrained CNN. Selected deep features were combined with radiomics features. A CNN was designed and trained. Combinations of features from pretrained, CNNs trained on NLST data, and classical radiomics were used to build classifiers. The best accuracy (76.79%) was obtained using feature combinations. An area under the receiver operating characteristic curve of 0.87 was obtained using a CNN trained on an augmented NLST data cohort. © 2018 Society of Photo-Optical Instrumentation Engineers (SPIE).","Convolutional neural network; Deep features; National Lung Screening Trial; Nonsmall cell lung cancer; Radiomics; Transfer learning","adult; Article; artificial neural network; Bayesian learning; cancer diagnosis; cancer prognosis; cancer screening; classifier; clinical feature; controlled study; convolutional neural network; diagnostic accuracy; female; human; k nearest neighbor; lung cancer; lung nodule; major clinical study; male; multicenter study; radiological parameters; random forest; randomized controlled trial; support vector machine; thorax radiography; transfer of learning","SPIE","23294302","","","","Article","Scopus","2-s2.0-85044656253"
"Zhang R.; Huang L.; Xia W.; Zhang B.; Qiu B.; Gao X.","Zhang, Rui (55729168300); Huang, Lin (57193509562); Xia, Wei (57204015762); Zhang, Bo (57193512308); Qiu, Bensheng (7102407325); Gao, Xin (56982120200)","55729168300; 57193509562; 57204015762; 57193512308; 7102407325; 56982120200","Multiple supervised residual network for osteosarcoma segmentation in CT images","2018","Computerized Medical Imaging and Graphics","66","10.1016/j.compmedimag.2018.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040604143&doi=10.1016%2fj.compmedimag.2018.01.006&partnerID=40&md5=49940a4984f171c6c3517cd1c74813f9","Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China; University of Science and Technology of China, Hefei, China; The Second Affiliated Hospital of Soochow University, Suzhou, China","Zhang R., Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China; Huang L., Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China, University of Science and Technology of China, Hefei, China; Xia W., Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China; Zhang B., The Second Affiliated Hospital of Soochow University, Suzhou, China; Qiu B., University of Science and Technology of China, Hefei, China; Gao X., Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China","Automatic and accurate segmentation of osteosarcoma region in CT images can help doctor make a reasonable treatment plan, thus improving cure rate. In this paper, a multiple supervised residual network (MSRN) was proposed for osteosarcoma image segmentation. Three supervised side output modules were added to the residual network. The shallow side output module could extract image shape features, such as edge features and texture features. The deep side output module could extract semantic features. The side output module could compute the loss value between output probability map and ground truth and back-propagate the loss information. Then, the parameters of residual network could be modified by gradient descent method. This could guide the multi-scale feature learning of the network. The final segmentation results were obtained by fusing the results output by the three side output modules. A total of 1900 CT images from 15 osteosarcoma patients were used to train the network and a total of 405 CT images from another 8 osteosarcoma patients were used to test the network. Results indicated that MSRN enabled a dice similarity coefficient (DSC) of 89.22%, a sensitivity of 88.74% and a F1-measure of 0.9305, which were larger than those obtained by fully convolutional network (FCN) and U-net. Thus, MSRN for osteosarcoma segmentation could give more accurate results than FCN and U-Net. © 2018 Elsevier Ltd","Deep residual network; Multiple supervised networks; Osteosarcoma segmentation","Algorithms; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Osteosarcoma; Tomography, X-Ray Computed; Image enhancement; Image segmentation; Semantics; Convolutional networks; Gradient Descent method; Image shape features; Multi-scale features; Osteosarcoma segmentation; Segmentation results; Similarity coefficients; Supervised network; Article; cancer patient; clinical article; clinical feature; computer assisted tomography; controlled study; human; image analysis; image processing; image segmentation; learning algorithm; osteosarcoma; priority journal; radiologist; supervised machine learning; algorithm; artificial neural network; diagnostic imaging; image processing; osteosarcoma; x-ray computed tomography; Computerized tomography","Elsevier Ltd","08956111","","CMIGE","29361340","Article","Scopus","2-s2.0-85040604143"
"Dehghanpoor R.; Ricks E.; Hursh K.; Gunderson S.; Farhoodi R.; Haspel N.; Hutchinson B.; Jagodzinski F.","Dehghanpoor, Ramin (57200422553); Ricks, Evan (57196032073); Hursh, Katie (57200412824); Gunderson, Sarah (57200413074); Farhoodi, Roshanak (55809579400); Haspel, Nurit (6506027377); Hutchinson, Brian (36628672500); Jagodzinski, Filip (23569292600)","57200422553; 57196032073; 57200412824; 57200413074; 55809579400; 6506027377; 36628672500; 23569292600","Predicting the effect of single and multiple mutations on protein structural stability","2018","Molecules","27","10.3390/molecules23020251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041189747&doi=10.3390%2fmolecules23020251&partnerID=40&md5=de0ecfa2a773307acb197ae2079d32c2","Department of Computer Science, University of Massachusetts Boston, Boston, 02125, MA, United States; Department of Computer Science, Western Washington University, Bellingham, 98225, WA, United States; Computing and Analytics Division, Pacific Northwest National Laboratory, Richland, 99354, WA, United States","Dehghanpoor R., Department of Computer Science, University of Massachusetts Boston, Boston, 02125, MA, United States; Ricks E., Department of Computer Science, Western Washington University, Bellingham, 98225, WA, United States; Hursh K., Department of Computer Science, Western Washington University, Bellingham, 98225, WA, United States; Gunderson S., Department of Computer Science, Western Washington University, Bellingham, 98225, WA, United States; Farhoodi R., Department of Computer Science, University of Massachusetts Boston, Boston, 02125, MA, United States; Haspel N., Department of Computer Science, University of Massachusetts Boston, Boston, 02125, MA, United States; Hutchinson B., Department of Computer Science, Western Washington University, Bellingham, 98225, WA, United States, Computing and Analytics Division, Pacific Northwest National Laboratory, Richland, 99354, WA, United States; Jagodzinski F., Department of Computer Science, Western Washington University, Bellingham, 98225, WA, United States","Predicting how a point mutation alters a protein's stability can guide pharmaceutical drug design initiatives which aim to counter the effects of serious diseases. Conducting mutagenesis studies in physical proteins can give insights about the effects of amino acid substitutions, but such wet-lab work is prohibitive due to the time as well as financial resources needed to assess the effect of even a single amino acid substitution. Computational methods for predicting the effects of a mutation on a protein structure can complement wet-lab work, and varying approaches are available with promising accuracy rates. In this work we compare and assess the utility of several machine learning methods and their ability to predict the effects of single and double mutations. We in silico generate mutant protein structures, and compute several rigidity metrics for each of them. We use these as features for our Support Vector Regression (SVR), Random Forest (RF), and Deep Neural Network (DNN) methods. We validate the predictions of our in silico mutations against experimental DDG stability data, and attain Pearson Correlation values upwards of 0.71 for single mutations, and 0.81 for double mutations. We perform ablation studies to assess which features contribute most to a model's success, and also introduce a voting scheme to synthesize a single prediction from the individual predictions of the three models. © 2018 by the authors.","DNN; Machine learning; Protein mutational study; RF; Rigidity analysis; SVR","Amino Acid Substitution; Computer Simulation; Decision Trees; Mutation; Neural Networks (Computer); Protein Conformation; Protein Stability; Proteins; Support Vector Machine; Thermodynamics; protein; amino acid substitution; artificial neural network; chemistry; computer simulation; decision tree; mutation; protein conformation; protein stability; support vector machine; thermodynamics","MDPI AG","14203049","","MOLEF","29382060","Article","Scopus","2-s2.0-85041189747"
"Prahs P.; Radeck V.; Mayer C.; Cvetkov Y.; Cvetkova N.; Helbig H.; Märker D.","Prahs, Philipp (24830840800); Radeck, Viola (36523584600); Mayer, Christian (56414154400); Cvetkov, Yordan (56770028800); Cvetkova, Nadezhda (56483314200); Helbig, Horst (35603680300); Märker, David (36097504600)","24830840800; 36523584600; 56414154400; 56770028800; 56483314200; 35603680300; 36097504600","OCT-based deep learning algorithm for the evaluation of treatment indication with anti-vascular endothelial growth factor medications","2018","Graefe's Archive for Clinical and Experimental Ophthalmology","82","10.1007/s00417-017-3839-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033462485&doi=10.1007%2fs00417-017-3839-y&partnerID=40&md5=0bf4b01907faaa7e70f33def8c6118c9","Department of Ophthalmology, University of Regensburg, Franz-Josef-Strauss-Allee 11, Regensburg, 93042, Germany; Department of Ophthalmology, Technical University of Munich, Ismaninger Str. 22, Munich, 81675, Germany","Prahs P., Department of Ophthalmology, University of Regensburg, Franz-Josef-Strauss-Allee 11, Regensburg, 93042, Germany; Radeck V., Department of Ophthalmology, University of Regensburg, Franz-Josef-Strauss-Allee 11, Regensburg, 93042, Germany; Mayer C., Department of Ophthalmology, Technical University of Munich, Ismaninger Str. 22, Munich, 81675, Germany; Cvetkov Y., Department of Ophthalmology, University of Regensburg, Franz-Josef-Strauss-Allee 11, Regensburg, 93042, Germany; Cvetkova N., Department of Ophthalmology, University of Regensburg, Franz-Josef-Strauss-Allee 11, Regensburg, 93042, Germany; Helbig H., Department of Ophthalmology, University of Regensburg, Franz-Josef-Strauss-Allee 11, Regensburg, 93042, Germany; Märker D., Department of Ophthalmology, University of Regensburg, Franz-Josef-Strauss-Allee 11, Regensburg, 93042, Germany","Purpose: Intravitreal injections with anti-vascular endothelial growth factor (anti-VEGF) medications have become the standard of care for their respective indications. Optical coherence tomography (OCT) scans of the central retina provide detailed anatomical data and are widely used by clinicians in the decision-making process of anti-VEGF indication. In recent years, significant progress has been made in artificial intelligence and computer vision research. We trained a deep convolutional artificial neural network to predict treatment indication based on central retinal OCT scans without human intervention. Method: A total of 183,402 retinal OCT B-scans acquired between 2008 and 2016 were exported from the institutional image archive of a university hospital. OCT images were cross-referenced with the electronic institutional intravitreal injection records. OCT images with a following intravitreal injection during the first 21 days after image acquisition were assigned into the ‘injection’ group, while the same amount of random OCT images without intravitreal injections was labeled as ‘no injection’. After image preprocessing, OCT images were split in a 9:1 ratio to training and test datasets. We trained a GoogLeNet inception deep convolutional neural network and assessed its performance on the validation dataset. We calculated prediction accuracy, sensitivity, specificity, and receiver operating characteristics. Results: The deep convolutional neural network was successfully trained on the extracted clinical data. The trained neural network classifier reached a prediction accuracy of 95.5% on the images in the validation dataset. For single retinal B-scans in the validation dataset, a sensitivity of 90.1% and a specificity of 96.2% were achieved. The area under the receiver operating characteristic curve was 0.968 on a per B-scan image basis, and 0.988 by averaging over six B-scans per examination on the validation dataset. Conclusion: Deep artificial neural networks show impressive performance on classification of retinal OCT scans. After training on historical clinical data, machine learning methods can offer the clinician support in the decision-making process. Care should be taken not to mistake neural network output as treatment recommendation and to ensure a final thorough evaluation by the treating physician. © 2017, Springer-Verlag GmbH Germany.","Age-related macular degeneration; Artificial intelligence; Computer vision; Computer-aided diagnosis; Deep learning; Diabetic retinopathy; Optical coherence tomography","Algorithms; Angiogenesis Inducing Agents; Diabetic Retinopathy; Humans; Machine Learning; Macular Edema; Neural Networks (Computer); Retrospective Studies; ROC Curve; Tomography, Optical Coherence; Vascular Endothelial Growth Factor A; vasculotropin inhibitor; angiogenic factor; vasculotropin A; accuracy; Article; B scan; classifier; controlled study; human; learning algorithm; major clinical study; optical coherence tomography; prediction; priority journal; receiver operating characteristic; retrospective study; sensitivity and specificity; treatment indication; algorithm; antagonists and inhibitors; artificial neural network; diabetic retinopathy; machine learning; macular edema; optical coherence tomography; procedures","Springer Verlag","0721832X","","GACOD","29127485","Article","Scopus","2-s2.0-85033462485"
"Arango-Argoty G.; Garner E.; Pruden A.; Heath L.S.; Vikesland P.; Zhang L.","Arango-Argoty, Gustavo (44060984200); Garner, Emily (56197020800); Pruden, Amy (57049332700); Heath, Lenwood S. (35515248200); Vikesland, Peter (6603770862); Zhang, Liqing (55709248500)","44060984200; 56197020800; 57049332700; 35515248200; 6603770862; 55709248500","DeepARG: A deep learning approach for predicting antibiotic resistance genes from metagenomic data","2018","Microbiome","393","10.1186/s40168-018-0401-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042849775&doi=10.1186%2fs40168-018-0401-z&partnerID=40&md5=762811169eb20faff68fadc54bbf9704","Department of Computer Science, Virginia Tech, Blacksburg, VA, United States; Department of Civil and Environmental Engineering, Virginia Tech, Blacksburg, VA, United States","Arango-Argoty G., Department of Computer Science, Virginia Tech, Blacksburg, VA, United States; Garner E., Department of Civil and Environmental Engineering, Virginia Tech, Blacksburg, VA, United States; Pruden A., Department of Civil and Environmental Engineering, Virginia Tech, Blacksburg, VA, United States; Heath L.S., Department of Computer Science, Virginia Tech, Blacksburg, VA, United States; Vikesland P., Department of Civil and Environmental Engineering, Virginia Tech, Blacksburg, VA, United States; Zhang L., Department of Computer Science, Virginia Tech, Blacksburg, VA, United States","Background: Growing concerns about increasing rates of antibiotic resistance call for expanded and comprehensive global monitoring. Advancing methods for monitoring of environmental media (e.g., wastewater, agricultural waste, food, and water) is especially needed for identifying potential resources of novel antibiotic resistance genes (ARGs), hot spots for gene exchange, and as pathways for the spread of ARGs and human exposure. Next-generation sequencing now enables direct access and profiling of the total metagenomic DNA pool, where ARGs are typically identified or predicted based on the ""best hits"" of sequence searches against existing databases. Unfortunately, this approach produces a high rate of false negatives. To address such limitations, we propose here a deep learning approach, taking into account a dissimilarity matrix created using all known categories of ARGs. Two deep learning models, DeepARG-SS and DeepARGLS, were constructed for short read sequences and full gene length sequences, respectively. Results: Evaluation of the deep learning models over 30 antibiotic resistance categories demonstrates that the DeepARG models can predict ARGs with both high precision (> 0.97) and recall (> 0.90). The models displayed an advantage over the typical best hit approach, yielding consistently lower false negative rates and thus higher overall recall (> 0.9). As more data become available for under-represented ARG categories, the DeepARG models' performance can be expected to be further enhanced due to the nature of the underlying neural networks. Our newly developed ARG database, DeepARG-DB, encompasses ARGs predicted with a high degree of confidence and extensive manual inspection, greatly expanding current ARG repositories. Conclusions: The deep learning models developed here offer more accurate antimicrobial resistance annotation relative to current bioinformatics practice. DeepARG does not require strict cutoffs, which enables identification of a much broader diversity of ARGs. The DeepARG models and database are available as a command line version and as a Web service at http://bench.cs.vt.edu/deeparg. © The Author(s). 2018.","Antibiotic resistance; Deep learning; Machine learning; Metagenomics","Computational Biology; Drug Resistance, Microbial; Gene Regulatory Networks; High-Throughput Nucleotide Sequencing; Humans; Machine Learning; Metagenome; Software; aminocoumarin derivative; aminoglycoside; antibiotic agent; bacitracin; beta lactamase; carbapenem; chloramphenicol; fosfomycin; fosmidomycin; fusidic acid; glycopeptide; kasugamycin; pseudomonic acid; puromycin; pyrimethamine; quinolone; rifampicin; streptothricin; sulfonamide; tetracycline; thiostrepton; triclosan; tunicamycin; accuracy; antibiotic resistance; antibiotic resistance gene; Article; bioinformatics; computer model; DNA sequence; gene; learning; measurement precision; metagenomics; mining; molecular genetics; nerve cell network; next generation sequencing; open reading frame; prediction; priority journal; recall; single nucleotide polymorphism; validation study; biology; gene regulatory network; high throughput sequencing; human; machine learning; metagenome; procedures; software","BioMed Central Ltd.","20492618","","","29391044","Article","Scopus","2-s2.0-85042849775"
