"Authors","Author full names","Author(s) ID","Title","Year","Source title","Cited by","DOI","Link","Affiliations","Authors with affiliations","Abstract","Author Keywords","Index Keywords","Publisher","ISSN","ISBN","CODEN","PubMed ID","Document Type","Source","EID"
"Komeda Y.; Handa H.; Watanabe T.; Nomura T.; Kitahashi M.; Sakurai T.; Okamoto A.; Minami T.; Kono M.; Arizumi T.; Takenaka M.; Hagiwara S.; Matsui S.; Nishida N.; Kashida H.; Kudo M.","Komeda, Yoriaki (57191628267); Handa, Hisashi (55534575000); Watanabe, Tomohiro (55544889900); Nomura, Takanobu (57200007995); Kitahashi, Misaki (57200008652); Sakurai, Toshiharu (56704189900); Okamoto, Ayana (57200007817); Minami, Tomohiro (56509871500); Kono, Masashi (56417183000); Arizumi, Tadaaki (54783943200); Takenaka, Mamoru (57191583397); Hagiwara, Satoru (13606202400); Matsui, Shigenaga (35512929700); Nishida, Naoshi (8924754900); Kashida, Hiroshi (7003725272); Kudo, Masatoshi (55216757300)","57191628267; 55534575000; 55544889900; 57200007995; 57200008652; 56704189900; 57200007817; 56509871500; 56417183000; 54783943200; 57191583397; 13606202400; 35512929700; 8924754900; 7003725272; 55216757300","Computer-Aided Diagnosis Based on Convolutional Neural Network System for Colorectal Polyp Classification: Preliminary Experience","2017","Oncology (Switzerland)","155","10.1159/000481227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038641450&doi=10.1159%2f000481227&partnerID=40&md5=5aab3785945c16d3c2ed841fcd231f27","Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Faculty of Science and Engineering, United Kingdom; Graduate School of Science and Engineering Research, Kindai University, Osaka-Sayama, Japan","Komeda Y., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Handa H., Faculty of Science and Engineering, United Kingdom; Watanabe T., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Nomura T., Graduate School of Science and Engineering Research, Kindai University, Osaka-Sayama, Japan; Kitahashi M., Graduate School of Science and Engineering Research, Kindai University, Osaka-Sayama, Japan; Sakurai T., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Okamoto A., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Minami T., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Kono M., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Arizumi T., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Takenaka M., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Hagiwara S., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Matsui S., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Nishida N., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Kashida H., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan; Kudo M., Department of Gastroenterology and Hepatology, Kindai University, Faculty of Medicine, 377-2 Ohno-Higashi, Osaka-Sayama, Osaka, 589-8511, Japan","Background and Aim: Computer-aided diagnosis (CAD) is becoming a next-generation tool for the diagnosis of human disease. CAD for colon polyps has been suggested as a particularly useful tool for trainee colonoscopists, as the use of a CAD system avoids the complications associated with endoscopic resections. In addition to conventional CAD, a convolutional neural network (CNN) system utilizing artificial intelligence (AI) has been developing rapidly over the past 5 years. We attempted to generate a unique CNN-CAD system with an AI function that studied endoscopic images extracted from movies obtained with colonoscopes used in routine examinations. Here, we report our preliminary results of this novel CNN-CAD system for the diagnosis of colon polyps. Methods: A total of 1,200 images from cases of colonoscopy performed between January 2010 and December 2016 at Kindai University Hospital were used. These images were extracted from the video of actual endoscopic examinations. Additional video images from 10 cases of unlearned processes were retrospectively assessed in a pilot study. They were simply diagnosed as either an adenomatous or nonadenomatous polyp. Results: The number of images used by AI to learn to distinguish adenomatous from nonadenomatous was 1,200:600. These images were extracted from the videos of actual endoscopic examinations. The size of each image was adjusted to 256 × 256 pixels. A 10-hold cross-validation was carried out. The accuracy of the 10-hold cross-validation is 0.751, where the accuracy is the ratio of the number of correct answers over the number of all the answers produced by the CNN. The decisions by the CNN were correct in 7 of 10 cases. Conclusion: A CNN-CAD system using routine colonoscopy might be useful for the rapid diagnosis of colorectal polyp classification. Further prospective studies in an in vivo setting are required to confirm the effectiveness of a CNN-CAD system in routine colonoscopy. © 2017 S. Karger AG, Basel.","Artificial intelligence; Colon polyp classification; Computer-aided diagnosis; Convolutional neural network; Deep learning","Colonic Polyps; Colonoscopy; Diagnosis, Computer-Assisted; Humans; Neural Networks (Computer); Retrospective Studies; Article; artificial intelligence; clinical evaluation; colon polyposis; colonoscopy; colorectal polyp; computer assisted diagnosis; convolutional neural network system; disease association; disease classification; human; image analysis; machine learning; major clinical study; pilot study; priority journal; retrospective study; artificial neural network; classification; colon polyp; computer assisted diagnosis; diagnostic imaging; procedures","S. Karger AG","00302414","","ONCOB","29258081","Article","Scopus","2-s2.0-85038641450"
"Vivanti R.; Szeskin A.; Lev-Cohain N.; Sosna J.; Joskowicz L.","Vivanti, R. (56394458100); Szeskin, A. (57195523999); Lev-Cohain, N. (56641628300); Sosna, J. (6603731004); Joskowicz, L. (7003332329)","56394458100; 57195523999; 56641628300; 6603731004; 7003332329","Automatic detection of new tumors and tumor burden evaluation in longitudinal liver CT scan studies","2017","International Journal of Computer Assisted Radiology and Surgery","56","10.1007/s11548-017-1660-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028616371&doi=10.1007%2fs11548-017-1660-z&partnerID=40&md5=6532bbd203032cd29a707cbe5f630377","The Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Givat Ram Campus, Jerusalem, 91904, Israel; Department of Radiology, Hadassah Hebrew University Medical Center, Jerusalem, Israel","Vivanti R., The Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Givat Ram Campus, Jerusalem, 91904, Israel; Szeskin A., The Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Givat Ram Campus, Jerusalem, 91904, Israel; Lev-Cohain N., Department of Radiology, Hadassah Hebrew University Medical Center, Jerusalem, Israel; Sosna J., Department of Radiology, Hadassah Hebrew University Medical Center, Jerusalem, Israel; Joskowicz L., The Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Givat Ram Campus, Jerusalem, 91904, Israel","Purpose: Radiological longitudinal follow-up of liver tumors in CT scans is the standard of care for disease progression assessment and for liver tumor therapy. Finding new tumors in the follow-up scan is essential to determine malignancy, to evaluate the total tumor burden, and to determine treatment efficacy. Since new tumors are typically small, they may be missed by examining radiologists. Methods: We describe a new method for the automatic detection and segmentation of new tumors in longitudinal liver CT studies and for liver tumors burden quantification. Its inputs are the baseline and follow-up CT scans, the baseline tumors delineation, and a tumor appearance prior model. Its outputs are the new tumors segmentations in the follow-up scan, the tumor burden quantification in both scans, and the tumor burden change. Our method is the first comprehensive method that is explicitly designed to find new liver tumors. It integrates information from the scans, the baseline known tumors delineations, and a tumor appearance prior model in the form of a global convolutional neural network classifier. Unlike other deep learning-based methods, it does not require large tagged training sets. Results: Our experimental results on 246 tumors, of which 97 were new tumors, from 37 longitudinal liver CT studies with radiologist approved ground-truth segmentations, yields a true positive new tumors detection rate of 86 versus 72% with stand-alone detection, and a tumor burden volume overlap error of 16%. Conclusions: New tumors detection and tumor burden volumetry are important for diagnosis and treatment. Our new method enables a simplified radiologist-friendly workflow that is potentially more accurate and reliable than the existing one by automatically and accurately following known tumors and detecting new tumors in the follow-up scan. © 2017, CARS.","Liver tumors detection; Liver tumors segmentation; Longitudinal CT study; Radiological assessment","Algorithms; Automation; Humans; Image Processing, Computer-Assisted; Liver Neoplasms; Longitudinal Studies; Retrospective Studies; Tomography, X-Ray Computed; Tumor Burden; contrast medium; Article; cancer diagnosis; follow up; human; image processing; image segmentation; liver parenchyma; liver tumor; machine learning; priority journal; tumor volume; volumetry; x-ray computed tomography; algorithm; automation; diagnostic imaging; liver tumor; longitudinal study; pathology; procedures; retrospective study; tumor volume; x-ray computed tomography","Springer Verlag","18616410","","","28856515","Article","Scopus","2-s2.0-85028616371"
"Guo J.; Qian K.; Zhang G.; Xu H.; Schuller B.","Guo, Jian (56648506600); Qian, Kun (58629705000); Zhang, Gongxuan (55565402900); Xu, Huijie (35207255400); Schuller, Björn (6603767415)","56648506600; 58629705000; 55565402900; 35207255400; 6603767415","Accelerating Biomedical Signal Processing Using GPU: A Case Study of Snore Sound Feature Extraction","2017","Interdisciplinary Sciences – Computational Life Sciences","2","10.1007/s12539-017-0232-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036618012&doi=10.1007%2fs12539-017-0232-9&partnerID=40&md5=dec3fb8af19fd4e3c2a5ddc4bb636267","School of Computer Science and Engineering, Nanjing University of Science Technology, Nanjing, China; Department of Electrical and Computer Engineering, MISP group, MMK Technische University Munchen, Munich, Germany; Department of Otolaryngology, Beijing Hospital, Beijing, China; Bjorn Schuller Department of Computing, Machine Learning Group Imperial College London, London, United Kingdom","Guo J., School of Computer Science and Engineering, Nanjing University of Science Technology, Nanjing, China; Qian K., Department of Electrical and Computer Engineering, MISP group, MMK Technische University Munchen, Munich, Germany; Zhang G., School of Computer Science and Engineering, Nanjing University of Science Technology, Nanjing, China; Xu H., Department of Otolaryngology, Beijing Hospital, Beijing, China; Schuller B., Bjorn Schuller Department of Computing, Machine Learning Group Imperial College London, London, United Kingdom","The advent of ‘Big Data’ and ‘Deep Learning’ offers both, a great challenge and a huge opportunity for personalised health-care. In machine learning-based biomedical data analysis, feature extraction is a key step for ‘feeding’ the subsequent classifiers. With increasing numbers of biomedical data, extracting features from these ‘big’ data is an intensive and time-consuming task. In this case study, we employ a Graphics Processing Unit (GPU) via Python to extract features from a large corpus of snore sound data. Those features can subsequently be imported into many well-known deep learning training frameworks without any format processing. The snore sound data were collected from several hospitals (20 subjects, with 770–990 MB per subject – in total 17.20 GB). Experimental results show that our GPU-based processing significantly speeds up the feature extraction phase, by up to seven times, as compared to the previous CPU system. © 2017, Springer-Verlag.","Biomedical; Feature extraction; GPU; Python; Signal processing","Algorithms; Humans; Machine Learning; Snoring; Sound; algorithm; human; machine learning; snoring; sound","Springer Science and Business Media Deutschland GmbH","19132751","","","28948531","Article","Scopus","2-s2.0-85036618012"
"Lin Y.; Qian F.; Shen L.; Chen F.; Chen J.; Shen B.","Lin, Yuxin (56152839700); Qian, Fuliang (55659060500); Shen, Li (57206658554); Chen, Feifei (57207166413); Chen, Jiajia (55717760800); Shen, Bairong (7401580760)","56152839700; 55659060500; 57206658554; 57207166413; 55717760800; 7401580760","Computer-aided biomarker discovery for precision medicine: Data resources, models and applications","2017","Briefings in Bioinformatics","62","10.1093/bib/bbx158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068495468&doi=10.1093%2fbib%2fbbx158&partnerID=40&md5=fc2056e66c3293cc1bf517bb709b030c","Center for Systems Biology, Soochow University, Suzhou, Jiangsu, China; School of Chemistry, Biology and Material Engineering, Suzhou University of Science and Technology, China","Lin Y., Center for Systems Biology, Soochow University, Suzhou, Jiangsu, China; Qian F., Center for Systems Biology, Soochow University, Suzhou, Jiangsu, China; Shen L., Center for Systems Biology, Soochow University, Suzhou, Jiangsu, China; Chen F., Center for Systems Biology, Soochow University, Suzhou, Jiangsu, China; Chen J., School of Chemistry, Biology and Material Engineering, Suzhou University of Science and Technology, China; Shen B., Center for Systems Biology, Soochow University, Suzhou, Jiangsu, China","Biomarkers are a class of measurable and evaluable indicators with the potential to predict disease initiation and progression. In contrast to disease-associated factors, biomarkers hold the promise to capture the changeable signatures of biological states. With methodological advances, computer-aided biomarker discovery has now become a burgeoning paradigm in the field of biomedical science. In recent years, the 'big data' term has accumulated for the systematical investigation of complex biological phenomena and promoted the flourishing of computational methods for systems-level biomarker screening. Compared with routine wet-lab experiments, bioinformatics approaches are more efficient to decode disease pathogenesis under a holistic framework, which is propitious to identify biomarkers ranging from single molecules to molecular networks for disease diagnosis, prognosis and therapy. In this review, the concept and characteristics of typical biomarker types, e.g. single molecular biomarkers, module/network biomarkers, cross-level biomarkers, etc., are explicated on the guidance of systems biology. Then, publicly available data resources together with some well-constructed biomarker databases and knowledge bases are introduced. Biomarker identification models using mathematical, network and machine learning theories are sequentially discussed. Based on network substructural and functional evidences, a novel bioinformatics model is particularly highlighted for microRNA biomarker discovery. This article aims to give deep insights into the advantages and challenges of current computational approaches for biomarker detection, and to light up the future wisdom toward precision medicine and nation-wide healthcare. © 2017 The Author 2017. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.","bioinformatics models; databases and knowledge bases; molecular biomarkers; precision medicine; systems biology","Biomarkers; Computer Simulation; Humans; Models, Biological; Precision Medicine; Systems Biology; biological marker; biological model; computer simulation; human; metabolism; personalized medicine; systems biology","Oxford University Press","14675463","","","29194464","Article","Scopus","2-s2.0-85068495468"
"Lee S.; Chang J.-H.","Lee, Soojeong (55878624500); Chang, Joon-Hyuk (34969012900)","55878624500; 34969012900","Deep learning ensemble with asymptotic techniques for oscillometric blood pressure estimation","2017","Computer Methods and Programs in Biomedicine","21","10.1016/j.cmpb.2017.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029183547&doi=10.1016%2fj.cmpb.2017.08.005&partnerID=40&md5=6b959be17086bc7dfbe4a26da1126bd8","School of Electronic Engineering, Hanyang University, 222 Wangsimni-ro, Seongdong, Seoul, 133-791, South Korea","Lee S., School of Electronic Engineering, Hanyang University, 222 Wangsimni-ro, Seongdong, Seoul, 133-791, South Korea; Chang J.-H., School of Electronic Engineering, Hanyang University, 222 Wangsimni-ro, Seongdong, Seoul, 133-791, South Korea","Background and Objective: This paper proposes a deep learning based ensemble regression estimator with asymptotic techniques, and offers a method that can decrease uncertainty for oscillometric blood pressure (BP) measurements using the bootstrap and Monte-Carlo approach. While the former is used to estimate SBP and DBP, the latter attempts to determine confidence intervals (CIs) for SBP and DBP based on oscillometric BP measurements. Method: This work originally employs deep belief networks (DBN)-deep neural networks (DNN) to effectively estimate BPs based on oscillometric measurements. However, there are some inherent problems with these methods. First, it is not easy to determine the best DBN-DNN estimator, and worthy information might be omitted when selecting one DBN-DNN estimator and discarding the others. Additionally, our input feature vectors, obtained from only five measurements per subject, represent a very small sample size; this is a critical weakness when using the DBN-DNN technique and can cause overfitting or underfitting, depending on the structure of the algorithm. To address these problems, an ensemble with an asymptotic approach (based on combining the bootstrap with the DBN-DNN technique) is utilized to generate the pseudo features needed to estimate the SBP and DBP. In the first stage, the bootstrap-aggregation technique is used to create ensemble parameters. Afterward, the AdaBoost approach is employed for the second-stage SBP and DBP estimation. We then use the bootstrap and Monte-Carlo techniques in order to determine the CIs based on the target BP estimated using the DBN-DNN ensemble regression estimator with the asymptotic technique in the third stage. Results: The proposed method can mitigate the estimation uncertainty such as large the standard deviation of error (SDE) on comparing the proposed DBN-DNN ensemble regression estimator with the DBN-DNN single regression estimator, we identify that the SDEs of the SBP and DBP are reduced by 0.58 and 0.57 mmHg, respectively. These indicate that the proposed method actually enhances the performance by 9.18% and 10.88% compared with the DBN-DNN single estimator. Conclusion: The proposed methodology improves the accuracy of BP estimation and reduces the uncertainty for BP estimation. © 2017","Blood pressure; Bootstrap; Confidence interval; Deep neural networks; Oscillometric measurement","Algorithms; Blood Pressure; Blood Pressure Determination; Humans; Machine Learning; Monte Carlo Method; Neural Networks (Computer); Oscillometry; Adaptive boosting; Blood pressure; Deep learning; Financial data processing; Monte Carlo methods; Regression analysis; Statistical methods; Uncertainty analysis; Aggregation techniques; Blood pressure estimation; Bootstrap; Confidence interval; Deep belief network (DBN); Estimation uncertainties; Monte Carlo techniques; Oscillometric measurements; algorithm; Article; back propagation; blood pressure measurement; deep belief network; deep neural network; diastolic blood pressure; human; measurement accuracy; Monte Carlo method; network learning; oscillometry; signal processing; systolic blood pressure; artificial neural network; blood pressure; blood pressure measurement; machine learning; procedures; Deep neural networks","Elsevier Ireland Ltd","01692607","","CMPBE","28946991","Article","Scopus","2-s2.0-85029183547"
"Carneiro G.; Nascimento J.; Bradley A.P.","Carneiro, Gustavo (23003641100); Nascimento, Jacinto (7006833402); Bradley, Andrew P. (7202846882)","23003641100; 7006833402; 7202846882","Automated Analysis of Unregistered Multi-View Mammograms with Deep Learning","2017","IEEE Transactions on Medical Imaging","143","10.1109/TMI.2017.2751523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030260449&doi=10.1109%2fTMI.2017.2751523&partnerID=40&md5=b9038afd21ee5b01dea7427090573746","Australian Centre for Visual Technologies, University of Adelaide, Adelaide, 5005, SA, Australia; Institute for Systems and Robotics, Instituto Superior Técnico, Lisbon, 1049-001, Portugal; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, 4072, QLD, Australia","Carneiro G., Australian Centre for Visual Technologies, University of Adelaide, Adelaide, 5005, SA, Australia; Nascimento J., Institute for Systems and Robotics, Instituto Superior Técnico, Lisbon, 1049-001, Portugal; Bradley A.P., School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, 4072, QLD, Australia","We describe an automated methodology for the analysis of unregistered cranio-caudal (CC) and medio-lateral oblique (MLO) mammography views in order to estimate the patient's risk of developing breast cancer. The main innovation behind this methodology lies in the use of deep learning models for the problem of jointly classifying unregistered mammogram views and respective segmentation maps of breast lesions (i.e., masses and micro-calcifications). This is a holistic methodology that can classify a whole mammographic exam, containing the CC and MLO views and the segmentation maps, as opposed to the classification of individual lesions, which is the dominant approach in the field. We also demonstrate that the proposed system is capable of using the segmentation maps generated by automated mass and micro-calcification detection systems, and still producing accurate results. The semi-automated approach (using manually defined mass and micro-calcification segmentation maps) is tested on two publicly available data sets (INbreast and DDSM), and results show that the volume under ROC surface (VUS) for a 3-class problem (normal tissue, benign, and malignant) is over 0.9, the area under ROC curve (AUC) for the 2-class 'benign versus malignant' problem is over 0.9, and for the 2-class breast screening problem (malignancy versus normal/benign) is also over 0.9. For the fully automated approach, the VUS results on INbreast is over 0.7, and the AUC for the 2-class 'benign versus malignant' problem is over 0.78, and the AUC for the 2-class breast screening is 0.86. © 2012 IEEE.","Deep learning; mammogram; multi-view classification; transfer learning","Breast; Breast Neoplasms; Databases, Factual; Female; Humans; Imaging, Three-Dimensional; Machine Learning; Mammography; Radiographic Image Interpretation, Computer-Assisted; ROC Curve; Automation; Biomineralization; Bone; Calcification (biochemistry); Deep learning; Diseases; Learning systems; Personnel training; Risk assessment; Risk perception; X ray screens; Breast; Cancer; Lesions; Mammogram; Multi-views; Transfer learning; Article; automation; breast calcification; breast cancer; breast lesion; breast tumor; cancer classification; cancer risk; cancer screening; cancer tissue; deep learning; diagnostic accuracy; diagnostic test accuracy study; false negative result; false positive result; high risk patient; human; image segmentation; intermethod comparison; machine learning; mammography; sensitivity and specificity; tumor differentiation; breast; breast tumor; computer assisted diagnosis; diagnostic imaging; factual database; female; mammography; procedures; receiver operating characteristic; three dimensional imaging; Mammography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28920897","Article","Scopus","2-s2.0-85030260449"
"Bejnordi B.E.; Veta M.; Van Diest P.J.; Van Ginneken B.; Karssemeijer N.; Litjens G.; Van Der Laak J.A.W.M.; Hermsen M.; Manson Q.F.; Balkenhol M.; Geessink O.; Stathonikos N.; Van Dijk M.C.R.F.; Bult P.; Beca F.; Beck A.H.; Wang D.; Khosla A.; Gargeya R.; Irshad H.; Zhong A.; Dou Q.; Li Q.; Chen H.; Lin H.-J.; Heng P.-A.; Haß C.; Bruni E.; Wong Q.; Halici U.; Öner M.U.; Cetin-Atalay R.; Berseth M.; Khvatkov V.; Vylegzhanin A.; Kraus O.; Shaban M.; Rajpoot N.; Awan R.; Sirinukunwattana K.; Qaiser T.; Tsang Y.-W.; Tellez D.; Annuscheit J.; Hufnagl P.; Valkonen M.; Kartasalo K.; Latonen L.; Ruusuvuori P.; Liimatainen K.; Albarqouni S.; Mungal B.; George A.; Demirci S.; Navab N.; Watanabe S.; Seno S.; Takenaka Y.; Matsuda H.; Phoulady H.A.; Kovalev V.; Kalinovsky A.; Liauchuk V.; Bueno G.; Fernandez-Carrobles M.M.; Serrano I.; Deniz O.; Racoceanu D.; Venâncio R.","Bejnordi, Babak Ehteshami (56986708300); Veta, Mitko (36519821000); Van Diest, Paul Johannes (7102753018); Van Ginneken, Bram (57202688150); Karssemeijer, Nico (24332021400); Litjens, Geert (36622356600); Van Der Laak, Jeroen A.W.M. (6701833644); Hermsen, Meyke (56694305400); Manson, Quirine F. (57192545288); Balkenhol, Maschenka (57202417370); Geessink, Oscar (57202426232); Stathonikos, Nikolaos (56141412100); Van Dijk, Marcory C.R.F. (7102854214); Bult, Peter (6602193995); Beca, Francisco (23993469500); Beck, Andrew H. (35363449100); Wang, Dayong (58165779800); Khosla, Aditya (36135822500); Gargeya, Rishab (57193736469); Irshad, Humayun (35759027100); Zhong, Aoxiao (57216519277); Dou, Qi (56903795500); Li, Quanzheng (7405862484); Chen, Hao (56493367600); Lin, Huang-Jing (57195683445); Heng, Pheng-Ann (7006677755); Haß, Christian (57199854433); Bruni, Elia (57191862766); Wong, Quincy (57199833978); Halici, Ugur (7003652887); Öner, Mustafa Ümit (57199862583); Cetin-Atalay, Rengul (6602870986); Berseth, Matt (57196222819); Khvatkov, Vitali (22834678900); Vylegzhanin, Alexei (57199859079); Kraus, Oren (56858495300); Shaban, Muhammad (57194123101); Rajpoot, Nasir (8042017200); Awan, Ruqayya (56717587400); Sirinukunwattana, Korsuk (43061431200); Qaiser, Talha (57190982929); Tsang, Yee-Wah (57072889500); Tellez, David (57199848524); Annuscheit, Jonas (57199859027); Hufnagl, Peter (7007182921); Valkonen, Mira (57192938209); Kartasalo, Kimmo (56926765900); Latonen, Leena (7801518847); Ruusuvuori, Pekka (8594550600); Liimatainen, Kaisa (57210133570); Albarqouni, Shadi (55129204800); Mungal, Bharti (57199859837); George, Ami (57199864399); Demirci, Stefanie (57213376774); Navab, Nassir (7003458998); Watanabe, Seiryo (57208550976); Seno, Shigeto (57214748425); Takenaka, Yoichi (57209875876); Matsuda, Hideo (35381793100); Phoulady, Hady Ahmady (56741276100); Kovalev, Vassili (7201852072); Kalinovsky, Alexander (44361280900); Liauchuk, Vitali (57210406541); Bueno, Gloria (7003988757); Fernandez-Carrobles, M. Milagro (55350382400); Serrano, Ismael (57205535899); Deniz, Oscar (8562422200); Racoceanu, Daniel (6603452376); Venâncio, Rui (57199846505)","56986708300; 36519821000; 7102753018; 57202688150; 24332021400; 36622356600; 6701833644; 56694305400; 57192545288; 57202417370; 57202426232; 56141412100; 7102854214; 6602193995; 23993469500; 35363449100; 58165779800; 36135822500; 57193736469; 35759027100; 57216519277; 56903795500; 7405862484; 56493367600; 57195683445; 7006677755; 57199854433; 57191862766; 57199833978; 7003652887; 57199862583; 6602870986; 57196222819; 22834678900; 57199859079; 56858495300; 57194123101; 8042017200; 56717587400; 43061431200; 57190982929; 57072889500; 57199848524; 57199859027; 7007182921; 57192938209; 56926765900; 7801518847; 8594550600; 57210133570; 55129204800; 57199859837; 57199864399; 57213376774; 7003458998; 57208550976; 57214748425; 57209875876; 35381793100; 56741276100; 7201852072; 44361280900; 57210406541; 7003988757; 55350382400; 57205535899; 8562422200; 6603452376; 57199846505","Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer","2017","JAMA - Journal of the American Medical Association","1944","10.1001/jama.2017.14585","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038431889&doi=10.1001%2fjama.2017.14585&partnerID=40&md5=f2f4967d696310fff8c21d34b08905f0","Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Postbus 9101, Nijmegen, 6500HB, Netherlands; Medical Image Analysis Group, Eindhoven University of Technology, Eindhoven, Netherlands; Department of Pathology, University Medical Center Utrecht, Utrecht, Netherlands; Department of Pathology, Radboud University Medical Center, Nijmegen, Netherlands; Pontifical Catholic University of Peru San Miguel, Lima, Peru; Sorbonne University, Pierre, Marie Curie University, Paris, France; Laboratorium Pathologie Oost Nederland, Hengelo, Netherlands; Rijnstate Hospital, Arnhem, Netherlands; BeckLab, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; PathAI, Cambridge, MA, United States; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States; Harker School, San Jose, CA, United States; Center for Clinical Data Science, Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Chinese University of Hong Kong, Hong Kong, Hong Kong; ExB Research and Development GmbH, Munich, Germany; Munich Business School, Munich, Germany; Department of Electrical and Electronics Engineering, Middle East Technical University, Ankara, Turkey; Neuroscience and Neurotechnology, Graduate School of Natural and Applied Sciences, Middle East Technical University, Ankara, Turkey; Cancer System Biology Laboratory, Graduate School of Informatics, Middle East Technical University, Ankara, Turkey; NLP LOGIX, Jacksonville, FL, United States; Smart Imaging Technologies, Houston, TX, United States; Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada; Tissue Image Analytics Lab., Department of Computer Science, University of Warwick, Coventry, United Kingdom; Department of Pathology, University Hospitals Coventry, Warwickshire National Health Service Foundation Trust, Coventry, United Kingdom; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Hochschule für Technik und Wirtschaft, Berlin, Germany; BioMediTech Institute, Faculty of Medicine and Life Sciences, Tampere University of Technology, Tampere, Finland; BioMediTech Institute, Faculty of Biomedical Science and Engineering, Tampere University of Technology, Tampere, Finland; Prostate Cancer Research Center, Faculty of Medicine and Life Sciences and BioMediTech, University of Tampere, Tampere, Finland; Faculty of Computing and Electrical Engineering, Tampere University of Technology, Pori, Finland; Technical University of Munich, Munich, Germany; Department of Bioinformatic Engineering, Osaka University, Japan; University of South Florida, Tampa, FL, United States; Biomedical Image Analysis Department, United Institute of Informatics Problems, Belarus National Academy of Sciences, Minsk, Belarus; Visilab, University of Castilla-La Mancha, Ciudad Real, Spain; INSERM, Laboratoire d'Imagerie Biomédicale, Sorbonne Universiteœ, Pierre and Marie Curie University, Paris, France","Bejnordi B.E., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Postbus 9101, Nijmegen, 6500HB, Netherlands; Veta M., Medical Image Analysis Group, Eindhoven University of Technology, Eindhoven, Netherlands; Van Diest P.J., Department of Pathology, University Medical Center Utrecht, Utrecht, Netherlands; Van Ginneken B., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Postbus 9101, Nijmegen, 6500HB, Netherlands; Karssemeijer N., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Postbus 9101, Nijmegen, 6500HB, Netherlands; Litjens G., Department of Pathology, Radboud University Medical Center, Nijmegen, Netherlands; Van Der Laak J.A.W.M., Department of Pathology, Radboud University Medical Center, Nijmegen, Netherlands; Hermsen M., Department of Pathology, University Medical Center Utrecht, Utrecht, Netherlands, Sorbonne University, Pierre, Marie Curie University, Paris, France; Manson Q.F., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Postbus 9101, Nijmegen, 6500HB, Netherlands; Balkenhol M., Sorbonne University, Pierre, Marie Curie University, Paris, France; Geessink O., Department of Pathology, University Medical Center Utrecht, Utrecht, Netherlands, Sorbonne University, Pierre, Marie Curie University, Paris, France, Laboratorium Pathologie Oost Nederland, Hengelo, Netherlands; Stathonikos N., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Postbus 9101, Nijmegen, 6500HB, Netherlands; Van Dijk M.C.R.F., Rijnstate Hospital, Arnhem, Netherlands; Bult P., Sorbonne University, Pierre, Marie Curie University, Paris, France; Beca F., BeckLab, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Beck A.H., BeckLab, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States, PathAI, Cambridge, MA, United States; Wang D., BeckLab, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States, PathAI, Cambridge, MA, United States; Khosla A., PathAI, Cambridge, MA, United States, Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States; Gargeya R., Harker School, San Jose, CA, United States; Irshad H., BeckLab, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Zhong A., Center for Clinical Data Science, Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Dou Q., Center for Clinical Data Science, Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States, Chinese University of Hong Kong, Hong Kong, Hong Kong; Li Q., Center for Clinical Data Science, Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Chen H., Chinese University of Hong Kong, Hong Kong, Hong Kong; Lin H.-J., Chinese University of Hong Kong, Hong Kong, Hong Kong; Heng P.-A., Chinese University of Hong Kong, Hong Kong, Hong Kong; Haß C., ExB Research and Development GmbH, Munich, Germany; Bruni E., ExB Research and Development GmbH, Munich, Germany; Wong Q., Munich Business School, Munich, Germany; Halici U., Department of Electrical and Electronics Engineering, Middle East Technical University, Ankara, Turkey, Neuroscience and Neurotechnology, Graduate School of Natural and Applied Sciences, Middle East Technical University, Ankara, Turkey; Öner M.U., Department of Electrical and Electronics Engineering, Middle East Technical University, Ankara, Turkey; Cetin-Atalay R., Cancer System Biology Laboratory, Graduate School of Informatics, Middle East Technical University, Ankara, Turkey; Berseth M., NLP LOGIX, Jacksonville, FL, United States; Khvatkov V., Smart Imaging Technologies, Houston, TX, United States; Vylegzhanin A., Smart Imaging Technologies, Houston, TX, United States; Kraus O., Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada; Shaban M., Tissue Image Analytics Lab., Department of Computer Science, University of Warwick, Coventry, United Kingdom; Rajpoot N., Tissue Image Analytics Lab., Department of Computer Science, University of Warwick, Coventry, United Kingdom, Department of Pathology, University Hospitals Coventry, Warwickshire National Health Service Foundation Trust, Coventry, United Kingdom; Awan R., Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Sirinukunwattana K., Tissue Image Analytics Lab., Department of Computer Science, University of Warwick, Coventry, United Kingdom; Qaiser T., Tissue Image Analytics Lab., Department of Computer Science, University of Warwick, Coventry, United Kingdom; Tsang Y.-W., Department of Pathology, University Hospitals Coventry, Warwickshire National Health Service Foundation Trust, Coventry, United Kingdom; Tellez D., Department of Pathology, Radboud University Medical Center, Nijmegen, Netherlands; Annuscheit J., Hochschule für Technik und Wirtschaft, Berlin, Germany; Hufnagl P., Hochschule für Technik und Wirtschaft, Berlin, Germany; Valkonen M., BioMediTech Institute, Faculty of Medicine and Life Sciences, Tampere University of Technology, Tampere, Finland; Kartasalo K., Hochschule für Technik und Wirtschaft, Berlin, Germany, BioMediTech Institute, Faculty of Biomedical Science and Engineering, Tampere University of Technology, Tampere, Finland; Latonen L., Prostate Cancer Research Center, Faculty of Medicine and Life Sciences and BioMediTech, University of Tampere, Tampere, Finland; Ruusuvuori P., Hochschule für Technik und Wirtschaft, Berlin, Germany, Faculty of Computing and Electrical Engineering, Tampere University of Technology, Pori, Finland; Liimatainen K., Hochschule für Technik und Wirtschaft, Berlin, Germany; Albarqouni S., Technical University of Munich, Munich, Germany; Mungal B., Technical University of Munich, Munich, Germany; George A., Technical University of Munich, Munich, Germany; Demirci S., Technical University of Munich, Munich, Germany; Navab N., Technical University of Munich, Munich, Germany; Watanabe S., Department of Bioinformatic Engineering, Osaka University, Japan; Seno S., Department of Bioinformatic Engineering, Osaka University, Japan; Takenaka Y., Department of Bioinformatic Engineering, Osaka University, Japan; Matsuda H., Department of Bioinformatic Engineering, Osaka University, Japan; Phoulady H.A., University of South Florida, Tampa, FL, United States; Kovalev V., Biomedical Image Analysis Department, United Institute of Informatics Problems, Belarus National Academy of Sciences, Minsk, Belarus; Kalinovsky A., Biomedical Image Analysis Department, United Institute of Informatics Problems, Belarus National Academy of Sciences, Minsk, Belarus; Liauchuk V., Biomedical Image Analysis Department, United Institute of Informatics Problems, Belarus National Academy of Sciences, Minsk, Belarus; Bueno G., Visilab, University of Castilla-La Mancha, Ciudad Real, Spain; Fernandez-Carrobles M.M., Visilab, University of Castilla-La Mancha, Ciudad Real, Spain; Serrano I., Visilab, University of Castilla-La Mancha, Ciudad Real, Spain; Deniz O., Visilab, University of Castilla-La Mancha, Ciudad Real, Spain; Racoceanu D., Pontifical Catholic University of Peru San Miguel, Lima, Peru, INSERM, Laboratoire d'Imagerie Biomédicale, Sorbonne Universiteœ, Pierre and Marie Curie University, Paris, France; Venâncio R., Sorbonne University, Pierre, Marie Curie University, Paris, France","IMPORTANCE: Application of deep learning algorithms to whole-slide pathology imagescan potentially improve diagnostic accuracy and efficiency. OBJECTIVE: Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin-stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists' diagnoses in a diagnostic setting. DESIGN, SETTING, AND PARTICIPANTS: Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n = 110) and without (n = 160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC). EXPOSURES: Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation. MAIN OUTCOMES AND MEASURES: The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor. RESULTS: The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4% [95% CI, 64.3%-80.4%]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95% CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884]; P <.001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95% CI, 0.927-0.998] for the pathologist WOTC). CONCLUSIONS AND RELEVANCE: In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting. © 2017 American Medical Association. All rights reserved.","","Algorithms; Breast Neoplasms; Female; Humans; Lymphatic Metastasis; Machine Learning; Pathologists; Pathology, Clinical; ROC Curve; eosin; hematoxylin; Article; automation; breast cancer; cancer classification; cancer diagnosis; diagnostic imaging; diagnostic reasoning; diagnostic test accuracy study; human; immunohistochemistry; learning algorithm; lymph node metastasis; machine learning; Netherlands; pathologist; priority journal; sensitivity and specificity; simulation; algorithm; breast tumor; comparative study; female; lymph node metastasis; pathologist; pathology; receiver operating characteristic","American Medical Association","00987484","","JAMAA","29234806","Article","Scopus","2-s2.0-85038431889"
"Badem H.; Basturk A.; Caliskan A.; Yuksel M.E.","Badem, Hasan (56780136800); Basturk, Alper (6506287432); Caliskan, Abdullah (57193646836); Yuksel, Mehmet Emin (7006176095)","56780136800; 6506287432; 57193646836; 7006176095","A new efficient training strategy for deep neural networks by hybridization of artificial bee colony and limited–memory BFGS optimization algorithms","2017","Neurocomputing","97","10.1016/j.neucom.2017.05.061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020757063&doi=10.1016%2fj.neucom.2017.05.061&partnerID=40&md5=c93b7238718850c36227bad8ea14aa84","Department of Computer Engineering, Erciyes University, Kayseri, Turkey; Department of Biomedical Engineering, Erciyes University, Kayseri, Turkey; Department of Computer Engineering, Kahramanmaras Sutcu Imam University, Kahramanmaras, Turkey","Badem H., Department of Computer Engineering, Erciyes University, Kayseri, Turkey, Department of Computer Engineering, Kahramanmaras Sutcu Imam University, Kahramanmaras, Turkey; Basturk A., Department of Computer Engineering, Erciyes University, Kayseri, Turkey; Caliskan A., Department of Biomedical Engineering, Erciyes University, Kayseri, Turkey; Yuksel M.E., Department of Biomedical Engineering, Erciyes University, Kayseri, Turkey","Working up with deep learning techniques requires profound understanding of the mechanisms underlying the optimization of the internal parameters of complex structures. The major factor limiting this understanding is that there exist only a few optimization methods such as gradient descent and Limited–memory Broyden–Fletcher–Goldfarb–Shannon (L-BFGS) to find the best local minima of the problem space for these complex structures such as deep neural network (DNN). Therefore, in this paper, we represent a new training approach named hybrid artificial bee colony based training strategy (HABCbTS) to tune the parameters of a DNN structure, which includes one or more autoencoder layers cascaded to a softmax classification layer. In this strategy, a derivative-free optimization algorithm “ABC” is combined with a derivative-based algorithm “L-BFGS” to construct “HABC”, which is used in the HABCbTS. Detailed simulation results supported by statistical analysis show that the proposed training strategy results in better classification performance compared to the DNN classifier trained with the L-BFGS, ABC and modified ABC. The obtained classification results are also compared with the state-of-the-art classifiers, including MLP, SVM, KNN, DT and NB on 15 data sets with different dimensions and sizes. © 2017 Elsevier B.V.","Artificial bee colony optimization algorithm; Deep learning; Deep neural network; Hybridization; L-BFGS; Stacked autoencoder network; Training strategy","Classification (of information); Complex networks; Deep learning; Deep neural networks; Learning systems; Artificial bee colony optimization algorithms; Auto encoders; Hybridization; L-BFGS; Training strategy; Article; artificial neural network; Bayesian learning; classification algorithm; classifier; computer simulation; decision tree; deep neural network; human; intermethod comparison; k nearest neighbor; learning algorithm; mathematical computing; perceptron; performance; priority journal; process optimization; statistical analysis; support vector machine; Optimization","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85020757063"
"Wang D.; Zeng S.; Xu C.; Qiu W.; Liang Y.; Joshi T.; Xu D.","Wang, Duolin (57192393574); Zeng, Shuai (57188946534); Xu, Chunhui (55991132200); Qiu, Wangren (36483294800); Liang, Yanchun (55584054800); Joshi, Trupti (34570184300); Xu, Dong (7404074295)","57192393574; 57188946534; 55991132200; 36483294800; 55584054800; 34570184300; 7404074295","MusiteDeep: A deep-learning framework for general and kinase-specific phosphorylation site prediction","2017","Bioinformatics","184","10.1093/bioinformatics/btx496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043988410&doi=10.1093%2fbioinformatics%2fbtx496&partnerID=40&md5=0f8869dc4c264bcde3fbbe3547b6bad5","Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun, 130012, China; Department of Electrical Engineering and Computer Science, Informatics Institute, Christopher S. Bond Life Sciences Center University of Missouri, Columbia, 65211, MO, United States; Computer Department, Jingdezhen Ceramic Institute, Jingdezhen, 333403, China; Department of Computer Science and Technology, Zhuhai College of Jilin University, Zhuhai, 519041, China; Department of Health Management and Informatics, School of Medicine, University of Missouri, Columbia, 65211, MO, United States","Wang D., Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun, 130012, China, Department of Electrical Engineering and Computer Science, Informatics Institute, Christopher S. Bond Life Sciences Center University of Missouri, Columbia, 65211, MO, United States; Zeng S., Department of Electrical Engineering and Computer Science, Informatics Institute, Christopher S. Bond Life Sciences Center University of Missouri, Columbia, 65211, MO, United States; Xu C., Department of Electrical Engineering and Computer Science, Informatics Institute, Christopher S. Bond Life Sciences Center University of Missouri, Columbia, 65211, MO, United States; Qiu W., Department of Electrical Engineering and Computer Science, Informatics Institute, Christopher S. Bond Life Sciences Center University of Missouri, Columbia, 65211, MO, United States, Computer Department, Jingdezhen Ceramic Institute, Jingdezhen, 333403, China; Liang Y., Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun, 130012, China, Department of Computer Science and Technology, Zhuhai College of Jilin University, Zhuhai, 519041, China; Joshi T., Department of Electrical Engineering and Computer Science, Informatics Institute, Christopher S. Bond Life Sciences Center University of Missouri, Columbia, 65211, MO, United States, Department of Health Management and Informatics, School of Medicine, University of Missouri, Columbia, 65211, MO, United States; Xu D., Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun, 130012, China, Department of Electrical Engineering and Computer Science, Informatics Institute, Christopher S. Bond Life Sciences Center University of Missouri, Columbia, 65211, MO, United States","Motivation: Computational methods for phosphorylation site prediction play important roles in protein function studies and experimental design. Most existing methods are based on feature extraction, which may result in incomplete or biased features. Deep learning as the cutting-edge machine learning method has the ability to automatically discover complex representations of phosphorylation patterns from the raw sequences, and hence it provides a powerful tool for improvement of phosphorylation site prediction. Results: We present MusiteDeep, the first deep-learning framework for predicting general and kinase-specific phosphorylation sites. MusiteDeep takes raw sequence data as input and uses convolutional neural networks with a novel two-dimensional attention mechanism. It achieves over a 50% relative improvement in the area under the precision-recall curve in general phosphorylation site prediction and obtains competitive results in kinase-specific prediction compared to other wellknown tools on the benchmark data. © The Author 2017. Published by Oxford University Press. All rights reserved.","","Machine Learning; Neural Networks (Computer); Phosphoproteins; Phosphorylation; Protein Kinases; Proteins; Sequence Analysis, Protein; Software; phosphoprotein; protein; protein kinase; artificial neural network; chemistry; machine learning; metabolism; phosphorylation; procedures; sequence analysis; software","Oxford University Press","13674803","","BOINF","29036382","Article","Scopus","2-s2.0-85043988410"
"Duan L.; Bao M.; Cui S.; Qiao Y.; Miao J.","Duan, Lijuan (22333554700); Bao, Menghu (57192428471); Cui, Song (56978632500); Qiao, Yuanhua (23467846300); Miao, Jun (24721619800)","22333554700; 57192428471; 56978632500; 23467846300; 24721619800","Motor Imagery EEG Classification Based on Kernel Hierarchical Extreme Learning Machine","2017","Cognitive Computation","27","10.1007/s12559-017-9494-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026551213&doi=10.1007%2fs12559-017-9494-0&partnerID=40&md5=2a4faa93bc63e9824bdfee1ccc1f53eb","Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; Beijing Key Laboratory on Integration and Analysis of Large-scale Stream Data, Beijing, China; National Engineering Laboratory for Critical Technologies of Information Security Classified Protection, Beijing, 100124, China; College of Applied Science, Beijing University of Technology, Beijing, 100124, China; Beijing Key Laboratory of Internet Culture and Digital Dissemination Research and School of Computer Science, Beijing Information Science and Technology University, Beijing, 100101, China","Duan L., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, Beijing Key Laboratory on Integration and Analysis of Large-scale Stream Data, Beijing, China; Bao M., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, National Engineering Laboratory for Critical Technologies of Information Security Classified Protection, Beijing, 100124, China; Cui S., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, National Engineering Laboratory for Critical Technologies of Information Security Classified Protection, Beijing, 100124, China; Qiao Y., College of Applied Science, Beijing University of Technology, Beijing, 100124, China; Miao J., Beijing Key Laboratory of Internet Culture and Digital Dissemination Research and School of Computer Science, Beijing Information Science and Technology University, Beijing, 100101, China","As connections from the brain to an external device, Brain-Computer Interface (BCI) systems are a crucial aspect of assisted communication and control. When equipped with well-designed feature extraction and classification approaches, information can be accurately acquired from the brain using such systems. The Hierarchical Extreme Learning Machine (HELM) has been developed as an effective and accurate classification approach due to its deep structure and extreme learning mechanism. A classification system for motor imagery EEG signals is proposed based on the HELM combined with a kernel, herein called the Kernel Hierarchical Extreme Learning Machine (KHELM). Principle Component Analysis (PCA) is used to reduce the dimensionality of the data, and Linear Discriminant Analysis (LDA) is introduced to push the features away from different classes. To demonstrate the performance, the proposed system is applied to the BCI competition 2003 Dataset Ia, and the results are compared with those from state-of-the-art methods; we find that the accuracy is up to 94.54%. © 2017, Springer Science+Business Media, LLC.","Electroencephalogram classification; Extreme learning machine; Hierarchical extreme learning machine; Kerne l-based extreme learning machine; Motor imagery","Brain computer interface; Classification (of information); Computer control systems; Discriminant analysis; Electroencephalography; Interfaces (computer); Knowledge acquisition; Learning systems; Principal component analysis; Communication and control; Extreme learning machine; Feature extraction and classification; Linear discriminant analysis; Motor imagery; Motor imagery eeg signals; Principle component analysis; State-of-the-art methods; Image classification","Springer New York LLC","18669956","","","","Article","Scopus","2-s2.0-85026551213"
"Lu Y.; Yi S.; Zeng N.; Liu Y.; Zhang Y.","Lu, Yang (57192810852); Yi, Shujuan (24451540900); Zeng, Nianyin (36703553900); Liu, Yurong (36062331200); Zhang, Yong (57211359640)","57192810852; 24451540900; 36703553900; 36062331200; 57211359640","Identification of rice diseases using deep convolutional neural networks","2017","Neurocomputing","702","10.1016/j.neucom.2017.06.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021853536&doi=10.1016%2fj.neucom.2017.06.023&partnerID=40&md5=795a293f86605df2cfe256d3a7837492","College of Information Technology, Heilongjiang Bayi Agricultural University, Daqing, 163319, Heilongjiang, China; Fujian Provincial Key Laboratory of Information Processing and Intelligent Control, Minjiang University, Fuzhou, China; Department of Instrumental and Electrical Engineering, Xiamen University, Xiamen, 361005, Fujian, China; Department of Mathematics, Yangzhou University, Yangzhou, 225002, Jiangsu, China; Communications Systems and Networks (CSN) Research Group, Faculty of Engineering, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; College of Electrical Science, Northeast Petroleum University, Daqing, 163318, Heilongjiang, China","Lu Y., College of Information Technology, Heilongjiang Bayi Agricultural University, Daqing, 163319, Heilongjiang, China, Fujian Provincial Key Laboratory of Information Processing and Intelligent Control, Minjiang University, Fuzhou, China; Yi S., College of Information Technology, Heilongjiang Bayi Agricultural University, Daqing, 163319, Heilongjiang, China; Zeng N., Department of Instrumental and Electrical Engineering, Xiamen University, Xiamen, 361005, Fujian, China; Liu Y., Department of Mathematics, Yangzhou University, Yangzhou, 225002, Jiangsu, China, Communications Systems and Networks (CSN) Research Group, Faculty of Engineering, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Zhang Y., College of Electrical Science, Northeast Petroleum University, Daqing, 163318, Heilongjiang, China","The automatic identification and diagnosis of rice diseases are highly desired in the field of agricultural information. Deep learning is a hot research topic in pattern recognition and machine learning at present, it can effectively solve these problems in vegetable pathology. In this study, we propose a novel rice diseases identification method based on deep convolutional neural networks (CNNs) techniques. Using a dataset of 500 natural images of diseased and healthy rice leaves and stems captured from rice experimental field, CNNs are trained to identify 10 common rice diseases. Under the 10-fold cross-validation strategy, the proposed CNNs-based model achieves an accuracy of 95.48%. This accuracy is much higher than conventional machine learning model. The simulation results for the identification of rice diseases show the feasibility and effectiveness of the proposed method. © 2017 Elsevier B.V.","Convolutional neural networks; Deep learning; Identification of rice diseases; Image recognition","Agricultural machinery; Artificial intelligence; Automation; Convolution; Deep neural networks; Diagnosis; Education; Image recognition; Learning systems; Neural networks; Pattern recognition; 10-fold cross-validation; Agricultural informations; Automatic identification; Conventional machines; Convolutional neural network; Hot research topics; Identification method; Natural images; Article; artificial neural network; controlled study; convolutional neural network; machine learning; measurement accuracy; nonhuman; plant disease; plant leaf; plant stem; priority journal; rice; simulation; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85021853536"
"Prevedello L.M.; Erdal B.S.; Ryu J.L.; Little K.J.; Demirer M.; Qian S.; White R.D.","Prevedello, Luciano M. (25641974000); Erdal, Barbaros S. (22033948200); Ryu, John L. (57195369019); Little, Kevin J. (26024330200); Demirer, Mutlu (57195473676); Qian, Songyue (57195480554); White, Richard D. (55481639900)","25641974000; 22033948200; 57195369019; 26024330200; 57195473676; 57195480554; 55481639900","Automated critical test findings identification and online notification system using artificial intelligence in imaging","2017","Radiology","187","10.1148/radiol.2017162664","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034811319&doi=10.1148%2fradiol.2017162664&partnerID=40&md5=562e849b7d0c6738dfd09e705a543e88","Department of Radiology, Ohio State University, Wexner Medical Center, 395 W 12th Ave, Columbus, 43210, OH, United States","Prevedello L.M., Department of Radiology, Ohio State University, Wexner Medical Center, 395 W 12th Ave, Columbus, 43210, OH, United States; Erdal B.S., Department of Radiology, Ohio State University, Wexner Medical Center, 395 W 12th Ave, Columbus, 43210, OH, United States; Ryu J.L., Department of Radiology, Ohio State University, Wexner Medical Center, 395 W 12th Ave, Columbus, 43210, OH, United States; Little K.J., Department of Radiology, Ohio State University, Wexner Medical Center, 395 W 12th Ave, Columbus, 43210, OH, United States; Demirer M., Department of Radiology, Ohio State University, Wexner Medical Center, 395 W 12th Ave, Columbus, 43210, OH, United States; Qian S., Department of Radiology, Ohio State University, Wexner Medical Center, 395 W 12th Ave, Columbus, 43210, OH, United States; White R.D., Department of Radiology, Ohio State University, Wexner Medical Center, 395 W 12th Ave, Columbus, 43210, OH, United States","To evaluate the performance of an artificial intelligence (AI) tool using a deep learning algorithm for detecting hemorrhage, mass effect, or hydrocephalus (HMH) at non-contrast material-enhanced head computed tomographic (CT) examinations and to determine algorithm performance for detection of suspected acute infarct (SAI). Materials and Methods: This HIPAA-compliant retrospective study was completed after institutional review board approval. A training and validation dataset of noncontrast-enhanced head CT examinations that comprised 100 examinations of HMH, 22 of SAI, and 124 of noncritical findings was obtained resulting in 2583 representative images. Examinations were processed by using a convolutional neural network (deep learning) using two different window and level configurations (brain window and stroke window). AI algorithm performance was tested on a separate dataset containing 50 examinations with HMH findings, 15 with SAI findings, and 35 with noncritical findings. Results: Final algorithm performance for HMH showed 90% (45 of 50) sensitivity (95% confidence interval [CI]: 78%, 97%) and 85% (68 of 80) specificity (95% CI: 76%, 92%), with area under the receiver operating characteristic curve (AUC) of 0.91 with the brain window. For SAI, the best performance was achieved with the stroke window showing 62% (13 of 21) sensitivity (95% CI: 38%, 82%) and 96% (27 of 28) specificity (95% CI: 82%, 100%), with AUC of 0.81. Conclusion: AI using deep learning demonstrates promise for detecting critical findings at noncontrast-enhanced head CT. A dedicated algorithm was required to detect SAI. Detection of SAI showed lower sensitivity in comparison to detection of HMH, but showed reasonable performance. Findings support further investigation of the algorithm in a controlled and prospective clinical setting to determine whether it can independently screen noncontrast-enhanced head CT examinations and notify the interpreting radiologist of critical findings. © 2017 RSNA.","","Algorithms; Craniocerebral Trauma; Critical Care; Decision Support Systems, Clinical; Female; Head; Humans; Machine Learning; Male; Medical Order Entry Systems; Middle Aged; Pattern Recognition, Automated; Radiology Information Systems; Reproducibility of Results; Sensitivity and Specificity; Systems Integration; Tomography, X-Ray Computed; adult; Article; artificial intelligence; artificial neural network; autoanalysis; bleeding; computer assisted tomography; contrast enhancement; convolutional neural network; deep learning algorithm; encephalomalacia; female; human; hydrocephalus; learning algorithm; major clinical study; male; online system; priority journal; retrospective study; sensitivity and specificity; algorithm; automated pattern recognition; clinical decision support system; diagnostic imaging; evaluation study; head; head injury; intensive care; machine learning; middle aged; organization and management; physician order entry system; procedures; radiology information system; reproducibility; system analysis; x-ray computed tomography","Radiological Society of North America Inc.","00338419","","RADLA","28678669","Article","Scopus","2-s2.0-85034811319"
"Ciritsis A.; Rossi C.; Wurnig M.C.; Phi Van V.; Boss A.","Ciritsis, Alexander (55751443200); Rossi, Cristina (7202652780); Wurnig, Moritz C. (38962086100); Phi Van, Valerie (57193709180); Boss, Andreas (9737288900)","55751443200; 7202652780; 38962086100; 57193709180; 9737288900","Intravoxel Incoherent Motion: Model-Free Determination of Tissue Type in Abdominal Organs Using Machine Learning","2017","Investigative Radiology","6","10.1097/RLI.0000000000000400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025835237&doi=10.1097%2fRLI.0000000000000400&partnerID=40&md5=84383debd6727fdae095da934653480d","Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Rämistr. 100, Zurich, 8091, Switzerland","Ciritsis A., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Rämistr. 100, Zurich, 8091, Switzerland; Rossi C., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Rämistr. 100, Zurich, 8091, Switzerland; Wurnig M.C., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Rämistr. 100, Zurich, 8091, Switzerland; Phi Van V., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Rämistr. 100, Zurich, 8091, Switzerland; Boss A., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Rämistr. 100, Zurich, 8091, Switzerland","Purpose For diffusion data sets including low and high b-values, the intravoxel incoherent motion model is commonly applied to characterize tissue. The aim of the present study was to show that machine learning allows a model-free approach to determine tissue type without a priori assumptions on the underlying physiology. Materials and Methods In 8 healthy volunteers, diffusion data sets were acquired using an echo-planar imaging sequence with 16 b-values in the range between 0 and 1000 s/mm2. Using the k-nearest neighbors technique, the machine learning algorithm was trained to distinguish abdominal organs (liver, kidney, spleen, muscle) using the signal intensities at different b-values as training features. For systematic variation of model complexity (number of neighbors), performance was assessed by calculation of the accuracy and the kappa coefficient (κ). Most important b-values for tissue discrimination were determined by principal component analysis. Results The optimal trade-off between model complexity and overfitting was found in the range between K = 11 to 13. On ""real-world"" data not previously applied to optimize the algorithm, the k-nearest neighbors algorithm was capable to accurately distinguish tissue types with best accuracy of 94.5% and κ = 0.92 reached for intermediate model complexity (K = 11). The principal component analysis showed that most important b-values are (with decreasing importance): b = 1000 s/mm2, b = 970 s/mm2, b = 750 s/mm2, b = 20 s/mm2, b = 620 s/mm2, and b = 40 s/mm2. Applying a reduced set of 6 most important b-values, still a similar accuracy was achieved on the real-world data set with an average accuracy of 93.7% and a κ coefficient of 0.91. Conclusions Machine learning allows for a model-free determination of tissue type using intra voxel incoherent motion signal decay curves as features. The technique may be useful for segmentation of abdominal organs or distinction between healthy and pathological tissues. © 2017 Wolters Kluwer Health, Inc. All rights reserved.","deep learning; IVIM; machine learning; tissue classification","Abdomen; Adult; Algorithms; Cluster Analysis; Diffusion Magnetic Resonance Imaging; Echo-Planar Imaging; Female; Humans; Image Processing, Computer-Assisted; Kidney; Liver; Machine Learning; Male; Motion; Principal Component Analysis; Reference Values; Reproducibility of Results; Spleen; Young Adult; accuracy; adult; Article; cohort analysis; controlled study; diffusion; female; human; human experiment; kidney parenchyma; learning algorithm; liver parenchyma; machine learning; male; muscle tissue; normal human; nuclear magnetic resonance imaging; priority journal; spleen tissue; training; abdomen; algorithm; anatomy and histology; cluster analysis; diffusion weighted imaging; echo planar imaging; image processing; kidney; liver; motion; principal component analysis; procedures; reference value; reproducibility; spleen; young adult","Lippincott Williams and Wilkins","00209996","","INVRA","28742733","Article","Scopus","2-s2.0-85025835237"
"Weng W.-H.; Wagholikar K.B.; McCray A.T.; Szolovits P.; Chueh H.C.","Weng, Wei-Hung (57198770804); Wagholikar, Kavishwar B. (35786418500); McCray, Alexa T. (35616151100); Szolovits, Peter (6701398669); Chueh, Henry C. (54790533500)","57198770804; 35786418500; 35616151100; 6701398669; 54790533500","Medical subdomain classification of clinical notes using a machine learning-based natural language processing approach","2017","BMC Medical Informatics and Decision Making","97","10.1186/s12911-017-0556-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037036815&doi=10.1186%2fs12911-017-0556-8&partnerID=40&md5=53e4de92e9a6411b6546a86e8ed1da25","Department of Biomedical Informatics, Harvard Medical School, 10 Shattuck Street, Boston, 02115, MA, United States; Laboratory of Computer Science, Massachusetts General Hospital, 50 Staniford Street, Boston, 02114, MA, United States; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, 02139, MA, United States; Department of Medicine, Massachusetts General Hospital, 55 Fruit St, Boston, 02114, MA, United States","Weng W.-H., Department of Biomedical Informatics, Harvard Medical School, 10 Shattuck Street, Boston, 02115, MA, United States, Laboratory of Computer Science, Massachusetts General Hospital, 50 Staniford Street, Boston, 02114, MA, United States, Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, 02139, MA, United States; Wagholikar K.B., Laboratory of Computer Science, Massachusetts General Hospital, 50 Staniford Street, Boston, 02114, MA, United States, Department of Medicine, Massachusetts General Hospital, 55 Fruit St, Boston, 02114, MA, United States; McCray A.T., Department of Biomedical Informatics, Harvard Medical School, 10 Shattuck Street, Boston, 02115, MA, United States; Szolovits P., Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, 02139, MA, United States; Chueh H.C., Laboratory of Computer Science, Massachusetts General Hospital, 50 Staniford Street, Boston, 02114, MA, United States, Department of Medicine, Massachusetts General Hospital, 55 Fruit St, Boston, 02114, MA, United States","Background: The medical subdomain of a clinical note, such as cardiology or neurology, is useful content-derived metadata for developing machine learning downstream applications. To classify the medical subdomain of a note accurately, we have constructed a machine learning-based natural language processing (NLP) pipeline and developed medical subdomain classifiers based on the content of the note. Methods: We constructed the pipeline using the clinical NLP system, clinical Text Analysis and Knowledge Extraction System (cTAKES), the Unified Medical Language System (UMLS) Metathesaurus, Semantic Network, and learning algorithms to extract features from two datasets - clinical notes from Integrating Data for Analysis, Anonymization, and Sharing (iDASH) data repository (n = 431) and Massachusetts General Hospital (MGH) (n = 91,237), and built medical subdomain classifiers with different combinations of data representation methods and supervised learning algorithms. We evaluated the performance of classifiers and their portability across the two datasets. Results: The convolutional recurrent neural network with neural word embeddings trained-medical subdomain classifier yielded the best performance measurement on iDASH and MGH datasets with area under receiver operating characteristic curve (AUC) of 0.975 and 0.991, and F1 scores of 0.845 and 0.870, respectively. Considering better clinical interpretability, linear support vector machine-trained medical subdomain classifier using hybrid bag-of-words and clinically relevant UMLS concepts as the feature representation, with term frequency-inverse document frequency (tf-idf)-weighting, outperformed other shallow learning classifiers on iDASH and MGH datasets with AUC of 0.957 and 0.964, and F1 scores of 0.932 and 0.934 respectively. We trained classifiers on one dataset, applied to the other dataset and yielded the threshold of F1 score of 0.7 in classifiers for half of the medical subdomains we studied. Conclusion: Our study shows that a supervised learning-based NLP approach is useful to develop medical subdomain classifiers. The deep learning algorithm with distributed word representation yields better performance yet shallow learning algorithms with the word and concept representation achieves comparable performance with better clinical interpretability. Portable classifiers may also be used across datasets from different institutions. © 2017 The Author(s).","Deep Learning; Distributed Representation; Machine Learning; Medical Decision Making, Computer-assisted; Natural Language Processing; Unified Medical Language System","Clinical Decision-Making; Humans; Machine Learning; Medical Records; Natural Language Processing; Unified Medical Language System; anonymization; embedding; extraction; general hospital; human; learning algorithm; major clinical study; Massachusetts; medical decision making; natural language processing; nervous system; pipeline; receiver operating characteristic; support vector machine; Unified Medical Language System; clinical decision making; machine learning; medical record","BioMed Central Ltd","14726947","","","29191207","Article","Scopus","2-s2.0-85037036815"
"Gao X.; Duan L.-M.","Gao, Xun (57193201251); Duan, Lu-Ming (7201932853)","57193201251; 7201932853","Efficient representation of quantum many-body states with deep neural networks","2017","Nature Communications","229","10.1038/s41467-017-00705-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029746340&doi=10.1038%2fs41467-017-00705-2&partnerID=40&md5=26a42407b045381c5603fdcb06927dda","Center for Quantum Information, IIIS, Tsinghua University, Beijing, 100084, China; Department of Physics, University of Michigan, Ann Arbor, 48109, MI, United States","Gao X., Center for Quantum Information, IIIS, Tsinghua University, Beijing, 100084, China; Duan L.-M., Center for Quantum Information, IIIS, Tsinghua University, Beijing, 100084, China, Department of Physics, University of Michigan, Ann Arbor, 48109, MI, United States","Part of the challenge for quantum many-body problems comes from the difficulty of representing large-scale quantum states, which in general requires an exponentially large number of parameters. Neural networks provide a powerful tool to represent quantum many-body states. An important open question is what characterizes the representational power of deep and shallow neural networks, which is of fundamental interest due to the popularity of deep learning methods. Here, we give a proof that, assuming a widely believed computational complexity conjecture, a deep neural network can efficiently represent most physical states, including the ground states of many-body Hamiltonians and states generated by quantum dynamics, while a shallow network representation with a restricted Boltzmann machine cannot efficiently represent some of those states. © 2017 The Author(s).","","artificial neural network; complexity; computer simulation; learning; machinery; parameterization; quantum mechanics; machine; nervous system; article; deep neural network; physics","Nature Publishing Group","20411723","","","28939812","Article","Scopus","2-s2.0-85029746340"
"Ben-Cohen A.; Klang E.; Diamant I.; Rozendorn N.; Raskin S.P.; Konen E.; Amitai M.M.; Greenspan H.","Ben-Cohen, Avi (56198986300); Klang, Eyal (56080228800); Diamant, Idit (13409806100); Rozendorn, Noa (56705498800); Raskin, Stephen P. (55389995700); Konen, Eli (6701640190); Amitai, Michal Marianne (6701865585); Greenspan, Hayit (7004965553)","56198986300; 56080228800; 13409806100; 56705498800; 55389995700; 6701640190; 6701865585; 7004965553","CT Image-based Decision Support System for Categorization of Liver Metastases Into Primary Cancer Sites: Initial Results","2017","Academic Radiology","29","10.1016/j.acra.2017.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026551979&doi=10.1016%2fj.acra.2017.06.008&partnerID=40&md5=20e39798a1bce7d4280fc1f2509dd04c","Faculty of Engineering, Department of Biomedical Engineering, Medical Image Processing Laboratory, Tel Aviv University, Haim Levanon 55, Tel Aviv, 69978, Israel; Sheba Medical Center, Diagnostic Imaging Department, Abdominal Imaging Unit, Affiliated to Sackler School of Medicine Tel Aviv University, Tel Hashomer, Israel","Ben-Cohen A., Faculty of Engineering, Department of Biomedical Engineering, Medical Image Processing Laboratory, Tel Aviv University, Haim Levanon 55, Tel Aviv, 69978, Israel; Klang E., Sheba Medical Center, Diagnostic Imaging Department, Abdominal Imaging Unit, Affiliated to Sackler School of Medicine Tel Aviv University, Tel Hashomer, Israel; Diamant I., Faculty of Engineering, Department of Biomedical Engineering, Medical Image Processing Laboratory, Tel Aviv University, Haim Levanon 55, Tel Aviv, 69978, Israel; Rozendorn N., Sheba Medical Center, Diagnostic Imaging Department, Abdominal Imaging Unit, Affiliated to Sackler School of Medicine Tel Aviv University, Tel Hashomer, Israel; Raskin S.P., Sheba Medical Center, Diagnostic Imaging Department, Abdominal Imaging Unit, Affiliated to Sackler School of Medicine Tel Aviv University, Tel Hashomer, Israel; Konen E., Sheba Medical Center, Diagnostic Imaging Department, Abdominal Imaging Unit, Affiliated to Sackler School of Medicine Tel Aviv University, Tel Hashomer, Israel; Amitai M.M., Sheba Medical Center, Diagnostic Imaging Department, Abdominal Imaging Unit, Affiliated to Sackler School of Medicine Tel Aviv University, Tel Hashomer, Israel; Greenspan H., Faculty of Engineering, Department of Biomedical Engineering, Medical Image Processing Laboratory, Tel Aviv University, Haim Levanon 55, Tel Aviv, 69978, Israel","Rationale and Objectives This study aimed to provide decision support for the human expert, to categorize liver metastases into their primary cancer sites. Currently, once a liver metastasis is detected, the process of finding the primary site is challenging, time-consuming, and requires multiple examinations. The proposed system can support the human expert in localizing the search for the cancer source by prioritizing the examinations to probable cancer sites. Materials and Methods The suggested method is a learning-based approach, using computed tomography (CT) data as the input source. Each metastasis is circumscribed by a radiologist in portal phase and in non-contrast CT images. Visual features are computed from these images, combined into feature vectors, and classified using support vector machine classification. A variety of different features were explored and tested. A leave-one-out cross-validation technique was conducted for classification evaluation. The methods were developed on a set of 50 lesion cases taken from 29 patients. Results Experiments were conducted on a separate set of 142 lesion cases taken from 71 patients with four different primary sites. Multiclass categorization results (four classes) achieved low accuracy results. However, the proposed system was found to provide promising results of 83% and 99% for top-2 and top-3 classification tasks, respectively. Moreover, when compared to the experts’ ability to distinguish the different metastases, the system shows improved results. Conclusions Automated systems, such as the one proposed, show promising new results and demonstrate new capabilities that, in the future, will be able to provide decision and treatment support for radiologists and oncologists, toward more efficient detection and treatment of cancer. © 2017 The Association of University Radiologists","CAD; Cancer; CT; deep learning; primary site","Algorithms; Decision Support Techniques; Humans; Image Processing, Computer-Assisted; Liver Neoplasms; Neoplasms, Unknown Primary; Support Vector Machine; Tomography, X-Ray Computed; Article; automation; breast cancer; cancer classification; cancer diagnosis; cancer localization; cancer patient; classification algorithm; clinical decision support system; colorectal cancer; comparative study; controlled study; female; human; liver metastasis; major clinical study; male; melanoma; pancreas cancer; primary tumor; priority journal; radiologist; support vector machine; validation process; workflow; x-ray computed tomography; algorithm; cancer of unknown primary site; decision support system; diagnostic imaging; image processing; liver tumor; secondary","Elsevier USA","10766332","","ARADF","28778512","Article","Scopus","2-s2.0-85026551979"
"Noor S.S.M.; Michael K.; Marshall S.; Ren J.","Noor, Siti Salwa Md (58587638300); Michael, Kaleena (56903788100); Marshall, Stephen (7401823400); Ren, Jinchang (23398632100)","58587638300; 56903788100; 7401823400; 23398632100","Hyperspectral image enhancement and mixture deep-learning classification of corneal epithelium injuries","2017","Sensors (Switzerland)","59","10.3390/s17112644","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034848231&doi=10.3390%2fs17112644&partnerID=40&md5=0befdab3d23c29ffa2566ff91e97be4c","Centre of Excellent Signal and Image Processing, Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, G1 1XW, United Kingdom; Glasgow Centre for Ophthalmic Research, Gartnavel General Hospital, Glasgow, G12 0YN, United Kingdom","Noor S.S.M., Centre of Excellent Signal and Image Processing, Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, G1 1XW, United Kingdom; Michael K., Glasgow Centre for Ophthalmic Research, Gartnavel General Hospital, Glasgow, G12 0YN, United Kingdom; Marshall S., Centre of Excellent Signal and Image Processing, Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, G1 1XW, United Kingdom; Ren J., Centre of Excellent Signal and Image Processing, Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, G1 1XW, United Kingdom","In our preliminary study, the reflectance signatures obtained from hyperspectral imaging (HSI) of normal and abnormal corneal epithelium tissues of porcine show similar morphology with subtle differences. Here we present image enhancement algorithms that can be used to improve the interpretability of data into clinically relevant information to facilitate diagnostics. A total of 25 corneal epithelium images without the application of eye staining were used. Three image feature extraction approaches were applied for image classification: (i) image feature classification from histogram using a support vector machine with a Gaussian radial basis function (SVM-GRBF); (ii) physical image feature classification using deep-learning Convolutional Neural Networks (CNNs) only; and (iii) the combined classification of CNNs and SVM-Linear. The performance results indicate that our chosen image features from the histogram and length-scale parameter were able to classify with up to 100% accuracy; particularly, at CNNs and CNNs-SVM, by employing 80% of the data sample for training and 20% for testing. Thus, in the assessment of corneal epithelium injuries, HSI has high potential as a method that could surpass current technologies regarding speed, objectivity, and reliability. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Corneal epithelium; Hyperspectral imaging; Image enhancement; Support vector machine","Algorithms; Animals; Epithelium, Corneal; Image Enhancement; Neural Networks (Computer); Reproducibility of Results; Swine; Classification (of information); Convolution; Deep learning; Deep neural networks; Graphic methods; Hyperspectral imaging; Image classification; Neural networks; Radial basis function networks; Spectroscopy; Support vector machines; Convolutional neural network; Corneal epithelium; Current technology; Gaussian radial basis functions; Image enhancement algorithm; Image feature extractions; Interpretability; Length scale parameter; algorithm; animal; artificial neural network; cornea epithelium; image enhancement; injuries; pig; reproducibility; Image enhancement","MDPI AG","14248220","","","29144388","Article","Scopus","2-s2.0-85034848231"
"Burlina P.M.; Joshi N.; Pekala M.; Pacheco K.D.; Freund D.E.; Bressler N.M.","Burlina, Philippe M. (6603713214); Joshi, Neil (57193277131); Pekala, Michael (7005118704); Pacheco, Katia D. (56578134400); Freund, David E. (7007157970); Bressler, Neil M. (7005055349)","6603713214; 57193277131; 7005118704; 56578134400; 7007157970; 7005055349","Automated grading of age-related macular degeneration from color fundus images using deep convolutional neural networks","2017","JAMA Ophthalmology","451","10.1001/jamaophthalmol.2017.3782","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034636594&doi=10.1001%2fjamaophthalmol.2017.3782&partnerID=40&md5=95ea75605495cfda20d79f3d4b085913","Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States; Retina Division, Brazilian Center, Vision Eye Hospital, Basilia, DF, Brazil; Retina Division, Wilmer Eye Institute, Johns Hopkins University, School of Medicine, Baltimore, MD, United States","Burlina P.M., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States; Joshi N., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States; Pekala M., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States; Pacheco K.D., Retina Division, Brazilian Center, Vision Eye Hospital, Basilia, DF, Brazil; Freund D.E., Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States; Bressler N.M., Retina Division, Wilmer Eye Institute, Johns Hopkins University, School of Medicine, Baltimore, MD, United States","IMPORTANCE: Age-related macular degeneration (AMD) affects millions of people throughout the world. The intermediate stage may go undetected, as it typically is asymptomatic. However, the preferred practice patterns for AMD recommend identifying individuals with this stage of the disease to educate how to monitor for the early detection of the choroidal neovascular stage before substantial vision loss has occurred and to consider dietary supplements that might reduce the risk of the disease progressing from the intermediate to the advanced stage. Identification, though, can be time-intensive and requires expertly trained individuals. OBJECTIVE: To develop methods for automatically detecting AMD from fundus images using a novel application of deep learning methods to the automated assessment of these images and to leverage artificial intelligence advances. DESIGN, SETTING, AND PARTICIPANTS: Deep convolutional neural networks that are explicitly trained for performing automated AMD grading were compared with an alternate deep learning method that used transfer learning and universal features and with a trained clinical grader. Age-related macular degeneration automated detection was applied to a 2-class classification problem in which the task was to distinguish the disease-free/early stages from the referable intermediate/advanced stages. Using several experiments that entailed different data partitioning, the performance of the machine algorithms and human graders in evaluating more than 130 000 images that were deidentified with respect to age, sex, and race/ethnicity from 4613 patients against a gold standard included in the National Institutes of Health Age-Related Eye Disease Study data set was evaluated. MAIN OUTCOMES AND MEASURES: Accuracy, receiver operating characteristics and area under the curve, and κ score. RESULTS: The deep convolutional neural network method yielded accuracy that ranged between 88.4% (SD, 0.5%) and 91.6% (SD, 0.1%), the area under the receiver operating characteristic curve was between 0.94 and 0.96, and κ (SD) between 0.764 (0.010) and 0.829 (0.003), which indicated a substantial agreement with the gold standard Age-Related Eye Disease Study data set. CONCLUSIONS AND RELEVANCE: Applying a deep learning–based automated assessment of AMD from fundus images can produce results that are similar to human performance levels. This study demonstrates that automated algorithms could play a role that is independent of expert human graders in the current management of AMD and could address the costs of screening or monitoring, access to health care, and the assessment of novel treatments that address the development or progression of AMD. © 2017 American Medical Association. All rights reserved.","","Algorithms; Fundus Oculi; Humans; Machine Learning; Neural Networks (Computer); Reproducibility of Results; ROC Curve; Wet Macular Degeneration; age related macular degeneration; algorithm; Article; artificial neural network; automation; deep convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; diet supplementation; eye fundus; eye photography; gold standard; human; intermethod comparison; major clinical study; predictive value; priority journal; risk reduction; sensitivity and specificity; subretinal neovascularization; visual impairment; algorithm; comparative study; eye fundus; machine learning; receiver operating characteristic; reproducibility; wet macular degeneration","American Medical Association","21686165","","","28973096","Article","Scopus","2-s2.0-85034636594"
"Ma J.; Wu F.; Jiang T.; Zhao Q.; Kong D.","Ma, Jinlian (57191263675); Wu, Fa (55820004700); Jiang, Tian’an (58594845800); Zhao, Qiyu (7402763952); Kong, Dexing (7202350810)","57191263675; 55820004700; 58594845800; 7402763952; 7202350810","Ultrasound image-based thyroid nodule automatic segmentation using convolutional neural networks","2017","International Journal of Computer Assisted Radiology and Surgery","134","10.1007/s11548-017-1649-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026518541&doi=10.1007%2fs11548-017-1649-7&partnerID=40&md5=38aaeaf11ccdfef5c9a98b989ca53389","State Key Lab of CAD&CG, College of Computer Science and Technology, Zhejiang University, Hangzhou, 310027, China; School of Mathematical Sciences, Zhejiang University, Hangzhou, 310027, China; Department of Ultrasound, First Affiliated Hospital, Zhejiang University, Hangzhou, 310003, China","Ma J., State Key Lab of CAD&CG, College of Computer Science and Technology, Zhejiang University, Hangzhou, 310027, China, School of Mathematical Sciences, Zhejiang University, Hangzhou, 310027, China; Wu F., School of Mathematical Sciences, Zhejiang University, Hangzhou, 310027, China; Jiang T., Department of Ultrasound, First Affiliated Hospital, Zhejiang University, Hangzhou, 310003, China; Zhao Q., Department of Ultrasound, First Affiliated Hospital, Zhejiang University, Hangzhou, 310003, China; Kong D., School of Mathematical Sciences, Zhejiang University, Hangzhou, 310027, China","Purpose: Delineation of thyroid nodule boundaries from ultrasound images plays an important role in calculation of clinical indices and diagnosis of thyroid diseases. However, it is challenging for accurate and automatic segmentation of thyroid nodules because of their heterogeneous appearance and components similar to the background. In this study, we employ a deep convolutional neural network (CNN) to automatically segment thyroid nodules from ultrasound images. Methods: Our CNN-based method formulates a thyroid nodule segmentation problem as a patch classification task, where the relationship among patches is ignored. Specifically, the CNN used image patches from images of normal thyroids and thyroid nodules as inputs and then generated the segmentation probability maps as outputs. A multi-view strategy is used to improve the performance of the CNN-based model. Additionally, we compared the performance of our approach with that of the commonly used segmentation methods on the same dataset. Results: The experimental results suggest that our proposed method outperforms prior methods on thyroid nodule segmentation. Moreover, the results show that the CNN-based model is able to delineate multiple nodules in thyroid ultrasound images accurately and effectively. In detail, our CNN-based model can achieve an average of the overlap metric, dice ratio, true positive rate, false positive rate, and modified Hausdorff distance as 0.8683 ± 0.0056 , 0.9224 ± 0.0027 , 0.915 ± 0.0077 , 0.0669 ± 0.0032 , 0.6228 ± 0.1414 on overall folds, respectively. Conclusion: Our proposed method is fully automatic without any user interaction. Quantitative results also indicate that our method is so efficient and accurate that it can be good enough to replace the time-consuming and tedious manual segmentation approach, demonstrating the potential clinical applications. © 2017, CARS.","Convolutional neural network; Segmentation; Thyroid nodule; Ultrasound image","Adult; Aged; Female; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Neural Networks (Computer); Probability; Thyroid Nodule; Ultrasonography; Young Adult; adult; aged; Article; automation; comparative effectiveness; computer assisted diagnosis; controlled study; convolutional neural network; diagnostic accuracy; diagnostic error; diagnostic test accuracy study; echography; experimental study; false positive result; female; human; image analysis; image segmentation; intermethod comparison; machine learning; major clinical study; male; modified hausdorff distance; parameters; predictive value; priority journal; support vector machine; syndrome delineation; thyroid nodule; true positive result; artificial neural network; diagnostic imaging; echography; image processing; middle aged; probability; procedures; thyroid nodule; young adult","Springer Verlag","18616410","","","28762196","Article","Scopus","2-s2.0-85026518541"
"Avendi M.R.; Kheradvar A.; Jafarkhani H.","Avendi, Michael R. (55587727800); Kheradvar, Arash (12806063600); Jafarkhani, Hamid (7004144452)","55587727800; 12806063600; 7004144452","Automatic segmentation of the right ventricle from cardiac MRI using a learning-based approach","2017","Magnetic Resonance in Medicine","108","10.1002/mrm.26631","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013271835&doi=10.1002%2fmrm.26631&partnerID=40&md5=249ab24a0ee366c84d44e4ea657937a7","The Edwards Lifesciences Center for Advanced Cardiovascular Technology, University of California, Irvine, CA, United States; Department Biomedical Engineering, University of California, Irvine, CA, United States; Center for Pervasive Communications and Computing, University of California, Irvine, CA, United States","Avendi M.R., The Edwards Lifesciences Center for Advanced Cardiovascular Technology, University of California, Irvine, CA, United States, Department Biomedical Engineering, University of California, Irvine, CA, United States, Center for Pervasive Communications and Computing, University of California, Irvine, CA, United States; Kheradvar A., The Edwards Lifesciences Center for Advanced Cardiovascular Technology, University of California, Irvine, CA, United States, Department Biomedical Engineering, University of California, Irvine, CA, United States; Jafarkhani H., Center for Pervasive Communications and Computing, University of California, Irvine, CA, United States","Purpose: This study aims to accurately segment the right ventricle (RV) from cardiac MRI using a fully automatic learning-based method. Methods: The proposed method uses deep learning algorithms, i.e., convolutional neural networks and stacked autoencoders, for automatic detection and initial segmentation of the RV chamber. The initial segmentation is then combined with the deformable models to improve the accuracy and robustness of the process. We trained our algorithm using 16 cardiac MRI datasets of the MICCAI 2012 RV Segmentation Challenge database and validated our technique using the rest of the dataset (32 subjects). Results: An average Dice metric of 82.5% along with an average Hausdorff distance of 7.85 mm were achieved for all the studied subjects. Furthermore, a high correlation and level of agreement with the ground truth contours for end-diastolic volume (0.98), end-systolic volume (0.99), and ejection fraction (0.93) were observed. Conclusion: Our results show that deep learning algorithms can be effectively used for automatic segmentation of the RV. Computed quantitative metrics of our method outperformed that of the existing techniques participated in the MICCAI 2012 challenge, as reported by the challenge organizers. Magn Reson Med 78:2439–2448, 2017. © 2017 International Society for Magnetic Resonance in Medicine. © 2017 International Society for Magnetic Resonance in Medicine","cardiac MRI; deep learning; deformable models; right ventricle; segmentation","Algorithms; Automation; Heart; Heart Ventricles; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Models, Statistical; Neural Networks (Computer); Pattern Recognition, Automated; Reproducibility of Results; Convolutional neural networks; Deep learning; Deformation; Heart; Image segmentation; Learning systems; Magnetic resonance; Automatic segmentations; Cardiac MRI; Deformable models; Initial segmentation; International society; Learning-based approach; Quantitative metrics; Right ventricle; cardiovascular magnetic resonance; clinical article; data base; heart ejection fraction; heart left ventricle enddiastolic volume; heart right ventricle; human; learning algorithm; model; nervous system; quantitative study; rest; algorithm; artificial neural network; automated pattern recognition; automation; computer assisted diagnosis; diagnostic imaging; heart; heart ventricle; image processing; machine learning; nuclear magnetic resonance imaging; reproducibility; statistical model; Learning algorithms","John Wiley and Sons Inc","07403194","","MRMEE","28205298","Article","Scopus","2-s2.0-85013271835"
"Kuhner A.; Schubert T.; Cenciarini M.; Wiesmeier I.K.; Coenen V.A.; Burgard W.; Weiller C.; Maurer C.","Kuhner, Andreas (57192427161); Schubert, Tobias (57224869622); Cenciarini, Massimo (13105139200); Wiesmeier, Isabella Katharina (56688558300); Coenen, Volker Arnd (6602721224); Burgard, Wolfram (7003610380); Weiller, Cornelius (7005494787); Maurer, Christoph (7102380530)","57192427161; 57224869622; 13105139200; 56688558300; 6602721224; 7003610380; 7005494787; 7102380530","Correlations between motor symptoms across different motor tasks, quantified via random forest feature classification in Parkinson's disease","2017","Frontiers in Neurology","17","10.3389/fneur.2017.00607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034033767&doi=10.3389%2ffneur.2017.00607&partnerID=40&md5=1508431ff88273d4fec227e2903ba50e","Department of Computer Science, University of Freiburg, Freiburg, Germany; BrainLinks BrainTools, Cluster of Excellence, University of Freiburg, Freiburg, Germany; Department of Neurology and Neuroscience, Medical Center, University of Freiburg, Freiburg, Germany; Medical Faculty, University of Freiburg, Freiburg, Germany; Department of Stereotactic and Functional Neurosurgery, Medical Center, University of Freiburg, Freiburg, Germany","Kuhner A., Department of Computer Science, University of Freiburg, Freiburg, Germany, BrainLinks BrainTools, Cluster of Excellence, University of Freiburg, Freiburg, Germany; Schubert T., Department of Computer Science, University of Freiburg, Freiburg, Germany, BrainLinks BrainTools, Cluster of Excellence, University of Freiburg, Freiburg, Germany; Cenciarini M., BrainLinks BrainTools, Cluster of Excellence, University of Freiburg, Freiburg, Germany, Department of Neurology and Neuroscience, Medical Center, University of Freiburg, Freiburg, Germany, Medical Faculty, University of Freiburg, Freiburg, Germany; Wiesmeier I.K., BrainLinks BrainTools, Cluster of Excellence, University of Freiburg, Freiburg, Germany, Department of Neurology and Neuroscience, Medical Center, University of Freiburg, Freiburg, Germany, Medical Faculty, University of Freiburg, Freiburg, Germany; Coenen V.A., BrainLinks BrainTools, Cluster of Excellence, University of Freiburg, Freiburg, Germany, Medical Faculty, University of Freiburg, Freiburg, Germany, Department of Stereotactic and Functional Neurosurgery, Medical Center, University of Freiburg, Freiburg, Germany; Burgard W., Department of Computer Science, University of Freiburg, Freiburg, Germany, BrainLinks BrainTools, Cluster of Excellence, University of Freiburg, Freiburg, Germany; Weiller C., BrainLinks BrainTools, Cluster of Excellence, University of Freiburg, Freiburg, Germany, Department of Neurology and Neuroscience, Medical Center, University of Freiburg, Freiburg, Germany, Medical Faculty, University of Freiburg, Freiburg, Germany; Maurer C., BrainLinks BrainTools, Cluster of Excellence, University of Freiburg, Freiburg, Germany, Department of Neurology and Neuroscience, Medical Center, University of Freiburg, Freiburg, Germany, Medical Faculty, University of Freiburg, Freiburg, Germany","Background: Objective assessments of Parkinson's disease (PD) patients' motor state using motion capture techniques are still rarely used in clinical practice, even though they may improve clinical management. One major obstacle relates to the large dimensionality of motor abnormalities in PD. We aimed to extract global motor performance measures covering different everyday motor tasks, as a function of a clinical intervention, i.e., deep brain stimulation (DBS) of the subthalamic nucleus. Methods: We followed a data-driven, machine-learning approach and propose performance measures that employ Random Forests with probability distributions. We applied this method to 14 PD patients with DBS switched-off or -on, and 26 healthy control subjects performing the Timed Up and Go Test (TUG), the Functional Reach Test (FRT), a hand coordination task, walking 10-m straight, and a 90° curve. Results: For each motor task, a Random Forest identified a specific set of metrics that optimally separated PD off DBS from healthy subjects. We noted the highest accuracy (94.6%) for standing up. This corresponded to a sensitivity of 91.5% to detect a PD patient off DBS, and a specificity of 97.2% representing the rate of correctly identified healthy subjects. We then calculated performance measures based on these sets of metrics and applied those results to characterize symptom severity in different motor tasks. Task-specific symptom severity measures correlated significantly with each other and with the Unified Parkinson's Disease Rating Scale (UPDRS, part III, correlation of r2 = 0.79). Agreement rates between different measures ranged from 79.8 to 89.3%. Conclusion: The close correlation of PD patients' various motor abnormalities quantified by different, task-specific severity measures suggests that these abnormalities are only facets of the underlying one-dimensional severity of motor deficits. The identification and characterization of this underlying motor deficit may help to optimize therapeutic interventions, e.g., to ""automatically"" adapt DBS settings in PD patients. © 2017 Kuhner, Schubert, Cenciarini, Wiesmeier, Coenen, Burgard, Weiller and Maurer.","Deep brain stimulation; Motion; Parkinson's disease; Random forest; Sensor suit","adult; aged; Article; brain depth stimulation; clinical article; controlled study; disease severity; female; human; male; middle aged; motor coordination; motor dysfunction; motor performance; Parkinson disease; random forest; subthalamic nucleus; task performance; Unified Parkinson Disease Rating Scale; walking","Frontiers Media S.A.","16642295","","","","Article","Scopus","2-s2.0-85034033767"
"Połap D.; Kęsik K.; Książek K.; Wozńiak M.","Połap, Dawid (56407208100); Kęsik, Karolina (57199049410); Książek, Kamil (57192172464); Wozńiak, Marcin (36195020800)","56407208100; 57199049410; 57192172464; 36195020800","Obstacle detection as a safety alert in augmented reality models by the use of deep learning techniques","2017","Sensors (Switzerland)","24","10.3390/s17122803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037524121&doi=10.3390%2fs17122803&partnerID=40&md5=222a4fe2ae9c47cb284b6ddd5dc2ee83","Institute of Mathematics, Silesian University of Technology, Kaszubska 23, Gliwice, 44-100, Poland","Połap D., Institute of Mathematics, Silesian University of Technology, Kaszubska 23, Gliwice, 44-100, Poland; Kęsik K., Institute of Mathematics, Silesian University of Technology, Kaszubska 23, Gliwice, 44-100, Poland; Książek K., Institute of Mathematics, Silesian University of Technology, Kaszubska 23, Gliwice, 44-100, Poland; Wozńiak M., Institute of Mathematics, Silesian University of Technology, Kaszubska 23, Gliwice, 44-100, Poland","Augmented reality (AR) is becoming increasingly popular due to its numerous applications. This is especially evident in games, medicine, education, and other areas that support our everyday activities. Moreover, this kind of computer system not only improves our vision and our perception of the world that surrounds us, but also adds additional elements, modifies existing ones, and gives additional guidance. In this article, we focus on interpreting a reality-based real-time environment evaluation for informing the user about impending obstacles. The proposed solution is based on a hybrid architecture that is capable of estimating as much incoming information as possible. The proposed solution has been tested and discussedwith respect to the advantages and disadvantages of different possibilities using this type of vision. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Augmented reality; Convolutional neural network; Hybrid architecture; Obstacle detection; Spiking neural network","Computer Systems; Machine Learning; User-Computer Interface; Augmented reality; Deep learning; Network architecture; Neural networks; Obstacle detectors; Convolutional neural network; Hybrid architectures; Learning techniques; Obstacle detection; Real-time environment; Safety alerts; Spiking neural networks; computer interface; computer system; machine learning; Education","MDPI AG","14248220","","","29207564","Article","Scopus","2-s2.0-85037524121"
"Turk S.; Merget B.; Rippmann F.; Fulle S.","Turk, Samo (7006016519); Merget, Benjamin (36666935700); Rippmann, Friedrich (55987630600); Fulle, Simone (24341054000)","7006016519; 36666935700; 55987630600; 24341054000","Coupling Matched Molecular Pairs with Machine Learning for Virtual Compound Optimization","2017","Journal of Chemical Information and Modeling","14","10.1021/acs.jcim.7b00298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039981808&doi=10.1021%2facs.jcim.7b00298&partnerID=40&md5=b0bc23165505bfab2f06f5cc61d841e8","BioMed X Innovation Center, Im Neuenheimer Feld 515, Heidelberg, 69120, Germany; Global Computational Chemistry, Merck KGaA, Frankfurter Strasse 250, Darmstadt, 64293, Germany","Turk S., BioMed X Innovation Center, Im Neuenheimer Feld 515, Heidelberg, 69120, Germany; Merget B., BioMed X Innovation Center, Im Neuenheimer Feld 515, Heidelberg, 69120, Germany; Rippmann F., Global Computational Chemistry, Merck KGaA, Frankfurter Strasse 250, Darmstadt, 64293, Germany; Fulle S., BioMed X Innovation Center, Im Neuenheimer Feld 515, Heidelberg, 69120, Germany","Matched molecular pair (MMP) analyses are widely used in compound optimization projects to gain insights into structure-activity relationships (SAR). The analysis is traditionally done via statistical methods but can also be employed together with machine learning (ML) approaches to extrapolate to novel compounds. The here introduced MMP/ML method combines a fragment-based MMP implementation with different machine learning methods to obtain automated SAR decomposition and prediction. To test the prediction capabilities and model transferability, two different compound optimization scenarios were designed: (1) ""new fragments"" which occurs when exploring new fragments for a defined compound series and (2) ""new static core and transformations"" which resembles for instance the identification of a new compound series. Very good results were achieved by all employed machine learning methods especially for the new fragments case, but overall deep neural network models performed best, allowing reliable predictions also for the new static core and transformations scenario, where comprehensive SAR knowledge of the compound series is missing. Furthermore, we show that models trained on all available data have a higher generalizability compared to models trained on focused series and can extend beyond chemical space covered in the training data. Thus, coupling MMP with deep neural networks provides a promising approach to make high quality predictions on various data sets and in different compound optimization scenarios. © 2017 American Chemical Society.","","Computer Simulation; Drug Discovery; Humans; Ligands; Machine Learning; Models, Biological; Structure-Activity Relationship; Deep learning; Deep neural networks; E-learning; Forecasting; Neural networks; Predictive analytics; ligand; Chemical space; Machine learning methods; Model transferabilities; Molecular pairs; Neural network model; Optimization project; Prediction capability; Structure-activity relationships; biological model; computer simulation; drug development; human; machine learning; procedures; structure activity relation; Learning systems","American Chemical Society","15499596","","JCISD","29131617","Article","Scopus","2-s2.0-85039981808"
"Supratak A.; Dong H.; Wu C.; Guo Y.","Supratak, Akara (56461348400); Dong, Hao (56547882800); Wu, Chao (55628577296); Guo, Yike (12765868000)","56461348400; 56547882800; 55628577296; 12765868000","DeepSleepNet: A model for automatic sleep stage scoring based on raw single-channel EEG","2017","IEEE Transactions on Neural Systems and Rehabilitation Engineering","776","10.1109/TNSRE.2017.2721116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023201286&doi=10.1109%2fTNSRE.2017.2721116&partnerID=40&md5=3f2fe85c15af1644dd4f0bfa2cb88d84","Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom","Supratak A., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Dong H., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Wu C., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Guo Y., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom","This paper proposes a deep learning model, named DeepSleepNet, for automatic sleep stage scoring based on raw single-channel EEG. Most of the existing methods rely on hand-engineered features, which require prior knowledge of sleep analysis. Only a few of them encode the temporal information, such as transition rules, which is important for identifying the next sleep stages, into the extracted features. In the proposed model, we utilize convolutional neural networks to extract time-invariant features, and bidirectional-long short-term memory to learn transition rules among sleep stages automatically from EEG epochs. We implement a two-step training algorithm to train our model efficiently. We evaluated our model using different single-channel EEGs (F4-EOG (left), Fpz-Cz, and Pz-Oz) from two public sleep data sets, that have different properties (e.g., sampling rate) and scoring standards (AASM and RK). The results showed that our model achieved similar overall accuracy and macro F1-score (MASS: 86.2%-81.7, Sleep-EDF: 82.0%-76.9) compared with the state-of-the-art methods (MASS: 85.9%-80.5, Sleep-EDF: 78.9%-73.7) on both data sets. This demonstrated that, without changing the model architecture and the training algorithm, our model could automatically learn features for sleep stage scoring from different raw single-channel EEGs from different data sets without utilizing any hand-engineered features. © 2017 IEEE.","Deep learning; Single-channel EEG; Sleep stage scoring","Adult; Algorithms; Automation; Electroencephalography; Female; Healthy Volunteers; Humans; Machine Learning; Male; Memory, Long-Term; Memory, Short-Term; Models, Neurological; Neural Networks (Computer); Polysomnography; Reproducibility of Results; Sleep Stages; Brain models; Convolution; Data mining; Deep learning; Education; Electroencephalography; Electrophysiology; Feature extraction; Long short-term memory; Neural networks; Personnel training; Convolutional neural network; Overall accuracies; Single channel eeg; Sleep; Sleep stage; State-of-the-art methods; Temporal information; Training algorithms; adult; Article; confusion; deepsleepnet; electroencephalography; electromyography; electrooculography; entropy; human; learning algorithm; machine learning; mathematical model; measurement accuracy; nerve cell network; normal human; performance; REM sleep; scoring system; sleep stage; training; algorithm; artificial neural network; automation; biological model; female; long term memory; machine learning; male; physiology; polysomnography; reproducibility; short term memory; sleep stage; Sleep research","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","28678710","Article","Scopus","2-s2.0-85023201286"
"Ibragimov B.; Toesca D.; Chang D.; Koong A.; Xing L.","Ibragimov, Bulat (40761505000); Toesca, Diego (57192543024); Chang, Daniel (9943395500); Koong, Albert (6701338558); Xing, Lei (7103349003)","40761505000; 57192543024; 9943395500; 6701338558; 7103349003","Combining deep learning with anatomical analysis for segmentation of the portal vein for liver SBRT planning","2017","Physics in Medicine and Biology","64","10.1088/1361-6560/aa9262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038208732&doi=10.1088%2f1361-6560%2faa9262&partnerID=40&md5=74bb3dcef18686566e3a699d8a6a2a84","Department of Radiation Oncology, Stanford University School of Medicine, 875 Blake Wilbur Drive, Palo Alto, 94305, CA, United States; Department of Radiation Oncology, University of Texas, MD Anderson Cancer Center, 1220 Holcombe Blvd, Houston, 77030, TX, United States","Ibragimov B., Department of Radiation Oncology, Stanford University School of Medicine, 875 Blake Wilbur Drive, Palo Alto, 94305, CA, United States; Toesca D., Department of Radiation Oncology, Stanford University School of Medicine, 875 Blake Wilbur Drive, Palo Alto, 94305, CA, United States; Chang D., Department of Radiation Oncology, Stanford University School of Medicine, 875 Blake Wilbur Drive, Palo Alto, 94305, CA, United States; Koong A., Department of Radiation Oncology, University of Texas, MD Anderson Cancer Center, 1220 Holcombe Blvd, Houston, 77030, TX, United States; Xing L., Department of Radiation Oncology, Stanford University School of Medicine, 875 Blake Wilbur Drive, Palo Alto, 94305, CA, United States","Automated segmentation of the portal vein (PV) for liver radiotherapy planning is a challenging task due to potentially low vasculature contrast, complex PV anatomy and image artifacts originated from fiducial markers and vasculature stents. In this paper, we propose a novel framework for automated segmentation of the PV from computed tomography (CT) images. We apply convolutional neural networks (CNNs) to learn the consistent appearance patterns of the PV using a training set of CT images with reference annotations and then enhance the PV in previously unseen CT images. Markov random fields (MRFs) were further used to smooth the results of the enhancement of the CNN enhancement and remove isolated mis-segmented regions. Finally, CNN-MRF-based enhancement was augmented with PV centerline detection that relied on PV anatomical properties such as tubularity and branch composition. The framework was validated on a clinical database with 72 CT images of patients scheduled for liver stereotactic body radiation therapy. The obtained accuracy of the segmentation was DSC = 0.83 and η = 1.08 mm in terms of the median Dice coefficient and mean symmetric surface distance, respectively, when segmentation is encompassed into the PV region of interest. The obtained results indicate that CNNs and anatomical analysis can be used for the accurate segmentation of the PV and potentially integrated into liver radiation therapy planning. © 2017 Institute of Physics and Engineering in Medicine.","deep learning; liver cancer; portal vein; radiotherapy planning; SBRT; segmentation","Humans; Image Processing, Computer-Assisted; Liver; Machine Learning; Portal Vein; Radiosurgery; Radiotherapy Planning, Computer-Assisted; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Image enhancement; Liver; Markov processes; Neural networks; Patient treatment; Radiotherapy; Structural frames; Anatomical properties; Automated segmentation; Convolutional neural network; Liver cancers; Portal veins; Radiotherapy planning; SBRT; Stereotactic body radiation therapy; anatomy and histology; diagnostic imaging; hepatic portal vein; human; image processing; liver; machine learning; procedures; radiation response; radiosurgery; radiotherapy planning system; vascularization; x-ray computed tomography; Image segmentation","Institute of Physics Publishing","00319155","","PHMBA","28994665","Article","Scopus","2-s2.0-85038208732"
"Díaz–Vico D.; Torres–Barrán A.; Omari A.; Dorronsoro J.R.","Díaz–Vico, David (57193767602); Torres–Barrán, Alberto (57191253002); Omari, Adil (55791064900); Dorronsoro, José R. (6601985984)","57193767602; 57191253002; 55791064900; 6601985984","Deep Neural Networks for Wind and Solar Energy Prediction","2017","Neural Processing Letters","61","10.1007/s11063-017-9613-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016499775&doi=10.1007%2fs11063-017-9613-7&partnerID=40&md5=ae68d3ddd7c5782059c027cf5ed4c5ca","Departamento de Ingeniería Informática e Instituto de Ingeniería del Conocimiento, Universidad Autónoma de Madrid, Madrid, Spain","Díaz–Vico D., Departamento de Ingeniería Informática e Instituto de Ingeniería del Conocimiento, Universidad Autónoma de Madrid, Madrid, Spain; Torres–Barrán A., Departamento de Ingeniería Informática e Instituto de Ingeniería del Conocimiento, Universidad Autónoma de Madrid, Madrid, Spain; Omari A., Departamento de Ingeniería Informática e Instituto de Ingeniería del Conocimiento, Universidad Autónoma de Madrid, Madrid, Spain; Dorronsoro J.R., Departamento de Ingeniería Informática e Instituto de Ingeniería del Conocimiento, Universidad Autónoma de Madrid, Madrid, Spain","Deep Learning models are recently receiving a large attention because of their very powerful modeling abilities, particularly on inputs that have a intrinsic one- or two-dimensional structure that can be captured and exploited by convolutional layers. In this work we will apply Deep Neural Networks (DNNs) in two problems, wind energy and daily solar radiation prediction, whose inputs, derived from Numerical Weather Prediction systems, have a clear spatial structure. As we shall see, the predictions of single deep models and, more so, of DNN ensembles can improve on those of Support Vector Regression, a Machine Learning method that can be considered the state of the art for regression. © 2017, Springer Science+Business Media New York.","Convolutional neural network; Deep learning; Solar energy; Wind energy","Convolution; Deep learning; Forecasting; Learning systems; Neural networks; Solar energy; Weather forecasting; Wind power; Convolutional neural network; Daily solar radiations; Energy prediction; Machine learning methods; Modeling abilities; Numerical weather prediction; Support vector regression (SVR); Two-dimensional structures; Deep neural networks","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-85016499775"
"Durant T.J.S.; Olson E.M.; Schulz W.L.; Torres R.","Durant, Thomas J.S. (57192252321); Olson, Eben M. (55771094900); Schulz, Wade L. (57002450200); Torres, Richard (7203008478)","57192252321; 55771094900; 57002450200; 7203008478","Very deep convolutional neural networks for morphologic classification of erythrocytes","2017","Clinical Chemistry","34","10.1373/clinchem.2017.276345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036625832&doi=10.1373%2fclinchem.2017.276345&partnerID=40&md5=21cad373b0f30c976d7ebead05c9e4aa","Department of Laboratory Medicine, Yale University School of Medicine, 55 Park St., PS345D, New Haven, 06511, CT, United States","Durant T.J.S., Department of Laboratory Medicine, Yale University School of Medicine, 55 Park St., PS345D, New Haven, 06511, CT, United States; Olson E.M., Department of Laboratory Medicine, Yale University School of Medicine, 55 Park St., PS345D, New Haven, 06511, CT, United States; Schulz W.L., Department of Laboratory Medicine, Yale University School of Medicine, 55 Park St., PS345D, New Haven, 06511, CT, United States; Torres R., Department of Laboratory Medicine, Yale University School of Medicine, 55 Park St., PS345D, New Haven, 06511, CT, United States","Background: Morphologic profiling of the erythrocyte population is a widely used and clinically valuable diagnostic modality, but one that relies on a slow manual process associated with significant labor cost and limited reproducibility. Automated profiling of erythrocytes from digital images by capable machine learning approaches would augment the throughput and value of morphologic analysis. To this end, we sought to evaluate the performance of leading implementation strategies for convolutional neural networks (CNNs) when applied to classification of erythrocytes based on morphology. Methods: Erythrocytes were manually classified into 1 of 10 classes using a custom-developed Web application. Using recent literature to guide architectural considerations for neural network design, we implemented a ""very deep"" CNN, consisting of >150 layers, with dense shortcut connections. Results: The final database comprised 3737 labeled cells. Ensemble model predictions on unseen data demonstrated a harmonic mean of recall and precision metrics of 92.70% and 89.39%, respectively. Of the 748 cells in the test set, 23 misclassification errors were made, with a correct classification frequency of 90.60%, represented as a harmonic mean across the 10 morphologic classes. Conclusions: These findings indicate that erythrocyte morphology profiles could be measured with a high degree of accuracy with ""very deep"" CNNs. Further, these data support future efforts to expand classes and optimize practical performance in a clinical environment as a prelude to full implementation as a clinical tool. © 2017 American Association for Clinical Chemistry.","","Databases, Factual; Erythrocytes; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); classification; error; erythrocyte structure; human; human cell; nervous system; prediction; recall; artificial neural network; cytology; erythrocyte; factual database; image processing; pathology; procedures","American Association for Clinical Chemistry Inc.","00099147","","CLCHA","28877918","Article","Scopus","2-s2.0-85036625832"
"Dreyer K.J.; Raymond Geis J.","Dreyer, Keith J. (7006172475); Raymond Geis, J. (6602850280)","7006172475; 6602850280","When machines think: Radiology's next frontier","2017","Radiology","120","10.1148/radiol.2017171183","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034856540&doi=10.1148%2fradiol.2017171183&partnerID=40&md5=c594a2935c69289cb80f1ff72ca49750","Department of Radiology, Massachusetts General Hospital, Center for Clinical Data Science, Partners Healthcare, Boston, MA, United States; Department of Radiology, University of Colorado, School of Medicine, Aurora, United States","Dreyer K.J., Department of Radiology, Massachusetts General Hospital, Center for Clinical Data Science, Partners Healthcare, Boston, MA, United States; Raymond Geis J., Department of Radiology, University of Colorado, School of Medicine, Aurora, United States","Artificial intelligence (AI), machine learning, and deep learning are terms now seen frequently, all of which refer to computer algorithms that change as they are exposed to more data. Many of these algorithms are surprisingly good at recognizing objects in images. The combination of large amounts of machine-consumable digital data, increased and cheaper computing power, and increasingly sophisticated statistical models combine to enable machines to find patterns in data in ways that are not only cost-effective but also potentially beyond humans' abilities. Building an AI algorithm can be surprisingly easy. Understanding the associated data structures and statistics, on the other hand, is often difficult and obscure. Converting the algorithm into a sophisticated product that works consistently in broad, general clinical use is complex and incompletely understood. To show how these AI products reduce costs and improve outcomes will require clinical translation and industrial-grade integration into routine workflow. Radiology has the chance to leverage AI to become a center of intelligently aggregated, quantitative, diagnostic information. Centaur radiologists, formed as a synergy of human plus computer, will provide interpretations using data extracted from images by humans and image-analysis computer algorithms, as well as the electronic health record, genomics, and other disparate sources. These interpretations will form the foundation of precision health care, or care customized to an individual patient. © 2017 RSNA.","","Algorithms; Decision Support Systems, Clinical; Diagnostic Imaging; Forecasting; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Pattern Recognition, Automated; Radiology; Software; algorithm; Article; artificial intelligence; clinical data repository; deep learning; human; machine learning; personalized medicine; priority journal; radiology; technology; automated pattern recognition; clinical decision support system; computer assisted diagnosis; diagnostic imaging; forecasting; machine learning; procedures; radiology; software; trends","Radiological Society of North America Inc.","00338419","","RADLA","29155639","Article","Scopus","2-s2.0-85034856540"
"Wang Z.; Li L.; Glicksberg B.S.; Israel A.; Dudley J.T.; Ma'ayan A.","Wang, Zichen (55650724200); Li, Li (56370080000); Glicksberg, Benjamin S. (55845627200); Israel, Ariel (26664657200); Dudley, Joel T. (18633685600); Ma'ayan, Avi (57203867894)","55650724200; 56370080000; 55845627200; 26664657200; 18633685600; 57203867894","Predicting age by mining electronic medical records with deep learning characterizes differences between chronological and physiological age","2017","Journal of Biomedical Informatics","24","10.1016/j.jbi.2017.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033378916&doi=10.1016%2fj.jbi.2017.11.003&partnerID=40&md5=65215f3a8a5451e48d38bc42c9ec1561","Department of Pharmacological Sciences, Mount Sinai Center for Bioinformatics, Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, New York, 10029, NY, United States; Department of Genetics and Genomic Sciences, Institute of Next Generation Healthcare, Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, New York, 10029, NY, United States; Department of Family Medicine, Clalit Health Services, Jerusalem, 90258, Israel","Wang Z., Department of Pharmacological Sciences, Mount Sinai Center for Bioinformatics, Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, New York, 10029, NY, United States; Li L., Department of Genetics and Genomic Sciences, Institute of Next Generation Healthcare, Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, New York, 10029, NY, United States; Glicksberg B.S., Department of Genetics and Genomic Sciences, Institute of Next Generation Healthcare, Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, New York, 10029, NY, United States; Israel A., Department of Family Medicine, Clalit Health Services, Jerusalem, 90258, Israel; Dudley J.T., Department of Genetics and Genomic Sciences, Institute of Next Generation Healthcare, Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, New York, 10029, NY, United States; Ma'ayan A., Department of Pharmacological Sciences, Mount Sinai Center for Bioinformatics, Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, New York, 10029, NY, United States","Determining the discrepancy between chronological and physiological age of patients is central to preventative and personalized care. Electronic medical records (EMR) provide rich information about the patient physiological state, but it is unclear whether such information can be predictive of chronological age. Here we present a deep learning model that uses vital signs and lab tests contained within the EMR of Mount Sinai Health System (MSHS) to predict chronological age. The model is trained on 377,686 EMR from patients of ages 18–85 years old. The discrepancy between the predicted and real chronological age is then used as a proxy to estimate physiological age. Overall, the model can predict the chronological age of patients with a standard deviation error of ∼7 years. The ages of the youngest and oldest patients were more accurately predicted, while patients of ages ranging between 40 and 60 years were the least accurately predicted. Patients with the largest discrepancy between their physiological and chronological age were further inspected. The patients predicted to be significantly older than their chronological age have higher systolic blood pressure, higher cholesterol, damaged liver, and anemia. In contrast, patients predicted to be younger than their chronological age have lower blood pressure and shorter stature among other indicators; both groups display lower weight than the population average. Using information from ∼10,000 patients from the entire cohort who have been also profiled with SNP arrays, genome-wide association study (GWAS) uncovers several novel genetic variants associated with aging. In particular, significant variants were mapped to genes known to be associated with inflammation, hypertension, lipid metabolism, height, and increased lifespan in mice. Several genes with missense mutations were identified as novel candidate aging genes. In conclusion, we demonstrate how EMR data can be used to assess overall health via a scale that is based on deviation from the patient's predicted chronological age. © 2017 Elsevier Inc.","Age prediction; Aging; Deep learning; Machine learning; Medical records","Adolescent; Adult; Age Factors; Aged; Aged, 80 and over; Cohort Studies; Data Mining; Electronic Health Records; Female; Genetic Predisposition to Disease; Genome-Wide Association Study; Humans; Learning; Male; Middle Aged; Polymorphism, Single Nucleotide; Young Adult; Aging of materials; Blood pressure; E-learning; Forecasting; Genes; Learning systems; Medical computing; cholesterol; Age predictions; Chronological age; Electronic medical record; Genome-wide association studies; Medical record; Physiological state; Standard deviation; Systolic blood pressure; accuracy; adolescent; age; age determination; aged; anemia; Article; body build; body weight; cholesterol blood level; cohort analysis; electronic medical record; female; gene identification; gene mapping; genetic association; genetic variability; genome-wide association study; human; hypertension; inflammation; laboratory test; lifespan; lipid metabolism; liver injury; male; missense mutation; physiological age; priority journal; single nucleotide polymorphism; systolic blood pressure; very elderly; vital sign; adult; data mining; electronic health record; genetic predisposition; learning; middle aged; young adult; Deep learning","Academic Press Inc.","15320464","","JBIOB","29113935","Article","Scopus","2-s2.0-85033378916"
"Deng L.; Fan C.; Zeng Z.","Deng, Lei (35329533000); Fan, Chao (56288406700); Zeng, Zhiwen (9634861000)","35329533000; 56288406700; 9634861000","A sparse autoencoder-based deep neural network for protein solvent accessibility and contact number prediction","2017","BMC Bioinformatics","17","10.1186/s12859-017-1971-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039746013&doi=10.1186%2fs12859-017-1971-7&partnerID=40&md5=49468300a5a144a7dc87ec7e2bec5c93","Central South University, School of Software, No.22 Shaoshan South Road, Changsha, 410075, China; Central South University, School of Information Science and Engineering, No.932 South Lushan Road, Changsha, 410083, China","Deng L., Central South University, School of Software, No.22 Shaoshan South Road, Changsha, 410075, China; Fan C., Central South University, School of Software, No.22 Shaoshan South Road, Changsha, 410075, China; Zeng Z., Central South University, School of Information Science and Engineering, No.932 South Lushan Road, Changsha, 410083, China","Background: Direct prediction of the three-dimensional (3D) structures of proteins from one-dimensional (1D) sequences is a challenging problem. Significant structural characteristics such as solvent accessibility and contact number are essential for deriving restrains in modeling protein folding and protein 3D structure. Thus, accurately predicting these features is a critical step for 3D protein structure building. Results: In this study, we present DeepSacon, a computational method that can effectively predict protein solvent accessibility and contact number by using a deep neural network, which is built based on stacked autoencoder and a dropout method. The results demonstrate that our proposed DeepSacon achieves a significant improvement in the prediction quality compared with the state-of-the-art methods. We obtain 0.70 three-state accuracy for solvent accessibility, 0.33 15-state accuracy and 0.74 Pearson Correlation Coefficient (PCC) for the contact number on the 5729 monomeric soluble globular protein dataset. We also evaluate the performance on the CASP11 benchmark dataset, DeepSacon achieves 0.68 three-state accuracy and 0.69 PCC for solvent accessibility and contact number, respectively. Conclusions: We have shown that DeepSacon can reliably predict solvent accessibility and contact number with stacked sparse autoencoder and a dropout approach. © 2017 The Author(s).","Contact number; Deep neural network; Sequence-derived features; Solvent accessibility","Algorithms; Machine Learning; Models, Molecular; Neural Networks (Computer); Proteins; Solvents; Benchmarking; Correlation methods; Forecasting; Learning systems; One dimensional; Proteins; Solvents; Transportation; protein; solvent; Derived features; Pearson correlation coefficients; Prediction quality; Protein 3-D structure; Solvent accessibility; State-of-the-art methods; Structural characteristics; Three dimensional (3D) structures; algorithm; artificial neural network; chemistry; machine learning; molecular model; Deep neural networks","BioMed Central Ltd.","14712105","","BBMIC","29297299","Article","Scopus","2-s2.0-85039746013"
"Waris M.A.; Iosifidis A.; Gabbouj M.","Waris, Muhammad Adeel (55925576100); Iosifidis, Alexandros (36720841400); Gabbouj, Moncef (7005332419)","55925576100; 36720841400; 7005332419","CNN-based edge filtering for object proposals","2017","Neurocomputing","17","10.1016/j.neucom.2017.05.071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020766935&doi=10.1016%2fj.neucom.2017.05.071&partnerID=40&md5=262aeaf107452560a5d0b1559d195454","Department of Signal Processing, Tampere University of Technology, P.O. Box 553, Tampere, FIN-33720, Finland; Department of Engineering, Electrical and Computer Engineering, Aarhus University, Denmark","Waris M.A., Department of Signal Processing, Tampere University of Technology, P.O. Box 553, Tampere, FIN-33720, Finland; Iosifidis A., Department of Signal Processing, Tampere University of Technology, P.O. Box 553, Tampere, FIN-33720, Finland, Department of Engineering, Electrical and Computer Engineering, Aarhus University, Denmark; Gabbouj M., Department of Signal Processing, Tampere University of Technology, P.O. Box 553, Tampere, FIN-33720, Finland","Recent advances in image-based object recognition have exploited object proposals to speed up the detection process by reducing the search space. In this paper, we present a novel idea that utilizes true objectness and semantic image filtering (retrieved within the convolutional layers of a Convolutional Neural Network) to propose effective region proposals. Information learned in fully convolutional layers is used to reduce the number of proposals and enhance their localization by producing highly accurate bounding boxes. The greatest benefit of our method is that it can be integrated into any existing approach exploiting edge-based objectness to achieve consistently high recall across various intersection over union thresholds. Experiments on PASCAL VOC 2007 and ImageNet datasets demonstrate that our approach improves two existing state-of-the-art models with significantly high margins and pushes the boundaries of object proposal generation. © 2017 Elsevier B.V.","Deep learning; Neural networks; Object detection; Object proposals; Region of interest","Convolution; Deep learning; Deep neural networks; Image segmentation; Neural networks; Object detection; Optical character recognition; Semantics; Convolutional neural network; Detection process; Highly accurate; Image based object recognition; Object proposals; Region of interest; Semantic images; State of the art; Article; artificial neural network; automated pattern recognition; convolutional neural network; digital filtering; image processing; image quality; measurement accuracy; network learning; priority journal; recall; scale up; semantics; signal detection; support vector machine; Object recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85020766935"
"Cui D.-M.; Yan W.; Wang X.-Q.; Lu L.-M.","Cui, De-Mi (57188633040); Yan, Weizhong (7402221344); Wang, Xiao-Quan (57196296994); Lu, Lie-Min (57196296564)","57188633040; 7402221344; 57196296994; 57196296564","Towards intelligent interpretation of low strain pile integrity testing results using machine learning techniques","2017","Sensors (Switzerland)","14","10.3390/s17112443","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032584430&doi=10.3390%2fs17112443&partnerID=40&md5=1755b975ad1b508aed4e0f07c3fea5b1","Anhui and Huaihe River Institute of Hydraulic Research, No. 771 Zhihuai Road, Bengbu, 233000, China; GE Global Research Center, Niskayuna, 12309, NY, United States","Cui D.-M., Anhui and Huaihe River Institute of Hydraulic Research, No. 771 Zhihuai Road, Bengbu, 233000, China; Yan W., GE Global Research Center, Niskayuna, 12309, NY, United States; Wang X.-Q., Anhui and Huaihe River Institute of Hydraulic Research, No. 771 Zhihuai Road, Bengbu, 233000, China; Lu L.-M., Anhui and Huaihe River Institute of Hydraulic Research, No. 771 Zhihuai Road, Bengbu, 233000, China","Low strain pile integrity testing (LSPIT), due to its simplicity and low cost, is one of the most popular NDE methods used in pile foundation construction. While performing LSPIT in the field is generally quite simple and quick, determining the integrity of the test piles by analyzing and interpreting the test signals (reflectograms) is still a manual process performed by experienced experts only. For foundation construction sites where the number of piles to be tested is large, it may take days before the expert can complete interpreting all of the piles and delivering the integrity assessment report. Techniques that can automate test signal interpretation, thus shortening the LSPIT’s turnaround time, are of great business value and are in great need. Motivated by this need, in this paper, we develop a computer-aided reflectogram interpretation (CARI) methodology that can interpret a large number of LSPIT signals quickly and consistently. The methodology, built on advanced signal processing and machine learning technologies, can be used to assist the experts in performing both qualitative and quantitative interpretation of LSPIT signals. Specifically, the methodology can ease experts’ interpretation burden by screening all test piles quickly and identifying a small number of suspected piles for experts to perform manual, in-depth interpretation. We demonstrate the methodology’s effectiveness using the LSPIT signals collected from a number of real-world pile construction sites. The proposed methodology can potentially enhance LSPIT and make it even more efficient and effective in quality control of deep foundation construction. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Deep foundation; Defect detection; Extreme learning machine; Neural network; Non-destructive evaluation; Pile integrity testing; Wavelet decomposition","Artificial intelligence; Computer aided analysis; Foundations; Learning systems; Neural networks; Nondestructive examination; Quality control; Signal processing; Wavelet decomposition; Deep foundations; Defect detection; Extreme learning machine; Non destructive evaluation; Pile integrity; article; artificial neural network; decomposition; human; quality control; quantitative analysis; signal processing; turnaround time; Piles","MDPI AG","14248220","","","29068431","Article","Scopus","2-s2.0-85032584430"
"Xu Y.; Pei J.; Lai L.","Xu, Youjun (56927067900); Pei, Jianfeng (7103299043); Lai, Luhua (7202615995)","56927067900; 7103299043; 7202615995","Deep Learning Based Regression and Multiclass Models for Acute Oral Toxicity Prediction with Automatic Chemical Feature Extraction","2017","Journal of Chemical Information and Modeling","168","10.1021/acs.jcim.7b00244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035312707&doi=10.1021%2facs.jcim.7b00244&partnerID=40&md5=c5c3a67bc172c538989afe8900020c4c","Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China; Beijing National Laboratory for Molecular Sciences, State Key Laboratory for Structural Chemistry of Unstable and Stable Species, College of Chemistry and Molecular Engineering, Peking University, Beijing, 100871, China; Peking-Tsinghua Center for Life Sciences, Peking University, Beijing, 100871, China","Xu Y., Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China; Pei J., Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China; Lai L., Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing, 100871, China, Beijing National Laboratory for Molecular Sciences, State Key Laboratory for Structural Chemistry of Unstable and Stable Species, College of Chemistry and Molecular Engineering, Peking University, Beijing, 100871, China, Peking-Tsinghua Center for Life Sciences, Peking University, Beijing, 100871, China","Median lethal death, LD50, is a general indicator of compound acute oral toxicity (AOT). Various in silico methods were developed for AOT prediction to reduce costs and time. In this study, we developed an improved molecular graph encoding convolutional neural networks (MGE-CNN) architecture to construct three types of high-quality AOT models: regression model (deepAOT-R), multiclassification model (deepAOT-C), and multitask model (deepAOT-CR). These predictive models highly outperformed previously reported models. For the two external data sets containing 1673 (test set I) and 375 (test set II) compounds, the R2 and mean absolute errors (MAEs) of deepAOT-R on the test set I were 0.864 and 0.195, and the prediction accuracies of deepAOT-C were 95.5% and 96.3% on test sets I and II, respectively. The two external prediction accuracies of deepAOT-CR are 95.0% and 94.1%, while the R2 and MAE are 0.861 and 0.204 for test set I, respectively. We then performed forward and backward exploration of deepAOT models for deep fingerprints, which could support shallow machine learning methods more efficiently than traditional fingerprints or descriptors. We further performed automatic feature learning, a key essence of deep learning, to map the corresponding activation values into fragment space and derive AOT-related chemical substructures by reverse mining of the features. Our deep learning architecture for AOT is generally applicable in predicting and exploring other toxicity or property end points of chemical compounds. The two deepAOT models are freely available at http://repharma.pku.edu.cn/DLAOT/DLAOThome.php or http://www.pkumdl.cn/DLAOT/DLAOThome.php. © 2017 American Chemical Society.","","Administration, Oral; Automation; Informatics; Lethal Dose 50; Machine Learning; Models, Statistical; Regression Analysis; Toxicity Tests; Convolutional neural networks; Forecasting; Learning systems; Network architecture; Predictive analytics; Regression analysis; Testing; Toxicity; Forward-and-backward; Learning architectures; Machine learning methods; Mean absolute error; Multi-class models; Multi-classification; Prediction accuracy; Toxicity predictions; automation; information science; LD50; machine learning; oral drug administration; procedures; regression analysis; statistical model; toxicity testing; Deep learning","American Chemical Society","15499596","","JCISD","29019671","Article","Scopus","2-s2.0-85035312707"
"Hussain S.; Guezennec X.L.; Yi W.; Dong H.; Chia J.; Yiping K.; Khoon L.K.; Bard F.","Hussain, Shaista (57210529218); Guezennec, Xavier Le (57197867201); Yi, Wang (57197875574); Dong, Huang (57197874911); Chia, Joanne (36196208200); Yiping, Ke (57197871409); Khoon, Lee Kee (36995869000); Bard, Frédéric (6701457485)","57210529218; 57197867201; 57197875574; 57197874911; 36196208200; 57197871409; 36995869000; 6701457485","Digging deep into Golgi phenotypic diversity with unsupervised machine learning","2017","Molecular Biology of the Cell","8","10.1091/mbc.E17-06-0379","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035802539&doi=10.1091%2fmbc.E17-06-0379&partnerID=40&md5=8e1159263653802f6f1e569dfdaf76cd","Institute of High Performance Computing, Singapore, 138673, Singapore; Institute of Molecular and Cell Biology, Singapore, 138673, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore, 639798, Singapore","Hussain S., Institute of High Performance Computing, Singapore, 138673, Singapore; Guezennec X.L., Institute of Molecular and Cell Biology, Singapore, 138673, Singapore; Yi W., Institute of High Performance Computing, Singapore, 138673, Singapore; Dong H., Institute of High Performance Computing, Singapore, 138673, Singapore; Chia J., Institute of Molecular and Cell Biology, Singapore, 138673, Singapore; Yiping K., School of Computer Science and Engineering, Nanyang Technological University, Singapore, 639798, Singapore; Khoon L.K., Institute of High Performance Computing, Singapore, 138673, Singapore; Bard F., Institute of Molecular and Cell Biology, Singapore, 138673, Singapore","The synthesis of glycans and the sorting of proteins are critical functions of the Golgi apparatus and depend on its highly complex and compartmentalized architecture. High-content image analysis coupled to RNA interference screening offers opportunities to explore this organelle organization and the gene network underlying it. To date, imagebased Golgi screens have based on a single parameter or supervised analysis with predefined Golgi structural classes. Here, we report the use of multiparametric data extracted from a single marker and a computational unsupervised analysis framework to explore Golgi phenotypic diversity more extensively. In contrast with the three visually definable phenotypes, our framework reproducibly identified 10 Golgi phenotypes. They were used to quantify and stratify phenotypic similarities among genetic perturbations. The derived phenotypic network partially overlaps previously reported protein-protein interactions as well as suggesting novel functional interactions. Our workflow suggests the existence of multiple stable Golgi organizational states and provides a proof of concept for the classification of drugs and genes using fine-grained phenotypic information. © 2017 Hussain, Le Guezennec, et al.","","Golgi Apparatus; HeLa Cells; High-Throughput Screening Assays; Humans; Phenotype; Polysaccharides; Reproducibility of Results; RNA Interference; RNA, Small Interfering; Unsupervised Machine Learning; small interfering RNA; polysaccharide; small interfering RNA; Article; cell population; comparative study; controlled study; female; gene targeting; genetic screening; Golgi complex; human; human cell; mathematical analysis; mathematical computing; penetrance; phenotypic variation; phylogenetic tree; priority journal; protein protein interaction; RNA analysis; RNA interference; unsupervised machine learning; genetics; Golgi complex; HeLa cell line; high throughput screening; metabolism; phenotype; physiology; procedures; reproducibility; RNA interference","American Society for Cell Biology","10591524","","MBCEE","29021342","Article","Scopus","2-s2.0-85035802539"
"Dai H.; Umarov R.; Kuwahara H.; Li Y.; Song L.; Gao X.","Dai, Hanjun (57189099007); Umarov, Ramzan (57193205804); Kuwahara, Hiroyuki (18037502700); Li, Yu (57221627042); Song, Le (58592565000); Gao, Xin (55712115900)","57189099007; 57193205804; 18037502700; 57221627042; 58592565000; 55712115900","Sequence2Vec: A novel embedding approach for modeling transcription factor binding affinity landscape","2017","Bioinformatics","36","10.1093/bioinformatics/btx480","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034451147&doi=10.1093%2fbioinformatics%2fbtx480&partnerID=40&md5=136fadd22c3bd031113cd2df57fe7478","College of Computing, Georgia Institute of Technology, Atlanta, 30332, GA, United States; King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, 23955-6900, Saudi Arabia","Dai H., College of Computing, Georgia Institute of Technology, Atlanta, 30332, GA, United States; Umarov R., King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, 23955-6900, Saudi Arabia; Kuwahara H., King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, 23955-6900, Saudi Arabia; Li Y., King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, 23955-6900, Saudi Arabia; Song L., College of Computing, Georgia Institute of Technology, Atlanta, 30332, GA, United States; Gao X., King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center (CBRC), Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, Thuwal, 23955-6900, Saudi Arabia","Motivation An accurate characterization of transcription factor (TF)-DNA affinity landscape is crucial to a quantitative understanding of the molecular mechanisms underpinning endogenous gene regulation. While recent advances in biotechnology have brought the opportunity for building binding affinity prediction methods, the accurate characterization of TF-DNA binding affinity landscape still remains a challenging problem. Results Here we propose a novel sequence embedding approach for modeling the transcription factor binding affinity landscape. Our method represents DNA binding sequences as a hidden Markov model which captures both position specific information and long-range dependency in the sequence. A cornerstone of our method is a novel message passing-like embedding algorithm, called Sequence2Vec, which maps these hidden Markov models into a common nonlinear feature space and uses these embedded features to build a predictive model. Our method is a novel combination of the strength of probabilistic graphical models, feature space embedding and deep learning. We conducted comprehensive experiments on over 90 large-scale TF-DNA datasets which were measured by different high-throughput experimental technologies. Sequence2Vec outperforms alternative machine learning methods as well as the state-of-the-art binding affinity prediction methods. Availability and implementation Our program is freely available at https://github.com/ramzan1990/sequence2vec. Contact xin.gao@kaust.edu.sa or lsong@cc.gatech.edu. Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author 2017. Published by Oxford University Press.","","Algorithms; Binding Sites; DNA; Machine Learning; Models, Statistical; Protein Binding; Sequence Analysis, DNA; Transcription Factors; DNA; protein binding; transcription factor; algorithm; binding site; chemistry; DNA sequence; machine learning; metabolism; procedures; statistical model","Oxford University Press","13674803","","BOINF","28961686","Article","Scopus","2-s2.0-85034451147"
"Guerguiev J.; Lillicrap T.P.; Richards B.A.","Guerguiev, Jordan (57200336277); Lillicrap, Timothy P. (6503977179); Richards, Blake A. (14626760300)","57200336277; 6503977179; 14626760300","Towards deep learning with segregated dendrites","2017","eLife","232","10.7554/eLife.22901","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040925989&doi=10.7554%2feLife.22901&partnerID=40&md5=d2e75e7cd947a20a0f8f8881d419712b","Department of Biological Sciences, University of Toronto Scarborough, Toronto, Canada; Department of Cell and Systems Biology, University of Toronto, Toronto, Canada; DeepMind, London, United Kingdom; Canadian Institute for Advanced Research, Toronto, Canada","Guerguiev J., Department of Biological Sciences, University of Toronto Scarborough, Toronto, Canada, Department of Cell and Systems Biology, University of Toronto, Toronto, Canada; Lillicrap T.P., DeepMind, London, United Kingdom; Richards B.A., Department of Biological Sciences, University of Toronto Scarborough, Toronto, Canada, Department of Cell and Systems Biology, University of Toronto, Toronto, Canada, Canadian Institute for Advanced Research, Toronto, Canada","Deep learning has led to significant advances in artificial intelligence, in part, by adopting strategies motivated by neurophysiology. However, it is unclear whether deep learning could occur in the real brain. Here, we show that a deep learning algorithm that utilizes multi- compartment neurons might help us to understand how the neocortex optimizes cost functions. Like neocortical pyramidal neurons, neurons in our model receive sensory information and higher- order feedback in electrotonically segregated compartments. Thanks to this segregation, neurons in different layers of the network can coordinate synaptic weight updates. As a result, the network learns to categorize images better than a single layer network. Furthermore, we show that our algorithm takes advantage of multilayer architectures to identify useful higher-order representations—the hallmark of deep learning. This work demonstrates that deep learning can be achieved using segregated dendritic compartments, which may help to explain the morphology of neocortical pyramidal neurons. © Guerguiev et al.","","Artificial Intelligence; Machine Learning; Models, Neurological; Neural Networks (Computer); article; dendrite; human cell; learning algorithm; morphology; neocortex; pyramidal nerve cell; synapse; artificial intelligence; artificial neural network; biological model; machine learning","eLife Sciences Publications Ltd","2050084X","","","29205151","Article","Scopus","2-s2.0-85040925989"
"Sommer C.; Hoefler R.; Samwer M.; Gerlich D.W.","Sommer, Christoph (23089299900); Hoefler, Rudolf (57195487147); Samwer, Matthias (55650760200); Gerlich, Daniel W. (7004150037)","23089299900; 57195487147; 55650760200; 7004150037","A deep learning and novelty detection framework for rapid phenotyping in high-content screening","2017","Molecular Biology of the Cell","65","10.1091/mbc.E17-05-0333","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033496825&doi=10.1091%2fmbc.E17-05-0333&partnerID=40&md5=aab2beb1b110fc35297a32e3158222c4","Institute of Molecular Biotechnology of the Austrian Academy of Sciences (IMBA), Vienna Biocenter (VBC), Vienna, 1030, Austria","Sommer C., Institute of Molecular Biotechnology of the Austrian Academy of Sciences (IMBA), Vienna Biocenter (VBC), Vienna, 1030, Austria; Hoefler R., Institute of Molecular Biotechnology of the Austrian Academy of Sciences (IMBA), Vienna Biocenter (VBC), Vienna, 1030, Austria; Samwer M., Institute of Molecular Biotechnology of the Austrian Academy of Sciences (IMBA), Vienna Biocenter (VBC), Vienna, 1030, Austria; Gerlich D.W., Institute of Molecular Biotechnology of the Austrian Academy of Sciences (IMBA), Vienna Biocenter (VBC), Vienna, 1030, Austria","Supervised machine learning is a powerful and widely used method for analyzing high-content screening data. Despite its accuracy, efficiency, and versatility, supervised machine learning has drawbacks, most notably its dependence on a priori knowledge of expected phenotypes and time-consuming classifier training. We provide a solution to these limitations with CellCognition Explorer, a generic novelty detection and deep learning framework. Application to several large-scale screening data sets on nuclear and mitotic cell morphologies demonstrates that CellCognition Explorer enables discovery of rare phenotypes without user training, which has broad implications for improved assay development in highcontent screening. © 2017 Sommer, Hoefler, et al.","","Algorithms; Animals; Biological Variation, Population; High-Throughput Screening Assays; Humans; Machine Learning; Numerical Analysis, Computer-Assisted; Phenotype; Software; Statistics as Topic; Article; autoanalysis; cell nucleus; cell population; cell screening; cell structure; controlled study; DNA damage; DNA repair; female; HeLa cell line; human; human cell; human genome; machine learning; mitosis; phenotype; priority journal; software; support vector machine; algorithm; animal; biological variation; genetics; high throughput screening; mathematical computing; phenotype; procedures; software; statistics; statistics and numerical data","American Society for Cell Biology","10591524","","MBCEE","28954863","Article","Scopus","2-s2.0-85033496825"
"Korotcov A.; Tkachenko V.; Russo D.P.; Ekins S.","Korotcov, Alexandru (11739705900); Tkachenko, Valery (35775650900); Russo, Daniel P. (57188754026); Ekins, Sean (57203197233)","11739705900; 35775650900; 57188754026; 57203197233","Comparison of Deep Learning with Multiple Machine Learning Methods and Metrics Using Diverse Drug Discovery Data Sets","2017","Molecular Pharmaceutics","240","10.1021/acs.molpharmaceut.7b00578","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037661214&doi=10.1021%2facs.molpharmaceut.7b00578&partnerID=40&md5=f9a122c0dfd9d32e3eb44e64e157444d","Science Data Software, LLC, 14914 Bradwill Court, Rockville, 20850, MD, United States; Collaborations Pharmaceuticals, Inc., 840 Main Campus Drive, Raleigh, 27606, NC, United States; Rutgers Center for Computational and Integrative Biology, Camden, 08102, NJ, United States","Korotcov A., Science Data Software, LLC, 14914 Bradwill Court, Rockville, 20850, MD, United States; Tkachenko V., Science Data Software, LLC, 14914 Bradwill Court, Rockville, 20850, MD, United States; Russo D.P., Collaborations Pharmaceuticals, Inc., 840 Main Campus Drive, Raleigh, 27606, NC, United States, Rutgers Center for Computational and Integrative Biology, Camden, 08102, NJ, United States; Ekins S., Collaborations Pharmaceuticals, Inc., 840 Main Campus Drive, Raleigh, 27606, NC, United States","Machine learning methods have been applied to many data sets in pharmaceutical research for several decades. The relative ease and availability of fingerprint type molecular descriptors paired with Bayesian methods resulted in the widespread use of this approach for a diverse array of end points relevant to drug discovery. Deep learning is the latest machine learning algorithm attracting attention for many of pharmaceutical applications from docking to virtual screening. Deep learning is based on an artificial neural network with multiple hidden layers and has found considerable traction for many artificial intelligence applications. We have previously suggested the need for a comparison of different machine learning methods with deep learning across an array of varying data sets that is applicable to pharmaceutical research. End points relevant to pharmaceutical research include absorption, distribution, metabolism, excretion, and toxicity (ADME/Tox) properties, as well as activity against pathogens and drug discovery data sets. In this study, we have used data sets for solubility, probe-likeness, hERG, KCNQ1, bubonic plague, Chagas, tuberculosis, and malaria to compare different machine learning methods using FCFP6 fingerprints. These data sets represent whole cell screens, individual proteins, physicochemical properties as well as a data set with a complex end point. Our aim was to assess whether deep learning offered any improvement in testing when assessed using an array of metrics including AUC, F1 score, Cohen's kappa, Matthews correlation coefficient and others. Based on ranked normalized scores for the metrics or data sets Deep Neural Networks (DNN) ranked higher than SVM, which in turn was ranked higher than all the other machine learning methods. Visualizing these properties for training and test sets using radar type plots indicates when models are inferior or perhaps over trained. These results also suggest the need for assessing deep learning further using multiple metrics with much larger scale comparisons, prospective testing as well as assessment of different fingerprints and DNN architectures beyond those used. © 2017 American Chemical Society.","deep learning; drug discovery; machine learning; pharmaceutics; support vector machine","Bayes Theorem; Datasets as Topic; Drug Discovery; Machine Learning; Neural Networks (Computer); potassium channel KCNQ1; algorithm; Article; artificial neural network; Bayesian learning; Chagas disease; comparative study; decision tree; drug absorption; drug development; drug distribution; drug excretion; drug metabolism; drug solubility; machine learning; malaria; physical chemistry; plague; priority journal; random forest; support vector machine; tuberculosis; artificial neural network; Bayes theorem; drug development; information processing; procedures","American Chemical Society","15438384","","MPOHB","29096442","Article","Scopus","2-s2.0-85037661214"
"Han Y.; Kim D.","Han, Youngmahn (57213215248); Kim, Dongsup (35248453300)","57213215248; 35248453300","Deep convolutional neural networks for pan-specific peptide-MHC class I binding prediction","2017","BMC Bioinformatics","70","10.1186/s12859-017-1997-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039845147&doi=10.1186%2fs12859-017-1997-x&partnerID=40&md5=0bfb5e3f039326eb9fe546093a53f284","Korea Advanced Institute of Science and Technology, Department of Bio and Brain Engineering, Daejeon, South Korea; Korea Institute of Science and Technology Information, Department of Convergence Technology Research, Daejeon, South Korea","Han Y., Korea Advanced Institute of Science and Technology, Department of Bio and Brain Engineering, Daejeon, South Korea, Korea Institute of Science and Technology Information, Department of Convergence Technology Research, Daejeon, South Korea; Kim D., Korea Advanced Institute of Science and Technology, Department of Bio and Brain Engineering, Daejeon, South Korea","Background: Computational scanning of peptide candidates that bind to a specific major histocompatibility complex (MHC) can speed up the peptide-based vaccine development process and therefore various methods are being actively developed. Recently, machine-learning-based methods have generated successful results by training large amounts of experimental data. However, many machine learning-based methods are generally less sensitive in recognizing locally-clustered interactions, which can synergistically stabilize peptide binding. Deep convolutional neural network (DCNN) is a deep learning method inspired by visual recognition process of animal brain and it is known to be able to capture meaningful local patterns from 2D images. Once the peptide-MHC interactions can be encoded into image-like array(ILA) data, DCNN can be employed to build a predictive model for peptide-MHC binding prediction. In this study, we demonstrated that DCNN is able to not only reliably predict peptide-MHC binding, but also sensitively detect locally-clustered interactions. Results: Nonapeptide-HLA-A and -B binding data were encoded into ILA data. A DCNN, as a pan-specific prediction model, was trained on the ILA data. The DCNN showed higher performance than other prediction tools for the latest benchmark datasets, which consist of 43 datasets for 15 HLA-A alleles and 25 datasets for 10 HLA-B alleles. In particular, the DCNN outperformed other tools for alleles belonging to the HLA-A3 supertype. The F1 scores of the DCNN were 0.86, 0.94, and 0.67 for HLA-A*31:01, HLA-A*03:01, and HLA-A*68:01 alleles, respectively, which were significantly higher than those of other tools. We found that the DCNN was able to recognize locally-clustered interactions that could synergistically stabilize peptide binding. We developed ConvMHC, a web server to provide user-friendly web interfaces for peptide-MHC class I binding predictions using the DCNN. ConvMHC web server can be accessible via http://jumong.kaist.ac.kr:8080/convmhc. Conclusions: We developed a novel method for peptide-HLA-I binding predictions using DCNN trained on ILA data that encode peptide binding data and demonstrated the reliable performance of the DCNN in nonapeptide binding predictions through the independent evaluation on the latest IEDB benchmark datasets. Our approaches can be applied to characterize locally-clustered patterns in molecular interactions, such as protein/DNA, protein/RNA, and drug/protein interactions. © 2017 The Author(s).","Convolutional neural network; Deep learning; Peptide-based vaccine development; Peptide-MHC class I binding prediction; T cell epitope prediction","Alleles; Amino Acid Sequence; Animals; Deep Learning; Histocompatibility Antigens Class I; Humans; Internet; Machine Learning; Peptides; Protein Binding; Reproducibility of Results; Artificial intelligence; Benchmarking; Bins; Convolution; Deep learning; Deep neural networks; Forecasting; Genes; Learning systems; Neural networks; Proteins; T-cells; Vaccines; Web services; HLA antigen class 1; peptide; protein binding; Benchmark datasets; Class I; Convolutional neural network; Major histocompatibility complex; Predictive modeling; Reliable performance; T-cell epitopes; Vaccine development; allele; amino acid sequence; animal; chemistry; human; immunology; Internet; machine learning; metabolism; reproducibility; Peptides","BioMed Central Ltd.","14712105","","BBMIC","29281985","Article","Scopus","2-s2.0-85039845147"
"Liu K.; Zhang R.; Tu W.; Fan L.; Deng Y.; Wang Y.; Li Q.; Xiao Y.; Liu S.","Liu, Kai (56451991900); Zhang, Rongguo (56163990700); Tu, Wenting (57202852701); Fan, Li (56611135400); Deng, Yufeng (57204511799); Wang, Yun (57190742493); Li, Qiong (55633927900); Xiao, Yi (25622657000); Liu, Shiyuan (9232762100)","56451991900; 56163990700; 57202852701; 56611135400; 57204511799; 57190742493; 55633927900; 25622657000; 9232762100","A preliminary investigation on pulmonary subsolid nodule detection using deep learning methods from chest X-rays; [深度学习技术对胸部X线平片亚实性结节的检测效能初探]","2017","Chinese Journal of Radiology (China)","1","10.3760/cma.j.issn.1005-1201.2017.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055885532&doi=10.3760%2fcma.j.issn.1005-1201.2017.12.006&partnerID=40&md5=ba7d85150d716687c32f4cf774e27f56","Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China","Liu K., Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China; Zhang R., Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China; Tu W., Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China; Fan L., Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China; Deng Y., Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China; Wang Y., Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China; Li Q., Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China; Xiao Y., Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China; Liu S., Department of Imaging, Changzheng Hospital, Second Military Medical University, Shanghai, 200003, China","Objective: To evaluate the effectiveness of deep learning methods: to detect subsolid nodules from chest X-ray images. Methods The building, training, and testing of the deep learning model were performed using the research platform developed by Infervision, China. The training dataset consisted of 1 965 chest X-ray images, which contained 85 labeled subsolid nodules and 1 880 solid nodules. Eighty-five subsolid nodules were confirmed by corresponding CT exams. We labeled each X-ray image using the corresponding reconstructed coronal slice from the CT exam as the gold standard, and trained the deep learning model using alternate training. After the training, the model was tested on a different dataset containing 56 subsolid nodules, which were also confirmed by corresponding coronal slices from CT exams. The model results were compared with an experienced radiologist in terms of sensitivity, specificity, and test time. Results: Out of the testing dataset that contained 56 subsolid nodules, the deep learning model marked 72 nodules, which consisted of 39 true positives (TP) and 33 false positives(FP). The model took 17 seconds. The human radiologist marked 39 nodules, with 31 TP and 8 FP. The radiologist took 50 minutes and 24 seconds. Conclusions: Subsolid nodules are prone to mis-diagnosis by human radiologists. The proposed deep learning model was able to effectively identify subsolid nodules from X-ray images. Copyright © 2017 by the Chinese Medical Association.","Chest radiography; Deep learning; Subsolid lung nodule","Article; computer assisted tomography; controlled study; diagnostic error; diagnostic test accuracy study; gold standard; human; lung nodule; machine learning; model; radiologist; sensitivity and specificity; thorax radiography; training","Chinese Medical Association","10051201","","","","Article","Scopus","2-s2.0-85055885532"
"Rachmadi M.F.; Del C. Valdés-Hernández M.; Agan M.L.F.; Komura T.","Rachmadi, Muhammad Febrian (54974181500); Del C. Valdés-Hernández, Maria (55698741100); Agan, Maria Leonora Fatimah (57194784012); Komura, Taku (57203194876)","54974181500; 55698741100; 57194784012; 57203194876","Deep learning vs. conventional machine learning: Pilot study of WMH segmentation in brain MRI with absence or mild vascular pathology","2017","Journal of Imaging","18","10.3390/jimaging3040066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050406708&doi=10.3390%2fjimaging3040066&partnerID=40&md5=264905e9433becd8c63fbea734f448fd","School of Informatics, University of Edinburgh, Edinburgh, EH8 9AB, United Kingdom; Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, EH16 4SB, United Kingdom","Rachmadi M.F., School of Informatics, University of Edinburgh, Edinburgh, EH8 9AB, United Kingdom, Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, EH16 4SB, United Kingdom; Del C. Valdés-Hernández M., Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, EH16 4SB, United Kingdom; Agan M.L.F., Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, EH16 4SB, United Kingdom; Komura T., School of Informatics, University of Edinburgh, Edinburgh, EH8 9AB, United Kingdom","In the wake of the use of deep learning algorithms in medical image analysis, we compared performance of deep learning algorithms, namely the deep Boltzmann machine (DBM), convolutional encoder network (CEN) and patch-wise convolutional neural network (patch-CNN), with two conventional machine learning schemes: Support vector machine (SVM) and random forest (RF), for white matter hyperintensities (WMH) segmentation on brain MRI with mild or no vascular pathology. We also compared all these approaches with a method in the Lesion Segmentation Tool public toolbox named lesion growth algorithm (LGA). We used a dataset comprised of 60 MRI data from 20 subjects in the Alzheimer's Disease Neuroimaging Initiative (ADNI) database, each scanned once every year during three consecutive years. Spatial agreement score, receiver operating characteristic and precision-recall performance curves, volume disagreement score, agreement with intra-/inter-observer reliability measurements and visual evaluation were used to find the best configuration of each learning algorithm for WMH segmentation. By using optimum threshold values for the probabilistic output from each algorithm to produce binary masks of WMH, we found that SVM and RF produced good results for medium to very large WMH burden but deep learning algorithms performed generally better than conventional ones in most evaluations. © 2017 by the authors.","Alzheimer's Disease; Brain MRI; Conventional machine learning; Deep learning; Dementia; Machine learning; Medical image analysis; Segmentation; White matter hyperintensities","Convolution; Decision trees; Deep learning; Image analysis; Image segmentation; Magnetic resonance imaging; Neural networks; Neurodegenerative diseases; Neuroimaging; Pathology; Support vector machines; Alzheimers disease; Brain MRI; Conventional machine learning; Conventional machines; Deep learning; Dementia; Machine-learning; Medical image analysis; Segmentation; White matter hyperintensities; Learning algorithms","MDPI","2313433X","","","","Article","Scopus","2-s2.0-85050406708"
"Almagro Armenteros J.J.; Sønderby C.K.; Sønderby S.K.; Nielsen H.; Winther O.","Almagro Armenteros, José Juan (57197746813); Sønderby, Casper Kaae (56955507900); Sønderby, Søren Kaae (57015250400); Nielsen, Henrik (55506452600); Winther, Ole (6701382702)","57197746813; 56955507900; 57015250400; 55506452600; 6701382702","DeepLoc: prediction of protein subcellular localization using deep learning","2017","Bioinformatics (Oxford, England)","686","10.1093/bioinformatics/btx431","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042325279&doi=10.1093%2fbioinformatics%2fbtx431&partnerID=40&md5=fff4c55d9faba4dc5f4e2af7625bb514","Department of Bio and Health Informatics, Technical University of Denmark, Denmark; Bioinformatics Centre, Department of Biology, University of Copenhagen, Copenhagen N, 2200, Denmark; DTU Compute, Technical University of Denmark, Denmark","Almagro Armenteros J.J., Department of Bio and Health Informatics, Technical University of Denmark, Denmark, Bioinformatics Centre, Department of Biology, University of Copenhagen, Copenhagen N, 2200, Denmark; Sønderby C.K., Bioinformatics Centre, Department of Biology, University of Copenhagen, Copenhagen N, 2200, Denmark; Sønderby S.K., Bioinformatics Centre, Department of Biology, University of Copenhagen, Copenhagen N, 2200, Denmark; Nielsen H., Department of Bio and Health Informatics, Technical University of Denmark, Denmark; Winther O., Bioinformatics Centre, Department of Biology, University of Copenhagen, Copenhagen N, 2200, Denmark, DTU Compute, Technical University of Denmark, Denmark","Motivation: The prediction of eukaryotic protein subcellular localization is a well-studied topic in bioinformatics due to its relevance in proteomics research. Many machine learning methods have been successfully applied in this task, but in most of them, predictions rely on annotation of homologues from knowledge databases. For novel proteins where no annotated homologues exist, and for predicting the effects of sequence variants, it is desirable to have methods for predicting protein properties from sequence information only.; Results: Here, we present a prediction algorithm using deep neural networks to predict protein subcellular localization relying only on sequence information. At its core, the prediction model uses a recurrent neural network that processes the entire protein sequence and an attention mechanism identifying protein regions important for the subcellular localization. The model was trained and tested on a protein dataset extracted from one of the latest UniProt releases, in which experimentally annotated proteins follow more stringent criteria than previously. We demonstrate that our model achieves a good accuracy (78% for 10 categories; 92% for membrane-bound or soluble), outperforming current state-of-the-art algorithms, including those relying on homology information.; Availability and implementation: The method is available as a web server at http://www.cbs.dtu.dk/services/DeepLoc. Example code is available at https://github.com/JJAlmagro/subcellular_localization. The dataset is available at http://www.cbs.dtu.dk/services/DeepLoc/data.php.; Contact: jjalma@dtu.dk. © The Author 2017. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com","","Computational Biology; Eukaryota; Eukaryotic Cells; Machine Learning; Models, Biological; Molecular Sequence Annotation; Neural Networks (Computer); Protein Transport; Sequence Analysis, Protein; Software; artificial neural network; biological model; biology; eukaryote; eukaryotic cell; machine learning; metabolism; molecular genetics; procedures; protein transport; sequence analysis; software","","13674811","","","29036616","Article","Scopus","2-s2.0-85042325279"
"Weigel K.A.; VanRaden P.M.; Norman H.D.; Grosu H.","Weigel, K.A. (57204215827); VanRaden, P.M. (7004667952); Norman, H.D. (55406884800); Grosu, H. (55943767600)","57204215827; 7004667952; 55406884800; 55943767600","A 100-Year Review: Methods and impact of genetic selection in dairy cattle—From daughter–dam comparisons to deep learning algorithms","2017","Journal of Dairy Science","69","10.3168/jds.2017-12954","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034070631&doi=10.3168%2fjds.2017-12954&partnerID=40&md5=d0bec85d5c0f7aa10bba1a39983d19a5","Department of Dairy Science, University of Wisconsin, Madison, 53706, United States; Animal Genomics and Improvement Laboratory, USDA-ARS, Beltsville, 20705, MD, United States; Council on Dairy Cattle Breeding, Bowie, 20716, MD, United States; National Research and Development Institute for Biology and Animal Nutrition, Balotesti, 077015, Romania","Weigel K.A., Department of Dairy Science, University of Wisconsin, Madison, 53706, United States; VanRaden P.M., Animal Genomics and Improvement Laboratory, USDA-ARS, Beltsville, 20705, MD, United States; Norman H.D., Council on Dairy Cattle Breeding, Bowie, 20716, MD, United States; Grosu H., National Research and Development Institute for Biology and Animal Nutrition, Balotesti, 077015, Romania","In the early 1900s, breed society herdbooks had been established and milk-recording programs were in their infancy. Farmers wanted to improve the productivity of their cattle, but the foundations of population genetics, quantitative genetics, and animal breeding had not been laid. Early animal breeders struggled to identify genetically superior families using performance records that were influenced by local environmental conditions and herd-specific management practices. Daughter–dam comparisons were used for more than 30 yr and, although genetic progress was minimal, the attention given to performance recording, genetic theory, and statistical methods paid off in future years. Contemporary (herdmate) comparison methods allowed more accurate accounting for environmental factors and genetic progress began to accelerate when these methods were coupled with artificial insemination and progeny testing. Advances in computing facilitated the implementation of mixed linear models that used pedigree and performance data optimally and enabled accurate selection decisions. Sequencing of the bovine genome led to a revolution in dairy cattle breeding, and the pace of scientific discovery and genetic progress accelerated rapidly. Pedigree-based models have given way to whole-genome prediction, and Bayesian regression models and machine learning algorithms have joined mixed linear models in the toolbox of modern animal breeders. Future developments will likely include elucidation of the mechanisms of genetic inheritance and epigenetic modification in key biological pathways, and genomic data will be used with data from on-farm sensors to facilitate precision management on modern dairy farms. © 2017 American Dairy Science Association","dairy cattle; genetic selection; genomic selection; statistical models","Algorithms; Animals; Breeding; Cattle; Dairying; Female; Machine Learning; Selection, Genetic; algorithm; animal; bovine; breeding; dairying; female; genetic selection; machine learning; procedures","Elsevier Inc.","00220302","","","29153163","Article","Scopus","2-s2.0-85034070631"
"Antoniades A.; Spyrou L.; Martin-Lopez D.; Valentin A.; Alarcon G.; Sanei S.; Took C.C.","Antoniades, Andreas (56401761100); Spyrou, Loukianos (9636747700); Martin-Lopez, David (56112518500); Valentin, Antonio (7005092859); Alarcon, Gonzalo (7101652729); Sanei, Saeid (56212338600); Took, Clive Cheong (56614550100)","56401761100; 9636747700; 56112518500; 7005092859; 7101652729; 56212338600; 56614550100","Detection of interictal discharges with convolutional neural networks using discrete ordered multichannel intracranial EEG","2017","IEEE Transactions on Neural Systems and Rehabilitation Engineering","74","10.1109/TNSRE.2017.2755770","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030673317&doi=10.1109%2fTNSRE.2017.2755770&partnerID=40&md5=3c4b6c06affb2b74963099ec687e0bc9","Department of Computer Science, University of Surrey, Guildford, GU2 7XH, United Kingdom; School of Engineering, University of Edinburgh, Edinburgh, EH9 3FB, United Kingdom; Kingston Hospital NHS FT, London, KT2 7QB, United Kingdom; King’s College London, London, SE5 9RS, United Kingdom; King’s College Hospital, London, SE5 9RS, United Kingdom; King’s College London, London, WC2R 2LS, United Kingdom; Hamad Medical Corporation, Doha, Qatar","Antoniades A., Department of Computer Science, University of Surrey, Guildford, GU2 7XH, United Kingdom; Spyrou L., School of Engineering, University of Edinburgh, Edinburgh, EH9 3FB, United Kingdom; Martin-Lopez D., Kingston Hospital NHS FT, London, KT2 7QB, United Kingdom, King’s College London, London, SE5 9RS, United Kingdom; Valentin A., King’s College Hospital, London, SE5 9RS, United Kingdom, King’s College London, London, WC2R 2LS, United Kingdom; Alarcon G., King’s College London, London, WC2R 2LS, United Kingdom, Hamad Medical Corporation, Doha, Qatar; Sanei S., Department of Computer Science, University of Surrey, Guildford, GU2 7XH, United Kingdom; Took C.C., Department of Computer Science, University of Surrey, Guildford, GU2 7XH, United Kingdom","Detection algorithms for electroencephalography (EEG) data, especially in the field of interictal epileptiform discharge (IED) detection, have traditionally employed handcrafted features, which utilized specific characteristics of neural responses. Although these algorithms achieve high accuracy, mere detection of an IED holds little clinical significance. In this paper, we consider deep learning for epileptic subjects to accommodate automatic feature generation from intracranial EEG data, while also providing clinical insight. Convolutional neural networks are trained in a subject independent fashion to demonstrate how meaningful features are automatically learned in a hierarchical process. We illustrate how the convolved filters in the deepest layers provide insight toward the different types of IEDs within the group, as confirmed by our expert clinicians. The morphology of the IEDs found in filters can help evaluate the treatment of a patient. To improve the learning of the deep model, moderately different score classes are utilized as opposed to binary IED and non-IED labels. The resulting model achieves state-of-the-art classification performance and is also invariant to time differences between the IEDs. This paper suggests that deep learning is suitable for automatic feature generation from intracranial EEG data, while also providing insight into the data. © 2017 IEEE.","Convolutional neural networks; Epilepsy detection; Intracranial EEG; Multi score class learning","Adolescent; Adult; Algorithms; Electrocorticography; Electrodes, Implanted; Epilepsy, Temporal Lobe; Female; Humans; Machine Learning; Male; Neural Networks (Computer); Nonlinear Dynamics; Reproducibility of Results; Seizures; Telemetry; Young Adult; Brain models; Convolution; Deep learning; Electrodes; Electrophysiology; Feature extraction; Learning systems; Neural networks; Patient treatment; Biological neural networks; Convolutional neural network; Epilepsy detection; Intracranial EEG; multi score class learning; accuracy; adolescent; adult; algorithm; Article; artificial neural network; clinical article; electroencephalography; epileptic discharge; female; human; male; scoring system; simulation; spike wave; electrocorticography; electrode implant; machine learning; nonlinear system; pathophysiology; procedures; reproducibility; seizure; telemetry; temporal lobe epilepsy; young adult; Electroencephalography","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","28952945","Article","Scopus","2-s2.0-85030673317"
"Cole J.H.; Poudel R.P.K.; Tsagkrasoulis D.; Caan M.W.A.; Steves C.; Spector T.D.; Montana G.","Cole, James H. (7403376270); Poudel, Rudra P.K. (55247997000); Tsagkrasoulis, Dimosthenis (26656325900); Caan, Matthan W.A. (55908175900); Steves, Claire (6507354480); Spector, Tim D. (35351391300); Montana, Giovanni (23019288000)","7403376270; 55247997000; 26656325900; 55908175900; 6507354480; 35351391300; 23019288000","Predicting brain age with deep learning from raw imaging data results in a reliable and heritable biomarker","2017","NeuroImage","495","10.1016/j.neuroimage.2017.07.059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029673464&doi=10.1016%2fj.neuroimage.2017.07.059&partnerID=40&md5=02424eca162f6a1fbda1fc7deecf8e81","Computational, Cognitive & Clinical Neuroimaging Laboratory, Division of Brain Sciences, Imperial College London, London, United Kingdom; Department of Biomedical Engineering, King's College London, London, United Kingdom; Department of Mathematics, Imperial College London, London, United Kingdom; Department of Radiology, Academic Medical Center, Amsterdam, Netherlands; Department of Twin Research & Genetic Epidemiology, King's College London, London, United Kingdom","Cole J.H., Computational, Cognitive & Clinical Neuroimaging Laboratory, Division of Brain Sciences, Imperial College London, London, United Kingdom; Poudel R.P.K., Department of Biomedical Engineering, King's College London, London, United Kingdom; Tsagkrasoulis D., Department of Mathematics, Imperial College London, London, United Kingdom; Caan M.W.A., Department of Radiology, Academic Medical Center, Amsterdam, Netherlands; Steves C., Department of Twin Research & Genetic Epidemiology, King's College London, London, United Kingdom; Spector T.D., Department of Twin Research & Genetic Epidemiology, King's College London, London, United Kingdom; Montana G., Department of Biomedical Engineering, King's College London, London, United Kingdom, Department of Mathematics, Imperial College London, London, United Kingdom","Machine learning analysis of neuroimaging data can accurately predict chronological age in healthy people. Deviations from healthy brain ageing have been associated with cognitive impairment and disease. Here we sought to further establish the credentials of ‘brain-predicted age’ as a biomarker of individual differences in the brain ageing process, using a predictive modelling approach based on deep learning, and specifically convolutional neural networks (CNN), and applied to both pre-processed and raw T1-weighted MRI data. Firstly, we aimed to demonstrate the accuracy of CNN brain-predicted age using a large dataset of healthy adults (N = 2001). Next, we sought to establish the heritability of brain-predicted age using a sample of monozygotic and dizygotic female twins (N = 62). Thirdly, we examined the test-retest and multi-centre reliability of brain-predicted age using two samples (within-scanner N = 20; between-scanner N = 11). CNN brain-predicted ages were generated and compared to a Gaussian Process Regression (GPR) approach, on all datasets. Input data were grey matter (GM) or white matter (WM) volumetric maps generated by Statistical Parametric Mapping (SPM) or raw data. CNN accurately predicted chronological age using GM (correlation between brain-predicted age and chronological age r = 0.96, mean absolute error [MAE] = 4.16 years) and raw (r = 0.94, MAE = 4.65 years) data. This was comparable to GPR brain-predicted age using GM data (r = 0.95, MAE = 4.66 years). Brain-predicted age was a heritable phenotype for all models and input data (h2 ≥ 0.5). Brain-predicted age showed high test-retest reliability (intraclass correlation coefficient [ICC] = 0.90–0.99). Multi-centre reliability was more variable within high ICCs for GM (0.83–0.96) and poor-moderate levels for WM and raw data (0.51–0.77). Brain-predicted age represents an accurate, highly reliable and genetically-influenced phenotype, that has potential to be used as a biomarker of brain ageing. Moreover, age predictions can be accurately generated on raw T1-MRI data, substantially reducing computation time for novel data, bringing the process closer to giving real-time information on brain health in clinical settings. © 2017","Biomarker; Brain ageing; Convolutional neural networks; Deep learning; Gaussian processes; Heritability; Neuroimaging; Reliability","Adolescent; Adult; Aged; Aged, 80 and over; Aging; Brain; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Middle Aged; Neural Networks (Computer); Phenotype; Young Adult; adult; age determination; aged; aging; Article; artificial neural network; brain; brain aging; convolutional neural network; deep learning; dizygotic twins; female; gray matter; heritability; human; machine learning; male; monozygotic twins; neuroimaging; normal human; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; priority journal; test retest reliability; white matter; adolescent; artificial neural network; brain; diagnostic imaging; image processing; machine learning; middle aged; pathology; phenotype; procedures; very elderly; young adult","Academic Press Inc.","10538119","","NEIME","28765056","Article","Scopus","2-s2.0-85029673464"
"Fan J.; Chow T.","Fan, Jicong (57194228850); Chow, Tommy (55505516700)","57194228850; 55505516700","Deep learning based matrix completion","2017","Neurocomputing","53","10.1016/j.neucom.2017.05.074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020903809&doi=10.1016%2fj.neucom.2017.05.074&partnerID=40&md5=5878a36bf16ed71e6d7ea469534613ea","Department of Electronic Engineering, City University of Hong Kong, Hong Kong SAR, Hong Kong","Fan J., Department of Electronic Engineering, City University of Hong Kong, Hong Kong SAR, Hong Kong; Chow T., Department of Electronic Engineering, City University of Hong Kong, Hong Kong SAR, Hong Kong","Previous matrix completion methods are generally based on linear and shallow models where the given incomplete matrices are of low-rank and the data are assumed to be generated by linear latent variable models. In this paper, we first propose a novel method called AutoEncoder based matrix completion (AEMC). The main idea of AEMC is to utilize the partially observed data to learn and construct a nonlinear latent variable model in the form of AutoEncoder. The hidden layer of the AutoEncoder has much fewer units than the visible layers do. Meanwhile, the unknown entries of the data are recovered to fit the nonlinear latent variable model. Based on AEMC, we further propose a deep learning based matrix completion (DLMC) method. In DLMC, AEMC is used as a pre-training step for both the missing entries and network parameters; the hidden layer of AEMC is then used to learn stacked AutoEncoders (SAEs) with greedy layer-wise training; finally, fine-tuning is carried out on the deep network formed by AEMC and SAEs to obtain the missing entries of the data and the parameters of the network. In addition, we also provide out-of-sample extensions for AEMC and DLMC to recover online incomplete data. AEMC and DLMC are compared with state-of-the-art methods in the tasks of synthetic matrix completion, image inpainting, and collaborative filtering. The experimental results verify the effectiveness and superiority of the proposed methods. © 2017 Elsevier B.V.","AutoEncoder; collaborative filtering; deep learning; image inpainting; Matrix completion; out-of-sample extension","Case based reasoning; Collaborative filtering; Image processing; Matrix algebra; Auto encoders; Image Inpainting; Latent variable modeling; Linear latent variables; Matrix completion; Network parameters; Out-of-sample extension; State-of-the-art methods; Article; artificial neural network; autoencoder based matrix completion; deep learning based matrix completion; digital filtering; image enhancement; information processing; information processing device; machine learning; priority journal; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85020903809"
"Murad A.; Pyun J.-Y.","Murad, Abdulmajid (57196452518); Pyun, Jae-Young (7003538614)","57196452518; 7003538614","Deep recurrent neural networks for human activity recognition","2017","Sensors (Switzerland)","343","10.3390/s17112556","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033394959&doi=10.3390%2fs17112556&partnerID=40&md5=e2720019d8a931a74ebb5f818f671c2a","Department of Information Communication Engineering, Chosun University, 375 Susuk-dong, Dong-gu, Gwangju, 501-759, South Korea","Murad A., Department of Information Communication Engineering, Chosun University, 375 Susuk-dong, Dong-gu, Gwangju, 501-759, South Korea; Pyun J.-Y., Department of Information Communication Engineering, Chosun University, 375 Susuk-dong, Dong-gu, Gwangju, 501-759, South Korea","Adopting deep learning methods for human activity recognition has been effective in extracting discriminative features from raw input sequences acquired from body-worn sensors. Although human movements are encoded in a sequence of successive samples in time, typical machine learning methods perform recognition tasks without exploiting the temporal correlations between input data samples. Convolutional neural networks (CNNs) address this issue by using convolutions across a one-dimensional temporal sequence to capture dependencies among input data. However, the size of convolutional kernels restricts the captured range of dependencies between data samples. As a result, typical models are unadaptable to a wide range of activity recognition configurations and require fixed-length input windows. In this paper, we propose the use of deep recurrent neural networks (DRNNs) for building recognition models that are capable of capturing long-range dependencies in variable-length input sequences. We present unidirectional, bidirectional, and cascaded architectures based on long short-term memory (LSTM) DRNNs and evaluate their effectiveness on miscellaneous benchmark datasets. Experimental results show that our proposed models outperform methods employing conventional machine learning, such as support vector machine (SVM) and k-nearest neighbors (KNN). Additionally, the proposed models yield better performance than other deep learning techniques, such as deep believe networks (DBNs) and CNNs. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Human activity recognition; Recurrent neural networks","Algorithms; Human Activities; Humans; Machine Learning; Memory, Short-Term; Neural Networks (Computer); Artificial intelligence; Convolution; Deep learning; Deep neural networks; Input output programs; Learning systems; Long short-term memory; Nearest neighbor search; Neural networks; Pattern recognition; Support vector machines; Conventional machines; Convolutional neural network; Discriminative features; Human activity recognition; K nearest neighbor (KNN); Long-range dependencies; Machine learning methods; Temporal correlations; algorithm; artificial neural network; human; human activities; machine learning; short term memory; Recurrent neural networks","MDPI AG","14248220","","","29113103","Article","Scopus","2-s2.0-85033394959"
"Stegmayer G.; Yones C.; Kamenetzky L.; Milone D.H.","Stegmayer, Georgina (6506368373); Yones, Cristian (54956134000); Kamenetzky, Laura (6602840669); Milone, Diego H. (6505923044)","6506368373; 54956134000; 6602840669; 6505923044","High Class-Imbalance in pre-miRNA Prediction: A Novel Approach Based on deepSOM","2017","IEEE/ACM Transactions on Computational Biology and Bioinformatics","27","10.1109/TCBB.2016.2576459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033208984&doi=10.1109%2fTCBB.2016.2576459&partnerID=40&md5=f3fa451d148a768fc5265b797ed7ebdb","Research Institute for Signals, Systems, and Computational Intelligence, Santa Fe, 3000, Argentina; Instituto de Investigaciones en Microbiologa y Parasitologa Mdica, Buenos Aires, 1121, Argentina","Stegmayer G., Research Institute for Signals, Systems, and Computational Intelligence, Santa Fe, 3000, Argentina; Yones C., Research Institute for Signals, Systems, and Computational Intelligence, Santa Fe, 3000, Argentina; Kamenetzky L., Instituto de Investigaciones en Microbiologa y Parasitologa Mdica, Buenos Aires, 1121, Argentina; Milone D.H., Research Institute for Signals, Systems, and Computational Intelligence, Santa Fe, 3000, Argentina","The computational prediction of novel microRNA within a full genome involves identifying sequences having the highest chance of being a miRNA precursor pre-miRNA. These sequences are usually named candidates to miRNA. The well-known pre-miRNAs are usually only a few in comparison to the hundreds of thousands of potential candidates to miRNA that have to be analyzed, which makes this task a high class-imbalance classification problem. The classical way of approaching it has been training a binary classifier in a supervised manner, using well-known pre-miRNAs as positive class and artificially defining the negative class. However, although the selection of positive labeled examples is straightforward, it is very difficult to build a set of negative examples in order to obtain a good set of training samples for a supervised method. In this work, we propose a novel and effective way of approaching this problem using machine learning, without the definition of negative examples. The proposal is based on clustering unlabeled sequences of a genome together with well-known miRNA precursors for the organism under study, which allows for the quick identification of the best candidates to miRNA as those sequences clustered with known precursors. Furthermore, we propose a deep model to overcome the problem of having very few positive class labels. They are always maintained in the deep levels as positive class while less likely pre-miRNA sequences are filtered level after level. Our approach has been compared with other methods for pre-miRNAs prediction in several species, showing effective predictivity of novel miRNAs. Additionally, we will show that our approach has a lower training time and allows for a better graphical navegability and interpretation of the results. A web-demo interface to try deepSOM is available at http://fich.unl.edu.ar/sinc/web-demo/deepsom/. © 2017 IEEE.","classification; deep self-organizing maps; high class-imbalance; Unsupervised learning","Animals; Computational Biology; Humans; MicroRNAs; Models, Statistical; Plants; Software; Unsupervised Machine Learning; Classification (of information); Conformal mapping; Forecasting; Genes; Learning systems; Self organizing maps; Unsupervised learning; microRNA; Binary classifiers; Computational predictions; High class; Negative examples; Supervised methods; Training sample; Training time; Unlabeled sequences; animal; biology; genetics; human; plant; procedures; software; statistical model; unsupervised machine learning; RNA","Institute of Electrical and Electronics Engineers Inc.","15455963","","","27295687","Article","Scopus","2-s2.0-85033208984"
"Jia Z.; Huang X.; Chang E.I.-C.; Xu Y.","Jia, Zhipeng (56939734100); Huang, Xingyi (57194830372); Chang, Eric I-Chao (7401837784); Xu, Yan (57192065052)","56939734100; 57194830372; 7401837784; 57192065052","Constrained Deep Weak Supervision for Histopathology Image Segmentation","2017","IEEE Transactions on Medical Imaging","168","10.1109/TMI.2017.2724070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023175219&doi=10.1109%2fTMI.2017.2724070&partnerID=40&md5=864ea1943786953282f76c3b36c510ab","Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; State Key Laboratory of Software Development Environment, Key Laboratory of Biomechanics and Mechanobiology, Ministry of Education, Research Institute, Beihang University in Shenzhen, Beijing, 100191, China; Microsoft Research, Beijing, 100080, China","Jia Z., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China, Microsoft Research, Beijing, 100080, China; Huang X., State Key Laboratory of Software Development Environment, Key Laboratory of Biomechanics and Mechanobiology, Ministry of Education, Research Institute, Beihang University in Shenzhen, Beijing, 100191, China; Chang E.I.-C., Microsoft Research, Beijing, 100080, China; Xu Y., State Key Laboratory of Software Development Environment, Key Laboratory of Biomechanics and Mechanobiology, Ministry of Education, Research Institute, Beihang University in Shenzhen, Beijing, 100191, China, Microsoft Research, Beijing, 100080, China","In this paper, we develop a new weakly supervised learning algorithm to learn to segment cancerous regions in histopathology images. This paper is under a multiple instance learning (MIL) framework with a new formulation, deep weak supervision (DWS); we also propose an effective way to introduce constraints to our neural networks to assist the learning process. The contributions of our algorithm are threefold: 1) we build an end-to-end learning system that segments cancerous regions with fully convolutional networks (FCNs) in which image-to-image weakly-supervised learning is performed; 2) we develop a DWS formulation to exploit multi-scale learning under weak supervision within FCNs; and 3) constraints about positive instances are introduced in our approach to effectively explore additional weakly supervised information that is easy to obtain and enjoy a significant boost to the learning process. The proposed algorithm, abbreviated as DWS-MIL, is easy to implement and can be trained efficiently. Our system demonstrates the state-of-the-art results on large-scale histopathology image data sets and can be applied to various applications in medical imaging beyond histopathology images, such as MRI, CT, and ultrasound images. © 1982-2012 IEEE.","Convolutional neural networks; fully convolutional networks; histopathology image segmentation; multiple instance learning; weakly supervised learning","Algorithms; Colon; Colonic Neoplasms; Databases, Factual; Histocytochemistry; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Supervised Machine Learning; Tissue Array Analysis; Bioinformatics; Computerized tomography; Convolution; Deep learning; Deep neural networks; Education; Image segmentation; Learning systems; Magnetic resonance imaging; Medical imaging; Neural networks; Personnel training; Supervised learning; Biomedical imaging; Cancer; Convolutional networks; Convolutional neural network; Multiple instance learning; Prediction algorithms; Weakly supervised learning; accuracy; Article; computer assisted tomography; conceptual framework; diagnostic imaging; echography; histopathology; human; image segmentation; information processing; learning; learning algorithm; nuclear magnetic resonance imaging; algorithm; artificial neural network; colon; colon tumor; cytochemistry; factual database; image processing; procedures; supervised machine learning; tissue microarray; Learning algorithms","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28692971","Article","Scopus","2-s2.0-85023175219"
"Xiao S.; Bucher F.; Wu Y.; Rokem A.; Lee C.S.; Marra K.V.; Fallon R.; Diaz-Aguilar S.; Aguilar E.; Friedlander M.; Lee A.Y.","Xiao, Sa (57208175773); Bucher, Felicitas (37057078400); Wu, Yue (57194851622); Rokem, Ariel (6507945628); Lee, Cecilia S. (56472056400); Marra, Kyle V. (55810193600); Fallon, Regis (57211248308); Diaz-Aguilar, Sophia (57190765917); Aguilar, Edith (7102769456); Friedlander, Martin (7102298919); Lee, Aaron Y. (26635526200)","57208175773; 37057078400; 57194851622; 6507945628; 56472056400; 55810193600; 57211248308; 57190765917; 7102769456; 7102298919; 26635526200","Fully automated, deep learning segmentation of oxygen-induced retinopathy images","2017","JCI Insight","38","10.1172/jci.insight.97585","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048158179&doi=10.1172%2fjci.insight.97585&partnerID=40&md5=aeda022bed924e1f49e560235cc5c186","Department of Ophthalmology, University of Washington, Seattle, WA, United States; Department of Molecular Medicine, Scripps Research Institute, San diego, CA, United States; Eye Center, Faculty of Medicine, University of Freiburg, Freiburg, Germany; eScience Institute, University of Washington, Seattle, WA, United States; Department of Bioengineering, University of California, San Diego, San Diego, CA, United States; Lowy Medical Research Institute, San diego, CA, United States; Department of Ophthalmology, Puget Sound Veteran Affairs, Seattle, WA, United States","Xiao S., Department of Ophthalmology, University of Washington, Seattle, WA, United States; Bucher F., Department of Molecular Medicine, Scripps Research Institute, San diego, CA, United States, Eye Center, Faculty of Medicine, University of Freiburg, Freiburg, Germany; Wu Y., Department of Ophthalmology, University of Washington, Seattle, WA, United States; Rokem A., eScience Institute, University of Washington, Seattle, WA, United States; Lee C.S., Department of Ophthalmology, University of Washington, Seattle, WA, United States; Marra K.V., Department of Molecular Medicine, Scripps Research Institute, San diego, CA, United States, Department of Bioengineering, University of California, San Diego, San Diego, CA, United States; Fallon R., Lowy Medical Research Institute, San diego, CA, United States; Diaz-Aguilar S., Department of Molecular Medicine, Scripps Research Institute, San diego, CA, United States; Aguilar E., Department of Molecular Medicine, Scripps Research Institute, San diego, CA, United States; Friedlander M., Department of Molecular Medicine, Scripps Research Institute, San diego, CA, United States, Lowy Medical Research Institute, San diego, CA, United States; Lee A.Y., Department of Ophthalmology, University of Washington, Seattle, WA, United States, eScience Institute, University of Washington, Seattle, WA, United States, Department of Ophthalmology, Puget Sound Veteran Affairs, Seattle, WA, United States","Oxygen-induced retinopathy (OIR) is a widely used model to study ischemia-driven neovascularization (NV) in the retina and to serve in proof-of-concept studies in evaluating antiangiogenic drugs for ocular, as well as nonocular, diseases. The primary parameters that are analyzed in this mouse model include the percentage of retina with vaso-obliteration (VO) and NV areas. However, quantification of these two key variables comes with a great challenge due to the requirement of human experts to read the images. Human readers are costly, time-consuming, and subject to bias. Using recent advances in machine learning and computer vision, we trained deep learning neural networks using over a thousand segmentations to fully automate segmentation in OIR images. While determining the percentage area of VO, our algorithm achieved a similar range of correlation coefficients to that of expert inter-human correlation coefficients. In addition, our algorithm achieved a higher range of correlation coefficients compared with inter-expert correlation coefficients for quantification of the percentage area of neovascular tufts. In summary, we have created an open-source, fully automated pipeline for the quantification of key values of OIR images using deep learning neural networks. © 2017 American Society for Clinical Investigation. All rights reserved.","","","American Society for Clinical Investigation","23793708","","","29263301","Article","Scopus","2-s2.0-85048158179"
"Yang X.; Liu C.; Wang Z.; Yang J.; Min H.L.; Wang L.; Cheng K.-T.T.","Yang, Xin (57203539516); Liu, Chaoyue (57193898373); Wang, Zhiwei (57216175393); Yang, Jun (57188570367); Min, Hung Le (57195474137); Wang, Liang (57221649435); Cheng, Kwang-Ting (Tim) (7402997957)","57203539516; 57193898373; 57216175393; 57188570367; 57195474137; 57221649435; 7402997957","Co-trained convolutional neural networks for automated detection of prostate cancer in multi-parametric MRI","2017","Medical Image Analysis","121","10.1016/j.media.2017.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028357096&doi=10.1016%2fj.media.2017.08.006&partnerID=40&md5=809874f1c00a4a63dfbef03e66ae575a","Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Department of Organ transplantation, Tongji Hospital, Huazhong University of Science and Technology, 430022, Wuhan, China; Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, 430030, Wuhan, China; School of Engineering, Hong Kong University of Science and Technology, Hong Kong","Yang X., Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Liu C., Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Wang Z., Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Yang J., Department of Organ transplantation, Tongji Hospital, Huazhong University of Science and Technology, 430022, Wuhan, China; Min H.L., Department of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Wang L., Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, 430030, Wuhan, China; Cheng K.-T.T., School of Engineering, Hong Kong University of Science and Technology, Hong Kong","Multi-parameter magnetic resonance imaging (mp-MRI) is increasingly popular for prostate cancer (PCa) detection and diagnosis. However, interpreting mp-MRI data which typically contains multiple unregistered 3D sequences, e.g. apparent diffusion coefficient (ADC) and T2-weighted (T2w) images, is time-consuming and demands special expertise, limiting its usage for large-scale PCa screening. Therefore, solutions to computer-aided detection of PCa in mp-MRI images are highly desirable. Most recent advances in automated methods for PCa detection employ a handcrafted feature based two-stage classification flow, i.e. voxel-level classification followed by a region-level classification. This work presents an automated PCa detection system which can concurrently identify the presence of PCa in an image and localize lesions based on deep convolutional neural network (CNN) features and a single-stage SVM classifier. Specifically, the developed co-trained CNNs consist of two parallel convolutional networks for ADC and T2w images respectively. Each network is trained using images of a single modality in a weakly-supervised manner by providing a set of prostate images with image-level labels indicating only the presence of PCa without priors of lesions’ locations. Discriminative visual patterns of lesions can be learned effectively from clutters of prostate and surrounding tissues. A cancer response map with each pixel indicating the likelihood to be cancerous is explicitly generated at the last convolutional layer of the network for each modality. A new back-propagated error E is defined to enforce both optimized classification results and consistent cancer response maps for different modalities, which help capture highly representative PCa-relevant features during the CNN feature learning process. The CNN features of each modality are concatenated and fed into a SVM classifier. For images which are classified to contain cancers, non-maximum suppression and adaptive thresholding are applied to the corresponding cancer response maps for PCa foci localization. Evaluation based on 160 patient data with 12-core systematic TRUS-guided prostate biopsy as the reference standard demonstrates that our system achieves a sensitivity of 0.46, 0.92 and 0.97 at 0.1, 1 and 10 false positives per normal/benign patient which is significantly superior to two state-of-the-art CNN-based methods (Oquab et al., 2015; Zhou et al., 2015) and 6-core systematic prostate biopsies. © 2017 Elsevier B.V.","Cancer response map; Co-trained CNN; Convolutional neural network; Prostate biopsy; Prostate cancer detection","Algorithms; Automation; Humans; Image Interpretation, Computer-Assisted; Image-Guided Biopsy; Magnetic Resonance Imaging; Male; Neural Networks (Computer); Prostatic Neoplasms; Reproducibility of Results; Sensitivity and Specificity; Automation; Biopsy; Classification (of information); Convolution; Deep neural networks; Diseases; Feature extraction; Hospital data processing; Image classification; Image segmentation; Magnetic levitation vehicles; Magnetic resonance imaging; Network layers; Neural networks; Scales (weighing instruments); Surface diffusion; Urology; Apparent diffusion coefficient; Computer aided detection; Convolutional neural network; Deep convolutional neural networks; Detection and diagnosis; Non-maximum suppression; Prostate biopsy; Prostate cancer detection; apparent diffusion coefficient; Article; artificial neural network; automation; cancer diagnosis; computer assisted diagnosis; controlled study; convolutional neural network; diagnostic test accuracy study; false positive result; human; human tissue; image processing; intermethod comparison; male; multiparametric magnetic resonance imaging; nuclear magnetic resonance scanner; priority journal; prostate biopsy; prostate cancer; sensitivity and specificity; support vector machine; transrectal ultrasonography; algorithm; artificial neural network; automation; diagnostic imaging; image guided biopsy; nuclear magnetic resonance imaging; procedures; prostate tumor; reproducibility; Calcium compounds","Elsevier B.V.","13618415","","MIAEC","28850876","Article","Scopus","2-s2.0-85028357096"
"Wawrzyński P.","Wawrzyński, Paweł (6507272295)","6507272295","ASD+M: Automatic parameter tuning in stochastic optimization and on-line learning","2017","Neural Networks","4","10.1016/j.neunet.2017.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029696570&doi=10.1016%2fj.neunet.2017.07.007&partnerID=40&md5=610fefd161693cf6d866910acee5bd0b","Warsaw University of Technology, Institute of Computer Science, Nowowiejska 15/19, Warsaw, 00-665, Poland","Wawrzyński P., Warsaw University of Technology, Institute of Computer Science, Nowowiejska 15/19, Warsaw, 00-665, Poland","In this paper the classic momentum algorithm for stochastic optimization is considered. A method is introduced that adjusts coefficients for this algorithm during its operation. The method does not depend on any preliminary knowledge of the optimization problem. In the experimental study, the method is applied to on-line learning in feed-forward neural networks, including deep auto-encoders, and outperforms any fixed coefficients. The method eliminates coefficients that are difficult to determine, with profound influence on performance. While the method itself has some coefficients, they are ease to determine and sensitivity of performance to them is low. Consequently, the method makes on-line learning a practically parameter-free process and broadens the area of potential application of this technology. © 2017 Elsevier Ltd","Classic momentum; Deep learning; Learning rate; On-line learning; Step-size; Stochastic gradient descent","Algorithms; Learning; Machine Learning; Neural Networks (Computer); Stochastic Processes; Deep learning; Feedforward neural networks; Gradient methods; Learning systems; Optimization; Stochastic systems; Auto encoders; Automatic parameter tuning; Learning rates; Online learning; Optimization problems; Step size; Stochastic gradient descent; Stochastic optimizations; Article; artificial neural network; experimental study; learning; online system; positive feedback; priority journal; process optimization; sensitivity analysis; stochastic optimization; algorithm; learning; machine learning; Markov chain; trends; E-learning","Elsevier Ltd","08936080","","NNETE","28950104","Article","Scopus","2-s2.0-85029696570"
"Samala R.K.; Chan H.-P.; Hadjiiski L.M.; Helvie M.A.; Cha K.H.; Richter C.D.","Samala, Ravi K (23005865500); Chan, Heang-Ping (7403402896); Hadjiiski, Lubomir M (7003646513); Helvie, Mark A (7005819436); Cha, Kenny H (55955567400); Richter, Caleb D (57199645329)","23005865500; 7403402896; 7003646513; 7005819436; 55955567400; 57199645329","Multi-task transfer learning deep convolutional neural network: Application to computer-aided diagnosis of breast cancer on mammograms","2017","Physics in Medicine and Biology","165","10.1088/1361-6560/aa93d4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038213282&doi=10.1088%2f1361-6560%2faa93d4&partnerID=40&md5=f6881b2f524463227b62674799808afc","Department of Radiology, University of Michigan, Ann Arbor, 48109-5842, MI, United States","Samala R.K., Department of Radiology, University of Michigan, Ann Arbor, 48109-5842, MI, United States; Chan H.-P., Department of Radiology, University of Michigan, Ann Arbor, 48109-5842, MI, United States; Hadjiiski L.M., Department of Radiology, University of Michigan, Ann Arbor, 48109-5842, MI, United States; Helvie M.A., Department of Radiology, University of Michigan, Ann Arbor, 48109-5842, MI, United States; Cha K.H., Department of Radiology, University of Michigan, Ann Arbor, 48109-5842, MI, United States; Richter C.D., Department of Radiology, University of Michigan, Ann Arbor, 48109-5842, MI, United States","Transfer learning in deep convolutional neural networks (DCNNs) is an important step in its application to medical imaging tasks. We propose a multi-task transfer learning DCNN with the aim of translating the 'knowledge' learned from non-medical images to medical diagnostic tasks through supervised training and increasing the generalization capabilities of DCNNs by simultaneously learning auxiliary tasks. We studied this approach in an important application: classification of malignant and benign breast masses. With Institutional Review Board (IRB) approval, digitized screen-film mammograms (SFMs) and digital mammograms (DMs) were collected from our patient files and additional SFMs were obtained from the Digital Database for Screening Mammography. The data set consisted of 2242 views with 2454 masses (1057 malignant, 1397 benign). In single-task transfer learning, the DCNN was trained and tested on SFMs. In multi-task transfer learning, SFMs and DMs were used to train the DCNN, which was then tested on SFMs. N-fold cross-validation with the training set was used for training and parameter optimization. On the independent test set, the multi-task transfer learning DCNN was found to have significantly (p = 0.007) higher performance compared to the single-task transfer learning DCNN. This study demonstrates that multi-task transfer learning may be an effective approach for training DCNN in medical imaging applications when training samples from a single modality are limited. © 2017 Institute of Physics and Engineering in Medicine.","computer-aided diagnosis; deep convolutional neural network; digital mammography; digitized screen-film mammography; mass; multi-task learning; transfer learning","Adult; Aged; Aged, 80 and over; Breast Neoplasms; Diagnosis, Computer-Assisted; Female; Humans; Machine Learning; Mammography; Middle Aged; Neural Networks (Computer); Young Adult; Computer aided diagnosis; Computer networks; Convolution; Deep neural networks; Diagnosis; Mammography; Medical imaging; Neural networks; X ray screens; Convolutional neural network; Digital mammography; mass; Multitask learning; Screen-film mammographies; Transfer learning; adult; aged; artificial neural network; breast tumor; computer assisted diagnosis; diagnostic imaging; female; human; machine learning; mammography; middle aged; procedures; very elderly; young adult; Computer aided instruction","Institute of Physics Publishing","00319155","","PHMBA","29035873","Article","Scopus","2-s2.0-85038213282"
"Li H.; Shaham U.; Stanton K.P.; Yao Y.; Montgomery R.R.; Kluger Y.","Li, Huamin (57193167628); Shaham, Uri (55662339300); Stanton, Kelly P. (55910692500); Yao, Yi (56428276800); Montgomery, Ruth R. (7202664579); Kluger, Yuval (22962330400)","57193167628; 55662339300; 55910692500; 56428276800; 7202664579; 22962330400","Gating mass cytometry data by deep learning","2017","Bioinformatics (Oxford, England)","55","10.1093/bioinformatics/btx448","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047386289&doi=10.1093%2fbioinformatics%2fbtx448&partnerID=40&md5=726ca771b1984f796de841644c1ae1b4","Applied Mathematics Program, United States; Department of Statistics, Yale University, 51 Prospect Street ,New Haven, 06511, CT, United States; Department of Pathology and Yale Cancer Center; Department of Internal Medicine, Yale School of Medicine, New Haven, 06520, CT, United States; Interdepartmental Program in Computational Biology and Bioinformatics, Yale University, New Haven, 06511, CT, United States","Li H., Applied Mathematics Program, United States; Shaham U., Department of Statistics, Yale University, 51 Prospect Street ,New Haven, 06511, CT, United States; Stanton K.P., Department of Pathology and Yale Cancer Center; Yao Y., Department of Internal Medicine, Yale School of Medicine, New Haven, 06520, CT, United States; Montgomery R.R., Department of Internal Medicine, Yale School of Medicine, New Haven, 06520, CT, United States; Kluger Y., Applied Mathematics Program, United States, Department of Pathology and Yale Cancer Center, Interdepartmental Program in Computational Biology and Bioinformatics, Yale University, New Haven, 06511, CT, United States","Motivation: Mass cytometry or CyTOF is an emerging technology for high-dimensional multiparameter single cell analysis that overcomes many limitations of fluorescence-based flow cytometry. New methods for analyzing CyTOF data attempt to improve automation, scalability, performance and interpretation of data generated in large studies. Assigning individual cells into discrete groups of cell types (gating) involves time-consuming sequential manual steps, untenable for larger studies.; Results: We introduce DeepCyTOF, a standardization approach for gating, based on deep learning techniques. DeepCyTOF requires labeled cells from only a single sample. It is based on domain adaptation principles and is a generalization of previous work that allows us to calibrate between a target distribution and a source distribution in an unsupervised manner. We show that DeepCyTOF is highly concordant (98%) with cell classification obtained by individual manual gating of each sample when applied to a collection of 16 biological replicates of primary immune blood cells, even when measured across several instruments. Further, DeepCyTOF achieves very high accuracy on the semi-automated gating challenge of the FlowCAP-I competition as well as two CyTOF datasets generated from primary immune blood cells: (i) 14 subjects with a history of infection with West Nile virus (WNV), (ii) 34 healthy subjects of different ages. We conclude that deep learning in         general, and DeepCyTOF specifically, offers a powerful computational approach for semi-automated gating of CyTOF and flow cytometry data.; Availability and implementation: Our codes and data are publicly available at https://github.com/KlugerLab/deepcytof.git.; Contact: yuval.kluger@yale.edu.; Supplementary information: Supplementary data are available at Bioinformatics online. © The Author 2017. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com","","Blood Cells; Calibration; Cell Separation; Computational Biology; Flow Cytometry; Humans; Machine Learning; Reference Standards; Reproducibility of Results; Single-Cell Analysis; biology; blood cell; calibration; cell separation; classification; flow cytometry; human; machine learning; procedures; reproducibility; single cell analysis; standard; standards","","13674811","","","29036374","Article","Scopus","2-s2.0-85047386289"
"Zhang L.; Lu L.; Nogues I.; Summers R.M.; Liu S.; Yao J.","Zhang, Ling (55971484200); Lu, Le (55474685200); Nogues, Isabella (56921932100); Summers, Ronald M. (7202364932); Liu, Shaoxiong (55813629200); Yao, Jianhua (57693843200)","55971484200; 55474685200; 56921932100; 7202364932; 55813629200; 57693843200","DeepPap: Deep convolutional networks for cervical cell classification","2017","IEEE Journal of Biomedical and Health Informatics","332","10.1109/JBHI.2017.2705583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035807487&doi=10.1109%2fJBHI.2017.2705583&partnerID=40&md5=f9f5bafece952f7c4600c1efea91bcaf","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Department of Pathology, Peoples Hospital of Nanshan District, Shenzhen, 518052, China","Zhang L., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Lu L., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Nogues I., Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Summers R.M., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Liu S., Department of Pathology, Peoples Hospital of Nanshan District, Shenzhen, 518052, China; Yao J., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States","Automation-assisted cervical screening via Pap smear or liquid-based cytology (LBC) is a highly effective cell imaging based cancer detection tool, where cells are partitioned into 'abnormal' and 'normal' categories. However, the success of most traditional classification methods relies on the presence of accurate cell segmentations. Despite sixty years of research in this field, accurate segmentation remains a challenge in the presence of cell clusters and pathologies. Moreover, previous classification methods are only built upon the extraction of hand-crafted features, such as morphology and texture. This paper addresses these limitations by proposing a method to directly classify cervical cells - without prior segmentation - based on deep features, using convolutional neural networks (ConvNets). First, the ConvNet is pretrained on a natural image dataset. It is subsequently fine-tuned on a cervical cell dataset consisting of adaptively resampled image patches coarsely centered on the nuclei. In the testing phase, aggregation is used to average the prediction scores of a similar set of image patches. The proposed method is evaluated on both Pap smear and LBC datasets. Results show that our method outperforms previous algorithms in classification accuracy (98.3%), area under the curve (0.99) values, and especially specificity (98.3%), when applied to the Herlev benchmark Pap smear dataset and evaluated using five-fold cross validation. Similar superior performances are also achieved on the HEMLBC (H&E stained manual LBC) dataset. Our method is promising for the development of automation-assisted reading systems in primary cervical screening. © 2013 IEEE.","Cell classification; Cervical cytology; deep learning; neural networks; Pap smear","Cervix Uteri; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Papanicolaou Test; Vaginal Smears; Cells; Classification (of information); Convolution; Cytology; Deep learning; Deep neural networks; Image segmentation; Neural networks; Textures; Area under the curves; Cancer detection; Cell classification; Classification accuracy; Classification methods; Convolutional networks; Cross validation; Pap smear; accuracy; area under the curve; Article; artificial neural network; cervical cell line; diagnostic test accuracy study; human; image segmentation; learning; Papanicolaou test; receiver operating characteristic; sensitivity and specificity; training; artificial neural network; computer assisted diagnosis; cytology; female; machine learning; Papanicolaou test; procedures; uterine cervix; vagina smear; Convolutional neural networks","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28541229","Article","Scopus","2-s2.0-85035807487"
"Eulenberg P.; Köhler N.; Blasi T.; Filby A.; Carpenter A.E.; Rees P.; Theis F.J.; Wolf F.A.","Eulenberg, Philipp (57190389906); Köhler, Niklas (57195577761); Blasi, Thomas (55480630600); Filby, Andrew (6507391747); Carpenter, Anne E. (8063969900); Rees, Paul (7202572641); Theis, Fabian J. (6701364934); Wolf, F. Alexander (57223603707)","57190389906; 57195577761; 55480630600; 6507391747; 8063969900; 7202572641; 6701364934; 57223603707","Reconstructing cell cycle and disease progression using deep learning","2017","Nature Communications","171","10.1038/s41467-017-00623-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028914209&doi=10.1038%2fs41467-017-00623-3&partnerID=40&md5=4aa164f0a373ca82cf53ce9baeb73d9b","Helmholtz Zentrum München - German Research Center for Environmental Health, Institute of Computational Biology, Neuherberg, Munich, Germany; Department of Physics, Arnold Sommerfeld Center for Theoretical Physics, LMU München, Munich, Germany; Imaging Platform at the Broad Institute of Harvard, Massachusetts Institute of Technology, Cambridge, MA, United States; Flow Cytometry Core Facility, Faculty of Medical Sciences, Newcastle University, Newcastle-upon-Tyne, United Kingdom; College of Engineering, Swansea University, Singleton Park, Swansea, United Kingdom; Department of Mathematics, TU München, Munich, Germany","Eulenberg P., Helmholtz Zentrum München - German Research Center for Environmental Health, Institute of Computational Biology, Neuherberg, Munich, Germany, Department of Physics, Arnold Sommerfeld Center for Theoretical Physics, LMU München, Munich, Germany; Köhler N., Helmholtz Zentrum München - German Research Center for Environmental Health, Institute of Computational Biology, Neuherberg, Munich, Germany, Department of Physics, Arnold Sommerfeld Center for Theoretical Physics, LMU München, Munich, Germany; Blasi T., Helmholtz Zentrum München - German Research Center for Environmental Health, Institute of Computational Biology, Neuherberg, Munich, Germany, Imaging Platform at the Broad Institute of Harvard, Massachusetts Institute of Technology, Cambridge, MA, United States; Filby A., Flow Cytometry Core Facility, Faculty of Medical Sciences, Newcastle University, Newcastle-upon-Tyne, United Kingdom; Carpenter A.E., Imaging Platform at the Broad Institute of Harvard, Massachusetts Institute of Technology, Cambridge, MA, United States; Rees P., Imaging Platform at the Broad Institute of Harvard, Massachusetts Institute of Technology, Cambridge, MA, United States, College of Engineering, Swansea University, Singleton Park, Swansea, United Kingdom; Theis F.J., Helmholtz Zentrum München - German Research Center for Environmental Health, Institute of Computational Biology, Neuherberg, Munich, Germany, Department of Mathematics, TU München, Munich, Germany; Wolf F.A., Helmholtz Zentrum München - German Research Center for Environmental Health, Institute of Computational Biology, Neuherberg, Munich, Germany","We show that deep convolutional neural networks combined with nonlinear dimension reduction enable reconstructing biological processes based on raw image data. We demonstrate this by reconstructing the cell cycle of Jurkat cells and disease progression in diabetic retinopathy. In further analysis of Jurkat cells, we detect and separate a subpopulation of dead cells in an unsupervised manner and, in classifying discrete cell cycle stages, we reach a sixfold reduction in error rate compared to a recent approach based on boosting on image features. In contrast to previous methods, deep learning based predictions are fast enough for on-the-fly analysis in an imaging flow cytometer. © 2017 The Author(s).","","Cell Cycle; Cell Division; Computer Simulation; Diabetic Retinopathy; Disease Progression; DNA; Flow Cytometry; Humans; Jurkat Cells; Machine Learning; Mitosis; Neural Networks (Computer); Reproducibility of Results; DNA; artificial neural network; cells and cell components; disease; flow cytometry; image; subpopulation; anaphase; Article; cell cycle; cell cycle progression; diabetic retinopathy; disease course; disease severity; DNA content; flow cytometer; human; human cell; interphase; Jurkat cell line; machine learning; metaphase; mitosis; phenotype; prediction; prophase; telophase; artificial neural network; cell cycle; cell division; computer simulation; diabetic retinopathy; disease exacerbation; flow cytometry; pathology; reproducibility","Nature Publishing Group","20411723","","","28878212","Article","Scopus","2-s2.0-85028914209"
"De Tobel J.; Radesh P.; Vandermeulen D.; Thevissen P.W.","De Tobel, J. (37121673800); Radesh, P. (57200727867); Vandermeulen, D. (7003312639); Thevissen, P.W. (13407275300)","37121673800; 57200727867; 7003312639; 13407275300","An automated technique to stage lower third molar development on panoramic radiographs for age estimation: a pilot study","2017","The Journal of forensic odonto-stomatology","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082359200&partnerID=40&md5=0ade231d4dddd25bb37002d82bb2adb1","Department of Electrical Engineering - ESAT/PSI, KU Leuven, Belgium; Department of Electrical Engineering - ESAT/PSI, KU Leuven, Belgium","De Tobel J., Department of Electrical Engineering - ESAT/PSI, KU Leuven, Belgium; Radesh P., Department of Electrical Engineering - ESAT/PSI, KU Leuven, Belgium; Vandermeulen D., Department of Electrical Engineering - ESAT/PSI, KU Leuven, Belgium; Thevissen P.W., Department of Electrical Engineering - ESAT/PSI, KU Leuven, Belgium","BACKGROUND: Automated methods to evaluate growth of hand and wrist bones on radiographs and magnetic resonance imaging have been developed. They can be applied to estimate age in children and subadults. Automated methods require the software to (1) recognise the region of interest in the image(s), (2) evaluate the degree of development and (3) correlate this to the age of the subject based on a reference population. For age estimation based on third molars an automated method for step (1) has been presented for 3D magnetic resonance imaging and is currently being optimised (Unterpirker et al. 2015).; AIM: To develop an automated method for step (2) based on lower third molars on panoramic radiographs.; MATERIALS AND METHODS: A modified Demirjian staging technique including ten developmental stages was developed. Twenty panoramic radiographs per stage per gender were retrospectively selected for FDI element 38. Two observers decided in consensus about the stages. When necessary, a third observer acted as a referee to establish the reference stage for the considered third molar. This set of radiographs was used as training data for machine learning algorithms for automated staging. First, image contrast settings were optimised to evaluate the third molar of interest and a rectangular bounding box was placed around it in a standardised way using Adobe Photoshop CC 2017 software. This bounding box indicated the region of interest for the next step. Second, several machine learning algorithms available in MATLAB R2017a software were applied for automated stage recognition. Third, the classification performance was evaluated in a 5-fold cross-validation scenario, using different validation metrics (accuracy, Rank-N recognition rate, mean absolute difference, linear kappa coefficient).; RESULTS: Transfer Learning as a type of Deep Learning Convolutional Neural Network approach outperformed all other tested approaches. Mean accuracy equalled 0.51, mean absolute difference was 0.6 stages and mean linearly weighted kappa was 0.82.; CONCLUSION: The overall performance of the presented automated pilot technique to stage lower third molar development on panoramic radiographs was similar to staging by human observers. It will be further optimised in future research, since it represents a necessary step to achieve a fully automated dental age estimation method, which to date is not available.","","Age Determination by Teeth; Algorithms; Female; Humans; Machine Learning; Male; Molar, Third; Pilot Projects; Radiography, Panoramic; Retrospective Studies; algorithm; dental age estimation; diagnostic imaging; female; growth, development and aging; human; machine learning; male; panoramic radiography; pilot study; procedures; retrospective study; third molar","","22196749","","","29384736","Article","Scopus","2-s2.0-85082359200"
"Welikala R.A.; Foster P.J.; Whincup P.H.; Rudnicka A.R.; Owen C.G.; Strachan D.P.; Barman S.A.","Welikala, R.A. (55659906400); Foster, P.J. (56457504000); Whincup, P.H. (7006237290); Rudnicka, A.R. (6603711082); Owen, C.G. (57217445127); Strachan, D.P. (55817551915); Barman, S.A. (7102545582)","55659906400; 56457504000; 7006237290; 6603711082; 57217445127; 55817551915; 7102545582","Automated arteriole and venule classification using deep learning for retinal images from the UK Biobank cohort","2017","Computers in Biology and Medicine","94","10.1016/j.compbiomed.2017.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029315560&doi=10.1016%2fj.compbiomed.2017.09.005&partnerID=40&md5=8b999c8840dd14be96d0a594fa59b4f5","School of Computer Science and Mathematics, Kingston University, KT1 2EE, Surrey, United Kingdom; NIHR Biomedical Research Centre, Moorfields Eye Hospital, London, EC1V 2PD, United Kingdom; UCL Institute of Ophthalmology, London, EC1V 9EL, United Kingdom; Population Health Research Institute, St. George's, University of London, London, SW17 0RE, United Kingdom","Welikala R.A., School of Computer Science and Mathematics, Kingston University, KT1 2EE, Surrey, United Kingdom; Foster P.J., NIHR Biomedical Research Centre, Moorfields Eye Hospital, London, EC1V 2PD, United Kingdom, UCL Institute of Ophthalmology, London, EC1V 9EL, United Kingdom; Whincup P.H., Population Health Research Institute, St. George's, University of London, London, SW17 0RE, United Kingdom; Rudnicka A.R., Population Health Research Institute, St. George's, University of London, London, SW17 0RE, United Kingdom; Owen C.G., Population Health Research Institute, St. George's, University of London, London, SW17 0RE, United Kingdom; Strachan D.P., Population Health Research Institute, St. George's, University of London, London, SW17 0RE, United Kingdom; Barman S.A., School of Computer Science and Mathematics, Kingston University, KT1 2EE, Surrey, United Kingdom","The morphometric characteristics of the retinal vasculature are associated with future risk of many systemic and vascular diseases. However, analysis of data from large population based studies is needed to help resolve uncertainties in some of these associations. This requires automated systems that extract quantitative measures of vessel morphology from large numbers of retinal images. Associations between retinal vessel morphology and disease precursors/outcomes may be similar or opposing for arterioles and venules. Therefore, the accurate detection of the vessel type is an important element in such automated systems. This paper presents a deep learning approach for the automatic classification of arterioles and venules across the entire retinal image, including vessels located at the optic disc. This comprises of a convolutional neural network whose architecture contains six learned layers: three convolutional and three fully-connected. Complex patterns are automatically learnt from the data, which avoids the use of hand crafted features. The method is developed and evaluated using 835,914 centreline pixels derived from 100 retinal images selected from the 135,867 retinal images obtained at the UK Biobank (large population-based cohort study of middle aged and older adults) baseline examination. This is a challenging dataset in respect to image quality and hence arteriole/venule classification is required to be highly robust. The method achieves a significant increase in accuracy of 8.1% when compared to the baseline method, resulting in an arteriole/venule classification accuracy of 86.97% (per pixel basis) over the entire retinal image. © 2017 Elsevier Ltd","Arteriole/venule classification; Convolutional neural networks; Deep learning; Epidemiological studies; Retinal images; UK Biobank","Arterioles; Biological Specimen Banks; Cohort Studies; Databases, Factual; Female; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Neural Networks (Computer); Optic Disk; Retinal Vessels; United Kingdom; Venules; Automation; Blood vessels; Classification (of information); Convolution; Image classification; Neural networks; Ophthalmology; Pixels; Population statistics; Uncertainty analysis; Automatic classification; Classification accuracy; Convolutional neural network; Epidemiological studies; Morphometric characteristics; Quantitative measures; Retinal image; UK Biobank; adult; Article; automation; biobank; cohort analysis; convolutional neural network; diagnostic error; eye bank; false positive result; fundus camera; human; image enhancement; image processing; image quality; image segmentation; machine learning; measurement accuracy; middle aged; optic disk; predictive value; priority journal; retina blood vessel; retina image; retina vein; retina venule; retinal arteriole; sensitivity and specificity; true positive result; United Kingdom; arteriole; artificial neural network; biobank; diagnostic imaging; factual database; female; image processing; male; optic disk; retina blood vessel; vascularization; venule; Deep learning","Elsevier Ltd","00104825","","CBMDA","28917120","Article","Scopus","2-s2.0-85029315560"
"Yaqub M.; Kelly B.; Papageorghiou A.T.; Noble J.A.","Yaqub, Mohammad (53165416500); Kelly, Brenda (7202842439); Papageorghiou, Aris T. (6603569987); Noble, J. Alison (56185660000)","53165416500; 7202842439; 6603569987; 56185660000","A Deep Learning Solution for Automatic Fetal Neurosonographic Diagnostic Plane Verification Using Clinical Standard Constraints","2017","Ultrasound in Medicine and Biology","44","10.1016/j.ultrasmedbio.2017.07.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029809732&doi=10.1016%2fj.ultrasmedbio.2017.07.013&partnerID=40&md5=d33e3f06f3633baa17448011b815ac6e","Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, United Kingdom; Nuffield Department of Obstetrics & Gynaecology, University of Oxford, Oxford, United Kingdom","Yaqub M., Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, United Kingdom; Kelly B., Nuffield Department of Obstetrics & Gynaecology, University of Oxford, Oxford, United Kingdom; Papageorghiou A.T., Nuffield Department of Obstetrics & Gynaecology, University of Oxford, Oxford, United Kingdom; Noble J.A., Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, United Kingdom","During routine ultrasound assessment of the fetal brain for biometry estimation and detection of fetal abnormalities, accurate imaging planes must be found by sonologists following a well-defined imaging protocol or clinical standard, which can be difficult for non-experts to do well. This assessment helps provide accurate biometry estimation and the detection of possible brain abnormalities. We describe a machine-learning method to assess automatically that transventricular ultrasound images of the fetal brain have been correctly acquired and meet the required clinical standard. We propose a deep learning solution, which breaks the problem down into three stages: (i) accurate localization of the fetal brain, (ii) detection of regions that contain structures of interest and (iii) learning the acoustic patterns in the regions that enable plane verification. We evaluate the developed methodology on a large real-world clinical data set of 2-D mid-gestation fetal images. We show that the automatic verification method approaches human expert assessment. © 2017 World Federation for Ultrasound in Medicine and Biology","Convolutional neural networks; Fetal ultrasound; Knowledge-based image analysis; Neurosonography; Pregnancy; Trans-ventricular plane","Brain; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Pregnancy; Ultrasonography, Prenatal; Brain; Knowledge based systems; Neural networks; Ultrasonic applications; Convolutional neural network; Fetal ultrasound; Knowledge based; Neurosonography; Pregnancy; Trans-ventricular plane; Article; artificial neural network; biometry; controlled study; convolutional neural network; deep learning solution; fetus; fetus echography; human; machine learning; measurement accuracy; measurement precision; priority journal; process optimization; septum pellucidum; artificial neural network; brain; diagnostic imaging; embryology; female; fetus echography; image processing; pregnancy; procedures; Deep learning","Elsevier USA","03015629","","USMBA","28958729","Article","Scopus","2-s2.0-85029809732"
"Qayyum A.; Anwar S.M.; Awais M.; Majid M.","Qayyum, Adnan (57202908543); Anwar, Syed Muhammad (36781722700); Awais, Muhammad (57224215215); Majid, Muhammad (55390149500)","57202908543; 36781722700; 57224215215; 55390149500","Medical image retrieval using deep convolutional neural network","2017","Neurocomputing","320","10.1016/j.neucom.2017.05.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019914033&doi=10.1016%2fj.neucom.2017.05.025&partnerID=40&md5=9ab87ad122f60ea26c0cdd012acc40fc","Department of Computer Engineering, University of Engineering and Technology, Taxila, Pakistan; Department of Software Engineering, University of Engineering and Technology, Taxila, Pakistan; Center for Vision, Speech and Signal Processing, University of Surrey, Surrey, United Kingdom; Signal, Image, Multimedia Processing and Learning (SIMPLE) Group, University of Engineering and Technology, Taxila, Pakistan; Cerebrai Artificial Intelligence, Surrey, United Kingdom","Qayyum A., Department of Computer Engineering, University of Engineering and Technology, Taxila, Pakistan; Anwar S.M., Department of Software Engineering, University of Engineering and Technology, Taxila, Pakistan, Signal, Image, Multimedia Processing and Learning (SIMPLE) Group, University of Engineering and Technology, Taxila, Pakistan; Awais M., Center for Vision, Speech and Signal Processing, University of Surrey, Surrey, United Kingdom, Cerebrai Artificial Intelligence, Surrey, United Kingdom; Majid M., Department of Computer Engineering, University of Engineering and Technology, Taxila, Pakistan, Signal, Image, Multimedia Processing and Learning (SIMPLE) Group, University of Engineering and Technology, Taxila, Pakistan","With a widespread use of digital imaging data in hospitals, the size of medical image repositories is increasing rapidly. This causes difficulty in managing and querying these large databases leading to the need of content based medical image retrieval (CBMIR) systems. A major challenge in CBMIR systems is the semantic gap that exists between the low level visual information captured by imaging devices and high level semantic information perceived by human. The efficacy of such systems is more crucial in terms of feature representations that can characterize the high-level information completely. In this paper, we propose a framework of deep learning for CBMIR system by using deep convolutional neural network (CNN) that is trained for classification of medical images. An intermodal dataset that contains twenty-four classes and five modalities is used to train the network. The learned features and the classification results are used to retrieve medical images. For retrieval, best results are achieved when class based predictions are used. An average classification accuracy of 99.77% and a mean average precision of 0.69 is achieved for retrieval task. The proposed method is best suited to retrieve multimodal medical images for different body organs. © 2017","Content based medical image retrieval (CBMIR); Convolutional neural networks (CNNs); Deep learning; Similarity metric","Convolution; Deep learning; Deep neural networks; Image retrieval; Medical imaging; Neural networks; Semantics; Classification accuracy; Classification results; Content based medical image retrieval; Convolutional neural network; Feature representation; High-level information; Multimodal medical images; Similarity metrics; accuracy; Article; artificial neural network; conceptual framework; content based image retrieval; content based medical image retrieval; convolutional neural network; human; image processing; image retrieval; machine learning; prediction; priority journal; Search engines","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85019914033"
"Wang A.; Wang J.; Lin H.; Zhang J.; Yang Z.; Xu K.","Wang, Anran (57193354806); Wang, Jian (55934279300); Lin, Hongfei (24468572400); Zhang, Jianhai (57214899744); Yang, Zhihao (16029941200); Xu, Kan (48762086600)","57193354806; 55934279300; 24468572400; 57214899744; 16029941200; 48762086600","A multiple distributed representation method based on neural network for biomedical event extraction","2017","BMC Medical Informatics and Decision Making","29","10.1186/s12911-017-0563-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038939080&doi=10.1186%2fs12911-017-0563-9&partnerID=40&md5=de035e0fc6d7c2158966ce284baac34a","School of Computer Science and Technology, Dalian University of Technology, Dalian, China","Wang A., School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Wang J., School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Lin H., School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Zhang J., School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Yang Z., School of Computer Science and Technology, Dalian University of Technology, Dalian, China; Xu K., School of Computer Science and Technology, Dalian University of Technology, Dalian, China","Background: Biomedical event extraction is one of the most frontier domains in biomedical research. The two main subtasks of biomedical event extraction are trigger identification and arguments detection which can both be considered as classification problems. However, traditional state-of-the-art methods are based on support vector machine (SVM) with massive manually designed one-hot represented features, which require enormous work but lack semantic relation among words. Methods: In this paper, we propose a multiple distributed representation method for biomedical event extraction. The method combines context consisting of dependency-based word embedding, and task-based features represented in a distributed way as the input of deep learning models to train deep learning models. Finally, we used softmax classifier to label the example candidates. Results: The experimental results on Multi-Level Event Extraction (MLEE) corpus show higher F-scores of 77.97% in trigger identification and 58.31% in overall compared to the state-of-the-art SVM method. Conclusions: Our distributed representation method for biomedical event extraction avoids the problems of semantic gap and dimension disaster from traditional one-hot representation methods. The promising results demonstrate that our proposed method is effective for biomedical event extraction. © 2017 The Author(s).","Biomedical event extraction; Convolutional neural network; Deep learning; Distributed representation","Biomedical Research; Humans; Machine Learning; Models, Theoretical; Neural Networks (Computer); disaster; embedding; extraction; learning; nervous system; support vector machine; artificial neural network; human; machine learning; medical research; procedures; theoretical model","BioMed Central Ltd","14726947","","","29297321","Article","Scopus","2-s2.0-85038939080"
"Fuller D.; Buote R.; Stanley K.","Fuller, Daniel (36473248400); Buote, Richard (57190763173); Stanley, Kevin (55389914100)","36473248400; 57190763173; 55389914100","A glossary for big data in population and public health: Discussion and commentary on terminology and research methods","2017","Journal of Epidemiology and Community Health","21","10.1136/jech-2017-209608","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031786632&doi=10.1136%2fjech-2017-209608&partnerID=40&md5=da036bc9e142236745e04d435f32b806","School of Human Kinetics and Recreation, Memorial University of Newfoundland, Saint John's, Canada; Division of Community Health and Humanities, Faculty of Medicine, Memorial University of Newfoundland, St John's, Canada; Department of Computer Science, College of Arts and Science, University of Saskatchewan, Saskatoon, Canada","Fuller D., School of Human Kinetics and Recreation, Memorial University of Newfoundland, Saint John's, Canada; Buote R., Division of Community Health and Humanities, Faculty of Medicine, Memorial University of Newfoundland, St John's, Canada; Stanley K., Department of Computer Science, College of Arts and Science, University of Saskatchewan, Saskatoon, Canada","The volume and velocity of data are growing rapidly and big data analytics are being applied to these data in many fields. Population and public health researchers may be unfamiliar with the terminology and statistical methods used in big data. This creates a barrier to the application of big data analytics. The purpose of this glossary is to define terms used in big data and big data analytics and to contextualise these terms. We define the five Vs of big data and provide definitions and distinctions for data mining, machine learning and deep learning, among other terms. We provide key distinctions between big data and statistical analysis methods applied to big data. We contextualise the glossary by providing examples where big data analysis methods have been applied to population and public health research problems and provide brief guidance on how to learn big data analysis methods. © Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2017.","","Data Interpretation, Statistical; Data Mining; Databases, Factual; Delivery of Health Care; Electronic Health Records; Humans; Public Health; Research Design; Statistics as Topic; Terminology as Topic; data interpretation; data mining; machine learning; public health; research method; statistical analysis; terminology; data analysis; data mining; human; machine learning; nomenclature; public health; statistical analysis; electronic health record; factual database; health care delivery; methodology; nomenclature; organization and management; procedures; public health; standards; statistics","BMJ Publishing Group","0143005X","","JECHD","28918390","Article","Scopus","2-s2.0-85031786632"
"Ting D.S.W.; Cheung C.Y.-L.; Lim G.; Tan G.S.W.; Quang N.D.; Gan A.; Hamzah H.; Garcia-Franco R.; Yeo I.Y.S.; Lee S.Y.; Wong E.Y.M.; Sabanayagam C.; Baskaran M.; Ibrahim F.; Tan N.C.; Finkelstein E.A.; Lamoureux E.L.; Wong I.Y.; Bressler N.M.; Sivaprasad S.; Varma R.; Jonas J.B.; He M.G.; Cheng C.-Y.; Cheung G.C.M.; Aung T.; Hsu W.; Lee M.L.; Wong T.Y.","Ting, Daniel Shu Wei (37010354600); Cheung, Carol Yim-Lui (35276903300); Lim, Gilbert (57188817284); Tan, Gavin Siew Wei (34972108600); Quang, Nguyen D. (57199833994); Gan, Alfred (57192941316); Hamzah, Haslina (36186810000); Garcia-Franco, Renata (6505575799); Yeo, Ian Yew San (7007017604); Lee, Shu Yen (8908145500); Wong, Edmund Yick Mun (7403161598); Sabanayagam, Charumathi (22136294700); Baskaran, Mani (7004985122); Ibrahim, Farah (57226131190); Tan, Ngiap Chuan (7202697085); Finkelstein, Eric A. (7005845861); Lamoureux, Ecosse L. (7003839871); Wong, Ian Y. (36490557200); Bressler, Neil M. (7005055349); Sivaprasad, Sobha (35547907400); Varma, Rohit (7201793519); Jonas, Jost B. (7202492953); He, Ming Guang (15765257500); Cheng, Ching-Yu (55539712500); Cheung, Gemmy Chui Ming (7202061785); Aung, Tin (26643141900); Hsu, Wynne (7402002763); Lee, Mong Li (7409117252); Wong, Tien Yin (7403147159)","37010354600; 35276903300; 57188817284; 34972108600; 57199833994; 57192941316; 36186810000; 6505575799; 7007017604; 8908145500; 7403161598; 22136294700; 7004985122; 57226131190; 7202697085; 7005845861; 7003839871; 36490557200; 7005055349; 35547907400; 7201793519; 7202492953; 15765257500; 55539712500; 7202061785; 26643141900; 7402002763; 7409117252; 7403147159","Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes","2017","JAMA - Journal of the American Medical Association","1374","10.1001/jama.2017.18152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038438910&doi=10.1001%2fjama.2017.18152&partnerID=40&md5=01578b7b226eb6c48188cbeb70af4e33","Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore; Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Department of Ophthalmology and Visual Sciences, Chinese University of Hong Kong, Hong Kong, Hong Kong; School of Computing, National University of Singapore, Singapore; Instituto Mexicano De Oftalmologia, IAP, Queretaro, Mexico; SingHealth Polyclinic, Singapore Health Service, Singapore, Singapore; Lien Center for Palliative Care, Health Services and Systems Research Program, Duke-NUS Graduate Medical School, Singapore, Singapore; Department of Ophthalmology, University of Hong Kong, Hong Kong, Hong Kong; Johns Hopkins Wilmer Eye Institute, Baltimore, MD, United States; Moorfields Eye Hospital National Health Service Foundation Trust, London, United Kingdom; University of Southern California, Gayle and Edward Roski Eye Institute, Los Angeles, CA, United States; Department of Ophthalmology, Ruprecht-Karls University of Heidelberg, Heidelberg, Germany; State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Centre, Sun Yatsen University, Guangzhou, China","Ting D.S.W., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Cheung C.Y.-L., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Department of Ophthalmology and Visual Sciences, Chinese University of Hong Kong, Hong Kong, Hong Kong; Lim G., School of Computing, National University of Singapore, Singapore; Tan G.S.W., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Quang N.D., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore; Gan A., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore; Hamzah H., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore; Garcia-Franco R., Instituto Mexicano De Oftalmologia, IAP, Queretaro, Mexico; Yeo I.Y.S., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Lee S.Y., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Wong E.Y.M., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Sabanayagam C., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Baskaran M., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Ibrahim F., Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Tan N.C., Duke-NUS Medical School, National University of Singapore, Singapore, Singapore, SingHealth Polyclinic, Singapore Health Service, Singapore, Singapore; Finkelstein E.A., Lien Center for Palliative Care, Health Services and Systems Research Program, Duke-NUS Graduate Medical School, Singapore, Singapore; Lamoureux E.L., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Wong I.Y., Department of Ophthalmology, University of Hong Kong, Hong Kong, Hong Kong; Bressler N.M., Johns Hopkins Wilmer Eye Institute, Baltimore, MD, United States; Sivaprasad S., Moorfields Eye Hospital National Health Service Foundation Trust, London, United Kingdom; Varma R., University of Southern California, Gayle and Edward Roski Eye Institute, Los Angeles, CA, United States; Jonas J.B., Department of Ophthalmology, Ruprecht-Karls University of Heidelberg, Heidelberg, Germany; He M.G., State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Centre, Sun Yatsen University, Guangzhou, China; Cheng C.-Y., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Cheung G.C.M., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Aung T., Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Hsu W., School of Computing, National University of Singapore, Singapore; Lee M.L., School of Computing, National University of Singapore, Singapore; Wong T.Y., Singapore Eye Research Institute, Singapore National Eye Center, 11 Third Hospital Ave, Singapore, 168751, Singapore, Duke-NUS Medical School, National University of Singapore, Singapore, Singapore","IMPORTANCE: A deep learning system (DLS) is a machine learning technology with potential for screening diabetic retinopathy and related eye diseases. OBJECTIVE: To evaluate the performance of a DLS in detecting referable diabetic retinopathy, vision-threatening diabetic retinopathy, possible glaucoma, and age-related macular degeneration (AMD) in community and clinic-based multiethnic populations with diabetes. DESIGN, SETTING, AND PARTICIPANTS: Diagnostic performance of a DLS for diabetic retinopathy and related eye diseases was evaluated using 494 661 retinal images. A DLS was trained for detectingdiabetic retinopathy (using 76 370 images), possible glaucoma (125189 images), and AMD (72 610 images), and performance of DLS was evaluated for detecting diabetic retinopathy (using 112 648 images), possible glaucoma (71896 images), and AMD (35 948 images). Training of the DLS was completed in May 2016, and validation of the DLS was completed in May 2017 for detection of referable diabetic retinopathy (moderate nonproliferative diabetic retinopathy or worse) and vision-threateningdiabetic retinopathy (severe nonproliferative diabetic retinopathy or worse) using a primary validation data set in the Singapore National Diabetic Retinopathy Screening Program and 10 multiethnic cohorts with diabetes. EXPOSURES: Use of a deep learning system. MAIN OUTCOMES AND MEASURES: Area under the receiver operating characteristic curve (AUC) and sensitivity and specificity of the DLS with professional graders (retinal specialists, general ophthalmologists, trained graders, or optometrists) as the reference standard. RESULTS: In the primary validation dataset (n = 14 880 patients; 71 896 images; mean [SD] age, 60.2 [2.2] years; 54.6% men), the prevalence of referable diabetic retinopathy was 3.0%; vision-threatening diabetic retinopathy, 0.6%; possible glaucoma, 0.1%; and AMD 2.5%. The AUC of the DLS for referable diabetic retinopathy was 0.936 (95% CI, 0.925-0.943), sensitivity was 90.5% (95% CI, 873%-93.0%), and specificity was 91.6% (95% CI, 91.0%-92.2%). For vision-threatening diabetic retinopathy, AUC was 0.958 (95% CI, 0.956-0.961), sensitivity was 100% (95% CI, 94.1%-100.0%), and specificity was 91.1% (95% CI, 90.7%-91.4%). For possible glaucoma, AUC was 0.942 (95% CI, 0.929-0.954), sensitivity was 96.4% (95% CI, 81.7%-99.9%), and specificity was 87.2% (95% CI, 86.8%-875%). For AMD AUC was 0.931 (95% CI, 0.928-0.935), sensitivity was 93.2% (95% CI, 91.1%-99.8%), and specificity was 88.7% (95% CI, 88.3%-89.0%). For referable diabetic retinopathy in the 10 additional datasets, AUC range was 0.889 to 0.983 (n = 40 752 images). CONCLUSIONS AND RELEVANCE: In this evaluation of retinal images from multiethnic cohorts of patients with diabetes, the DLS had high sensitivity and specificity for identifying diabetic retinopathy and related eye diseases. Further research is necessary to evaluate the applicability of the DLS in health care settings and the utility of the DLS to improve vision outcomes. © 2017 American Medical Association. All rights reserved.","","Area Under Curve; Datasets as Topic; Diabetes Mellitus; Diabetic Retinopathy; Eye Diseases; Female; Glaucoma; Humans; Machine Learning; Male; Middle Aged; Retina; ROC Curve; Sensitivity and Specificity; accreditation; adult; age related macular degeneration; area under the curve; Article; cohort analysis; controlled study; deep learning system; diabetic retinopathy; diagnostic procedure; diagnostic test accuracy study; disease severity; female; glaucoma; human; machine learning; major clinical study; male; ophthalmologist; optometrist; priority journal; retina examination; retina image; sensitivity and specificity; standard; validation process; comparative study; diabetes mellitus; diabetic retinopathy; diagnostic imaging; ethnology; eye disease; glaucoma; information processing; middle aged; pathology; receiver operating characteristic; retina; validation study","American Medical Association","00987484","","JAMAA","29234807","Article","Scopus","2-s2.0-85038438910"
"Liu J.; Osadchy M.; Ashton L.; Foster M.; Solomon C.J.; Gibson S.J.","Liu, Jinchao (50461986900); Osadchy, Margarita (6603646259); Ashton, Lorna (8341036300); Foster, Michael (57654202100); Solomon, Christopher J. (7102812437); Gibson, Stuart J. (9040731300)","50461986900; 6603646259; 8341036300; 57654202100; 7102812437; 9040731300","Deep convolutional neural networks for Raman spectrum recognition: A unified solution","2017","Analyst","312","10.1039/c7an01371j","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032280695&doi=10.1039%2fc7an01371j&partnerID=40&md5=41e6c7a5b343c13e798281786af04044","VisionMetric Ltd., Canterbury, Kent, CT2 7FG, United Kingdom; Department of Computer Science, University of Haifa Mount Carmel, Haifa, 31905, Israel; Department of Chemistry, Lancaster University Bailrigg, Lancaster, LA1 4YW, United Kingdom; IS-Instruments Ltd., 220 Vale Road, Tonbridge Kent, TN9 1SP, United Kingdom; School of Physical Sciences, University of Kent, Canterbury, CT2 7NH, United Kingdom","Liu J., VisionMetric Ltd., Canterbury, Kent, CT2 7FG, United Kingdom; Osadchy M., Department of Computer Science, University of Haifa Mount Carmel, Haifa, 31905, Israel; Ashton L., Department of Chemistry, Lancaster University Bailrigg, Lancaster, LA1 4YW, United Kingdom; Foster M., IS-Instruments Ltd., 220 Vale Road, Tonbridge Kent, TN9 1SP, United Kingdom; Solomon C.J., School of Physical Sciences, University of Kent, Canterbury, CT2 7NH, United Kingdom; Gibson S.J., School of Physical Sciences, University of Kent, Canterbury, CT2 7NH, United Kingdom","Machine learning methods have found many applications in Raman spectroscopy, especially for the identification of chemical species. However, almost all of these methods require non-trivial preprocessing such as baseline correction and/or PCA as an essential step. Here we describe our unified solution for the identification of chemical species in which a convolutional neural network is trained to automatically identify substances according to their Raman spectrum without the need for preprocessing. We evaluated our approach using the RRUFF spectral database, comprising mineral sample data. Superior classification performance is demonstrated compared with other frequently used machine learning algorithms including the popular support vector machine method. © 2017 The Royal Society of Chemistry.","","","Royal Society of Chemistry","00032654","","ANALA","28993828","Article","Scopus","2-s2.0-85032280695"
"Maxwell A.; Li R.; Yang B.; Weng H.; Ou A.; Hong H.; Zhou Z.; Gong P.; Zhang C.","Maxwell, Andrew (55877170700); Li, Runzhi (13409528300); Yang, Bei (57200115803); Weng, Heng (56516194900); Ou, Aihua (21733762200); Hong, Huixiao (7401521704); Zhou, Zhaoxian (56141233100); Gong, Ping (55982343800); Zhang, Chaoyang (7405496346)","55877170700; 13409528300; 57200115803; 56516194900; 21733762200; 7401521704; 56141233100; 55982343800; 7405496346","Deep learning architectures for multi-label classification of intelligent health risk prediction","2017","BMC Bioinformatics","101","10.1186/s12859-017-1898-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039757640&doi=10.1186%2fs12859-017-1898-z&partnerID=40&md5=046c5277d5f35120565a276efb2aac68","School of Computing, University of Southern Mississippi, Hattiesburg, 39406, MS, United States; School of Information and Engineering, Zhengzhou University, Cooperative Innovation Center of Internet Healthcare, Zhengzhou, 450000, China; The Second Affiliated Hospital of Guangzhou University of Chinese Medicine, Department of Big Medical Data, Health Construction Administration Center, Guangzhou, China; Division of Bioinformatics and Biostatistics, National Center for Toxicological Research, US Food and Drug Administration (FDA), Jefferson, 72079, AR, United States; Environmental Lab, US Army Engineer Research and Development Center, Vicksburg, 39180, MS, United States","Maxwell A., School of Computing, University of Southern Mississippi, Hattiesburg, 39406, MS, United States; Li R., School of Information and Engineering, Zhengzhou University, Cooperative Innovation Center of Internet Healthcare, Zhengzhou, 450000, China; Yang B., School of Information and Engineering, Zhengzhou University, Cooperative Innovation Center of Internet Healthcare, Zhengzhou, 450000, China; Weng H., The Second Affiliated Hospital of Guangzhou University of Chinese Medicine, Department of Big Medical Data, Health Construction Administration Center, Guangzhou, China; Ou A., The Second Affiliated Hospital of Guangzhou University of Chinese Medicine, Department of Big Medical Data, Health Construction Administration Center, Guangzhou, China; Hong H., Division of Bioinformatics and Biostatistics, National Center for Toxicological Research, US Food and Drug Administration (FDA), Jefferson, 72079, AR, United States; Zhou Z., School of Computing, University of Southern Mississippi, Hattiesburg, 39406, MS, United States; Gong P., Environmental Lab, US Army Engineer Research and Development Center, Vicksburg, 39180, MS, United States; Zhang C., School of Computing, University of Southern Mississippi, Hattiesburg, 39406, MS, United States","Background: Multi-label classification of data remains to be a challenging problem. Because of the complexity of the data, it is sometimes difficult to infer information about classes that are not mutually exclusive. For medical data, patients could have symptoms of multiple different diseases at the same time and it is important to develop tools that help to identify problems early. Intelligent health risk prediction models built with deep learning architectures offer a powerful tool for physicians to identify patterns in patient data that indicate risks associated with certain types of chronic diseases. Results: Physical examination records of 110,300 anonymous patients were used to predict diabetes, hypertension, fatty liver, a combination of these three chronic diseases, and the absence of disease (8 classes in total). The dataset was split into training (90%) and testing (10%) sub-datasets. Ten-fold cross validation was used to evaluate prediction accuracy with metrics such as precision, recall, and F-score. Deep Learning (DL) architectures were compared with standard and state-of-the-art multi-label classification methods. Preliminary results suggest that Deep Neural Networks (DNN), a DL architecture, when applied to multi-label classification of chronic diseases, produced accuracy that was comparable to that of common methods such as Support Vector Machines. We have implemented DNNs to handle both problem transformation and algorithm adaption type multi-label methods and compare both to see which is preferable. Conclusions: Deep Learning architectures have the potential of inferring more information about the patterns of physical examination data than common classification methods. The advanced techniques of Deep Learning can be used to identify the significance of different features from physical examination data as well as to learn the contributions of each feature that impact a patient's risk for chronic diseases. However, accurate prediction of chronic disease risks remains a challenging problem that warrants further studies. © 2017 The Author(s).","Deep learning; Deep neural networks; Intelligent health risk prediction; Medical health records; Multi-label classification","Algorithms; Chronic Disease; Deep Learning; Health; Humans; Neural Networks (Computer); Risk Assessment; ROC Curve; Support Vector Machine; Deep learning; Deep neural networks; Diseases; Forecasting; Health; Health risks; Hospital data processing; Medical problems; Network architecture; Statistical tests; Accurate prediction; Classification methods; Learning architectures; Medical health; Multi label classification; Problem transformations; Risk prediction models; Risk predictions; algorithm; artificial neural network; chronic disease; health; human; receiver operating characteristic; risk assessment; support vector machine; Classification (of information)","BioMed Central Ltd.","14712105","","BBMIC","29297288","Article","Scopus","2-s2.0-85039757640"
"Zhou F.; Wu F.; Zhang Z.; Dong M.","Zhou, Fugen (23468179000); Wu, Fuxiang (56890093600); Zhang, Zhengchen (36700700300); Dong, Minghui (14017760900)","23468179000; 56890093600; 36700700300; 14017760900","Node-level parallelization for deep neural networks with conditional independent graph","2017","Neurocomputing","5","10.1016/j.neucom.2017.06.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020842908&doi=10.1016%2fj.neucom.2017.06.002&partnerID=40&md5=b5581e54b0e2d8ad83bae5269362322c","Beihang University, XueYuan Road No. 37, HaiDian District, Beijing, China; R), Agency for Science, Technology and Research, Singapore","Zhou F., Beihang University, XueYuan Road No. 37, HaiDian District, Beijing, China; Wu F., Beihang University, XueYuan Road No. 37, HaiDian District, Beijing, China; Zhang Z., R), Agency for Science, Technology and Research, Singapore; Dong M., R), Agency for Science, Technology and Research, Singapore","Deep neural networks require high performance computing and highly effective implementation to constrain the running time into a reasonable range. We proposed a novel node-level parallelization, conditional independent parallelization, of the forward and backward propagations to improve the level of concurrency. The propagations exploit a conditional independent graph (CIG) built in O(N) times, which consists of conditional independent sets of nodes. Each set in the CIG is sequentially visited, while the nodes in the set are calculated concurrently. Besides, we analyze the properties of the CIG and prove the correctness of the propagations with the CIG, then study the theoretical speedup ratios of the parallelization. Moreover, this parallelism can be applied to arbitrary structures of neural networks without influencing convergence, which only needs a conditional independent graph. It can be further integrated into other frameworks with batch-level and data-level parallelism to improve the level of concurrency. Since modern GPU supports concurrent kernels, the parallelization can also be implemented on GPU directly. To verify the parallelization in experiments, we implement an autoencoder, a dependency parser and an image recognizer with the parallelization and test them on a 4-core CPU I7 4790K with 32 GB memory. The results demonstrate that it can achieve maximum speedups of 3.965 × for the autoencoder, of 3.106 × for the parsing and of 2.966 × for the recognizer. © 2017 Elsevier B.V.","Concurrent kernels; Conditional independent graph; Deep neural networks; Node-level parallelization; OpenMP","Application programming interfaces (API); Graph theory; Learning systems; Arbitrary structures; Concurrent kernels; Conditional independent graph; Data-level parallelism; Forward-and-backward; High performance computing; OpenMP; Parallelizations; Article; artificial neural network; automation; back propagation; conditional independent graph; deep neural network; image processing; kernel method; machine learning; node level parallelization; nonlinear system; pattern recognition; priority journal; process optimization; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85020842908"
"Huang Y.; Zheng H.; Liu C.; Ding X.; Rohde G.K.","Huang, Yue (55021805400); Zheng, Han (57194874624); Liu, Chi (56477565600); Ding, Xinghao (21833592600); Rohde, Gustavo K. (7003382291)","55021805400; 57194874624; 56477565600; 21833592600; 7003382291","Epithelium-stroma classification via convolutional neural networks and unsupervised domain adaptation in histopathological images","2017","IEEE Journal of Biomedical and Health Informatics","62","10.1109/JBHI.2017.2691738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035810135&doi=10.1109%2fJBHI.2017.2691738&partnerID=40&md5=420957eae8ab7975bb371eba7d1b2849","School of Information Science and Engineering, Xiamen University, Xiamen, 361005, China; Department of Biomedical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Electrical Engineering Department, Biomedical Engineering Department, University of Virginia, 22903, VA, United States","Huang Y., School of Information Science and Engineering, Xiamen University, Xiamen, 361005, China; Zheng H., School of Information Science and Engineering, Xiamen University, Xiamen, 361005, China; Liu C., Department of Biomedical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Ding X., School of Information Science and Engineering, Xiamen University, Xiamen, 361005, China; Rohde G.K., Electrical Engineering Department, Biomedical Engineering Department, University of Virginia, 22903, VA, United States","Epithelium-stroma classification is a necessary preprocessing step in histopathological image analysis. Current deep learning based recognition methods for histology data require collection of large volumes of labeled data in order to train a new neural network when there are changes to the image acquisition procedure. However, it is extremely expensive for pathologists to manually label sufficient volumes of data for each pathology study in a professional manner, which results in limitations in real-world applications. A very simple but effective deep learning method, that introduces the concept of unsupervised domain adaptation to a simple convolutional neural network (CNN), has been proposed in this paper. Inspired by transfer learning, our paper assumes that the training data and testing data follow different distributions, and there is an adaptation operation to more accurately estimate the kernels in CNN in feature extraction, in order to enhance performance by transferring knowledge from labeled data in source domain to unlabeled data in target domain. The model has been evaluated using three independent public epithelium-stroma datasets by cross-dataset validations. The experimental results demonstrate that for epithelium-stroma classification, the proposed framework outperforms the state-of-the-art deep neural network model, and it also achieves better performance than other existing deep domain adaptation methods. The proposed model can be considered to be a better option for real-world applications in histopathological image analysis, since there is no longer a requirement for large-scale labeled data in each specified domain. © 2013 IEEE.","Convolutional neural networks; domain adaptation; epithelium-stroma classification; histopathological image analysis; transfer learning","Algorithms; Breast Neoplasms; Connective Tissue; Epithelium; Female; Histocytochemistry; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Convolution; Deep learning; Deep neural networks; Image analysis; Image classification; Labeled data; Learning systems; Transfer learning; Different distributions; Domain adaptation; Histopathological image analysis; Histopathological images; Neural network model; Pre-processing step; Professional manner; Recognition methods; classification; epithelium; extraction; human; image analysis; learning; nervous system; stroma; validation process; algorithm; artificial neural network; breast tumor; connective tissue; cytochemistry; diagnostic imaging; epithelium; female; image processing; machine learning; pathology; procedures; Convolutional neural networks","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28410112","Article","Scopus","2-s2.0-85035810135"
"Min X.; Zeng W.; Chen S.; Chen N.; Chen T.; Jiang R.","Min, Xu (57193353206); Zeng, Wanwen (57189046061); Chen, Shengquan (57198359439); Chen, Ning (58102051400); Chen, Ting (55687667200); Jiang, Rui (57200775668)","57193353206; 57189046061; 57198359439; 58102051400; 55687667200; 57200775668","Predicting enhancers with deep convolutional neural networks","2017","BMC Bioinformatics","67","10.1186/s12859-017-1878-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036450976&doi=10.1186%2fs12859-017-1878-3&partnerID=40&md5=539a70b0d01bb22634976c25586c4839","MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China; Tsinghua University, Department of Computer Science and Technology, State Key Lab of Intelligent Technology and Systems, Beijing, 100084, China; Tsinghua University, Department of Automation, Beijing, 100084, China; University of Southern California, Program in Computational Biology and Bioinformatics, Los Angeles, 90089, CA, United States","Min X., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China, Tsinghua University, Department of Computer Science and Technology, State Key Lab of Intelligent Technology and Systems, Beijing, 100084, China; Zeng W., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China, Tsinghua University, Department of Automation, Beijing, 100084, China; Chen S., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China, Tsinghua University, Department of Automation, Beijing, 100084, China; Chen N., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China, Tsinghua University, Department of Computer Science and Technology, State Key Lab of Intelligent Technology and Systems, Beijing, 100084, China; Chen T., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China, Tsinghua University, Department of Computer Science and Technology, State Key Lab of Intelligent Technology and Systems, Beijing, 100084, China, University of Southern California, Program in Computational Biology and Bioinformatics, Los Angeles, 90089, CA, United States; Jiang R., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST, Beijing, 100084, China, Tsinghua University, Department of Automation, Beijing, 100084, China","Background: With the rapid development of deep sequencing techniques in the recent years, enhancers have been systematically identified in such projects as FANTOM and ENCODE, forming genome-wide landscapes in a series of human cell lines. Nevertheless, experimental approaches are still costly and time consuming for large scale identification of enhancers across a variety of tissues under different disease status, making computational identification of enhancers indispensable. Results: To facilitate the identification of enhancers, we propose a computational framework, named DeepEnhancer, to distinguish enhancers from background genomic sequences. Our method purely relies on DNA sequences to predict enhancers in an end-to-end manner by using a deep convolutional neural network (CNN). We train our deep learning model on permissive enhancers and then adopt a transfer learning strategy to fine-tune the model on enhancers specific to a cell line. Results demonstrate the effectiveness and efficiency of our method in the classification of enhancers against random sequences, exhibiting advantages of deep learning over traditional sequence-based classifiers. We then construct a variety of neural networks with different architectures and show the usefulness of such techniques as max-pooling and batch normalization in our method. To gain the interpretability of our approach, we further visualize convolutional kernels as sequence logos and successfully identify similar motifs in the JASPAR database. Conclusions: DeepEnhancer enables the identification of novel enhancers using only DNA sequences via a highly accurate deep learning model. The proposed computational framework can also be applied to similar problems, thereby prompting the use of machine learning methods in life sciences. © 2017 The Author(s).","","Algorithms; Computational Biology; Databases, Factual; DNA; Enhancer Elements, Genetic; Genome, Human; Genomics; Humans; Machine Learning; Models, Genetic; Neural Networks (Computer); Cell culture; Classification (of information); Convolution; Deep learning; DNA sequences; Genes; Learning systems; Neural networks; DNA; Computational framework; Computational identification; Convolutional kernel; Convolutional neural network; Effectiveness and efficiencies; Experimental approaches; Machine learning methods; Transfer learning; algorithm; artificial neural network; biological model; biology; chemistry; enhancer region; factual database; genetics; genomics; human; human genome; machine learning; Deep neural networks","BioMed Central Ltd.","14712105","","BBMIC","29219068","Article","Scopus","2-s2.0-85036450976"
"Ye C.","Ye, Chuyang (49865215200)","49865215200","Tissue microstructure estimation using a deep network inspired by a dictionary-based framework","2017","Medical Image Analysis","30","10.1016/j.media.2017.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029031282&doi=10.1016%2fj.media.2017.09.001&partnerID=40&md5=1b99700c7cd9638e726a9534926251f7","Brainnetome Center, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","Ye C., Brainnetome Center, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","Diffusion magnetic resonance imaging (dMRI) captures the anisotropic pattern of water displacement in the neuronal tissue and allows noninvasive investigation of the complex tissue microstructure. A number of biophysical models have been proposed to relate the tissue organization with the observed diffusion signals, so that the tissue microstructure can be inferred. The Neurite Orientation Dispersion and Density Imaging (NODDI) model has been a popular choice and has been widely used for many neuroscientific studies. It models the diffusion signal with three compartments that are characterized by distinct diffusion properties, and the parameters in the model describe tissue microstructure. In NODDI, these parameters are estimated in a maximum likelihood framework, where the nonlinear model fitting is computationally intensive. Therefore, efforts have been made to develop efficient and accurate algorithms for NODDI microstructure estimation, which is still an open problem. In this work, we propose a deep network based approach that performs end-to-end estimation of NODDI microstructure, which is named Microstructure Estimation using a Deep Network (MEDN). MEDN comprises two cascaded stages and is motivated by the AMICO algorithm, where the NODDI microstructure estimation is formulated in a dictionary-based framework. The first stage computes the coefficients of the dictionary. It resembles the solution to a sparse reconstruction problem, where the iterative process in conventional estimation approaches is unfolded and truncated, and the weights are learned instead of predetermined by the dictionary. In the second stage, microstructure properties are computed from the output of the first stage, which resembles the weighted sum of normalized dictionary coefficients in AMICO, and the weights are also learned. Because spatial consistency of diffusion signals can be used to reduce the effect of noise, we also propose MEDN+, which is an extended version of MEDN. MEDN+ allows incorporation of neighborhood information by inserting a stage with learned weights before the MEDN structure, where the diffusion signals in the neighborhood of a voxel are processed. The weights in MEDN or MEDN+ are jointly learned from training samples that are acquired with diffusion gradients densely sampling the q-space. We performed MEDN and MEDN+ on brain dMRI scans, where two shells each with 30 gradient directions were used, and measured their accuracy with respect to the gold standard. Results demonstrate that the proposed networks outperform the competing methods. © 2017 Elsevier B.V.","Deep network; Diffusion MRI; NODDI; Sparse reconstruction; Tissue microstructure","Algorithms; Anisotropy; Connectome; Diffusion Magnetic Resonance Imaging; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Machine Learning; Neuroimaging; Biomedical signal processing; Diffusion; Iterative methods; Magnetic levitation vehicles; Magnetic resonance imaging; Maximum likelihood estimation; Microstructure; Neurons; Deep networks; Diffusion mris; NODDI; Sparse reconstruction; Tissue microstructures; accuracy; algorithm; Article; book; diffusion; noise; priority journal; tissue structure; anisotropy; computer assisted diagnosis; connectome; diffusion weighted imaging; human; image enhancement; machine learning; neuroimaging; procedures; Tissue","Elsevier B.V.","13618415","","MIAEC","28910696","Article","Scopus","2-s2.0-85029031282"
"Sun W.; Zhao H.; Jin Z.","Sun, Wenyun (57193737107); Zhao, Haitao (58090034600); Jin, Zhong (36915349100)","57193737107; 58090034600; 36915349100","An efficient unconstrained facial expression recognition algorithm based on Stack Binarized Auto-encoders and Binarized Neural Networks","2017","Neurocomputing","33","10.1016/j.neucom.2017.06.050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021789014&doi=10.1016%2fj.neucom.2017.06.050&partnerID=40&md5=d786e703a217b984cee1857c6387a10e","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China","Sun W., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Zhao H., School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; Jin Z., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","Although deep learning has achieved good performances in many pattern recognition tasks, the over-fitting problem is still a serious issue for training deep networks containing large sets of parameters with limited labeled data. In this work, Binarized Auto-encoders (BAEs) and Stacked Binarized Auto-encoders (Stacked BAEs) are proposed to learn a kind of domain knowledge from a large-scale unlabeled facial dataset. By transferring the knowledge to another Binarized Neural Networks (BNNs) based supervised learning task with limited labeled data, the performance of the BNNs can be improved. A real-world facial expression recognition system is constructed by combining an unconstrained face normalization method, a variant of LBP descriptor, BAEs and BNNs. The experiment result shows that the whole system achieves good performance on the Static Facial Expressions in the Wild (SFEW) benchmark with minimal hardware requirements and lower memory and computation costs. © 2017 Elsevier B.V.","Binarized Auto-encoder; Facial expression recognition; Unconstrained face","Benchmarking; Bins; Deep learning; Education; Learning systems; Pattern recognition; Auto encoders; Computation costs; Domain knowledge; Face normalization; Facial expression recognition; Facial Expressions; Over fitting problem; Unconstrained face; algorithm; Article; Binarized Neural Network; classifier; controlled study; data augmentation; facial expression recognition algorithm; information processing; intermethod comparison; multi scale dense local binary patterns; priority journal; Stack Binarized Auto encoders; static facial expressions in the wild; support vector machine; Face recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85021789014"
"Naito T.; Nagashima Y.; Taira K.; Uchio N.; Tsuji S.; Shimizu J.","Naito, Tatsuhiko (56900561000); Nagashima, Yu (54916087400); Taira, Kenichiro (57194579728); Uchio, Naohiro (56993957800); Tsuji, Shoji (55520355200); Shimizu, Jun (55178982100)","56900561000; 54916087400; 57194579728; 56993957800; 55520355200; 55178982100","Identification and segmentation of myelinated nerve fibers in a cross-sectional optical microscopic image using a deep learning model","2017","Journal of Neuroscience Methods","18","10.1016/j.jneumeth.2017.08.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028066929&doi=10.1016%2fj.jneumeth.2017.08.014&partnerID=40&md5=bc9133f12a6b7226cdef016281e4349c","The Department of Neurology, The University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 1138655, Japan","Naito T., The Department of Neurology, The University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 1138655, Japan; Nagashima Y., The Department of Neurology, The University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 1138655, Japan; Taira K., The Department of Neurology, The University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 1138655, Japan; Uchio N., The Department of Neurology, The University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 1138655, Japan; Tsuji S., The Department of Neurology, The University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 1138655, Japan; Shimizu J., The Department of Neurology, The University of Tokyo Hospital, 7-3-1 Hongo, Bunkyo-ku, Tokyo, 1138655, Japan","Background The morphometric analysis of myelinated nerve fibers of peripheral nerves in cross-sectional optical microscopic images is valuable. Several automated methods for nerve fiber identification and segmentation have been reported. This paper presents a new method that uses a deep learning model of a convolutional neural network (CNN). We tested it for human sural nerve biopsy images. Methods The method comprises four steps: normalization, clustering segmentation, myelinated nerve fiber identification, and clump splitting. A normalized sample image was separated into individual objects with clustering segmentation. Each object was applied to a CNN deep learning model that labeled myelinated nerve fibers as positive and other structures as negative. Only positives proceeded to the next step. For pretraining the model, 70,000 positive and negative data each from 39 samples were used. The accuracy of the proposed algorithm was evaluated using 10 samples that were not part of the training set. A P-value of <0.05 was considered statistically significant. Results The total true-positive rate (TPR) for the detection of myelinated fibers was 0.982, and the total false-positive rate was 0.016. The defined total area similarity (AS) and area overlap error of segmented myelin sheaths were 0.967 and 0.068, respectively. In all but one sample, there were no significant differences in estimated morphometric parameters obtained from our method and manual segmentation. Comparison with existing methods The TPR and AS were higher than those obtained using previous methods. Conclusions High-performance automated identification and segmentation of myelinated nerve fibers were achieved using a deep learning model. © 2017 Elsevier B.V.","","Adolescent; Adult; Aged; Biopsy; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Male; Microscopy; Middle Aged; Nerve Fibers, Myelinated; Pattern Recognition, Automated; Sural Nerve; adolescent; adult; aged; Article; convolutional neural network; cross-sectional study; female; human; human tissue; image analysis; image segmentation; learning algorithm; male; microscopy; middle aged; myelin sheath; myelinated nerve; nerve biopsy; nonmyelinated nerve; priority journal; Schwann cell; sural nerve; automated pattern recognition; biopsy; cytology; image processing; machine learning; microscopy; pathology; procedures","Elsevier B.V.","01650270","","JNMED","28837816","Article","Scopus","2-s2.0-85028066929"
"Muhammad H.; Fuchs T.J.; De Cuir N.; De Moraes C.G.; Blumberg D.M.; Liebmann J.M.; Ritch R.; Hood D.C.","Muhammad, Hassan (56890942400); Fuchs, Thomas J. (56454885300); De Cuir, Nicole (57188755350); De Moraes, Carlos G. (26428121800); Blumberg, Dana M. (15847535900); Liebmann, Jeffrey M. (57206430203); Ritch, Robert (35374631600); Hood, Donald C. (36004514000)","56890942400; 56454885300; 57188755350; 26428121800; 15847535900; 57206430203; 35374631600; 36004514000","Hybrid Deep Learning on Single Wide-field Optical Coherence tomography Scans Accurately Classifies Glaucoma Suspects","2017","Journal of Glaucoma","176","10.1097/IJG.0000000000000765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037633827&doi=10.1097%2fIJG.0000000000000765&partnerID=40&md5=889635f132462d314e2b9c22ef231cdd","Department of Physiology Biophysics, and Systems Biology, Weill Cornell Medicine, United States; Department of Medical Physics, United States; Department of Computational Biology, United States; Department of Pathology, Memorial Sloan Kettering Cancer Center, United States; Department of Psychology, Columbia University, 406 Schermerhorn Hall, MC 5501, 1190 Amsterdam Avenue, New York, 10027, NY, United States; Department of Ophthalmology, United States; College of Physicians and Surg., Columbia University, United States; Einhorn Clinical Research Center, New York Eye and Ear Infirmary of Mount Sinai, New York, NY, United States","Muhammad H., Department of Physiology Biophysics, and Systems Biology, Weill Cornell Medicine, United States, Department of Medical Physics, United States; Fuchs T.J., Department of Physiology Biophysics, and Systems Biology, Weill Cornell Medicine, United States, Department of Medical Physics, United States, Department of Computational Biology, United States, Department of Pathology, Memorial Sloan Kettering Cancer Center, United States; De Cuir N., Department of Psychology, Columbia University, 406 Schermerhorn Hall, MC 5501, 1190 Amsterdam Avenue, New York, 10027, NY, United States, College of Physicians and Surg., Columbia University, United States; De Moraes C.G., Department of Ophthalmology, United States; Blumberg D.M., Department of Ophthalmology, United States; Liebmann J.M., Department of Ophthalmology, United States; Ritch R., Einhorn Clinical Research Center, New York Eye and Ear Infirmary of Mount Sinai, New York, NY, United States; Hood D.C., Department of Psychology, Columbia University, 406 Schermerhorn Hall, MC 5501, 1190 Amsterdam Avenue, New York, 10027, NY, United States, Department of Ophthalmology, United States","Purpose: Existing summary statistics based upon optical coherence tomographic (OCT) scans and/or visual fields (VFs) are suboptimal for distinguishing between healthy and glaucomatous eyes in the clinic. This study evaluates the extent to which a hybrid deep learning method (HDLM), combined with a single wide-field OCT protocol, can distinguish eyes previously classified as either healthy suspects or mild glaucoma. Methods: In total, 102 eyes from 102 patients, with or suspected open-angle glaucoma, had previously been classified by 2 glaucoma experts as either glaucomatous (57 eyes) or healthy/suspects (45 eyes). The HDLM had access only to information from a single, wide-field (9×12 mm) swept-source OCT scan per patient. Convolutional neural networks were used to extract rich features from maps derived from these scans. Random forest classifier was used to train a model based on these features to predict the existence of glaucomatous damage. The algorithm was compared against traditional OCT and VF metrics. Results: The accuracy of the HDLM ranged from 63.7% to 93.1% depending upon the input map. The retinal nerve fiber layer probability map had the best accuracy (93.1%), with 4 false positives, and 3 false negatives. In comparison, the accuracy of the OCT and 24-2 and 10-2 VF metrics ranged from 66.7% to 87.3%. The OCT quadrants analysis had the best accuracy (87.3%) of the metrics, with 4 false positives and 9 false negatives. Conclusions: The HDLM protocol outperforms standard OCT and VF clinical metrics in distinguishing healthy suspect eyes from eyes with early glaucoma. It should be possible to further improve this algorithm and with improvement it might be useful for screening. © 2017 Wolters Kluwer Health, Inc. All rights reserved.","classification; detection; image processing; machine learning; optical coherence tomography","Glaucoma, Open-Angle; Humans; Intraocular Pressure; Machine Learning; Nerve Fibers; Neural Networks (Computer); Ocular Hypertension; Reproducibility of Results; Retinal Ganglion Cells; Tomography, Optical Coherence; Visual Fields; access to information; algorithm; Article; classifier; controlled study; diagnostic test; diagnostic test accuracy study; disease classification; disease severity; false negative result; false positive result; gonioscopy; human; hybrid deep learning method; machine learning; major clinical study; medical expert; nerve cell network; open angle glaucoma; optical coherence tomography; priority journal; random forest; receiver operating characteristic; retinal nerve fiber layer thickness; single wide field optical coherence tomography; artificial neural network; classification; intraocular hypertension; intraocular pressure; machine learning; nerve fiber; open angle glaucoma; optical coherence tomography; pathology; pathophysiology; physiology; procedures; reproducibility; retina ganglion cell; visual field","Lippincott Williams and Wilkins","10570829","","JOGLE","29045329","Article","Scopus","2-s2.0-85037633827"
"Sharma A.; Rani R.","Sharma, Aman (57214355671); Rani, Rinkle (55232407400)","57214355671; 55232407400","An optimized framework for cancer classification using deep learning and genetic algorithm","2017","Journal of Medical Imaging and Health Informatics","31","10.1166/jmihi.2017.2266","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032907669&doi=10.1166%2fjmihi.2017.2266&partnerID=40&md5=8a24b19ed8796bae8c48d77f7b94be16","Computer Science and Engineering Department, Thapar University, Patiala, Punjab, 147004, India","Sharma A., Computer Science and Engineering Department, Thapar University, Patiala, Punjab, 147004, India; Rani R., Computer Science and Engineering Department, Thapar University, Patiala, Punjab, 147004, India","Biological data analysis using automated computational tools and artificial intelligence techniques particularly machine learning has shown promising results in past few years. Machine learning approaches are used extensively in improving diagnosis and prognosis of various chronic and fatal diseases such as cancer, diabetes and heart attack. This paper presents an extensive evaluation of deep learning (feed-forward neural networks) using H2o and Deep belief network in cancer data. Further, this paper proposes an optimized framework for cancer classification using deep learning and genetic algorithm. This framework is based on already existing machine learning framework (H2o) for scalable computing. The main advantage of proposed approach is scalable cancer classification using gene expression data and automated feature extraction using deep learning. In this paper, our technique is applied to classify cancer types from publicly available gene expression data. Also, parameter optimization using a genetic algorithm (GA) is incorporated to further improve the classifier performance. Copyright © 2017 American Scientific Publishers.","Cancer Classification; Deep Learning; Gene Expression; Genetic Algorithm; H2O; Optimization","acute lymphoblastic leukemia; acute myeloid leukemia; Article; artificial neural network; automation; cancer classification; classifier; data extraction; data processing; gene expression; genetic algorithm; learning algorithm; lung adenocarcinoma; machine learning; measurement accuracy; prediction; process optimization; squamous cell lung carcinoma","American Scientific Publishers","21567018","","","","Article","Scopus","2-s2.0-85032907669"
"Baldi P.; Sadowski P.; Lu Z.","Baldi, Pierre (7101759672); Sadowski, Peter (56074914700); Lu, Zhiqin (7404769018)","7101759672; 56074914700; 7404769018","Learning in the machine: The symmetries of the deep learning channel","2017","Neural Networks","19","10.1016/j.neunet.2017.08.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029542312&doi=10.1016%2fj.neunet.2017.08.008&partnerID=40&md5=b0806e99e9fbddbc9ba7ad728afa7682","Department of Computer Science, University of California, Irvine, Irvine, 92617, CA, United States; Department of Mathematics, University of California, Irvine, Irvine, 92617, CA, United States","Baldi P., Department of Computer Science, University of California, Irvine, Irvine, 92617, CA, United States; Sadowski P., Department of Computer Science, University of California, Irvine, Irvine, 92617, CA, United States; Lu Z., Department of Mathematics, University of California, Irvine, Irvine, 92617, CA, United States","In a physical neural system, learning rules must be local both in space and time. In order for learning to occur, non-local information must be communicated to the deep synapses through a communication channel, the deep learning channel. We identify several possible architectures for this learning channel (Bidirectional, Conjoined, Twin, Distinct) and six symmetry challenges: (1) symmetry of architectures; (2) symmetry of weights; (3) symmetry of neurons; (4) symmetry of derivatives; (5) symmetry of processing; and (6) symmetry of learning rules. Random backpropagation (RBP) addresses the second and third symmetry, and some of its variations, such as skipped RBP (SRBP) address the first and the fourth symmetry. Here we address the last two desirable symmetries showing through simulations that they can be achieved and that the learning channel is particularly robust to symmetry variations. Specifically, random backpropagation and its variations can be performed with the same non-linear neurons used in the main input–output forward channel, and the connections in the learning channel can be adapted using the same algorithm used in the forward channel, removing the need for any specialized hardware in the learning channel. Finally, we provide mathematical results in simple cases showing that the learning equations in the forward and backward channels converge to fixed points, for almost any initial conditions. In symmetric architectures, if the weights in both channels are small at initialization, adaptation in both channels leads to weights that are essentially symmetric during and after learning. Biological connections are discussed. © 2017 Elsevier Ltd","Backpropagation; Deep learning; Learning channel; Learning dynamics; Local learning; Neural networks","Machine Learning; Neural Networks (Computer); Backpropagation algorithms; Deep learning; Network architecture; Neural networks; Neurons; Forward channels; Forward-and-backward; Initial conditions; Learning channel; Local learning; Neural systems; Non-linear neurons; Specialized hardware; accuracy; Article; artificial neural network; back propagation; classification algorithm; linear system; machine learning; mathematical analysis; mathematical model; nonlinear system; priority journal; probability; simulation; artificial neural network; Backpropagation","Elsevier Ltd","08936080","","NNETE","28938130","Article","Scopus","2-s2.0-85029542312"
"Schirrmeister R.T.; Springenberg J.T.; Fiederer L.D.J.; Glasstetter M.; Eggensperger K.; Tangermann M.; Hutter F.; Burgard W.; Ball T.","Schirrmeister, Robin Tibor (56743243100); Springenberg, Jost Tobias (55324920300); Fiederer, Lukas Dominique Josef (56637026400); Glasstetter, Martin (57199420109); Eggensperger, Katharina (56397110000); Tangermann, Michael (23006710500); Hutter, Frank (55931808800); Burgard, Wolfram (7003610380); Ball, Tonio (8442532500)","56743243100; 55324920300; 56637026400; 57199420109; 56397110000; 23006710500; 55931808800; 7003610380; 8442532500","Deep learning with convolutional neural networks for EEG decoding and visualization","2017","Human Brain Mapping","1687","10.1002/hbm.23730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034247766&doi=10.1002%2fhbm.23730&partnerID=40&md5=edaafdce4238d4e75c58b2ffecb108f8","Translational Neurotechnology Lab, Epilepsy Center, Medical Center – University of Freiburg, Engelberger Str. 21, Freiburg, 79106, Germany; BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany; Machine Learning Lab, Computer Science Dept, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany; Neurobiology and Biophysics, Faculty of Biology, University of Freiburg, Hansastr. 9a, Freiburg, 79104, Germany; Machine Learning for Automated Algorithm Design Lab, Computer Science Dept, University of Freiburg, Georges-Köhler-Allee 52, Freiburg im Breisgau, 79110, Germany; Brain State Decoding Lab, Computer Science Dept, University of Freiburg, Albertstr. 23, Freiburg, 79104, Germany; Autonomous Intelligent Systems Lab, Computer Science Dept, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany","Schirrmeister R.T., Translational Neurotechnology Lab, Epilepsy Center, Medical Center – University of Freiburg, Engelberger Str. 21, Freiburg, 79106, Germany, BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany; Springenberg J.T., BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany, Machine Learning Lab, Computer Science Dept, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany; Fiederer L.D.J., Translational Neurotechnology Lab, Epilepsy Center, Medical Center – University of Freiburg, Engelberger Str. 21, Freiburg, 79106, Germany, BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany, Neurobiology and Biophysics, Faculty of Biology, University of Freiburg, Hansastr. 9a, Freiburg, 79104, Germany; Glasstetter M., Translational Neurotechnology Lab, Epilepsy Center, Medical Center – University of Freiburg, Engelberger Str. 21, Freiburg, 79106, Germany, BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany; Eggensperger K., BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany, Machine Learning for Automated Algorithm Design Lab, Computer Science Dept, University of Freiburg, Georges-Köhler-Allee 52, Freiburg im Breisgau, 79110, Germany; Tangermann M., BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany, Brain State Decoding Lab, Computer Science Dept, University of Freiburg, Albertstr. 23, Freiburg, 79104, Germany; Hutter F., BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany, Machine Learning for Automated Algorithm Design Lab, Computer Science Dept, University of Freiburg, Georges-Köhler-Allee 52, Freiburg im Breisgau, 79110, Germany; Burgard W., BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany, Autonomous Intelligent Systems Lab, Computer Science Dept, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany; Ball T., Translational Neurotechnology Lab, Epilepsy Center, Medical Center – University of Freiburg, Engelberger Str. 21, Freiburg, 79106, Germany, BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-Köhler-Allee 79, Freiburg, 79110, Germany","Deep learning with convolutional neural networks (deep ConvNets) has revolutionized computer vision through end-to-end learning, that is, learning from the raw data. There is increasing interest in using deep ConvNets for end-to-end EEG analysis, but a better understanding of how to design and train ConvNets for end-to-end EEG decoding and how to visualize the informative EEG features the ConvNets learn is still needed. Here, we studied deep ConvNets with a range of different architectures, designed for decoding imagined or executed tasks from raw EEG. Our results show that recent advances from the machine learning field, including batch normalization and exponential linear units, together with a cropped training strategy, boosted the deep ConvNets decoding performance, reaching at least as good performance as the widely used filter bank common spatial patterns (FBCSP) algorithm (mean decoding accuracies 82.1% FBCSP, 84.0% deep ConvNets). While FBCSP is designed to use spectral power modulations, the features used by ConvNets are not fixed a priori. Our novel methods for visualizing the learned features demonstrated that ConvNets indeed learned to use spectral power modulations in the alpha, beta, and high gamma frequencies, and proved useful for spatially mapping the learned features by revealing the topography of the causal contributions of features in different frequency bands to the decoding decision. Our study thus shows how to design and train ConvNets to decode task-related information from the raw EEG without handcrafted features and highlights the potential of deep ConvNets combined with advanced visualization techniques for EEG-based brain mapping. Hum Brain Mapp 38:5391–5420, 2017. © 2017 Wiley Periodicals, Inc. © 2017 The Authors Human Brain Mapping Published by Wiley Periodicals, Inc.","brain mapping; brain–computer interface; brain–machine interface; EEG analysis; electroencephalography; end-to-end learning; machine learning; model interpretability","Brain; Brain Mapping; Brain-Computer Interfaces; Electroencephalography; Humans; Imagination; Language; Machine Learning; Motor Activity; Neural Pathways; Space Perception; algorithm; Article; artificial neural network; convolutional neural network; correlation coefficient; electroencephalogram; frequency analysis; machine learning; mathematical computing; modulation; priority journal; spectral sensitivity; task performance; topography; brain; brain computer interface; brain mapping; depth perception; electroencephalography; human; imagination; language; motor activity; nerve tract; physiology; procedures","John Wiley and Sons Inc.","10659471","","HBMAE","28782865","Article","Scopus","2-s2.0-85034247766"
"Martinez-Murcia F.J.; Górriz J.M.; Ramírez J.; Illán I.A.; Segovia F.; Castillo-Barnes D.; Salas-Gonzalez D.","Martinez-Murcia, Francisco J. (55062058300); Górriz, Juan M. (7004736801); Ramírez, Javier (57191694395); Illán, Ignacio A. (55251085600); Segovia, Fermín (26424738700); Castillo-Barnes, Diego (57194785841); Salas-Gonzalez, Diego (23101090600)","55062058300; 7004736801; 57191694395; 55251085600; 26424738700; 57194785841; 23101090600","Functional brain imaging synthesis based on image decomposition and kernel modeling: Application to neurodegenerative diseases","2017","Frontiers in Neuroinformatics","15","10.3389/fninf.2017.00065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036518066&doi=10.3389%2ffninf.2017.00065&partnerID=40&md5=9e54ab95a08fe2a754ab19bc4d082c95","Signal Processing and Biomedical Application, Department of Signal Theory Networking and Communication, University of Granada, Granada, Spain; Department of Scientific Computing, Florida State University, Tallahassee, FL, United States","Martinez-Murcia F.J., Signal Processing and Biomedical Application, Department of Signal Theory Networking and Communication, University of Granada, Granada, Spain; Górriz J.M., Signal Processing and Biomedical Application, Department of Signal Theory Networking and Communication, University of Granada, Granada, Spain; Ramírez J., Signal Processing and Biomedical Application, Department of Signal Theory Networking and Communication, University of Granada, Granada, Spain; Illán I.A., Department of Scientific Computing, Florida State University, Tallahassee, FL, United States; Segovia F., Signal Processing and Biomedical Application, Department of Signal Theory Networking and Communication, University of Granada, Granada, Spain; Castillo-Barnes D., Signal Processing and Biomedical Application, Department of Signal Theory Networking and Communication, University of Granada, Granada, Spain; Salas-Gonzalez D., Signal Processing and Biomedical Application, Department of Signal Theory Networking and Communication, University of Granada, Granada, Spain","The rise of neuroimaging in research and clinical practice, together with the development of new machine learning techniques has strongly encouraged the Computer Aided Diagnosis (CAD) of different diseases and disorders. However, these algorithms are often tested in proprietary datasets to which the access is limited and, therefore, a direct comparison between CAD procedures is not possible. Furthermore, the sample size is often small for developing accurate machine learning methods. Multi-center initiatives are currently a very useful, although limited, tool in the recruitment of large populations and standardization of CAD evaluation. Conversely, we propose a brain image synthesis procedure intended to generate a new image set that share characteristics with an original one. Our system focuses on nuclear imaging modalities such as PET or SPECT brain images. We analyze the dataset by applying PCA to the original dataset, and then model the distribution of samples in the projected eigenbrain space using a Probability Density Function (PDF) estimator. Once the model has been built, we can generate new coordinates on the eigenbrain space belonging to the same class, which can be then projected back to the image space. The system has been evaluated on different functional neuroimaging datasets assessing the: resemblance of the synthetic images with the original ones, the differences between them, their generalization ability and the independence of the synthetic dataset with respect to the original. The synthetic images maintain the differences between groups found at the original dataset, with no significant differences when comparing them to real-world samples. Furthermore, they featured a similar performance and generalization capability to that of the original dataset. These results prove that these images are suitable for standardizing the evaluation of CAD pipelines, and providing data augmentation in machine learning systems-e.g. in deep learning-, or even to train future professionals at medical school. © 2017 Martnez-Murcia, Górriz, Ramírez, Illán, Segovia, Castillo-Barnes, and Salas-Gonzalez for the Alzheimer’s Disease Neuroimaging Initiative.","Alzheimer’s disease (AD); Data augmentation; Density estimation; Evaluation; Neuroimaging; Parkinson’s disease (PD); Synthesis; Validation","tracer; Alzheimer disease; Article; clinical practice; degenerative disease; disease course; disease simulation; functional neuroimaging; human; kernel method; machine learning; mathematical model; mild cognitive impairment; Parkinson disease; principal component analysis; single photon emission computed tomography; validation process","Frontiers Media S.A.","16625196","","","","Article","Scopus","2-s2.0-85036518066"
"Afridi M.J.; Ross A.; Liu X.; Bennewitz M.F.; Shuboni D.D.; Shapiro E.M.","Afridi, Muhammad Jamal (36439153900); Ross, Arun (7402568052); Liu, Xiaoming (35793096800); Bennewitz, Margaret F. (26421987800); Shuboni, Dorela D. (37032000200); Shapiro, Erik M. (7202925786)","36439153900; 7402568052; 35793096800; 26421987800; 37032000200; 7202925786","Intelligent and automatic in vivo detection and quantification of transplanted cells in MRI","2017","Magnetic Resonance in Medicine","8","10.1002/mrm.26571","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029451479&doi=10.1002%2fmrm.26571&partnerID=40&md5=98a02645374a58ada4c2990be55104fb","Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, United States; Vascular Medicine Institute, University of Pittsburgh, Pittsburgh, PA, United States; Department of Radiology, Michigan State University, East Lansing, MI, United States","Afridi M.J., Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, United States; Ross A., Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, United States; Liu X., Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, United States; Bennewitz M.F., Vascular Medicine Institute, University of Pittsburgh, Pittsburgh, PA, United States; Shuboni D.D., Department of Radiology, Michigan State University, East Lansing, MI, United States; Shapiro E.M., Department of Radiology, Michigan State University, East Lansing, MI, United States","Purpose: Magnetic resonance imaging (MRI)-based cell tracking has emerged as a useful tool for identifying the location of transplanted cells, and even their migration. Magnetically labeled cells appear as dark contrast in T2*-weighted MRI, with sensitivities of individual cells. One key hurdle to the widespread use of MRI-based cell tracking is the inability to determine the number of transplanted cells based on this contrast feature. In the case of single cell detection, manual enumeration of spots in three-dimensional (3D) MRI in principle is possible; however, it is a tedious and time-consuming task that is prone to subjectivity and inaccuracy on a large scale. This research presents the first comprehensive study on how a computer-based intelligent, automatic, and accurate cell quantification approach can be designed for spot detection in MRI scans. Methods: Magnetically labeled mesenchymal stem cells (MSCs) were transplanted into rats using an intracardiac injection, accomplishing single cell seeding in the brain. T2*-weighted MRI of these rat brains were performed where labeled MSCs appeared as spots. Using machine learning and computer vision paradigms, approaches were designed to systematically explore the possibility of automatic detection of these spots in MRI. Experiments were validated against known in vitro scenarios. Results: Using the proposed deep convolutional neural network (CNN) architecture, an in vivo accuracy up to 97.3% and in vitro accuracy of up to 99.8% was achieved for automated spot detection in MRI data. Conclusion: The proposed approach for automatic quantification of MRI-based cell tracking will facilitate the use of MRI in large-scale cell therapy studies. Magn Reson Med 78:1991–2002, 2017. © 2016 International Society for Magnetic Resonance in Medicine. © 2016 International Society for Magnetic Resonance in Medicine","cell therapy; iron oxide; Machine learning; MRI","Algorithms; Animals; Brain; Cell Tracking; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Mesenchymal Stem Cell Transplantation; Mesenchymal Stromal Cells; Pattern Recognition, Automated; Rats; Convolutional neural networks; Deep neural networks; Flowcharting; Iron oxides; Learning systems; Machine learning; Magnetic resonance imaging; Stem cells; Automatic quantification; Cell therapy; Detection and quantifications; International society; Intracardiac injection; Mesenchymal stem cell; Single-cell detection; Threedimensional (3-d); animal cell; animal experiment; animal tissue; Article; artificial intelligence; artificial neural network; automation; cell labeling; cell migration; cell tracking; cell transplantation; contrast; controlled study; in vivo study; machine learning; magnetism; measurement accuracy; mesenchymal stem cell; mesenchymal stem cell transplantation; nonhuman; nuclear magnetic resonance imaging; rat; single cell analysis; three dimensional imaging; algorithm; animal; automated pattern recognition; brain; cell tracking; cytology; diagnostic imaging; image processing; mesenchymal stem cell transplantation; mesenchymal stroma cell; nuclear magnetic resonance imaging; procedures; Cell culture","John Wiley and Sons Inc","07403194","","MRMEE","28019017","Article","Scopus","2-s2.0-85029451479"
"Parisi G.I.; Tani J.; Weber C.; Wermter S.","Parisi, German I. (56028608900); Tani, Jun (56072068100); Weber, Cornelius (7402376952); Wermter, Stefan (7003826680)","56028608900; 56072068100; 7402376952; 7003826680","Lifelong learning of human actions with deep neural network self-organization","2017","Neural Networks","87","10.1016/j.neunet.2017.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030761514&doi=10.1016%2fj.neunet.2017.09.001&partnerID=40&md5=7e27de4e52e03c9d872e5b8ae1566bb7","Knowledge Technology Institute, Department of Informatics, University of Hamburg, Germany; Cognitive Neurorobotics Research Unit, Okinawa Institute of Science and Technology (OIST), Japan","Parisi G.I., Knowledge Technology Institute, Department of Informatics, University of Hamburg, Germany; Tani J., Cognitive Neurorobotics Research Unit, Okinawa Institute of Science and Technology (OIST), Japan; Weber C., Knowledge Technology Institute, Department of Informatics, University of Hamburg, Germany; Wermter S., Knowledge Technology Institute, Department of Informatics, University of Hamburg, Germany","Lifelong learning is fundamental in autonomous robotics for the acquisition and fine-tuning of knowledge through experience. However, conventional deep neural models for action recognition from videos do not account for lifelong learning but rather learn a batch of training data with a predefined number of action classes and samples. Thus, there is the need to develop learning systems with the ability to incrementally process available perceptual cues and to adapt their responses over time. We propose a self-organizing neural architecture for incrementally learning to classify human actions from video sequences. The architecture comprises growing self-organizing networks equipped with recurrent neurons for processing time-varying patterns. We use a set of hierarchically arranged recurrent networks for the unsupervised learning of action representations with increasingly large spatiotemporal receptive fields. Lifelong learning is achieved in terms of prediction-driven neural dynamics in which the growth and the adaptation of the recurrent networks are driven by their capability to reconstruct temporally ordered input sequences. Experimental results on a classification task using two action benchmark datasets show that our model is competitive with state-of-the-art methods for batch learning also when a significant number of sample labels are missing or corrupted during training sessions. Additional experiments show the ability of our model to adapt to non-stationary input avoiding catastrophic interference. © 2017 The Author(s)","Action recognition; Lifelong learning; Self-organizing neural networks; Unsupervised deep learning","Humans; Machine Learning; Neural Networks (Computer); Neurons; Pattern Recognition, Visual; Robotics; Classification (of information); Deep neural networks; Image recognition; Network architecture; Neural networks; Recurrent neural networks; Action recognition; Action representations; Additional experiments; Growing self-organizing networks; Life long learning; Self-organizing neural network; Spatiotemporal receptive field; State-of-the-art methods; Article; artificial neural network; classification algorithm; human activities; measurement accuracy; prediction; priority journal; unsupervised machine learning; videorecording; human; machine learning; nerve cell; pattern recognition; physiology; procedures; robotics; trends; Deep learning","Elsevier Ltd","08936080","","NNETE","29017140","Article","Scopus","2-s2.0-85030761514"
"De Tobel J.; Radesh P.; Vandermeulen D.; Thevissen P.W.","De Tobel, Jannick (37121673800); Radesh, Purnima (57200727867); Vandermeulen, Dirk (7003312639); Thevissen, Patrick W. (13407275300)","37121673800; 57200727867; 7003312639; 13407275300","An automated technique to stage lower third molar development on panoramic radiographs for age estimation: A pilot study","2017","Journal of Forensic Odonto-Stomatology","64","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046780029&partnerID=40&md5=2de44a5602a15512524bf28d5fe69a87","Department of Oral Health Sciences – Forensic Dentistry, KU Leuven, Department of Dentistry, University Hospitals Leuven, Belgium; Department of Radiology and Nuclear Medicine, Ghent University, Belgium; Department of Head, Neck and Maxillofacial Surgery, Ghent University Hospital, Belgium; Department of Oral and Maxillofacial Surgery, Leuven University Hospital, Belgium; Department of Electrical Engineering, ESAT/PSI, KU Leuven, Belgium","De Tobel J., Department of Oral Health Sciences – Forensic Dentistry, KU Leuven, Department of Dentistry, University Hospitals Leuven, Belgium, Department of Radiology and Nuclear Medicine, Ghent University, Belgium, Department of Head, Neck and Maxillofacial Surgery, Ghent University Hospital, Belgium, Department of Oral and Maxillofacial Surgery, Leuven University Hospital, Belgium; Radesh P., Department of Oral Health Sciences – Forensic Dentistry, KU Leuven, Department of Dentistry, University Hospitals Leuven, Belgium; Vandermeulen D., Department of Electrical Engineering, ESAT/PSI, KU Leuven, Belgium; Thevissen P.W., Department of Oral Health Sciences – Forensic Dentistry, KU Leuven, Department of Dentistry, University Hospitals Leuven, Belgium","Background: Automated methods to evaluate growth of hand and wrist bones on radiographs and magnetic resonance imaging have been developed. They can be applied to estimate age in children and subadults. Automated methods require the software to (1) recognise the region of interest in the image(s), (2) evaluate the degree of development and (3) correlate this to the age of the subject based on a reference population. For age estimation based on third molars an automated method for step (1) has been presented for 3D magnetic resonance imaging and is currently being optimised (Unterpirker et al. 2015). Aim: To develop an automated method for step (2) based on lower third molars on panoramic radiographs. Materials and methods: A modified Demirjian staging technique including ten developmental stages was developed. Twenty panoramic radiographs per stage per gender were retrospectively selected for FDI element 38. Two observers decided in consensus about the stages. When necessary, a third observer acted as a referee to establish the reference stage for the considered third molar. This set of radiographs was used as training data for machine learning algorithms for automated staging. First, image contrast settings were optimised to evaluate the third molar of interest and a rectangular bounding box was placed around it in a standardised way using Adobe Photoshop CC 2017 software. This bounding box indicated the region of interest for the next step. Second, several machine learning algorithms available in MATLAB R2017a software were applied for automated stage recognition. Third, the classification performance was evaluated in a 5-fold cross-validation scenario, using different validation metrics (accuracy, Rank-N recognition rate, mean absolute difference, linear kappa coefficient). Results: Transfer Learning as a type of Deep Learning Convolutional Neural Network approach outperformed all other tested approaches. Mean accuracy equalled 0.51, mean absolute difference was 0.6 stages and mean linearly weighted kappa was 0.82. Conclusion: The overall performance of the presented automated pilot technique to stage lower third molar development on panoramic radiographs was similar to staging by human observers. It will be further optimised in future research, since it represents a necessary step to achieve a fully automated dental age estimation method, which to date is not available. © 2017, International Organisation for Forensic Odonto-Stomatology. All rights reserved.","Finger print; Forensic identification; Forensic odontology; Mandibular lingual canals; Victim identification","","International Organisation for Forensic Odonto-Stomatology","0258414X","","JFOSE","29384736","Article","Scopus","2-s2.0-85046780029"
"Sohaib M.; Kim C.-H.; Kim J.-M.","Sohaib, Muhammad (57193162038); Kim, Cheol-Hong (57223773862); Kim, Jong-Myon (55850196800)","57193162038; 57223773862; 55850196800","A hybrid feature model and deep-learning-based bearing fault diagnosis","2017","Sensors (Switzerland)","161","10.3390/s17122876","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037871090&doi=10.3390%2fs17122876&partnerID=40&md5=8297494ea83f7c697087f84bc21f44dd","Department of Electrical, Electronics and Computer Engineering, University of Ulsan, Ulsan, 44610, South Korea; School of Electronics and Computer Engineering, Chonnam National University, Gwangju, 61186, South Korea","Sohaib M., Department of Electrical, Electronics and Computer Engineering, University of Ulsan, Ulsan, 44610, South Korea; Kim C.-H., School of Electronics and Computer Engineering, Chonnam National University, Gwangju, 61186, South Korea; Kim J.-M., Department of Electrical, Electronics and Computer Engineering, University of Ulsan, Ulsan, 44610, South Korea","Bearing fault diagnosis is imperative for the maintenance, reliability, and durability of rotary machines. It can reduce economical losses by eliminating unexpected downtime in industry due to failure of rotary machines. Though widely investigated in the past couple of decades, continued advancement is still desirable to improve upon existing fault diagnosis techniques. Vibration acceleration signals collected from machine bearings exhibit nonstationary behavior due to variable working conditions and multiple fault severities. In the current work, a two-layered bearing fault diagnosis scheme is proposed for the identification of fault pattern and crack size for a given fault type. A hybrid feature pool is used in combination with sparse stacked autoencoder (SAE)-based deep neural networks (DNNs) to perform effective diagnosis of bearing faults of multiple severities. The hybrid feature pool can extract more discriminating information from the raw vibration signals, to overcome the nonstationary behavior of the signals caused by multiple crack sizes. More discriminating information helps the subsequent classifier to effectively classify data into the respective classes. The results indicate that the proposed scheme provides satisfactory performance in diagnosing bearing defects of multiple severities. Moreover, the results also demonstrate that the proposed model outperforms other state-of-the-art algorithms, i.e., support vector machines (SVMs) and backpropagation neural networks (BPNNs). © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Autoencoders; Bearing fault diagnosis; Fault diagnosis; Fault severity; Hybrid features; Multi crack size; Stacked autoencoders","Backpropagation algorithms; Classification (of information); Cracks; Deep learning; Deep neural networks; Electric fault currents; Failure analysis; Learning systems; Neural networks; Rotating machinery; Support vector machines; Autoencoders; Bearing fault diagnosis; Fault severities; Hybrid features; Multi-crack; acceleration; acceleration; article; article; back propagation neural network; back propagation neural network; deep learning; deep learning; deep neural network; deep neural network; stacked autoencoder; stacked autoencoder; support vector machine; support vector machine; vibration; vibration; work environment; work environment; Fault detection","MDPI AG","14248220","","","29232908","Article","Scopus","2-s2.0-85037871090"
"Yu N.; Yu Z.; Pan Y.","Yu, Ning (35489801100); Yu, Zeng (57188663522); Pan, Yi (24765302500)","35489801100; 57188663522; 24765302500","A deep learning method for lincRNA detection using auto-encoder algorithm","2017","BMC bioinformatics","20","10.1186/s12859-017-1922-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043237608&doi=10.1186%2fs12859-017-1922-3&partnerID=40&md5=a8c393b7a1099ff083c481fbccd95c4b","Department of Computer Science, Georgia State University, 25 Park Place, Atlanta, 30303, GA, United States; Department of Computer Science, Georgia State University, 25 Park Place, Atlanta, 30303, GA, United States; Department of Computer Science, Georgia State University, 25 Park Place, Atlanta, 30303, GA, United States","Yu N., Department of Computer Science, Georgia State University, 25 Park Place, Atlanta, 30303, GA, United States; Yu Z., Department of Computer Science, Georgia State University, 25 Park Place, Atlanta, 30303, GA, United States; Pan Y., Department of Computer Science, Georgia State University, 25 Park Place, Atlanta, 30303, GA, United States","BACKGROUND: RNA sequencing technique (RNA-seq) enables scientists to develop novel data-driven methods for discovering more unidentified lincRNAs. Meantime, knowledge-based technologies are experiencing a potential revolution ignited by the new deep learning methods. By scanning the newly found data set from RNA-seq, scientists have found that: (1) the expression of lincRNAs appears to be regulated, that is, the relevance exists along the DNA sequences; (2) lincRNAs contain some conversed patterns/motifs tethered together by non-conserved regions. The two evidences give the reasoning for adopting knowledge-based deep learning methods in lincRNA detection. Similar to coding region transcription, non-coding regions are split at transcriptional sites. However, regulatory RNAs rather than message RNAs are generated. That is, the transcribed RNAs participate the biological process as regulatory units instead of generating proteins. Identifying these transcriptional regions from non-coding regions is the first step towards lincRNA recognition.; RESULTS: The auto-encoder method achieves 100% and 92.4% prediction accuracy on transcription sites over the putative data sets. The experimental results also show the excellent performance of predictive deep neural network on the lincRNA data sets compared with support vector machine and traditional neural network. In addition, it is validated through the newly discovered lincRNA data set and one unreported transcription site is found by feeding the whole annotated sequences through the deep learning machine, which indicates that deep learning method has the extensive ability for lincRNA prediction.; CONCLUSIONS: The transcriptional sequences of lincRNAs are collected from the annotated human DNA genome data. Subsequently, a two-layer deep neural network is developed for the lincRNA detection, which adopts the auto-encoder algorithm and utilizes different encoding schemes to obtain the best performance over intergenic DNA sequence data. Driven by those newly annotated lincRNA data, deep learning methods based on auto-encoder algorithm can exert their capability in knowledge learning in order to capture the useful features and the information correlation along DNA genome sequences for lincRNA detection. As our knowledge, this is the first application to adopt the deep learning techniques for identifying lincRNA transcription sequences.","Auto-encoder; Deep learning; Knowledge-based discovery; Long intergenic non-coding RNA (lincRNA); RNA-seq; Transcription sites","Algorithms; Computational Biology; Humans; Machine Learning; RNA, Long Noncoding; Sequence Analysis, RNA; long untranslated RNA; algorithm; biology; genetics; human; machine learning; procedures; sequence analysis","","14712105","","","29244011","Article","Scopus","2-s2.0-85043237608"
"Qi T.; Xu Y.; Quan Y.; Wang Y.; Ling H.","Qi, Tangquan (36601275200); Xu, Yong (57274194400); Quan, Yuhui (55266983200); Wang, Yaodong (57195233148); Ling, Haibin (57191091290)","36601275200; 57274194400; 55266983200; 57195233148; 57191091290","Image-based action recognition using hint-enhanced deep neural networks","2017","Neurocomputing","54","10.1016/j.neucom.2017.06.041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026394713&doi=10.1016%2fj.neucom.2017.06.041&partnerID=40&md5=acf6b85af2f7495e40e3387364b499bb","School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Center for Information Science and Technology, Computer and Information Science Department, Temple University, Philadelphia, PA, United States","Qi T., School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Xu Y., School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Quan Y., School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Wang Y., School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Ling H., School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China, Center for Information Science and Technology, Computer and Information Science Department, Temple University, Philadelphia, PA, United States","While human action recognition from still images finds wide applications in computer vision, it remains a very challenging problem. Compared with video-based ones, image-based action representation and recognition are impossible to access the motion cues of action, which largely increases the difficulties in dealing with pose variances and cluttered backgrounds. Motivated by the recent success of convolutional neural networks (CNN) in learning discriminative features from objects in the presence of variations and backgrounds, in this paper, we investigate the potentials of CNN in image-based action recognition. A new action recognition method is proposed by implicitly integrating pose hints into the CNN framework, i.e., we use a CNN originally learned for object recognition as a base network and then transfer it to action recognition by training the base network jointly with inference of poses. Such a joint training scheme can guide the network towards pose inference and meanwhile prevent the unrelated knowledge inherited from the base network. For further performance improvement, the training data is augmented by enriching the pose-related samples. The experimental results on three benchmark datasets have demonstrated the effectiveness of our method. © 2017","Action recognition; Convolutional neural networks; Pose hints","Convolution; Neural networks; Object recognition; Action recognition; Action representations; Benchmark datasets; Cluttered backgrounds; Convolutional neural network; Discriminative features; Human-action recognition; Pose hints; accuracy; algorithm; Article; calculation; convolutional neural network; illumination; image analysis; image quality; linear system; machine learning; mathematical analysis; mathematical model; nonlinear system; priority journal; support vector machine; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85026394713"
"Wolterink J.M.; Leiner T.; Viergever M.A.; Išgum I.","Wolterink, Jelmer M. (56198388700); Leiner, Tim (7004171845); Viergever, Max A. (57203030739); Išgum, Ivana (6507874503)","56198388700; 7004171845; 57203030739; 6507874503","Generative adversarial networks for noise reduction in low-dose CT","2017","IEEE Transactions on Medical Imaging","761","10.1109/TMI.2017.2708987","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029680697&doi=10.1109%2fTMI.2017.2708987&partnerID=40&md5=d642b66dd730a843a56d423a80a49cdd","Image Sciences Institute, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands; Department of Radiology, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands","Wolterink J.M., Image Sciences Institute, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands; Leiner T., Department of Radiology, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands; Viergever M.A., Image Sciences Institute, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands; Išgum I., Image Sciences Institute, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands","Noise is inherent to low-dose CT acquisition. We propose to train a convolutional neural network (CNN) jointly with an adversarial CNN to estimate routine-dose CT images from low-dose CT images and hence reduce noise. A generator CNN was trained to transform low-dose CT images into routine-dose CT images using voxelwise loss minimization. An adversarial discriminator CNN was simultaneously trained to distinguish the output of the generator from routine-dose CT images. The performance of this discriminatorwas used as an adversarial loss for the generator. Experimentswere performed using CT images of an anthropomorphic phantom containing calcium inserts, as well as patient non-contrast-enhanced cardiac CT images. The phantom and patients were scanned at 20% and 100% routine clinical dose. Three training strategies were compared: The first used only voxelwise loss, the second combined voxelwise loss and adversarial loss, and the third used only adversarial loss. The results showed that training with only voxelwise loss resulted in the highest peak signal-Tonoise ratio with respect to reference routine-dose images. However,CNNstrainedwith adversarial loss capturedimage statistics of routine-dose images better. Noise reduction improved quantification of low-density calcified inserts in phantom CT images and allowed coronary calcium scoring in low-dose patient CT images with high noise levels. Testing took less than 10 s per CT volume. CNN-based lowdose CT noise reduction in the image domain is feasible. Training with an adversarial network improves the CNNs ability to generate imageswith an appearance similar to that of reference routine-dose CT images. © 2017 Institute of Electrical and Electronics Engineers Inc. All rights reserved.","Coronary calcium scoring; Deep learning; Generative adversarialnetworks; Low-dose cardiacCT; Noise reduction.","Arteries; Calcinosis; Humans; Image Processing, Computer-Assisted; Phantoms, Imaging; Signal-To-Noise Ratio; Tomography, X-Ray Computed; Calcium; Deep learning; Image denoising; Image enhancement; Neural networks; Noise abatement; Phantoms; Adversarial networks; Anthropomorphic phantoms; Convolutional neural network; Coronary calcium; Generative adversarialnetworks; High noise levels; Low dose; Signaltonoise ratio (SNR); Article; artificial neural network; clinical article; computer assisted tomography; controlled study; deep learning; entropy; human; noise reduction; partial volume (imaging); radiation dose reduction; receptive field; supervised machine learning; wavelet transformation; artery; calcinosis; diagnostic imaging; image processing; imaging phantom; procedures; signal noise ratio; x-ray computed tomography; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28574346","Article","Scopus","2-s2.0-85029680697"
"Weile J.; Sun S.; Cote A.G.; Knapp J.; Verby M.; Mellor J.C.; Wu Y.; Pons C.; Wong C.; van Lieshout N.; Yang F.; Tasan M.; Tan G.; Yang S.; Fowler D.M.; Nussbaum R.; Bloom J.D.; Vidal M.; Hill D.E.; Aloy P.; Roth F.P.","Weile, Jochen (23987151700); Sun, Song (56991749100); Cote, Atina G (8067423200); Knapp, Jennifer (57188989255); Verby, Marta (57188983682); Mellor, Joseph C (7103106882); Wu, Yingzhou (57191042632); Pons, Carles (24071268100); Wong, Cassandra (57188972831); van Lieshout, Natascha (58988055900); Yang, Fan (57214194232); Tasan, Murat (35485796400); Tan, Guihong (56655918800); Yang, Shan (57030798300); Fowler, Douglas M (11240810700); Nussbaum, Robert (7102608280); Bloom, Jesse D (7201379306); Vidal, Marc (7202764997); Hill, David E (57203608435); Aloy, Patrick (6701754884); Roth, Frederick P (7103020414)","23987151700; 56991749100; 8067423200; 57188989255; 57188983682; 7103106882; 57191042632; 24071268100; 57188972831; 58988055900; 57214194232; 35485796400; 56655918800; 57030798300; 11240810700; 7102608280; 7201379306; 7202764997; 57203608435; 6701754884; 7103020414","A framework for exhaustively mapping functional missense variants","2017","Molecular Systems Biology","94","10.15252/msb.20177908","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039053585&doi=10.15252%2fmsb.20177908&partnerID=40&md5=43afbae8ef945befa9d33792eaa659ad","Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada; The Donnelly Centre, University of Toronto, Toronto, ON, Canada; Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Department of Medical Biochemistry and Microbiology, Uppsala University, Uppsala, Sweden; SeqWell Inc, Boston, MA, United States; Institute for Research in Biomedicine (IRB Barcelona), The Barcelona Institute for Science and Technology, Barcelona, Catalonia, Spain; Invitae Corp., San Francisco, CA, United States; Department of Genome Sciences, University of Washington, Seattle, WA, United States; Fred Hutchinson Research Center, Seattle, WA, United States; Center for Cancer Systems Biology (CCSB), Dana-Farber Cancer Institute, Boston, MA, United States; Department of Genetics, Harvard Medical School, Boston, MA, United States; Institució Catalana de Recerca I Estudis Avançats (ICREA), Barcelona, Catalonia, Spain; Canadian Institute for Advanced Research, Toronto, ON, Canada","Weile J., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada, Department of Computer Science, University of Toronto, Toronto, ON, Canada; Sun S., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada, Department of Computer Science, University of Toronto, Toronto, ON, Canada, Department of Medical Biochemistry and Microbiology, Uppsala University, Uppsala, Sweden; Cote A.G., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada; Knapp J., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada; Verby M., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada; Mellor J.C., The Donnelly Centre, University of Toronto, Toronto, ON, Canada, SeqWell Inc, Boston, MA, United States; Wu Y., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada, Department of Computer Science, University of Toronto, Toronto, ON, Canada; Pons C., Institute for Research in Biomedicine (IRB Barcelona), The Barcelona Institute for Science and Technology, Barcelona, Catalonia, Spain; Wong C., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada; van Lieshout N., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada; Yang F., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada, Department of Computer Science, University of Toronto, Toronto, ON, Canada; Tasan M., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada, Department of Computer Science, University of Toronto, Toronto, ON, Canada; Tan G., The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada; Yang S., Invitae Corp., San Francisco, CA, United States; Fowler D.M., Department of Genome Sciences, University of Washington, Seattle, WA, United States; Nussbaum R., Invitae Corp., San Francisco, CA, United States; Bloom J.D., Fred Hutchinson Research Center, Seattle, WA, United States; Vidal M., Center for Cancer Systems Biology (CCSB), Dana-Farber Cancer Institute, Boston, MA, United States, Department of Genetics, Harvard Medical School, Boston, MA, United States; Hill D.E., Center for Cancer Systems Biology (CCSB), Dana-Farber Cancer Institute, Boston, MA, United States; Aloy P., Institute for Research in Biomedicine (IRB Barcelona), The Barcelona Institute for Science and Technology, Barcelona, Catalonia, Spain, Institució Catalana de Recerca I Estudis Avançats (ICREA), Barcelona, Catalonia, Spain; Roth F.P., Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, ON, Canada, The Donnelly Centre, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada, Department of Computer Science, University of Toronto, Toronto, ON, Canada, Canadian Institute for Advanced Research, Toronto, ON, Canada","Although we now routinely sequence human genomes, we can confidently identify only a fraction of the sequence variants that have a functional impact. Here, we developed a deep mutational scanning framework that produces exhaustive maps for human missense variants by combining random codon mutagenesis and multiplexed functional variation assays with computational imputation and refinement. We applied this framework to four proteins corresponding to six human genes: UBE2I (encoding SUMO E2 conjugase), SUMO1 (small ubiquitin-like modifier), TPK1 (thiamin pyrophosphokinase), and CALM1/2/3 (three genes encoding the protein calmodulin). The resulting maps recapitulate known protein features and confidently identify pathogenic variation. Assays potentially amenable to deep mutational scanning are already available for 57% of human disease genes, suggesting that DMS could ultimately map functional variation for all human disease genes. © 2017 The Authors. Published under the terms of the CC BY 4.0 license.","complementation; deep mutational scanning; genotype–phenotype; variants of uncertain significance","Calmodulin; Disease; DNA Mutational Analysis; Humans; Machine Learning; Mutation, Missense; Phenotype; Phylogeny; Reproducibility of Results; SUMO-1 Protein; Ubiquitin-Conjugating Enzymes; calmodulin; SUMO 1 protein; thiamine pyrophosphokinase; ubiquitin conjugating enzyme; ubiquitin-conjugating enzyme UBC9; Article; deep mutational scanning; gene; gene frequency; human; machine learning; missense mutation; mutational analysis; phenotype; priority journal; ube21 gene; diseases; dna mutational analysis; genetics; metabolism; missense mutation; phylogeny; procedures; reproducibility","Blackwell Publishing Ltd","17444292","","","29269382","Article","Scopus","2-s2.0-85039053585"
"Cuperus J.T.; Groves B.; Kuchina A.; Rosenberg A.B.; Jojic N.; Fields S.; Seelig G.","Cuperus, Josh T. (6602701203); Groves, Benjamin (56825416500); Kuchina, Anna (54395518200); Rosenberg, Alexander B. (53064560300); Jojic, Nebojsa (7003727143); Fields, Stanley (7102919472); Seelig, Georg (7004244336)","6602701203; 56825416500; 54395518200; 53064560300; 7003727143; 7102919472; 7004244336","Deep learning of the regulatory grammar of yeast 5′ untranslated regions from 500,000 random sequences","2017","Genome Research","111","10.1101/gr.224964.117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037713084&doi=10.1101%2fgr.224964.117&partnerID=40&md5=21fb5871647ea682b589f1e832d6fcd4","Department of Genome Sciences, University of Washington, Seattle, 98195, WA, United States; Howard, Hughes Medical Institute, University of Washington, Seattle, 98195, WA, United States; Department of Electrical Engineering, University of Washington, Seattle, 98195, WA, United States; Microsoft Research, Seattle, 98195, WA, United States; Department of Medicine, University of Washington, Seattle, 98195, WA, United States; Department of Computer Science and Engineering, University of Washington, Seattle, 98195, WA, United States","Cuperus J.T., Department of Genome Sciences, University of Washington, Seattle, 98195, WA, United States, Howard, Hughes Medical Institute, University of Washington, Seattle, 98195, WA, United States; Groves B., Department of Electrical Engineering, University of Washington, Seattle, 98195, WA, United States; Kuchina A., Department of Electrical Engineering, University of Washington, Seattle, 98195, WA, United States; Rosenberg A.B., Department of Electrical Engineering, University of Washington, Seattle, 98195, WA, United States; Jojic N., Microsoft Research, Seattle, 98195, WA, United States; Fields S., Department of Genome Sciences, University of Washington, Seattle, 98195, WA, United States, Howard, Hughes Medical Institute, University of Washington, Seattle, 98195, WA, United States, Department of Medicine, University of Washington, Seattle, 98195, WA, United States; Seelig G., Department of Electrical Engineering, University of Washington, Seattle, 98195, WA, United States, Department of Computer Science and Engineering, University of Washington, Seattle, 98195, WA, United States","Our ability to predict protein expression from DNA sequence alone remains poor, reflecting our limited understanding of cis-regulatory grammar and hampering the design of engineered genes for synthetic biology applications. Here, we generate a model that predicts the protein expression of the 5′ untranslated region (UTR) of mRNAs in the yeast Saccharomyces cerevisiae. We constructed a library of half a million 50-nucleotide-long random 5′ UTRs and assayed their activity in a massively parallel growth selection experiment. The resulting data allow us to quantify the impact on protein expression of Kozak sequence composition, upstream open reading frames (uORFs), and secondary structure. We trained a convolutional neural network (CNN) on the random library and showed that it performs well at predicting the protein expression of both a held-out set of the random 5′ UTRs as well as native S. cerevisiae 5′ UTRs. The model additionally was used to computationally evolve highly active 5′ UTRs. We confirmed experimentally that the great majority of the evolved sequences led to higher protein expression rates than the starting sequences, demonstrating the predictive power of this model. © 2017 Cuperus et al.","","5' Untranslated Regions; Alternative Splicing; Computer Simulation; Gene Library; Machine Learning; Models, Genetic; Neural Networks (Computer); RNA, Fungal; RNA, Messenger; Saccharomyces cerevisiae; messenger RNA; fungal RNA; 5' untranslated region; Article; artificial neural network; DNA sequence; molecular library; nonhuman; open reading frame; priority journal; protein expression; protein secondary structure; regulatory sequence; Saccharomyces cerevisiae; yeast; 5' untranslated region; alternative RNA splicing; biological model; computer simulation; gene library; genetics; machine learning","Cold Spring Harbor Laboratory Press","10889051","","GEREF","29097404","Article","Scopus","2-s2.0-85037713084"
"Zheng H.; Wang R.; Yu Z.; Wang N.; Gu Z.; Zheng B.","Zheng, Haiyong (24922273300); Wang, Ruchen (57190193724); Yu, Zhibin (36999020600); Wang, Nan (56957444700); Gu, Zhaorui (57190192665); Zheng, Bing (35304360700)","24922273300; 57190193724; 36999020600; 56957444700; 57190192665; 35304360700","Automatic plankton image classification combining multiple view features via multiple kernel learning","2017","BMC Bioinformatics","81","10.1186/s12859-017-1954-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039735722&doi=10.1186%2fs12859-017-1954-8&partnerID=40&md5=9b9415edf6173835c2866d7da7e1d0db","Ocean University of China, Department of Electronic Engineering, No. 238 Songling Road, Qingdao, 266100, China; Ocean University of China, College of Information Science and Engineering, No. 238 Songling Road, Qingdao, 266100, China","Zheng H., Ocean University of China, Department of Electronic Engineering, No. 238 Songling Road, Qingdao, 266100, China; Wang R., Ocean University of China, Department of Electronic Engineering, No. 238 Songling Road, Qingdao, 266100, China; Yu Z., Ocean University of China, Department of Electronic Engineering, No. 238 Songling Road, Qingdao, 266100, China; Wang N., Ocean University of China, Department of Electronic Engineering, No. 238 Songling Road, Qingdao, 266100, China; Gu Z., Ocean University of China, Department of Electronic Engineering, No. 238 Songling Road, Qingdao, 266100, China; Zheng B., Ocean University of China, College of Information Science and Engineering, No. 238 Songling Road, Qingdao, 266100, China","Background: Plankton, including phytoplankton and zooplankton, are the main source of food for organisms in the ocean and form the base of marine food chain. As the fundamental components of marine ecosystems, plankton is very sensitive to environment changes, and the study of plankton abundance and distribution is crucial, in order to understand environment changes and protect marine ecosystems. This study was carried out to develop an extensive applicable plankton classification system with high accuracy for the increasing number of various imaging devices. Literature shows that most plankton image classification systems were limited to only one specific imaging device and a relatively narrow taxonomic scope. The real practical system for automatic plankton classification is even non-existent and this study is partly to fill this gap. Results: Inspired by the analysis of literature and development of technology, we focused on the requirements of practical application and proposed an automatic system for plankton image classification combining multiple view features via multiple kernel learning (MKL). For one thing, in order to describe the biomorphic characteristics of plankton more completely and comprehensively, we combined general features with robust features, especially by adding features like Inner-Distance Shape Context for morphological representation. For another, we divided all the features into different types from multiple views and feed them to multiple classifiers instead of only one by combining different kernel matrices computed from different types of features optimally via multiple kernel learning. Moreover, we also applied feature selection method to choose the optimal feature subsets from redundant features for satisfying different datasets from different imaging devices. We implemented our proposed classification system on three different datasets across more than 20 categories from phytoplankton to zooplankton. The experimental results validated that our system outperforms state-of-the-art plankton image classification systems in terms of accuracy and robustness. Conclusions: This study demonstrated automatic plankton image classification system combining multiple view features using multiple kernel learning. The results indicated that multiple view features combined by NLMKL using three kernel functions (linear, polynomial and Gaussian kernel functions) can describe and use information of features better so that achieve a higher classification accuracy. © 2017 The Author(s).","Feature selection; Image classification; Multiple kernel learning; Multiple view features; Plankton classification","Algorithms; Automation; Databases as Topic; Deep Learning; Image Processing, Computer-Assisted; Plankton; Support Vector Machine; Ecology; Ecosystems; Feature extraction; Image classification; Imaging techniques; Phytoplankton; Plankton; Classification accuracy; Feature selection methods; Gaussian kernel functions; Image classification systems; Inner-distance shape contexts; Morphological representation; Multiple Kernel Learning; Multiple views; classification; classifier; diagnostic test accuracy study; kernel method; learning; nonhuman; phytoplankton; zooplankton; algorithm; automation; cytology; data base; image processing; plankton; support vector machine; Classification (of information)","BioMed Central Ltd.","14712105","","BBMIC","29297354","Article","Scopus","2-s2.0-85039735722"
"Rönnqvist S.; Sarlin P.","Rönnqvist, Samuel (55308200600); Sarlin, Peter (36061341300)","55308200600; 36061341300","Bank distress in the news: Describing events through deep learning","2017","Neurocomputing","42","10.1016/j.neucom.2016.12.110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021743187&doi=10.1016%2fj.neucom.2016.12.110&partnerID=40&md5=dc79cd375dc21b49fdac0a32d67142bf","Turku Centre for Computer Science – TUCS Department of Information Technologies, Åbo Akademi University, Turku, Finland; Applied Computational Linguistics Lab, Goethe University Frankfurt am Main, Germany; Department of Economics, Hanken School of Economics, Helsinki, Finland; RiskLab Finland Arcada, University of Applied Sciences, Helsinki, Finland","Rönnqvist S., Turku Centre for Computer Science – TUCS Department of Information Technologies, Åbo Akademi University, Turku, Finland, Applied Computational Linguistics Lab, Goethe University Frankfurt am Main, Germany; Sarlin P., Department of Economics, Hanken School of Economics, Helsinki, Finland, RiskLab Finland Arcada, University of Applied Sciences, Helsinki, Finland","While many models are purposed for detecting the occurrence of significant events in financial systems, the task of providing qualitative detail on the developments is not usually as well automated. We present a deep learning approach for detecting relevant discussion in text and extracting natural language descriptions of events. Supervised by only a small set of event information, comprising entity names and dates, the model is leveraged by unsupervised learning of semantic vector representations on extensive text data. We demonstrate applicability to the study of financial risk based on news (6.6M articles), particularly bank distress and government interventions (243 events), where indices can signal the level of bank-stress-related reporting at the entity level, or aggregated at national or European level, while being coupled with explanations. Thus, we exemplify how text, as timely, widely available and descriptive data, can serve as a useful complementary source of information for financial and systemic risk analytics. © 2017 Elsevier B.V.","Bank distress; Distributional semantics; Event detection; Financial risk; Neural networks; Text mining","Finance; Natural language processing systems; Neural networks; Semantics; Text mining; Distributional semantics; Event detection; Financial risks; Financial system; Government intervention; Learning approach; Natural languages; Semantic vectors; Article; artificial neural network; descriptive research; European; financial management; government; language; machine learning; model; prediction; priority journal; risk assessment; semantics; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85021743187"
"Chan P.P.K.; Lin Z.; Hu X.; Tsang E.C.C.; Yeung D.S.","Chan, Patrick P.K. (7403497727); Lin, Zhe (57194594590); Hu, Xian (57194591015); Tsang, Eric C.C. (7004402522); Yeung, Daniel S. (7103391375)","7403497727; 57194594590; 57194591015; 7004402522; 7103391375","Sensitivity based robust learning for stacked autoencoder against evasion attack","2017","Neurocomputing","18","10.1016/j.neucom.2017.06.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021955741&doi=10.1016%2fj.neucom.2017.06.032&partnerID=40&md5=689d9ae9da10bb6a4b9945cf91c1458f","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Faculty of Information Technology, Macau University of Science and Technology, Macau, Macao; IEEE SMC Society, United States","Chan P.P.K., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Lin Z., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Hu X., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Tsang E.C.C., Faculty of Information Technology, Macau University of Science and Technology, Macau, Macao; Yeung D.S., IEEE SMC Society, United States","Although deep learning has achieved excellent performance in many applications, some studies indicate that deep learning algorithms are vulnerable in an adversarial environment. A small distortion on a sample leads to misclassification easily. Until now, the vulnerability issue of stacked autoencoder, which is one of the most popular deep learning algorithms, has not been investigated. In this paper, we firstly investigate the existing evasion attack to stacked autoencoder in an effort to understand whether, and to what extent, they can work efficiently. A robust learning algorithm which minimizes both its error and sensitivity is then proposed for stacked autoencoder. The sensitivity is defined as the change of the output due to a small fluctuation on the input. As the proposed algorithm considers not only accuracy but also stability, a more robust stacked autoencoder against evasion attack is expected. The performance of our methods is then evaluated and compared with conventional stacked autoencoder and denoising autoencoder experimentally in terms of accuracy, robustness and time complexity. Moreover, the experimental results also suggest that the proposed learning method is more robust than others when a training set is contaminated. © 2017 Elsevier B.V.","Adversarial learning; Deep learning; Evasion attack; Robustness; Sensitivity","Deep learning; Robustness (control systems); Adversarial environments; Adversarial learning; Denoising Autoencoder; Evasion attack; Misclassifications; Robust learning algorithm; Sensitivity; Stacked autoencoder; Article; autoencoder; classifier; computer security; data processing; learning algorithm; machine learning; priority journal; Learning algorithms","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85021955741"
"Luo S.; Zhu L.; Althoefer K.; Liu H.","Luo, Shan (56028986000); Zhu, Leqi (57750992700); Althoefer, Kaspar (6701489118); Liu, Hongbin (55719408400)","56028986000; 57750992700; 6701489118; 55719408400","Knock-Knock: Acoustic object recognition by using stacked denoising autoencoders","2017","Neurocomputing","26","10.1016/j.neucom.2017.03.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017121577&doi=10.1016%2fj.neucom.2017.03.014&partnerID=40&md5=fe0df667aa151966cb7eac6142b95fa2","Centre for Robotics Research, Department of Informatics, King's College London, WC2R 2LS, United Kingdom; School of Engineering and Materials Science, Queen Mary University of London, E1 4NS, London, United Kingdom","Luo S., Centre for Robotics Research, Department of Informatics, King's College London, WC2R 2LS, United Kingdom; Zhu L., Centre for Robotics Research, Department of Informatics, King's College London, WC2R 2LS, United Kingdom; Althoefer K., Centre for Robotics Research, Department of Informatics, King's College London, WC2R 2LS, United Kingdom, School of Engineering and Materials Science, Queen Mary University of London, E1 4NS, London, United Kingdom; Liu H., Centre for Robotics Research, Department of Informatics, King's College London, WC2R 2LS, United Kingdom","This paper presents a successful application of deep learning for object recognition based on acoustic data. The shortcomings of previously employed approaches where handcrafted features describing the acoustic data are being used, include limiting the capability of the found representation to be widely applicable and facing the risk of capturing only insignificant characteristics for a task. In contrast, there is no need to define the feature representation format when using multilayer/deep learning architecture methods: features can be learned from raw sensor data without defining discriminative characteristics a-priori. In this paper, stacked denoising autoencoders are applied to train a deep learning model. Knocking each object in our test set 120 times with a marker pen to obtain the auditory data, thirty different objects were successfully classified in our experiment and each object was knocked 120 times by a marker pen to obtain the auditory data. By employing the proposed deep learning framework, a high accuracy of 91.50% was achieved. A traditional method using handcrafted features with a shallow classifier was taken as a benchmark and the attained recognition rate was only 58.22%. Interestingly, a recognition rate of 82.00% was achieved when using a shallow classifier with raw acoustic data as input. In addition, we could show that the time taken to classify one object using deep learning was far less (by a factor of more than 6) than utilizing the traditional method. It was also explored how different model parameters in our deep architecture affect the recognition performance. © 2017 Elsevier B.V.","Acoustic data analysis; Deep networks; Object recognition","Deep learning; Learning systems; Network architecture; Object recognition; Acoustic data; Deep architectures; Feature representation; High-accuracy; Learning architectures; Learning frameworks; Learning models; Model parameters; acoustics; Article; automated pattern recognition; classifier; deep learning; intermethod comparison; machine learning; priority journal; sound; stacked denoising autoencoder; support vector machine; Classification (of information)","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85017121577"
"Qu Y.-H.; Yu H.; Gong X.-J.; Xu J.-H.; Lee H.-S.","Qu, Yu-Hui (57200130643); Yu, Hua (56822179300); Gong, Xiu-Jun (17343586700); Xu, Jia-Hui (57200129209); Lee, Hong-Shun (57200134218)","57200130643; 56822179300; 17343586700; 57200129209; 57200134218","On the prediction of DNA-binding proteins only from primary sequences: A deep learning approach","2017","PLoS ONE","48","10.1371/journal.pone.0188129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039863846&doi=10.1371%2fjournal.pone.0188129&partnerID=40&md5=08b343a61597e7776c0a3d6a2d01c28d","School of Computer Science and Technology, Tianjin University, Nankai, Tianjin, 30072, China; Tianjin Key Laboratory of Cognitive Computing and Application, Nankai, Tianjin, 30072, China; Beijing KEDONG Electric Power Control System Co. LTD, Qinghe, Beijing, 100192, China","Qu Y.-H., School of Computer Science and Technology, Tianjin University, Nankai, Tianjin, 30072, China, Tianjin Key Laboratory of Cognitive Computing and Application, Nankai, Tianjin, 30072, China; Yu H., School of Computer Science and Technology, Tianjin University, Nankai, Tianjin, 30072, China, Tianjin Key Laboratory of Cognitive Computing and Application, Nankai, Tianjin, 30072, China; Gong X.-J., School of Computer Science and Technology, Tianjin University, Nankai, Tianjin, 30072, China, Tianjin Key Laboratory of Cognitive Computing and Application, Nankai, Tianjin, 30072, China; Xu J.-H., Beijing KEDONG Electric Power Control System Co. LTD, Qinghe, Beijing, 100192, China; Lee H.-S., School of Computer Science and Technology, Tianjin University, Nankai, Tianjin, 30072, China, Tianjin Key Laboratory of Cognitive Computing and Application, Nankai, Tianjin, 30072, China","DNA-binding proteins play pivotal roles in alternative splicing, RNA editing, methylating and many other biological functions for both eukaryotic and prokaryotic proteomes. Predicting the functions of these proteins from primary amino acids sequences is becoming one of the major challenges in functional annotations of genomes. Traditional prediction methods often devote themselves to extracting physiochemical features from sequences but ignoring motif information and location information between motifs. Meanwhile, the small scale of data volumes and large noises in training data result in lower accuracy and reliability of predictions. In this paper, we propose a deep learning based method to identify DNA-binding proteins from primary sequences alone. It utilizes two stages of convolutional neutral network to detect the function domains of protein sequences, and the long short-term memory neural network to identify their long term dependencies, an binary cross entropy to evaluate the quality of the neural networks. When the proposed method is tested with a realistic DNA binding protein dataset, it achieves a prediction accuracy of 94.2% at the Matthew’s correlation coefficient of 0.961. Compared with the LibSVM on the arabidopsis and yeast datasets via independent tests, the accuracy raises by 9% and 4% respectively. Comparative experiments using different feature extraction methods show that our model performs similar accuracy with the best of others, but its values of sensitivity, specificity and AUC increase by 27.83%, 1.31% and 16.21% respectively. Those results suggest that our method is a promising tool for identifying DNA-binding proteins. © 2017 Qu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Amino Acid Sequence; Arabidopsis; DNA-Binding Proteins; Models, Theoretical; Reproducibility of Results; Yeasts; DNA binding protein; DNA binding protein; amino acid sequence; Arabidopsis; area under the curve; Article; controlled study; correlation coefficient; entropy; gene expression profiling; human; machine learning; nonhuman; physical chemistry; protein analysis; protein DNA binding; protein domain; protein motif; random forest; sensitivity and specificity; support vector machine; yeast; amino acid sequence; chemistry; genetics; metabolism; reproducibility; theoretical model","Public Library of Science","19326203","","POLNC","29287069","Article","Scopus","2-s2.0-85039863846"
"Jurtz V.I.; Johansen A.R.; Nielsen M.; Almagro Armenteros J.J.; Nielsen H.; Sønderby C.K.; Winther O.; Sønderby Sø.K.","Jurtz, Vanessa Isabell (57189091550); Johansen, Alexander Rosenberg (57189603133); Nielsen, Morten (58463508800); Almagro Armenteros, Jose Juan (57197746813); Nielsen, Henrik (55506452600); Sønderby, Casper Kaae (56955507900); Winther, Ole (6701382702); Sønderby, Søren Kaae (57015250400)","57189091550; 57189603133; 58463508800; 57197746813; 55506452600; 56955507900; 6701382702; 57015250400","An introduction to deep learning on biological sequence data: Examples and solutions","2017","Bioinformatics","106","10.1093/bioinformatics/btx531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034426580&doi=10.1093%2fbioinformatics%2fbtx531&partnerID=40&md5=e6a15900b2df1a20d0c6c4b6036a7a75","Department of Bio and Health Informatics, Denmark; Department of Applied Mathematics and Computer Science, Technical University of Denmark, Lyngby, Denmark; Instituto de Investigaciones Biotecnológicas, Universidad Nacional de San Martín, Buenos Aires, Argentina; Department of Biology, University of Copenhagen, Copenhagen, Denmark","Jurtz V.I., Department of Bio and Health Informatics, Denmark; Johansen A.R., Department of Applied Mathematics and Computer Science, Technical University of Denmark, Lyngby, Denmark; Nielsen M., Department of Bio and Health Informatics, Denmark, Instituto de Investigaciones Biotecnológicas, Universidad Nacional de San Martín, Buenos Aires, Argentina; Almagro Armenteros J.J., Department of Bio and Health Informatics, Denmark; Nielsen H., Department of Bio and Health Informatics, Denmark; Sønderby C.K., Department of Biology, University of Copenhagen, Copenhagen, Denmark; Winther O., Department of Applied Mathematics and Computer Science, Technical University of Denmark, Lyngby, Denmark, Department of Biology, University of Copenhagen, Copenhagen, Denmark; Sønderby Sø.K., Department of Biology, University of Copenhagen, Copenhagen, Denmark","Motivation Deep neural network architectures such as convolutional and long short-term memory networks have become increasingly popular as machine learning tools during the recent years. The availability of greater computational resources, more data, new algorithms for training deep models and easy to use libraries for implementation and training of neural networks are the drivers of this development. The use of deep learning has been especially successful in image recognition; and the development of tools, applications and code examples are in most cases centered within this field rather than within biology. Results Here, we aim to further the development of deep learning methods within biology by providing application examples and ready to apply and adapt code templates. Given such examples, we illustrate how architectures consisting of convolutional and long short-term memory neural networks can relatively easily be designed and trained to state-of-the-art performance on three biological sequence problems: prediction of subcellular localization, protein secondary structure and the binding of peptides to MHC Class II molecules. Availability and implementation All implementations and datasets are available online to the scientific community at https://github.com/vanessajurtz/lasagne4bio. Contact skaaesonderby@gmail.com Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author 2017. Published by Oxford University Press. All rights reserved.","","Computational Biology; Machine Learning; Neural Networks (Computer); Peptides; Protein Binding; Protein Structure, Secondary; Protein Transport; Sequence Analysis, Protein; peptide; protein binding; artificial neural network; biology; machine learning; metabolism; procedures; protein secondary structure; protein transport; sequence analysis","Oxford University Press","13674803","","BOINF","28961695","Article","Scopus","2-s2.0-85034426580"
"Wang H.; Zhou Z.; Li Y.; Chen Z.; Lu P.; Wang W.; Liu W.; Yu L.","Wang, Hongkai (52365086000); Zhou, Zongwei (57201419561); Li, Yingci (36514965600); Chen, Zhonghua (57193110729); Lu, Peiou (36010797600); Wang, Wenzhi (57233034400); Liu, Wanyu (56255789200); Yu, Lijuan (55686827100)","52365086000; 57201419561; 36514965600; 57193110729; 36010797600; 57233034400; 56255789200; 55686827100","Comparison of machine learning methods for classifying mediastinal lymph node metastasis of non-small cell lung cancer from 18F-FDG PET/CT images","2017","EJNMMI Research","201","10.1186/s13550-017-0260-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010894651&doi=10.1186%2fs13550-017-0260-9&partnerID=40&md5=f993083a0662d75b12c0585d861e7ad9","Department of Biomedical Engineering, Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, No. 2 Linggong Street, Ganjingzi District, Dalian, 116024, Liaoning, China; Department of Biomedical Informatics and the College of Health Solutions, Arizona State University, 13212 East Shea Boulevard, Scottsdale, 85259, AZ, United States; Center of PET/CT, The Affiliated Tumor Hospital of Harbin Medical University, 150 Haping Road, Nangang District, Harbin, 150081, Heilongjiang Province, China; HIT–INSA Sino French Research Centre for Biomedical Imaging, Harbin Institute of Technology, Harbin, 150001, Heilongjiang, China","Wang H., Department of Biomedical Engineering, Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, No. 2 Linggong Street, Ganjingzi District, Dalian, 116024, Liaoning, China; Zhou Z., Department of Biomedical Informatics and the College of Health Solutions, Arizona State University, 13212 East Shea Boulevard, Scottsdale, 85259, AZ, United States; Li Y., Center of PET/CT, The Affiliated Tumor Hospital of Harbin Medical University, 150 Haping Road, Nangang District, Harbin, 150081, Heilongjiang Province, China; Chen Z., Department of Biomedical Engineering, Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, No. 2 Linggong Street, Ganjingzi District, Dalian, 116024, Liaoning, China; Lu P., Center of PET/CT, The Affiliated Tumor Hospital of Harbin Medical University, 150 Haping Road, Nangang District, Harbin, 150081, Heilongjiang Province, China; Wang W., Center of PET/CT, The Affiliated Tumor Hospital of Harbin Medical University, 150 Haping Road, Nangang District, Harbin, 150081, Heilongjiang Province, China; Liu W., HIT–INSA Sino French Research Centre for Biomedical Imaging, Harbin Institute of Technology, Harbin, 150001, Heilongjiang, China; Yu L., Center of PET/CT, The Affiliated Tumor Hospital of Harbin Medical University, 150 Haping Road, Nangang District, Harbin, 150081, Heilongjiang Province, China","Background: This study aimed to compare one state-of-the-art deep learning method and four classical machine learning methods for classifying mediastinal lymph node metastasis of non-small cell lung cancer (NSCLC) from 18F-FDG PET/CT images. Another objective was to compare the discriminative power of the recently popular PET/CT texture features with the widely used diagnostic features such as tumor size, CT value, SUV, image contrast, and intensity standard deviation. The four classical machine learning methods included random forests, support vector machines, adaptive boosting, and artificial neural network. The deep learning method was the convolutional neural networks (CNN). The five methods were evaluated using 1397 lymph nodes collected from PET/CT images of 168 patients, with corresponding pathology analysis results as gold standard. The comparison was conducted using 10 times 10-fold cross-validation based on the criterion of sensitivity, specificity, accuracy (ACC), and area under the ROC curve (AUC). For each classical method, different input features were compared to select the optimal feature set. Based on the optimal feature set, the classical methods were compared with CNN, as well as with human doctors from our institute. Results: For the classical methods, the diagnostic features resulted in 81~85% ACC and 0.87~0.92 AUC, which were significantly higher than the results of texture features. CNN’s sensitivity, specificity, ACC, and AUC were 84, 88, 86, and 0.91, respectively. There was no significant difference between the results of CNN and the best classical method. The sensitivity, specificity, and ACC of human doctors were 73, 90, and 82, respectively. All the five machine learning methods had higher sensitivities but lower specificities than human doctors. Conclusions: The present study shows that the performance of CNN is not significantly different from the best classical methods and human doctors for classifying mediastinal lymph node metastasis of NSCLC from PET/CT images. Because CNN does not need tumor segmentation or feature calculation, it is more convenient and more objective than the classical methods. However, CNN does not make use of the import diagnostic features, which have been proved more discriminative than the texture features for classifying small-sized lymph nodes. Therefore, incorporating the diagnostic features into CNN is a promising direction for future research. © 2017, The Author(s).","Computer-aided diagnosis; Deep learning; Machine learning; Non-small cell lung cancer; Positron-emission tomography","fluorodeoxyglucose f 18; adult; aged; area under the curve; Article; comparative study; computer assisted tomography; controlled study; diagnostic test accuracy study; female; human; image analysis; intermethod comparison; lymph node metastasis; machine learning; major clinical study; male; mediastinum lymph node; non small cell lung cancer; positron emission tomography; priority journal; sensitivity and specificity; tumor classification; validation therapy","Springer Verlag","2191219X","","","","Article","Scopus","2-s2.0-85010894651"
"Smith K.P.; Richmond D.L.; Brennan-Krohn T.; Elliott H.L.; Kirby J.E.","Smith, Kenneth P. (57213077987); Richmond, David L. (57197056767); Brennan-Krohn, Thea (14619084500); Elliott, Hunter L. (35094022600); Kirby, James E. (7202383785)","57213077987; 57197056767; 14619084500; 35094022600; 7202383785","Development of MAST: A Microscopy-Based Antimicrobial Susceptibility Testing Platform","2017","SLAS Technology","23","10.1177/2472630317727721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034746957&doi=10.1177%2f2472630317727721&partnerID=40&md5=89d7dca6332d6dce154e3ecd3eb5cccd","Department of Pathology, Beth Israel Deaconess Medical Center, Boston, MA, United States; Image and Data Analysis Core, Harvard Medical School, Boston, MA, United States; Division of Infectious Diseases, Boston Children’s Hospital, Boston, MA, United States","Smith K.P., Department of Pathology, Beth Israel Deaconess Medical Center, Boston, MA, United States; Richmond D.L., Image and Data Analysis Core, Harvard Medical School, Boston, MA, United States; Brennan-Krohn T., Department of Pathology, Beth Israel Deaconess Medical Center, Boston, MA, United States, Division of Infectious Diseases, Boston Children’s Hospital, Boston, MA, United States; Elliott H.L., Image and Data Analysis Core, Harvard Medical School, Boston, MA, United States; Kirby J.E., Department of Pathology, Beth Israel Deaconess Medical Center, Boston, MA, United States","Antibiotic resistance is compromising our ability to treat bacterial infections. Clinical microbiology laboratories guide appropriate treatment through antimicrobial susceptibility testing (AST) of patient bacterial isolates. However, increasingly, pathogens are developing resistance to a broad range of antimicrobials, requiring AST of alternative agents for which no commercially available testing methods are available. Therefore, there exists a significant AST testing gap in which current methodologies cannot adequately address the need for rapid results in the face of unpredictable susceptibility profiles. To address this gap, we developed a multicomponent, microscopy-based AST (MAST) platform capable of AST determinations after only a 2 h incubation. MAST consists of a solid-phase microwell growth surface in a 384-well plate format, inkjet printing–based application of both antimicrobials and bacteria at any desired concentrations, automated microscopic imaging of bacterial replication, and a deep learning approach for automated image classification and determination of antimicrobial minimal inhibitory concentrations (MICs). In evaluating a susceptible strain set, 95.8% were within ±1 and 99.4% were within ±2, twofold dilutions, respectively, of reference broth microdilution MIC values. Most (98.3%) of the results were in categorical agreement. We conclude that MAST offers promise for rapid, accurate, and flexible AST to help address the antimicrobial testing gap. © 2017, © 2017 Society for Laboratory Automation and Screening.","antimicrobials; inkjet printing; machine learning; susceptibility testing","Anti-Infective Agents; Bacteria; Humans; Microbial Sensitivity Tests; Microscopy; Time Factors; Deep learning; Ink jet printing; Learning systems; Microorganisms; Microwave integrated circuits; Patient treatment; Testing; cefepime; ciprofloxacin; gentamicin; meropenem; antiinfective agent; Antibiotic resistance; Antimicrobial susceptibility testing; Antimicrobial testing; antimicrobials; Bacterial infections; Bacterial replication; Clinical microbiology laboratories; Minimal inhibitory concentration; Acinetobacter baumannii; antibiotic resistance; antibiotic sensitivity; Article; bacterial growth; broth dilution; cell density; cell structure; colony forming unit; controlled study; culture optimization; Enterobacter cloacae; Escherichia coli; growth inhibition; image processing; interference microscopy; Klebsiella pneumoniae; learning; microscopy; microscopy based antibiotic sensitivity; microtiter plate assay; minimum inhibitory concentration; nonhuman; phase contrast microscopy; Pseudomonas aeruginosa; bacterium; drug effect; evaluation study; human; microbial sensitivity test; microscopy; procedures; time factor; Antimicrobial agents","SAGE Publications Inc.","24726303","","","28837780","Article","Scopus","2-s2.0-85034746957"
"Jauregi Unanue I.; Zare Borzeshi E.; Piccardi M.","Jauregi Unanue, Iñigo (57205405527); Zare Borzeshi, Ehsan (50861172400); Piccardi, Massimo (7003728868)","57205405527; 50861172400; 7003728868","Recurrent neural networks with specialized word embeddings for health-domain named-entity recognition","2017","Journal of Biomedical Informatics","92","10.1016/j.jbi.2017.11.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034622038&doi=10.1016%2fj.jbi.2017.11.007&partnerID=40&md5=a9a334df8705c8291b707a64807b2896","University of Technology Sydney (UTS), Australia; Capital Markets Cooperative Research Centre (CMCRC), Australia","Jauregi Unanue I., University of Technology Sydney (UTS), Australia, Capital Markets Cooperative Research Centre (CMCRC), Australia; Zare Borzeshi E., Capital Markets Cooperative Research Centre (CMCRC), Australia; Piccardi M., University of Technology Sydney (UTS), Australia","Background Previous state-of-the-art systems on Drug Name Recognition (DNR) and Clinical Concept Extraction (CCE) have focused on a combination of text “feature engineering” and conventional machine learning algorithms such as conditional random fields and support vector machines. However, developing good features is inherently heavily time-consuming. Conversely, more modern machine learning approaches such as recurrent neural networks (RNNs) have proved capable of automatically learning effective features from either random assignments or automated word “embeddings”. Objectives (i) To create a highly accurate DNR and CCE system that avoids conventional, time-consuming feature engineering. (ii) To create richer, more specialized word embeddings by using health domain datasets such as MIMIC-III. (iii) To evaluate our systems over three contemporary datasets. Methods Two deep learning methods, namely the Bidirectional LSTM and the Bidirectional LSTM-CRF, are evaluated. A CRF model is set as the baseline to compare the deep learning systems to a traditional machine learning approach. The same features are used for all the models. Results We have obtained the best results with the Bidirectional LSTM-CRF model, which has outperformed all previously proposed systems. The specialized embeddings have helped to cover unusual words in DrugBank and MedLine, but not in the i2b2/VA dataset. Conclusions We present a state-of-the-art system for DNR and CCE. Automated word embeddings has allowed us to avoid costly feature engineering and achieve higher accuracy. Nevertheless, the embeddings need to be retrained over datasets that are adequate for the domain, in order to adequately cover the domain-specific vocabulary. © 2017 Elsevier Inc.","Artificial intelligence [MeSH]; Clinical concept extraction; Drug name recognition; Machine learning [MeSH]; Neural networks (computer) [MeSH]","Algorithms; Databases, Factual; Humans; Machine Learning; Neural Networks (Computer); Character recognition; Cost engineering; Deep learning; Extraction; Information retrieval; Learning algorithms; Mesh generation; MESH networking; Natural language processing systems; Random processes; Text processing; Concept extraction; Conditional random field; Conventional machines; Machine learning approaches; Name recognition; Named entity recognition; Recurrent neural network (RNNs); State-of-the-art system; accuracy; Article; artificial neural network; automation; clinical concept extraction; drug name recognition; information processing; long short term memory; long term memory; machine learning; natural language processing; priority journal; recurrent neural network; short term memory; word recognition; algorithm; factual database; human; Long short-term memory","Academic Press Inc.","15320464","","JBIOB","29146561","Article","Scopus","2-s2.0-85034622038"
"Men K.; Dai J.; Li Y.","Men, Kuo (36464032300); Dai, Jianrong (7401679180); Li, Yexiong (35286024200)","36464032300; 7401679180; 35286024200","Automatic segmentation of the clinical target volume and organs at risk in the planning CT for rectal cancer using deep dilated convolutional neural networks:","2017","Medical Physics","237","10.1002/mp.12602","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032264644&doi=10.1002%2fmp.12602&partnerID=40&md5=a8bde8fc7fd7ccf5d7085ffcf366bbf6","National Cancer Center, Cancer Hospital Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China","Men K., National Cancer Center, Cancer Hospital Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China; Dai J., National Cancer Center, Cancer Hospital Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China; Li Y., National Cancer Center, Cancer Hospital Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China","Purpose: Delineation of the clinical target volume (CTV) and organs at risk (OARs) is very important for radiotherapy but is time-consuming and prone to inter-observer variation. Here, we proposed a novel deep dilated convolutional neural network (DDCNN)-based method for fast and consistent auto-segmentation of these structures. Methods: Our DDCNN method was an end-to-end architecture enabling fast training and testing. Specifically, it employed a novel multiple-scale convolutional architecture to extract multiple-scale context features in the early layers, which contain the original information on fine texture and boundaries and which are very useful for accurate auto-segmentation. In addition, it enlarged the receptive fields of dilated convolutions at the end of networks to capture complementary context features. Then, it replaced the fully connected layers with fully convolutional layers to achieve pixel-wise segmentation. We used data from 278 patients with rectal cancer for evaluation. The CTV and OARs were delineated and validated by senior radiation oncologists in the planning computed tomography (CT) images. A total of 218 patients chosen randomly were used for training, and the remaining 60 for validation. The Dice similarity coefficient (DSC) was used to measure segmentation accuracy. Results: Performance was evaluated on segmentation of the CTV and OARs. In addition, the performance of DDCNN was compared with that of U-Net. The proposed DDCNN method outperformed the U-Net for all segmentations, and the average DSC value of DDCNN was 3.8% higher than that of U-Net. Mean DSC values of DDCNN were 87.7% for the CTV, 93.4% for the bladder, 92.1% for the left femoral head, 92.3% for the right femoral head, 65.3% for the intestine, and 61.8% for the colon. The test time was 45 s per patient for segmentation of all the CTV, bladder, left and right femoral heads, colon, and intestine. We also assessed our approaches and results with those in the literature: our system showed superior performance and faster speed. Conclusions: These data suggest that DDCNN can be used to segment the CTV and OARs accurately and efficiently. It was invariant to the body size, body shape, and age of the patients. DDCNN could improve the consistency of contouring and streamline radiotherapy workflows. © 2017 American Association of Physicists in Medicine.","automatic segmentation; clinical target volume; deep dilated convolutional neural networks; deep learning; organs at risk; radiotherapy","Automation; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Organs at Risk; Radiotherapy Planning, Computer-Assisted; Rectal Neoplasms; Time Factors; Tomography, X-Ray Computed; Computerized tomography; Convolution; Deep neural networks; Diseases; Image segmentation; Network architecture; Pixels; iohexol; Automatic segmentations; Clinical target volumes; Convolutional neural network; Deep dilated convolutional neural network; Deep learning; Femoral heads; Organs at risks; Performance; Similarity coefficients; Target organs; Article; artificial neural network; automation; bladder tissue; body build; body size; cancer radiotherapy; clinical evaluation; clinical feature; Clinical Target Volume; colon tissue; comparative study; cone beam computed tomography; dilated convolutional neural network; femoral head; human; image analysis; image enhancement; image segmentation; intestine tissue; major clinical study; medical information; organs at risk; radiation oncologist; receptive field; rectum cancer; time to treatment; treatment planning; diagnostic imaging; image processing; machine learning; organs at risk; procedures; radiation response; radiotherapy planning system; rectum tumor; time factor; x-ray computed tomography; Radiotherapy","John Wiley and Sons Ltd","00942405","","MPHYA","28963779","Article","Scopus","2-s2.0-85032264644"
"Mohammed A.; Zamani M.; Bayford R.; Demosthenous A.","Mohammed, Ameer (57037956700); Zamani, Majid (57198744432); Bayford, Richard (6603764288); Demosthenous, Andreas (6603720155)","57037956700; 57198744432; 6603764288; 6603720155","Toward on-demand deep brain stimulation using online Parkinson’s disease prediction driven by dynamic detection","2017","IEEE Transactions on Neural Systems and Rehabilitation Engineering","23","10.1109/TNSRE.2017.2722986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023199283&doi=10.1109%2fTNSRE.2017.2722986&partnerID=40&md5=caf47ff28c2fdd5149b873fc535730e3","Department of Electronic and Electrical Engineering, University College London, London, WC1E 7JE, United Kingdom; Department of Natural Sciences, Middlesex University, London, NW4 6BT, United Kingdom","Mohammed A., Department of Electronic and Electrical Engineering, University College London, London, WC1E 7JE, United Kingdom; Zamani M., Department of Electronic and Electrical Engineering, University College London, London, WC1E 7JE, United Kingdom; Bayford R., Department of Natural Sciences, Middlesex University, London, NW4 6BT, United Kingdom; Demosthenous A., Department of Electronic and Electrical Engineering, University College London, London, WC1E 7JE, United Kingdom","In Parkinson’s disease (PD), on-demand deep brain stimulation is required so that stimulation is regulated to reduce side effects resulting from continuous stimulation and PD exacerbation due to untimely stimulation. Also, the progressive nature of PD necessitates the use of dynamic detection schemes that can track the nonlinearities in PD. This paper proposes the use of dynamic feature extraction and dynamic pattern classification to achieve dynamic PD detection taking into account the demand for high accuracy, low computation, and real-time detection. The dynamic feature extraction and dynamic pattern classification are selected by evaluating a subset of feature extraction, dimensionality reduction, and classification algorithms that have been used in brain–machine interfaces. A novel dimensionality reduction technique, the maximum ratio method (MRM) is proposed, which provides the most efficient performance. In terms of accuracy and complexity for hardware implementation, a combination having discrete wavelet transform for feature extraction, MRM for dimensionality reduction, and dynamic k-nearest neighbor for classification was chosen as the most efficient. It achieves a classification accuracy of 99.29%, an F1-score of 97.90%, and a choice probability of 99.86%. © 2017 IEEE.","Biomedical signal processing; Deep brain stimulation (DBS); Dimensionality reduction; Dynamic detection; Dynamic pattern classification; Feature extraction; Parkinson’s disease; Semi-synthetic LFP generation","Algorithms; Computer Simulation; Computer Systems; Deep Brain Stimulation; Electroencephalography; Fourier Analysis; Humans; Nonlinear Dynamics; Normal Distribution; Parkinson Disease; Reproducibility of Results; Subthalamic Nucleus; Support Vector Machine; Wavelet Analysis; Biomedical signal processing; Brain computer interface; Classification (of information); Discrete wavelet transforms; Extraction; Hardware; Nearest neighbor search; Neurosurgery; Signal processing; Deep brain stimulation; Dimensionality reduction; Dynamic detection; Dynamic patterns; Parkinson; semi-synthetic LFP generation; accuracy; algorithm; Article; bradykinesia; brain depth stimulation; dynamics; electroencephalography; local field potential; machine learning; mathematical model; Parkinson disease; probability; receiver operating characteristic; sensitivity and specificity; signal processing; support vector machine; brain depth stimulation; classification; computer simulation; computer system; Fourier analysis; human; nonlinear system; normal distribution; Parkinson disease; procedures; reproducibility; subthalamic nucleus; wavelet analysis; Feature extraction","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","28682261","Article","Scopus","2-s2.0-85023199283"
"Xu Y.; Wang Y.; Luo J.; Zhao W.; Zhou X.","Xu, Yungang (55673393300); Wang, Yongcui (36674054100); Luo, Jiesi (55482635000); Zhao, Weiling (55303603800); Zhou, Xiaobo (57200238870)","55673393300; 36674054100; 55482635000; 55303603800; 57200238870","Deep learning of the splicing (epi)genetic code reveals a novel candidate mechanism linking histone modifications to ESC fate decision","2017","Nucleic Acids Research","58","10.1093/nar/gkx870","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039060379&doi=10.1093%2fnar%2fgkx870&partnerID=40&md5=a7e6433414339570175e63c066937fd2","Center for Systems Medicine, School of Biomedical Bioinformatics, 77030, TX, United States; Center for Bioinformatics and Systems Biology, Wake Forest School of Medicine, Winston-Salem, 27157, NC, United States; Key Laboratory of Adaptation and Evolution of Plateau Biota, Northwest Institute of Plateau Biology, Chinese Academy of Sciences, Xining, Qinghai, 810008, China","Xu Y., Center for Systems Medicine, School of Biomedical Bioinformatics, 77030, TX, United States, Center for Bioinformatics and Systems Biology, Wake Forest School of Medicine, Winston-Salem, 27157, NC, United States; Wang Y., Key Laboratory of Adaptation and Evolution of Plateau Biota, Northwest Institute of Plateau Biology, Chinese Academy of Sciences, Xining, Qinghai, 810008, China; Luo J., Center for Systems Medicine, School of Biomedical Bioinformatics, 77030, TX, United States; Zhao W., Center for Systems Medicine, School of Biomedical Bioinformatics, 77030, TX, United States; Zhou X., Center for Systems Medicine, School of Biomedical Bioinformatics, 77030, TX, United States, Center for Bioinformatics and Systems Biology, Wake Forest School of Medicine, Winston-Salem, 27157, NC, United States","Alternative splicing (AS) is a genetically and epigenetically regulated pre-mRNA processing to increase transcriptome and proteome diversity. Comprehensively decoding these regulatory mechanisms holds promise in getting deeper insights into a variety of biological contexts involving in AS, such as development and diseases. We assembled splicing (epi)genetic code, DeepCode, for human embryonic stem cell (hESC) differentiation by integrating heterogeneous features of genomic sequences, 16 histone modifications with a multi-label deep neural network. With the advantages of epigenetic features, DeepCode significantly improves the performance in predicting the splicing patterns and their changes during hESC differentiation. Meanwhile, DeepCode reveals the superiority of epigenomic features and their dominant roles in decoding AS patterns, highlighting the necessity of including the epigenetic properties when assembling a more comprehensive splicing code.Moreover, DeepCode allows the robust predictions across cell lineages and datasets. Especially, we identified a putative H3K36me3-regulated AS event leading to a nonsense-mediated mRNA decay of BARD1. Reduced BARD1 expression results in the attenuation of ATM/ATR signalling activities and further the hESC differentiation. These results suggest a novel candidate mechanism linking histone modifications to hESC fate decision. In addition, when trained in different contexts, DeepCode can be expanded to a variety of biological and biomedical fields. © The Author(s) 2017.","","Alternative Splicing; Cell Differentiation; Cell Line; Cell Lineage; Embryonic Stem Cells; Epigenesis, Genetic; High-Throughput Nucleotide Sequencing; Histone Code; Humans; Machine Learning; Neural Networks (Computer); Sequence Analysis, RNA; Tumor Suppressor Proteins; Ubiquitin-Protein Ligases; BRCA1 associated ring domain protein 1; histone; messenger RNA; BARD1 protein, human; tumor suppressor protein; ubiquitin protein ligase; alternative RNA splicing; Article; artificial neural network; cell differentiation; cell fate; cell lineage; controlled study; DeepCode; embryo; embryonic stem cell; epigenetics; gene sequence; genetic code; histone modification; human; human cell; nonsense mediated mRNA decay; prediction; priority journal; protein expression; signal transduction; artificial neural network; cell line; embryonic stem cell; evaluation study; genetic epigenesis; genetics; high throughput sequencing; histone code; machine learning; metabolism; sequence analysis","Oxford University Press","03051048","","NARHA","29036709","Article","Scopus","2-s2.0-85039060379"
"Tarasova O.; Rudik A.; Dmitriev A.; Lagunin A.; Filimonov D.; Poroikov V.","Tarasova, Olga (55914745500); Rudik, Anastassia (6603691745); Dmitriev, Alexander (55574184314); Lagunin, Alexey (6602271875); Filimonov, Dmitry (7003288016); Poroikov, Vladimir (7004294720)","55914745500; 6603691745; 55574184314; 6602271875; 7003288016; 7004294720","Qna-based prediction of sites of metabolism","2017","Molecules","7","10.3390/molecules22122123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040370022&doi=10.3390%2fmolecules22122123&partnerID=40&md5=3a067312aa381089fac3eaadee6a671f","Institute of Biomedical Chemistry, 10 Building 8, Pogodinskaya Street, Moscow, 119121, Russian Federation; Pirogov Russian National Research Medical University, 1 Ostrovityanova Str., Moscow, 117997, Russian Federation","Tarasova O., Institute of Biomedical Chemistry, 10 Building 8, Pogodinskaya Street, Moscow, 119121, Russian Federation; Rudik A., Institute of Biomedical Chemistry, 10 Building 8, Pogodinskaya Street, Moscow, 119121, Russian Federation; Dmitriev A., Institute of Biomedical Chemistry, 10 Building 8, Pogodinskaya Street, Moscow, 119121, Russian Federation; Lagunin A., Institute of Biomedical Chemistry, 10 Building 8, Pogodinskaya Street, Moscow, 119121, Russian Federation, Pirogov Russian National Research Medical University, 1 Ostrovityanova Str., Moscow, 117997, Russian Federation; Filimonov D., Institute of Biomedical Chemistry, 10 Building 8, Pogodinskaya Street, Moscow, 119121, Russian Federation; Poroikov V., Institute of Biomedical Chemistry, 10 Building 8, Pogodinskaya Street, Moscow, 119121, Russian Federation","Metabolism of xenobiotics (Greek xenos: exogenous substances) plays an essential role in the prediction of biological activity and testing for the subsequent research and development of new drug candidates. Integration of various methods and techniques using different computational and experimental approaches is one of the keys to a successful metabolism prediction. While multiple structure-based and ligand-based approaches to metabolism prediction exist, the most important problem arises at the first stage of metabolism prediction: detection of the sites of metabolism (SOMs). In this paper, we describe the application of Quantitative Neighborhoods of Atoms (QNA) descriptors for prediction of the SOMs using potential function method, as well as several different machine learning techniques: naïve Bayes, random forest classifier, multilayer perceptron with back propagation and convolutional neural networks, and deep neural networks. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Computational prediction; Cytochromes; QNA; Quantitative Neighborhoods of Atoms; Sites of metabolism; SOM","Bayes Theorem; Cytochrome P-450 Enzyme System; Datasets as Topic; Humans; Ligands; Machine Learning; Models, Chemical; Molecular Structure; Neural Networks (Computer); Xenobiotics; cytochrome P450; ligand; xenobiotic agent; artificial neural network; Bayes theorem; chemical model; chemical structure; chemistry; human; information processing; machine learning; metabolism","MDPI AG","14203049","","MOLEF","29194399","Article","Scopus","2-s2.0-85040370022"
"Shahin M.; Ahmed B.; Hamida S.T.-B.; Mulaffer F.L.; Glos M.; Penzel T.","Shahin, Mostafa (24345241900); Ahmed, Beena (24801981100); Hamida, Sana Tmar-Ben (35759039100); Mulaffer, Fathima Lamana (57190287420); Glos, Martin (6603077240); Penzel, Thomas (57207902667)","24345241900; 24801981100; 35759039100; 57190287420; 6603077240; 57207902667","Deep Learning and Insomnia: Assisting Clinicians with Their Diagnosis","2017","IEEE Journal of Biomedical and Health Informatics","67","10.1109/JBHI.2017.2650199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035787462&doi=10.1109%2fJBHI.2017.2650199&partnerID=40&md5=01bbbcee6a9f79c21e238ead62ff9879","Electrical and Computer Engineering Program, Texas AandM University at Qatar, Doha, 123, Qatar; Interdisciplinary Centre for Sleep Medicine, Charité University Hospital, Berlin, D-10177, Germany","Shahin M., Electrical and Computer Engineering Program, Texas AandM University at Qatar, Doha, 123, Qatar; Ahmed B., Electrical and Computer Engineering Program, Texas AandM University at Qatar, Doha, 123, Qatar; Hamida S.T.-B., Electrical and Computer Engineering Program, Texas AandM University at Qatar, Doha, 123, Qatar; Mulaffer F.L., Electrical and Computer Engineering Program, Texas AandM University at Qatar, Doha, 123, Qatar; Glos M., Interdisciplinary Centre for Sleep Medicine, Charité University Hospital, Berlin, D-10177, Germany; Penzel T., Interdisciplinary Centre for Sleep Medicine, Charité University Hospital, Berlin, D-10177, Germany","Effective sleep analysis is hampered by the lack of automated tools catering to disordered sleep patterns and cumbersome monitoring hardware. In this paper, we apply deep learning on a set of 57 EEG features extracted from a maximum of two EEG channels to accurately differentiate between patients with insomnia or controls with no sleep complaints. We investigated two different approaches to achieve this. The first approach used EEG data from the whole sleep recording irrespective of the sleep stage (stage-independent classification), while the second used only EEG data from insomnia-impacted specific sleep stages (stage-dependent classification). We trained and tested our system using both healthy and disordered sleep collected from 41 controls and 42 primary insomnia patients. When compared with manual assessments, an NREM + REM based classifier had an overall discrimination accuracy of 92% and 86% between two groups using both two and one EEG channels, respectively. These results demonstrate that deep learning can be used to assist in the diagnosis of sleep disorders such as insomnia. © 2013 IEEE.","Automatic sleep stage scoring; deep learning; electroencephalogram (EEG); insomnia; sleep analysis","Adult; Diagnosis, Computer-Assisted; Electroencephalography; Female; Humans; Machine Learning; Male; Middle Aged; Polysomnography; Signal Processing, Computer-Assisted; Sleep Initiation and Maintenance Disorders; Sleep Stages; Electroencephalography; Sleep research; Discrimination accuracy; Electro-encephalogram (EEG); insomnia; Monitoring hardware; Sleep analysis; Sleep complaints; Sleep recordings; Sleep stage; adult; Article; clinical article; cohort analysis; controlled study; decision tree; diagnostic accuracy; electrocardiography; electroencephalography; electromyography; electrooculography; Hjorth parameters; human; insomnia; machine learning; mathematical model; measurement accuracy; nonREM sleep; nose breathing; observational study; outcome assessment; polysomnography; primary insomnia; REM sleep; sleep disordered breathing; sleep medicine; sleep parameters; sleep stage; computer assisted diagnosis; female; insomnia; machine learning; male; middle aged; procedures; signal processing; Deep learning","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28092583","Article","Scopus","2-s2.0-85035787462"
"Liang L.; Liu M.; Sun W.","Liang, Liang (36622308500); Liu, Minliang (57193857565); Sun, Wei (27467836000)","36622308500; 57193857565; 27467836000","A deep learning approach to estimate chemically-treated collagenous tissue nonlinear anisotropic stress-strain responses from microscopy images","2017","Acta Biomaterialia","38","10.1016/j.actbio.2017.09.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029693017&doi=10.1016%2fj.actbio.2017.09.025&partnerID=40&md5=0b65314dafa81463d7a7536ed68345c9","Tissue Mechanics Laboratory, The Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology and Emory University, Atlanta, GA, United States","Liang L., Tissue Mechanics Laboratory, The Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology and Emory University, Atlanta, GA, United States; Liu M., Tissue Mechanics Laboratory, The Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology and Emory University, Atlanta, GA, United States; Sun W., Tissue Mechanics Laboratory, The Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology and Emory University, Atlanta, GA, United States","Biological collagenous tissues comprised of networks of collagen fibers are suitable for a broad spectrum of medical applications owing to their attractive mechanical properties. In this study, we developed a noninvasive approach to estimate collagenous tissue elastic properties directly from microscopy images using Machine Learning (ML) techniques. Glutaraldehyde-treated bovine pericardium (GLBP) tissue, widely used in the fabrication of bioprosthetic heart valves and vascular patches, was chosen to develop a representative application. A Deep Learning model was designed and trained to process second harmonic generation (SHG) images of collagen networks in GLBP tissue samples, and directly predict the tissue elastic mechanical properties. The trained model is capable of identifying the overall tissue stiffness with a classification accuracy of 84%, and predicting the nonlinear anisotropic stress-strain curves with average regression errors of 0.021 and 0.031. Thus, this study demonstrates the feasibility and great potential of using the Deep Learning approach for fast and noninvasive assessment of collagenous tissue elastic properties from microstructural images. Statement of Significance: In this study, we developed, to our best knowledge, the first Deep Learning-based approach to estimate the elastic properties of collagenous tissues directly from noninvasive second harmonic generation images. The success of this study holds promise for the use of Machine Learning techniques to noninvasively and efficiently estimate the mechanical properties of many structure-based biological materials, and it also enables many potential applications such as serving as a quality control tool to select tissue for the manufacturing of medical devices (e.g. bioprosthetic heart valves). © 2017 Acta Materialia Inc.","Collagenous tissue; Convolutional neural network; Deep Learning; Elastic property","Animals; Anisotropy; Cattle; Collagen; Elasticity; Glutaral; Machine Learning; Microscopy, Confocal; Neural Networks (Computer); Nonlinear Dynamics; Pericardium; Regression Analysis; ROC Curve; Stress, Mechanical; Anisotropy; Biomechanics; Collagen; Deep learning; Elasticity; Harmonic generation; Heart; Histology; Medical applications; Medical imaging; Neural networks; Nonlinear optics; Stress-strain curves; Tissue; collagen; glutaraldehyde; Anisotropic stress; Bovine pericardium; Collagenous tissues; Convolutional neural network; Deep learning; Elastic properties; Glutaraldehydes; Learning approach; Machine learning techniques; Microscopy images; accuracy; animal tissue; anisotropy; Article; biomechanics; bovine; collagen fiber; elasticity; feasibility study; machine learning; microscopy; non invasive procedure; nonhuman; nonlinear system; pericardium; priority journal; rigidity; stress strain relationship; animal; anisotropy; artificial neural network; chemistry; confocal microscopy; drug effect; mechanical stress; procedures; receiver operating characteristic; regression analysis; Noninvasive medical procedures","Acta Materialia Inc","17427061","","","28939354","Article","Scopus","2-s2.0-85029693017"
"Sheng B.; Hu Q.; Li J.; Yang W.; Zhang B.; Sun C.","Sheng, Biyun (58422937200); Hu, Qichang (57001961800); Li, Jun (57206965333); Yang, Wankou (8891611800); Zhang, Baochang (55791583300); Sun, Changyin (35249817500)","58422937200; 57001961800; 57206965333; 8891611800; 55791583300; 35249817500","Filtered shallow-deep feature channels for pedestrian detection","2017","Neurocomputing","6","10.1016/j.neucom.2017.03.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018866404&doi=10.1016%2fj.neucom.2017.03.007&partnerID=40&md5=3ff2a022636c374ffbb5982e96951c80","School of Automation, Southeast University, Nanjing, 210096, China; Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Southeast University, Nanjing, 210096, China; School of Computer Science, The University of Adelaide, 5005, SA, Australia; School of Automation Science and Electrical Engineering, Beihang University, Beijing, 100191, China","Sheng B., School of Automation, Southeast University, Nanjing, 210096, China, Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Southeast University, Nanjing, 210096, China; Hu Q., School of Computer Science, The University of Adelaide, 5005, SA, Australia; Li J., School of Automation, Southeast University, Nanjing, 210096, China, Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Southeast University, Nanjing, 210096, China; Yang W., School of Automation, Southeast University, Nanjing, 210096, China, Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Southeast University, Nanjing, 210096, China; Zhang B., School of Automation Science and Electrical Engineering, Beihang University, Beijing, 100191, China; Sun C., School of Automation, Southeast University, Nanjing, 210096, China, Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Southeast University, Nanjing, 210096, China","The semantic segmentation task is highly related to detection and apparently can provide complementary information for detection. In this paper, we propose integrating deep semantic segmentation feature maps into the original pedestrian detection framework which combines feature channels with AdaBoost classifiers. Firstly, we develop shallow-deep channels by concatenating shallow hand-crafted and deep segmentation channels to capture appearance clues as well as semantic attributes. Then a set of manually designed filters are utilized on the new channels to generate more response feature maps. Finally a cascade AdaBoost classifier is learned for hard negatives selection and pedestrian detection. With abundant feature information, our proposed detector achieves superior results on Caltech USA 10x and ETH dataset. © 2017 Elsevier B.V.","Pedestrian detectionDeep semantic segmentationShallow-deep channelsAdaBoost classifier","Adaptive boosting; Classification (of information); Semantics; Ada boost classifiers; Feature information; Feature map; New channels; Pedestrian detection; Response features; Semantic attribute; Semantic segmentation; AdaBoost; Article; classifier; machine learning; pedestrian; priority journal; semantics; shallow deep feature channel; Feature extraction","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85018866404"
"Gan M.; Li W.; Zeng W.; Wang X.; Jiang R.","Gan, Mingxin (25928377500); Li, Wenran (57195754592); Zeng, Wanwen (57189046061); Wang, Xiaojian (57196447624); Jiang, Rui (57200775668)","25928377500; 57195754592; 57189046061; 57196447624; 57200775668","Mimvec: A deep learning approach for analyzing the human phenome","2017","BMC Systems Biology","3","10.1186/s12918-017-0451-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029752725&doi=10.1186%2fs12918-017-0451-z&partnerID=40&md5=8603ebe6d8461689f0da26f5152f5630","University of Science and Technology Beijing, Department of Management Science and Engineering, Dongling School of Economics and Management, Beijing, 100083, China; Tsinghua University, Ministry of Education Key Laboratory of Bioinformatics; Bioinformatics Division, Department of Automation and Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China; Chinese Academy of Medical Sciences and Peking Union Medical College, State Key Laboratory of Cardiovascular Disease, Fu Wai Hospital, National Center for Cardiovascular Diseases, Beijing, 100037, China; Tsinghua University, Institute for Data Science, Beijing, 100084, China","Gan M., University of Science and Technology Beijing, Department of Management Science and Engineering, Dongling School of Economics and Management, Beijing, 100083, China; Li W., Tsinghua University, Ministry of Education Key Laboratory of Bioinformatics; Bioinformatics Division, Department of Automation and Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China; Zeng W., Tsinghua University, Ministry of Education Key Laboratory of Bioinformatics; Bioinformatics Division, Department of Automation and Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China; Wang X., Chinese Academy of Medical Sciences and Peking Union Medical College, State Key Laboratory of Cardiovascular Disease, Fu Wai Hospital, National Center for Cardiovascular Diseases, Beijing, 100037, China; Jiang R., Tsinghua University, Ministry of Education Key Laboratory of Bioinformatics; Bioinformatics Division, Department of Automation and Tsinghua National Laboratory for Information Science and Technology, Beijing, 100084, China, Tsinghua University, Institute for Data Science, Beijing, 100084, China","Background: The human phenome has been widely used with a variety of genomic data sources in the inference of disease genes. However, most existing methods thus far derive phenotype similarity based on the analysis of biomedical databases by using the traditional term frequency-inverse document frequency (TF-IDF) formulation. This framework, though intuitive, not only ignores semantic relationships between words but also tends to produce high-dimensional vectors, and hence lacks the ability to precisely capture intrinsic semantic characteristics of biomedical documents. To overcome these limitations, we propose a framework called mimvec to analyze the human phenome by making use of the state-of-the-art deep learning technique in natural language processing. Results: We converted 24,061 records in the Online Mendelian Inheritance in Man (OMIM) database to low-dimensional vectors using our method. We demonstrated that the vector presentation not only effectively enabled classification of phenotype records against gene ones, but also succeeded in discriminating diseases of different inheritance styles and different mechanisms. We further derived pairwise phenotype similarities between 7988 human inherited diseases using their vector presentations. With a joint analysis of this phenome with multiple genomic data, we showed that phenotype overlap indeed implied genotype overlap. We finally used the derived phenotype similarities with genomic data to prioritize candidate genes and demonstrated advantages of this method over existing ones. Conclusions: Our method is capable of not only capturing semantic relationships between words in biomedical records but also alleviating the dimensional disaster accompanying the traditional TF-IDF framework. With the approaching of precision medicine, there will be abundant electronic records of medicine and health awaiting for deep analysis, and we expect to see a wide spectrum of applications borrowing the idea of our method in the near future. © 2017 The Author(s).","","Computational Biology; Databases, Genetic; Disease; Humans; Inheritance Patterns; Machine Learning; Natural Language Processing; Phenotype; biology; diseases; genetic database; genetics; human; inheritance; machine learning; natural language processing; phenotype; procedures","BioMed Central Ltd.","17520509","","","28950906","Article","Scopus","2-s2.0-85029752725"
"Shaham U.; Stanton K.P.; Zhao J.; Li H.; Raddassi K.; Montgomery R.; Kluger Y.","Shaham, Uri (55662339300); Stanton, Kelly P. (55910692500); Zhao, Jun (57199498373); Li, Huamin (57193167628); Raddassi, Khadir (6603296401); Montgomery, Ruth (7202664579); Kluger, Yuval (22962330400)","55662339300; 55910692500; 57199498373; 57193167628; 6603296401; 7202664579; 22962330400","Removal of batch effects using distribution-matching residual networks","2017","Bioinformatics","95","10.1093/bioinformatics/btx196","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040695740&doi=10.1093%2fbioinformatics%2fbtx196&partnerID=40&md5=904624350423097e0624742436dc3810","Department of Statistics, Yale University, New Haven, 06511, CT, United States; Department of Pathology, Yale School of Medicine, New Haven, 06510, CT, United States; Program of Computational Biology and Bioinformatics, Yale University, New Haven, 06520, CT, United States; Applied Mathematics Program, Yale University, New Haven, 06511, CT, United States; Departments of Neurology and Immunobiology, Yale School of Medicine, New Haven, 06510, CT, United States; Department of Internal Medicine, Yale School of Medicine, New Haven, 06510, CT, United States","Shaham U., Department of Statistics, Yale University, New Haven, 06511, CT, United States; Stanton K.P., Department of Pathology, Yale School of Medicine, New Haven, 06510, CT, United States, Program of Computational Biology and Bioinformatics, Yale University, New Haven, 06520, CT, United States; Zhao J., Program of Computational Biology and Bioinformatics, Yale University, New Haven, 06520, CT, United States; Li H., Applied Mathematics Program, Yale University, New Haven, 06511, CT, United States; Raddassi K., Departments of Neurology and Immunobiology, Yale School of Medicine, New Haven, 06510, CT, United States; Montgomery R., Department of Internal Medicine, Yale School of Medicine, New Haven, 06510, CT, United States; Kluger Y., Department of Pathology, Yale School of Medicine, New Haven, 06510, CT, United States, Program of Computational Biology and Bioinformatics, Yale University, New Haven, 06520, CT, United States, Applied Mathematics Program, Yale University, New Haven, 06511, CT, United States","Motivation: Sources of variability in experimentally derived data include measurement error in addition to the physical phenomena of interest. This measurement error is a combination of systematic components, originating from the measuring instrument and random measurement errors. Several novel biological technologies, such as mass cytometry and single-cell RNA-seq (scRNA-seq), are plagued with systematic errors that May severely affect statistical analysis if the data are not properly calibrated. Results: We propose a novel deep learning approach for removing systematic batch effects. Our method is based on a residual neural network, trained to minimize the Maximum Mean Discrepancy between the multivariate distributions of two replicates, measured in different batches. We apply our method to mass cytometry and scRNA-seq datasets, and demonstrate that it effectively attenuates batch effects. © The Author 2017.","","Computational Biology; Cytophotometry; Data Accuracy; Humans; Machine Learning; Sequence Analysis, RNA; Single-Cell Analysis; Statistics as Topic; biology; cytophotometry; human; machine learning; measurement accuracy; procedures; sequence analysis; single cell analysis; statistics","Oxford University Press","13674803","","BOINF","28419223","Article","Scopus","2-s2.0-85040695740"
"Umadevi K.S.; Jeyapriya J.","Umadevi, K.S. (58493077500); Jeyapriya, J. (57200335600)","58493077500; 57200335600","Cascaded neural network based automated detection of diabetic retinopathy","2017","Indian Journal of Public Health Research and Development","0","10.5958/0976-5506.2017.00518.6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040943489&doi=10.5958%2f0976-5506.2017.00518.6&partnerID=40&md5=6bb0d3096c87b9ff996c5cab846cf512","School of Computing Science & Engineering, VIT University, Vellore, India","Umadevi K.S., School of Computing Science & Engineering, VIT University, Vellore, India; Jeyapriya J., School of Computing Science & Engineering, VIT University, Vellore, India","Diabetes is a persistent disease influencing the internal organs when the pancreas losses its functionality to produce insulin in appropriate amount. Ion latter stages, it severely influences the circulatory system and vision system by damaging retina. Such an ailment is referred as Diabetic Retinopathy (DR) and is a condition of an ailment where the retina is harmed on the grounds that fluid breaks away from the walls of blood vessels into the retina. The diagnosing features for DR comprises of features occurring in and around the regions of blood vessel zone which will result into exudes, hemorrhages, microaneurysms and generation of textures on the albumen region of eye balls. In this study we present a new method relying on cascaded neural network for high precision detection of DR and comparison of its classifications proficiency is drawn out with various DR systems. The majority of the studyed systems are profoundly advanced regarding the analyzed fundus images is catching up to the human ophthalmologist’s characterization capacities. © 2017, Indian Journal of Public Health Research and Development. All rights reserved.","Blood vessel; Detection of diabetic retinopathy; Microaneurysms; Retinal nerve hemorrhages","Article; automation; cascaded neural network; classifier; deep neural network; diabetic retinopathy; diagnostic accuracy; eye photography; human; image analysis; intermethod comparison; machine learning; retina blood vessel; sensitivity and specificity","Institute of Medico-Legal Publications","09760245","","","","Article","Scopus","2-s2.0-85040943489"
"Tian S.; Yan Y.; Yu L.; Qian J.; Ye F.","Tian, Shengwei (35119846500); Yan, Yilin (57195054996); Yu, Long (55272883600); Qian, Jin (55730651000); Ye, Feiyue (8417467500)","35119846500; 57195054996; 55272883600; 55730651000; 8417467500","Prediction of anti-HIV activity on the basis of stacked auto-encoder","2017","Journal of Chemometrics","2","10.1002/cem.2916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025086041&doi=10.1002%2fcem.2916&partnerID=40&md5=01ca7e417284822b28160d15847946df","School of Software, Xinjiang University, 499 Xibei Road, Ürümqi, 830008, China; School of Computer Engineering, Jiangsu University of Technology, Zhongwu Avenue #1801, Changzhou, 213001, China; Key Laboratory of Cloud Computing and Intelligent Information Processing of Changzhou City, Jiangsu University of Technology, Changzhou, 213000, China; Network Center, Xinjiang University, 14 Shengli Road, Ürümqi, 830046, China; Institute of Information Science and Engineering, Xinjiang University, 14 Shengli Road, Ürümqi, 830046, China","Tian S., School of Software, Xinjiang University, 499 Xibei Road, Ürümqi, 830008, China, School of Computer Engineering, Jiangsu University of Technology, Zhongwu Avenue #1801, Changzhou, 213001, China, Key Laboratory of Cloud Computing and Intelligent Information Processing of Changzhou City, Jiangsu University of Technology, Changzhou, 213000, China; Yan Y., Institute of Information Science and Engineering, Xinjiang University, 14 Shengli Road, Ürümqi, 830046, China; Yu L., School of Computer Engineering, Jiangsu University of Technology, Zhongwu Avenue #1801, Changzhou, 213001, China, Key Laboratory of Cloud Computing and Intelligent Information Processing of Changzhou City, Jiangsu University of Technology, Changzhou, 213000, China, Network Center, Xinjiang University, 14 Shengli Road, Ürümqi, 830046, China; Qian J., School of Computer Engineering, Jiangsu University of Technology, Zhongwu Avenue #1801, Changzhou, 213001, China, Key Laboratory of Cloud Computing and Intelligent Information Processing of Changzhou City, Jiangsu University of Technology, Changzhou, 213000, China; Ye F., School of Computer Engineering, Jiangsu University of Technology, Zhongwu Avenue #1801, Changzhou, 213001, China, Key Laboratory of Cloud Computing and Intelligent Information Processing of Changzhou City, Jiangsu University of Technology, Changzhou, 213000, China","The prediction of biologically active compounds plays a very important role for high-throughput screening approaches in drug discovery. Most computational models, in this area, concentrate on measuring structural similarities between chemical elements. There are various methods to predict anti-HIV activity, such as artificial neural network and support vector machine, but generally using shallow machine learning with low accuracies and less samples. In this work, one of deep learning methods, stacked auto-encoder (SAE), is proposed to predict anti-HIV activity of a broad group of compounds for the first time. Through contrasting experiments of artificial neural network, support vector machine, and SAE under the same condition, the accuracy after descriptors screening is higher than using raw descriptors, and SAE performs better than the other two methods to achieve the perfect forecast of anti-HIV activity. It has a great significance on promoting anti-HIV drug design, which therefore can reduce research and development costs and improve the efficiency of anti-HIV drug discovery. Copyright © 2017 John Wiley & Sons, Ltd.","anti-HIV activity prediction; classification modeling; deep learning; stacked auto-encoder","Bioactivity; Chemical elements; Deep learning; Neural networks; Signal encoding; Support vector machines; Activity predictions; Anti-HIV; Anti-HIV activity; Anti-HIV activity prediction; Auto encoders; Classification models; Deep learning; Descriptors; Drug discovery; Stacked auto-encoder; Forecasting","John Wiley and Sons Ltd","08869383","","JOCHE","","Article","Scopus","2-s2.0-85025086041"
"Ramsundar B.; Liu B.; Wu Z.; Verras A.; Tudor M.; Sheridan R.P.; Pande V.","Ramsundar, Bharath (56097570200); Liu, Bowen (57195509000); Wu, Zhenqin (57195509174); Verras, Andreas (16314532400); Tudor, Matthew (7006064092); Sheridan, Robert P. (7201693208); Pande, Vijay (7004966384)","56097570200; 57195509000; 57195509174; 16314532400; 7006064092; 7201693208; 7004966384","Is Multitask Deep Learning Practical for Pharma?","2017","Journal of Chemical Information and Modeling","178","10.1021/acs.jcim.7b00146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028532336&doi=10.1021%2facs.jcim.7b00146&partnerID=40&md5=f36cb72270fd3cd8ea5cc7c40496f0bd","Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Department of Chemistry, Stanford University, Stanford, 94305, CA, United States; Chemistry Capabilities and Screening, Merck and Co., Inc., 2000 Galloping Hill Road, Kenilworth, 07033, NJ, United States; Chemistry Capabilities and Screening, Merck and Co., Inc., 770 Sumneytown Pike, West Point, 19846, PA, United States","Ramsundar B., Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Liu B., Department of Chemistry, Stanford University, Stanford, 94305, CA, United States; Wu Z., Department of Chemistry, Stanford University, Stanford, 94305, CA, United States; Verras A., Chemistry Capabilities and Screening, Merck and Co., Inc., 2000 Galloping Hill Road, Kenilworth, 07033, NJ, United States; Tudor M., Chemistry Capabilities and Screening, Merck and Co., Inc., 770 Sumneytown Pike, West Point, 19846, PA, United States; Sheridan R.P., Chemistry Capabilities and Screening, Merck and Co., Inc., 2000 Galloping Hill Road, Kenilworth, 07033, NJ, United States; Pande V., Department of Chemistry, Stanford University, Stanford, 94305, CA, United States","Multitask deep learning has emerged as a powerful tool for computational drug discovery. However, despite a number of preliminary studies, multitask deep networks have yet to be widely deployed in the pharmaceutical and biotech industries. This lack of acceptance stems from both software difficulties and lack of understanding of the robustness of multitask deep networks. Our work aims to resolve both of these barriers to adoption. We introduce a high-quality open-source implementation of multitask deep networks as part of the DeepChem open-source platform. Our implementation enables simple python scripts to construct, fit, and evaluate sophisticated deep models. We use our implementation to analyze the performance of multitask deep networks and related deep models on four collections of pharmaceutical data (three of which have not previously been analyzed in the literature). We split these data sets into train/valid/test using time and neighbor splits to test multitask deep learning performance under challenging conditions. Our results demonstrate that multitask deep networks are surprisingly robust and can offer strong improvement over random forests. Our analysis and open-source implementation in DeepChem provide an argument that multitask deep networks are ready for widespread use in commercial drug discovery. © 2017 American Chemical Society.","","Absorption, Radiation; Drug Discovery; Inhibitory Concentration 50; Machine Learning; Protein Kinase Inhibitors; Serine Proteinase Inhibitors; Software; Ultraviolet Rays; Decision trees; Open source software; protein kinase inhibitor; serine proteinase inhibitor; Barriers to adoption; Biotech industry; Drug discovery; High quality; Learning performance; Open source implementation; Open source platforms; chemistry; drug development; IC50; machine learning; procedures; radiation absorption; software; ultraviolet radiation; Deep learning","American Chemical Society","15499596","","JCISD","28692267","Article","Scopus","2-s2.0-85028532336"
"Luo G.; Stone B.L.; Johnson M.D.; Tarczy-Hornoch P.; Wilcox A.B.; Mooney S.D.; Sheng X.; Haug P.J.; Nkoy F.L.","Luo, Gang (7401536289); Stone, Bryan L (7201855889); Johnson, Michael D (56982111500); Tarczy-Hornoch, Peter (6701576629); Wilcox, Adam B (7102335792); Mooney, Sean D (57207721730); Sheng, Xiaoming (7102570433); Haug, Peter J (24480894300); Nkoy, Flory L (25646207000)","7401536289; 7201855889; 56982111500; 6701576629; 7102335792; 57207721730; 7102570433; 24480894300; 25646207000","Automating construction of machine learning models with clinical big data: Proposal rationale and methods","2017","JMIR Research Protocols","31","10.2196/resprot.7757","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043340967&doi=10.2196%2fresprot.7757&partnerID=40&md5=01df95371059b07f7a7224f95a8cc580","Department of Biomedical Informatics and Medical Education, University of Washington, Seattle, WA, United States; Department of Pediatrics, University of Utah, Salt Lake City, UT, United States; Division of Neonatology, Department of Pediatrics, University of Washington, Seattle, WA, United States; Department of Computer Science and Engineering, University of Washington, Seattle, WA, United States; Homer Warner Research Center, Intermountain Healthcare, Murray, UT, United States; Department of Biomedical Informatics, University of Utah, Salt Lake City, UT, United States","Luo G., Department of Biomedical Informatics and Medical Education, University of Washington, Seattle, WA, United States; Stone B.L., Department of Pediatrics, University of Utah, Salt Lake City, UT, United States; Johnson M.D., Department of Pediatrics, University of Utah, Salt Lake City, UT, United States; Tarczy-Hornoch P., Department of Biomedical Informatics and Medical Education, University of Washington, Seattle, WA, United States, Division of Neonatology, Department of Pediatrics, University of Washington, Seattle, WA, United States, Department of Computer Science and Engineering, University of Washington, Seattle, WA, United States; Wilcox A.B., Department of Biomedical Informatics and Medical Education, University of Washington, Seattle, WA, United States; Mooney S.D., Department of Biomedical Informatics and Medical Education, University of Washington, Seattle, WA, United States; Sheng X., Department of Pediatrics, University of Utah, Salt Lake City, UT, United States; Haug P.J., Homer Warner Research Center, Intermountain Healthcare, Murray, UT, United States, Department of Biomedical Informatics, University of Utah, Salt Lake City, UT, United States; Nkoy F.L., Department of Pediatrics, University of Utah, Salt Lake City, UT, United States","Background: To improve health outcomes and cut health care costs, we often need to conduct prediction/classification using large clinical datasets (aka, clinical big data), for example, to identify high-risk patients for preventive interventions. Machine learning has been proposed as a key technology for doing this. Machine learning has won most data science competitions and could support many clinical activities, yet only 15% of hospitals use it for even limited purposes. Despite familiarity with data, health care researchers often lack machine learning expertise to directly use clinical big data, creating a hurdle in realizing value from their data. Health care researchers can work with data scientists with deep machine learning knowledge, but it takes time and effort for both parties to communicate effectively. Facing a shortage in the United States of data scientists and hiring competition from companies with deep pockets, health care systems have difficulty recruiting data scientists. Building and generalizing a machine learning model often requires hundreds to thousands of manual iterations by data scientists to select the following: (1) hyper-parameter values and complex algorithms that greatly affect model accuracy and (2) operators and periods for temporally aggregating clinical attributes (eg, whether a patient's weight kept rising in the past year). This process becomes infeasible with limited budgets. Objective: This study's goal is to enable health care researchers to directly use clinical big data, make machine learning feasible with limited budgets and data scientist resources, and realize value from data. Methods: This study will allow us to achieve the following: (1) finish developing the new software, Automated Machine Learning (Auto-ML), to automate model selection for machine learning with clinical big data and validate Auto-ML on seven benchmark modeling problems of clinical importance; (2) apply Auto-ML and novel methodology to two new modeling problems crucial for care management allocation and pilot one model with care managers; and (3) perform simulations to estimate the impact of adopting Auto-ML on US patient outcomes. Results: We are currently writing Auto-ML's design document. We intend to finish our study by around the year 2022. Conclusions: Auto-ML will generalize to various clinical prediction/classification problems. With minimal help from data scientists, health care researchers can use Auto-ML to quickly build high-quality models. This will boost wider use of machine learning in health care and improve patient outcomes. © Gang Luo, Bryan L Stone, Michael D Johnson, Peter Tarczy-Hornoch, Adam B Wilcox, Sean D Mooney, Xiaoming Sheng, Peter J Haug, Flory L Nkoy.","Automated temporal aggregation; Automatic model selection; Care management; Clinical big data; Machine learning","","JMIR Publications Inc.","19290748","","","","Article","Scopus","2-s2.0-85043340967"
"Rhee P.K.; Erdenee E.; Kyun S.D.; Ahmed M.U.; Jin S.","Rhee, Phill Kyu (7006801841); Erdenee, Enkhbayar (57190964944); Kyun, Shin Dong (57195965854); Ahmed, Minhaz Uddin (55844167000); Jin, Songguo (15055995600)","7006801841; 57190964944; 57195965854; 55844167000; 15055995600","Active and semi-supervised learning for object detection with imperfect data","2017","Cognitive Systems Research","45","10.1016/j.cogsys.2017.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030532834&doi=10.1016%2fj.cogsys.2017.05.006&partnerID=40&md5=621c23f81a1ef55ac9fe7e2c08e70e25","Computer and Information Engineering Department, Inha University, 100 Inha-ro, Nam-gu 22212, Incheon, South Korea","Rhee P.K., Computer and Information Engineering Department, Inha University, 100 Inha-ro, Nam-gu 22212, Incheon, South Korea; Erdenee E., Computer and Information Engineering Department, Inha University, 100 Inha-ro, Nam-gu 22212, Incheon, South Korea; Kyun S.D., Computer and Information Engineering Department, Inha University, 100 Inha-ro, Nam-gu 22212, Incheon, South Korea; Ahmed M.U., Computer and Information Engineering Department, Inha University, 100 Inha-ro, Nam-gu 22212, Incheon, South Korea; Jin S., Computer and Information Engineering Department, Inha University, 100 Inha-ro, Nam-gu 22212, Incheon, South Korea","In this paper, we address the combination of the active learning (AL) and semi-supervised (SSL) learnings, called ASSL, to leverage the strong points of the both learning paradigms for improving the performance of object detection. Considering the pros and cons of the AL and SSL learning methods, ASSL where SSL method provides the incremental improvement of semi-supervised detection performance by combining the concept of diversity imported from AL methods. The proposed method demonstrates outstanding performance compared with state-of-art methods on the challenging Caltech pedestrian detection dataset, reducing the miss rate to 12.2%, which is significantly smaller than current state-of-art. In addition, extensive experiments have been carried out using ILSVRC detection dataset and online evaluation for activity recognition. © 2017 Elsevier B.V.","Active Learning (AL); Convolutional Neural Network (CNN); Deep learning; Object detection; Semi-Supervised Learning (SSL)","Aluminum; Artificial intelligence; Deep learning; Neural networks; Object recognition; Supervised learning; Active Learning; Activity recognition; Convolutional neural network; Detection performance; Incremental improvements; Semi- supervised learning; Semi-supervised learning (SSL); State-of-art methods; active learning; Article; artificial intelligence; data analysis; evaluation study; human; information processing; machine learning; online system; pattern recognition; pedestrian; priority journal; semi supervised learning; task performance; vision; Object detection","Elsevier B.V.","13890417","","CSROA","","Article","Scopus","2-s2.0-85030532834"
"Neylon J.; Min Y.; Low D.A.; Santhanam A.","Neylon, John (55777012800); Min, Yugang (36337970100); Low, Daniel A. (57202437462); Santhanam, Anand (8249169200)","55777012800; 36337970100; 57202437462; 8249169200","A neural network approach for fast, automated quantification of DIR performance:","2017","Medical Physics","24","10.1002/mp.12321","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024388559&doi=10.1002%2fmp.12321&partnerID=40&md5=1c50f98caf88c6e8ccd822de7a764e5f","Department of Radiation Oncology, UCLA, 200 Medical Plaza, Los Angeles, 90095, CA, United States","Neylon J., Department of Radiation Oncology, UCLA, 200 Medical Plaza, Los Angeles, 90095, CA, United States; Min Y., Department of Radiation Oncology, UCLA, 200 Medical Plaza, Los Angeles, 90095, CA, United States; Low D.A., Department of Radiation Oncology, UCLA, 200 Medical Plaza, Los Angeles, 90095, CA, United States; Santhanam A., Department of Radiation Oncology, UCLA, 200 Medical Plaza, Los Angeles, 90095, CA, United States","Purpose: A critical step in adaptive radiotherapy (ART) workflow is deformably registering the simulation CT with the daily or weekly volumetric imaging. Quantifying the deformable image registration accuracy under these circumstances is a complex task due to the lack of known ground-truth landmark correspondences between the source data and target data. Generating landmarks manually (using experts) is time-consuming, and limited by image quality and observer variability. While image similarity metrics (ISM) may be used as an alternative approach to quantify the registration error, there is a need to characterize the ISM values by developing a nonlinear cost function and translate them to physical distance measures in order to enable fast, quantitative comparison of registration performance. Methods: In this paper, we present a proof-of-concept methodology for automated quantification of DIR performance. A nonlinear cost function was developed as a combination of ISM values and governed by the following two expectations for an accurate registration: (a) the deformed data obtained from transforming the simulation CT data with the deformation vector field (DVF) should match the target image data with near perfect similarity, and (b) the similarity between the simulation CT and deformed data should match the similarity between the simulation CT and the target image data. A deep neural network (DNN) was developed that translated the cost function values to actual physical distance measure. To train the neural network, patient-specific biomechanical models of the head-and-neck anatomy were employed. The biomechanical model anatomy was systematically deformed to represent changes in patient posture and physiological regression. Volumetric source and target images with known ground-truth deformations vector fields were then generated, representing the daily or weekly imaging data. Annotated data was then fed through a supervised machine learning process, iteratively optimizing a nonlinear model able to predict the target registration error (TRE) for given ISM values. The cost function for sub-volumes enclosing critical radiotherapy structures in the head-and-neck region were computed and compared with the ground truth TRE values. Results: When examining different combinations of registration parameters for a single DIR, the neural network was able to quantify DIR error to within a single voxel for 95% of the sub-volumes examined. In addition, correlations between the neural network predicted error and the ground-truth TRE for the Planning Target Volume and the parotid contours were consistently observed to be > 0.9. For variations in posture and tumor regression for 10 different patients, patient-specific neural networks predicted the TRE to within a single voxel > 90% on average. Conclusions: The formulation presented in this paper demonstrates the ability for fast, accurate quantification of registration performance. DNN provided the necessary level of abstraction to estimate a quantified TRE from the ISM expectations described above, when sufficiently trained on annotated data. In addition, biomechanical models facilitated the DNN with the required variations in the patient posture and physiological regression. With further development and validation on clinical patient data, such networks have potential impact in patient and site-specific optimization, and stream-lining clinical registration validation. © 2017 American Association of Physicists in Medicine.","accuracy; DIR; machine learning; neural network; radiotherapy","Algorithms; Costs and Cost Analysis; Head; Humans; Image Processing, Computer-Assisted; Neck; Neural Networks (Computer); Tomography, X-Ray Computed; Biomechanics; Computerized tomography; Cost functions; Costs; Deep neural networks; Deformation; Errors; Iterative methods; Medical imaging; Metadata; Physiological models; Supervised learning; Accuracy; DIR; Ground truth; Image similarity; Machine-learning; Metric values; Neural-networks; Similarity metrics; Target images; Target registration errors; anatomy; body position; clinical article; expectation; female; head; human; imaging; male; neck; nervous system; parotid gland; patient coding; physical model; quantitative study; registration; simulation; supervised machine learning; tumor regression; validation process; algorithm; artificial neural network; cost; image processing; x-ray computed tomography; Radiotherapy","John Wiley and Sons Ltd","00942405","","MPHYA","28477340","Article","Scopus","2-s2.0-85024388559"
"Li Y.; Zhang T.","Li, Yujian (26642995500); Zhang, Ting (57198705645)","26642995500; 57198705645","Deep neural mapping support vector machines","2017","Neural Networks","39","10.1016/j.neunet.2017.05.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021171148&doi=10.1016%2fj.neunet.2017.05.010&partnerID=40&md5=6738de334d5f5628f496936f67889a45","College of Computer Science, Beijing University of Technology, Beijing, 100124, China","Li Y., College of Computer Science, Beijing University of Technology, Beijing, 100124, China; Zhang T., College of Computer Science, Beijing University of Technology, Beijing, 100124, China","The choice of kernel has an important effect on the performance of a support vector machine (SVM). The effect could be reduced by NEUROSVM, an architecture using multilayer perceptron for feature extraction and SVM for classification. In binary classification, a general linear kernel NEUROSVM can be theoretically simplified as an input layer, many hidden layers, and an SVM output layer. As a feature extractor, the sub-network composed of the input and hidden layers is first trained together with a virtual ordinary output layer by backpropagation, then with the output of its last hidden layer taken as input of the SVM classifier for further training separately. By taking the sub-network as a kernel mapping from the original input space into a feature space, we present a novel model, called deep neural mapping support vector machine (DNMSVM), from the viewpoint of deep learning. This model is also a new and general kernel learning method, where the kernel mapping is indeed an explicit function expressed as a sub-network, different from an implicit function induced by a kernel function traditionally. Moreover, we exploit a two-stage procedure of contrastive divergence learning and gradient descent for DNMSVM to jointly training an adaptive kernel mapping instead of a kernel function, without requirement of kernel tricks. As a whole of the sub-network and the SVM classifier, the joint training of DNMSVM is done by using gradient descent to optimize the objective function with the sub-network layer-wise pre-trained via contrastive divergence learning of restricted Boltzmann machines. Compared to the separate training of NEUROSVM, the joint training is a new algorithm for DNMSVM to have advantages over NEUROSVM. Experimental results show that DNMSVM can outperform NEUROSVM and RBFSVM (i.e., SVM with the kernel of radial basis function), demonstrating its effectiveness. © 2017 Elsevier Ltd","Deep learning; Kernel choice; Kernel function; Kernel mapping; Neural network; Support vector machine","Humans; Neural Networks (Computer); Support Vector Machine; Deep learning; Deep neural networks; Education; Learning systems; Mapping; Network layers; Neural networks; Radial basis function networks; Vector spaces; Vectors; Binary classification; Contrastive divergence; Kernel choice; Kernel function; Kernel learning methods; Kernel mapping; Radial basis functions; Restricted boltzmann machine; Article; artificial neural network; calculation; deep neural mapping support vector machine; kernel method; learning algorithm; mathematical computing; network learning; priority journal; process optimization; support vector machine; artificial neural network; human; Support vector machines","Elsevier Ltd","08936080","","NNETE","28646763","Article","Scopus","2-s2.0-85021171148"
"Song S.-H.; Kim D.K.","Song, Se-Hui (57201613873); Kim, Dong Keun (55742977500)","57201613873; 55742977500","Development of a stress classification model using deep belief networks for stress monitoring","2017","Healthcare Informatics Research","28","10.4258/hir.2017.23.4.285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045391496&doi=10.4258%2fhir.2017.23.4.285&partnerID=40&md5=5a4d7ea07968947847f0c1286134f4db","Department of Mobile Software, Graduate School, Sangmyung University, Seoul, South Korea; Department of Intelligent Engineering Informatics for Human, College of Convergence Engineering, Sangmyung University, Seoul, South Korea","Song S.-H., Department of Mobile Software, Graduate School, Sangmyung University, Seoul, South Korea; Kim D.K., Department of Intelligent Engineering Informatics for Human, College of Convergence Engineering, Sangmyung University, Seoul, South Korea","Objectives: Stress management is related to public healthcare and quality of life; an accurate stress classification method is necessary for the design of stress monitoring systems. Therefore, the goal of this study was to design a novel stress classification model using a deep learning method. Methods: In this paper, we present a stress classification model using the dataset from the sixth Korea National Health and Nutrition Examination Survey conducted from 2013 to 2015 (KNHANES VI) to analyze stress-related health data. Statistical analysis was performed to identify the nine features of stress detection, and we evaluated the performance of the proposed stress classification by comparison with several stress detection models. The proposed model was also evaluated using Deep Belief Networks (DBN). Results: We designed profiles depending on the number of hidden layers, nodes, and hyper-parameters according to the loss function results. The experimental results showed that the proposed model achieved an accuracy and a specificity of 66.23% and 75.32%, respectively. The proposed DBN model performed better than other classification models, such as support vector machine, naive Bayesian classifier, and random forest. Conclusions: The proposed model in this study was demonstrated to be effective in classifying stress detection, and in particular, it is expected to be applicable for stress prediction in stress monitoring systems. © 2017 The Korean Society of Medical Informatics.","Deep belief network; KNHANES; Machine learning; Stress; Stress classification model","article; diagnostic test accuracy study; Korea; loss of function mutation; machine learning; monitoring; nutrition; prediction; public health; random forest; statistical analysis; stress; support vector machine","Korean Society of Medical Informatics","20933681","","","","Article","Scopus","2-s2.0-85045391496"
"Baka N.; Leenstra S.; Van Walsum T.","Baka, Nora (24176604100); Leenstra, Sieger (6701467758); Van Walsum, Theo (6603247641)","24176604100; 6701467758; 6603247641","Ultrasound Aided Vertebral Level Localization for Lumbar Surgery","2017","IEEE Transactions on Medical Imaging","46","10.1109/TMI.2017.2738612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028955915&doi=10.1109%2fTMI.2017.2738612&partnerID=40&md5=e1a0e88df39781b9dfa1f6b8f5fbb8af","Department of Radiology, Biomedical Imaging Group Rotterdam, Erasmus MC, University Medical Center Rotterdam, Rotterdam, 3015 GE, Netherlands; Department of Nuclear Medicine and Medical Informatics, Erasmus MC, University Medical Center Rotterdam, Rotterdam, 3015 GE, Netherlands; Department of Neurosurgery, Erasmus MC, University Medical Center Rotterdam, Rotterdam, 3015 GE, Netherlands; Department of Neurosurgery, St. Elisabeth Hospital Tilburg, Tilburg, 5022 GC, Netherlands","Baka N., Department of Radiology, Biomedical Imaging Group Rotterdam, Erasmus MC, University Medical Center Rotterdam, Rotterdam, 3015 GE, Netherlands, Department of Nuclear Medicine and Medical Informatics, Erasmus MC, University Medical Center Rotterdam, Rotterdam, 3015 GE, Netherlands; Leenstra S., Department of Neurosurgery, Erasmus MC, University Medical Center Rotterdam, Rotterdam, 3015 GE, Netherlands, Department of Neurosurgery, St. Elisabeth Hospital Tilburg, Tilburg, 5022 GC, Netherlands; Van Walsum T., Department of Radiology, Biomedical Imaging Group Rotterdam, Erasmus MC, University Medical Center Rotterdam, Rotterdam, 3015 GE, Netherlands, Department of Nuclear Medicine and Medical Informatics, Erasmus MC, University Medical Center Rotterdam, Rotterdam, 3015 GE, Netherlands","Localization of the correct vertebral level for surgical entry during lumbar hernia surgery is not straightforward. In this paper, we develop and evaluate a solution using free-hand 2-D ultrasound (US) imaging in the operation room (OR). Our system exploits the difference in spinous process shapes of the vertebrae. The spinous processes are pre-operatively outlined and labeled in a lateral lumbar X-ray of the patient. Then, in the OR the spinous processes are imaged with 2-D sagittal US, and are automatically segmented and registered with the X-ray shapes. After a small number of scanned vertebrae, the system robustly matches the shapes, and propagates the X-ray label to the US images. The main contributions of our work are: we propose a deep convolutional neural network-based bone segmentation algorithm from US imaging that outperforms state of the art methods in both performance and speed. We present a matching strategy that determines the levels of the spinal processes being imaged. And lastly, we evaluate the complete procedure on 19 clinical data sets from two hospitals, and two observers. The final labeling was correct in 92% of the cases, demonstrating the feasibility of US-based surgical entry point detection for spinal surgeries. © 1982-2012 IEEE.","Bone segmentation; computer aided surgery; deep learning; lumbar X-ray; machine learning; spine; surgical guidance","Algorithms; Humans; Image Processing, Computer-Assisted; Lumbar Vertebrae; Machine Learning; Male; Middle Aged; Surgery, Computer-Assisted; Ultrasonography; Bone; Computer aided instruction; Deep learning; Deep neural networks; Learning systems; Musculoskeletal system; Neural networks; Radiology; Surgery; Transplantation (surgical); Ultrasonic applications; Ultrasonic imaging; Bone segmentation; Computer aided surgery; Shape; spine; Surgical guidance; Two-dimensional displays; Xray imaging; adult; aged; Article; clinical article; computer assisted surgery; echography; human; image quality; image segmentation; low back pain; lumbar spine; male; spine radiography; spine surgery; spinous process; two-dimensional imaging; algorithm; computer assisted surgery; diagnostic imaging; echography; image processing; lumbar vertebra; machine learning; middle aged; procedures; surgery; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28809678","Article","Scopus","2-s2.0-85028955915"
"Chandrakala S.; Rajeswari N.","Chandrakala, S. (6505853809); Rajeswari, Natarajan (57209721846)","6505853809; 57209721846","Representation Learning Based Speech Assistive System for Persons with Dysarthria","2017","IEEE Transactions on Neural Systems and Rehabilitation Engineering","27","10.1109/TNSRE.2016.2638830","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029581677&doi=10.1109%2fTNSRE.2016.2638830&partnerID=40&md5=c43f59f7a36f468328137469cd90ee1e","School of Computing, SASTRA University, Thanjavur, 613 401, India; Department of Computer Science and Engineering, Sri Venkateswara College of Engineering, Sriperumbudur, India","Chandrakala S., School of Computing, SASTRA University, Thanjavur, 613 401, India; Rajeswari N., Department of Computer Science and Engineering, Sri Venkateswara College of Engineering, Sriperumbudur, India","An assistive system for persons with vocal impairment due to dysarthria converts dysarthric speech to normal speech or text. Because of the articulatory deficits, dysarthric speech recognition needs a robust learning technique. Representation learning is significant for complex tasks such as dysarthric speech recognition. We focus on robust representation for dysarthric speech recognition that involves recognizing sequential patterns of varying length utterances. We propose a hybrid framework that uses a generative learning based data representation with a discriminative learning based classifier. In this hybrid framework, we propose to use Example Specific Hidden Markov Models (ESHMMs) to obtain log-likelihood scores for a dysarthric speech utterance to form fixed dimensional score vector representation. This representation is used as an input to discriminative classifier such as support vector machine.The performance of the proposed approach is evaluatedusingUA-Speechdatabase.The recognitionaccuracy is much better than the conventional hidden Markov model based approach and Deep Neural Network-Hidden Markov Model (DNN-HMM). The efficiency of the discriminative nature of score vector representation is proved for 'very low' intelligibility words. © 2001-2011 IEEE.","Dysarthric speech recognition; example specific hidden Markov model (ESHMMs); representation learning; score vector representation; support vector machine; varying length sequential data","Algorithms; Communication Aids for Disabled; Dysarthria; Humans; Machine Learning; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Speech Intelligibility; Speech Production Measurement; Treatment Outcome; Deep learning; Deep neural networks; Hidden Markov models; Markov processes; Speech; Support vector machines; Trellis codes; Vectors; Data representations; Discriminative classifiers; Discriminative learning; example specific hidden Markov model (ESHMMs); representation learning; Sequential data; Sequential patterns; Vector representations; Article; artificial neural network; assistive technology; deep neural network hidden markov model; dysarthria; example specific hidden markov model; Fourier transformation; hidden Markov model; human; learning; machine learning; sequential analysis; speech discrimination; speech intelligibility; word recognition; algorithm; automated pattern recognition; communication aid; dysarthria; machine learning; procedures; reproducibility; sensitivity and specificity; speech analysis; treatment outcome; Speech recognition","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","27992342","Article","Scopus","2-s2.0-85029581677"
"Magana-Mora A.; Kalkatawi M.; Bajic V.B.","Magana-Mora, Arturo (55542494400); Kalkatawi, Manal (54879391200); Bajic, Vladimir B. (35377862500)","55542494400; 54879391200; 35377862500","Omni-Polya: A method and tool for accurate recognition of poly(A) signals in human genomic DNA","2017","BMC Genomics","27","10.1186/s12864-017-4033-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027514004&doi=10.1186%2fs12864-017-4033-7&partnerID=40&md5=5ad73f4c362304150d5dd4166db1fbdf","King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center, Thuwal, 23955-6900, Saudi Arabia","Magana-Mora A., King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center, Thuwal, 23955-6900, Saudi Arabia; Kalkatawi M., King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center, Thuwal, 23955-6900, Saudi Arabia; Bajic V.B., King Abdullah University of Science and Technology (KAUST), Computational Bioscience Research Center, Thuwal, 23955-6900, Saudi Arabia","Background: Polyadenylation is a critical stage of RNA processing during the formation of mature mRNA, and is present in most of the known eukaryote protein-coding transcripts and many long non-coding RNAs. The correct identification of poly(A) signals (PAS) not only helps to elucidate the 3'-end genomic boundaries of a transcribed DNA region and gene regulatory mechanisms but also gives insight into the multiple transcript isoforms resulting from alternative PAS. Although progress has been made in the in-silico prediction of genomic signals, the recognition of PAS in DNA genomic sequences remains a challenge. Results: In this study, we analyzed human genomic DNA sequences for the 12 most common PAS variants. Our analysis has identified a set of features that helps in the recognition of true PAS, which may be involved in the regulation of the polyadenylation process. The proposed features, in combination with a recognition model, resulted in a novel method and tool, Omni-PolyA. Omni-PolyA combines several machine learning techniques such as different classifiers in a tree-like decision structure and genetic algorithms for deriving a robust classification model. We performed a comparison between results obtained by state-of-the-art methods, deep neural networks, and Omni-PolyA. Results show that Omni-PolyA significantly reduced the average classification error rate by 35.37% in the prediction of the 12 considered PAS variants relative to the state-of-the-art results. Conclusions: The results of our study demonstrate that Omni-PolyA is currently the most accurate model for the prediction of PAS in human and can serve as a useful complement to other PAS recognition methods. Omni-PolyA is publicly available as an online tool accessible at www.cbrc.kaust.edu.sa/omnipolya/. © 2017 The Author(s).","Bioinformatics; Genomic DNA; Machine learning; Polyadenylation; Prediction","Data Mining; Genome, Human; Genomics; Humans; Poly A; Polyadenylation; genomic DNA; polyadenylic acid; polyadenylic acid; accuracy; Article; computer model; DNA sequence; genetic algorithm; human; machine learning; nerve cell network; nonhuman; Omni PolyA; polyadenylation; regulatory RNA sequence; support vector machine; data mining; genetics; genomics; human genome; metabolism; polyadenylation","BioMed Central Ltd.","14712164","","BGMEE","28810905","Article","Scopus","2-s2.0-85027514004"
"Swager A.-F.; van der Sommen F.; Klomp S.R.; Zinger S.; Meijer S.L.; Schoon E.J.; Bergman J.J.G.H.M.; de With P.H.; Curvers W.L.","Swager, Anne-Fré (56043936200); van der Sommen, Fons (6507741535); Klomp, Sander R. (57194162823); Zinger, Sveta (56129114800); Meijer, Sybren L. (55420460800); Schoon, Erik J. (6603349081); Bergman, Jacques J.G.H.M. (55915132500); de With, Peter H. (7003945229); Curvers, Wouter L. (6505610743)","56043936200; 6507741535; 57194162823; 56129114800; 55420460800; 6603349081; 55915132500; 7003945229; 6505610743","Computer-aided detection of early Barrett's neoplasia using volumetric laser endomicroscopy","2017","Gastrointestinal Endoscopy","106","10.1016/j.gie.2017.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018983661&doi=10.1016%2fj.gie.2017.03.011&partnerID=40&md5=1782b15a580da931c3f28921b4670299","Department of Gastroenterology and Hepatology, Academic Medical Center, Amsterdam, Netherlands; Department of Pathology, Academic Medical Center, Amsterdam, Netherlands; Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; Department of Gastroenterology and Hepatology, Catharina Hospital, Eindhoven, Netherlands","Swager A.-F., Department of Gastroenterology and Hepatology, Academic Medical Center, Amsterdam, Netherlands; van der Sommen F., Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; Klomp S.R., Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; Zinger S., Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; Meijer S.L., Department of Pathology, Academic Medical Center, Amsterdam, Netherlands; Schoon E.J., Department of Gastroenterology and Hepatology, Catharina Hospital, Eindhoven, Netherlands; Bergman J.J.G.H.M., Department of Gastroenterology and Hepatology, Academic Medical Center, Amsterdam, Netherlands; de With P.H., Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; Curvers W.L., Department of Gastroenterology and Hepatology, Catharina Hospital, Eindhoven, Netherlands","Background and Aims Volumetric laser endomicroscopy (VLE) is an advanced imaging system that provides a near-microscopic resolution scan of the esophageal wall layers up to 3-mm deep. VLE has the potential to improve detection of early neoplasia in Barrett's esophagus (BE). However, interpretation of VLE images is complex because of the large amount of data that need to be interpreted in real time. The aim of this study was to investigate the feasibility of a computer algorithm to identify early BE neoplasia on ex vivo VLE images. Methods We used 60 VLE images from a database of high-quality ex vivo VLE-histology correlations, obtained from BE patients ± neoplasia (30 nondysplastic BE [NDBE] and 30 high-grade dysplasia/early adenocarcinoma images). VLE features from a recently developed clinical VLE prediction score for BE neoplasia served as input for the algorithm: (1) higher VLE surface than subsurface signal and (2) lack of layering. With this input, novel clinically inspired algorithm features were developed, based on signal intensity statistics and grayscale correlations. For comparison, generic image analysis methods were examined for their performance to detect neoplasia. For classification of the images in the NDBE or neoplastic group, several machine learning methods were evaluated. Leave-1-out cross-validation was used for algorithm validation. Results Three novel clinically inspired algorithm features were developed. The feature “layering and signal decay statistics” showed the optimal performance compared with the other clinically features (“layering” and “signal intensity distribution”) and generic image analyses methods, with an area under the receiver operating characteristic curve (AUC) of.95. Corresponding sensitivity and specificity were 90% and 93%, respectively. In addition, the algorithm showed a better performance than the clinical VLE prediction score (AUC.81). Conclusions This is the first study in which a computer algorithm for BE neoplasia was developed based on VLE images with direct histologic correlates. The algorithm showed good performance to detect BE neoplasia in ex vivo VLE images compared with the performance of a recently developed clinical VLE prediction score. This study suggests that an automatic detection algorithm has the potential to assist endoscopists in detecting early neoplasia on VLE. Future studies on in vivo VLE scans are needed to further validate the algorithm. © 2017 American Society for Gastrointestinal Endoscopy","","Adenocarcinoma; Aged; Algorithms; Barrett Esophagus; Case-Control Studies; Diagnosis, Computer-Assisted; Esophageal Neoplasms; Esophagoscopy; Esophagus; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Male; Microscopy, Confocal; Middle Aged; Reproducibility of Results; ROC Curve; Sensitivity and Specificity; Support Vector Machine; aged; algorithm; Article; Barrett esophagus; computer assisted diagnosis; diagnostic test accuracy study; ex vivo study; feasibility study; female; gastrointestinal endoscopy; histology; human; human tissue; image analysis; intermethod comparison; machine learning; major clinical study; male; priority journal; sensitivity and specificity; volumetric laser endomicroscopy; adenocarcinoma; Barrett esophagus; case control study; computer assisted diagnosis; confocal microscopy; esophagoscopy; esophagus; esophagus tumor; middle aged; pathology; procedures; receiver operating characteristic; reproducibility; support vector machine","Mosby Inc.","00165107","","GAENB","28322771","Article","Scopus","2-s2.0-85018983661"
"Kam H.J.; Kim H.Y.","Kam, Hye Jin (57195422214); Kim, Ha Young (57200074208)","57195422214; 57200074208","Learning representations for the early detection of sepsis with deep neural networks","2017","Computers in Biology and Medicine","145","10.1016/j.compbiomed.2017.08.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027992040&doi=10.1016%2fj.compbiomed.2017.08.015&partnerID=40&md5=22bfab7eb8e77df158e7ce063a8f07a5","Health Innovation Bigdata Center, Asan Institute for Life Sciences, Asan Medical Center, 88, Olympic-ro 43 gil, Songpa-gu, Seoul, 05505, South Korea; Department of Financial Engineering, School of Business, Ajou University, Worldcupro 206, Yeongtong-gu, Suwon, 16499, South Korea","Kam H.J., Health Innovation Bigdata Center, Asan Institute for Life Sciences, Asan Medical Center, 88, Olympic-ro 43 gil, Songpa-gu, Seoul, 05505, South Korea; Kim H.Y., Department of Financial Engineering, School of Business, Ajou University, Worldcupro 206, Yeongtong-gu, Suwon, 16499, South Korea","Background Sepsis is one of the leading causes of death in intensive care unit patients. Early detection of sepsis is vital because mortality increases as the sepsis stage worsens. Objective This study aimed to develop detection models for the early stage of sepsis using deep learning methodologies, and to compare the feasibility and performance of the new deep learning methodology with those of the regression method with conventional temporal feature extraction. Method Study group selection adhered to the InSight model. The results of the deep learning-based models and the InSight model were compared. Results With deep feedforward networks, the area under the ROC curve (AUC) of the models were 0.887 and 0.915 for the InSight and the new feature sets, respectively. For the model with the combined feature set, the AUC was the same as that of the basic feature set (0.915). For the long short-term memory model, only the basic feature set was applied and the AUC improved to 0.929 compared with the existing 0.887 of the InSight model. Conclusions The contributions of this paper can be summarized in three ways: (i) improved performance without feature extraction using domain knowledge, (ii) verification of feature extraction capability of deep neural networks through comparison with reference features, and (iii) improved performance with feedforward neural networks using long short-term memory, a neural network architecture that can learn sequential patterns. © 2017 Elsevier Ltd","Clinical decision support system; Deep learning; Early detection; Feature extraction; LSTM; Multivariate time-series; Sepsis","Adult; Critical Care; Female; Humans; Machine Learning; Male; Models, Biological; Neural Networks (Computer); Sepsis; Brain; Decision support systems; Deep learning; Deep neural networks; Extraction; Feature extraction; Feedforward neural networks; Intensive care units; Network architecture; Regression analysis; Area under the ROC curve; Clinical decision support systems; Extraction capability; Feed-forward network; Learning Based Models; LSTM; Multivariate time series; Sepsis; Article; artificial neural network; blood oxygen tension; body temperature; breathing rate; controlled study; early diagnosis; feasibility study; heart rate; human; intermethod comparison; leukocyte count; methodology; model; network learning; pH; priority journal; pulse pressure; receiver operating characteristic; sepsis; short term memory; systolic blood pressure; adult; biological model; female; intensive care; machine learning; male; procedures; sepsis; Long short-term memory","Elsevier Ltd","00104825","","CBMDA","28843829","Article","Scopus","2-s2.0-85027992040"
"Sharma H.; Zerbe N.; Klempert I.; Hellwich O.; Hufnagl P.","Sharma, Harshita (56272987100); Zerbe, Norman (37058017200); Klempert, Iris (57006745500); Hellwich, Olaf (6701327873); Hufnagl, Peter (7007182921)","56272987100; 37058017200; 57006745500; 6701327873; 7007182921","Deep convolutional neural networks for automatic classification of gastric carcinoma using whole slide images in digital histopathology","2017","Computerized Medical Imaging and Graphics","224","10.1016/j.compmedimag.2017.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021455354&doi=10.1016%2fj.compmedimag.2017.06.001&partnerID=40&md5=28cedab5f1a16ec7ed155b93c459c9fc","Computer Vision and Remote Sensing, Technical University Berlin, Berlin, Germany; Department of Digital Pathology and IT, Institute of Pathology, Charité University Hospital, Berlin, Germany","Sharma H., Computer Vision and Remote Sensing, Technical University Berlin, Berlin, Germany; Zerbe N., Department of Digital Pathology and IT, Institute of Pathology, Charité University Hospital, Berlin, Germany; Klempert I., Department of Digital Pathology and IT, Institute of Pathology, Charité University Hospital, Berlin, Germany; Hellwich O., Computer Vision and Remote Sensing, Technical University Berlin, Berlin, Germany; Hufnagl P., Department of Digital Pathology and IT, Institute of Pathology, Charité University Hospital, Berlin, Germany","Deep learning using convolutional neural networks is an actively emerging field in histological image analysis. This study explores deep learning methods for computer-aided classification in H&E stained histopathological whole slide images of gastric carcinoma. An introductory convolutional neural network architecture is proposed for two computerized applications, namely, cancer classification based on immunohistochemical response and necrosis detection based on the existence of tumor necrosis in the tissue. Classification performance of the developed deep learning approach is quantitatively compared with traditional image analysis methods in digital histopathology requiring prior computation of handcrafted features, such as statistical measures using gray level co-occurrence matrix, Gabor filter-bank responses, LBP histograms, gray histograms, HSV histograms and RGB histograms, followed by random forest machine learning. Additionally, the widely known AlexNet deep convolutional framework is comparatively analyzed for the corresponding classification problems. The proposed convolutional neural network architecture reports favorable results, with an overall classification accuracy of 0.6990 for cancer classification and 0.8144 for necrosis detection. © 2017 Elsevier Ltd","Cancer classification; Convolutional neural networks; Deep learning; Digital pathology; Gastric carcinoma; Histopathological image analysis; Necrosis detection","Algorithms; Automatic Data Processing; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Software; Stomach Neoplasms; Computer aided instruction; Convolution; Decision trees; Deep learning; Diseases; Gabor filters; Graphic methods; Image analysis; Image classification; Network architecture; Neural networks; Cancer classification; Convolutional neural network; Digital pathologies; Gastric carcinoma; Histopathological image analysis; Article; artificial neural network; cancer classification; computer aided design; deep convolutional neural network; diagnostic accuracy; digital imaging; histogram; histopathology; human; human tissue; image analysis; immunohistochemistry; machine learning; priority journal; probability; random forest; statistical analysis; stomach adenocarcinoma; stomach carcinoma; tumor necrosis; algorithm; classification; image processing; information processing; machine learning; pathology; procedures; software; stomach tumor; Deep neural networks","Elsevier Ltd","08956111","","CMIGE","28676295","Article","Scopus","2-s2.0-85021455354"
"Sun W.; Zheng B.; Qian W.","Sun, Wenqing (56091845500); Zheng, Bin (7201781356); Qian, Wei (36842193500)","56091845500; 7201781356; 36842193500","Automatic feature learning using multichannel ROI based on deep structured algorithms for computerized lung cancer diagnosis","2017","Computers in Biology and Medicine","166","10.1016/j.compbiomed.2017.04.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018458426&doi=10.1016%2fj.compbiomed.2017.04.006&partnerID=40&md5=64b01e25e7cf0850fe37814b2435910b","College of Engineering, University of Texas at El Paso, El Paso, TX, United States; College of Engineering, University of Oklahoma, Norman, OK, United States","Sun W., College of Engineering, University of Texas at El Paso, El Paso, TX, United States; Zheng B., College of Engineering, University of Oklahoma, Norman, OK, United States; Qian W., College of Engineering, University of Texas at El Paso, El Paso, TX, United States","This study aimed to analyze the ability of extracting automatically generated features using deep structured algorithms in lung nodule CT image diagnosis, and compare its performance with traditional computer aided diagnosis (CADx) systems using hand-crafted features. All of the 1018 cases were acquired from Lung Image Database Consortium (LIDC) public lung cancer database. The nodules were segmented according to four radiologists’ markings, and 13,668 samples were generated by rotating every slice of nodule images. Three multichannel ROI based deep structured algorithms were designed and implemented in this study: convolutional neural network (CNN), deep belief network (DBN), and stacked denoising autoencoder (SDAE). For the comparison purpose, we also implemented a CADx system using hand-crafted features including density features, texture features and morphological features. The performance of every scheme was evaluated by using a 10-fold cross-validation method and an assessment index of the area under the receiver operating characteristic curve (AUC). The observed highest area under the curve (AUC) was 0.899±0.018 achieved by CNN, which was significantly higher than traditional CADx with the AUC=0.848±0.026. The results from DBN was also slightly higher than CADx, while SDAE was slightly lower. By visualizing the automatic generated features, we found some meaningful detectors like curvy stroke detectors from deep structured schemes. The study results showed the deep structured algorithms with automatically generated features can achieve desirable performance in lung nodule diagnosis. With well-tuned parameters and large enough dataset, the deep learning algorithms can have better performance than current popular CADx. We believe the deep learning algorithms with similar data preprocessing procedure can be used in other medical image analysis areas as well. © 2017","Big data; Computer aided diagnosis; Deep learning; Lung cancer; Unsupervised feature learning","Female; Humans; Image Processing, Computer-Assisted; Lung Neoplasms; Machine Learning; Male; Neural Networks (Computer); Predictive Value of Tests; Tomography, X-Ray Computed; Big data; Biological organs; Computer aided diagnosis; Computer aided instruction; Computerized tomography; Diseases; Image analysis; Learning algorithms; Medical computing; Medical imaging; Neural networks; Structured programming; 10-fold cross-validation; Area Under the Curve (AUC); Automatically generated; Convolutional Neural Networks (CNN); Deep belief network (DBN); Lung Cancer; Receiver operating characteristic curves; Unsupervised feature learning; area under the curve; Article; artificial neural network; cancer diagnosis; cancer screening; computer aided design; deep belief network; human; image analysis; learning algorithm; lung cancer; lung nodule; machine learning; major clinical study; priority journal; radiologist; receiver operating characteristic; stacked denoising autoencoder; x-ray computed tomography; artificial neural network; diagnostic imaging; female; image processing; lung tumor; machine learning; male; predictive value; x-ray computed tomography; Deep learning","Elsevier Ltd","00104825","","CBMDA","28473055","Article","Scopus","2-s2.0-85018458426"
"Zhang Z.; Ma C.; Zhu R.","Zhang, Zhen (56150393500); Ma, Cheng (8914125600); Zhu, Rong (7202446527)","56150393500; 8914125600; 7202446527","A FPGA-based, granularity-variable neuromorphic processor and its application in a MIMO real-time control system","2017","Sensors (Switzerland)","2","10.3390/s17091941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028348596&doi=10.3390%2fs17091941&partnerID=40&md5=8d0b23b636520a5c0fe8a92d7108a5d6","Department of Precision Instrument, Tsinghua University, Beijing, 100084, China","Zhang Z., Department of Precision Instrument, Tsinghua University, Beijing, 100084, China; Ma C., Department of Precision Instrument, Tsinghua University, Beijing, 100084, China; Zhu R., Department of Precision Instrument, Tsinghua University, Beijing, 100084, China","Artificial Neural Networks (ANNs), including Deep Neural Networks (DNNs), have become the state-of-the-art methods in machine learning and achieved amazing success in speech recognition, visual object recognition, and many other domains. There are several hardware platforms for developing accelerated implementation of ANN models. Since Field Programmable Gate Array (FPGA) architectures are flexible and can provide high performance per watt of power consumption, they have drawn a number of applications from scientists. In this paper, we propose a FPGA-based, granularity-variable neuromorphic processor (FBGVNP). The traits of FBGVNP can be summarized as granularity variability, scalability, integrated computing, and addressing ability: first, the number of neurons is variable rather than constant in one core, second, the multi-core network scale can be extended in various forms, third, the neuron addressing and computing processes are executed simultaneously. These make the processor more flexible and better suited for different applications. Moreover, a neural network-based controller is mapped to FBGVNP and applied in a multi-input, multi-output, (MIMO) real-time, temperature-sensing and control system. Experiments validate the effectiveness of the neuromorphic processor. The FBGVNP provides a new scheme for building ANNs, which is flexible, highly energy-efficient, and can be applied in many areas. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial neural networks; FPGA; Granularity variable; MIMO control; Neuromorphic processor","Computer Systems; Neural Networks (Computer); Neurons; Control systems; Deep neural networks; Energy efficiency; Learning systems; Neural networks; Object recognition; Real time control; Speech recognition; Granularity variable; Integrated computing; MIMO controls; Network-based controllers; Neuromorphic; State-of-the-art methods; Temperature sensing; Visual object recognition; artificial neural network; computer system; nerve cell; Field programmable gate arrays (FPGA)","MDPI AG","14248220","","","28832522","Article","Scopus","2-s2.0-85028348596"
"Meng M.; Chua Y.J.; Wouterson E.; Ong C.P.K.","Meng, Min (57193017578); Chua, Yiting Jacqueline (57193017259); Wouterson, Erwin (6507291019); Ong, Chin Peng Kelvin (57193016279)","57193017578; 57193017259; 6507291019; 57193016279","Ultrasonic signal classification and imaging system for composite materials via deep convolutional neural networks","2017","Neurocomputing","167","10.1016/j.neucom.2016.11.066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016608671&doi=10.1016%2fj.neucom.2016.11.066&partnerID=40&md5=7fb1b717aeb1bd607a0968855f7a9f42","Department of Computer Science, Guangdong University of Technology, Guangzhou, China; School of Mechanical and Aeronautical Engineering, Singapore Polytechnic, Singapore","Meng M., Department of Computer Science, Guangdong University of Technology, Guangzhou, China, School of Mechanical and Aeronautical Engineering, Singapore Polytechnic, Singapore; Chua Y.J., School of Mechanical and Aeronautical Engineering, Singapore Polytechnic, Singapore; Wouterson E., School of Mechanical and Aeronautical Engineering, Singapore Polytechnic, Singapore; Ong C.P.K., School of Mechanical and Aeronautical Engineering, Singapore Polytechnic, Singapore","Automated ultrasonic signal classification systems are finding increasing use in many applications for the recognition of large volumes of inspection signals. Wavelet transform is a well-known signal processing technique in fault signal diagnosis system. Most of the proposed approaches have mainly used low-level handcraft features based on wavelet transform to encode the information for different defect classes. In this paper, we proposed a deep learning based framework to classify ultrasonic signals from carbon fiber reinforced polymer (CFRP) specimens with void and delamination. In our proposed algorithm, deep Convolutional Neural Networks (CNNs) are used to learn a compact and effective representation for each signal from wavelet coefficients. To yield superior results, we proposed to use a linear SVM top layer in the training process of signal classification task. The experimental results demonstrated the excellent performance of our proposed algorithm against the classical classifier with manually generated attributes. In addition, a post processing scheme is developed to interpret the classifier outputs with a C-scan imaging process and visualize the locations of defects using a 3D model representation. © 2017","Deep convolutional neural networks; Feature extraction; Ultrasonic signal classification; Wavelet transform","Carbon; Carbon fiber reinforced plastics; Convolution; Defects; Feature extraction; Fiber reinforced plastics; Neural networks; Signal processing; Ultrasonic applications; Wavelet transforms; carbon fiber; polymer; Carbon fiber reinforced polymer; Convolutional neural network; Diagnosis systems; Post-processing scheme; Signal classification; Signal processing technique; Ultrasonic signals; Wavelet coefficients; Article; artificial neural network; calculation; classification algorithm; classifier; composite material; deep convolutional neural network; entropy; image processing; imaging system; prediction; priority journal; probability; signal processing; support vector machine; wavelet analysis; Acoustic signal processing","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85016608671"
"Xue W.; Islam A.; Bhaduri M.; Li S.","Xue, Wufeng (36457947300); Islam, Ali (7103365997); Bhaduri, Mousumi (26432538700); Li, Shuo (57189925356)","36457947300; 7103365997; 26432538700; 57189925356","Direct Multitype Cardiac Indices Estimation via Joint Representation and Regression Learning","2017","IEEE Transactions on Medical Imaging","67","10.1109/TMI.2017.2709251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030480983&doi=10.1109%2fTMI.2017.2709251&partnerID=40&md5=ea776ff0691d85ce5efc11bb4598e2bb","Department of Medical Imaging, Western University, London, N6A 3K7, ON, Canada; Digital Imaging Group of London, London, N6A 3K7, ON, United Kingdom","Xue W., Department of Medical Imaging, Western University, London, N6A 3K7, ON, Canada; Islam A., Digital Imaging Group of London, London, N6A 3K7, ON, United Kingdom; Bhaduri M., Digital Imaging Group of London, London, N6A 3K7, ON, United Kingdom; Li S., Department of Medical Imaging, Western University, London, N6A 3K7, ON, Canada","Cardiac indices estimation is of great importance during identification and diagnosis of cardiac disease in clinical routine. However, estimation of multitype cardiac indices with consistently reliable and high accuracy is still a great challenge due to the high variability of cardiac structures and the complexity of temporal dynamics in cardiac MR sequences. While efforts have been devoted into cardiac volumes estimation through feature engineering followed by a independent regression model, these methods suffer from the vulnerable feature representation and incompatible regression model. In this paper, we propose a semi-automated method for multitype cardiac indices estimation. After the manual labeling of two landmarks for ROI cropping, an integrated deep neural network Indices-Net is designed to jointly learn the representation and regression models. It comprises two tightly-coupled networks, such as a deep convolution autoencoder for cardiac image representation, and a multiple output convolution neural network for indices regression. Joint learning of the two networks effectively enhances the expressiveness of image representation with respect to cardiac indices, and the compatibility between image representation and indices regression, thus leading to accurate and reliable estimations for all the cardiac indices. When applied with five-fold cross validation on MR images of 145 subjects, Indices-Net achieves consistently low estimation error for LV wall thicknesses (1.44 ± 0.71 mm) and areas of cavity and myocardium (204 ± 133 mm2). It outperforms, with significant error reductions, segmentation method (55.1% and 17.4%), and two-phase direct volume-only methods (12.7% and 14.6%) for wall thicknesses and areas, respectively. These advantages endow the proposed method a great potential in clinical cardiac function assessment. © 1982-2012 IEEE.","cardiac MR; deep convolution autoencoder; direct estimation; joint learning; Multitype cardiac indices","Heart; Heart Function Tests; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging, Cine; Neural Networks (Computer); Regression Analysis; Convolution; Deep neural networks; Diagnosis; Estimation; Image enhancement; Magnetic resonance imaging; Regression analysis; Auto encoders; Cardiac MR; Convolution neural network; Feature representation; Image representations; Joint learning; Multitype; Tightly coupled networks; adolescent; adult; aged; anatomic landmark; Article; artificial neural network; cardiac muscle; cardiovascular magnetic resonance; heart index; heart left ventricle wall; heart volume; human; image segmentation; machine learning; major clinical study; mathematical model; measurement accuracy; measurement error; reliability; validation study; anatomy and histology; artificial neural network; cine magnetic resonance imaging; computer assisted diagnosis; diagnostic imaging; heart; heart function test; machine learning; physiology; procedures; regression analysis; Heart","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28574348","Article","Scopus","2-s2.0-85030480983"
"Chi J.; Walia E.; Babyn P.; Wang J.; Groot G.; Eramian M.","Chi, Jianning (40761307100); Walia, Ekta (16069673800); Babyn, Paul (7006367819); Wang, Jimmy (57194787810); Groot, Gary (57193655346); Eramian, Mark (8677533000)","40761307100; 16069673800; 7006367819; 57194787810; 57193655346; 8677533000","Thyroid Nodule Classification in Ultrasound Images by Fine-Tuning Deep Convolutional Neural Network","2017","Journal of Digital Imaging","297","10.1007/s10278-017-9997-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022224703&doi=10.1007%2fs10278-017-9997-y&partnerID=40&md5=830cc7a812ac3966111ca462ff1bb99c","Department of Computer Science, University of Saskatchewan, 176 Thorvaldson Bldg, 110 Science Place, Saskatoon, S7N 5C9, SK, Canada; Department of Medical Imaging, University of Saskatchewan, 103 Hospital Dr, Saskatoon, S7N 0W8, SK, Canada; Department of Surgery, Royal University Hospital, 103 Hospital Drive, Suite 2646, Saskatoon, S7N 0W8, SK, Canada","Chi J., Department of Computer Science, University of Saskatchewan, 176 Thorvaldson Bldg, 110 Science Place, Saskatoon, S7N 5C9, SK, Canada; Walia E., Department of Computer Science, University of Saskatchewan, 176 Thorvaldson Bldg, 110 Science Place, Saskatoon, S7N 5C9, SK, Canada; Babyn P., Department of Medical Imaging, University of Saskatchewan, 103 Hospital Dr, Saskatoon, S7N 0W8, SK, Canada; Wang J., Department of Medical Imaging, University of Saskatchewan, 103 Hospital Dr, Saskatoon, S7N 0W8, SK, Canada; Groot G., Department of Surgery, Royal University Hospital, 103 Hospital Drive, Suite 2646, Saskatoon, S7N 0W8, SK, Canada; Eramian M., Department of Computer Science, University of Saskatchewan, 176 Thorvaldson Bldg, 110 Science Place, Saskatoon, S7N 5C9, SK, Canada","With many thyroid nodules being incidentally detected, it is important to identify as many malignant nodules as possible while excluding those that are highly likely to be benign from fine needle aspiration (FNA) biopsies or surgeries. This paper presents a computer-aided diagnosis (CAD) system for classifying thyroid nodules in ultrasound images. We use deep learning approach to extract features from thyroid ultrasound images. Ultrasound images are pre-processed to calibrate their scale and remove the artifacts. A pre-trained GoogLeNet model is then fine-tuned using the pre-processed image samples which leads to superior feature extraction. The extracted features of the thyroid ultrasound images are sent to a Cost-sensitive Random Forest classifier to classify the images into “malignant” and “benign” cases. The experimental results show the proposed fine-tuned GoogLeNet model achieves excellent classification performance, attaining 98.29% classification accuracy, 99.10% sensitivity and 93.90% specificity for the images in an open access database (Pedraza et al. 16), while 96.34% classification accuracy, 86% sensitivity and 99% specificity for the images in our local health region database. © 2017, The Author(s).","Computer vision; Convolutional neural network; Deep learning; Fine-tuning; Machine learning; Thyroid nodules; Ultrasonography","Biopsy, Fine-Needle; Diagnosis, Computer-Assisted; Humans; Neural Networks (Computer); Sensitivity and Specificity; Thyroid Gland; Thyroid Nodule; Ultrasonography; Classification (of information); Computer aided diagnosis; Computer vision; Convolution; Decision trees; Deep learning; Deep neural networks; Education; Image processing; Learning systems; Neural networks; Ultrasonics; Ultrasonography; Classification accuracy; Classification performance; Computer Aided Diagnosis(CAD); Convolutional neural network; Fine tuning; Fine-needle aspirations; Random forest classifier; Thyroid nodule; artificial neural network; classification; computer assisted diagnosis; diagnostic imaging; echography; fine needle aspiration biopsy; human; pathology; procedures; sensitivity and specificity; thyroid gland; thyroid nodule; Image classification","Springer New York LLC","08971889","","JDIME","28695342","Article","Scopus","2-s2.0-85022224703"
"Tan W.R.; Chan C.S.; Aguirre H.E.; Tanaka K.","Tan, Wei Ren (57192559815); Chan, Chee Seng (57194450557); Aguirre, Hernán E. (6603898641); Tanaka, Kiyoshi (55430510400)","57192559815; 57194450557; 6603898641; 55430510400","Fuzzy qualitative deep compression network","2017","Neurocomputing","13","10.1016/j.neucom.2017.04.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018159350&doi=10.1016%2fj.neucom.2017.04.023&partnerID=40&md5=c08b212b1281acc76f6b1ea149a8361a","Faculty of Engineering, Shinshu University, 4-17-1 Wakasato, Nagano, 380-8553, Japan; Center of Image and Signal Processing, Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, 50603, Malaysia","Tan W.R., Faculty of Engineering, Shinshu University, 4-17-1 Wakasato, Nagano, 380-8553, Japan; Chan C.S., Center of Image and Signal Processing, Faculty of Computer Science & Information Technology, University of Malaya, Kuala Lumpur, 50603, Malaysia; Aguirre H.E., Faculty of Engineering, Shinshu University, 4-17-1 Wakasato, Nagano, 380-8553, Japan; Tanaka K., Faculty of Engineering, Shinshu University, 4-17-1 Wakasato, Nagano, 380-8553, Japan","Recently, Convolutional Neural Networks (CNNs) have become a popular choice to tackle image classification tasks. Despite that, it is almost infeasible to embed the CNNs into resource limited hardware (e.g. mobile devices) due to its extremely high memory requirement. To address this problem, several methods were proposed to reduce the CNN memory requirement with a minimum compensation on the classification accuracy. In this paper, we propose a novel one-shot deep compression method based on the fuzzy quantity space to remove redundant CNN weights. Experiments in three public datasets (i.e. MNIST, CIFAR-10 and ImageNet) showed that our proposed approach is able to compress the CNN up to 14 × with a minimal loss of classification accuracy. Also, we present the first attempt to train an end-to-end fuzzy qualitative deep compression model in the fine-art paintings classification problem. We argue that the classification of fine-art collections is a more challenging problem in comparison to objects classification. This is because some of the artworks are neither non-representational nor figurative, and might even require imagination to recognize them. Hence, a question may arise as to whether a machine is able to capture imagination in paintings. One way to find out is by training a deep model and then visualize the low-level to high-level features learnt. Extensive experiments have been conducted on the recently publicly available Wikiart paintings dataset that consists of more than 80,000 paintings and our solution achieve state-of-the-art results (68%) in overall performance. The source code and models are available at: https://github.com/cs-chan/fuzzyDCN. © 2017 Elsevier B.V.","Convolutional neural network; Deep compression; Fuzzy deep learning; Image classification; Painting classification","Classification (of information); Convolution; Mobile devices; Mobile telecommunication systems; Neural networks; Classification accuracy; Compression methods; Compression model; Convolutional neural network; High-level features; Memory requirements; Painting classifications; State of the art; Article; artificial neural network; controlled study; Convolutional Neural Network; fuzzy qualitative deep compression network; fuzzy system; image analysis; limit of quantitation; measurement accuracy; measurement precision; priority journal; Image classification","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85018159350"
"Oskouie S.K.; Prenner S.B.; Shah S.J.; Sauer A.J.","Oskouie, Suzanne K. (57190621688); Prenner, Stuart B. (35759408800); Shah, Sanjiv J. (12545068000); Sauer, Andrew J. (14527997800)","57190621688; 35759408800; 12545068000; 14527997800","Differences in Repolarization Heterogeneity Among Heart Failure With Preserved Ejection Fraction Phenotypic Subgroups","2017","American Journal of Cardiology","17","10.1016/j.amjcard.2017.05.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021185960&doi=10.1016%2fj.amjcard.2017.05.031&partnerID=40&md5=07851a914ce4fa05af71f9e7a57c7e5e","Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, Illinois, United States; Department of Cardiovascular Disease, The University of Kansas School of Medicine, Kansas City, Kansas, United States","Oskouie S.K., Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, Illinois, United States; Prenner S.B., Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, Illinois, United States; Shah S.J., Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, Illinois, United States; Sauer A.J., Department of Cardiovascular Disease, The University of Kansas School of Medicine, Kansas City, Kansas, United States","Heart failure with preserved ejection fraction (HFpEF) is a highly heterogeneous syndrome associated with multiple medical comorbidities and pathophysiologic pathways or phenotypes. We recently developed a phenomapping method combining deep phenotyping with machine learning analysis to classify HFpEF patients into 3 clinically distinct phenotypic subgroups (phenogroups) with different clinical outcomes. Phenogroup #1 was younger with lower B-type natriuretic peptide levels, phenogroup #2 had the highest prevalence of obesity and diabetes mellitus, and phenogroup #3 was the oldest with the most factors for chronic kidney disease, the most dysfunctional myocardial mechanics, and the highest adverse outcomes. The pathophysiological differences between these phenogroups, however, remain incompletely described. We sought to evaluate whether these 3 groups differ on the basis of repolarization heterogeneity, which has previously been linked to adverse outcomes in HFpEF. The T-peak to T-end (TpTe) interval, a well-validated index of repolarization heterogeneity, was measured by 2 readers blinded to each other and all other clinical data on the electrocardiograms of 201 HFpEF patients enrolled in a systematic observational study. TpTe duration was associated with higher B-type natriuretic peptide level (p = 0.006), increased QRS-T angle (p = 0.008), and lower septal e′ velocity (p = 0.007). TpTe duration was greatest in phenogroup #3 (100.4 ± 24.5 ms) compared with phenogroups #1 (91.2 ± 17.3 ms) and #2 (90.2 ± 17.0 ms) (p = 0.0098). On multivariable analyses, increased TpTe was independently associated with the high-risk phenogroup #3 classification. In conclusion, repolarization heterogeneity is a marker of a specific subset of HFpEF patients identified using unsupervised machine learning analysis and therefore may be a key pathophysiologic marker in this subset of HFpEF patients. © 2017 Elsevier Inc.","","Aged; Biomarkers; Echocardiography, Doppler; Electrocardiography; Female; Heart Failure; Heart Ventricles; Humans; Male; Middle Aged; Natriuretic Peptide, Brain; Outpatients; Phenotype; Prognosis; Prospective Studies; Retrospective Studies; Severity of Illness Index; Stroke Volume; brain natriuretic peptide; biological marker; brain natriuretic peptide; adult; aged; Article; chronic kidney failure; clinical trial (topic); diabetes mellitus; echocardiography; female; heart failure with preserved ejection fraction; heart repolarization; hormone blood level; human; major clinical study; male; middle aged; obesity; phenotype; PR interval; priority journal; QRS interval; T-peak to T-end; unsupervised machine learning; blood; diagnostic imaging; Doppler echocardiography; electrocardiography; heart failure; heart stroke volume; heart ventricle; outpatient; pathophysiology; physiology; prognosis; prospective study; retrospective study; severity of illness index","Elsevier Inc.","00029149","","AJCDA","28651852","Article","Scopus","2-s2.0-85021185960"
"Kim M.; Kim Y.; Yoo J.; Wang J.; Kim H.","Kim, Myungjong (56122905900); Kim, Younggwan (56066762200); Yoo, Joohong (56330703100); Wang, Jun (35219327700); Kim, Hoirin (7410129403)","56122905900; 56066762200; 56330703100; 35219327700; 7410129403","Regularized Speaker Adaptation of KL-HMM for Dysarthric Speech Recognition","2017","IEEE Transactions on Neural Systems and Rehabilitation Engineering","38","10.1109/TNSRE.2017.2681691","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029604485&doi=10.1109%2fTNSRE.2017.2681691&partnerID=40&md5=7f1303d1435f54bbf95a583917968142","Department of Bioengineering, University of Texas at Dallas, Richardson, 75080, TX, United States; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 305-701, South Korea","Kim M., Department of Bioengineering, University of Texas at Dallas, Richardson, 75080, TX, United States; Kim Y., School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 305-701, South Korea; Yoo J., School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 305-701, South Korea; Wang J., Department of Bioengineering, University of Texas at Dallas, Richardson, 75080, TX, United States; Kim H., School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 305-701, South Korea","This paper addresses the problem of recognizing the speech uttered by patients with dysarthria, which is a motor speech disorder impeding the physical production of speech. Patients with dysarthria have articulatory limitation, and therefore, they often have trouble in pronouncing certain sounds, resulting in undesirable phonetic variation. Modern automatic speech recognition systems designed for regular speakers are ineffective for dysarthric sufferers due to the phonetic variation. To capture the phonetic variation, Kullback-Leibler divergence-based hidden Markov model (KL-HMM) is adopted, where the emission probability of state is parameterized by a categorical distribution using phoneme posterior probabilities obtained from a deep neural network-based acoustic model. To further reflect speaker-specific phonetic variation patterns, a speaker adaptation method based on a combination of L2 regularization and confusion-reducing regularization, which can enhance discriminability between categorical distributions of the KL-HMM states while preserving speaker-specific information is proposed. Evaluation of the proposed speaker adaptation method on a database of several hundred words for 30 speakers consisting of 12 mildly dysarthric, 8 moderately dysarthric, and 10 non-dysarthric control speakers showed that the proposed approach significantly outperformed the conventional deep neural network-based speaker adapted system on dysarthric as well as non-dysarthric speech. © 2001-2011 IEEE.","Dysarthria; KL-HMM; regularization; speaker adaptation; speech recognition","Adult; Algorithms; Communication Aids for Disabled; Computer Simulation; Dysarthria; Female; Humans; Machine Learning; Male; Markov Chains; Models, Statistical; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Speech Production Measurement; Deep neural networks; Hidden Markov models; Linguistics; Markov processes; Probability distributions; Speech; Automatic speech recognition system; Dysarthria; Emission probabilities; KL-HMM; Kullback Leibler divergence; regularization; Speaker adaptation; Speaker specific informations; acoustics; adult; Article; automatic speech recognition; compulsion; controlled study; dysarthria; female; hidden Markov model; human; Korean (people); kullback leibler hidden Markov model; major clinical study; male; mathematical analysis; microphone; motor dysfunction; nerve cell network; phonetics; sound; speech analysis; speech articulation; speech discrimination; speech disorder; speech sound disorder; speech test; algorithm; automated pattern recognition; communication aid; computer simulation; dysarthria; machine learning; Markov chain; pathophysiology; procedures; reproducibility; sensitivity and specificity; statistical model; Speech recognition","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","28320669","Article","Scopus","2-s2.0-85029604485"
"Zhao J.; Lv Y.; Zhou Z.; Cao F.","Zhao, Jianwei (36618500900); Lv, Yongbiao (57195242053); Zhou, Zhenghua (55511512300); Cao, Feilong (7102711915)","36618500900; 57195242053; 55511512300; 7102711915","A novel deep learning algorithm for incomplete face recognition: Low-rank-recovery network","2017","Neural Networks","21","10.1016/j.neunet.2017.06.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026459206&doi=10.1016%2fj.neunet.2017.06.013&partnerID=40&md5=9f5e70d76617495deeab9674f3346cb3","Department of Mathematics and Information Sciences, China Jiliang University, Hangzhou, Zhejiang Province, 310018, China","Zhao J., Department of Mathematics and Information Sciences, China Jiliang University, Hangzhou, Zhejiang Province, 310018, China; Lv Y., Department of Mathematics and Information Sciences, China Jiliang University, Hangzhou, Zhejiang Province, 310018, China; Zhou Z., Department of Mathematics and Information Sciences, China Jiliang University, Hangzhou, Zhejiang Province, 310018, China; Cao F., Department of Mathematics and Information Sciences, China Jiliang University, Hangzhou, Zhejiang Province, 310018, China","There have been a lot of methods to address the recognition of complete face images. However, in real applications, the images to be recognized are usually incomplete, and it is more difficult to realize such a recognition. In this paper, a novel convolution neural network frame, named a low-rank-recovery network (LRRNet), is proposed to conquer the difficulty effectively inspired by matrix completion and deep learning techniques. The proposed LRRNet first recovers the incomplete face images via an approach of matrix completion with the truncated nuclear norm regularization solution, and then extracts some low-rank parts of the recovered images as the filters. With these filters, some important features are obtained by means of the binaryzation and histogram algorithms. Finally, these features are classified with the classical support vector machines (SVMs). The proposed LRRNet method has high face recognition rate for the heavily corrupted images, especially for the images in the large databases. The proposed LRRNet performs well and efficiently for the images with heavily corrupted, especially in the case of large databases. Extensive experiments on several benchmark databases demonstrate that the proposed LRRNet performs better than some other excellent robust face recognition methods. © 2017 Elsevier Ltd","ADMM; Convolutional neural networks; Deep learning; Face recognition; Recovery of low-rank matrix","Biometric Identification; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Computer system recovery; Convolution; Database systems; Deep learning; Deep neural networks; Education; Learning algorithms; Neural networks; Recovery; Support vector machines; ADMM; Convolution neural network; Convolutional neural network; Face recognition methods; Face recognition rates; Low-rank matrices; Nuclear norm regularizations; Support vector machine (SVMs); algorithm; analytic method; Article; artificial neural network; binaryzation algorithm; controlled study; cost; dense hybrid representation method; facial recognition; histogram algorithm; image analysis; intermethod comparison; learning algorithm; low rank recovery network; matrix completion; measurement accuracy; priority journal; sparse representation based classification method; support vector machine; automated pattern recognition; biometry; machine learning; procedures; Face recognition","Elsevier Ltd","08936080","","NNETE","28772239","Article","Scopus","2-s2.0-85026459206"
"Le N.-Q.-K.; Ho Q.-T.; Ou Y.-Y.","Le, Nguyen-Quoc-Khanh (57208281644); Ho, Quang-Thai (57194618797); Ou, Yu-Yen (35847309000)","57208281644; 57194618797; 35847309000","Incorporating deep learning with convolutional neural networks and position specific scoring matrices for identifying electron transport proteins","2017","Journal of Computational Chemistry","78","10.1002/jcc.24842","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021306883&doi=10.1002%2fjcc.24842&partnerID=40&md5=cad1677388239a9ed3e8594b538824c6","Department of Computer Science and Engineering, Yuan Ze University, Chung-Li, Taiwan","Le N.-Q.-K., Department of Computer Science and Engineering, Yuan Ze University, Chung-Li, Taiwan; Ho Q.-T., Department of Computer Science and Engineering, Yuan Ze University, Chung-Li, Taiwan; Ou Y.-Y., Department of Computer Science and Engineering, Yuan Ze University, Chung-Li, Taiwan","In several years, deep learning is a modern machine learning technique using in a variety of fields with state-of-the-art performance. Therefore, utilization of deep learning to enhance performance is also an important solution for current bioinformatics field. In this study, we try to use deep learning via convolutional neural networks and position specific scoring matrices to identify electron transport proteins, which is an important molecular function in transmembrane proteins. Our deep learning method can approach a precise model for identifying of electron transport proteins with achieved sensitivity of 80.3%, specificity of 94.4%, and accuracy of 92.3%, with MCC of 0.71 for independent dataset. The proposed technique can serve as a powerful tool for identifying electron transport proteins and can help biologists understand the function of the electron transport proteins. Moreover, this study provides a basis for further research that can enrich a field of applying deep learning in bioinformatics. © 2017 Wiley Periodicals, Inc. © 2017 Wiley Periodicals, Inc.","bioinformatics; convolutional neural network; deep learning; electron transport protein; position specific scoring matrix","Bioinformatics; Convolution; Deep neural networks; Education; Electron transport properties; Electrons; Learning systems; Neural networks; Proteins; Convolutional neural network; Electron transport; Molecular function; Position specific scoring matrix; Precise modeling; Scoring matrices; State-of-the-art performance; Trans-membrane proteins; Deep learning","John Wiley and Sons Inc.","01928651","","JCCHD","28643394","Article","Scopus","2-s2.0-85021306883"
"Lopes U.K.; Valiati J.F.","Lopes, U.K. (57195301128); Valiati, J.F. (8915545700)","57195301128; 8915545700","Pre-trained convolutional neural networks as feature extractors for tuberculosis detection","2017","Computers in Biology and Medicine","213","10.1016/j.compbiomed.2017.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026881283&doi=10.1016%2fj.compbiomed.2017.08.001&partnerID=40&md5=396e9bae77f2fa9c6ef8e078f46bb385","Artificial Intelligence Engineers - AIE, 262, Vieira de Castro Street, Porto Alegre, RS, Brazil; DevGrid, 482, Italia Avenue, Caxias do Sul, RS, Brazil","Lopes U.K., DevGrid, 482, Italia Avenue, Caxias do Sul, RS, Brazil; Valiati J.F., Artificial Intelligence Engineers - AIE, 262, Vieira de Castro Street, Porto Alegre, RS, Brazil","It is estimated that in 2015, approximately 1.8 million people infected by tuberculosis died, most of them in developing countries. Many of those deaths could have been prevented if the disease had been detected at an earlier stage, but the most advanced diagnosis methods are still cost prohibitive for mass adoption. One of the most popular tuberculosis diagnosis methods is the analysis of frontal thoracic radiographs; however, the impact of this method is diminished by the need for individual analysis of each radiography by properly trained radiologists. Significant research can be found on automating diagnosis by applying computational techniques to medical images, thereby eliminating the need for individual image analysis and greatly diminishing overall costs. In addition, recent improvements on deep learning accomplished excellent results classifying images on diverse domains, but its application for tuberculosis diagnosis remains limited. Thus, the focus of this work is to produce an investigation that will advance the research in the area, presenting three proposals to the application of pre-trained convolutional neural networks as feature extractors to detect the disease. The proposals presented in this work are implemented and compared to the current literature. The obtained results are competitive with published works demonstrating the potential of pre-trained convolutional networks as medical image feature extractors. © 2017 Elsevier Ltd","Computer assisted diagnosis; Convolutional neural networks; Deep learning; Ensemble learning; Multiple instance learning; Tuberculosis","Female; Humans; Image Processing, Computer-Assisted; Male; Neural Networks (Computer); Tuberculosis, Pulmonary; Computer aided diagnosis; Computer aided instruction; Convolution; Cost benefit analysis; Developing countries; Feature extraction; Image enhancement; Medical imaging; Neural networks; Tubes (components); Computer assisted diagnosis; Convolutional neural network; Ensemble learning; Multiple instance learning; Tuberculosis; accuracy; Article; convolutional neural network; human; image analysis; machine learning; priority journal; radiography; tuberculosis; artificial neural network; diagnostic imaging; female; image processing; lung tuberculosis; male; procedures; Deep learning","Elsevier Ltd","00104825","","CBMDA","28800442","Article","Scopus","2-s2.0-85026881283"
"Guo X.; Dominick K.C.; Minai A.A.; Li H.; Erickson C.A.; Lu L.J.","Guo, Xinyu (57221244475); Dominick, Kelli C. (15847766600); Minai, Ali A. (7004258894); Li, Hailong (56767931400); Erickson, Craig A. (9332722600); Lu, Long J. (54403388300)","57221244475; 15847766600; 7004258894; 56767931400; 9332722600; 54403388300","Diagnosing autism spectrum disorder from brain resting-state functional connectivity patterns using a deep neural network with a novel feature selection method","2017","Frontiers in Neuroscience","138","10.3389/fnins.2017.00460","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028330242&doi=10.3389%2ffnins.2017.00460&partnerID=40&md5=3ec19faaf4dc4c6b16f4368053494f6f","Division of Biomedical Informatics, Cincinnati Children's Hospital Research Foundation, Cincinnati, OH, United States; Department of Electrical Engineering and Computing Systems, University of Cincinnati, Cincinnati, OH, United States; The Kelly O'Leary Center for Autism Spectrum Disorders, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States; School of Information Management, Wuhan University, Wuhan, China; Department of Environmental Health, College of Medicine, University of Cincinnati, Cincinnati, OH, United States","Guo X., Division of Biomedical Informatics, Cincinnati Children's Hospital Research Foundation, Cincinnati, OH, United States, Department of Electrical Engineering and Computing Systems, University of Cincinnati, Cincinnati, OH, United States; Dominick K.C., The Kelly O'Leary Center for Autism Spectrum Disorders, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States; Minai A.A., Department of Electrical Engineering and Computing Systems, University of Cincinnati, Cincinnati, OH, United States; Li H., Division of Biomedical Informatics, Cincinnati Children's Hospital Research Foundation, Cincinnati, OH, United States; Erickson C.A., The Kelly O'Leary Center for Autism Spectrum Disorders, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States; Lu L.J., Division of Biomedical Informatics, Cincinnati Children's Hospital Research Foundation, Cincinnati, OH, United States, Department of Electrical Engineering and Computing Systems, University of Cincinnati, Cincinnati, OH, United States, School of Information Management, Wuhan University, Wuhan, China, Department of Environmental Health, College of Medicine, University of Cincinnati, Cincinnati, OH, United States","The whole-brain functional connectivity (FC) pattern obtained from resting-state functional magnetic resonance imaging data are commonly applied to study neuropsychiatric conditions such as autism spectrum disorder (ASD) by using different machine learning models. Recent studies indicate that both hyper- and hypoaberrant ASD-associated FCs were widely distributed throughout the entire brain rather than only in some specific brain regions. Deep neural networks (DNN) with multiple hidden layers have shown the ability to systematically extract lower-to-higher level information from high dimensional data across a series of neural hidden layers, significantly improving classification accuracy for such data. In this study, a DNN with a novel feature selection method (DNN-FS) is developed for the high dimensional whole-brain resting-state FC pattern classification of ASD patients vs. typical development (TD) controls. The feature selection method is able to help the DNN generate low dimensional high-quality representations of the whole-brain FC patterns by selecting features with high discriminating power from multiple trained sparse auto-encoders. For the comparison, a DNN without the feature selection method (DNN-woFS) is developed, and both of them are tested with different architectures (i.e., with different numbers of hidden layers/nodes). Results show that the best classification accuracy of 86.36% is generated by the DNN-FS approach with 3 hidden layers and 150 hidden nodes (3/150). Remarkably, DNN-FS outperforms DNN-woFS for all architectures studied. The most significant accuracy improvement was 9.09% with the 3/150 architecture. The method also outperforms other feature selection methods, e.g., two sample t-test and elastic net. In addition to improving the classification accuracy, a Fisher's score-based biomarker identification method based on the DNN is also developed, and used to identify 32 FCs related to ASD. These FCs come from or cross different pre-defined brain networks including the default-mode, cingulo-opercular, frontal-parietal, and cerebellum. Thirteen of them are statically significant between ASD and TD groups (two sample t-test p < 0.05) while 19 of themare not. The relationship between the statically significant FCs and the corresponding ASD behavior symptoms is discussed based on the literature and clinician's expert knowledge. Meanwhile, the potential reason of obtaining 19 FCs which are not statistically significant is also provided. © 2017 Guo, Dominick, Minai, Li, Erickson and Lu.","Autism spectrum disorder; Deep neural network; Feature selection; Resting-state fMRI; Sparse auto-encoder","","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85028330242"
"Lee H.; Troschel F.M.; Tajmir S.; Fuchs G.; Mario J.; Fintelmann F.J.; Do S.","Lee, Hyunkwang (57193528962); Troschel, Fabian M. (57193734513); Tajmir, Shahein (57000496000); Fuchs, Georg (57194620589); Mario, Julia (56895968700); Fintelmann, Florian J. (13605476700); Do, Synho (24173146300)","57193528962; 57193734513; 57000496000; 57194620589; 56895968700; 13605476700; 24173146300","Pixel-Level Deep Segmentation: Artificial Intelligence Quantifies Muscle on Computed Tomography for Body Morphometric Analysis","2017","Journal of Digital Imaging","130","10.1007/s10278-017-9988-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021296993&doi=10.1007%2fs10278-017-9988-z&partnerID=40&md5=74624e9f9828ed9625798e0951827523","Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Department of Radiology, Charite - Universitaetsmedizin Berlin, Chariteplatz 1, Berlin, 10117, Germany","Lee H., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Troschel F.M., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Tajmir S., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Fuchs G., Department of Radiology, Charite - Universitaetsmedizin Berlin, Chariteplatz 1, Berlin, 10117, Germany; Mario J., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Fintelmann F.J., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Do S., Department of Radiology, Massachusetts General Hospital, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States","Pretreatment risk stratification is key for personalized medicine. While many physicians rely on an “eyeball test” to assess whether patients will tolerate major surgery or chemotherapy, “eyeballing” is inherently subjective and difficult to quantify. The concept of morphometric age derived from cross-sectional imaging has been found to correlate well with outcomes such as length of stay, morbidity, and mortality. However, the determination of the morphometric age is time intensive and requires highly trained experts. In this study, we propose a fully automated deep learning system for the segmentation of skeletal muscle cross-sectional area (CSA) on an axial computed tomography image taken at the third lumbar vertebra. We utilized a fully automated deep segmentation model derived from an extended implementation of a fully convolutional network with weight initialization of an ImageNet pre-trained model, followed by post processing to eliminate intramuscular fat for a more accurate analysis. This experiment was conducted by varying window level (WL), window width (WW), and bit resolutions in order to better understand the effects of the parameters on the model performance. Our best model, fine-tuned on 250 training images and ground truth labels, achieves 0.93 ± 0.02 Dice similarity coefficient (DSC) and 3.68 ± 2.29% difference between predicted and ground truth muscle CSA on 150 held-out test cases. Ultimately, the fully automated segmentation system can be embedded into the clinical environment to accelerate the quantification of muscle and expanded to volume analysis of 3D datasets. © 2017, The Author(s).","Artificial intelligence; Computed tomography; Computer-aided diagnosis (CAD); Convolutional neural networks; Deep learning; Muscle segmentation","Adipose Tissue; Age Factors; Artificial Intelligence; Body Mass Index; Female; Humans; Length of Stay; Machine Learning; Male; Middle Aged; Muscle, Skeletal; Obesity; Sex Factors; Time Factors; Tomography, X-Ray Computed; Artificial intelligence; Automation; Chemotherapy; Computer aided diagnosis; Computer aided instruction; Computerized tomography; Convolution; Deep neural networks; Diagnosis; Education; Image segmentation; Muscle; Neural networks; Tomography; Computed tomography images; Computer Aided Diagnosis(CAD); Convolutional networks; Convolutional neural network; Cross-sectional imaging; Muscle segmentation; Personalized medicines; Similarity coefficients; adipose tissue; age; artificial intelligence; body mass; diagnostic imaging; female; human; length of stay; machine learning; male; middle aged; obesity; procedures; sex factor; skeletal muscle; time factor; x-ray computed tomography; Deep learning","Springer New York LLC","08971889","","JDIME","28653123","Article","Scopus","2-s2.0-85021296993"
"Zhang J.; Li K.; Liang Y.; Li N.","Zhang, Jian (56340058300); Li, Ke (57326566800); Liang, Yun (55352015600); Li, Na (56794999000)","56340058300; 57326566800; 55352015600; 56794999000","Learning 3D faces from 2D images via Stacked Contractive Autoencoder","2017","Neurocomputing","31","10.1016/j.neucom.2016.11.062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012870255&doi=10.1016%2fj.neucom.2016.11.062&partnerID=40&md5=c221f99bc314fc7405d5a697c59e57ea","School of Science and Technology, Zhejiang International Studies University, Hangzhou, 310012, China; Zhengzhou Institute of Surveying and Mapping, Zhengzhou, 450052, China; College of Mathematics and Informatics, South China Agricultural University, Guangzhou, 510642, China; School of Computing Science, Simon Fraser University, Burnaby, V5A 1S6, Canada","Zhang J., School of Science and Technology, Zhejiang International Studies University, Hangzhou, 310012, China, School of Computing Science, Simon Fraser University, Burnaby, V5A 1S6, Canada; Li K., Zhengzhou Institute of Surveying and Mapping, Zhengzhou, 450052, China, School of Computing Science, Simon Fraser University, Burnaby, V5A 1S6, Canada; Liang Y., College of Mathematics and Informatics, South China Agricultural University, Guangzhou, 510642, China, School of Computing Science, Simon Fraser University, Burnaby, V5A 1S6, Canada; Li N., School of Science and Technology, Zhejiang International Studies University, Hangzhou, 310012, China","3D face reconstruction from a 2D face image has been found important to various applications such as face detection and recognition because a 3D face provides more semantic information than 2D image. This paper proposes a deep learning framework for 3D face reconstruction. The framework is designed to compute subspace feature of arbitrary face image, then map the feature to its counterpart in another subspace learned with 3D faces, and reconstruct the 3D face using the counterpart feature. During the course of training, we learn 2D and 3D subspaces through Stacked Contractive Autoencoders (SCAE), use a one-layer fully connected neural network to learn the mapping, and use the pre-trained parameters of the SCAEs and the one-layer network to initialize a deep feedforward neural network whose input are face images and output are 3D faces. The network is optimized by gradient descent algorithm with back-propagation. Extensive experimental results on various data sets indicate the effectiveness of the proposed SCAE-based 3D face reconstruction method. © 2017","3D face reconstruction; Deep learning; Neural network; Stacked Contractive Autoencoder; Subspace","Backpropagation; Backpropagation algorithms; Deep learning; Deep neural networks; Feedforward neural networks; Image processing; Image reconstruction; Learning systems; Network layers; Neural networks; Semantics; 3D face reconstruction; Auto encoders; Face detection and recognition; Fully connected neural network; Gradient descent algorithms; Learning frameworks; Semantic information; Subspace; Article; artificial neural network; automated face detection; automated face recognition; image analysis; image processing; image reconstruction; imaging and display; intermethod comparison; machine learning; measurement error; priority journal; three dimensional imaging; two dimensional imaging; Face recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85012870255"
"Geraci J.; Wilansky P.; De Luca V.; Roy A.; Kennedy J.L.; Strauss J.","Geraci, Joseph (56572353500); Wilansky, Pamela (56163477100); De Luca, Vincenzo (7005424497); Roy, Anvesh (57195261201); Kennedy, James L. (57218564693); Strauss, John (57943270100)","56572353500; 56163477100; 7005424497; 57195261201; 57218564693; 57943270100","Applying deep neural networks to unstructured text notes in electronic medical records for phenotyping youth depression","2017","Evidence-Based Mental Health","48","10.1136/eb-2017-102688","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026677729&doi=10.1136%2feb-2017-102688&partnerID=40&md5=4a5bd9af00d2905e6989a277a69807b1","Centre for Addiction and Mental Health, Toronto, ON, Canada; Department of Pathology and Molecular Medicine, Queen’s University, Kingston, NY, United States; Shannon Centennial Informatics Lab, Centre for Addiction and Mental Health, Toronto, ON, Canada; Cundill Centre for Child and Youth Depression, Centre for Addiction and Mental Health, Toronto, ON, Canada","Geraci J., Centre for Addiction and Mental Health, Toronto, ON, Canada, Department of Pathology and Molecular Medicine, Queen’s University, Kingston, NY, United States, Shannon Centennial Informatics Lab, Centre for Addiction and Mental Health, Toronto, ON, Canada; Wilansky P., Centre for Addiction and Mental Health, Toronto, ON, Canada; De Luca V., Centre for Addiction and Mental Health, Toronto, ON, Canada; Roy A., Centre for Addiction and Mental Health, Toronto, ON, Canada; Kennedy J.L., Centre for Addiction and Mental Health, Toronto, ON, Canada; Strauss J., Centre for Addiction and Mental Health, Toronto, ON, Canada, Shannon Centennial Informatics Lab, Centre for Addiction and Mental Health, Toronto, ON, Canada, Cundill Centre for Child and Youth Depression, Centre for Addiction and Mental Health, Toronto, ON, Canada","Background We report a study of machine learning applied to the phenotyping of psychiatric diagnosis for research recruitment in youth depression, conducted with 861 labelled electronic medical records (EMRs) documents. A model was built that could accurately identify individuals who were suitable candidates for a study on youth depression. Objective Our objective was a model to identify individuals who meet inclusion criteria as well as unsuitable patients who would require exclusion. Methods Our methods included applying a system that coded the EMR documents by removing personally identifying information, using two psychiatrists who labelled a set of EMR documents (from which the 861 came), using a brute force search and training a deep neural network for this task. Findings According to a cross-validation evaluation, we describe a model that had a specificity of 97% and a sensitivity of 45% and a second model with a specificity of 53% and a sensitivity of 89%. We combined these two models into a third one (sensitivity 93.5%; specificity 68%; positive predictive value (precision) 77%) to generate a list of most suitable candidates in support of research recruitment. Conclusion Our efforts are meant to demonstrate the potential for this type of approach for patient recruitment purposes but it should be noted that a larger sample size is required to build a truly reliable recommendation system. Clinical implications Future efforts will employ alternate neural network algorithms available and other machine learning methods. © Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2017. All rights reserved.","","Adolescent; Algorithms; Depression; Electronic Health Records; Humans; Machine Learning; Young Adult; diagnostic test accuracy study; electronic medical record; human; identifiable information; juvenile; machine learning; model; nervous system; phenotype; predictive value; psychiatrist; sample size; validation process; adolescent; algorithm; depression; electronic health record; machine learning; young adult","BMJ Publishing Group","13620347","","","28739578","Article","Scopus","2-s2.0-85026677729"
"Shi J.; Wu J.; Li Y.; Zhang Q.; Ying S.","Shi, Jun (7404495816); Wu, Jinjie (57191708953); Li, Yan (55900053900); Zhang, Qi (56841055400); Ying, Shihui (24451523300)","7404495816; 57191708953; 55900053900; 56841055400; 24451523300","Histopathological Image Classification with Color Pattern Random Binary Hashing-Based PCANet and Matrix-Form Classifier","2017","IEEE Journal of Biomedical and Health Informatics","64","10.1109/JBHI.2016.2602823","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029929139&doi=10.1109%2fJBHI.2016.2602823&partnerID=40&md5=9c3c0d41da739278df573ba90344829b","Institute of Biomedical Engineering, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Shenzhen City Key Laboratory of Embedded System Design, Shenzhen Laboratory of IC Design for Internet of Things, Shenzhen University, Shenzhen, 518060, China; Department of Mathematics, School of Science, Shanghai University, Shanghai, 200444, China","Shi J., Institute of Biomedical Engineering, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Wu J., Institute of Biomedical Engineering, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Li Y., Shenzhen City Key Laboratory of Embedded System Design, Shenzhen Laboratory of IC Design for Internet of Things, Shenzhen University, Shenzhen, 518060, China; Zhang Q., Institute of Biomedical Engineering, School of Communication and Information Engineering, Shanghai University, Shanghai, 200444, China; Ying S., Department of Mathematics, School of Science, Shanghai University, Shanghai, 200444, China","The computer-Aided diagnosis for histopathological images has attracted considerable attention. Principal component analysis network (PCANet) is a novel deep learning algorithm for feature learning with the simple network architecture and parameters. In this study, a color pattern random binary hashing-based PCANet (C-RBH-PCANet) algorithm is proposed to learn an effective feature representation from color histopathological images. The color norm pattern and angular pattern are extracted from the principal component images of R, G, and B color channels after cascaded PCA networks. The random binary encoding is then performed on both color norm pattern images and angular pattern images to generate multiple binary images. Moreover, we rearrange the pooled local histogram features by spatial pyramid pooling to a matrix-form for reducing the dimension of feature and preserving spatial information. Therefore, a C-RBH-PCANet and matrix-form classifier-based feature learning and classification framework is proposed for diagnosis of color histopathological images. The experimental results on three color histopathological image datasets show that the proposed C-RBH-PCANet algorithm is superior to the original PCANet and other conventional unsupervised deep learning algorithms, while the best performance is achieved by the proposed feature learning and classification framework that combines C-RBH-PCANet and matrix-form classifier. © 2013 IEEE.","Color angular pattern; color histopathological image; color norm pattern; matrix-form classifier; PCANet; random binary hashing","Algorithms; Breast Neoplasms; Databases, Factual; Female; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Kidney Diseases; Machine Learning; Principal Component Analysis; ROC Curve; Binary images; Color; Color printing; Computer aided diagnosis; Deep learning; Image classification; Image coding; Learning algorithms; Network architecture; Color angular patterns; Histopathological images; Matrix forms; PCANet; random binary hashing; classification; classifier; diagnosis; histogram; learning algorithm; principal component analysis; algorithm; breast tumor; computer assisted diagnosis; cytochemistry; diagnostic imaging; factual database; female; human; kidney disease; machine learning; principal component analysis; procedures; receiver operating characteristic; Classification (of information)","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","27576270","Article","Scopus","2-s2.0-85029929139"
"Zhou X.; Takayama R.; Wang S.; Hara T.; Fujita H.","Zhou, Xiangrong (55643005500); Takayama, Ryosuke (57191698570); Wang, Song (55775934200); Hara, Takeshi (57211769926); Fujita, Hiroshi (22634241800)","55643005500; 57191698570; 55775934200; 57211769926; 22634241800","Deep learning of the sectional appearances of 3D CT images for anatomical structure segmentation based on an FCN voting method","2017","Medical Physics","149","10.1002/mp.12480","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028583341&doi=10.1002%2fmp.12480&partnerID=40&md5=7df42f3f8e73a0461cb8ae592579cc11","Department of Intelligent Image Information, Graduate School of Medicine, Gifu University, Gifu, 501-1194, Japan; Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States","Zhou X., Department of Intelligent Image Information, Graduate School of Medicine, Gifu University, Gifu, 501-1194, Japan; Takayama R., Department of Intelligent Image Information, Graduate School of Medicine, Gifu University, Gifu, 501-1194, Japan; Wang S., Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States; Hara T., Department of Intelligent Image Information, Graduate School of Medicine, Gifu University, Gifu, 501-1194, Japan; Fujita H., Department of Intelligent Image Information, Graduate School of Medicine, Gifu University, Gifu, 501-1194, Japan","Purpose: We propose a single network trained by pixel-to-label deep learning to address the general issue of automatic multiple organ segmentation in three-dimensional (3D) computed tomography (CT) images. Our method can be described as a voxel-wise multiple-class classification scheme for automatically assigning labels to each pixel/voxel in a 2D/3D CT image. Methods: We simplify the segmentation algorithms of anatomical structures (including multiple organs) in a CT image (generally in 3D) to a majority voting scheme over the semantic segmentation of multiple 2D slices drawn from different viewpoints with redundancy. The proposed method inherits the spirit of fully convolutional networks (FCNs) that consist of ""convolution"" and ""deconvolution"" layers for 2D semantic image segmentation, and expands the core structure with 3D-2D-3D transformations to adapt to 3D CT image segmentation. All parameters in the proposed network are trained pixel-to-label from a small number of CT cases with human annotations as the ground truth. The proposed network naturally fulfills the requirements of multiple organ segmentations in CT cases of different sizes that cover arbitrary scan regions without any adjustment. Results: The proposed network was trained and validated using the simultaneous segmentation of 19 anatomical structures in the human torso, including 17 major organs and two special regions (lumen and content inside of stomach). Some of these structures have never been reported in previous research on CT segmentation. A database consisting of 240 (95% for training and 5% for testing) 3D CT scans, together with their manually annotated ground-truth segmentations, was used in our experiments. The results show that the 19 structures of interest were segmented with acceptable accuracy (88.1% and 87.9% voxels in the training and testing datasets, respectively, were labeled correctly) against the ground truth. Conclusions: We propose a single network based on pixel-to-label deep learning to address the challenging issue of anatomical structure segmentation in 3D CT cases. The novelty of this work is the policy of deep learning of the different 2D sectional appearances of 3D anatomical structures for CT cases and the majority voting of the 3D segmentation results from multiple crossed 2D sections to achieve availability and reliability with better efficiency, generality, and flexibility than conventional segmentation methods, which must be guided by human expertise. © 2017 The Authors. Medical Physics published by Wiley Periodicals, Inc. on behalf of American Association of Physicists in Medicine.","2D semantic segmentation; anatomical structure segmentation; CT images; deep learning; fully convolutional network (FCN)","Humans; Imaging, Three-Dimensional; Lung; Machine Learning; Tomography, X-Ray Computed; Computerized tomography; Convolution; Deep learning; Pixels; Semantic Web; Semantics; 2d semantic segmentation; 3d computed tomographies; Anatomical structure segmentation; Anatomical structures; Computed tomography images; Convolutional networks; Deep learning; Fully convolutional network; Ground truth; Semantic segmentation; case report; classification; computer assisted tomography; human; image segmentation; learning; reliability; stomach; trunk; diagnostic imaging; lung; machine learning; procedures; three dimensional imaging; x-ray computed tomography; Semantic Segmentation","John Wiley and Sons Ltd","00942405","","MPHYA","28730602","Article","Scopus","2-s2.0-85028583341"
"Laksshman S.; Bhat R.R.; Viswanath V.; Li X.","Laksshman, Sundaram (57195245635); Bhat, Rajendra Rana (57193648977); Viswanath, Vivek (57195250435); Li, Xiaolin (57203730508)","57195245635; 57193648977; 57195250435; 57203730508","DeepBipolar: Identifying genomic mutations for bipolar disorder via deep learning","2017","Human Mutation","35","10.1002/humu.23272","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026507495&doi=10.1002%2fhumu.23272&partnerID=40&md5=643e89bb37174db495739e615556fded","National Science Foundation Center for Big Learning, University of Florida, Gainesville, FL, United States","Laksshman S., National Science Foundation Center for Big Learning, University of Florida, Gainesville, FL, United States; Bhat R.R., National Science Foundation Center for Big Learning, University of Florida, Gainesville, FL, United States; Viswanath V., National Science Foundation Center for Big Learning, University of Florida, Gainesville, FL, United States; Li X., National Science Foundation Center for Big Learning, University of Florida, Gainesville, FL, United States","Bipolar disorder, also known as manic depression, is a brain disorder that affects the brain structure of a patient. It results in extreme mood swings, severe states of depression, and overexcitement simultaneously. It is estimated that roughly 3% of the population of the United States (about 5.3 million adults) suffers from bipolar disorder. Recent research efforts like the Twin studies have demonstrated a high heritability factor for the disorder, making genomics a viable alternative for detecting and treating bipolar disorder, in addition to the conventional lengthy and costly postsymptom clinical diagnosis. Motivated by this study, leveraging several emerging deep learning algorithms, we design an end-to-end deep learning architecture (called DeepBipolar) to predict bipolar disorder based on limited genomic data. DeepBipolar adopts the Deep Convolutional Neural Network (DCNN) architecture that automatically extracts features from genotype information to predict the bipolar phenotype. We participated in the Critical Assessment of Genome Interpretation (CAGI) bipolar disorder challenge and DeepBipolar was considered the most successful by the independent assessor. In this work, we thoroughly evaluate the performance of DeepBipolar and analyze the type of signals we believe could have affected the classifier in distinguishing the case samples from the control set. © 2017 Wiley Periodicals, Inc.","bipolar disorder; convolutional neural network; deep learning; exome single-nucleotide polymorphisms analysis","Algorithms; Bipolar Disorder; Genomics; Humans; Machine Learning; Mutation; Polymorphism, Single Nucleotide; Article; biology; bipolar disorder; chromosome; classifier; decision tree; exome; gene mutation; genotype; heritability; human; machine learning; nerve cell network; phenotype; priority journal; random forest; single nucleotide polymorphism; United States; whole exome sequencing; algorithm; bipolar disorder; genetics; genomics; machine learning; mutation; procedures","John Wiley and Sons Inc.","10597794","","HUMUE","28600868","Article","Scopus","2-s2.0-85026507495"
"Xiong D.; Zeng J.; Gong H.","Xiong, Dapeng (58825716600); Zeng, Jianyang (33468010200); Gong, Haipeng (57205067584)","58825716600; 33468010200; 57205067584","A deep learning framework for improving long-range residue-residue contact prediction using a hierarchical strategy","2017","Bioinformatics (Oxford, England)","33","10.1093/bioinformatics/btx296","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044408878&doi=10.1093%2fbioinformatics%2fbtx296&partnerID=40&md5=cfb140cde4a7efd2fc63971722c14737","Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China","Xiong D., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China, Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Zeng J., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China, Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Gong H., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China, Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China","Motivation: Residue-residue contacts are of great value for protein structure prediction, since contact information, especially from those long-range residue pairs, can significantly reduce the complexity of conformational sampling for protein structure prediction in practice. Despite progresses in the past decade on protein targets with abundant homologous sequences, accurate contact prediction for proteins with limited sequence information is still far from satisfaction. Methodologies for these hard targets still need further improvement.; Results: We presented a computational program DeepConPred, which includes a pipeline of two novel deep-learning-based methods (DeepCCon and DeepRCon) as well as a contact refinement step, to improve the prediction of long-range residue contacts from primary sequences. When compared with previous prediction approaches, our framework employed an effective scheme to identify optimal and important features for contact prediction, and was only trained with coevolutionary information derived from a limited number of homologous sequences to ensure robustness and usefulness for hard targets. Independent tests showed that 59.33%/49.97%, 64.39%/54.01% and 70.00%/59.81% of the top L/5, top L/10 and top 5 predictions were correct for CASP10/CASP11 proteins, respectively. In general, our algorithm ranked as one of the best methods for CASP targets.; Availability and implementation: All source data and codes are available at http://166.111.152.91/Downloads.html .; Contact: hgong@tsinghua.edu.cn or zengjy321@tsinghua.edu.cn.; Supplementary information: Supplementary data are available at Bioinformatics online. © The Author (2017). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com","","Computational Biology; Databases, Protein; Machine Learning; Models, Molecular; Protein Conformation; Software; biology; machine learning; molecular model; procedures; protein conformation; protein database; software","","13674811","","","28472263","Article","Scopus","2-s2.0-85044408878"
"Heffernan R.; Yang Y.; Paliwal K.; Zhou Y.","Heffernan, Rhys (56388539300); Yang, Yuedong (8439078900); Paliwal, Kuldip (7005281122); Zhou, Yaoqi (7405366766)","56388539300; 8439078900; 7005281122; 7405366766","Capturing non-local interactions by long short-term memory bidirectional recurrent neural networks for improving prediction of protein secondary structure, backbone angles, contact numbers and solvent accessibility","2017","Bioinformatics","244","10.1093/bioinformatics/btx218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026373829&doi=10.1093%2fbioinformatics%2fbtx218&partnerID=40&md5=12c22772c00a23ec6d9170e03ec9e9b4","Signal Processing Laboratory, Griffith University, Brisbane, 4111, QLD, Australia; Institute for Glycomics and School of Information and Communication Technology, Griffith University, Southport, 4222, QLD, Australia","Heffernan R., Signal Processing Laboratory, Griffith University, Brisbane, 4111, QLD, Australia; Yang Y., Institute for Glycomics and School of Information and Communication Technology, Griffith University, Southport, 4222, QLD, Australia; Paliwal K., Signal Processing Laboratory, Griffith University, Brisbane, 4111, QLD, Australia; Zhou Y., Institute for Glycomics and School of Information and Communication Technology, Griffith University, Southport, 4222, QLD, Australia","Motivation: The accuracy of predicting protein local and global structural properties such as secondary structure and solvent accessible surface area has been stagnant for many years because of the challenge of accounting for non-local interactions between amino acid residues that are close in three-dimensional structural space but far from each other in their sequence positions. All existing machine-learning techniques relied on a sliding window of 10-20 amino acid residues to capture some short to intermediate non-local interactions. Here, we employed Long Short-Term Memory (LSTM) Bidirectional Recurrent Neural Networks (BRNNs) which are capable of capturing long range interactions without using a window. Results: We showed that the application of LSTM-BRNN to the prediction of protein structural properties makes the most significant improvement for residues with the most long-range contacts (ji-jj>19) over a previous window-based, deep-learning method SPIDER2. Capturing long-range interactions allows the accuracy of three-state secondary structure prediction to reach 84% and the correlation coefficient between predicted and actual solvent accessible surface areas to reach 0.80, plus a reduction of 5%, 10%, 5% and 10% in the mean absolute error for backbone /, w, h and s angles, respectively, from SPIDER2. More significantly, 27% of 182724 40-residue models directly constructed from predicted Ca atom-based h and s have similar structures to their corresponding native structures (6A° RMSD or less), which is 3% better than models built by / and w angles. We expect the method to be useful for assisting protein structure and function prediction. © 2017 The Author.","","Computational Biology; Machine Learning; Models, Molecular; Neural Networks (Computer); Protein Structure, Secondary; Proteins; Solvents; protein; solvent; artificial neural network; biology; chemistry; machine learning; molecular model; procedures; protein secondary structure","Oxford University Press","13674803","","BOINF","28430949","Article","Scopus","2-s2.0-85026373829"
"Lenselink E.B.; Ten Dijke N.; Bongers B.; Papadatos G.; Van Vlijmen H.W.T.; Kowalczyk W.; Ijzerman A.P.; Van Westen G.J.P.","Lenselink, Eelke B. (55968062600); Ten Dijke, Niels (57195353528); Bongers, Brandon (57217663910); Papadatos, George (7801435004); Van Vlijmen, Herman W. T. (6603020559); Kowalczyk, Wojtek (55760640500); Ijzerman, Adriaan P. (35478030800); Van Westen, Gerard J. P. (35770054200)","55968062600; 57195353528; 57217663910; 7801435004; 6603020559; 55760640500; 35478030800; 35770054200","Beyond the hype: deep neural networks outperform established methods using a ChEMBL bioactivity benchmark set","2017","Journal of Cheminformatics","211","10.1186/s13321-017-0232-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027404377&doi=10.1186%2fs13321-017-0232-0&partnerID=40&md5=59067588ca413f8f0010d8d40f0b012b","Division of Medicinal Chemistry, Drug Discovery and Safety, Leiden Academic Centre for Drug Research, Leiden University, P.O. Box 9502, Leiden, 2300 RA, Netherlands; Leiden Institute of Advanced Computer Science, Leiden University, P.O. Box 9512, Leiden, 2300 RA, Netherlands; European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Genome Campus, Hinxton, Cambridge, United Kingdom; GlaxoSmithKline, Medicines Research Centre, Gunnels Wood Road, Stevenage, Herts, SG1 2NY, United Kingdom","Lenselink E.B., Division of Medicinal Chemistry, Drug Discovery and Safety, Leiden Academic Centre for Drug Research, Leiden University, P.O. Box 9502, Leiden, 2300 RA, Netherlands; Ten Dijke N., Leiden Institute of Advanced Computer Science, Leiden University, P.O. Box 9512, Leiden, 2300 RA, Netherlands; Bongers B., Division of Medicinal Chemistry, Drug Discovery and Safety, Leiden Academic Centre for Drug Research, Leiden University, P.O. Box 9502, Leiden, 2300 RA, Netherlands; Papadatos G., European Molecular Biology Laboratory, European Bioinformatics Institute (EMBL-EBI), Wellcome Genome Campus, Hinxton, Cambridge, United Kingdom, GlaxoSmithKline, Medicines Research Centre, Gunnels Wood Road, Stevenage, Herts, SG1 2NY, United Kingdom; Van Vlijmen H.W.T., Division of Medicinal Chemistry, Drug Discovery and Safety, Leiden Academic Centre for Drug Research, Leiden University, P.O. Box 9502, Leiden, 2300 RA, Netherlands; Kowalczyk W., Leiden Institute of Advanced Computer Science, Leiden University, P.O. Box 9512, Leiden, 2300 RA, Netherlands; Ijzerman A.P., Division of Medicinal Chemistry, Drug Discovery and Safety, Leiden Academic Centre for Drug Research, Leiden University, P.O. Box 9502, Leiden, 2300 RA, Netherlands; Van Westen G.J.P., Division of Medicinal Chemistry, Drug Discovery and Safety, Leiden Academic Centre for Drug Research, Leiden University, P.O. Box 9502, Leiden, 2300 RA, Netherlands","The increase of publicly available bioactivity data in recent years has fueled and catalyzed research in chemogenomics, data mining, and modeling approaches. As a direct result, over the past few years a multitude of different methods have been reported and evaluated, such as target fishing, nearest neighbor similarity-based methods, and Quantitative Structure Activity Relationship (QSAR)-based protocols. However, such studies are typically conducted on different datasets, using different validation strategies, and different metrics. In this study, different methods were compared using one single standardized dataset obtained from ChEMBL, which is made available to the public, using standardized metrics (BEDROC and Matthews Correlation Coefficient). Specifically, the performance of Naïve Bayes, Random Forests, Support Vector Machines, Logistic Regression, and Deep Neural Networks was assessed using QSAR and proteochemometric (PCM) methods. All methods were validated using both a random split validation and a temporal validation, with the latter being a more realistic benchmark of expected prospective execution. Deep Neural Networks are the top performing classifiers, highlighting the added value of Deep Neural Networks over other more conventional methods. Moreover, the best method ('DNN-PCM') performed significantly better at almost one standard deviation higher than the mean performance. Furthermore, Multi-task and PCM implementations were shown to improve performance over single task Deep Neural Networks. Conversely, target prediction performed almost two standard deviations under the mean performance. Random Forests, Support Vector Machines, and Logistic Regression performed around mean performance. Finally, using an ensemble of DNNs, alongside additional tuning, enhanced the relative performance by another 27% (compared with unoptimized 'DNN-PCM'). Here, a standardized set to test and evaluate different machine learning algorithms in the context of multi-task learning is offered by providing the data and the protocols.[Figure not available: see fulltext.] © 2017 The Author(s).","ChEMBL; Cheminformatics; Chemogenomics; Deep neural networks; Proteochemometrics; QSAR","","BioMed Central Ltd.","17582946","","","","Article","Scopus","2-s2.0-85027404377"
"Nguyen D.T.; Yoon H.S.; Pham T.D.; Park K.R.","Nguyen, Dat Tien (35608738000); Yoon, Hyo Sik (57191035819); Pham, Tuyen Danh (55808639500); Park, Kang Ryoung (8983316300)","35608738000; 57191035819; 55808639500; 8983316300","Spoof detection for finger-vein recognition system using NIR camera","2017","Sensors (Switzerland)","33","10.3390/s17102261","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030709290&doi=10.3390%2fs17102261&partnerID=40&md5=871ba31e32c59c56a71bada76f217b02","Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil Jung-gu, Seoul, 100-715, South Korea","Nguyen D.T., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil Jung-gu, Seoul, 100-715, South Korea; Yoon H.S., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil Jung-gu, Seoul, 100-715, South Korea; Pham T.D., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil Jung-gu, Seoul, 100-715, South Korea; Park K.R., Division of Electronics and Electrical Engineering, Dongguk University, 30 Pildong-ro 1-gil Jung-gu, Seoul, 100-715, South Korea","Finger-vein recognition, a new and advanced biometrics recognition method, is attracting the attention of researchers because of its advantages such as high recognition performance and lesser likelihood of theft and inaccuracies occurring on account of skin condition defects. However, as reported by previous researchers, it is possible to attack a finger-vein recognition system by using presentation attack (fake) finger-vein images. As a result, spoof detection, named as presentation attack detection (PAD), is necessary in such recognition systems. Previous attempts to establish PAD methods primarily focused on designing feature extractors by hand (handcrafted feature extractor) based on the observations of the researchers about the difference between real (live) and presentation attack finger-vein images. Therefore, the detection performance was limited. Recently, the deep learning framework has been successfully applied in computer vision and delivered superior results compared to traditional handcrafted methods on various computer vision applications such as image-based face recognition, gender recognition and image classification. In this paper, we propose a PAD method for near-infrared (NIR) camera-based finger-vein recognition system using convolutional neural network (CNN) to enhance the detection ability of previous handcrafted methods. Using the CNN method, we can derive a more suitable feature extractor for PAD than the other handcrafted methods using a training procedure. We further process the extracted image features to enhance the presentation attack finger-vein image detection ability of the CNN method using principal component analysis method (PCA) for dimensionality reduction of feature space and support vector machine (SVM) for classification. Through extensive experimental results, we confirm that our proposed method is adequate for presentation attack finger-vein image detection and it can deliver superior detection results compared to CNN-based methods and other previous handcrafted methods. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural network; NIR camera-based finger-vein recognition; Presentation attack detection; Spoof detection; Transfer learning","Fingers; Humans; Neural Networks (Computer); Support Vector Machine; Veins; Cameras; Computer vision; Convolution; Face recognition; Image enhancement; Image processing; Infrared devices; Neural networks; Optical character recognition; Principal component analysis; Support vector machines; Vector spaces; Attack detection; Convolutional neural network; Finger-vein recognition; Spoof detection; Transfer learning; artificial neural network; finger; human; support vector machine; vascularization; vein; Palmprint recognition","MDPI AG","14248220","","","28974031","Article","Scopus","2-s2.0-85030709290"
"Ostmeyer J.; Christley S.; Rounds W.H.; Toby I.; Greenberg B.M.; Monson N.L.; Cowell L.G.","Ostmeyer, Jared (51665520200); Christley, Scott (8838692800); Rounds, William H. (55648948500); Toby, Inimary (35772892200); Greenberg, Benjamin M. (8862389300); Monson, Nancy L. (6603878788); Cowell, Lindsay G. (7004190232)","51665520200; 8838692800; 55648948500; 35772892200; 8862389300; 6603878788; 7004190232","Statistical classifiers for diagnosing disease from immune repertoires: A case study using multiple sclerosis","2017","BMC Bioinformatics","47","10.1186/s12859-017-1814-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028950537&doi=10.1186%2fs12859-017-1814-6&partnerID=40&md5=6168e521c701979f675cec931a18f0af","UT Southwestern Medical Center, Department of Clinical Sciences, 5323 Harry Hines Boulevard, Dallas, 75390-9066, TX, United States; UT Southwestern Medical Center, Department of Neurology and Neurotherapeutics, 5323 Harry Hines Boulevard, Dallas, 75390-9036, TX, United States","Ostmeyer J., UT Southwestern Medical Center, Department of Clinical Sciences, 5323 Harry Hines Boulevard, Dallas, 75390-9066, TX, United States; Christley S., UT Southwestern Medical Center, Department of Clinical Sciences, 5323 Harry Hines Boulevard, Dallas, 75390-9066, TX, United States; Rounds W.H., UT Southwestern Medical Center, Department of Clinical Sciences, 5323 Harry Hines Boulevard, Dallas, 75390-9066, TX, United States; Toby I., UT Southwestern Medical Center, Department of Clinical Sciences, 5323 Harry Hines Boulevard, Dallas, 75390-9066, TX, United States; Greenberg B.M., UT Southwestern Medical Center, Department of Neurology and Neurotherapeutics, 5323 Harry Hines Boulevard, Dallas, 75390-9036, TX, United States; Monson N.L., UT Southwestern Medical Center, Department of Neurology and Neurotherapeutics, 5323 Harry Hines Boulevard, Dallas, 75390-9036, TX, United States; Cowell L.G., UT Southwestern Medical Center, Department of Clinical Sciences, 5323 Harry Hines Boulevard, Dallas, 75390-9066, TX, United States","Background: Deep sequencing of lymphocyte receptor repertoires has made it possible to comprehensively profile the clonal composition of lymphocyte populations. This opens the door for novel approaches to diagnose and prognosticate diseases with a driving immune component by identifying repertoire sequence patterns associated with clinical phenotypes. Indeed, recent studies support the feasibility of this, demonstrating an association between repertoire-level summary statistics (e.g., diversity) and patient outcomes for several diseases. In our own prior work, we have shown that six codons in VH4-containing genes in B cells from the cerebrospinal fluid of patients with relapsing remitting multiple sclerosis (RRMS) have higher replacement mutation frequencies than observed in healthy controls or patients with other neurological diseases. However, prior methods to date have been limited to focusing on repertoire-level summary statistics, ignoring the vast amounts of information in the millions of individual immune receptors comprising a repertoire. We have developed a novel method that addresses this limitation by using innovative approaches for accommodating the extraordinary sequence diversity of immune receptors and widely used machine learning approaches. We applied our method to RRMS, an autoimmune disease that is notoriously difficult to diagnose. Results: We use the biochemical features encoded by the complementarity determining region 3 of each B cell receptor heavy chain in every patient repertoire as input to a detector function, which is fit to give the correct diagnosis for each patient using maximum likelihood optimization methods. The resulting statistical classifier assigns patients to one of two diagnosis categories, RRMS or other neurological disease, with 87% accuracy by leave-one-out cross-validation on training data (N=23) and 72% accuracy on unused data from a separate study (N=102). Conclusions: Our method is the first to apply statistical learning to immune repertoires to aid disease diagnosis, learning repertoire-level labels from the set of individual immune repertoire sequences. This method produced a repertoire-based statistical classifier for diagnosing RRMS that provides a high degree of diagnostic capability, rivaling the accuracy of diagnosis by a clinical expert. Additionally, this method points to a diagnostic biochemical motif in the antibodies of RRMS patients, which may offer insight into the disease process. © 2017 The Author(s).","Antibody; CDR3; Immune repertoire; Machine learning; Multiple sclerosis; Statistical classifier","Amino Acid Sequence; Area Under Curve; B-Lymphocytes; Complementarity Determining Regions; High-Throughput Nucleotide Sequencing; Humans; Models, Statistical; Multiple Sclerosis, Relapsing-Remitting; Nervous System Diseases; ROC Curve; Antibodies; Artificial intelligence; Cell membranes; Cerebrospinal fluid; Classification (of information); Diagnosis; Diagnostic radiography; Learning systems; Lymphocytes; Maximum likelihood; Neurology; Statistical methods; Statistics; CDR3; Complementarity-determining region 3; Immune repertoire; Leave-one-out cross validations; Machine learning approaches; Multiple sclerosis; Relapsing-remitting multiple sclerosis; Statistical classifier; amino acid sequence; area under the curve; B lymphocyte; chemistry; classification; complementarity determining region; high throughput sequencing; human; immunology; metabolism; multiple sclerosis; neurologic disease; receiver operating characteristic; statistical model; Computer aided diagnosis","BioMed Central Ltd.","14712105","","BBMIC","28882107","Article","Scopus","2-s2.0-85028950537"
"Finnegan A.; Song J.S.","Finnegan, Alex (57196357920); Song, Jun S. (7404786746)","57196357920; 7404786746","Maximum entropy methods for extracting the learned features of deep neural networks","2017","PLoS Computational Biology","28","10.1371/journal.pcbi.1005836","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032731576&doi=10.1371%2fjournal.pcbi.1005836&partnerID=40&md5=9943256b5dbb910eaa0e642313da80b2","Department of Physics, University of Illinois, Urbana-Champaign, Urbana, IL, United States; Carl R. Woese Institute for Genomic Biology, University of Illinois, Urbana-Champaign, Urbana, IL, United States","Finnegan A., Department of Physics, University of Illinois, Urbana-Champaign, Urbana, IL, United States, Carl R. Woese Institute for Genomic Biology, University of Illinois, Urbana-Champaign, Urbana, IL, United States; Song J.S., Department of Physics, University of Illinois, Urbana-Champaign, Urbana, IL, United States, Carl R. Woese Institute for Genomic Biology, University of Illinois, Urbana-Champaign, Urbana, IL, United States","New architectures of multilayer artificial neural networks and new methods for training them are rapidly revolutionizing the application of machine learning in diverse fields, including business, social science, physical sciences, and biology. Interpreting deep neural networks, however, currently remains elusive, and a critical challenge lies in understanding which meaningful features a network is actually learning. We present a general method for interpreting deep neural networks and extracting network-learned features from input data. We describe our algorithm in the context of biological sequence analysis. Our approach, based on ideas from statistical physics, samples from the maximum entropy distribution over possible sequences, anchored at an input sequence and subject to constraints implied by the empirical function learned by a network. Using our framework, we demonstrate that local transcription factor binding motifs can be identified from a network trained on ChIP-seq data and that nucleosome positioning signals are indeed learned by a network trained on chemical cleavage nucleosome maps. Imposing a further constraint on the maximum entropy distribution also allows us to probe whether a network is learning global sequence features, such as the high GC content in nucleosome-rich regions. This work thus provides valuable mathematical tools for interpreting and extracting learned features from feed-forward neural networks. © 2017 Finnegan, Song.","","Algorithms; Computer Simulation; Entropy; Machine Learning; Models, Statistical; Neural Networks (Computer); Pattern Recognition, Automated; Sequence Analysis, DNA; Bioinformatics; Maximum entropy methods; Multilayer neural networks; Statistical Physics; transcription factor; Critical challenges; Diverse fields; General method; Input datas; Machine-learning; Maximum entropy distribution; Maximum-entropy methods; Multilayer artificial neural networks; Nucleosomes; Physical science; Article; artificial neural network; cell division; chromatin immunoprecipitation; conceptual framework; data analysis; DNA binding; entropy; extraction; human; human cell; learning algorithm; Markov chain; mathematical analysis; Monte Carlo method; nucleosome; nucleotide motif; sequence analysis; signal transduction; algorithm; automated pattern recognition; computer simulation; DNA sequence; entropy; machine learning; procedures; statistical model; Deep neural networks","Public Library of Science","1553734X","","","29084280","Article","Scopus","2-s2.0-85032731576"
"Li K.; Wu Y.; Nan Y.; Li P.; Li Y.","Li, Ke (56517259300); Wu, Yalei (57031013200); Nan, Yu (57193380955); Li, Pengfei (57193384478); Li, Yang (56075073900)","56517259300; 57031013200; 57193380955; 57193384478; 56075073900","Hierarchical multi-class classification in multimodal spacecraft data using DNN and weighted support vector machine","2017","Neurocomputing","31","10.1016/j.neucom.2016.08.131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013477443&doi=10.1016%2fj.neucom.2016.08.131&partnerID=40&md5=b902b55807537310df8d658229ead99c","Fundamental Science on Ergonomics and Environment Control Laboratory, School of Aeronautic Science and Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China","Li K., Fundamental Science on Ergonomics and Environment Control Laboratory, School of Aeronautic Science and Engineering, Beihang University, Beijing, China; Wu Y., Fundamental Science on Ergonomics and Environment Control Laboratory, School of Aeronautic Science and Engineering, Beihang University, Beijing, China; Nan Y., Fundamental Science on Ergonomics and Environment Control Laboratory, School of Aeronautic Science and Engineering, Beihang University, Beijing, China; Li P., Fundamental Science on Ergonomics and Environment Control Laboratory, School of Aeronautic Science and Engineering, Beihang University, Beijing, China; Li Y., School of Automation Science and Electrical Engineering, Beihang University, Beijing, China","Prognostics and health management (PHM) is widely applied to assess the reliability, safety and operation of systems particularly in spacecraft systems. However, spacecraft systems are very complex with intangibility and uncertainty, and it is difficult to model and analyze the complex degradation process, and thus there is no single prognostic method for solving the critical and complicated problem. This paper presents a novel hierarchical multi-class classification method using deep neural networks (DNN) and weighted support vector machine (WSVM) in order to achieve a highly discriminative feature representation for classifying the multimodal spacecraft data. First, the stack auto-Encoder (SAE) or deep belief network is adopted to initialize the initial weights and offsets of the hierarchical multi-layer neural network in order to reduce the dimension of the original multimodal data, and the optimal depth of multi-layer neural network and the discriminative features are also obtained. Second, in order to make the high dimensional spacecraft data more separable, the initialization parameters are online monitored by using a gradient descent method. Finally, a flexible hierarchical estimation method of a multi-class weighted support vector machines (MCWSVM) is applied to classify the multimodal spacecraft data. The performance of the proposed work is evaluated by the classification accuracy, sensitivity, specificity and execution time, respectively. The results demonstrate that the proposed DNN with MCWSVM is efficient in terms of better classification accuracy at a lesser execution time when compared to K-nearest neighbors (KNN), SVM and naive Bayes method (NBM). © 2017 Elsevier B.V.","Deep belief network; Deep neural network (DNN); Multi-modal spacecraft data; Prognostics and health management (PHM); Weighted support vector machine (WSVM)","Classification (of information); Classifiers; Complex networks; Deep neural networks; Gradient methods; Information management; Learning systems; Nearest neighbor search; Network layers; Spacecraft; Support vector machines; Uncertainty analysis; Vectors; Classification accuracy; Deep belief networks; Hierarchical estimation; K nearest neighbor (KNN); Multi-class classification; Prognostics and health managements; Spacecraft data; Weighted support vector machine; Article; Bayesian learning; computer network; controlled study; data processing; deep belief network; default mode network; k nearest neighbor; measurement accuracy; multimodal spacecraft data; priority journal; sensitivity and specificity; stack auto encoder; support vector machine; weighted support vector machine; Multilayer neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85013477443"
"Do B.H.; Langlotz C.; Beaulieu C.F.","Do, Bao H. (36906824500); Langlotz, Curtis (20134955200); Beaulieu, Christopher F. (57204084528)","36906824500; 20134955200; 57204084528","Bone Tumor Diagnosis Using a Naïve Bayesian Model of Demographic and Radiographic Features","2017","Journal of Digital Imaging","51","10.1007/s10278-017-0001-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026921111&doi=10.1007%2fs10278-017-0001-7&partnerID=40&md5=c5973153919de1753b46d5adfddf62cf","Department of Radiology, VA Palo Alto Health Care System, 3801 Miranda Avenue, Palo Alto, 94304, CA, United States; Department of Radiology, Stanford University, 300 Pasteur Drive, Stanford, 94305, CA, United States","Do B.H., Department of Radiology, VA Palo Alto Health Care System, 3801 Miranda Avenue, Palo Alto, 94304, CA, United States; Langlotz C., Department of Radiology, Stanford University, 300 Pasteur Drive, Stanford, 94305, CA, United States; Beaulieu C.F., Department of Radiology, Stanford University, 300 Pasteur Drive, Stanford, 94305, CA, United States","Because many bone tumors have a variety of appearances and are uncommon, few radiologists develop sufficient expertise to guide optimal management. Bayesian inference can guide decision-making by computing probabilities of multiple diagnoses to generate a differential. We built and validated a naïve Bayes machine (NBM) that processes 18 demographic and radiographic features. We reviewed over 1664 analog radiographic cases of bone tumors and selected 811 cases (66 diagnoses) for annotation using a quantitative imaging platform. Leave-one-out cross validation was performed. Primary accuracy was defined as the correct pathological diagnosis as the top machine prediction. Differential accuracy was defined as whether the correct pathological diagnosis was within the top three predictions. For the 29 most common diagnoses (710 cases), primary accuracy was 44%, and differential accuracy was 60%. For the top 10 most common diagnoses (478 cases), primary accuracy was 62%, and differential accuracy was 80%. The machine returned relevant diagnoses for the majority of unknown test cases and may be a feasible alternative to machine learning approaches such as deep neural networks or support vector machines that typically require larger training data (our model required a minimum of five samples per diagnosis) and are “black boxes” (our model can provide details of probability calculations to identify features that most significantly contribute to truth diagnoses). Finally, our Bayes model was designed to scale and “learn” from external data, enabling incorporation of outside knowledge such as Dahlin’s Bone Tumors, a reference of anatomic and demographic statistics of more than 10,000 tumors. © 2017, Society for Imaging Informatics in Medicine.","Bone tumor diagnosis; Naïve Bayes model","Bayes Theorem; Bone Neoplasms; Demography; Diagnosis, Differential; Humans; Image Processing, Computer-Assisted; Radiography; Reproducibility of Results; Bayesian networks; Bone; Decision making; Deep neural networks; Inference engines; Learning systems; Population statistics; Probability; Sodium; Statistical methods; Tumors; Bayes models; Bayesian inference; Bone tumor; Feasible alternatives; Leave-one-out cross validations; Machine learning approaches; Probability calculations; Quantitative imaging; Bayes theorem; bone tumor; demography; diagnostic imaging; differential diagnosis; human; image processing; procedures; radiography; reproducibility; Diagnosis","Springer New York LLC","08971889","","JDIME","28752323","Article","Scopus","2-s2.0-85026921111"
"Han S.; Kang H.-K.; Jeong J.-Y.; Park M.-H.; Kim W.; Bang W.-C.; Seong Y.-K.","Han, Seokmin (55665814100); Kang, Ho-Kyung (57195836670); Jeong, Ja-Yeon (57188955981); Park, Moon-Ho (55516078300); Kim, Wonsik (57199880916); Bang, Won-Chul (7004161564); Seong, Yeong-Kyeong (7006759179)","55665814100; 57195836670; 57188955981; 55516078300; 57199880916; 7004161564; 7006759179","A deep learning framework for supporting the classification of breast lesions in ultrasound images","2017","Physics in Medicine and Biology","282","10.1088/1361-6560/aa82ec","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029902761&doi=10.1088%2f1361-6560%2faa82ec&partnerID=40&md5=1ab402a01033dc2a4c1d12eec06a9309","Korea National University of Transportation, Uiwang-si, Kyunggi-do, South Korea; Samsung Electronics, Suwon-si, Kyunggi-do, South Korea","Han S., Korea National University of Transportation, Uiwang-si, Kyunggi-do, South Korea; Kang H.-K., Samsung Electronics, Suwon-si, Kyunggi-do, South Korea; Jeong J.-Y., Samsung Electronics, Suwon-si, Kyunggi-do, South Korea; Park M.-H., Samsung Electronics, Suwon-si, Kyunggi-do, South Korea; Kim W., Samsung Electronics, Suwon-si, Kyunggi-do, South Korea; Bang W.-C., Samsung Electronics, Suwon-si, Kyunggi-do, South Korea; Seong Y.-K., Samsung Electronics, Suwon-si, Kyunggi-do, South Korea","In this research, we exploited the deep learning framework to differentiate the distinctive types of lesions and nodules in breast acquired with ultrasound imaging. A biopsy-proven benchmarking dataset was built from 5151 patients cases containing a total of 7408 ultrasound breast images, representative of semi-automatically segmented lesions associated with masses. The dataset comprised 4254 benign and 3154 malignant lesions. The developed method includes histogram equalization, image cropping and margin augmentation. The GoogLeNet convolutionary neural network was trained to the database to differentiate benign and malignant tumors. The networks were trained on the data with augmentation and the data without augmentation. Both of them showed an area under the curve of over 0.9. The networks showed an accuracy of about 0.9 (90%), a sensitivity of 0.86 and a specificity of 0.96. Although target regions of interest (ROIs) were selected by radiologists, meaning that radiologists still have to point out the location of the ROI, the classification of malignant lesions showed promising results. If this method is used by radiologists in clinical situations it can classify malignant lesions in a short time and support the diagnosis of radiologists in discriminating malignant lesions. Therefore, the proposed method can work in tandem with human radiologists to improve performance, which is a fundamental purpose of computer-aided diagnosis. © 2017 Institute of Physics and Engineering in Medicine.","breast cancer; CADx; classification; deep learning","Breast Neoplasms; Diagnosis, Computer-Assisted; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Middle Aged; Neural Networks (Computer); ROC Curve; Ultrasonography, Mammary; Classification (of information); Computer aided diagnosis; Deep learning; Diagnosis; Image classification; Ultrasonic imaging; Area under the curves; Benign and malignant tumors; Breast Cancer; CADx; Clinical situations; Histogram equalizations; Improve performance; Learning frameworks; artificial neural network; breast tumor; classification; computer assisted diagnosis; diagnostic imaging; echomammography; female; human; machine learning; middle aged; pathology; procedures; receiver operating characteristic; Medical imaging","Institute of Physics Publishing","00319155","","PHMBA","28753132","Article","Scopus","2-s2.0-85029902761"
"Buckley S.","Buckley, Steve (7101614164)","7101614164","Combining broadband spectra and machine learning to derive material properties","2017","Spectroscopy (Santa Monica)","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032297347&partnerID=40&md5=823be4e59c1c589f5832a992405527c4","Flash Photonics, Inc., University of Washington, United States","Buckley S., Flash Photonics, Inc., University of Washington, United States","A quiet but interesting trend has been occurring in material analysis, coincident with the rise of artificial intelligence (AI) and so-called ""deep"" machine learning methods. Astute spectroscopists have always known that there is more information in the spectra that they obtain than simply the molecular or atomic peaks that are directly measured. Particularly with methods such as infrared, Raman, and laser-induced breakdown spectroscopy (LIBS), the spectral background contains a wealth of information about the sample, and analytical combinations of the peaks can provide material properties. Traditionally, such analytical combinations of peaks were performed explicitly by analysts, but now information about material properties embedded in the spectra can be derived implicitly by AI and machine learning algorithms. This column introduces these ideas and touches on recent results indicative of what more may be coming in this direction.","","Artificial intelligence; Atomic emission spectroscopy; Laser induced breakdown spectroscopy; Learning systems; Broadband spectra; Laserinduced breakdown spectroscopy (LIBS); Machine learning methods; Material analysis; Wealth of information; Learning algorithms","Advanstar Communications Inc.","08876703","","SPECE","","Article","Scopus","2-s2.0-85032297347"
"Zhang J.; Song Y.; Xia F.; Zhu C.; Zhang Y.; Song W.; Xu J.; Ma X.","Zhang, Jing (55653519700); Song, Yanlin (56488778800); Xia, Fan (57203965948); Zhu, Chenjing (57171241300); Zhang, Yingying (57195552940); Song, Wenpeng (57216656969); Xu, Jianguo (56978345500); Ma, Xuelei (55523405000)","55653519700; 56488778800; 57203965948; 57171241300; 57195552940; 57216656969; 56978345500; 55523405000","Rapid and accurate intraoperative pathological diagnosis by artificial intelligence with deep learning technology","2017","Medical Hypotheses","16","10.1016/j.mehy.2017.08.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028735131&doi=10.1016%2fj.mehy.2017.08.021&partnerID=40&md5=02be4440a6bf9f3304150a6c96b63ffb","State Key Laboratory of Biotherapy and Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, China; Department of Neurosurgery, West China Hospital, Sichuan University, Chengdu, 610041, China","Zhang J., State Key Laboratory of Biotherapy and Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, China, Department of Neurosurgery, West China Hospital, Sichuan University, Chengdu, 610041, China; Song Y., State Key Laboratory of Biotherapy and Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, China; Xia F., State Key Laboratory of Biotherapy and Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, China; Zhu C., State Key Laboratory of Biotherapy and Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, China; Zhang Y., State Key Laboratory of Biotherapy and Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, China; Song W., State Key Laboratory of Biotherapy and Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, China; Xu J., Department of Neurosurgery, West China Hospital, Sichuan University, Chengdu, 610041, China; Ma X., State Key Laboratory of Biotherapy and Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, China","Frozen section is widely used for intraoperative pathological diagnosis (IOPD), which is essential for intraoperative decision making. However, frozen section suffers from some drawbacks, such as time consuming and high misdiagnosis rate. Recently, artificial intelligence (AI) with deep learning technology has shown bright future in medicine. We hypothesize that AI with deep learning technology could help IOPD, with a computer trained by a dataset of intraoperative lesion images. Evidences supporting our hypothesis included the successful use of AI with deep learning technology in diagnosing skin cancer, and the developed method of deep-learning algorithm. Large size of the training dataset is critical to increase the diagnostic accuracy. The performance of the trained machine could be tested by new images before clinical use. Real-time diagnosis, easy to use and potential high accuracy were the advantages of AI for IOPD. In sum, AI with deep learning technology is a promising method to help rapid and accurate IOPD. © 2017 Elsevier Ltd","Artificial intelligence; Deep learning; Frozen section; Intraoperative pathological diagnosis","Artificial Intelligence; Decision Making, Computer-Assisted; Diagnosis, Computer-Assisted; Diagnostic Errors; Frozen Sections; Humans; Intraoperative Period; Machine Learning; Models, Theoretical; Skin Neoplasms; Article; artificial intelligence; cancer diagnosis; diagnostic accuracy; diagnostic imaging; diagnostic test; diagnostic value; histopathology; intraoperative period; learning algorithm; medical technology; skin defect; skin disease; computer assisted diagnosis; decision support system; diagnostic error; frozen section; human; intraoperative period; machine learning; prevention and control; procedures; skin tumor; theoretical model","Churchill Livingstone","03069877","","MEHYD","28915974","Article","Scopus","2-s2.0-85028735131"
"Cockrell C.; An G.","Cockrell, Chase (55668829200); An, Gary (7102580539)","55668829200; 7102580539","Sepsis reconsidered: Identifying novel metrics for behavioral landscape characterization with a high-performance computing implementation of an agent-based model","2017","Journal of Theoretical Biology","24","10.1016/j.jtbi.2017.07.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027722597&doi=10.1016%2fj.jtbi.2017.07.016&partnerID=40&md5=49267b0e662cee755e1695a5c8357d7e","Department of Surgery, University of Chicago Medicine, 5841 South Maryland Ave, MC 5094, Chicago, 60637, IL, United States","Cockrell C., Department of Surgery, University of Chicago Medicine, 5841 South Maryland Ave, MC 5094, Chicago, 60637, IL, United States; An G., Department of Surgery, University of Chicago Medicine, 5841 South Maryland Ave, MC 5094, Chicago, 60637, IL, United States","Objectives Sepsis affects nearly 1 million people in the United States per year, has a mortality rate of 28–50% and requires more than $20 billion a year in hospital costs. Over a quarter century of research has not yielded a single reliable diagnostic test or a directed therapeutic agent for sepsis. Central to this insufficiency is the fact that sepsis remains a clinical/physiological diagnosis representing a multitude of molecularly heterogeneous pathological trajectories. Advances in computational capabilities offered by High Performance Computing (HPC) platforms call for an evolution in the investigation of sepsis to attempt to define the boundaries of traditional research (bench, clinical and computational) through the use of computational proxy models. We present a novel investigatory and analytical approach, derived from how HPC resources and simulation are used in the physical sciences, to identify the epistemic boundary conditions of the study of clinical sepsis via the use of a proxy agent-based model of systemic inflammation. Design Current predictive models for sepsis use correlative methods that are limited by patient heterogeneity and data sparseness. We address this issue by using an HPC version of a system-level validated agent-based model of sepsis, the Innate Immune Response ABM (IIRBM), as a proxy system in order to identify boundary conditions for the possible behavioral space for sepsis. We then apply advanced analysis derived from the study of Random Dynamical Systems (RDS) to identify novel means for characterizing system behavior and providing insight into the tractability of traditional investigatory methods. Results The behavior space of the IIRABM was examined by simulating over 70 million sepsis patients for up to 90 days in a sweep across the following parameters: cardio-respiratory-metabolic resilience; microbial invasiveness; microbial toxigenesis; and degree of nosocomial exposure. In addition to using established methods for describing parameter space, we developed two novel methods for characterizing the behavior of a RDS: Probabilistic Basins of Attraction (PBoA) and Stochastic Trajectory Analysis (STA). Computationally generated behavioral landscapes demonstrated attractor structures around stochastic regions of behavior that could be described in a complementary fashion through use of PBoA and STA. The stochasticity of the boundaries of the attractors highlights the challenge for correlative attempts to characterize and classify clinical sepsis. Conclusions HPC simulations of models like the IIRABM can be used to generate approximations of the behavior space of sepsis to both establish “boundaries of futility” with respect to existing investigatory approaches and apply system engineering principles to investigate the general dynamic properties of sepsis to provide a pathway for developing control strategies. The issues that bedevil the study and treatment of sepsis, namely clinical data sparseness and inadequate experimental sampling of system behavior space, are fundamental to nearly all biomedical research, manifesting in the “Crisis of Reproducibility” at all levels. HPC-augmented simulation-based research offers an investigatory strategy more consistent with that seen in the physical sciences (which combine experiment, theory and simulation), and an opportunity to utilize the leading advances in HPC, namely deep machine learning and evolutionary computing, to form the basis of an iterative scientific process to meet the full promise of Precision Medicine (right drug, right patient, right time). © 2017","Attractors; Cytokines; Parameter space; Personalized medicine; Precision medicine; Random dynamical systems; Stochastic dynamical systems","Computational Biology; Computer Simulation; Humans; Machine Learning; Precision Medicine; Sepsis; Systems Analysis; United States; antibiotic agent; landscape; modeling; pathology; stochasticity; analytic method; Article; cardiovascular parameters; high performance computing; hospital infection; human; inflammation; innate immune response agent based model; machine learning; mathematical computing; metabolic parameters; nonhuman; priority journal; probabilistic basins of attraction; process model; random dynamical system; sepsis; statistical analysis; stochastic trajectory analysis; theoretical model; validation study; biology; computer simulation; personalized medicine; procedures; sepsis; system analysis; trends","Academic Press","00225193","","JTBIA","28728997","Article","Scopus","2-s2.0-85027722597"
"Poria S.; Peng H.; Hussain A.; Howard N.; Cambria E.","Poria, Soujanya (55316592700); Peng, Haiyun (57193317246); Hussain, Amir (19734290900); Howard, Newton (55326572900); Cambria, Erik (56140547500)","55316592700; 57193317246; 19734290900; 55326572900; 56140547500","Ensemble application of convolutional neural networks and multiple kernel learning for multimodal sentiment analysis","2017","Neurocomputing","166","10.1016/j.neucom.2016.09.117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012926540&doi=10.1016%2fj.neucom.2016.09.117&partnerID=40&md5=5695bf1810a54ea540c1497a1383a1de","Department of Computing Science and Mathematics, University of Stirling, United Kingdom; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Computational Neuroscience and Functional Neurosurgery, University of Oxford, United Kingdom","Poria S., Department of Computing Science and Mathematics, University of Stirling, United Kingdom; Peng H., School of Computer Science and Engineering, Nanyang Technological University, Singapore; Hussain A., Department of Computing Science and Mathematics, University of Stirling, United Kingdom; Howard N., Computational Neuroscience and Functional Neurosurgery, University of Oxford, United Kingdom; Cambria E., School of Computer Science and Engineering, Nanyang Technological University, Singapore","The advent of the Social Web has enabled anyone with an Internet connection to easily create and share their ideas, opinions and content with millions of other people around the world. In pace with a global deluge of videos from billions of computers, smartphones, tablets, university projectors and security cameras, the amount of multimodal content on the Web has been growing exponentially, and with that comes the need for decoding such information into useful knowledge. In this paper, a multimodal affective data analysis framework is proposed to extract user opinion and emotions from video content. In particular, multiple kernel learning is used to combine visual, audio and textual modalities. The proposed framework outperforms the state-of-the-art model in multimodal sentiment analysis research with a margin of 10–13% and 3–5% accuracy on polarity detection and emotion recognition, respectively. The paper also proposes an extensive study on decision-level fusion. © 2017 Elsevier B.V.","Classification; Convolutional neural network; Deep learning; ELM; Emotion; MKL; Multimodal sentiment analysis; Sentiment; SVM","Classification (of information); Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Sentiment analysis; Support vector machines; Decision level fusion; Emotion; Emotion recognition; Ensemble applications; Internet connection; Multi-modal; Multiple Kernel Learning; Sentiment; accuracy; Article; artificial neural network; camera; cognition; computer; data analysis; emotion; human; Internet; kernel method; priority journal; recognition; smartphone; Modal analysis","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85012926540"
"Barros P.; Parisi G.I.; Weber C.; Wermter S.","Barros, Pablo (55734354000); Parisi, German I. (56028608900); Weber, Cornelius (7402376952); Wermter, Stefan (7003826680)","55734354000; 56028608900; 7402376952; 7003826680","Emotion-modulated attention improves expression recognition: A deep learning model","2017","Neurocomputing","65","10.1016/j.neucom.2017.01.096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016057848&doi=10.1016%2fj.neucom.2017.01.096&partnerID=40&md5=82d344f309dba2d8899bc16f6d55a6b7","Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany","Barros P., Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Parisi G.I., Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Weber C., Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Wermter S., Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany","Spatial attention in humans and animals involves the visual pathway and the superior colliculus, which integrate multimodal information. Recent research has shown that affective stimuli play an important role in attentional mechanisms, and behavioral studies show that the focus of attention in a given region of the visual field is increased when affective stimuli are present. This work proposes a neurocomputational model that learns to attend to emotional expressions and to modulate emotion recognition. Our model consists of a deep architecture which implements convolutional neural networks to learn the location of emotional expressions in a cluttered scene. We performed a number of experiments for detecting regions of interest, based on emotion stimuli, and show that the attention model improves emotion expression recognition when used as emotional attention modulator. Finally, we analyze the internal representations of the learned neural filters and discuss their role in the performance of our model. © 2017 The Authors","Convolutional neural networks; Deep learning; Emotion recognition; Emotional attention; Multimodal processing","Convolution; Neural networks; Speech recognition; Vision; Convolutional neural network; Emotion recognition; Emotional attention; Expression recognition; Internal representation; Multi-modal information; Multimodal processing; Neurocomputational models; Article; artificial neural network; automated pattern recognition; body movement; convolutional neural network; emotion; facial expression; image processing; machine learning; multimedia; priority journal; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85016057848"
"Singh H.; Yadav G.; Mallaiah R.; Joshi P.; Joshi V.; Kaur R.; Bansal S.; Brahmachari S.K.","Singh, Harpreet (57195262666); Yadav, Gautam (57195260588); Mallaiah, Raghuram (57195264620); Joshi, Preetha (55755408800); Joshi, Vinay (57214588860); Kaur, Ravneet (58541012300); Bansal, Suneyna (57206513791); Brahmachari, Samir K. (55628577702)","57195262666; 57195260588; 57195264620; 55755408800; 57214588860; 58541012300; 57206513791; 55628577702","iNICU – Integrated Neonatal Care Unit: Capturing Neonatal Journey in an Intelligent Data Way","2017","Journal of Medical Systems","26","10.1007/s10916-017-0774-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026629109&doi=10.1007%2fs10916-017-0774-8&partnerID=40&md5=036e720b7af60d595955fff4922e348b","Academy of Scientific and Innovative Research, New Delhi, India; Oxyent Medical Private Limited, 801 DLF Tower B, New Delhi, 110025, India; Kalawati Hospital, Shiv Chowk, Rewari, Haryana, India; Fortis Le Femme, Greater Kailash -2, New Delhi, India; Kokilaben Dhirubhai Ambani Hospital, Mumbai, India; CSIR-Institute of Genomics and Integrated Biology, Mathura Road, New Delhi, 110020, India","Singh H., Academy of Scientific and Innovative Research, New Delhi, India, Oxyent Medical Private Limited, 801 DLF Tower B, New Delhi, 110025, India; Yadav G., Kalawati Hospital, Shiv Chowk, Rewari, Haryana, India; Mallaiah R., Fortis Le Femme, Greater Kailash -2, New Delhi, India; Joshi P., Kokilaben Dhirubhai Ambani Hospital, Mumbai, India; Joshi V., Kokilaben Dhirubhai Ambani Hospital, Mumbai, India; Kaur R., Oxyent Medical Private Limited, 801 DLF Tower B, New Delhi, 110025, India; Bansal S., Oxyent Medical Private Limited, 801 DLF Tower B, New Delhi, 110025, India; Brahmachari S.K., Academy of Scientific and Innovative Research, New Delhi, India, CSIR-Institute of Genomics and Integrated Biology, Mathura Road, New Delhi, 110020, India","Neonatal period represents first 28 days of life, which is the most vulnerable time for a child’s survival especially for the preterm babies. High neonatal mortality is a prominent and persistent problem across the globe. Non-availability of trained staff and infrastructure are the major recognized hurdles in the quality care of these neonates. Hourly progress growth charts and reports are still maintained manually by nurses along with continuous calculation of drug dosage and nutrition as per the changing weight of the baby. iNICU (integrated Neonatology Intensive Care Unit) leverages Beaglebone and Intel Edison based IoT integration with biomedical devices in NICU i.e. monitor, ventilator and blood gas machine. iNICU is hosted on IBM Softlayer based cloud computing infrastructure and map NICU workflow in Java based responsive web application to provide translational research informatics support to the clinicians. iNICU captures real time vital parameters i.e. respiration rate, heart rate, lab data and PACS amounting for millions of data points per day per child. Stream of data is sent to Apache Kafka layer which stores the same in Apache Cassandra NoSQL. iNICU also captures clinical data like feed intake, urine output, and daily assessment of child in PostgreSQL database. It acts as first Big Data hub (of both structured and unstructured data) of neonates across India offering temporal (longitudinal) data of their stay in NICU and allow clinicians in evaluating efficacy of their interventions. iNICU leverages drools based clinical rule based engine and deep learning based big data analytical model coded in R and PMML. iNICU solution aims to improve care time, fills skill gap, enable remote monitoring of neonates in rural regions, assists in identifying the early onset of disease, and reduction in neonatal mortality. © 2017, The Author(s).","Deep learning; EMR/his; IoT cloud; Neonate health; Neonatology intensive care unit; PACS","Humans; India; Infant, Newborn; Infant, Premature; Intensive Care Units, Neonatal; Rural Population; Workflow; architecture; Article; artificial intelligence; calculator; clinical care time; cloud computing; computer interface; data analysis; data synthesis; deep learning neural network; hospital admission; hospital discharge; hospital management; human; integrated health care system; integrated neonatal care unit; laboratory information system; machine learning; medical care; neonatal calculator; neonatal intensive care unit; neonatal score; neonatologist; newborn; newborn assessment; newborn intensive care; newborn intensive care nursing; nursing care; onset age; statistical analysis; system analysis; time; workflow; India; prematurity; rural population","Springer New York LLC","01485598","","JMSYD","28748430","Article","Scopus","2-s2.0-85026629109"
"Friston K.J.; Lin M.; Frith C.D.; Pezzulo G.; Hobson J.A.; Ondobaka S.","Friston, Karl J. (36080215500); Lin, Marco (57195621720); Frith, Christopher D. (36051252900); Pezzulo, Giovanni (6508225279); Hobson, J.Allan (7102667150); Ondobaka, Sasha (54885292500)","36080215500; 57195621720; 36051252900; 6508225279; 7102667150; 54885292500","Active inference, curiosity and insight","2017","Neural Computation","196","10.1162/NECO_a_00999","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029283962&doi=10.1162%2fNECO_a_00999&partnerID=40&md5=76fb1ee4073674d0d0d7a1a9df95033e","Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, WC1N 3BG, United Kingdom; Institute of Philosophy, School of Advanced Studies, University of London, EC1E 7HU, United Kingdom; Institute of Cognitive Sciences and Technologies, National Research Council, Rome, 7-00185, Italy; Division of Sleep Medicine, Harvard Medical School, Boston, 02215, MA, United States","Friston K.J., Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, WC1N 3BG, United Kingdom; Lin M., Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, WC1N 3BG, United Kingdom; Frith C.D., Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, WC1N 3BG, United Kingdom, Institute of Philosophy, School of Advanced Studies, University of London, EC1E 7HU, United Kingdom; Pezzulo G., Institute of Cognitive Sciences and Technologies, National Research Council, Rome, 7-00185, Italy; Hobson J.A., Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, WC1N 3BG, United Kingdom, Division of Sleep Medicine, Harvard Medical School, Boston, 02215, MA, United States; Ondobaka S., Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London, WC1N 3BG, United Kingdom","This article offers a formal account of curiosity and insight in terms of active (Bayesian) inference. It deals with the dual problem of inferring states of the world and learning its statistical structure. In contrast to current trends in machine learning (e.g., deep learning), we focus on how people attain insight and understanding using just a handful of observations, which are solicited through curious behavior. We use simulations of abstract rule learning and approximate Bayesian inference to show that minimizing (expected) variational free energy leads to active sampling of novel contingencies. This epistemic behavior closes explanatory gaps in generativemodels of the world, thereby reducing uncertainty and satisfying curiosity. We then move from epistemic learning to model selection or structure learning to show how abductive processes emerge when agents test plausible hypotheses about symmetries (i.e., invariances or rules) in their generative models. The ensuing Bayesian model reduction evinces mechanisms associated with sleep and has all the hallmarks of ""aha"" moments. This formulation moves toward a computational account of consciousness in the pre-Cartesian sense of sharable knowledge (i.e., con: ""together""; scire: ""to know""). © 2017 Massachusetts Institute of Technology.","","Bayesian networks; Free energy; Inference engines; Learning systems; Active sampling; Approximate Bayesian inference; Explanatory gaps; Generative model; Model Selection; Statistical structures; Structure-learning; Variational free energy; Abstracting","MIT Press Journals","08997667","","","28777724","Article","Scopus","2-s2.0-85029283962"
"Wang S.; Li Z.; Yu Y.; Xu J.","Wang, Sheng (58428221300); Li, Zhen (57788458100); Yu, Yizhou (8554163500); Xu, Jinbo (57203521425)","58428221300; 57788458100; 8554163500; 57203521425","Folding Membrane Proteins by Deep Transfer Learning","2017","Cell Systems","53","10.1016/j.cels.2017.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031094104&doi=10.1016%2fj.cels.2017.09.001&partnerID=40&md5=6958eb978e1b701e83bda448cc4f5343","Toyota Technological Institute at Chicago, Chicago, 60637, IL, United States; Department of Human Genetics, University of Chicago, Chicago, 60637, IL, United States; Department of Computer Science, University of Hong Kong, Hong Kong; Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","Wang S., Toyota Technological Institute at Chicago, Chicago, 60637, IL, United States, Department of Human Genetics, University of Chicago, Chicago, 60637, IL, United States, Computational Bioscience Research Center (CBRC), King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Li Z., Toyota Technological Institute at Chicago, Chicago, 60637, IL, United States, Department of Computer Science, University of Hong Kong, Hong Kong; Yu Y., Department of Computer Science, University of Hong Kong, Hong Kong; Xu J., Toyota Technological Institute at Chicago, Chicago, 60637, IL, United States","Computational elucidation of membrane protein (MP) structures is challenging partially due to lack of sufficient solved structures for homology modeling. Here, we describe a high-throughput deep transfer learning method that first predicts MP contacts by learning from non-MPs and then predicts 3D structure models using the predicted contacts as distance restraints. Tested on 510 non-redundant MPs, our method has contact prediction accuracy at least 0.18 better than existing methods, predicts correct folds for 218 MPs, and generates 3D models with root-mean-square deviation (RMSD) less than 4 and 5 Å for 57 and 108 MPs, respectively. A rigorous blind test in the continuous automated model evaluation project shows that our method predicted high-resolution 3D models for two recent test MPs of 210 residues with RMSD ∼2 Å. We estimated that our method could predict correct folds for 1,345–1,871 reviewed human multi-pass MPs including a few hundred new folds, which shall facilitate the discovery of drugs targeting at MPs. A deep transfer learning method is presented to predict membrane protein contact map by learning sequence-structure relationships from non-membrane proteins, which overcomes the challenge that there are not many solved membrane protein structures for deep learning model training. The predicted contacts are pretty accurate and can help predict correct folds and accurate 3D models for ∼40% and ∼20% of 510 non-redundant membrane proteins, respectively. © 2017 Elsevier Inc.","co-evolution analysis; deep learning; deep transfer learning; homology modeling; membrane protein contact prediction; membrane protein folding; multiple sequence alignment","Algorithms; Computational Biology; Computer Simulation; Databases, Protein; Deep Learning; Forecasting; Humans; Membrane Proteins; Molecular Dynamics Simulation; Protein Conformation; Protein Folding; Protein Structure, Tertiary; Sequence Analysis, Protein; membrane protein; membrane protein; accuracy; Article; deep transfer learning; machine learning; priority journal; protein folding; protein structure; sequence homology; structural model; algorithm; biology; chemistry; computer simulation; forecasting; human; metabolism; molecular dynamics; physiology; procedures; protein conformation; protein database; protein folding; protein tertiary structure; sequence analysis","Cell Press","24054712","","","28957654","Article","Scopus","2-s2.0-85031094104"
"Xu Y.; Yan K.; Kim J.; Wang X.; Li C.; Su L.; Yu S.; Xu X.; Feng D.D.","Xu, Yupeng (56597097800); Yan, Ke (57213117230); Kim, Jinman (55720292700); Wang, Xiuying (9639442200); Li, Changyang (35799902900); Su, Li (36544261300); Yu, Suqin (55922797500); Xu, Xun (8615095400); Feng, Dagan David (7401981167)","56597097800; 57213117230; 55720292700; 9639442200; 35799902900; 36544261300; 55922797500; 8615095400; 7401981167","Dual-stage deep learning framework for pigment epithelium detachment segmentation in polypoidal choroidal vasculopathy","2017","Biomedical Optics Express","52","10.1364/BOE.8.004061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028768220&doi=10.1364%2fBOE.8.004061&partnerID=40&md5=c5786f0f4f13519ad441b158134c950e","Department of Ophthalmology, Shanghai General Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, 200080, China; Shanghai Key Laboratory of Fundus Disease, Shanghai Engineering Center for Visual Science and Photomedicine, Shanghai, 200080, China; Biomedical and Multimedia Information Technology (BMIT) Research Group, The University of Sydney, Sydney, 2006, NSW, Australia","Xu Y., Department of Ophthalmology, Shanghai General Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, 200080, China, Shanghai Key Laboratory of Fundus Disease, Shanghai Engineering Center for Visual Science and Photomedicine, Shanghai, 200080, China; Yan K., Biomedical and Multimedia Information Technology (BMIT) Research Group, The University of Sydney, Sydney, 2006, NSW, Australia; Kim J., Biomedical and Multimedia Information Technology (BMIT) Research Group, The University of Sydney, Sydney, 2006, NSW, Australia; Wang X., Biomedical and Multimedia Information Technology (BMIT) Research Group, The University of Sydney, Sydney, 2006, NSW, Australia; Li C., Biomedical and Multimedia Information Technology (BMIT) Research Group, The University of Sydney, Sydney, 2006, NSW, Australia; Su L., Department of Ophthalmology, Shanghai General Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, 200080, China, Shanghai Key Laboratory of Fundus Disease, Shanghai Engineering Center for Visual Science and Photomedicine, Shanghai, 200080, China; Yu S., Department of Ophthalmology, Shanghai General Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, 200080, China, Shanghai Key Laboratory of Fundus Disease, Shanghai Engineering Center for Visual Science and Photomedicine, Shanghai, 200080, China; Xu X., Department of Ophthalmology, Shanghai General Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, 200080, China, Shanghai Key Laboratory of Fundus Disease, Shanghai Engineering Center for Visual Science and Photomedicine, Shanghai, 200080, China; Feng D.D., Biomedical and Multimedia Information Technology (BMIT) Research Group, The University of Sydney, Sydney, 2006, NSW, Australia","Worldwide, polypoidal choroidal vasculopathy (PCV) is a common visionthreatening exudative maculopathy, and pigment epithelium detachment (PED) is an important clinical characteristic. Thus, precise and efficient PED segmentation is necessary for PCV clinical diagnosis and treatment. We propose a dual-stage learning framework via deep neural networks (DNN) for automated PED segmentation in PCV patients to avoid issues associated with manual PED segmentation (subjectivity, manual segmentation errors, and high time consumption).The optical coherence tomography scans of fifty patients were quantitatively evaluated with different algorithms and clinicians. Dual-stage DNN outperformed existing PED segmentation methods for all segmentation accuracy parameters, including true positive volume fraction (85.74 ± 8.69%), dice similarity coefficient (85.69 ± 8.08%), positive predictive value (86.02 ± 8.99%) and false positive volume fraction (0.38 ± 0.18%). Dual-stage DNN achieves accurate PED quantitative information, works with multiple types of PEDs and agrees well with manual delineation, suggesting that it is a potential automated assistant for PCV management. © 2017 Optical Society of America.","Image processing; Medical and biological imaging; Optical coherence tomography; Pattern recognition, neural networks","Deep neural networks; Diagnosis; Image processing; Medical imaging; Optical data processing; Optical tomography; Pattern recognition; Tomography; Volume fraction; Clinical characteristics; Manual segmentation; Medical and biological imaging; Positive predictive values; Quantitative information; Segmentation accuracy; Segmentation methods; Similarity coefficients; Article; artificial neural network; dual stage learning framework; image processing; image segmentation; machine learning; mathematical model; optical coherence tomography; polypoidal choroidal vasculopathy; retina detachment; Deep learning","OSA - The Optical Society","21567085","","","","Article","Scopus","2-s2.0-85028768220"
"Nguyen T.V.; Mirza B.","Nguyen, Tam V. (24480257100); Mirza, Bilal (55603121100)","24480257100; 55603121100","Dual-layer kernel extreme learning machine for action recognition","2017","Neurocomputing","36","10.1016/j.neucom.2017.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017564311&doi=10.1016%2fj.neucom.2017.04.007&partnerID=40&md5=a554e6b974240a4edf278b5636ebfd13","Department of Computer Science, University of Dayton, United States; David Geffen School of Medicine, University of California, Los Angeles, United States","Nguyen T.V., Department of Computer Science, University of Dayton, United States; Mirza B., David Geffen School of Medicine, University of California, Los Angeles, United States","In this paper, we propose a simple yet effective method for video based action recognition referred to as dual-layer kernel extreme learning machine (DKELM). Our approach takes advantages of both early and late fusion techniques into a unified framework. In particular, the first layer in DKELM adopts linear kernel extreme learning machine (KELM) on handcrafted feature kernel, deep-learned feature kernel, and the fused kernel to provide various perspectives about the video. The second layer trains a radial basis function based KELM classifier on different fusion scores obtained from the first layer to predict the final action class label. Finally, we empirically show the superior performance of DKELM, both in terms of accuracy and computational time, over some state-of-the-art human action recognition methods on two large-scale datasets. © 2017","Action recognition; Dual-layer kernel learning; Extreme learning machine","Knowledge acquisition; Neural networks; Radial basis function networks; Action recognition; Computational time; Extreme learning machine; Human-action recognition; Kernel learning; Large-scale datasets; Radial basis functions; Unified framework; Article; brain function; classifier; dual-layer kernel extreme learning machine; extreme learning machine; human; machine learning; priority journal; support vector machine; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85017564311"
"Hess M.; Lenz S.; Blätte T.J.; Bullinger L.; Binder H.","Hess, Moritz (55935582100); Lenz, Stefan (57196094468); Blätte, Tamara J. (56497040100); Bullinger, Lars (6506340561); Binder, Harald (7202460535)","55935582100; 57196094468; 56497040100; 6506340561; 7202460535","Partitioned learning of deep Boltzmann machines for SNP data","2017","Bioinformatics","22","10.1093/bioinformatics/btx408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031794551&doi=10.1093%2fbioinformatics%2fbtx408&partnerID=40&md5=36c6dbf68dadf98bc7e266566ff6ada7","Institute of Medical Biostatistics Epidemiology and Informatics (IMBEI), University Medical Center, Mainz, 55131, Germany; Department of Internal Medicine III, University Hospital of Ulm, Ulm, 89081, Germany; Institute for Medical Biometry and Statistics, Faculty of Medicine and Medical Center, University of Freiburg, Freiburg, 79104, Germany","Hess M., Institute of Medical Biostatistics Epidemiology and Informatics (IMBEI), University Medical Center, Mainz, 55131, Germany; Lenz S., Institute of Medical Biostatistics Epidemiology and Informatics (IMBEI), University Medical Center, Mainz, 55131, Germany; Blätte T.J., Department of Internal Medicine III, University Hospital of Ulm, Ulm, 89081, Germany; Bullinger L., Department of Internal Medicine III, University Hospital of Ulm, Ulm, 89081, Germany; Binder H., Institute of Medical Biostatistics Epidemiology and Informatics (IMBEI), University Medical Center, Mainz, 55131, Germany, Institute for Medical Biometry and Statistics, Faculty of Medicine and Medical Center, University of Freiburg, Freiburg, 79104, Germany","Motivation Learning the joint distributions of measurements, and in particular identification of an appropriate low-dimensional manifold, has been found to be a powerful ingredient of deep leaning approaches. Yet, such approaches have hardly been applied to single nucleotide polymorphism (SNP) data, probably due to the high number of features typically exceeding the number of studied individuals. Results After a brief overview of how deep Boltzmann machines (DBMs), a deep learning approach, can be adapted to SNP data in principle, we specifically present a way to alleviate the dimensionality problem by partitioned learning. We propose a sparse regression approach to coarsely screen the joint distribution of SNPs, followed by training several DBMs on SNP partitions that were identified by the screening. Aggregate features representing SNP patterns and the corresponding SNPs are extracted from the DBMs by a combination of statistical tests and sparse regression. In simulated case-control data, we show how this can uncover complex SNP patterns and augment results from univariate approaches, while maintaining type 1 error control. Time-to-event endpoints are considered in an application with acute myeloid leukemia patients, where SNP patterns are modeled after a pre-screening based on gene expression data. The proposed approach identified three SNPs that seem to jointly influence survival in a validation dataset. This indicates the added value of jointly investigating SNPs compared to standard univariate analyses and makes partitioned learning of DBMs an interesting complementary approach when analyzing SNP data. Availability and implementation A Julia package is provided at 'http://github.com/binderh/BoltzmannMachines.jl'. Contact binderh@imbi.uni-freiburg.de Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author 2017. Published by Oxford University Press. All rights reserved.","","Computational Biology; Gene Expression Regulation, Leukemic; Humans; Leukemia, Myeloid; Machine Learning; Polymorphism, Single Nucleotide; Software; biology; gene expression regulation; genetics; human; machine learning; myeloid leukemia; procedures; single nucleotide polymorphism; software","Oxford University Press","13674803","","BOINF","28655145","Article","Scopus","2-s2.0-85031794551"
"Tran T.; Kavuluru R.","Tran, Tung (57193316218); Kavuluru, Ramakanth (23467019200)","57193316218; 23467019200","Predicting mental conditions based on “history of present illness” in psychiatric notes with deep neural networks","2017","Journal of Biomedical Informatics","54","10.1016/j.jbi.2017.06.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021835221&doi=10.1016%2fj.jbi.2017.06.010&partnerID=40&md5=f08a9dde2636b715342d823646ebf332","Department of Computer Science, University of Kentucky, 329 Rose Street, Lexington, 40506, KY, United States; Division of Biomedical Informatics, Department of Internal Medicine, University Kentucky, 725 Rose Street, Lexington, 40536, KY, United States","Tran T., Department of Computer Science, University of Kentucky, 329 Rose Street, Lexington, 40506, KY, United States; Kavuluru R., Department of Computer Science, University of Kentucky, 329 Rose Street, Lexington, 40506, KY, United States, Division of Biomedical Informatics, Department of Internal Medicine, University Kentucky, 725 Rose Street, Lexington, 40536, KY, United States","Background: Applications of natural language processing to mental health notes are not common given the sensitive nature of the associated narratives. The CEGS N-GRID 2016 Shared Task in Clinical Natural Language Processing (NLP) changed this scenario by providing the first set of neuropsychiatric notes to participants. This study summarizes our efforts and results in proposing a novel data use case for this dataset as part of the third track in this shared task. Objective: We explore the feasibility and effectiveness of predicting a set of common mental conditions a patient has based on the short textual description of patient's history of present illness typically occurring in the beginning of a psychiatric initial evaluation note. Materials and methods: We clean and process the 1000 records made available through the N-GRID clinical NLP task into a key-value dictionary and build a dataset of 986 examples for which there is a narrative for history of present illness as well as Yes/No responses with regards to presence of specific mental conditions. We propose two independent deep neural network models: one based on convolutional neural networks (CNN) and another based on recurrent neural networks with hierarchical attention (ReHAN), the latter of which allows for interpretation of model decisions. We conduct experiments to compare these methods to each other and to baselines based on linear models and named entity recognition (NER). Results: Our CNN model with optimized thresholding of output probability estimates achieves best overall mean micro-F score of 63.144% for 11 common mental conditions with statistically significant gains (p<0.05) over all other models. The ReHAN model with interpretable attention mechanism scored 61.904% mean micro-F1 score. Both models’ improvements over baseline models (support vector machines and NER) are statistically significant. The ReHAN model additionally aids in interpretation of the results by surfacing important words and sentences that lead to a particular prediction for each instance. Conclusions: Although the history of present illness is a short text segment averaging 300 words, it is a good predictor for a few conditions such as anxiety, depression, panic disorder, and attention deficit hyperactivity disorder. Proposed CNN and RNN models outperform baseline approaches and complement each other when evaluating on a per-label basis. © 2017","Convolutional and recurrent neural networks; Hierarchical attention networks; Multi-label text classification; Psychiatric condition prediction","Humans; Machine Learning; Mental Disorders; Natural Language Processing; Neural Networks (Computer); Classification (of information); Convolution; Diseases; Forecasting; Natural language processing systems; Recurrent neural networks; Text processing; Attention deficit hyperactivity disorder; Attention mechanisms; Condition prediction; Convolutional Neural Networks (CNN); Interpretation of models; Multi-label text classification; Named entity recognition; Probability estimate; anxiety; Article; artificial neural network; attention deficit disorder; bipolar disorder; convolutional neural network; deep neural network; depression; diagnostic test; eating disorder; human; intermethod comparison; machine learning; medical history; medical record; mental health; natural language processing; Neuropsychiatric Genome Scale and RDoC Individualized Domain; panic; posttraumatic stress disorder; prediction; priority journal; psychosis; recurrent neural network; mental disease; Deep neural networks","Academic Press Inc.","15320464","","JBIOB","28606869","Article","Scopus","2-s2.0-85021835221"
"Wang Z.; Teng S.; Liu G.; Zhao Z.; Wu H.","Wang, Zhengxia (24832261300); Teng, Shenghua (24831248000); Liu, Guodong (57746565300); Zhao, Zengshun (55667575500); Wu, Hongli (55960436600)","24832261300; 24831248000; 57746565300; 55667575500; 55960436600","Hierarchical sparse representation with deep dictionary for multi-modal classification","2017","Neurocomputing","5","10.1016/j.neucom.2016.11.079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015298369&doi=10.1016%2fj.neucom.2016.11.079&partnerID=40&md5=d3a7a0578c71f09172c2c6d10d82764c","Department of information Science and Engineering, Chongqing Jiaotong University, Chongqing, 400074, China; Department of Automation, Chongqing University, Chongqing, 400044, China; College of Electronics, Communication and Physics, Shandong University of Science and Technology, Shandong, 266590, China; College of Civil Engineering, Chongqing Jiaotong University, Chongqing, 400074, China; College of Information Science and Technology, Hainan Normal University, Hainan, 571100, China","Wang Z., Department of information Science and Engineering, Chongqing Jiaotong University, Chongqing, 400074, China, Department of Automation, Chongqing University, Chongqing, 400044, China; Teng S., College of Electronics, Communication and Physics, Shandong University of Science and Technology, Shandong, 266590, China; Liu G., College of Civil Engineering, Chongqing Jiaotong University, Chongqing, 400074, China; Zhao Z., College of Electronics, Communication and Physics, Shandong University of Science and Technology, Shandong, 266590, China; Wu H., College of Information Science and Technology, Hainan Normal University, Hainan, 571100, China","Sparse representation based classification (SRC) methods have achieved many successes in pattern recognition and machine learning. In such methods, the training samples of all categories are mixed and compose a dictionary to represent the test sample via sparsity constraint. Then, the class with the minimum representation error wins for labeling the test sample. In general, SRC is more flexible and effective than many supervised learning methods. However, in some cases it is unlikely to represent the test sample accurately, which tends to undermine the classification accuracy. To alleviate this issue, we propose a hierarchical sparse representation based classification method by augmenting the single-layer sparse representation into the hierarchical representation with a deep dictionary. Specifically, the features from all training samples are first divided into several groups according to their labels. Then we employ hierarchical clustering in each group and combine them to form a deep dictionary such that the root layer includes only a certain amount of the most representative exemplars while the subsequent layers focus on characterizing the remaining individual information across different groups. Furthermore, we use the layer-after-layer residuals to encode the variation patterns across individuals in different scales. Given the deep dictionary, a hierarchical sparse representation based classification method is presented to determine the label for each test sample by iteratively representing its primary part with the exemplars in different groups but the remaining parts by the variation patterns encoded in different layers. To further improve the classification accuracy and robustness, we extend our method by taking advantage of the complementary information in multi-view features. Experiments on Multiple Features Data Set show promising results compared with the state-of-the-art classification methods. © 2017 Elsevier B.V.","Deep dictionary; Hierarchical sparse representation; Multi-view feature","Hierarchical clustering; Iterative methods; Learning systems; Pattern recognition; Sampling; Classification accuracy; Classification methods; Hierarchical representation; Multi-views; Sparse representation; Sparse representation based classifications; Sparsity constraints; Supervised learning methods; accuracy; analytic method; Article; classification; cluster analysis; data base; hierarchical sparse representation based classification method; information processing; nomenclature; priority journal; Classification (of information)","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85015298369"
"Dou Q.; Yu L.; Chen H.; Jin Y.; Yang X.; Qin J.; Heng P.-A.","Dou, Qi (56903795500); Yu, Lequan (56903335400); Chen, Hao (56493367600); Jin, Yueming (57191745209); Yang, Xin (56967210500); Qin, Jing (35339855100); Heng, Pheng-Ann (7006677755)","56903795500; 56903335400; 56493367600; 57191745209; 56967210500; 35339855100; 7006677755","3D deeply supervised network for automated segmentation of volumetric medical images","2017","Medical Image Analysis","456","10.1016/j.media.2017.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019483926&doi=10.1016%2fj.media.2017.05.001&partnerID=40&md5=bf5f0cba83debfa77d77cc780e7d674c","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong","Dou Q., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Yu L., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Chen H., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Jin Y., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Yang X., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Qin J., Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Heng P.-A., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong","While deep convolutional neural networks (CNNs) have achieved remarkable success in 2D medical image segmentation, it is still a difficult task for CNNs to segment important organs or structures from 3D medical images owing to several mutually affected challenges, including the complicated anatomical environments in volumetric images, optimization difficulties of 3D networks and inadequacy of training samples. In this paper, we present a novel and efficient 3D fully convolutional network equipped with a 3D deep supervision mechanism to comprehensively address these challenges; we call it 3D DSN. Our proposed 3D DSN is capable of conducting volume-to-volume learning and inference, which can eliminate redundant computations and alleviate the risk of over-fitting on limited training data. More importantly, the 3D deep supervision mechanism can effectively cope with the optimization problem of gradients vanishing or exploding when training a 3D deep model, accelerating the convergence speed and simultaneously improving the discrimination capability. Such a mechanism is developed by deriving an objective function that directly guides the training of both lower and upper layers in the network, so that the adverse effects of unstable gradient changes can be counteracted during the training procedure. We also employ a fully connected conditional random field model as a post-processing step to refine the segmentation results. We have extensively validated the proposed 3D DSN on two typical yet challenging volumetric medical image segmentation tasks: (i) liver segmentation from 3D CT scans and (ii) whole heart and great vessels segmentation from 3D MR images, by participating two grand challenges held in conjunction with MICCAI. We have achieved competitive segmentation results to state-of-the-art approaches in both challenges with a much faster speed, corroborating the effectiveness of our proposed 3D DSN. © 2017 Elsevier B.V.","3D deeply supervised networks; 3D fully convolutional networks; Deep learning; Volumetric medical image segmentation","Humans; Imaging, Three-Dimensional; Neural Networks (Computer); Reproducibility of Results; Sensitivity and Specificity; Supervised Machine Learning; Computerized tomography; Convolution; Deep learning; Deep neural networks; Image segmentation; Magnetic resonance imaging; Medical imaging; Network layers; Neural networks; Optimization; Automated segmentation; Conditional random field; Convolutional networks; Convolutional neural network; Optimization problems; State-of-the-art approach; Supervised network; Supervision mechanisms; Article; automation; cone beam computed tomography; controlled study; density gradient; discrimination learning; great blood vessel; heart; human; image segmentation; liver; priority journal; process optimization; supervised machine learning; three dimensional imaging; velocity; volume; x-ray computed tomography; artificial neural network; procedures; reproducibility; sensitivity and specificity; supervised machine learning; three dimensional imaging; validation study; Medical image processing","Elsevier B.V.","13618415","","MIAEC","28526212","Article","Scopus","2-s2.0-85019483926"
"Vang Y.S.; Xie X.","Vang, Yeeleng S. (57195684602); Xie, Xiaohui (8311948600)","57195684602; 8311948600","HLA class I binding prediction via convolutional neural networks","2017","Bioinformatics (Oxford, England)","72","10.1093/bioinformatics/btx264","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032791369&doi=10.1093%2fbioinformatics%2fbtx264&partnerID=40&md5=b6908b9ecb256733b39fa8d8df5cdb75","Institute for Genomics and Bioinformatics, University of California, Irvine, 92697, CA, United States; Institute for Genomics and Bioinformatics, University of California, Irvine, 92697, CA, United States","Vang Y.S., Institute for Genomics and Bioinformatics, University of California, Irvine, 92697, CA, United States; Xie X., Institute for Genomics and Bioinformatics, University of California, Irvine, 92697, CA, United States, Institute for Genomics and Bioinformatics, University of California, Irvine, 92697, CA, United States","Motivation: Many biological processes are governed by protein-ligand interactions. One such example is the recognition of self and non-self cells by the immune system. This immune response process is regulated by the major histocompatibility complex (MHC) protein which is encoded by the human leukocyte antigen (HLA) complex. Understanding the binding potential between MHC and peptides can lead to the design of more potent, peptide-based vaccines and immunotherapies for infectious autoimmune diseases.; Results: We apply machine learning techniques from the natural language processing (NLP) domain to address the task of MHC-peptide binding prediction. More specifically, we introduce a new distributed representation of amino acids, name HLA-Vec, that can be used for a variety of downstream proteomic machine learning tasks. We then propose a deep convolutional neural network architecture, name HLA-CNN, for the task of HLA class I-peptide binding prediction. Experimental results show combining the new distributed representation with our HLA-CNN architecture achieves state-of-the-art results in the majority of the latest two Immune Epitope Database (IEDB) weekly automated benchmark datasets. We further apply our model to predict binding on the human genome and identify 15 genes with potential for self binding.; Availability and Implementation: Codes to generate the HLA-Vec and HLA-CNN are publicly available at: https://github.com/uci-cbcl/HLA-bind .; Contact: xhx@ics.uci.edu.; Supplementary information: Supplementary data are available at Bioinformatics online. © The Author (2017). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com","","Epitopes; Histocompatibility Antigens Class I; HLA Antigens; Humans; Machine Learning; Neural Networks (Computer); Peptides; Protein Binding; Proteomics; epitope; HLA antigen; HLA antigen class 1; peptide; protein binding; artificial neural network; human; machine learning; metabolism; procedures; proteomics","","13674811","","","28444127","Article","Scopus","2-s2.0-85032791369"
"Jiang X.; Zhang H.; Duan F.; Quan X.","Jiang, Xue (57412991100); Zhang, Han (57161255400); Duan, Feng (24537140100); Quan, Xiongwen (21739680600)","57412991100; 57161255400; 24537140100; 21739680600","Identify Huntington's disease associated genes based on restricted Boltzmann machine with RNA-seq data","2017","BMC Bioinformatics","18","10.1186/s12859-017-1859-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030853005&doi=10.1186%2fs12859-017-1859-6&partnerID=40&md5=8f459a806a9a326a6e8fe374d825d38a","Nankai University, College of Computer and Control Engineering, Tongyan Road, Tianjin, 300350, China; Nankai University, Tianjin Key Laboratory of Intelligent Robotics, Tongyan Road, Tianjin, 300350, China","Jiang X., Nankai University, College of Computer and Control Engineering, Tongyan Road, Tianjin, 300350, China, Nankai University, Tianjin Key Laboratory of Intelligent Robotics, Tongyan Road, Tianjin, 300350, China; Zhang H., Nankai University, College of Computer and Control Engineering, Tongyan Road, Tianjin, 300350, China, Nankai University, Tianjin Key Laboratory of Intelligent Robotics, Tongyan Road, Tianjin, 300350, China; Duan F., Nankai University, College of Computer and Control Engineering, Tongyan Road, Tianjin, 300350, China, Nankai University, Tianjin Key Laboratory of Intelligent Robotics, Tongyan Road, Tianjin, 300350, China; Quan X., Nankai University, College of Computer and Control Engineering, Tongyan Road, Tianjin, 300350, China, Nankai University, Tianjin Key Laboratory of Intelligent Robotics, Tongyan Road, Tianjin, 300350, China","Background: Predicting disease-associated genes is helpful for understanding the molecular mechanisms during the disease progression. Since the pathological mechanisms of neurodegenerative diseases are very complex, traditional statistic-based methods are not suitable for identifying key genes related to the disease development. Recent studies have shown that the computational models with deep structure can learn automatically the features of biological data, which is useful for exploring the characteristics of gene expression during the disease progression. Results: In this paper, we propose a deep learning approach based on the restricted Boltzmann machine to analyze the RNA-seq data of Huntington's disease, namely stacked restricted Boltzmann machine (SRBM). According to the SRBM, we also design a novel framework to screen the key genes during the Huntington's disease development. In this work, we assume that the effects of regulatory factors can be captured by the hierarchical structure and narrow hidden layers of the SRBM. First, we select disease-associated factors with different time period datasets according to the differentially activated neurons in hidden layers. Then, we select disease-associated genes according to the changes of the gene energy in SRBM at different time periods. Conclusions: The experimental results demonstrate that SRBM can detect the important information for differential analysis of time series gene expression datasets. The identification accuracy of the disease-associated genes is improved to some extent using the novel framework. Moreover, the prediction precision of disease-associated genes for top ranking genes using SRBM is effectively improved compared with that of the state of the art methods. © 2017 The Author(s).","Huntington's disease; Key genes associated to the disease progression; Restricted Boltzmann machine; RNA-seq data","Algorithms; Cluster Analysis; Computer Simulation; Disease Progression; Gene Expression Regulation; Genetic Association Studies; Genetic Predisposition to Disease; Humans; Huntington Disease; Molecular Sequence Annotation; Neurons; ROC Curve; Sequence Analysis, RNA; Gene expression; Genes; RNA; Time series analysis; Disease progression; Hierarchical structures; Huntington's disease; Identification accuracy; Restricted boltzmann machine; RNA-Seq datum; State-of-the-art methods; Time series gene expressions; algorithm; cluster analysis; computer simulation; disease exacerbation; gene expression regulation; genetic association study; genetic predisposition; genetics; human; Huntington chorea; molecular genetics; nerve cell; pathology; receiver operating characteristic; sequence analysis; Neurodegenerative diseases","BioMed Central Ltd.","14712105","","BBMIC","29020921","Article","Scopus","2-s2.0-85030853005"
"Young J.D.; Cai C.; Lu X.","Young, Jonathan D. (57195944996); Cai, Chunhui (56849836300); Lu, Xinghua (12799008300)","57195944996; 56849836300; 12799008300","Unsupervised deep learning reveals prognostically relevant subtypes of glioblastoma","2017","BMC Bioinformatics","40","10.1186/s12859-017-1798-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030319132&doi=10.1186%2fs12859-017-1798-2&partnerID=40&md5=b25406d39ebcf2206bb7dc5a5d3a8b20","University of Pittsburgh, Department of Biomedical Informatics, 5607 Baum Blvd, Pittsburgh, 15206, PA, United States; University of Pittsburgh, Intelligent Systems Program, 5607 Baum Blvd, Pittsburgh, 15206, PA, United States; University of Pittsburgh, Center for Causal Discovery, 5607 Baum Blvd, Pittsburgh, 15206, PA, United States","Young J.D., University of Pittsburgh, Department of Biomedical Informatics, 5607 Baum Blvd, Pittsburgh, 15206, PA, United States, University of Pittsburgh, Intelligent Systems Program, 5607 Baum Blvd, Pittsburgh, 15206, PA, United States; Cai C., University of Pittsburgh, Department of Biomedical Informatics, 5607 Baum Blvd, Pittsburgh, 15206, PA, United States, University of Pittsburgh, Center for Causal Discovery, 5607 Baum Blvd, Pittsburgh, 15206, PA, United States; Lu X., University of Pittsburgh, Department of Biomedical Informatics, 5607 Baum Blvd, Pittsburgh, 15206, PA, United States, University of Pittsburgh, Center for Causal Discovery, 5607 Baum Blvd, Pittsburgh, 15206, PA, United States","Background: One approach to improving the personalized treatment of cancer is to understand the cellular signaling transduction pathways that cause cancer at the level of the individual patient. In this study, we used unsupervised deep learning to learn the hierarchical structure within cancer gene expression data. Deep learning is a group of machine learning algorithms that use multiple layers of hidden units to capture hierarchically related, alternative representations of the input data. We hypothesize that this hierarchical structure learned by deep learning will be related to the cellular signaling system. Results: Robust deep learning model selection identified a network architecture that is biologically plausible. Our model selection results indicated that the 1st hidden layer of our deep learning model should contain about 1300 hidden units to most effectively capture the covariance structure of the input data. This agrees with the estimated number of human transcription factors, which is approximately 1400. This result lends support to our hypothesis that the 1st hidden layer of a deep learning model trained on gene expression data may represent signals related to transcription factor activation. Using the 3rd hidden layer representation of each tumor as learned by our unsupervised deep learning model, we performed consensus clustering on all tumor samples-leading to the discovery of clusters of glioblastoma multiforme with differential survival. One of these clusters contained all of the glioblastoma samples with G-CIMP, a known methylation phenotype driven by the IDH1 mutation and associated with favorable prognosis, suggesting that the hidden units in the 3rd hidden layer representations captured a methylation signal without explicitly using methylation data as input. We also found differentially expressed genes and well-known mutations (NF1, IDH1, EGFR) that were uniquely correlated with each of these clusters. Exploring these unique genes and mutations will allow us to further investigate the disease mechanisms underlying each of these clusters. Conclusions: In summary, we show that a deep learning model can be trained to represent biologically and clinically meaningful abstractions of cancer gene expression data. Understanding what additional relationships these hidden layer abstractions have with the cancer cellular signaling system could have a significant impact on the understanding and treatment of cancer. © 2017 The Author(s).","Cancer; Deep belief network; Deep learning; Gene expression; Glioblastoma multiforme; Model selection; Unsupervised learning","Algorithms; Brain Neoplasms; Cluster Analysis; Gene Expression Profiling; Gene Expression Regulation, Neoplastic; Glioblastoma; Humans; Machine Learning; Prognosis; Abstracting; Alkylation; Cluster analysis; Diagnosis; Diseases; Gene expression; Genes; Input output programs; Learning algorithms; Learning systems; Methylation; Network architecture; Patient treatment; Transcription; Transcription factors; Tumors; Unsupervised learning; Cancer; Cancer gene expression; Deep belief networks; Differentially expressed gene; Glioblastoma multiforme; Hierarchical structures; Human transcription factors; Model Selection; algorithm; brain tumor; classification; cluster analysis; gene expression profiling; gene expression regulation; genetics; glioblastoma; human; machine learning; prognosis; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","28984190","Article","Scopus","2-s2.0-85030319132"
"Li S.; Chen J.; Liu B.","Li, Shumin (57421660100); Chen, Junjie (56556575800); Liu, Bin (56151911700)","57421660100; 56556575800; 56151911700","Protein remote homology detection based on bidirectional long short-term memory","2017","BMC Bioinformatics","54","10.1186/s12859-017-1842-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030849925&doi=10.1186%2fs12859-017-1842-2&partnerID=40&md5=3abc6bc97fd656a54d04b94a55c708f6","HIT Campus Shenzhen University Town, School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Xili, Shenzhen, 518055, China","Li S., HIT Campus Shenzhen University Town, School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Xili, Shenzhen, 518055, China; Chen J., HIT Campus Shenzhen University Town, School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Xili, Shenzhen, 518055, China; Liu B., HIT Campus Shenzhen University Town, School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Xili, Shenzhen, 518055, China","Background: Protein remote homology detection plays a vital role in studies of protein structures and functions. Almost all of the traditional machine leaning methods require fixed length features to represent the protein sequences. However, it is never an easy task to extract the discriminative features with limited knowledge of proteins. On the other hand, deep learning technique has demonstrated its advantage in automatically learning representations. It is worthwhile to explore the applications of deep learning techniques to the protein remote homology detection. Results: In this study, we employ the Bidirectional Long Short-Term Memory (BLSTM) to learn effective features from pseudo proteins, also propose a predictor called ProDec-BLSTM: it includes input layer, bidirectional LSTM, time distributed dense layer and output layer. This neural network can automatically extract the discriminative features by using bidirectional LSTM and the time distributed dense layer. Conclusion: Experimental results on a widely-used benchmark dataset show that ProDec-BLSTM outperforms other related methods in terms of both the mean ROC and mean ROC50 scores. This promising result shows that ProDec-BLSTM is a useful tool for protein remote homology detection. Furthermore, the hidden patterns learnt by ProDec-BLSTM can be interpreted and visualized, and therefore, additional useful information can be obtained. © 2017 The Author(s).","Bidirectional Long Short-Term Memory; Neural network; Protein remote homology detection; Protein sequence analysis","Algorithms; Databases, Protein; Proteins; ROC Curve; Structural Homology, Protein; Brain; Deep learning; Learning algorithms; Learning systems; Neural networks; Proteins; protein; Benchmark datasets; Discriminative features; Learning techniques; Machine leaning; Protein sequence analysis; Protein sequences; Protein structures; Remote homology detections; algorithm; chemistry; protein database; receiver operating characteristic; structural homology; Long short-term memory","BioMed Central Ltd.","14712105","","BBMIC","29017445","Article","Scopus","2-s2.0-85030849925"
"Bejnordi B.E.; Zuidhof G.; Balkenhol M.; Hermsen M.; Bult P.; Van Ginneken B.; Karssemeijer N.; Litjens G.; Van Der Laak J.","Bejnordi, Babak Ehteshami (56986708300); Zuidhof, Guido (57194976890); Balkenhol, Maschenka (57202417370); Hermsen, Meyke (56694305400); Bult, Peter (6602193995); Van Ginneken, Bram (57202688150); Karssemeijer, Nico (24332021400); Litjens, Geert (36622356600); Van Der Laak, Jeroen (6701833644)","56986708300; 57194976890; 57202417370; 56694305400; 6602193995; 57202688150; 24332021400; 36622356600; 6701833644","Context-aware stacked convolutional neural networks for classification of breast carcinomas in whole-slide histopathology images","2017","Journal of Medical Imaging","134","10.1117/1.JMI.4.4.044504","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040456298&doi=10.1117%2f1.JMI.4.4.044504&partnerID=40&md5=366b43f900571e534af58f246b809abc","Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Nijmegen, Netherlands; Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Pathology, Nijmegen, Netherlands","Bejnordi B.E., Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Nijmegen, Netherlands; Zuidhof G., Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Pathology, Nijmegen, Netherlands; Balkenhol M., Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Pathology, Nijmegen, Netherlands; Hermsen M., Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Pathology, Nijmegen, Netherlands; Bult P., Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Pathology, Nijmegen, Netherlands; Van Ginneken B., Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Nijmegen, Netherlands; Karssemeijer N., Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Nijmegen, Netherlands; Litjens G., Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Nijmegen, Netherlands, Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Pathology, Nijmegen, Netherlands; Van Der Laak J., Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Nijmegen, Netherlands, Radboud University Medical Center, Diagnostic Image Analysis Group, Department of Pathology, Nijmegen, Netherlands","Currently, histopathological tissue examination by a pathologist represents the gold standard for breast lesion diagnostics. Automated classification of histopathological whole-slide images (WSIs) is challenging owing to the wide range of appearances of benign lesions and the visual similarity of ductal carcinoma in-situ (DCIS) to invasive lesions at the cellular level. Consequently, analysis of tissue at high resolutions with a large contextual area is necessary. We present context-aware stacked convolutional neural networks (CNN) for classification of breast WSIs into normal/benign, DCIS, and invasive ductal carcinoma (IDC). We first train a CNN using high pixel resolution to capture cellular level information. The feature responses generated by this model are then fed as input to a second CNN, stacked on top of the first. Training of this stacked architecture with large input patches enables learning of fine-grained (cellular) details and global tissue structures. Our system is trained and evaluated on a dataset containing 221 WSIs of hematoxylin and eosin stained breast tissue specimens. The system achieves an AUC of 0.962 for the binary classification of nonmalignant and malignant slides and obtains a three-class accuracy of 81.3% for classification of WSIs into normal/benign, DCIS, and IDC, demonstrating its potential for routine diagnostics. © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","breast cancer; context-aware CNN; convolutional neural networks; deep learning; histopathology","eosin; hematoxylin; area under the curve; Article; breast carcinoma in situ; breast tissue; cancer classification; cohort analysis; convolutional neural network; diagnostic accuracy; false positive result; histopathology; human; human tissue; intraductal carcinoma; machine learning; random forest; receiver operating characteristic","SPIE","23294302","","","","Article","Scopus","2-s2.0-85040456298"
"Keshavan M.S.; Sudarshan M.","Keshavan, Matcheri S. (16740130400); Sudarshan, Mukund (57193071486)","16740130400; 57193071486","Deep dreaming, aberrant salience and psychosis: Connecting the dots by artificial neural networks","2017","Schizophrenia Research","9","10.1016/j.schres.2017.01.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010280527&doi=10.1016%2fj.schres.2017.01.020&partnerID=40&md5=b768b3cdf3b69073cc6e12cac9c4b0a7","BethIsrael Deaconess Medical Center, United States; Harvard Medical School, United States; Cornell University, United States","Keshavan M.S., BethIsrael Deaconess Medical Center, United States, Harvard Medical School, United States; Sudarshan M., Cornell University, United States","Why some individuals, when presented with unstructured sensory inputs, develop altered perceptions not based in reality, is not well understood. Machine learning approaches can potentially help us understand how the brain normally interprets sensory inputs. Artificial neural networks (ANN) progressively extract higher and higher-level features of sensory input and identify the nature of an object based on a priori information. However, some ANNs which use algorithms such as the “deep-dreaming” developed by Google, allow the network to over-emphasize some objects it “thinks” it recognizes in those areas, and iteratively enhance such outputs leading to representations that appear farther and farther from “reality”. We suggest that such “deep dreaming” ANNs may model aberrant salience, a mechanism suggested for pathogenesis of psychosis. Such models can generate testable predictions for psychosis. © 2017 Elsevier B.V.","Artificial neural networks; Deep dreaming; Psychosis; Schizophrenia","Brain; Creativity; Humans; Machine Learning; Models, Neurological; Neural Networks (Computer); Neural Pathways; Psychotic Disorders; Schizophrenia; algorithm; Article; artificial neural network; brain function; deep dreaming; human; machine learning; pathogenesis; perception; prediction; priority journal; psychosis; sensory stimulation; biological model; brain; creativity; nerve tract; pathophysiology; psychosis; schizophrenia","Elsevier B.V.","09209964","","SCRSE","28130003","Article","Scopus","2-s2.0-85010280527"
"Wang S.; Zhou M.; Liu Z.; Liu Z.; Gu D.; Zang Y.; Dong D.; Gevaert O.; Tian J.","Wang, Shuo (58671609100); Zhou, Mu (56878023500); Liu, Zaiyi (55763975900); Liu, Zhenyu (57204479755); Gu, Dongsheng (57202679950); Zang, Yali (36017980100); Dong, Di (36170318900); Gevaert, Olivier (23003890000); Tian, Jie (7401636162)","58671609100; 56878023500; 55763975900; 57204479755; 57202679950; 36017980100; 36170318900; 23003890000; 7401636162","Central focused convolutional neural networks: Developing a data-driven model for lung nodule segmentation","2017","Medical Image Analysis","368","10.1016/j.media.2017.06.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021726055&doi=10.1016%2fj.media.2017.06.014&partnerID=40&md5=067ebd5fb694ae854567017f00d548a0","CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China; Stanford Center for Biomedical Informatics Research (BMIR), Department of Medicine, Stanford University, CA 94305, United States; University of Chinese Academy of Sciences, Beijing 100049, China; Guangdong General Hospital, Guangzhou, Guangdong 510080, China; Beijing Key Laboratory of Molecular Imaging, Beijing 100190, China","Wang S., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China; Zhou M., Stanford Center for Biomedical Informatics Research (BMIR), Department of Medicine, Stanford University, CA 94305, United States; Liu Z., Guangdong General Hospital, Guangzhou, Guangdong 510080, China; Liu Z., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China; Gu D., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China; Zang Y., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China; Dong D., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China; Gevaert O., Stanford Center for Biomedical Informatics Research (BMIR), Department of Medicine, Stanford University, CA 94305, United States; Tian J., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, University of Chinese Academy of Sciences, Beijing 100049, China, Beijing Key Laboratory of Molecular Imaging, Beijing 100190, China","Accurate lung nodule segmentation from computed tomography (CT) images is of great importance for image-driven lung cancer analysis. However, the heterogeneity of lung nodules and the presence of similar visual characteristics between nodules and their surroundings make it difficult for robust nodule segmentation. In this study, we propose a data-driven model, termed the Central Focused Convolutional Neural Networks (CF-CNN), to segment lung nodules from heterogeneous CT images. Our approach combines two key insights: 1) the proposed model captures a diverse set of nodule-sensitive features from both 3-D and 2-D CT images simultaneously; 2) when classifying an image voxel, the effects of its neighbor voxels can vary according to their spatial locations. We describe this phenomenon by proposing a novel central pooling layer retaining much information on voxel patch center, followed by a multi-scale patch learning strategy. Moreover, we design a weighted sampling to facilitate the model training, where training samples are selected according to their degree of segmentation difficulty. The proposed method has been extensively evaluated on the public LIDC dataset including 893 nodules and an independent dataset with 74 nodules from Guangdong General Hospital (GDGH). We showed that CF-CNN achieved superior segmentation performance with average dice scores of 82.15% and 80.02% for the two datasets respectively. Moreover, we compared our results with the inter-radiologists consistency on LIDC dataset, showing a difference in average dice score of only 1.98%. © 2017","Computer-aided diagnosis; Convolutional neural networks; Deep learning; Lung nodule segmentation","Diagnosis, Computer-Assisted; Humans; Lung Neoplasms; Machine Learning; Neural Networks (Computer); Sensitivity and Specificity; Tomography, X-Ray Computed; Biological organs; Computer aided diagnosis; Computer aided instruction; Convolution; Deep learning; Image segmentation; Neural networks; Convolutional neural network; Data-driven model; General hospitals; Learning strategy; Lung nodule segmentation; Nodule segmentation; Segmentation performance; Sensitive features; Article; comparative study; computer assisted tomography; controlled study; human; image analysis; image processing; lung nodule; outcome assessment; priority journal; artificial neural network; computer assisted diagnosis; diagnostic imaging; lung tumor; machine learning; procedures; sensitivity and specificity; x-ray computed tomography; Computerized tomography","Elsevier B.V.","13618415","","MIAEC","28688283","Article","Scopus","2-s2.0-85021726055"
"Blaes S.; Burwick T.","Blaes, Sebastian (58547697100); Burwick, Thomas (23666445000)","58547697100; 23666445000","Few-shot learning in deep networks through global prototyping","2017","Neural Networks","18","10.1016/j.neunet.2017.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026747988&doi=10.1016%2fj.neunet.2017.07.001&partnerID=40&md5=93c861102294d1b7f3a2504b8b2d66e5","Frankfurt Institute for Advanced Studies (FIAS), Goethe University Frankfurt, Ruth-Moufang-Str. 1, Frankfurt am Main, 60438, Germany; Maastricht Centre for Systems Biology (MaCSBio), Maastricht University, P.O. Box 616, Maastricht, 6200, MD, Netherlands","Blaes S., Frankfurt Institute for Advanced Studies (FIAS), Goethe University Frankfurt, Ruth-Moufang-Str. 1, Frankfurt am Main, 60438, Germany; Burwick T., Frankfurt Institute for Advanced Studies (FIAS), Goethe University Frankfurt, Ruth-Moufang-Str. 1, Frankfurt am Main, 60438, Germany, Maastricht Centre for Systems Biology (MaCSBio), Maastricht University, P.O. Box 616, Maastricht, 6200, MD, Netherlands","Training a deep convolution neural network (CNN) to succeed in visual object classification usually requires a great number of examples. Here, starting from such a pre-learned CNN, we study the task of extending the network to classify additional categories on the basis of only few examples (“few-shot learning”). We find that a simple and fast prototype-based learning procedure in the global feature layers (“Global Prototype Learning”, GPL) leads to some remarkably good classification results for a large portion of the new classes. It requires only up to ten examples for the new classes to reach a plateau in performance. To understand this few-shot learning performance resulting from GPL as well as the performance of the original network, we use the t-SNE method (Maaten and Hinton, 2008) to visualize clusters of object category examples. This reveals the strong connection between classification performance and data distribution and explains why some new categories only need few examples for learning while others resist good classification results even when trained with many more examples. © 2017 Elsevier Ltd","Convolutional Neural Networks; Deep Learning; Few-Shot Learning; Object Recognition; Transfer Learning","Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Convolution; Deep learning; Learning systems; Neural networks; Object recognition; Classification performance; Classification results; Convolution neural network; Convolutional neural network; Few-Shot Learning; Prototype-based learning; Transfer learning; Visual object classification; algorithm; Article; artificial neural network; classification; classifier; controlled study; deep convolution neural network; few shot learning; global prototype learning; information processing; learning; multifactor dimensionality reduction; priority journal; automated pattern recognition; machine learning; procedures; Deep neural networks","Elsevier Ltd","08936080","","NNETE","28793243","Article","Scopus","2-s2.0-85026747988"
"Fiannaca A.; La Rosa M.; La Paglia L.; Rizzo R.; Urso A.","Fiannaca, Antonino (23396462500); La Rosa, Massimo (23389564300); La Paglia, Laura (57213540435); Rizzo, Riccardo (8886626300); Urso, Alfonso (6602428079)","23396462500; 23389564300; 57213540435; 8886626300; 6602428079","NRC: Non-coding RNA Classifier based on structural features","2017","BioData Mining","49","10.1186/s13040-017-0148-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026541335&doi=10.1186%2fs13040-017-0148-2&partnerID=40&md5=3323ed9e1f36e64fc15dd6b35f86bb5c","ICAR-CNR, National Research Council of Italy, Via Ugo La Malfa, Palermo, 90146, Italy","Fiannaca A., ICAR-CNR, National Research Council of Italy, Via Ugo La Malfa, Palermo, 90146, Italy; La Rosa M., ICAR-CNR, National Research Council of Italy, Via Ugo La Malfa, Palermo, 90146, Italy; La Paglia L., ICAR-CNR, National Research Council of Italy, Via Ugo La Malfa, Palermo, 90146, Italy; Rizzo R., ICAR-CNR, National Research Council of Italy, Via Ugo La Malfa, Palermo, 90146, Italy; Urso A., ICAR-CNR, National Research Council of Italy, Via Ugo La Malfa, Palermo, 90146, Italy","Motivation: Non-coding RNA (ncRNA) are small non-coding sequences involved in gene expression regulation of many biological processes and diseases. The recent discovery of a large set of different ncRNAs with biologically relevant roles has opened the way to develop methods able to discriminate between the different ncRNA classes. Moreover, the lack of knowledge about the complete mechanisms in regulative processes, together with the development of high-throughput technologies, has required the help of bioinformatics tools in addressing biologists and clinicians with a deeper comprehension of the functional roles of ncRNAs. In this work, we introduce a new ncRNA classification tool, nRC (non-coding RNA Classifier). Our approach is based on features extraction from the ncRNA secondary structure together with a supervised classification algorithm implementing a deep learning architecture based on convolutional neural networks. Results: We tested our approach for the classification of 13 different ncRNA classes. We obtained classification scores, using the most common statistical measures. In particular, we reach an accuracy and sensitivity score of about 74%. Conclusion: The proposed method outperforms other similar classification methods based on secondary structure features and machine learning algorithms, including the RNAcon tool that, to date, is the reference classifier. nRC tool is freely available as a docker image at https://hub.docker.com/r/tblab/nrc/. The source code of nRC tool is also available at https://github.com/IcarPA-TBlab/nrc. © 2017 The Author(s).","Classification; Deep learning; ncRNA; Structural features","microRNA; ribosome RNA; transfer RNA; untranslated RNA; Article; artificial neural network; bioinformatics; classification algorithm; classifier; convolutional neural network; learning algorithm; machine learning; measurement accuracy; priority journal; protein secondary structure; RNA extraction; RNA sequence; RNA structure; sensitivity analysis; statistical analysis; validation process","BioMed Central Ltd.","17560381","","","","Article","Scopus","2-s2.0-85026541335"
"Bu S.; Wang L.; Han P.; Liu Z.; Li K.","Bu, Shuhui (24479271800); Wang, Lei (57196334752); Han, Pengcheng (56182011800); Liu, Zhenbao (55635378800); Li, Ke (57326566800)","24479271800; 57196334752; 56182011800; 55635378800; 57326566800","3D shape recognition and retrieval based on multi-modality deep learning","2017","Neurocomputing","40","10.1016/j.neucom.2016.06.088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014534738&doi=10.1016%2fj.neucom.2016.06.088&partnerID=40&md5=b1f5e1d79de91f8ef46b2f877396ad5c","Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China; Information Engineering University, Zhengzhou, 450001, Henan, China","Bu S., Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China; Wang L., Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China; Han P., Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China; Liu Z., Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China; Li K., Information Engineering University, Zhengzhou, 450001, Henan, China","For 3D shape analysis, an effective and efficient feature is the key to popularize its applications in 3D domain where the major challenge lies in designing an effective high-level feature. The three-dimensional shape contains various useful information including visual information, geometric relationships, and other type properties. Thus the strategy of exploring these characteristics is the core of extracting effective 3D shape features. In this paper, we propose a novel 3D feature learning framework which combines different modality data effectively to promote the discriminability of uni-modal feature by using deep learning. The geometric information and visual information are extracted by Convolutional Neural Networks (CNNs) and Convolutional Deep Belief Networks (CDBNs), respectively, and then two independent Deep Belief Networks (DBNs) are employed to learn high-level features from geometric and visual features. Finally, a Restricted Boltzmann Machine (RBM) is trained for mining the deep correlations between different modalities. Extensive experiments demonstrate that the proposed framework achieves better performance. © 2017 Elsevier B.V.","3D shape; Deep learning; Multi modality; Recognition; Retrieval","Convolution; Convolutional neural networks; Geometry; 3-D shape; Geometric information; Geometric relationships; Multi modality; Recognition; Restricted boltzmann machine; Retrieval; Three-dimensional shape; Article; artificial neural network; automated pattern recognition; classifier; convolutional deep belief network; convolutional neural network; data extraction; data mining; deep learning; image analysis; image retrieval; machine learning; multimedia; priority journal; restricted Boltzmann machine; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85014534738"
"Fan Y.; Levine M.D.; Wen G.; Qiu S.","Fan, Yaxiang (55876915300); Levine, Martin D. (7404035243); Wen, Gongjian (7102510641); Qiu, Shaohua (56178432800)","55876915300; 7404035243; 7102510641; 56178432800","A deep neural network for real-time detection of falling humans in naturally occurring scenes","2017","Neurocomputing","79","10.1016/j.neucom.2017.02.082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018714168&doi=10.1016%2fj.neucom.2017.02.082&partnerID=40&md5=1432388759b5599091cc519b26cacaff","Science and Technology on Automatic Target Recognition Laboratory (ATR), National University of Defense Technology, Changsha, China; Department of Electrical and Computer Engineering, Center for Intelligent Machines, McGill University, 3480 University Street, Montreal, Canada","Fan Y., Science and Technology on Automatic Target Recognition Laboratory (ATR), National University of Defense Technology, Changsha, China; Levine M.D., Department of Electrical and Computer Engineering, Center for Intelligent Machines, McGill University, 3480 University Street, Montreal, Canada; Wen G., Science and Technology on Automatic Target Recognition Laboratory (ATR), National University of Defense Technology, Changsha, China; Qiu S., Science and Technology on Automatic Target Recognition Laboratory (ATR), National University of Defense Technology, Changsha, China","We introduce a novel approach to the problem of human fall detection in naturally occurring scenes. This is important because falling incidents cause thousands of deaths every year and vision-based approaches offer a promising and effective way to detect falls. To address this challenging issue, we regard it as an example of action detection and propose to also locate its temporal extent. We achieve this by exploiting the effectiveness of deep networks. In the training stage, the trimmed video clips of four phases (standing, falling, fallen and not moving) in a fall are converted to four categories of so-called dynamic image to train a deep ConvNet that scores and predicts the label of each dynamic image. In the testing stage, a set of sub-videos is generated using a sliding window on an untrimmed video that converts it to multiple dynamic images. Based on the predicted label of each dynamic image by the trained deep ConvNet, the videos are classified as falling or not by a “standing watch” for a situation consisting of the four sequential phases. In order to localize the temporal extent of the event, we propose a difference score method (DSM) based on adjacent dynamic images in the temporal sequence. We collect a new dataset, called the YouTube Fall Dataset (YTFD), which contains 430 falling incidents and 176 normal activities and use it to learn the deep network to detect falling humans. We perform experiments on datasets of varying complexity: Le2i fall detection dataset, multiple cameras fall dataset, high quality fall simulation dataset and our own YouTube Fall Dataset. The results demonstrate the effectiveness and efficiency of our approach. © 2017 Elsevier B.V.","Action detection; Convolutional neural network; Deep learning; Dynamic image; Fall detection; Temporal location","Communication channels (information theory); Deep learning; Neural networks; Signal detection; Video cameras; Convolutional neural network; Dynamic images; Effectiveness and efficiencies; Fall detection; Human fall detection; Naturally occurring; Real-time detection; Vision-based approaches; Article; artificial neural network; deep learning; falling; false negative result; false positive result; human; illumination; information processing; learning; long short term memory; long term memory; prediction; priority journal; recurrent neural network; sensitivity and specificity; short term memory; simulation; sudden cardiac death; support vector machine; terrorism; Deep neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85018714168"
"Li H.; Giger M.L.; Huynh B.Q.; Antropova N.O.","Li, Hui (56986807700); Giger, Maryellen L. (7103040897); Huynh, Benjamin Q. (57210935985); Antropova, Natalia O. (57190279968)","56986807700; 7103040897; 57210935985; 57190279968","Deep learning in breast cancer risk assessment: Evaluation of convolutional neural networks on a clinical dataset of full-field digital mammograms","2017","Journal of Medical Imaging","74","10.1117/1.JMI.4.4.041304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029820268&doi=10.1117%2f1.JMI.4.4.041304&partnerID=40&md5=ac28e4cce8354d78b4b8d63d411368e2","University of Chicago, Department of Radiology, Chicago, IL, United States","Li H., University of Chicago, Department of Radiology, Chicago, IL, United States; Giger M.L., University of Chicago, Department of Radiology, Chicago, IL, United States; Huynh B.Q., University of Chicago, Department of Radiology, Chicago, IL, United States; Antropova N.O., University of Chicago, Department of Radiology, Chicago, IL, United States","To evaluate deep learning in the assessment of breast cancer risk in which convolutional neural networks (CNNs) with transfer learning are used to extract parenchymal characteristics directly from full-field digital mammographic (FFDM) images instead of using computerized radiographic texture analysis (RTA), 456 clinical FFDM cases were included: a ""high-risk"" BRCA1/2 gene-mutation carriers dataset (53 cases), a ""high-risk"" unilateral cancer patients dataset (75 cases), and a ""low-risk dataset"" (328 cases). Deep learning was compared to the use of features from RTA, as well as to a combination of both in the task of distinguishing between high- and low-risk subjects. Similar classification performances were obtained using CNN [area under the curve (AUC)=0.83; standard error (SE)=0.03] and RTA (AUC=0.82; SE=0.03) in distinguishing BRCA1/2 carriers and low-risk women. However, in distinguishing unilateral cancer patients and low-risk women, performance was significantly greater with CNN (AUC=0.82; SE=0.03) compared to RTA (AUC=0.73; SE=0.03). Fusion classifiers performed significantly better than the RTA-alone classifiers with AUC values of 0.86 and 0.84 in differentiating BRCA1/2 carriers from low-risk women and unilateral cancer patients from low-risk women, respectively. In conclusion, deep learning extracted parenchymal characteristics from FFDMs performed as well as, or better than, conventional texture analysis in the task of distinguishing between cancer risk populations. © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","breast cancer risk assessment; convolutional neural network; deep learning; full-field digital mammogram; mammographic parenchymal patterns; radiographic texture analysis; transfer learning","adult; area under the curve; Article; breast cancer; cancer risk; controlled study; convolutional neural network; digital mammography; female; gene mutation; human; learning; low risk population; machine learning; major clinical study; retrospective study; risk assessment; tumor suppressor gene","SPIE","23294302","","","","Article","Scopus","2-s2.0-85029820268"
"Liu C.; Cui P.; Huang T.","Liu, Chenglin (55762420200); Cui, Peng (55925440000); Huang, Tao (56542142100)","55762420200; 55925440000; 56542142100","Identification of cell cycle-regulated genes by convolutional neural network","2017","Combinatorial Chemistry and High Throughput Screening","9","10.2174/1386207320666170417144937","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033569992&doi=10.2174%2f1386207320666170417144937&partnerID=40&md5=41bfde9e2af34374f9275e130101a1ff","School of Life Sciences and Biotechnology, Shanghai Jiao Tong University, 800 Dongchuan Rd, Minhang, Shanghai, 200240, China; Institute of Health Sciences, Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences, Shanghai, 200031, China; Department of Bioinformatics, SJTU-Yale Joint Center for Biostatistics, Shanghai Jiao Tong University, 800 Dongchuan Rd, Minhang, Shanghai, 200240, China","Liu C., School of Life Sciences and Biotechnology, Shanghai Jiao Tong University, 800 Dongchuan Rd, Minhang, Shanghai, 200240, China; Cui P., School of Life Sciences and Biotechnology, Shanghai Jiao Tong University, 800 Dongchuan Rd, Minhang, Shanghai, 200240, China, Department of Bioinformatics, SJTU-Yale Joint Center for Biostatistics, Shanghai Jiao Tong University, 800 Dongchuan Rd, Minhang, Shanghai, 200240, China; Huang T., Institute of Health Sciences, Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences, Shanghai, 200031, China","Background: The cell cycle-regulated genes express periodically with the cell cycle stages, and the identification and study of these genes can provide a deep understanding of the cell cycle process. Large false positives and low overlaps are big problems in cell cycle-regulated gene detection. Methods: Here, a computational framework called DLGene was proposed for cell cycle-regulated gene detection. It is based on the convolutional neural network, a deep learning algorithm representing raw form of data pattern without assumption of their distribution. First, the expression data was transformed to categorical state data to denote the changing state of gene expression, and four different expression patterns were revealed for the reported cell cycle-regulated genes. Then, DLGene was applied to discriminate the non-cell cycle gene and the four subtypes of cell cycle genes. Its performances were compared with six traditional machine learning methods. At last, the biological functions of representative cell cycle genes for each subtype are analyzed. Results: Our method showed better and more balanced performance of sensitivity and specificity comparing to other machine learning algorithms. The cell cycle genes had very different expression pattern with non-cell cycle genes and among the cell-cycle genes, there were four subtypes. Our method not only detects the cell cycle genes, but also describes its expression pattern, such as when its highest expression level is reached and how it changes with time. For each type, we analyzed the biological functions of the representative genes and such results provided novel insight to the cell cycle mechanisms. © 2017 Bentham Science Publishers.","Cell cycle; Cell cycle-regulated genes; Classification; Convolutional neural network; Deep learning; Machine learning","Algorithms; Cell Cycle Proteins; Databases, Genetic; Neural Networks (Computer); Saccharomyces cerevisiae; Saccharomyces cerevisiae Proteins; cell cycle protein; Saccharomyces cerevisiae protein; article; cell cycle; convolutional neural network; deep learning; sensitivity and specificity; algorithm; artificial neural network; genetic database; genetics; metabolism; Saccharomyces cerevisiae","Bentham Science Publishers","13862073","","CCHSF","28413974","Article","Scopus","2-s2.0-85033569992"
"Henglin M.; Stein G.; Hushcha P.V.; Snoek J.; Wiltschko A.B.; Cheng S.","Henglin, Mir (54880548600); Stein, Gillian (57196021902); Hushcha, Pavel V. (57196022224); Snoek, Jasper (15129127600); Wiltschko, Alexander B. (24402165100); Cheng, Susan (35602819200)","54880548600; 57196021902; 57196022224; 15129127600; 24402165100; 35602819200","Machine Learning Approaches in Cardiovascular Imaging","2017","Circulation: Cardiovascular Imaging","94","10.1161/CIRCIMAGING.117.005614","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031011688&doi=10.1161%2fCIRCIMAGING.117.005614&partnerID=40&md5=6811fe31b4686bdae2e46a714d70911c","Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, 75 Francis St, Boston, MA, United States; Google Brain, Google Inc, Cambridge, MA, United States; Framingham Heart Study, MA, United States","Henglin M., Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, 75 Francis St, Boston, MA, United States; Stein G., Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, 75 Francis St, Boston, MA, United States; Hushcha P.V., Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, 75 Francis St, Boston, MA, United States; Snoek J., Google Brain, Google Inc, Cambridge, MA, United States; Wiltschko A.B., Google Brain, Google Inc, Cambridge, MA, United States; Cheng S., Cardiovascular Division, Brigham and Women's Hospital, Harvard Medical School, 75 Francis St, Boston, MA, United States, Framingham Heart Study, MA, United States","Cardiovascular imaging technologies continue to increase in their capacity to capture and store large quantities of data. Modern computational methods, developed in the field of machine learning, offer new approaches to leveraging the growing volume of imaging data available for analyses. Machine learning methods can now address data-related problems ranging from simple analytic queries of existing measurement data to the more complex challenges involved in analyzing raw images. To date, machine learning has been used in 2 broad and highly interconnected areas: Automation of tasks that might otherwise be performed by a human and generation of clinically important new knowledge. Most cardiovascular imaging studies have focused on task-oriented problems, but more studies involving algorithms aimed at generating new clinical insights are emerging. Continued expansion in the size and dimensionality of cardiovascular imaging databases is driving strong interest in applying powerful deep learning methods, in particular, to analyze these data. Overall, the most effective approaches will require an investment in the resources needed to appropriately prepare such large data sets for analyses. Notwithstanding current technical and logistical challenges, machine learning and especially deep learning methods have much to offer and will substantially impact the future practice and science of cardiovascular imaging. © 2017 American Heart Association, Inc.","algorithms; artificial intelligence; automation; workflow","Algorithms; Automation; Cardiovascular Diseases; Diagnostic Imaging; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Predictive Value of Tests; Prognosis; Reproducibility of Results; Severity of Illness Index; Workflow; Article; artificial intelligence; diffusion tensor imaging; human; hypertrophy; image analysis; image quality; machine learning; mortality rate; nuclear magnetic resonance imaging; patient care; pneumonia; priority journal; speech discrimination; ST segment elevation myocardial infarction; ultrasound; algorithm; automation; Cardiovascular Diseases; computer assisted diagnosis; diagnostic imaging; predictive value; procedures; prognosis; reproducibility; severity of illness index; workflow","Lippincott Williams and Wilkins","19419651","","","28956772","Article","Scopus","2-s2.0-85031011688"
"Yu S.; Wu Y.; Li W.; Song Z.; Zeng W.","Yu, Shaoyong (56171292600); Wu, Yun (56093449100); Li, Wei (56975564100); Song, Zhijun (36769310000); Zeng, Wenhua (57204698934)","56171292600; 56093449100; 56975564100; 36769310000; 57204698934","A model for fine-grained vehicle classification based on deep learning","2017","Neurocomputing","92","10.1016/j.neucom.2016.09.116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012926200&doi=10.1016%2fj.neucom.2016.09.116&partnerID=40&md5=fdfacf537d2c8797a6980f3e86044d51","Department of Cognitive Science, Xiamen University, Xiamen, 361000, China; School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, 361024, China; The 28th Research Institute of China Electronics Technology Group Corporation, Nanjing, 210007, China","Yu S., Department of Cognitive Science, Xiamen University, Xiamen, 361000, China, School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, 361024, China; Wu Y., School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, 361024, China; Li W., School of Computer and Information Engineering, Xiamen University of Technology, Xiamen, 361024, China; Song Z., The 28th Research Institute of China Electronics Technology Group Corporation, Nanjing, 210007, China; Zeng W., Department of Cognitive Science, Xiamen University, Xiamen, 361000, China","A model for fine-grained vehicle classification based on deep learning is proposed to handle complicated transportation scene. This model comprises of two parts, vehicle detection model and vehicle fine-grained detection and classification model. Faster R-CNN method is adopted in vehicle detection model to extract single vehicle images from an image with clutter background which may contains serval vehicles. This step provides data for the next classification model. In vehicle fine-grained classification model, an image contains only one vehicle is fed into a CNN model to produce a feature, then a joint bayesian network is used to implement the fine-grained classification process. Experiments show that vehicle's make and model can be recognized from transportation images effectively by using our method. Furthermore,in order to build a large scale database easier, this paper comes up with a novel network collaborative annotation mechanism. © 2017","Deep learning; Fine-graind classification; Network collabrative annotation; Vehicle detection","Bayesian networks; Image processing; Object detection; Vehicles; Classification models; Classification process; Clutter background; Fine grained; Large-scale database; Vehicle classification; Vehicle detection; Vehicle images; accuracy; Article; artificial neural network; Bayesian learning; classification algorithm; data analysis; image analysis; mathematical computing; mathematical model; motor vehicle; normal distribution; priority journal; support vector machine; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85012926200"
"Wu S.; Oerlemans A.; Bakker E.M.; Lew M.S.","Wu, Song (55925404400); Oerlemans, Ard (23036132300); Bakker, Erwin M. (7202451935); Lew, Michael S. (57208852387)","55925404400; 23036132300; 7202451935; 57208852387","Deep binary codes for large scale image retrieval","2017","Neurocomputing","25","10.1016/j.neucom.2016.12.070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012906614&doi=10.1016%2fj.neucom.2016.12.070&partnerID=40&md5=209b4e5f9df3a088b213bc8cab45888d","LIACS Media Lab, Leiden University, Niels Bohrweg 1, Leiden, Netherlands; VDG Security BV, Zoetermeer, Netherlands","Wu S., LIACS Media Lab, Leiden University, Niels Bohrweg 1, Leiden, Netherlands; Oerlemans A., VDG Security BV, Zoetermeer, Netherlands; Bakker E.M., LIACS Media Lab, Leiden University, Niels Bohrweg 1, Leiden, Netherlands; Lew M.S., LIACS Media Lab, Leiden University, Niels Bohrweg 1, Leiden, Netherlands","Recent studies have shown that image representations built upon deep convolutional layers in Convolutional Neural Networks (CNNs) have strong discriminative characteristics. In this paper, we present a novel and effective method to create compact binary codes (deep binary codes) based on deep convolutional features for image retrieval. Deep binary codes are generated by comparing the response from each feature map and the average response across all the feature maps on the deep convolutional layers. Additionally, a spatial cross-summing strategy is proposed to directly generate bit-scalable binary codes. As the deep binary codes on different deep layers can be obtained by passing the image through the CNN and each of them makes a different contribution to the search accuracy, we then present a dynamic, on-the-fly late fusion approach where the top N high quality search scores from deep binary codes are automatically determined online and fused to further enhance the retrieval precision. Two strengths of the proposed methods are that the generation of deep binary codes is based on a generic model, which does not require additional training for new image domains, and that the dynamic late fusion scheme is query adaptive. Extensive experimental results on well known benchmarks show that the performance of deep binary codes are competitive with state-of-the-art approaches for large scale image retrieval. Moreover, it is shown that the dynamic late fusion scheme significantly enhances the search accuracy. © 2017 Elsevier B.V.","Convolutional neural network; Deep binary codes; Large scale image search; Late fusion","Benchmarking; Binary codes; Bins; Codes (symbols); Convolution; Deep neural networks; Image fusion; Neural networks; Convolutional neural network; Generic modeling; Image representations; Image search; Late fusion; On the flies; Search accuracy; State-of-the-art approach; accuracy; Article; artificial neural network; benchmarking; classification; comparative study; controlled study; convolutional neural network; deep binary code; dynamic late fusion; error; hashing learning; image analysis; image classification; image representation; image retrieval; imaging and display; large scale image retrieval; machine learning; priority journal; quality control; quantization error; retrieval precision; spatial cross summing; statistical analysis; statistical concepts; Image retrieval","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85012906614"
"Veiga J.J.D.; O'reilly M.; Whelan D.; Caulfield B.; Ward T.E.","Veiga, Jose Juan Dominguez (57192092295); O'reilly, Martin (57143718400); Whelan, Darragh (56647778900); Caulfield, Brian (6602906583); Ward, Tomas E. (7402100229)","57192092295; 57143718400; 56647778900; 6602906583; 7402100229","Feature-free activity classification of inertial sensor data with machine vision techniques: Method, development, and evaluation","2017","JMIR mHealth and uHealth","22","10.2196/mhealth.7521","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050338163&doi=10.2196%2fmhealth.7521&partnerID=40&md5=dd2f814ddd3e99ca20fda3790c05ee0b","Insight Centre for Data Analytics, Department of Electronic Engineering, Maynooth University, Maynooth, Ireland; Insight Centre for Data Analytics, University College Dublin, Dublin, Ireland","Veiga J.J.D., Insight Centre for Data Analytics, Department of Electronic Engineering, Maynooth University, Maynooth, Ireland; O'reilly M., Insight Centre for Data Analytics, University College Dublin, Dublin, Ireland; Whelan D., Insight Centre for Data Analytics, University College Dublin, Dublin, Ireland; Caulfield B., Insight Centre for Data Analytics, University College Dublin, Dublin, Ireland; Ward T.E., Insight Centre for Data Analytics, Department of Electronic Engineering, Maynooth University, Maynooth, Ireland","Background: Inertial sensors are one of the most commonly used sources of data for human activity recognition (HAR) and exercise detection (ED) tasks. The time series produced by these sensors are generally analyzed through numerical methods. Machine learning techniques such as random forests or support vector machines are popular in this field for classification efforts, but they need to be supported through the isolation of a potentially large number of additionally crafted features derived from the raw data. This feature preprocessing step can involve nontrivial digital signal processing (DSP) techniques. However, in many cases, the researchers interested in this type of activity recognition problems do not possess the necessary technical background for this feature-set development. Objective: The study aimed to present a novel application of established machine vision methods to provide interested researchers with an easier entry path into the HAR and ED fields. This can be achieved by removing the need for deep DSP skills through the use of transfer learning. This can be done by using a pretrained convolutional neural network (CNN) developed for machine vision purposes for exercise classification effort. The new method should simply require researchers to generate plots of the signals that they would like to build classifiers with, store them as images, and then place them in folders according to their training label before retraining the network. Methods: We applied a CNN, an established machine vision technique, to the task of ED. Tensorflow, a high-level framework for machine learning, was used to facilitate infrastructure needs. Simple time series plots generated directly from accelerometer and gyroscope signals are used to retrain an openly available neural network (Inception), originally developed for machine vision tasks. Data from 82 healthy volunteers, performing 5 different exercises while wearing a lumbar-worn inertial measurement unit (IMU), was collected. The ability of the proposed method to automatically classify the exercise being completed was assessed using this dataset. For comparative purposes, classification using the same dataset was also performed using the more conventional approach of feature-extraction and classification using random forest classifiers. Results: With the collected dataset and the proposed method, the different exercises could be recognized with a 95.89% (3827/3991) accuracy, which is competitive with current state-of-the-art techniques in ED. Conclusions: The high level of accuracy attained with the proposed approach indicates that the waveform morphologies in the time-series plots for each of the exercises is sufficiently distinct among the participants to allow the use of machine vision approaches. The use of high-level machine learning frameworks, coupled with the novel use of machine vision techniques instead of complex manually crafted features, may facilitate access to research in the HAR field for individuals without extensive digital signal processing or machine learning backgrounds. ©Jose Juan Dominguez Veiga, Martin O'Reilly, Darragh Whelan, Brian Caulfield, Tomas E Ward.","Biofeedback; Exercise; Machine learning","","JMIR Publications Inc.","22915222","","","","Article","Scopus","2-s2.0-85050338163"
"Alex V.; Vaidhya K.; Thirunavukkarasu S.; Kesavadas C.; Krishnamurthi G.","Alex, Varghese (57188548063); Vaidhya, Kiran (57188549853); Thirunavukkarasu, Subramaniam (57188549735); Kesavadas, Chandrasekharan (6603428049); Krishnamurthi, Ganapathy (6601974005)","57188548063; 57188549853; 57188549735; 6603428049; 6601974005","Semisupervised learning using denoising autoencoders for brain lesion detection and segmentation","2017","Journal of Medical Imaging","51","10.1117/1.JMI.4.4.041311","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040465671&doi=10.1117%2f1.JMI.4.4.041311&partnerID=40&md5=b6a1f838382c2c2837d20e4bd8c70582","Indian Institute of Technology Madras, Department of Engineering Design, Chennai, India; Sree Chitra Tirunal Institute for Medical Sciences and Technology, Department of Radiology, Trivandrum, India","Alex V., Indian Institute of Technology Madras, Department of Engineering Design, Chennai, India; Vaidhya K., Indian Institute of Technology Madras, Department of Engineering Design, Chennai, India; Thirunavukkarasu S., Indian Institute of Technology Madras, Department of Engineering Design, Chennai, India; Kesavadas C., Sree Chitra Tirunal Institute for Medical Sciences and Technology, Department of Radiology, Trivandrum, India; Krishnamurthi G., Indian Institute of Technology Madras, Department of Engineering Design, Chennai, India","The work explores the use of denoising autoencoders (DAEs) for brain lesion detection, segmentation, and false-positive reduction. Stacked denoising autoencoders (SDAEs) were pretrained using a large number of unlabeled patient volumes and fine-tuned with patches drawn from a limited number of patients (n=20, 40, 65). The results show negligible loss in performance even when SDAE was fine-tuned using 20 labeled patients. Low grade glioma (LGG) segmentation was achieved using a transfer learning approach in which a network pretrained with high grade glioma data was fine-tuned using LGG image patches. The networks were also shown to generalize well and provide good segmentation on unseen BraTS 2013 and BraTS 2015 test data. The manuscript also includes the use of a single layer DAE, referred to as novelty detector (ND). ND was trained to accurately reconstruct nonlesion patches. The reconstruction error maps of test data were used to localize lesions. The error maps were shown to assign unique error distributions to various constituents of the glioma, enabling localization. The ND learns the nonlesion brain accurately as it was also shown to provide good segmentation performance on ischemic brain lesions in images from a different database. © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","brain lesion; deep learning; denoising autoencoder; gliomas; magnetic resonance imaging; stacked denoising autoencoder","Article; controlled study; data base; denoising autoencoder; false negative result; false positive result; glioma; human; nerve cell; stacked denoising autoencoder; supervised machine learning","SPIE","23294302","","","","Article","Scopus","2-s2.0-85040465671"
"Zhang C.; Li R.; Huang Q.; Tian Q.","Zhang, Chunjie (55860215300); Li, Ruiying (57205612133); Huang, Qingming (8435766200); Tian, Qi (7102891959)","55860215300; 57205612133; 8435766200; 7102891959","Hierarchical deep semantic representation for visual categorization","2017","Neurocomputing","14","10.1016/j.neucom.2016.11.065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012888589&doi=10.1016%2fj.neucom.2016.11.065&partnerID=40&md5=7dd8ad99c5c39af56db445d376ab9c60","Institute of Automation, Chinese Academy of Sciences, 100190, Beijing, China; School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China; Key Lab of Intell. Info. Process, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Department of Computer Sciences, University of Texas at San Antonio, 78249, TX, United States","Zhang C., Institute of Automation, Chinese Academy of Sciences, 100190, Beijing, China, School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China; Li R., School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China; Huang Q., School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China, Key Lab of Intell. Info. Process, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Tian Q., Department of Computer Sciences, University of Texas at San Antonio, 78249, TX, United States","Visual features are unsatisfactory to effectively describe the visual semantics. However, single layer based semantic modeling may be not able to cope with complicated semantic contents. In this paper, we propose Hierarchical Deep Semantic Representation (H-DSR), a hierarchical framework which combines semantic context modeling with visual features. First, the input image is sampled with spatially fixed grids. Deep features are then extracted for each sample in particular location. Second, using pre-learned classifiers, a detection response map is constructed for each patch. Semantic representation is then extracted from the map, which have a sense of latent semantic context. We combine the semantic and visual representations for joint representation. Third, a hierarchical deep semantic representation is built with recurrent reconstructions using three layers. The concatenated visual and semantic representations are used as the inputs of subsequent layers for semantic representation extraction. Finally, we verify the effectiveness of H-DSR for visual categorization on two publicly available datasets: Oxford Flowers 17 and UIUC-Sports. Improved performances are obtained over many baseline methods. © 2017 Elsevier B.V.","Image representation; Semantic representation; Visual categorization","Semantic Web; Baseline methods; Image representations; Semantic content; Semantic context; Semantic representation; Visual categorization; Visual representations; Visual semantics; Article; artificial neural network; calculation; classifier; controlled study; hierarchical deep semantic representation; image analysis; image reconstruction; information processing; machine learning; mathematical analysis; mathematical computing; priority journal; semantic representation; semantics; visual categorization; visual feature; Semantics","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85012888589"
"Teare P.; Fishman M.; Benzaquen O.; Toledano E.; Elnekave E.","Teare, Philip (57194619252); Fishman, Michael (56679181000); Benzaquen, Oshra (25647302700); Toledano, Eyal (57194462707); Elnekave, Eldad (8986227700)","57194619252; 56679181000; 25647302700; 57194462707; 8986227700","Malignancy Detection on Mammography Using Dual Deep Convolutional Neural Networks and Genetically Discovered False Color Input Enhancement","2017","Journal of Digital Imaging","78","10.1007/s10278-017-9993-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021291420&doi=10.1007%2fs10278-017-9993-2&partnerID=40&md5=9cde5e73f913f2dd7581bb9f936bc928","Zebra Medical Vision LTD, Shfayim, Israel; Beth Israel Deaconess Medical Center, Boston, MA, United States; Rabin Medical Center, Petach Tikvah, Israel","Teare P., Zebra Medical Vision LTD, Shfayim, Israel; Fishman M., Beth Israel Deaconess Medical Center, Boston, MA, United States; Benzaquen O., Rabin Medical Center, Petach Tikvah, Israel; Toledano E., Zebra Medical Vision LTD, Shfayim, Israel; Elnekave E., Zebra Medical Vision LTD, Shfayim, Israel, Rabin Medical Center, Petach Tikvah, Israel","Breast cancer is the most prevalent malignancy in the US and the third highest cause of cancer-related mortality worldwide. Regular mammography screening has been attributed with doubling the rate of early cancer detection over the past three decades, yet estimates of mammographic accuracy in the hands of experienced radiologists remain suboptimal with sensitivity ranging from 62 to 87% and specificity from 75 to 91%. Advances in machine learning (ML) in recent years have demonstrated capabilities of image analysis which often surpass those of human observers. Here we present two novel techniques to address inherent challenges in the application of ML to the domain of mammography. We describe the use of genetic search of image enhancement methods, leading us to the use of a novel form of false color enhancement through contrast limited adaptive histogram equalization (CLAHE), as a method to optimize mammographic feature representation. We also utilize dual deep convolutional neural networks at different scales, for classification of full mammogram images and derivative patches combined with a random forest gating network as a novel architectural solution capable of discerning malignancy with a specificity of 0.91 and a specificity of 0.80. To our knowledge, this represents the first automatic stand-alone mammography malignancy detection algorithm with sensitivity and specificity performance similar to that of expert radiologists. © 2017, Society for Imaging Informatics in Medicine.","Convolutional neural networks; Deep learning; Machine learning; Mammography","Algorithms; Breast Neoplasms; Datasets as Topic; Female; Humans; Image Enhancement; Mammography; Neural Networks (Computer); Sensitivity and Specificity; Artificial intelligence; Convolution; Decision trees; Deep learning; Diseases; Education; Genetic algorithms; Learning systems; Mammography; Neural networks; Architectural solutions; Contrast Limited Adaptive Histogram Equalization (CLAHE); Convolutional neural network; Detection algorithm; Early cancer detection; Mammographic features; Mammography screening; Sensitivity and specificity; algorithm; artificial neural network; breast tumor; classification; diagnostic imaging; female; genetics; human; image enhancement; information processing; mammography; procedures; sensitivity and specificity; Deep neural networks","Springer New York LLC","08971889","","JDIME","28656455","Article","Scopus","2-s2.0-85021291420"
"Kooi T.; Karssemeijer N.","Kooi, Thijs (41261813100); Karssemeijer, Nico (24332021400)","41261813100; 24332021400","Classifying symmetrical differences and temporal change for the detection of malignant masses in mammography using deep neural networks","2017","Journal of Medical Imaging","41","10.1117/1.JMI.4.4.044501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032749172&doi=10.1117%2f1.JMI.4.4.044501&partnerID=40&md5=c1267b4a16dadbaede19ffb2f6cd98c8","Radboud UMC Nijmegen, Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Nijmegen, Netherlands","Kooi T., Radboud UMC Nijmegen, Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Nijmegen, Netherlands; Karssemeijer N., Radboud UMC Nijmegen, Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Nijmegen, Netherlands","We investigate the addition of symmetry and temporal context information to a deep convolutional neural network (CNN) with the purpose of detecting malignant soft tissue lesions in mammography. We employ a simple linear mapping that takes the location of a mass candidate and maps it to either the contralateral or prior mammogram, and regions of interest (ROIs) are extracted around each location. Two different architectures are subsequently explored: (1) a fusion model employing two datastreams where both ROIs are fed to the network during training and testing and (2) a stagewise approach where a single ROI CNN is trained on the primary image and subsequently used as a feature extractor for both primary and contralateral or prior ROIs. A shallow gradient boosted tree classifier is then trained on the concatenation of these features and used to classify the joint representation. The baseline yielded an AUC of 0.87 with confidence interval [0.853, 0.893]. For the analysis of symmetrical differences, the first architecture where both primary and contralateral patches are presented during training obtained an AUC of 0.895 with confidence interval [0.877, 0.913], and the second architecture where a new classifier is retrained on the concatenation an AUC of 0.88 with confidence interval [0.859, 0.9]. We found a significant difference between the first architecture and the baseline at high specificity with p 0.02. When using the same architectures to analyze temporal change, we yielded an AUC of 0.884 with confidence interval [0.865, 0.902] for the first architecture and an AUC of 0.879 with confidence interval [0.858, 0.898] in the second setting. Although improvements for temporal analysis were consistent, they were not found to be significant. The results show our proposed method is promising and we suspect performance can greatly be improved when more temporal data become available. ©2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","breast cancer.; computer-aided diagnosis; convolutional neural networks; deep learning; machine learning","Article; breast cancer; comparative study; confidence interval; controlled study; deep neural network; diagnostic test accuracy study; female; human; image analysis; information processing; machine learning; major clinical study; mammography; measurement error; soft tissue cancer; temporal analysis; validation study","SPIE","23294302","","","","Article","Scopus","2-s2.0-85032749172"
"Pound M.P.; Atkinson J.A.; Townsend A.J.; Wilson M.H.; Griffiths M.; Jackson A.S.; Bulat A.; Tzimiropoulos G.; Wells D.M.; Murchie E.H.; Pridmore T.P.; French A.P.","Pound, Michael P. (36823470100); Atkinson, Jonathan A. (55809955300); Townsend, Alexandra J. (57196401578); Wilson, Michael H. (56903382400); Griffiths, Marcus (56652514900); Jackson, Aaron S. (56332674800); Bulat, Adrian (57191432700); Tzimiropoulos, Georgios (18042589100); Wells, Darren M. (36620696000); Murchie, Erik H. (6603351945); Pridmore, Tony P. (6701847105); French, Andrew P. (7202095090)","36823470100; 55809955300; 57196401578; 56903382400; 56652514900; 56332674800; 57191432700; 18042589100; 36620696000; 6603351945; 6701847105; 7202095090","Deep machine learning provides state-of-the-art performance in image-based plant phenotyping","2017","GigaScience","213","10.1093/gigascience/gix083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032854973&doi=10.1093%2fgigascience%2fgix083&partnerID=40&md5=4dc1263cc0476b2c7c9f6d1e3fdee104","School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, United Kingdom; School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, United Kingdom; Centre for Plant Sciences, Faculty of Biological Sciences, University of Leeds, Leeds, LS2 9JT, United Kingdom","Pound M.P., School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, United Kingdom; Atkinson J.A., School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, United Kingdom; Townsend A.J., School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, United Kingdom; Wilson M.H., Centre for Plant Sciences, Faculty of Biological Sciences, University of Leeds, Leeds, LS2 9JT, United Kingdom; Griffiths M., School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, United Kingdom; Jackson A.S., School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, United Kingdom; Bulat A., School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, United Kingdom; Tzimiropoulos G., School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, United Kingdom; Wells D.M., School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, United Kingdom; Murchie E.H., School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, United Kingdom; Pridmore T.P., School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, United Kingdom; French A.P., School of Computer Science, University of Nottingham, Jubilee Campus, Wollaton Road, Nottingham, NG8 1BB, United Kingdom, School of Biosciences, University of Nottingham, Sutton Bonington Campus, Nr Loughborough, LE12 5RD, United Kingdom","In plant phenotyping, it has become important to be able to measure many features on large image sets in order to aid genetic discovery. The size of the datasets, now often captured robotically, often precludes manual inspection, hence the motivation for finding a fully automated approach. Deep learning is an emerging field that promises unparalleled results on many data analysis problems. Building on artificial neural networks, deep approaches have many more hidden layers in the network, and hence have greater discriminative and predictive power. We demonstrate the use of such approaches as part of a plant phenotyping pipeline. We show the success offered by such techniques when applied to the challenging problem of image-based plant phenotyping and demonstrate state-of-the-art results (>97% accuracy) for root and shoot feature identification and localization. We use fully automated trait identification using deep learning to identify quantitative trait loci in root architecture datasets. The majority (12 out of 14) of manually identified quantitative trait loci were also discovered using our automated approach based on deep learning detection to locate plant features. We have shown deep learning-based phenotyping to have very good detection and localization accuracy in validation and testing image sets. We have shown that such features can be used to derive meaningful biological traits, which in turn can be used in quantitative trait loci discovery pipelines. This process can be completely automated. We predict a paradigm shift in image-based phenotyping bought about by such deep learning approaches, given sufficient training sets. © The Author 2017.","Deep learning; Image analysis; Phenotyping; QTL; Root; Shoot","Machine Learning; Phenotype; Plant Roots; Plant Shoots; Plants; Quantitative Trait Loci; Triticum; Article; artificial neural network; automation; classification; deep machine learning; image analysis; image processing; learning algorithm; machine learning; nonhuman; phenotype; plant; plant root; priority journal; quantitative trait locus; shoot; validation process; classification; genetics; phenotype; plant; wheat","Oxford University Press","2047217X","","","29020747","Article","Scopus","2-s2.0-85032854973"
"Sher G.; Zhi D.; Zhang S.","Sher, Gene (48161857400); Zhi, Degui (57211105610); Zhang, Shaojie (36641041500)","48161857400; 57211105610; 36641041500","DRREP: Deep ridge regressed epitope predictor","2017","BMC Genomics","21","10.1186/s12864-017-4024-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030313529&doi=10.1186%2fs12864-017-4024-8&partnerID=40&md5=e8370bdccdc9627edb2319758693d55a","University of Central Florida, Department of Computer Science, Orlando, FL, United States; University of Texas Health Science Center at Houston, School of Biomedical Informatics, Houston, TX, United States","Sher G., University of Central Florida, Department of Computer Science, Orlando, FL, United States; Zhi D., University of Texas Health Science Center at Houston, School of Biomedical Informatics, Houston, TX, United States; Zhang S., University of Central Florida, Department of Computer Science, Orlando, FL, United States","Introduction: The ability to predict epitopes plays an enormous role in vaccine development in terms of our ability to zero in on where to do a more thorough in-vivo analysis of the protein in question. Though for the past decade there have been numerous advancements and improvements in epitope prediction, on average the best benchmark prediction accuracies are still only around 60%. New machine learning algorithms have arisen within the domain of deep learning, text mining, and convolutional networks. This paper presents a novel analytically trained and string kernel using deep neural network, which is tailored for continuous epitope prediction, called: Deep Ridge Regressed Epitope Predictor (DRREP). Results: DRREP was tested on long protein sequences from the following datasets: SARS, Pellequer, HIV, AntiJen, and SEQ194. DRREP was compared to numerous state of the art epitope predictors, including the most recently published predictors called LBtope and DMNLBE. Using area under ROC curve (AUC), DRREP achieved a performance improvement over the best performing predictors on SARS (13.7%), HIV (8.9%), Pellequer (1.5%), and SEQ194 (3.1%), with its performance being matched only on the AntiJen dataset, by the LBtope predictor, where both DRREP and LBtope achieved an AUC of 0.702. Conclusion: DRREP is an analytically trained deep neural network, thus capable of learning in a single step through regression. By combining the features of deep learning, string kernels, and convolutional networks, the system is able to perform residue-by-residue prediction of continues epitopes with higher accuracy than the current state of the art predictors. © 2017 The Author(s).","Analytical learning; Continuous epitope; Convolutional network; Deep network; Epitope prediction; Linear epitope; Neural network; String kernel","Amino Acid Sequence; Computational Biology; Epitopes, B-Lymphocyte; Neural Networks (Computer); epitope; epitope; algorithm; amino acid sequence; AntiJen database; Article; artificial neural network; data base; deep ridge regressed epitope predictor; Human immunodeficiency virus infection; kernel method; learning; machine learning; mining; nerve cell; Pellequer database; prediction; predictor variable; SEQ194 database; severe acute respiratory syndrome; biology; chemistry; immunology; procedures","BioMed Central Ltd.","14712164","","BGMEE","28984193","Article","Scopus","2-s2.0-85030313529"
"Hegelich S.","Hegelich, Simon (56454315100)","56454315100","Deep learning and punctuated equilibrium theory","2017","Cognitive Systems Research","12","10.1016/j.cogsys.2017.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019642130&doi=10.1016%2fj.cogsys.2017.02.006&partnerID=40&md5=fdd3835da31901fdd91e96dc5385eed0","Bavarian School of Public Policy, Technical University of Munich, Richard-Wagner-Str. 1, Munich, D-80333, Germany","Hegelich S., Bavarian School of Public Policy, Technical University of Munich, Richard-Wagner-Str. 1, Munich, D-80333, Germany","Deep learning is associated with the latest success stories in AI. In particular, deep neural networks are applied in increasingly different fields to model complex processes. Interestingly, the underlying algorithm of backpropagation was originally designed for political science models. The theoretical foundations of this approach are very similar to the concept of Punctuated Equilibrium Theory (PET). The article discusses the concept of deep learning and shows parallels to PET. A showcase model demonstrates how deep learning can be used to provide a missing link in the study of the policy process: the connection between attention in the political system (as inputs) and budget shifts (as outputs). © 2017 Elsevier B.V.","Backpropagation; Deep learning; Neural networks; Policy process; Punctuated equilibrium","Backpropagation; Backpropagation algorithms; Budget control; Deep neural networks; Neural networks; Model complexes; Policy process; Political science; Political systems; Punctuated equilibrium; Theoretical foundations; algorithm; area under the curve; Article; artificial neural network; backpropagation algorithm; data processing; deep learning; deep neural network; machine learning; mathematical computing; measurement accuracy; measurement noise; model; noise; policy; politics; prediction; priority journal; punctuated equilibrium theory; receiver operating characteristic; theory; Deep learning","Elsevier B.V.","13890417","","CSROA","","Article","Scopus","2-s2.0-85019642130"
"Andreu-Perez J.; Garcia-Gancedo L.; McKinnell J.; van der Drift A.; Powell A.; Hamy V.; Keller T.; Yang G.-Z.","Andreu-Perez, Javier (55653526300); Garcia-Gancedo, Luis (57204048682); McKinnell, Jonathan (57195728329); van der Drift, Anniek (50761522200); Powell, Adam (57211603440); Hamy, Valentin (57274545800); Keller, Thomas (57195723476); Yang, Guang-Zhong (55539304100)","55653526300; 57204048682; 57195728329; 50761522200; 57211603440; 57274545800; 57195723476; 55539304100","Developing fine-grained actigraphies for rheumatoid arthritis patients from a single accelerometer using machine learning","2017","Sensors (Switzerland)","18","10.3390/s17092113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029648475&doi=10.3390%2fs17092113&partnerID=40&md5=3b391e32d158129aec34dba923e818af","The Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; School of Computer Science and Electronic Engineering, University of Essex, Colchester, CO4 3SQ, United Kingdom; Clinical Innovation Digital Platforms, Projects Clinical Platforms and Sciences, GSK, Stevenage, SG1 2NY, United Kingdom; Emerging Platforms, Platform Technology & Science, GSK, Stevenage, SG1 2NY, United Kingdom; Tessella Altran’s World Class Center for Analytics, Stevenage, SG1 3QP, United Kingdom","Andreu-Perez J., The Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom, School of Computer Science and Electronic Engineering, University of Essex, Colchester, CO4 3SQ, United Kingdom; Garcia-Gancedo L., Clinical Innovation Digital Platforms, Projects Clinical Platforms and Sciences, GSK, Stevenage, SG1 2NY, United Kingdom; McKinnell J., Emerging Platforms, Platform Technology & Science, GSK, Stevenage, SG1 2NY, United Kingdom; van der Drift A., Tessella Altran’s World Class Center for Analytics, Stevenage, SG1 3QP, United Kingdom; Powell A., Tessella Altran’s World Class Center for Analytics, Stevenage, SG1 3QP, United Kingdom; Hamy V., Clinical Innovation Digital Platforms, Projects Clinical Platforms and Sciences, GSK, Stevenage, SG1 2NY, United Kingdom; Keller T., Emerging Platforms, Platform Technology & Science, GSK, Stevenage, SG1 2NY, United Kingdom; Yang G.-Z., The Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom","In addition to routine clinical examination, unobtrusive and physical monitoring of Rheumatoid Arthritis (RA) patients provides an important source of information to enable understanding the impact of the disease on quality of life. Besides an increase in sedentary behaviour, pain in RA can negatively impact simple physical activities such as getting out of bed and standing up from a chair. The objective of this work is to develop a method that can generate fine-grained actigraphies to capture the impact of the disease on the daily activities of patients. A processing methodology is presented to automatically tag activity accelerometer data from a cohort of moderate-to-severe RA patients. A study of procesing methods based on machine learning and deep learning is provided. Thirty subjects, 10 RA patients and 20 healthy control subjects, were recruited in the study. A single tri-axial accelerometer was attached to the position of the fifth lumbar vertebra (L5) of each subject with a tag prediction granularity of 3 s. The proposed method is capable of handling unbalanced datasets from tagged data while accounting for long-duration activities such as sitting and lying, as well as short transitions such as sit-to-stand or lying-to-sit. The methodology also includes a novel mechanism for automatically applying a threshold to predictions by their confidence levels, in addition to a logical filter to correct for infeasible sequences of activities. Performance tests showed that the method was able to achieve around 95% accuracy and 81% F-score. The produced actigraphies can be helpful to generate objective RA disease-specific markers of patient mobility in-between clinical site visits. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Actigraphy; Continuous monitoring; Machine learning; Rheumatoid arthritis","Accelerometry; Arthritis, Rheumatoid; Humans; Machine Learning; Posture; Quality of Life; Accelerometers; Artificial intelligence; Joints (anatomy); Learning systems; Patient monitoring; Accelerometer data; Actigraphy; Clinical examination; Confidence levels; Continuous monitoring; Rheumatoid arthritis; Triaxial accelerometer; Unbalanced datasets; accelerometry; body position; human; machine learning; quality of life; rheumatoid arthritis; Diseases","MDPI AG","14248220","","","28906437","Article","Scopus","2-s2.0-85029648475"
"Zong N.; Kim H.; Ngo V.; Harismendy O.","Zong, Nansu (55205153900); Kim, Hyeoneui (8207259400); Ngo, Victoria (57202481885); Harismendy, Olivier (13806459100)","55205153900; 8207259400; 57202481885; 13806459100","Deep mining heterogeneous networks of biomedical linked data to predict novel drug-target associations","2017","Bioinformatics","146","10.1093/bioinformatics/btx160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026403314&doi=10.1093%2fbioinformatics%2fbtx160&partnerID=40&md5=dd99f9821acdd7f6fdfcf15fc7098fb7","Department of Biomedical Informatics, School of Medicine, UC, San Diego, 92093, CA, United States; Betty Irene Moore School of Nursing, UC Davis, Sacramento, 95817, CA, United States; Moores Cancer Center, UC, San Diego, 92093, CA, United States","Zong N., Department of Biomedical Informatics, School of Medicine, UC, San Diego, 92093, CA, United States; Kim H., Department of Biomedical Informatics, School of Medicine, UC, San Diego, 92093, CA, United States; Ngo V., Betty Irene Moore School of Nursing, UC Davis, Sacramento, 95817, CA, United States; Harismendy O., Department of Biomedical Informatics, School of Medicine, UC, San Diego, 92093, CA, United States, Moores Cancer Center, UC, San Diego, 92093, CA, United States","Motivation: A heterogeneous network topology possessing abundant interactions between biomedical entities has yet to be utilized in similarity-based methods for predicting drug-target associations based on the array of varying features of drugs and their targets. Deep learning reveals features of vertices of a large network that can be adapted in accommodating the similarity-based solutions to provide a flexible method of drug-target prediction. Results: We propose a similarity-based drug-target prediction method that enhances existing association discovery methods by using a topology-based similarity measure. DeepWalk, a deep learning method, is adopted in this study to calculate the similarities within Linked Tripartite Network (LTN), a heterogeneous network generated from biomedical linked datasets. This proposed method shows promising results for drug-target association prediction: 98.96% AUC ROC score with a 10-fold cross-validation and 99.25% AUC ROC score with a Monte Carlo crossvalidation with LTN. By utilizing DeepWalk, we demonstrate that: (i) this method outperforms other existing topology-based similarity computation methods, (ii) the performance is better for tripartite than with bipartite networks and (iii) the measure of similarity using network topology outperforms the ones derived from chemical structure (drugs) or genomic sequence (targets). Our proposed methodology proves to be capable of providing a promising solution for drug-target prediction based on topological similarity with a heterogeneous network, and may be readily re-purposed and adapted in the existing of similarity-based methodologies. © The Author 2017. Published by Oxford University Press. All rights reserved.","","Computational Biology; Data Mining; Humans; Machine Learning; Pharmacology; Semantic Web; Software; biology; data mining; human; machine learning; pharmacology; procedures; semantic web; software","Oxford University Press","13674803","","BOINF","28430977","Article","Scopus","2-s2.0-85026403314"
"Yang X.; Kwitt R.; Styner M.; Niethammer M.","Yang, Xiao (57013859600); Kwitt, Roland (15061561600); Styner, Martin (6701492552); Niethammer, Marc (6701819640)","57013859600; 15061561600; 6701492552; 6701819640","Quicksilver: Fast predictive image registration – A deep learning approach","2017","NeuroImage","429","10.1016/j.neuroimage.2017.07.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024476040&doi=10.1016%2fj.neuroimage.2017.07.008&partnerID=40&md5=56e0f76d9d4612e16e2d447314708ffe","University of North Carolina at Chapel Hill, Chapel Hill, United States; Biomedical Research Imaging Center (BRIC), Chapel Hill, United States; Department of Psychiatry, UNC, Chapel Hill, United States; Department of Computer Science, University of Salzburg, Austria","Yang X., University of North Carolina at Chapel Hill, Chapel Hill, United States; Kwitt R., Department of Computer Science, University of Salzburg, Austria; Styner M., University of North Carolina at Chapel Hill, Chapel Hill, United States, Department of Psychiatry, UNC, Chapel Hill, United States; Niethammer M., University of North Carolina at Chapel Hill, Chapel Hill, United States, Biomedical Research Imaging Center (BRIC), Chapel Hill, United States","This paper introduces Quicksilver, a fast deformable image registration method. Quicksilver registration for image-pairs works by patch-wise prediction of a deformation model based directly on image appearance. A deep encoder-decoder network is used as the prediction model. While the prediction strategy is general, we focus on predictions for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model. Specifically, we predict the momentum-parameterization of LDDMM, which facilitates a patch-wise prediction strategy while maintaining the theoretical properties of LDDMM, such as guaranteed diffeomorphic mappings for sufficiently strong regularization. We also provide a probabilistic version of our prediction network which can be sampled during the testing time to calculate uncertainties in the predicted deformations. Finally, we introduce a new correction network which greatly increases the prediction accuracy of an already existing prediction network. We show experimental results for uni-modal atlas-to-image as well as uni-/multi-modal image-to-image registrations. These experiments demonstrate that our method accurately predicts registrations obtained by numerical optimization, is very fast, achieves state-of-the-art registration results on four standard validation datasets, and can jointly learn an image similarity measure. Quicksilver is freely available as an open-source software. © 2017 Elsevier Inc.","Brain imaging; Deep learning; Image registration","Algorithms; Brain; Brain Mapping; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Pattern Recognition, Automated; accuracy; art; Article; computer network; correction network; deep learning model; deterministic network; diffeomorphic mapping; fast predictive image registration; imaging software; label overlap; Large Deformation Diffeomorphic Metric Mapping model; mathematical analysis; parameterization; patch pruning; patch wise prediction; prediction; priority journal; probabilistic network; process optimization; validation process; algorithm; anatomy and histology; automated pattern recognition; brain; brain mapping; human; image processing; machine learning; physiology; procedures; three dimensional imaging","Academic Press Inc.","10538119","","NEIME","28705497","Article","Scopus","2-s2.0-85024476040"
"Yin Z.; Zhang J.","Yin, Zhong (51061764400); Zhang, Jianhua (57057829600)","51061764400; 57057829600","Cross-subject recognition of operator functional states via EEG and switching deep belief networks with adaptive weights","2017","Neurocomputing","38","10.1016/j.neucom.2017.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019567781&doi=10.1016%2fj.neucom.2017.05.002&partnerID=40&md5=09fee51330b37f82febd610b93951886","Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Jungong Road 516, Yangpu District, Shanghai, 200093, China; Department of Automation, East China University of Science and Technology, Shanghai, 200237, China","Yin Z., Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Jungong Road 516, Yangpu District, Shanghai, 200093, China; Zhang J., Department of Automation, East China University of Science and Technology, Shanghai, 200237, China","Assessing operator functional states (OFS) by using neurophysiological signals can provide continuous prediction of instantaneous human performance in safety-critical human–machine systems. Most existing OFS recognizers were built via a subject-dependent manner, where a new model has to be trained based on historical physiological data of the same subject. The main objective of this paper is to generalize such paradigm to cross-subject OFS recognition by exploiting the new improvements in deep learning principles. To this end, we propose a novel EEG-based OFS classifier, switching deep belief networks with adaptive weights (SDBN), which is generic for detecting variations of mental workload, mental fatigue, and the coupling effect of the two variables across multiple subjects. The temporal OFS is predicted by switching the ensembles of the static and adaptive DBNs at each time step via a Gaussian-kernel based criterion. The results comparison demonstrates that the SDBN not only significantly improves classification accuracy but also has the capability to distinguish multiple dimensions in OFS. © 2017 Elsevier B.V.","Deep belief networks; Deep learning; Electroencephalogram; Mental fatigue; Mental workload; Operator functional states","Diseases; Electroencephalography; Physiological models; Safety engineering; Classification accuracy; Deep belief networks; Mental fatigue; Mental workload; Multiple dimensions; Operator functional state; Physiological data; Subject recognition; adult; Article; artificial neural network; classifier; dysthymia; electroencephalography; human; human experiment; kernel method; male; mental load; normal human; operator functional state; prediction; priority journal; recognition; switching deep belief network; young adult; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85019567781"
"Zhang P.; Zhuo T.; Huang W.; Chen K.; Kankanhalli M.","Zhang, Peng (55547108553); Zhuo, Tao (55352369900); Huang, Wei (56195325600); Chen, Kangli (56763084500); Kankanhalli, Mohan (7003629165)","55547108553; 55352369900; 56195325600; 56763084500; 7003629165","Online object tracking based on CNN with spatial-temporal saliency guided sampling","2017","Neurocomputing","50","10.1016/j.neucom.2016.10.073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012922935&doi=10.1016%2fj.neucom.2016.10.073&partnerID=40&md5=1bef7829ea0a9c3b13ea64d78f36c29f","School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Sensor-enhanced Social Media (SeSaMe) Centre, National University of Singapore, Singapore; School of Information Engineering, Nanchang University, China; School of Computing, National University of Singapore, Singapore","Zhang P., School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Zhuo T., Sensor-enhanced Social Media (SeSaMe) Centre, National University of Singapore, Singapore; Huang W., School of Information Engineering, Nanchang University, China; Chen K., School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Kankanhalli M., School of Computing, National University of Singapore, Singapore","Arbitrary tracking is hard due to nonstop intrinsic and extrinsic variations in realistic scenarios. Even for the popular tracking-by-learning strategies, effective appearance modeling of the non-rigid objects is still challenging because of the targets’ articulatory deformations on-the-fly, which may heavily degrade the discriminative capability of the online generated visual features. With widely emerged deep learning showing its success for feature extraction in different recognition tasks, more and more deep models such as CNN have been demonstrated contributive to improving the performance of online tracking. However, only depending on the outputs from last layer of CNN is not an optimum representation since the coarse spatial resolution cannot guarantee an accurate localization for a qualified sampling process, especially when objects have severe deformations, sampling from the region with a pre-defined scale would inevitably guide a poor online learning. To overcome such a limitation of CNN based tracking, in this work, we incorporated spatial-temporal saliency detection to guide a more accurate target localization for qualified sampling within an inter-frame motion flow map. With an optional strategy for the output combination of intra-frame appearance correlations and inter-frame motion saliency based on a compositional energy optimization, the proposed tracking has shown a superior performance in comparison to the other state-of-art trackers on both challenging non-rigid and generic tracking benchmark datasets. © 2017 Elsevier B.V.","CNN; Saliency; Sampling; Spatial-temporal; Tracking","Benchmarking; Deep learning; Deformation; Feature extraction; Image recognition; Object recognition; Sampling; Surface discharges; Appearance modeling; Energy optimization; Online object tracking; Realistic scenario; Saliency; Spatial resolution; Spatial temporals; Target localization; accuracy; algorithm; Article; artificial neural network; benchmarking; circulant matrix based kernelized correlation; compositional energy optimization; controlled study; convolutional neuron network; factual database; human; imaging and display; information processing; interframe motion flow map; kernelized correlation filter; machine learning; online object tracking; online system; priority journal; process optimization; qualitative analysis; salient motion detection; sampling; spatial region localization; spatial temporal saliency guided sampling; spatial temporal target region localization; statistical analysis; statistical concepts; statistical model; video saliency detection; video saliency segmentation; Target tracking","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85012922935"
"Ambale-Venkatesh B.; Yang X.; Wu C.O.; Liu K.; Gregory Hundley W.; McClelland R.; Gomes A.S.; Folsom A.R.; Shea S.; Guallar E.; Bluemke D.A.; Lima J.A.C.","Ambale-Venkatesh, Bharath (36605465800); Yang, Xiaoying (57196098431); Wu, Colin O. (14034880400); Liu, Kiang (7003731899); Gregory Hundley, W. (35427923100); McClelland, Robyn (35403567600); Gomes, Antoinette S. (7202385958); Folsom, Aaron R. (36043809200); Shea, Steven (57203072455); Guallar, Eliseo (7003727498); Bluemke, David A. (7006047770); Lima, João A.C. (7202778154)","36605465800; 57196098431; 14034880400; 7003731899; 35427923100; 35403567600; 7202385958; 36043809200; 57203072455; 7003727498; 7006047770; 7202778154","Cardiovascular Event Prediction by Machine Learning: The Multi-Ethnic Study of Atherosclerosis","2017","Circulation Research","381","10.1161/CIRCRESAHA.117.311312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031820117&doi=10.1161%2fCIRCRESAHA.117.311312&partnerID=40&md5=5b95284f6726f54e11b4579998925886","Department of Radiology, United States; Bloomberg School of Public Health, United States; Department of Medicine, Cardiology and Radiology, Johns Hopkins University, 600 N Wolfe St, Baltimore, 21287, MD, United States; George Washington University, DC, United States; Office of Biostatistics, NHLBI, NIH, Bethesda, MD, United States; Department of Preventive Medicine, Northwestern University Medical School, Chicago, IL, United States; Department of Cardiology, Wake Forest University Health Sciences, Winston-Salem, NC, United States; Department of Biostatistics, University of Washington, Seattle, United States; Department of Radiology, UCLA School of Medicine, Los Angeles, CA, United States; Division of Epidemiology and Community Health, University of Minnesota, Minneapolis, United States; Departments of Medicine and Epidemiology, Columbia University, New York, NY, United States; Radiology and Imaging Sciences, NIH Clinical Center, Bethesda, MD, United States","Ambale-Venkatesh B., Department of Radiology, United States; Yang X., George Washington University, DC, United States; Wu C.O., Office of Biostatistics, NHLBI, NIH, Bethesda, MD, United States; Liu K., Department of Preventive Medicine, Northwestern University Medical School, Chicago, IL, United States; Gregory Hundley W., Department of Cardiology, Wake Forest University Health Sciences, Winston-Salem, NC, United States; McClelland R., Department of Biostatistics, University of Washington, Seattle, United States; Gomes A.S., Department of Radiology, UCLA School of Medicine, Los Angeles, CA, United States; Folsom A.R., Division of Epidemiology and Community Health, University of Minnesota, Minneapolis, United States; Shea S., Departments of Medicine and Epidemiology, Columbia University, New York, NY, United States; Guallar E., Bloomberg School of Public Health, United States; Bluemke D.A., Radiology and Imaging Sciences, NIH Clinical Center, Bethesda, MD, United States; Lima J.A.C., Department of Medicine, Cardiology and Radiology, Johns Hopkins University, 600 N Wolfe St, Baltimore, 21287, MD, United States","Rationale: Machine learning may be useful to characterize cardiovascular risk, predict outcomes, and identify biomarkers in population studies. Objective: To test the ability of random survival forests, a machine learning technique, to predict 6 cardiovascular outcomes in comparison to standard cardiovascular risk scores. Methods and Results: We included participants from the MESA (Multi-Ethnic Study of Atherosclerosis). Baseline measurements were used to predict cardiovascular outcomes over 12 years of follow-up. MESA was designed to study progression of subclinical disease to cardiovascular events where participants were initially free of cardiovascular disease. All 6814 participants from MESA, aged 45 to 84 years, from 4 ethnicities, and 6 centers across the United States were included. Seven-hundred thirty-five variables from imaging and noninvasive tests, questionnaires, and biomarker panels were obtained. We used the random survival forests technique to identify the top-20 predictors of each outcome. Imaging, electrocardiography, and serum biomarkers featured heavily on the top-20 lists as opposed to traditional cardiovascular risk factors. Age was the most important predictor for all-cause mortality. Fasting glucose levels and carotid ultrasonography measures were important predictors of stroke. Coronary Artery Calcium score was the most important predictor of coronary heart disease and all atherosclerotic cardiovascular disease combined outcomes. Left ventricular structure and function and cardiac troponin-T were among the top predictors for incident heart failure. Creatinine, age, and ankle-brachial index were among the top predictors of atrial fibrillation. TNF-α (tissue necrosis factor-α) and IL (interleukin)-2 soluble receptors and NT-proBNP (N-Terminal Pro-B-Type Natriuretic Peptide) levels were important across all outcomes. The random survival forests technique performed better than established risk scores with increased prediction accuracy (decreased Brier score by 10%-25%). Conclusions: Machine learning in conjunction with deep phenotyping improves prediction accuracy in cardiovascular event prediction in an initially asymptomatic population. These methods may lead to greater insights on subclinical disease markers without apriori assumptions of causality. Clinical Trial Registration: URL: http://www.clinicaltrials.gov. Unique identifier: NCT00005487. © 2017 American Heart Association, Inc.","atrial fibrillation; cardiovascular disease; coronary heart disease; heart failure; machine learning; mortality; stroke","Aged; Aged, 80 and over; Atherosclerosis; Cardiovascular Diseases; Cohort Studies; Ethnic Groups; Female; Follow-Up Studies; Humans; Machine Learning; Male; Middle Aged; Predictive Value of Tests; Survival Rate; amino terminal pro brain natriuretic peptide; biological marker; creatinine; interleukin 2 receptor; troponin T; tumor necrosis factor; accuracy; adult; age; aged; all cause mortality; ankle brachial index; Article; Asian American; atherosclerosis; atrial fibrillation; Black person; cardiac imaging; cardiovascular disease; cardiovascular mortality; cardiovascular risk; carotid arteriography; Caucasian; cerebrovascular accident; clinical outcome; cohort analysis; computer prediction; controlled study; coronary artery calcium score; disease exacerbation; disease marker; echography; electrocardiography; ethnicity; female; follow up; glucose blood level; heart failure; heart left ventricle; heart left ventricle function; Hispanic; human; intermethod comparison; ischemic heart disease; machine learning; major clinical study; male; measurement; morphology; observational study; phenotype; predictor variable; priority journal; prospective study; questionnaire; scoring system; survival prediction; United States; atherosclerosis; cardiovascular disease; clinical trial; diagnostic imaging; ethnic group; ethnology; machine learning; middle aged; mortality; multicenter study; predictive value; randomized controlled trial; survival rate; trends; very elderly","Lippincott Williams and Wilkins","00097330","","CIRUA","28794054","Article","Scopus","2-s2.0-85031820117"
"Yi F.; Moon I.; Javidi B.","Yi, Faliu (36560720900); Moon, Inkyu (55388941800); Javidi, Bahram (7101754586)","36560720900; 55388941800; 7101754586","Automated red blood cells extraction from holographic images using fully convolutional neural networks","2017","Biomedical Optics Express","50","10.1364/BOE.8.004466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030975386&doi=10.1364%2fBOE.8.004466&partnerID=40&md5=78a54129accb6d6779aa4be3f66b6121","Department of Clinical Science, University of Texas Southwestern Medical Center, Dallas, 75390, TX, United States; Department of Robotics Engineering, Daegu Gyeongbuk Institute of Science & Technology, Daegu, 42988, South Korea; Department of Electrical and Computer Engineering, University of Connecticut, Storrs, 06269, CT, United States","Yi F., Department of Clinical Science, University of Texas Southwestern Medical Center, Dallas, 75390, TX, United States; Moon I., Department of Robotics Engineering, Daegu Gyeongbuk Institute of Science & Technology, Daegu, 42988, South Korea; Javidi B., Department of Electrical and Computer Engineering, University of Connecticut, Storrs, 06269, CT, United States","In this paper, we present two models for automatically extracting red blood cells (RBCs) from RBCs holographic images based on a deep learning fully convolutional neural network (FCN) algorithm. The first model, called FCN-1, only uses the FCN algorithm to carry out RBCs prediction, whereas the second model, called FCN-2, combines the FCN approach with the marker-controlled watershed transform segmentation scheme to achieve RBCs extraction. Both models achieve good segmentation accuracy. In addition, the second model has much better performance in terms of cell separation than traditional segmentation methods. In the proposed methods, the RBCs phase images are first numerically reconstructed from RBCs holograms recorded with off-axis digital holographic microscopy. Then, some RBCs phase images are manually segmented and used as training data to fine-tune the FCN. Finally, each pixel in new input RBCs phase images is predicted into either foreground or background using the trained FCN models. The RBCs prediction result from the first model is the final segmentation result, whereas the result from the second model is used as the internal markers of the marker-controlled transform algorithm for further segmentation. Experimental results show that the given schemes can automatically extract RBCs from RBCs phase images and much better RBCs separation results are obtained when the FCN technique is combined with the marker-controlled watershed segmentation algorithm. © 2017 Optical Society of America.","(090.1995) digital holography; (100.6890) three-dimensional image processing; (150.0150) machine vision; (150.1135) algorithms; (170.3880) medical and biological imaging","Bioinformatics; Blood; Cells; Convolution; Extraction; Holograms; Holography; Image processing; Medical imaging; Microscopic examination; Neural networks; Convolutional neural network; Digital holographic microscopy; Digital holography; Marker-controlled watershed segmentation; Marker-controlled watersheds; Medical and biological imaging; Segmentation accuracy; Three-dimensional image processing; Image segmentation","OSA - The Optical Society","21567085","","","","Article","Scopus","2-s2.0-85030975386"
"Wu H.; Wang K.; Lu L.; Xue Y.; Lyu Q.; Jiang M.","Wu, Hongjie (55660096200); Wang, Kun (56896432500); Lu, Liyao (56157994600); Xue, Yu (56501123700); Lyu, Qiang (57195724160); Jiang, Min (57190276167)","55660096200; 56896432500; 56157994600; 56501123700; 57195724160; 57190276167","Deep Conditional Random Field Approach to Transmembrane Topology Prediction and Application to GPCR Three-Dimensional Structure Modeling","2017","IEEE/ACM Transactions on Computational Biology and Bioinformatics","12","10.1109/TCBB.2016.2602872","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032453429&doi=10.1109%2fTCBB.2016.2602872&partnerID=40&md5=84a69b7ff1c60086acc66b81ebebcf7f","School of Electronic and Information Engineering, Suzhou University of Science and Technology, Suzhou, 215009, China; Department of Computer Sciences, University of Minnesota, Twin Cities, 55455, MN, United States; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, 21004, China; School of Computer Science and Technology, Soochow University, Suzhou, 215006, China; Central Laboratory and Clinical Laboratory, Soochow University, Suzhou, 215006, China","Wu H., School of Electronic and Information Engineering, Suzhou University of Science and Technology, Suzhou, 215009, China; Wang K., School of Electronic and Information Engineering, Suzhou University of Science and Technology, Suzhou, 215009, China; Lu L., Department of Computer Sciences, University of Minnesota, Twin Cities, 55455, MN, United States; Xue Y., School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, 21004, China; Lyu Q., School of Computer Science and Technology, Soochow University, Suzhou, 215006, China; Jiang M., Central Laboratory and Clinical Laboratory, Soochow University, Suzhou, 215006, China","Transmembrane proteins play important roles in cellular energy production, signal transmission, and metabolism. Many shallow machine learning methods have been applied to transmembrane topology prediction, but the performance was limited by the large size of membrane proteins and the complex biological evolution information behind the sequence. In this paper, we proposed a novel deep approach based on conditional random fields named as dCRF-TM for predicting the topology of transmembrane proteins. Conditional random fields take into account more complicated interrelation between residue labels in full-length sequence than HMM and SVM-based methods. Three widely-used datasets were employed in the benchmark. DCRF-TM had the accuracy 95 percent over helix location prediction and the accuracy 78 percent over helix number prediction. DCRF-TM demonstrated a more robust performance on large size proteins (>350 residues) against 11 state-of-the-art predictors. Further dCRF-TM was applied to ab initio modeling three-dimensional structures of seven-transmembrane receptors, also known as G protein-coupled receptors. The predictions on 24 solved G protein-coupled receptors and unsolved vasopressin V2 receptor illustrated that dCRF-TM helped abGPCR-I-TASSER to improve TM-score 34.3 percent rather than using the random transmembrane definition. Two out of five predicted models caught the experimental verified disulfide bonds in vasopressin V2 receptor. © 2017 IEEE.","conditional random fields; Deep learning; G protein-coupled receptor; transmembrane protein; vasopressin V2 receptor","Computational Biology; Databases, Protein; Humans; Models, Molecular; Models, Statistical; Protein Conformation; Receptors, G-Protein-Coupled; Sequence Analysis, Protein; Biological membranes; Biology; Covalent bonds; Deep learning; Forecasting; Image segmentation; Learning systems; Random processes; Sulfur compounds; Three dimensional computer graphics; Topology; G protein coupled receptor; Conditional random field; G protein coupled receptors; Machine learning methods; Three dimensional structure modeling; Three-dimensional structure; Trans-membrane proteins; Transmembrane receptors; Vasopressin V2 receptors; biology; chemistry; human; metabolism; molecular model; procedures; protein conformation; protein database; sequence analysis; statistical model; Proteins","Institute of Electrical and Electronics Engineers Inc.","15455963","","","27576262","Article","Scopus","2-s2.0-85032453429"
"Su C.; Gao Y.; Xie Y.; Xue Y.; Ge L.; Li H.","Su, Chong (54879955000); Gao, Yue (57192275784); Xie, Yuxiao (57207375661); Xue, Yong (57196377043); Ge, Lijun (57196374820); Li, Hongguang (36066834200)","54879955000; 57192275784; 57207375661; 57196377043; 57196374820; 36066834200","A hybrid classifier based on nonlinear-PCA and deep belief networks with applications in dysphagia diagnosis","2017","Computer Assisted Surgery","1","10.1080/24699322.2017.1389391","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032806347&doi=10.1080%2f24699322.2017.1389391&partnerID=40&md5=1ea2522c91a89b2c26b1a8e7f422be96","School of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Department of Rehabilitation, China-Japanese Friendship Hospital, Beijing, China","Su C., School of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Gao Y., School of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Xie Y., Department of Rehabilitation, China-Japanese Friendship Hospital, Beijing, China; Xue Y., Department of Rehabilitation, China-Japanese Friendship Hospital, Beijing, China; Ge L., Department of Rehabilitation, China-Japanese Friendship Hospital, Beijing, China; Li H., School of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China","Traditional dysphagia prescreening diagnostic methods require doctors specialists to give patients a total score based on a water swallow test scale. This method is limited by the high dimensionality of the diagnostic elements in the water swallow test scale with heavy workload (Towards each patient, the scale requires the doctors give score for 18 diagnostic elements respectively) as well as the difficulties of extracting and using the diagnostic scale data’s non-linear features and hidden expertise information (Even with the scale scores, specific diagnostic conclusions are still given by expert doctors under the expertise). In this paper, a hybrid classifier model based on Nonlinear-Principal Component Analysis (NPCA) and Deep Belief Networks (DBN) is proposed in order to effectively extract the diagnostic scale data’s nonlinear features and hidden information and to provide the key scale elements’ locating methods towards the diagnostic results (The key scale elements that affect different diagnostic conclusions are given to improve the efficiency and pertinence of diagnosis and reduce the workload of diagnosis). We demonstrate the effectiveness of the proposed method using the frame of ‘information entropy theory’. Real dysphagia diagnosis examples from the China-Japanese Friendship Hospital are used to demonstrate applications of the proposed methods. The examples show satisfactory results compared to the traditional classifier. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","deep belief networks (DBN); Dysphagia diagnosis; entropy; non-linear PCA (NPCA)","Cohort Studies; Deglutition; Deglutition Disorders; Diagnostic Techniques, Digestive System; Humans; Machine Learning; Neural Networks (Computer); Principal Component Analysis; Water; water; artificial neural network; classification; cohort analysis; digestive system examination; dysphagia; human; machine learning; physiology; principal component analysis; swallowing","Taylor and Francis Ltd.","24699322","","","29095063","Article","Scopus","2-s2.0-85032806347"
"Jain H.; Eshwa S.C.; Suresh Kumar N.","Jain, Harshit (57192392080); Eshwa, Srivinayak Chaitanya (57195610770); Suresh Kumar, N. (56180472100)","57192392080; 57195610770; 56180472100","Leprosy detection using image processing and deep learning","2017","Journal of Global Pharma Technology","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029215531&partnerID=40&md5=31a97ea94fbc1c8c7c485dc726ff3c22","School of Computing Science and Engineering, VIT University, Vellore, India","Jain H., School of Computing Science and Engineering, VIT University, Vellore, India; Eshwa S.C., School of Computing Science and Engineering, VIT University, Vellore, India; Suresh Kumar N., School of Computing Science and Engineering, VIT University, Vellore, India","Leprosy, generally called as Hansen's ailment, is an enervating and ceaseless bacterial malady. As indicated by World Health Organization's report, there were 189,000 uninterrupted occurrences of Leprosy in 2012 with 230,000 new conclusions. Though it is reparable at later stages, an early conclusion expects nerve deliberation and the inadequacies it causes. The makers thusly put forward a Convolutional Neural Network based building for Leprosy damage affirmation. To set up the framework, researchers and scientist use Dermnet Nz datasets close by web scratched pictures to finish a best accuracy of 91.6% on a dataset split into 60% of get ready pictures, 20% of pictures are used for cross endorsement and 20% for testing of the results. © 2009-2017, JGPT.","Convolutional Neural Network; Deep learning; Detection algorithm; Image Processing; Leprosy; Neural network","Article; artificial neural network; diagnostic accuracy; disease classification; human; image processing; leprosy; machine learning; major clinical study","Journal of Global Pharma Technology","09758542","","","","Article","Scopus","2-s2.0-85029215531"
"Nibali A.; He Z.; Wollersheim D.","Nibali, Aiden (57184280200); He, Zhen (55475765900); Wollersheim, Dennis (16040739700)","57184280200; 55475765900; 16040739700","Pulmonary nodule classification with deep residual networks","2017","International Journal of Computer Assisted Radiology and Surgery","210","10.1007/s11548-017-1605-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019232353&doi=10.1007%2fs11548-017-1605-6&partnerID=40&md5=c9cdb492716410952687fbde78c04122","Department of Computer Science and Computer Engineering, La Trobe University, Melbourne, Australia; Department of Public Health, La Trobe University, Melbourne, Australia","Nibali A., Department of Computer Science and Computer Engineering, La Trobe University, Melbourne, Australia; He Z., Department of Computer Science and Computer Engineering, La Trobe University, Melbourne, Australia; Wollersheim D., Department of Public Health, La Trobe University, Melbourne, Australia","Purpose : Lung cancer has the highest death rate among all cancers in the USA. In this work we focus on improving the ability of computer-aided diagnosis (CAD) systems to predict the malignancy of nodules from cropped CT images of lung nodules. Methods: We evaluate the effectiveness of very deep convolutional neural networks at the task of expert-level lung nodule malignancy classification. Using the state-of-the-art ResNet architecture as our basis, we explore the effect of curriculum learning, transfer learning, and varying network depth on the accuracy of malignancy classification. Results: Due to a lack of public datasets with standardized problem definitions and train/test splits, studies in this area tend to not compare directly against other existing work. This makes it hard to know the relative improvement in the new solution. In contrast, we directly compare our system against two state-of-the-art deep learning systems for nodule classification on the LIDC/IDRI dataset using the same experimental setup and data set. The results show that our system achieves the highest performance in terms of all metrics measured including sensitivity, specificity, precision, AUROC, and accuracy. Conclusions: The proposed method of combining deep residual learning, curriculum learning, and transfer learning translates to high nodule classification accuracy. This reveals a promising new direction for effective pulmonary nodule CAD systems that mirrors the success of recent deep learning advances in other image-based application domains. © 2017, CARS.","Convolutional neural network; CT images; Lung nodule","Algorithms; Diagnosis, Computer-Assisted; Humans; Lung Neoplasms; Multidetector Computed Tomography; Neural Networks (Computer); Solitary Pulmonary Nodule; Article; artificial neural network; cancer classification; computer assisted tomography; convolutional neural network; curriculum; diagnostic accuracy; diagnostic test accuracy study; false negative result; false positive result; follow up; histogram; human; image processing; lung cancer; lung nodule; machine learning; major clinical study; perceptron; priority journal; sensitivity and specificity; algorithm; artificial neural network; classification; computer assisted diagnosis; lung nodule; lung tumor; multidetector computed tomography; procedures","Springer Verlag","18616410","","","28501942","Article","Scopus","2-s2.0-85019232353"
"Zhang X.","Zhang, Xiaoqing (57196077420)","57196077420","Melanoma segmentation based on deep learning","2017","Computer Assisted Surgery","31","10.1080/24699322.2017.1389405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031748547&doi=10.1080%2f24699322.2017.1389405&partnerID=40&md5=85f990bc01b91e550bf05734489611c7","College of Information Science and Technology, Donghua University, Shanghai, China","Zhang X., College of Information Science and Technology, Donghua University, Shanghai, China","Malignant melanoma is one of the most deadly forms of skin cancer, which is one of the world's fastest-growing cancers. Early diagnosis and treatment is critical. In this study, a neural network structure is utilized to construct a broad and accurate basis for the diagnosis of skin cancer, thereby reducing screening errors. The technique is able to improve the efficacy for identification of normally indistinguishable lesions (such as pigment spots) versus clinically unknown lesions, and to ultimately improve the diagnostic accuracy. In the field of medical imaging, in general, using neural networks for image segmentation is relatively rare. The existing traditional machine-learning neural network algorithms still cannot completely solve the problem of information loss, nor detect the precise division of the boundary area. We use an improved neural network framework, described herein, to achieve efficacious feature learning, and satisfactory segmentation of melanoma images. The architecture of the network includes multiple convolution layers, dropout layers, softmax layers, multiple filters, and activation functions. The number of data sets can be increased via rotation of the training set. A non-linear activation function (such as ReLU and ELU) is employed to alleviate the problem of gradient disappearance, and RMSprop/Adam are incorporated to optimize the loss algorithm. A batch normalization layer is added between the convolution layer and the activation layer to solve the problem of gradient disappearance and explosion. Experiments, described herein, show that our improved neural network architecture achieves higher accuracy for segmentation of melanoma images as compared with existing processes. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","convolutional neural networks; deep learning; image segmentation; Melanoma","Algorithms; Deep Learning; Early Detection of Cancer; Humans; Image Processing, Computer-Assisted; Melanoma; Neural Networks (Computer); Reproducibility of Results; Skin Neoplasms; algorithm; artificial neural network; early cancer diagnosis; human; image processing; melanoma; pathology; procedures; reproducibility; skin tumor","Taylor and Francis Ltd.","24699322","","","29043858","Article","Scopus","2-s2.0-85031748547"
"Wang P.; Ge R.; Xiao X.; Cai Y.; Wang G.; Zhou F.","Wang, Pu (55619296226); Ge, Ruiquan (57225423805); Xiao, Xuan (8324397400); Cai, Yunpeng (8234801000); Wang, Guoqing (57204646943); Zhou, Fengfeng (55634210800)","55619296226; 57225423805; 8324397400; 8234801000; 57204646943; 55634210800","Rectified-Linear-Unit-Based Deep Learning for Biomedical Multi-label Data","2017","Interdisciplinary Sciences – Computational Life Sciences","25","10.1007/s12539-016-0196-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026856487&doi=10.1007%2fs12539-016-0196-1&partnerID=40&md5=aa9ff8a97231a07bf0580ceb3a16fa43","Shenzhen Institutes of Advanced Technology, and Key Lab for Health Informatics, Chinese Academy of Sciences, Shenzhen, 518055, Guangdong, China; Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences, Shenzhen, 518055, Guangdong, China; Computer Department, Jingdezhen Ceramic Institute, Jingdezhen, 333403, Jiangxi, China; Department of Pathogenobiology, Basic Medical College of Jilin University, Changchun, 130012, Jilin, China; College of Computer Science and Technology, Jilin University, Changchun, 130012, Jilin, China; Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China","Wang P., Shenzhen Institutes of Advanced Technology, and Key Lab for Health Informatics, Chinese Academy of Sciences, Shenzhen, 518055, Guangdong, China, Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences, Shenzhen, 518055, Guangdong, China, Computer Department, Jingdezhen Ceramic Institute, Jingdezhen, 333403, Jiangxi, China; Ge R., Shenzhen Institutes of Advanced Technology, and Key Lab for Health Informatics, Chinese Academy of Sciences, Shenzhen, 518055, Guangdong, China, Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences, Shenzhen, 518055, Guangdong, China; Xiao X., Computer Department, Jingdezhen Ceramic Institute, Jingdezhen, 333403, Jiangxi, China; Cai Y., Shenzhen Institutes of Advanced Technology, and Key Lab for Health Informatics, Chinese Academy of Sciences, Shenzhen, 518055, Guangdong, China; Wang G., Department of Pathogenobiology, Basic Medical College of Jilin University, Changchun, 130012, Jilin, China; Zhou F., College of Computer Science and Technology, Jilin University, Changchun, 130012, Jilin, China, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China","Disease diagnosis is one of the major data mining questions by the clinicians. The current diagnosis models usually have a strong assumption that one patient has only one disease, i.e. a single-label data mining problem. But the patients, especially when at the late stages, may have more than one disease and require a multi-label diagnosis. The multi-label data mining is much more difficult than a single-label one, and very few algorithms have been developed for this situation. Deep learning is a data mining algorithm with highly dense inner structure and has achieved many successful applications in the other areas. We propose a hypothesis that rectified-linear-unit-based deep learning algorithm may also be good at the clinical questions, by revising the last layer as a multi-label output. The proof-of-concept experimental data support the hypothesis, and the community may be interested in trying more applications. © 2016, International Association of Scientists in the Interdisciplinary Areas and Springer-Verlag Berlin Heidelberg.","Clinical diagnosis; Deep learning; Multi-label classification; Rectified linear unit; Single-label classification","Algorithms; Biomedical Technology; Machine Learning; Saccharomyces cerevisiae; algorithm; machine learning; medical technology; metabolism; Saccharomyces cerevisiae","International Association of Scientists in the International Association of Scientists in the","19132751","","","27837428","Article","Scopus","2-s2.0-85026856487"
"Zieliński B.; Plichta A.; Misztal K.; Spurek P.; Brzychczy-Włoch M.; Ochońska D.","Zieliński, Bartosz (15727135200); Plichta, Anna (55054592300); Misztal, Krzysztof (55440337800); Spurek, Przemysław (54906233900); Brzychczy-Włoch, Monika (8627476800); Ochońska, Dorota (56070647100)","15727135200; 55054592300; 55440337800; 54906233900; 8627476800; 56070647100","Deep learning approach to bacterial colony classification","2017","PLoS ONE","110","10.1371/journal.pone.0184554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029488169&doi=10.1371%2fjournal.pone.0184554&partnerID=40&md5=dbddf51f8af355c493732f6fbc570210","Faculty of Mathematics and Computer Science, Jagiellonian University, 6 Łojasiewicza Street, Kraków, 30-348, Poland; Department of Computer Science, Cracow University of Technology, 24 Warszawska Street, Kraków, 31-422, Poland; Department of Bacteriology, Microbial Ecology and Parasitology, Chair of Microbiology, Jagiellonian University Medical College, 18 Czysta Street, Kraków, 31-121, Poland; Department of Infection Epidemiology, Chair of Microbiology, Faculty of Medicine, Jagiellonian University Medical College, 18 Czysta Street, Kraków, 31-121, Poland","Zieliński B., Faculty of Mathematics and Computer Science, Jagiellonian University, 6 Łojasiewicza Street, Kraków, 30-348, Poland; Plichta A., Department of Computer Science, Cracow University of Technology, 24 Warszawska Street, Kraków, 31-422, Poland; Misztal K., Faculty of Mathematics and Computer Science, Jagiellonian University, 6 Łojasiewicza Street, Kraków, 30-348, Poland; Spurek P., Faculty of Mathematics and Computer Science, Jagiellonian University, 6 Łojasiewicza Street, Kraków, 30-348, Poland; Brzychczy-Włoch M., Department of Bacteriology, Microbial Ecology and Parasitology, Chair of Microbiology, Jagiellonian University Medical College, 18 Czysta Street, Kraków, 31-121, Poland; Ochońska D., Department of Infection Epidemiology, Chair of Microbiology, Faculty of Medicine, Jagiellonian University Medical College, 18 Czysta Street, Kraków, 31-121, Poland","In microbiology it is diagnostically useful to recognize various genera and species of bacteria. It can be achieved using computer-aided methods, which make the recognition processes more automatic and thus significantly reduce the time necessary for the classification. Moreover, in case of diagnostic uncertainty (the misleading similarity in shape or structure of bacterial cells), such methods can minimize the risk of incorrect recognition. In this article, we apply the state of the art method for texture analysis to classify genera and species of bacteria. This method uses deep Convolutional Neural Networks to obtain image descriptors, which are then encoded and classified with Support Vector Machine or Random Forest. To evaluate this approach and to make it comparable with other approaches, we provide a new dataset of images. DIBaS dataset (Digital Image of Bacterial Species) contains 660 images with 33 different genera and species of bacteria. © 2017 Zieliński et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Bacteria; Databases, Factual; Machine Learning; Neural Networks (Computer); Support Vector Machine; bacterium colony; learning; nervous system; random forest; support vector machine; artificial neural network; bacterium; classification; factual database; machine learning","Public Library of Science","19326203","","POLNC","28910352","Article","Scopus","2-s2.0-85029488169"
"Burlina P.; Billings S.; Joshi N.; Albayda J.","Burlina, Philippe (6603713214); Billings, Seth (37761152200); Joshi, Neil (57193277131); Albayda, Jemima (55496076200)","6603713214; 37761152200; 57193277131; 55496076200","Automated diagnosis of myositis from muscle ultrasound: Exploring the use of machine learning and deep learning methods","2017","PLoS ONE","95","10.1371/journal.pone.0184059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028647173&doi=10.1371%2fjournal.pone.0184059&partnerID=40&md5=004185e5429824afd7881cbeae094098","Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, United States; Division of Rheumatology, Johns Hopkins School of Medicine, Baltimore, MD, United States","Burlina P., Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, United States; Billings S., Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, United States; Joshi N., Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, United States; Albayda J., Division of Rheumatology, Johns Hopkins School of Medicine, Baltimore, MD, United States","Objective: To evaluate the use of ultrasound coupled with machine learning (ML) and deep learning (DL) techniques for automated or semi-automated classification of myositis. Methods: Eighty subjects comprised of 19 with inclusion body myositis (IBM), 14 with polymyositis (PM), 14 with dermatomyositis (DM), and 33 normal (N) subjects were included in this study, where 3214 muscle ultrasound images of 7 muscles (observed bilaterally) were acquired. We considered three problems of classification including (A) normal vs. affected (DM, PM, IBM); (B) normal vs. IBM patients; and (C) IBM vs. other types of myositis (DM or PM). We studied the use of an automated DL method using deep convolutional neural networks (DL-DCNNs) for diagnostic classification and compared it with a semi-automated conventional ML method based on random forests (ML-RF) and “engineered” features. We used the known clinical diagnosis as the gold standard for evaluating performance of muscle classification. Results: The performance of the DL-DCNN method resulted in accuracies ± standard deviation of 76.2% ± 3.1% for problem (A), 86.6% ± 2.4% for (B) and 74.8% ± 3.9% for (C), while the ML-RF method led to accuracies of 72.3% ± 3.3% for problem (A), 84.3% ± 2.3% for (B) and 68.9% ± 2.5% for (C). Conclusions: This study demonstrates the application of machine learning methods for automatically or semi-automatically classifying inflammatory muscle disease using muscle ultrasound. Compared to the conventional random forest machine learning method used here, which has the drawback of requiring manual delineation of muscle/fat boundaries, DCNN-based classification by and large improved the accuracies in all classification problems while providing a fully automated approach to classification. © 2017 Burlina et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Adult; Aged; Aged, 80 and over; Dermatomyositis; Female; Humans; Machine Learning; Male; Middle Aged; Muscles; Myositis; Myositis, Inclusion Body; Neural Networks (Computer); Polymyositis; Ultrasonography; Young Adult; creatine kinase; adult; aged; Article; artificial neural network; clinical article; computer assisted diagnosis; controlled study; creatine kinase blood level; deep convolutional neural network; deep learning method; dermatomyositis; diagnostic accuracy; disease classification; female; gold standard; human; human tissue; inclusion body myositis; intermethod comparison; machine learning; male; myositis; polymyositis; random forest; ultrasound; very elderly; young adult; artificial neural network; dermatomyositis; diagnostic imaging; echography; inclusion body myositis; middle aged; muscle; myositis; polymyositis; procedures","Public Library of Science","19326203","","POLNC","28854220","Article","Scopus","2-s2.0-85028647173"
"Li H.; Hou J.; Adhikari B.; Lyu Q.; Cheng J.","Li, Haiou (55372224000); Hou, Jie (56673336000); Adhikari, Badri (56120455900); Lyu, Qiang (57195724160); Cheng, Jianlin (57203108630)","55372224000; 56673336000; 56120455900; 57195724160; 57203108630","Deep learning methods for protein torsion angle prediction","2017","BMC Bioinformatics","44","10.1186/s12859-017-1834-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029659778&doi=10.1186%2fs12859-017-1834-2&partnerID=40&md5=7f5a0c3f3f032f7316408a27b322ab5a","Soochow University, Department of Computer Science and Technology, Suzhou, Jiangsu, 215006, China; University of Missouri, Department of Electrical Engineering and Computer Science, Columbia, 65211, MO, United States; University of Missouri-St. Louis, Department of Mathematics and Computer Science, 1 University Blvd. 311 Express Scripts Hall, St. Louis, 63121, MO, United States","Li H., Soochow University, Department of Computer Science and Technology, Suzhou, Jiangsu, 215006, China; Hou J., University of Missouri, Department of Electrical Engineering and Computer Science, Columbia, 65211, MO, United States; Adhikari B., University of Missouri-St. Louis, Department of Mathematics and Computer Science, 1 University Blvd. 311 Express Scripts Hall, St. Louis, 63121, MO, United States; Lyu Q., Soochow University, Department of Computer Science and Technology, Suzhou, Jiangsu, 215006, China; Cheng J., University of Missouri, Department of Electrical Engineering and Computer Science, Columbia, 65211, MO, United States","Background: Deep learning is one of the most powerful machine learning methods that has achieved the state-of-the-art performance in many domains. Since deep learning was introduced to the field of bioinformatics in 2012, it has achieved success in a number of areas such as protein residue-residue contact prediction, secondary structure prediction, and fold recognition. In this work, we developed deep learning methods to improve the prediction of torsion (dihedral) angles of proteins. Results: We design four different deep learning architectures to predict protein torsion angles. The architectures including deep neural network (DNN) and deep restricted Boltzmann machine (DRBN), deep recurrent neural network (DRNN) and deep recurrent restricted Boltzmann machine (DReRBM) since the protein torsion angle prediction is a sequence related problem. In addition to existing protein features, two new features (predicted residue contact number and the error distribution of torsion angles extracted from sequence fragments) are used as input to each of the four deep learning architectures to predict phi and psi angles of protein backbone. The mean absolute error (MAE) of phi and psi angles predicted by DRNN, DReRBM, DRBM and DNN is about 20-21° and 29-30° on an independent dataset. The MAE of phi angle is comparable to the existing methods, but the MAE of psi angle is 29°, 2° lower than the existing methods. On the latest CASP12 targets, our methods also achieved the performance better than or comparable to a state-of-the art method. Conclusions: Our experiment demonstrates that deep learning is a valuable method for predicting protein torsion angles. The deep recurrent network architecture performs slightly better than deep feed-forward architecture, and the predicted residue contact number and the error distribution of torsion angles extracted from sequence fragments are useful features for improving prediction accuracy. © 2017 The Author(s).","Deep learning; Deep recurrent neural network; Protein torsion angle prediction; Restricted Boltzmann machine","Machine Learning; Molecular Structure; Neural Networks (Computer); Protein Structure, Secondary; Proteins; Deep neural networks; Dihedral angle; Errors; Forecasting; Learning systems; Network architecture; Proteins; Recurrent neural networks; Torsional stress; protein; Feed-forward architectures; Learning architectures; Machine learning methods; Restricted boltzmann machine; Secondary structure prediction; State-of-the-art methods; State-of-the-art performance; Torsion angle; artificial neural network; chemical structure; chemistry; machine learning; protein secondary structure; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","28923002","Article","Scopus","2-s2.0-85029659778"
"Li S.; Liu G.; Tang X.; Lu J.; Hu J.","Li, Shaobo (7409243297); Liu, Guokai (57195267684); Tang, Xianghong (56327175300); Lu, Jianguang (57189699728); Hu, Jianjun (12242142100)","7409243297; 57195267684; 56327175300; 57189699728; 12242142100","An ensemble deep convolutional neural network model with improved D-S evidence fusion for bearing fault diagnosis","2017","Sensors (Switzerland)","177","10.3390/s17081729","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026624931&doi=10.3390%2fs17081729&partnerID=40&md5=abc69ff06c8f522ef36828cef08d4e97","School of Mechanical Engineering, Guizhou University, Guiyang, 550025, China; Key Laboratory of Advanced Manufacturing Technology, Ministry of Education, Guizhou University, Guiyang, 550025, China; Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States","Li S., School of Mechanical Engineering, Guizhou University, Guiyang, 550025, China; Liu G., Key Laboratory of Advanced Manufacturing Technology, Ministry of Education, Guizhou University, Guiyang, 550025, China; Tang X., School of Mechanical Engineering, Guizhou University, Guiyang, 550025, China, Key Laboratory of Advanced Manufacturing Technology, Ministry of Education, Guizhou University, Guiyang, 550025, China; Lu J., School of Mechanical Engineering, Guizhou University, Guiyang, 550025, China, Key Laboratory of Advanced Manufacturing Technology, Ministry of Education, Guizhou University, Guiyang, 550025, China; Hu J., School of Mechanical Engineering, Guizhou University, Guiyang, 550025, China, Department of Computer Science and Engineering, University of South Carolina, Columbia, 29208, SC, United States","Intelligent machine health monitoring and fault diagnosis are becoming increasingly important for modern manufacturing industries. Current fault diagnosis approaches mostly depend on expert-designed features for building prediction models. In this paper, we proposed IDSCNN, a novel bearing fault diagnosis algorithm based on ensemble deep convolutional neural networks and an improved Dempster–Shafer theory based evidence fusion. The convolutional neural networks take the root mean square (RMS) maps from the FFT (Fast Fourier Transformation) features of the vibration signals from two sensors as inputs. The improved D-S evidence theory is implemented via distance matrix from evidences and modified Gini Index. Extensive evaluations of the IDSCNN on the Case Western Reserve Dataset showed that our IDSCNN algorithm can achieve better fault diagnosis performance than existing machine learning methods by fusing complementary or conflicting evidences from different models and sensors and adapting to different load conditions. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Bearing fault diagnosis; Convolutional neural networks; D-S evidence theory; Deep learning","Convolution; Deep learning; Deep neural networks; Electric fault currents; Failure analysis; Formal logic; Learning systems; Neural networks; Bearing fault diagnosis; Conflicting evidence; Convolutional neural network; D S evidence theory; Diagnosis performance; Fast Fourier transformations; Machine learning methods; Manufacturing industries; Fault detection","MDPI AG","14248220","","","28788099","Article","Scopus","2-s2.0-85026624931"
"Macías-García L.; Luna-Romera J.M.; García-Gutiérrez J.; Martínez-Ballesteros M.; Riquelme-Santos J.C.; González-Cámpora R.","Macías-García, Laura (55432985900); Luna-Romera, José María (57191279432); García-Gutiérrez, Jorge (57209423602); Martínez-Ballesteros, María (35409627600); Riquelme-Santos, José C. (57219716128); González-Cámpora, Ricardo (7006806167)","55432985900; 57191279432; 57209423602; 35409627600; 57219716128; 7006806167","A study of the suitability of autoencoders for preprocessing data in breast cancer experimentation","2017","Journal of Biomedical Informatics","18","10.1016/j.jbi.2017.06.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021625847&doi=10.1016%2fj.jbi.2017.06.020&partnerID=40&md5=ea8fc1d17e8bbd1ea71486211459afad","Department of Anatomic Pathology., Hospital Infanta Elena, Huelva, Spain; Department of Computer Languages and Systems, ETSII, University of Seville, Spain; Department of Anatomic Pathology, Hospital Universitario Virgen Macarena, Seville, Spain","Macías-García L., Department of Anatomic Pathology., Hospital Infanta Elena, Huelva, Spain; Luna-Romera J.M., Department of Computer Languages and Systems, ETSII, University of Seville, Spain; García-Gutiérrez J., Department of Computer Languages and Systems, ETSII, University of Seville, Spain; Martínez-Ballesteros M., Department of Computer Languages and Systems, ETSII, University of Seville, Spain; Riquelme-Santos J.C., Department of Computer Languages and Systems, ETSII, University of Seville, Spain; González-Cámpora R., Department of Anatomic Pathology, Hospital Universitario Virgen Macarena, Seville, Spain","Breast cancer is the most common cause of cancer death in women. Today, post-transcriptional protein products of the genes involved in breast cancer can be identified by immunohistochemistry. However, this method has problems arising from the intra-observer and inter-observer variability in the assessment of pathologic variables, which may result in misleading conclusions. Using an optimal selection of preprocessing techniques may help to reduce observer variability. Deep learning has emerged as a powerful technique for any tasks related to machine learning such as classification and regression. The aim of this work is to use autoencoders (neural networks commonly used to feed deep learning architectures) to improve the quality of the data for developing immunohistochemistry signatures with prognostic value in breast cancer. Our testing on data from 222 patients with invasive non-special type breast carcinoma shows that an automatic binarization of experimental data after autoencoding could outperform other classical preprocessing techniques (such as human-dependent or automatic binarization only) when applied to the prognosis of breast cancer by immunohistochemical signatures. © 2017","Autoencoder; Biomedical data; Breast cancer; Deep learning; Preprocessing","Breast Neoplasms; Female; Humans; Machine Learning; Neural Networks (Computer); Observer Variation; Prognosis; Bins; Deep neural networks; Diagnosis; Diseases; Education; Learning systems; tumor marker; Auto encoders; Automatic binarization; Biomedical data; Breast Cancer; Interobserver variability; Learning architectures; Preprocessing; Preprocessing techniques; Article; artificial neural network; breast cancer; breast carcinoma; cancer prognosis; controlled study; experimentation; human; human tissue; immunohistochemistry; information processing; invasive carcinoma; machine learning; major clinical study; priority journal; quality control; breast tumor; female; machine learning; observer variation; prognosis; Deep learning","Academic Press Inc.","15320464","","JBIOB","28663073","Article","Scopus","2-s2.0-85021625847"
"Taghanaki S.A.; Kawahara J.; Miles B.; Hamarneh G.","Taghanaki, Saeid Asgari (55511019100); Kawahara, Jeremy (55823349400); Miles, Brandon (55620927600); Hamarneh, Ghassan (6603568967)","55511019100; 55823349400; 55620927600; 6603568967","Pareto-optimal multi-objective dimensionality reduction deep auto-encoder for mammography classification","2017","Computer Methods and Programs in Biomedicine","28","10.1016/j.cmpb.2017.04.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018513373&doi=10.1016%2fj.cmpb.2017.04.012&partnerID=40&md5=110b5ebed1c1c3315ff22ffd1af9f631","Medical Image Analysis Lab, Simon Fraser University, Canada","Taghanaki S.A., Medical Image Analysis Lab, Simon Fraser University, Canada; Kawahara J., Medical Image Analysis Lab, Simon Fraser University, Canada; Miles B., Medical Image Analysis Lab, Simon Fraser University, Canada; Hamarneh G., Medical Image Analysis Lab, Simon Fraser University, Canada","Background and objective Feature reduction is an essential stage in computer aided breast cancer diagnosis systems. Multilayer neural networks can be trained to extract relevant features by encoding high-dimensional data into low-dimensional codes. Optimizing traditional auto-encoders works well only if the initial weights are close to a proper solution. They are also trained to only reduce the mean squared reconstruction error (MRE) between the encoder inputs and the decoder outputs, but do not address the classification error. The goal of the current work is to test the hypothesis that extending traditional auto-encoders (which only minimize reconstruction error) to multi-objective optimization for finding Pareto-optimal solutions provides more discriminative features that will improve classification performance when compared to single-objective and other multi-objective approaches (i.e. scalarized and sequential). Methods In this paper, we introduce a novel multi-objective optimization of deep auto-encoder networks, in which the auto-encoder optimizes two objectives: MRE and mean classification error (MCE) for Pareto-optimal solutions, rather than just MRE. These two objectives are optimized simultaneously by a non-dominated sorting genetic algorithm. Results We tested our method on 949 X-ray mammograms categorized into 12 classes. The results show that the features identified by the proposed algorithm allow a classification accuracy of up to 98.45%, demonstrating favourable accuracy over the results of state-of-the-art methods reported in the literature. Conclusions We conclude that adding the classification objective to the traditional auto-encoder objective and optimizing for finding Pareto-optimal solutions, using evolutionary multi-objective optimization, results in producing more discriminative features. © 2017 Elsevier B.V.","Auto-encoder; Breast cancer; Computer aided diagnosis; Feature reduction; Multi-objective optimization","Algorithms; Breast Neoplasms; Diagnosis, Computer-Assisted; Humans; Mammography; Neural Networks (Computer); Clustering algorithms; Computer aided diagnosis; Data mining; Diseases; Errors; Genetic algorithms; Learning systems; Multilayer neural networks; Optimal systems; Optimization; Pareto principle; Signal encoding; Auto encoders; Breast Cancer; Classification performance; Evolutionary multiobjective optimization; Feature reduction; Mammography classification; Non- dominated sorting genetic algorithms; State-of-the-art methods; analytical error; Article; autoanalyzer; automation; breast density; breast tissue; classification; comparative study; controlled study; genetic algorithm; image reconstruction; information processing device; mammography; mean classification error; mean squared reconstruction error; multifactor dimensionality reduction; pareto optimal multi objective dimensionality reduction deep auto encoder; support vector machine; algorithm; artificial neural network; breast tumor; classification; computer assisted diagnosis; diagnostic imaging; human; mammography; procedures; Multiobjective optimization","Elsevier Ireland Ltd","01692607","","CMPBE","28552129","Article","Scopus","2-s2.0-85018513373"
"Lakhani P.","Lakhani, Paras (8763051900)","8763051900","Deep Convolutional Neural Networks for Endotracheal Tube Position and X-ray Image Classification: Challenges and Opportunities","2017","Journal of Digital Imaging","79","10.1007/s10278-017-9980-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020637979&doi=10.1007%2fs10278-017-9980-7&partnerID=40&md5=7cfc7d8e4a9dfa21172c85d5f6812514","Thomas Jefferson University Hospital, Sidney Kimmel Jefferson Medical College, Philadelphia, 19107, PA, United States","Lakhani P., Thomas Jefferson University Hospital, Sidney Kimmel Jefferson Medical College, Philadelphia, 19107, PA, United States","The goal of this study is to evaluate the efficacy of deep convolutional neural networks (DCNNs) in differentiating subtle, intermediate, and more obvious image differences in radiography. Three different datasets were created, which included presence/absence of the endotracheal (ET) tube (n = 300), low/normal position of the ET tube (n = 300), and chest/abdominal radiographs (n = 120). The datasets were split into training, validation, and test. Both untrained and pre-trained deep neural networks were employed, including AlexNet and GoogLeNet classifiers, using the Caffe framework. Data augmentation was performed for the presence/absence and low/normal ET tube datasets. Receiver operating characteristic (ROC), area under the curves (AUC), and 95% confidence intervals were calculated. Statistical differences of the AUCs were determined using a non-parametric approach. The pre-trained AlexNet and GoogLeNet classifiers had perfect accuracy (AUC 1.00) in differentiating chest vs. abdominal radiographs, using only 45 training cases. For more difficult datasets, including the presence/absence and low/normal position endotracheal tubes, more training cases, pre-trained networks, and data-augmentation approaches were helpful to increase accuracy. The best-performing network for classifying presence vs. absence of an ET tube was still very accurate with an AUC of 0.99. However, for the most difficult dataset, such as low vs. normal position of the endotracheal tube, DCNNs did not perform as well, but achieved a reasonable AUC of 0.81. © 2017, The Author(s).","Artificial intelligence; Artificial neural networks (ANNs); Classification; Machine learning; Radiography","Area Under Curve; Datasets as Topic; Humans; Intubation, Intratracheal; Neural Networks (Computer); Radiography, Abdominal; Radiography, Thoracic; ROC Curve; Artificial intelligence; Classification (of information); Computerized tomography; Convolution; Image classification; Learning algorithms; Learning systems; Neural networks; Radiography; Tubes (components); X ray radiography; Area under the curves; Confidence interval; Convolutional neural network; Data augmentation; Nonparametric approaches; Receiver operating characteristics; Statistical differences; X-ray image classifications; abdominal radiography; area under the curve; artificial neural network; classification; devices; endotracheal intubation; human; information processing; procedures; receiver operating characteristic; thorax radiography; Deep neural networks","Springer New York LLC","08971889","","JDIME","28600640","Article","Scopus","2-s2.0-85020637979"
"Hu Z.; Zhang Z.; Yang H.; Chen Q.; Zuo D.","Hu, Ze (57193441418); Zhang, Zhan (55606660000); Yang, Haiqin (13403893400); Chen, Qing (56287396200); Zuo, Decheng (11339633500)","57193441418; 55606660000; 13403893400; 56287396200; 11339633500","A deep learning approach for predicting the quality of online health expert question-answering services","2017","Journal of Biomedical Informatics","27","10.1016/j.jbi.2017.06.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020855618&doi=10.1016%2fj.jbi.2017.06.012&partnerID=40&md5=3cb2afa72b6ae994db0d7b7e7fd2ec8e","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Department of Computing, Hang Seng Management College, Hong Kong; Research Center on Satellite Technology, Harbin Institute of Technology, Harbin, 150001, China","Hu Z., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Zhang Z., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China; Yang H., Department of Computing, Hang Seng Management College, Hong Kong; Chen Q., Research Center on Satellite Technology, Harbin Institute of Technology, Harbin, 150001, China; Zuo D., School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China","Recently, online health expert question-answering (HQA) services (systems) have attracted more and more health consumers to ask health-related questions everywhere at any time due to the convenience and effectiveness. However, the quality of answers in existing HQA systems varies in different situations. It is significant to provide effective tools to automatically determine the quality of the answers. Two main characteristics in HQA systems raise the difficulties of classification: (1) physicians’ answers in an HQA system are usually written in short text, which yields the data sparsity issue; (2) HQA systems apply the quality control mechanism, which refrains the wisdom of crowd. The important information, such as the best answer and the number of users’ votes, is missing. To tackle these issues, we prepare the first HQA research data set labeled by three medical experts in 90 days and formulate the problem of predicting the quality of answers in the system as a classification task. We not only incorporate the standard textual feature of answers, but also introduce a set of unique non-textual features, i.e., the popular used surface linguistic features and the novel social features, from other modalities. A multimodal deep belief network (DBN)-based learning framework is then proposed to learn the high-level hidden semantic representations of answers from both textual features and non-textual features while the learned joint representation is fed into popular classifiers to determine the quality of answers. Finally, we conduct extensive experiments to demonstrate the effectiveness of including the non-textual features and the proposed multimodal deep learning framework. © 2017 Elsevier Inc.","Deep belief network; Deep learning; Multimodal learning; Online health expert question-answering services; Social features; Surface linguistic features","Consumer Health Information; Delivery of Health Care; Humans; Machine Learning; Quality Control; Semantics; Classification (of information); E-learning; Education; Health; Linguistics; Online systems; Semantics; Text processing; Deep belief networks; Linguistic features; Multi-modal learning; Question-answering services; Social features; area under the curve; Article; binary classification; classification; classification task; classifier; controlled study; deep belief network based learning framework; deep learning approach; information processing; machine learning; non textual feature; online health expert question answering service; online system; prediction; predictive value; priority journal; process optimization; public health message; quality control; semantic representation; short text classification; task performance; text quality prediction; consumer health information; health care delivery; human; quality control; semantics; Deep learning","Academic Press Inc.","15320464","","JBIOB","28606870","Article","Scopus","2-s2.0-85020855618"
"Wang Y.; Qiu Y.; Thai T.; Moore K.; Liu H.; Zheng B.","Wang, Yunzhi (57205302373); Qiu, Yuchen (36994032800); Thai, Theresa (55940639600); Moore, Kathleen (8560429300); Liu, Hong (51563613000); Zheng, Bin (7201781356)","57205302373; 36994032800; 55940639600; 8560429300; 51563613000; 7201781356","A two-step convolutional neural network based computer-aided detection scheme for automatically segmenting adipose tissue volume depicting on CT images","2017","Computer Methods and Programs in Biomedicine","88","10.1016/j.cmpb.2017.03.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015984007&doi=10.1016%2fj.cmpb.2017.03.017&partnerID=40&md5=6e593436e248418003bb95653c00cefa","School of Electrical and Computer Engineering, University of Oklahoma, Norman, 73019, OK, United States; Health Science Center of University of Oklahoma, Oklahoma City, 73104, OK, United States","Wang Y., School of Electrical and Computer Engineering, University of Oklahoma, Norman, 73019, OK, United States; Qiu Y., School of Electrical and Computer Engineering, University of Oklahoma, Norman, 73019, OK, United States; Thai T., Health Science Center of University of Oklahoma, Oklahoma City, 73104, OK, United States; Moore K., Health Science Center of University of Oklahoma, Oklahoma City, 73104, OK, United States; Liu H., School of Electrical and Computer Engineering, University of Oklahoma, Norman, 73019, OK, United States; Zheng B., School of Electrical and Computer Engineering, University of Oklahoma, Norman, 73019, OK, United States","Accurately assessment of adipose tissue volume inside a human body plays an important role in predicting disease or cancer risk, diagnosis and prognosis. In order to overcome limitation of using only one subjectively selected CT image slice to estimate size of fat areas, this study aims to develop and test a computer-aided detection (CAD) scheme based on deep learning technique to automatically segment subcutaneous fat areas (SFA) and visceral fat areas (VFA) depicting on volumetric CT images. A retrospectively collected CT image dataset was divided into two independent training and testing groups. The proposed CAD framework consisted of two steps with two convolution neural networks (CNNs) namely, Selection-CNN and Segmentation-CNN. The first CNN was trained using 2,240 CT slices to select abdominal CT slices depicting SFA and VFA. The second CNN was trained with 84,000 pixel patches and applied to the selected CT slices to identify fat-related pixels and assign them into SFA and VFA classes. Comparing to the manual CT slice selection and fat pixel segmentation results, the accuracy of CT slice selection using the Selection-CNN yielded 95.8%, while the accuracy of fat pixel segmentation using the Segmentation-CNN was 96.8%. This study demonstrated the feasibility of applying a new deep learning based CAD scheme to automatically recognize abdominal section of human body from CT scans and segment SFA and VFA from volumetric CT data with high accuracy or agreement with the manual segmentation results. © 2017 Elsevier B.V.","Computer-aided detection (CAD); Convolution neural network (CNN); Deep learning; Segmentation of adipose tissue; Subcutaneous fat area (SFA); Visceral fat area (VFA)","Abdomen; Abdominal Fat; Humans; Image Interpretation, Computer-Assisted; Intra-Abdominal Fat; Neural Networks (Computer); Subcutaneous Fat; Tomography, X-Ray Computed; Computer aided diagnosis; Computer aided instruction; Computer networks; Convolution; Deep learning; Diagnosis; Image segmentation; Neural networks; Pixels; Risk assessment; Statistical tests; Tissue; Adipose tissue; Computer-aided detection; Convolution neural network; Subcutaneous fat; Visceral fat; adipose tissue; Article; automation; body size; cancer patient; classifier; clinical article; computed tomography scanner; computer aided design; cone beam computed tomography; convolution neural network; female; human; image reconstruction; image segmentation; intraperitoneal fat; machine learning; ovary cancer; retrospective study; sensitivity and specificity; subcutaneous fat; abdomen; abdominal fat; artificial neural network; computer assisted diagnosis; diagnostic imaging; intraabdominal fat; x-ray computed tomography; Computerized tomography","Elsevier Ireland Ltd","01692607","","CMPBE","28495009","Article","Scopus","2-s2.0-85015984007"
"Noori H.R.; Schöttler J.; Ercsey-Ravasz M.; Cosa-Linan A.; Varga M.; Toroczkai Z.; Spanagel R.","Noori, Hamid R. (55881233000); Schöttler, Judith (57195279588); Ercsey-Ravasz, Maria (14015425000); Cosa-Linan, Alejandro (57191975529); Varga, Melinda (56825291100); Toroczkai, Zoltan (57202673837); Spanagel, Rainer (7005639170)","55881233000; 57195279588; 14015425000; 57191975529; 56825291100; 57202673837; 7005639170","A multiscale cerebral neurochemical connectome of the rat brain","2017","PLoS Biology","29","10.1371/journal.pbio.2002612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026767270&doi=10.1371%2fjournal.pbio.2002612&partnerID=40&md5=8b1042c42c643fbb5c25fd6c6c3e579a","Institute of Psychopharmacology, Central Institute of Mental Health, Medical Faculty Mannheim, University of Heidelberg, Mannheim, Germany; Neuronal Convergence Group, Max Planck Institute for Biological Cybernetics, Tübingen, Germany; Institut des Hautes Etudes Scientifiques, Bures-sur-Yvette, France; Faculty of Physics, Babes-Bolyai University, Cluj-Napoca, Romania; Romanian Institute of Science and Technology, Cluj-Napoca, Romania; Physics Department and the Interdisciplinary Center for Network Science and Applications, University of Notre Dame, Notre Dame, IN, United States","Noori H.R., Institute of Psychopharmacology, Central Institute of Mental Health, Medical Faculty Mannheim, University of Heidelberg, Mannheim, Germany, Neuronal Convergence Group, Max Planck Institute for Biological Cybernetics, Tübingen, Germany, Institut des Hautes Etudes Scientifiques, Bures-sur-Yvette, France; Schöttler J., Institute of Psychopharmacology, Central Institute of Mental Health, Medical Faculty Mannheim, University of Heidelberg, Mannheim, Germany; Ercsey-Ravasz M., Faculty of Physics, Babes-Bolyai University, Cluj-Napoca, Romania, Romanian Institute of Science and Technology, Cluj-Napoca, Romania; Cosa-Linan A., Institute of Psychopharmacology, Central Institute of Mental Health, Medical Faculty Mannheim, University of Heidelberg, Mannheim, Germany; Varga M., Physics Department and the Interdisciplinary Center for Network Science and Applications, University of Notre Dame, Notre Dame, IN, United States; Toroczkai Z., Physics Department and the Interdisciplinary Center for Network Science and Applications, University of Notre Dame, Notre Dame, IN, United States; Spanagel R., Institute of Psychopharmacology, Central Institute of Mental Health, Medical Faculty Mannheim, University of Heidelberg, Mannheim, Germany","Understanding the rat neurochemical connectome is fundamental for exploring neuronal information processing. By using advanced data mining, supervised machine learning, and network analysis, this study integrates over 5 decades of neuroanatomical investigations into a multiscale, multilayer neurochemical connectome of the rat brain. This neurochemical connectivity database (ChemNetDB) is supported by comprehensive systematically-determined receptor distribution maps. The rat connectome has an onion-type structural organization and shares a number of structural features with mesoscale connectomes of mouse and macaque. Furthermore, we demonstrate that extremal values of graph theoretical measures (e.g., degree and betweenness) are associated with evolutionary-conserved deep brain structures such as amygdala, bed nucleus of the stria terminalis, dorsal raphe, and lateral hypothalamus, which regulate primitive, yet fundamental functions, such as circadian rhythms, reward, aggression, anxiety, and fear. The ChemNetDB is a freely available resource for systems analysis of motor, sensory, emotional, and cognitive information processing. © 2017 Noori et al.","","Animals; Cluster Analysis; Computer Simulation; Databases, Factual; Models, Biological; Nerve Net; Rats; aggression; amygdala; anxiety; circadian rhythm; connectome; data base; data mining; dorsal region; lateral hypothalamus; Macaca; nonhuman; onion; reward; stria terminalis; supervised machine learning; system analysis; theoretical model; animal; biological model; cluster analysis; computer simulation; factual database; nerve cell network; rat","Public Library of Science","15449173","","PBLIB","28671956","Article","Scopus","2-s2.0-85026767270"
"Furusho Y.; Kubo T.; Ikeda K.","Furusho, Yasutaka (57033853900); Kubo, Takatomi (55318335000); Ikeda, Kazushi (7404890707)","57033853900; 55318335000; 7404890707","Roles of pre-training in deep neural networks from information theoretical perspective","2017","Neurocomputing","9","10.1016/j.neucom.2016.12.083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016000512&doi=10.1016%2fj.neucom.2016.12.083&partnerID=40&md5=2b9eacb32893dc200717a3f045615c1c","Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, 630-0192, Nara, Japan","Furusho Y., Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, 630-0192, Nara, Japan; Kubo T., Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, 630-0192, Nara, Japan; Ikeda K., Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, 630-0192, Nara, Japan","Although deep learning shows high performance in pattern recognition and machine learning, the reasons remain unclarified. To tackle this problem, we calculated the information theoretical variables of the representations in the hidden layers and analyzed their relationship to the performance. We found that entropy and mutual information, both of which decrease in a different way as the layer deepens, are related to the generalization errors after fine-tuning. This suggests that the information theoretical variables might be a criterion for determining the number of layers in deep learning without fine-tuning that requires high computational loads. © 2017 Elsevier B.V.","Deep neural networks; Information theory; Pre-training","Computation theory; Deep neural networks; Information theory; Neural networks; Pattern recognition; Computational loads; Fine tuning; Generalization Error; Hidden layers; Mutual informations; Number of layers; Pre-training; Without fine-tuning; Article; artificial neural network; automated pattern recognition; controlled study; deep neural network; information processing; learning algorithm; machine learning; measurement accuracy; Stacked Autoencoder; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85016000512"
"Salomon M.; Couturier R.; Guyeux C.; Couchot J.-F.; Bahi J.M.","Salomon, M. (9736770200); Couturier, R. (8655841300); Guyeux, C. (35198071500); Couchot, J.-F. (22633267000); Bahi, J.M. (36146744700)","9736770200; 8655841300; 35198071500; 22633267000; 36146744700","Steganalysis via a convolutional neural network using large convolution filters for embedding process with same stego key: A deep learning approach for telemedicine; [Stéganalyse via un réseau de neurones convolutionnel à partir de larges filtres de convolution, pour des embarquements utilisant une seule clé : une approche deep learning pour la télémédecine]","2017","European Research in Telemedicine","26","10.1016/j.eurtel.2017.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023757991&doi=10.1016%2fj.eurtel.2017.06.001&partnerID=40&md5=a9366a09f776ae4a7c3904fd5ee7dcc4","Femto-ST Institute, UMR 6174 CNRS, University of Bourgogne Franche-Comté, 16, route de Gray, Besançon, 25000, France","Salomon M., Femto-ST Institute, UMR 6174 CNRS, University of Bourgogne Franche-Comté, 16, route de Gray, Besançon, 25000, France; Couturier R., Femto-ST Institute, UMR 6174 CNRS, University of Bourgogne Franche-Comté, 16, route de Gray, Besançon, 25000, France; Guyeux C., Femto-ST Institute, UMR 6174 CNRS, University of Bourgogne Franche-Comté, 16, route de Gray, Besançon, 25000, France; Couchot J.-F., Femto-ST Institute, UMR 6174 CNRS, University of Bourgogne Franche-Comté, 16, route de Gray, Besançon, 25000, France; Bahi J.M., Femto-ST Institute, UMR 6174 CNRS, University of Bourgogne Franche-Comté, 16, route de Gray, Besançon, 25000, France","Introduction Steganography, the art to hide information inside host media like pictures and movies, and steganalysis, its countermeasure attempting to detect the presence of an hidden information within an innocent-looking document, are frequently reported as promising information security techniques for telemedicine. For the past few years, in the race between image steganography and steganalysis, deep learning has emerged as a very promising alternative to steganalyzer approaches based on rich image models combined with ensemble classifiers. A key knowledge of image steganalyzer, which combines relevant image features and innovative classification procedures, can be deduced by a deep learning approach called convolutional neural networks (CNN). This kind of deep learning networks is so well-suited for classification tasks based on the detection of variations in 2D shapes that it is the state-of-the-art in many image recognition problems. Materials and methods We design a CNN-based steganalyzer for images obtained by applying steganography with a unique embedding key. The proposed CNN has a quite different shape compared to the ones resulting from the earlier works, and it is able to provide high detection accuracy for several steganographics tools when the same stego key is reused during the embedding process. The convolutional part of our proposal starts by a global filtering, using a single filter, followed by a second convolutional layer that produces a reduced set of high-level features (256 features for 512 × 512 pixels input images) thanks to the use of large filters. Results The proposed architecture embeds less convolutions, with much larger filters in the final convolutional layer, and is more general: it is able to deal with larger images and lower payloads. For the “same embedding key” scenario, our proposal outperforms all other steganalyzers, in particular the existing CNN-based ones, and defeats many state-of-the-art image steganography schemes. The information encoded by the final vector of features is so discriminating that the classifier part can be reduced to only two output neurons. We finally evaluated the detection ability of the CNN against two spatial domain steganographic schemes and a frequency domain one. More precisely, we designed a perfect steganalyzer for embedding payloads of 0.4 bit per pixel, and for all the steganographic tools investigated in this article (working either in spatial or in frequency domains). Rather interesting results have been obtained too, albeit to a lesser extent, for a payload value of 0.1 bpp. Discussion and conclusions The obtained results are very encouraging, and they outperform all the previous deep learning proposals for steganalysis. A first step in the design of a universal detector has been achieved too, as we are able to detect HUGO based hidden messages even when a WOW steganographier has been used during the training stage. These results allow us to propose to add fragile watermarks on media like pictures or pdf medical documents, to guarantee the authenticity of the material: any attempt of modification of the support will alter the watermark, proving by doing so the modification. Another application is to add personal and medical information inside medical images. © 2017 Elsevier Masson SAS","Deep learning; Steganalyzis; Steganography; Telemedicine security","analysis; Article; classifier; convolutional neural network; embedding; filtration; human; machine learning; nerve cell; priority journal; steganalysis; telemedicine","Elsevier Masson SAS","2212764X","","","","Article","Scopus","2-s2.0-85023757991"
"Wu H.; Lorenson A.; Anderson B.; Witteman L.; Wu H.; Meredig B.; Morgan D.","Wu, Henry (55770811200); Lorenson, Aren (57193843198); Anderson, Ben (57213451172); Witteman, Liam (57193852720); Wu, Haotian (57193854418); Meredig, Bryce (36176190400); Morgan, Dane (7403985808)","55770811200; 57193843198; 57213451172; 57193852720; 57193854418; 36176190400; 7403985808","Robust FCC solute diffusion predictions from ab-initio machine learning methods","2017","Computational Materials Science","57","10.1016/j.commatsci.2017.03.052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017139092&doi=10.1016%2fj.commatsci.2017.03.052&partnerID=40&md5=bfadac56aa6d35715ce3c33be487bcf8","Department of Materials Science and Engineering, University of Wisconsin-Madison, Madison, United States; Citrine Informatics, Redwood City, 94061, CA, United States","Wu H., Department of Materials Science and Engineering, University of Wisconsin-Madison, Madison, United States; Lorenson A., Department of Materials Science and Engineering, University of Wisconsin-Madison, Madison, United States; Anderson B., Department of Materials Science and Engineering, University of Wisconsin-Madison, Madison, United States; Witteman L., Department of Materials Science and Engineering, University of Wisconsin-Madison, Madison, United States; Wu H., Department of Materials Science and Engineering, University of Wisconsin-Madison, Madison, United States; Meredig B., Citrine Informatics, Redwood City, 94061, CA, United States; Morgan D., Department of Materials Science and Engineering, University of Wisconsin-Madison, Madison, United States","We evaluate the performance of four machine learning methods for modeling and predicting FCC solute diffusion barriers. More than 200 FCC solute diffusion barriers from previous density functional theory (DFT) calculations served as our dataset to train four machine learning methods: linear regression (LR), decision tree (DT), Gaussian kernel ridge regression (GKRR), and artificial neural network (ANN). We separately optimize key physical descriptors favored by each method to model diffusion barriers. We also assess the ability of each method to extrapolate when faced with new hosts with limited known data. GKRR and ANN were found to perform the best, showing 0.15 eV cross-validation errors and predicting impurity diffusion in new hosts to within 0.2 eV when given only 5 data points from the host. We demonstrate the success of a combined DFT + data mining approach towards solving materials science challenges and predict the diffusion barrier of all available impurities across all FCC hosts. © 2017","Data-mining; DFT; Diffusion; Machine learning; Neural network","Artificial intelligence; Calculations; Data mining; Decision theory; Decision trees; Deep neural networks; Density functional theory; Diffusion; Diffusion in solids; Forecasting; Impurities; Learning systems; Neural networks; Regression analysis; Ab initio; Cross validation errors; Data points; Descriptors; Gaussian kernels; Impurity diffusion; Machine learning methods; Solute diffusion; Diffusion barriers","Elsevier B.V.","09270256","","CMMSE","","Article","Scopus","2-s2.0-85017139092"
"Zhang S.; Grave E.; Sklar E.; Elhadad N.","Zhang, Shaodian (55150032900); Grave, Edouard (55208388000); Sklar, Elizabeth (7003818615); Elhadad, Noémie (6505774943)","55150032900; 55208388000; 7003818615; 6505774943","Longitudinal analysis of discussion topics in an online breast cancer community using convolutional neural networks","2017","Journal of Biomedical Informatics","45","10.1016/j.jbi.2017.03.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015998929&doi=10.1016%2fj.jbi.2017.03.012&partnerID=40&md5=66792a8c3f8c52fd4879ca135a5a72c3","Department of Biomedical Informatics, Columbia University, New York, NY, United States; King's College London, London, United Kingdom","Zhang S., Department of Biomedical Informatics, Columbia University, New York, NY, United States; Grave E., Department of Biomedical Informatics, Columbia University, New York, NY, United States; Sklar E., King's College London, London, United Kingdom; Elhadad N., Department of Biomedical Informatics, Columbia University, New York, NY, United States","Identifying topics of discussions in online health communities (OHC) is critical to various information extraction applications, but can be difficult because topics of OHC content are usually heterogeneous and domain-dependent. In this paper, we provide a multi-class schema, an annotated dataset, and supervised classifiers based on convolutional neural network (CNN) and other models for the task of classifying discussion topics. We apply the CNN classifier to the most popular breast cancer online community, and carry out cross-sectional and longitudinal analyses to show topic distributions and topic dynamics throughout members’ participation. Our experimental results suggest that CNN outperforms other classifiers in the task of topic classification and identify several patterns and trajectories. For example, although members discuss mainly disease-related topics, their interest may change through time and vary with their disease severities. © 2017","Breast cancer; Convolutional neural network; Deep learning; Longitudinal analysis; Online health community; Topic","Breast Neoplasms; Cross-Sectional Studies; Female; Humans; Internet; Neural Networks (Computer); Patient Participation; Classification (of information); Convolution; Deep learning; Diseases; Neural networks; Breast Cancer; Convolutional neural network; Longitudinal analysis; Online health communities; Topic; Article; artificial neural network; breast cancer; cancer staging; classification algorithm; controlled study; cross-sectional study; human; illness trajectory; longitudinal study; online system; support vector machine; breast tumor; female; Internet; patient participation; Data mining","Academic Press Inc.","15320464","","JBIOB","28323113","Article","Scopus","2-s2.0-85015998929"
"Luo Y.; Ahmad F.S.; Shah S.J.","Luo, Yuan (55712619800); Ahmad, Faraz S. (54392524600); Shah, Sanjiv J. (12545068000)","55712619800; 54392524600; 12545068000","Tensor Factorization for Precision Medicine in Heart Failure with Preserved Ejection Fraction","2017","Journal of Cardiovascular Translational Research","34","10.1007/s12265-016-9727-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010748886&doi=10.1007%2fs12265-016-9727-8&partnerID=40&md5=247a184313a6bc8e2145154e3a29a2d4","Department of Preventive Medicine, Northwestern University Feinberg School of Medicine, 11th Floor, Arthur Rubloff Building, 750 N. Lake Shore Drive, Chicago, 60611, IL, United States; Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, IL, United States","Luo Y., Department of Preventive Medicine, Northwestern University Feinberg School of Medicine, 11th Floor, Arthur Rubloff Building, 750 N. Lake Shore Drive, Chicago, 60611, IL, United States; Ahmad F.S., Department of Preventive Medicine, Northwestern University Feinberg School of Medicine, 11th Floor, Arthur Rubloff Building, 750 N. Lake Shore Drive, Chicago, 60611, IL, United States, Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Shah S.J., Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, IL, United States","Heart failure with preserved ejection fraction (HFpEF) is a heterogeneous clinical syndrome that may benefit from improved subtyping in order to better characterize its pathophysiology and to develop novel targeted therapies. The United States Precision Medicine Initiative comes amid the rapid growth in quantity and modality of clinical data for HFpEF patients ranging from deep phenotypic to trans-omic data. Tensor factorization, a form of machine learning, allows for the integration of multiple data modalities to derive clinically relevant HFpEF subtypes that may have significant differences in underlying pathophysiology and differential response to therapies. Tensor factorization also allows for better interpretability by supporting dimensionality reduction and identifying latent groups of data for meaningful summarization of both features and disease outcomes. In this narrative review, we analyze the modest literature on the application of tensor factorization to related biomedical fields including genotyping and phenotyping. Based on the cited work including work of our own, we suggest multiple tensor factorization formulations capable of integrating the deep phenotypic and trans-omic modalities of data for HFpEF, or accounting for interactions between genetic variants at different omic hierarchies. We encourage extensive experimental studies to tackle challenges in applying tensor factorization for precision medicine in HFpEF, including effectively incorporating existing medical knowledge, properly accounting for uncertainty, and efficiently enforcing sparsity for better interpretability. © 2017, Springer Science+Business Media New York.","Big data; Heart failure with preserved ejection fraction; Machine learning; Precision medicine; Tensor factorization; Trans-omics","Comorbidity; Echocardiography; Genetic Predisposition to Disease; Genomics; Heart Failure; Humans; Machine Learning; Phenotype; Precision Medicine; Predictive Value of Tests; Prognosis; Risk Factors; Stroke Volume; Systems Biology; Systems Integration; Article; biomedicine; data analysis; data complexity; data mining; echocardiography; electrocardiogram; genetic variability; genome-wide association study; genotype; heart failure with preserved ejection fraction; human; machine learning; multimodal imaging; next generation sequencing; personalized medicine; phenotype; priority journal; RNA sequence; tensor factorization; United States; classification; comorbidity; genetic predisposition; genetics; genomics; heart failure; heart stroke volume; pathophysiology; personalized medicine; predictive value; procedures; prognosis; risk factor; system analysis; systems biology","Springer New York LLC","19375387","","","28116551","Article","Scopus","2-s2.0-85010748886"
"Ragoza M.; Hochuli J.; Idrobo E.; Sunseri J.; Koes D.R.","Ragoza, Matthew (57190972676); Hochuli, Joshua (57194064510); Idrobo, Elisa (57194066229); Sunseri, Jocelyn (6506162431); Koes, David Ryan (6504625843)","57190972676; 57194064510; 57194066229; 6506162431; 6504625843","Protein-Ligand Scoring with Convolutional Neural Networks","2017","Journal of Chemical Information and Modeling","509","10.1021/acs.jcim.6b00740","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018558434&doi=10.1021%2facs.jcim.6b00740&partnerID=40&md5=d6bd98cfd81f516c6aabd3dd8aff789f","Department of Neuroscience, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Department of Computer Science, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Department of Biological Sciences, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Department of Computational and Systems Biology, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Department of Computer Science, College of New Jersey, Ewing, 08628, NJ, United States","Ragoza M., Department of Neuroscience, University of Pittsburgh, Pittsburgh, 15260, PA, United States, Department of Computer Science, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Hochuli J., Department of Computer Science, University of Pittsburgh, Pittsburgh, 15260, PA, United States, Department of Biological Sciences, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Idrobo E., Department of Computer Science, College of New Jersey, Ewing, 08628, NJ, United States; Sunseri J., Department of Computational and Systems Biology, University of Pittsburgh, Pittsburgh, 15260, PA, United States; Koes D.R., Department of Computational and Systems Biology, University of Pittsburgh, Pittsburgh, 15260, PA, United States","Computational approaches to drug discovery can reduce the time and cost associated with experimental assays and enable the screening of novel chemotypes. Structure-based drug design methods rely on scoring functions to rank and predict binding affinities and poses. The ever-expanding amount of protein-ligand binding and structural data enables the use of deep machine learning techniques for protein-ligand scoring. We describe convolutional neural network (CNN) scoring functions that take as input a comprehensive three-dimensional (3D) representation of a protein-ligand interaction. A CNN scoring function automatically learns the key features of protein-ligand interactions that correlate with binding. We train and optimize our CNN scoring functions to discriminate between correct and incorrect binding poses and known binders and nonbinders. We find that our CNN scoring function outperforms the AutoDock Vina scoring function when ranking poses both for pose prediction and virtual screening. © 2017 American Chemical Society.","","Computational Biology; Drug Evaluation, Preclinical; Ligands; Models, Molecular; Neural Networks (Computer); Protein Conformation; Proteins; User-Computer Interface; Binders; Binding energy; Convolution; Deep learning; Learning systems; Ligands; Proteins; ligand; protein; Binding affinities; Computational approach; Machine learning techniques; Protein-ligand interactions; Scoring functions; Structure based drug designs; Three dimensional (3D) representation; Virtual Screening; artificial neural network; biology; chemistry; computer interface; metabolism; molecular model; preclinical study; procedures; protein conformation; Convolutional neural networks","American Chemical Society","15499596","","JCISD","28368587","Article","Scopus","2-s2.0-85018558434"
"Dervishi A.","Dervishi, Albion (57194463114)","57194463114","Fuzzy risk stratification and risk assessment model for clinical monitoring in the ICU","2017","Computers in Biology and Medicine","9","10.1016/j.compbiomed.2017.05.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020266546&doi=10.1016%2fj.compbiomed.2017.05.034&partnerID=40&md5=3b45dfbefeacf2244a0c39098e9b60d0","Berliner Straße 27d, Lutherstadt Wittenberg, 06886, Germany","Dervishi A., Berliner Straße 27d, Lutherstadt Wittenberg, 06886, Germany","Background The decisions that clinicians make in intensive care units (ICUs) based on monitored parameters reflecting physiological deterioration are of major medical and biomedical engineering interest. These parameters have been investigated and assessed for their usefulness in risk assessment. Methods Totally, 127 ICU adult patients were studied. They were selected from a MIMIC II Waveform Database Matched Subset and had continuous monitoring of heart rate, invasive blood pressure, and oxygen saturation. The monitored data were dimension reduced using deep learning autoencoders and then used to train a support vector machine model (SVM). A combination of methods including fuzzy c-means clustering (FCM), and a random forest (RF) was used to determine the risk levels. Results When classifying patients into stable or deteriorating groups the main performance parameter was the receiver operating characteristics (ROC). The area under the ROC (AUROC) was 93.2 (95% CI (92.9–93.4)) with sensitivity and specificity values of 0.80 and 0.89, respectively. The suggested fuzzy risk levels using the combined method of the FCM clustering and RF achieved an accuracy of 1 (0.9999, 1), with both sensitivity and specificity values equal to 1. Conclusions The potential for using models in risk assessment to estimate a patient's physiological status, stable or deteriorating, within 4 h has been demonstrated. The study was based on retrospective analysis and further studies are needed to evaluate the impact on clinical outcomes using this model. © 2017 Elsevier Ltd","Decision support; Fuzzy C-means; Fuzzy risk; ICU risk stratification; Physiologic monitoring; Random forest; SVM","Fuzzy Logic; Humans; Intensive Care Units; Monitoring, Physiologic; Risk Assessment; Biomedical engineering; Blood pressure; Decision support systems; Decision trees; Deterioration; Fuzzy systems; Intensive care units; Physiological models; Physiology; Risk perception; Support vector machines; Decision supports; Fuzzy C mean; Fuzzy risk; Physiologic monitoring; Random forests; Risk stratification; adult; area under the curve; arterial pressure; Article; blood pressure monitoring; comparative study; controlled study; diastolic blood pressure; fuzzy c means clustering; fuzzy logic; heart arrest; heart rate; heart rate measurement; heart rate variability; human; intensive care unit; major clinical study; mean arterial pressure; oxygen saturation; physiologic monitoring; priority journal; random forest; receiver operating characteristic; risk assessment; sensitivity and specificity; support vector machine; systolic blood pressure; fuzzy logic; intensive care unit; organization and management; physiologic monitoring; procedures; Risk assessment","Elsevier Ltd","00104825","","CBMDA","28599216","Article","Scopus","2-s2.0-85020266546"
"He J.; Yang S.; Gan C.","He, Jun (57214005033); Yang, Shixi (7406949168); Gan, Chunbiao (7006659530)","57214005033; 7406949168; 7006659530","Unsupervised fault diagnosis of a gear transmission chain using a deep belief network","2017","Sensors (Switzerland)","67","10.3390/s17071564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021731047&doi=10.3390%2fs17071564&partnerID=40&md5=4a702e9878c05535dedaaae7d42bffdb","The State Key Laboratory of Fluid Power and Mechatronic Systems, College of Mechanical Engineering, Zhejiang University, Hangzhou, 310027, China; The Key Laboratory of Advanced Manufacturing Technology of Zhejiang Province, College of Mechanical Engineering, Zhejiang University, Hangzhou, 310027, China","He J., The State Key Laboratory of Fluid Power and Mechatronic Systems, College of Mechanical Engineering, Zhejiang University, Hangzhou, 310027, China, The Key Laboratory of Advanced Manufacturing Technology of Zhejiang Province, College of Mechanical Engineering, Zhejiang University, Hangzhou, 310027, China; Yang S., The State Key Laboratory of Fluid Power and Mechatronic Systems, College of Mechanical Engineering, Zhejiang University, Hangzhou, 310027, China, The Key Laboratory of Advanced Manufacturing Technology of Zhejiang Province, College of Mechanical Engineering, Zhejiang University, Hangzhou, 310027, China; Gan C., The State Key Laboratory of Fluid Power and Mechatronic Systems, College of Mechanical Engineering, Zhejiang University, Hangzhou, 310027, China, The Key Laboratory of Advanced Manufacturing Technology of Zhejiang Province, College of Mechanical Engineering, Zhejiang University, Hangzhou, 310027, China","Artificial intelligence (AI) techniques, which can effectively analyze massive amounts of fault data and automatically provide accurate diagnosis results, have been widely applied to fault diagnosis of rotating machinery. Conventional AI methods are applied using features selected by a human operator, which are manually extracted based on diagnostic techniques and field expertise. However, developing robust features for each diagnostic purpose is often labour-intensive and time-consuming, and the features extracted for one specific task may be unsuitable for others. In this paper, a novel AI method based on a deep belief network (DBN) is proposed for the unsupervised fault diagnosis of a gear transmission chain, and the genetic algorithm is used to optimize the structural parameters of the network. Compared to the conventional AI methods, the proposed method can adaptively exploit robust features related to the faults by unsupervised feature learning, thus requires less prior knowledge about signal processing techniques and diagnostic expertise. Besides, it is more powerful at modelling complex structured data. The effectiveness of the proposed method is validated using datasets from rolling bearings and gearbox. To show the superiority of the proposed method, its performance is compared with two well-known classifiers, i.e., back propagation neural network (BPNN) and support vector machine (SVM). The fault classification accuracies are 99.26% for rolling bearings and 100% for gearbox when using the proposed method, which are much higher than that of the other two methods. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Deep belief networks; Fault diagnosis; Gear transmission chain; Unsupervised feature learning","Bayesian networks; Bearings (machine parts); Chains; Complex networks; Deep learning; Education; Failure analysis; Gears; Genetic algorithms; Machinery; Neural networks; Power transmission; Roller bearings; Signal processing; Support vector machines; Back-propagation neural networks; Deep belief network (DBN); Deep belief networks; Fault classification accuracy; Fault diagnosis of rotating machineries; Gear transmissions; Signal processing technique; Unsupervised feature learning; algorithm; article; back propagation neural network; deep belief network; diagnostic test accuracy study; genetic algorithm; human; learning; signal processing; support vector machine; Fault detection","MDPI AG","14248220","","","28677638","Article","Scopus","2-s2.0-85021731047"
"Fu X.; Liu W.; Xu Y.; Cui L.","Fu, Xianghua (9238038200); Liu, Wangwang (57193539671); Xu, Yingying (57157656700); Cui, Laizhong (35736733600)","9238038200; 57193539671; 57157656700; 35736733600","Combine HowNet lexicon to train phrase recursive autoencoder for sentence-level sentiment analysis","2017","Neurocomputing","87","10.1016/j.neucom.2017.01.079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014683274&doi=10.1016%2fj.neucom.2017.01.079&partnerID=40&md5=d6cff0db00fa59f4d691f69af50f4db8","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong, 518060, China","Fu X., College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong, 518060, China; Liu W., College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong, 518060, China; Xu Y., College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong, 518060, China; Cui L., College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong, 518060, China","Detecting sentiment of sentences in online reviews is still a challenging task. Traditional machine learning methods often use bag-of-words representations which cannot properly capture complex linguistic phenomena in sentiment analysis. Recently, recursive autoencoder (RAE) methods have been proposed for sentence-level sentiment analysis. They use word embedding to represent each word, and learn compositional vector representation of phrases and sentences with recursive autoencoders. Although RAE methods outperform other state-of-the-art sentiment prediction approaches on commonly used datasets, they tend to generate very deep parse trees, and need a large amount of labeled data for each node during the process of learning compositional vector representations. Furthermore, RAE methods mainly combine adjacent words in sequence with a greedy strategy, which make capturing semantic relations between distant words difficult. To solve these issues, we propose a semi-supervised method which combines HowNet lexicon to train phrase recursive autoencoders (we call it CHL-PRAE). CHL-PRAE constructs the phrase recursive autoencoder (PRAE) model at first. Then the model calculates the sentiment orientation of each node with the HowNet lexicon, which acts as sentiment labels, when we train the softmax classifier of PRAE. Furthermore, our CHL-PRAE model conducts bidirectional training to capture global information. Compared with RAE and some supervised methods such as support vector machine (SVM) and naïve Bayesian on English and Chinese datasets, the experiment results show that CHL-PRAE can provide the best performance for sentence-level sentiment analysis. © 2017 Elsevier B.V.","HowNet lexicon; Phrase structure tree; Recursive autoencoder; Sentiment analysis","Encoding (symbols); Forestry; Large dataset; Semantics; Semi-supervised learning; Sentiment analysis; Support vector machines; Trees (mathematics); Auto encoders; Global informations; HowNet lexicons; Linguistic phenomena; Machine learning methods; Phrase structure trees; Semi-supervised method; Vector representations; Article; Bayesian learning; Chinese (language); classifier; English (language); linguistics; machine learning; natural language processing; recursive autoencoder; semantics; sentiment analysis; support vector machine; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85014683274"
"R. Tavakoli H.; Borji A.; Laaksonen J.; Rahtu E.","R. Tavakoli, Hamed (57201603431); Borji, Ali (23395793600); Laaksonen, Jorma (56253107200); Rahtu, Esa (6505786260)","57201603431; 23395793600; 56253107200; 6505786260","Exploiting inter-image similarity and ensemble of extreme learners for fixation prediction using deep features","2017","Neurocomputing","57","10.1016/j.neucom.2017.03.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017026850&doi=10.1016%2fj.neucom.2017.03.018&partnerID=40&md5=5d4544fe8c7965d1f5ce7bce8d971f1b","Department of Computer Science, Aalto University, PO Box 15400, FI-00076 Aalto, Espoo, Finland; Center for Research in Computer Vision (CRCV), Computer Science Department, University of Central Florida (UCF), Orlando, 32816-2365, Florida, United States; Center for Machine Vision Research, University of Oulu, P.O Box 4500, Oulu, FI-90014, Finland; Tampere University of Technology, PO Box 527, FI-33101, Tampere, Finland","R. Tavakoli H., Department of Computer Science, Aalto University, PO Box 15400, FI-00076 Aalto, Espoo, Finland; Borji A., Center for Research in Computer Vision (CRCV), Computer Science Department, University of Central Florida (UCF), Orlando, 32816-2365, Florida, United States; Laaksonen J., Department of Computer Science, Aalto University, PO Box 15400, FI-00076 Aalto, Espoo, Finland; Rahtu E., Center for Machine Vision Research, University of Oulu, P.O Box 4500, Oulu, FI-90014, Finland, Tampere University of Technology, PO Box 527, FI-33101, Tampere, Finland","This paper presents a novel fixation prediction and saliency modeling framework based on inter-image similarities and ensemble of Extreme Learning Machines (ELM). The proposed framework is inspired by two observations, (1) the contextual information of a scene along with low-level visual cues modulates attention, (2) the influence of scene memorability on eye movement patterns caused by the resemblance of a scene to a former visual experience. Motivated by such observations, we develop a framework that estimates the saliency of a given image using an ensemble of extreme learners, each trained on an image similar to the input image. That is, after retrieving a set of similar images for a given image, a saliency predictor is learnt from each of the images in the retrieved image set using an ELM, resulting in an ensemble. The saliency of the given image is then measured in terms of the mean of predicted saliency value by the ensemble's members. © 2017 Elsevier B.V.","Extreme learning machines; Fixation prediction; Inter-image similarity; Saliency prediction; Visual attention","Behavioral research; Eye movements; Image analysis; Knowledge acquisition; Learning systems; Contextual information; Extreme learning machine; Eye movement patterns; Image similarity; Low-level visual cues; Saliency modeling; Visual Attention; Visual experiences; Article; attention; extreme learning machine; eye movement; image processing; image retrieval; machine learning; prediction; visual memory; Forecasting","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85017026850"
"Yan K.; Xu Y.; Fang X.; Zheng C.; Liu B.","Yan, Ke (55263065600); Xu, Yong (57110954800); Fang, Xiaozhao (36992071500); Zheng, Chunhou (35106317400); Liu, Bin (56151911700)","55263065600; 57110954800; 36992071500; 35106317400; 56151911700","Protein fold recognition based on sparse representation based classification","2017","Artificial Intelligence in Medicine","36","10.1016/j.artmed.2017.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016192536&doi=10.1016%2fj.artmed.2017.03.006&partnerID=40&md5=ef9650281559ac85a77921529c07e858","School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, Guangdong, China; College of Electrical Engineering and Automation, Anhui University, Hefei, 230039, Anhui, China","Yan K., School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, Guangdong, China; Xu Y., School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, Guangdong, China; Fang X., School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, Guangdong, China; Zheng C., College of Electrical Engineering and Automation, Anhui University, Hefei, 230039, Anhui, China; Liu B., School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, Guangdong, China","Knowledge of protein fold type is critical for determining the protein structure and function. Because of its importance, several computational methods for fold recognition have been proposed. Most of them are based on well-known machine learning techniques, such as Support Vector Machines (SVMs), Artificial Neural Network (ANN), etc. Although these machine learning methods play a role in stimulating the development of this important area, new techniques are still needed to further improve the predictive performance for fold recognition. Sparse Representation based Classification (SRC) has been widely used in image processing, and shows better performance than other related machine learning methods. In this study, we apply the SRC to solve the protein fold recognition problem. Experimental results on a widely used benchmark dataset show that the proposed method is able to improve the performance of some basic classifiers and three state-of-the-art methods to feature selection, including autocross-covariance (ACC) fold, D-D, and Bi-gram. Finally, we propose a novel computational predictor called MF-SRC for fold recognition by combining these three features into the framework of SRC to achieve further performance improvement. Compared with other computational methods in this field on DD dataset, EDD dataset and TG dataset, the proposed method achieves stable performance by reducing the influence of the noise in the dataset. It is anticipated that the proposed predictor may become a useful high throughput tool for large-scale fold recognition or at least, play a complementary role to the existing predictors in this regard. © 2017 Elsevier B.V.","Protein fold recognition; Protein representation; Sparse representation based classification","Algorithms; Image Processing, Computer-Assisted; Protein Folding; Proteins; Support Vector Machine; Artificial intelligence; Benchmarking; Computational methods; Deep neural networks; Image processing; Learning systems; Neural networks; Protein folding; Proteins; Support vector machines; protein; Machine learning methods; Machine learning techniques; Predictive performance; Protein fold recognition; Protein structures; Sparse representation based classifications; State-of-the-art methods; Support vector machine (SVMs); amino acid composition; amino acid sequence; Article; hydrophobicity; machine learning; molecular recognition; physical chemistry; priority journal; protein analysis; protein folding; protein secondary structure; sparse representation based classification; algorithm; image processing; support vector machine; Classification (of information)","Elsevier B.V.","09333657","","AIMEE","28359635","Article","Scopus","2-s2.0-85016192536"
"Uziela K.; Hurtado D.M.; Shu N.; Wallner B.; Elofsson A.","Uziela, Karolis (56674583900); Hurtado, David Menéndez (57194470603); Shu, Nanjiang (23976544500); Wallner, Björn (57207559214); Elofsson, Arne (7003471235)","56674583900; 57194470603; 23976544500; 57207559214; 7003471235","ProQ3D: Improved model quality assessments using deep learning","2017","Bioinformatics","123","10.1093/bioinformatics/btw819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020299629&doi=10.1093%2fbioinformatics%2fbtw819&partnerID=40&md5=71936b81e031ac96303eadb0837efa59","Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, 171 21, Sweden; Bioinformatics Short-term Support and Infrastructure (BILS), Science for Life Laboratory, Solna, 171 21, Sweden; Department of Physics, Chemistry and Biology (IFM)/Bioinformatics, Linköping University, Linköping, 581 83, Sweden","Uziela K., Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, 171 21, Sweden; Hurtado D.M., Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, 171 21, Sweden; Shu N., Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, 171 21, Sweden, Bioinformatics Short-term Support and Infrastructure (BILS), Science for Life Laboratory, Solna, 171 21, Sweden; Wallner B., Department of Physics, Chemistry and Biology (IFM)/Bioinformatics, Linköping University, Linköping, 581 83, Sweden; Elofsson A., Department of Biochemistry and Biophysics and Science for Life Laboratory, Stockholm University, Solna, 171 21, Sweden","Summary: Protein quality assessment is a long-standing problem in bioinformatics. For more than a decade we have developed state-of-art predictors by carefully selecting and optimising inputs to a machine learning method. The correlation has increased from 0.60 in ProQ to 0.81 in ProQ2 and 0.85 in ProQ3 mainly by adding a large set of carefully tuned descriptions of a protein. Here, we show that a substantial improvement can be obtained using exactly the same inputs as in ProQ2 or ProQ3 but replacing the support vector machine by a deep neural network. This improves the Pearson correlation to 0.90 (0.85 using ProQ2 input features). Availability and Implementation: ProQ3D is freely available both as a webserver and a stand-alone program at http://proq3.bioinfo.se/ . © The Author 2017.","","Computational Biology; Models, Molecular; Neural Networks (Computer); Protein Conformation; Software; Support Vector Machine; artificial neural network; biology; molecular model; procedures; protein conformation; software; support vector machine","Oxford University Press","13674803","","BOINF","28052925","Article","Scopus","2-s2.0-85020299629"
"Olier J.S.; Barakova E.; Regazzoni C.; Rauterberg M.","Olier, Juan Sebastian (56728417800); Barakova, Emilia (35614959800); Regazzoni, Carlo (35513672400); Rauterberg, Matthias (6701479494)","56728417800; 35614959800; 35513672400; 6701479494","Re-framing the characteristics of concepts and their relation to learning and cognition in artificial agents","2017","Cognitive Systems Research","19","10.1016/j.cogsys.2017.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017450328&doi=10.1016%2fj.cogsys.2017.03.005&partnerID=40&md5=0fece0df38c76170cacc3d42c6b6dc74","Department of Industrial Design, Eindhoven University of Technology, Eindhoven, Netherlands; Department of Electrical, Electronic, Telecommunications Engineering and Naval Architecture, University of Genoa, Genoa, Italy","Olier J.S., Department of Industrial Design, Eindhoven University of Technology, Eindhoven, Netherlands, Department of Electrical, Electronic, Telecommunications Engineering and Naval Architecture, University of Genoa, Genoa, Italy; Barakova E., Department of Industrial Design, Eindhoven University of Technology, Eindhoven, Netherlands; Regazzoni C., Department of Electrical, Electronic, Telecommunications Engineering and Naval Architecture, University of Genoa, Genoa, Italy; Rauterberg M., Department of Industrial Design, Eindhoven University of Technology, Eindhoven, Netherlands","In this work, the problems of knowledge acquisition and information processing are explored in relation to the definitions of concepts and conceptual processing, and their implications for artificial agents. The discussion focuses on views of cognition as a dynamic property in which the world is actively represented in grounded mental states which only have meaning in the action context. Reasoning is understood as an emerging property consequence of actions-environment couplings achieved through experience, and concepts as situated and dynamic phenomena enabling behaviours. Re-framing the characteristics of concepts is considered crucial to overcoming settled beliefs and reinterpreting new understandings in artificial systems. The first part presents a review of concepts from cognitive sciences. Support is found for views on grounded and embodied cognition, describing concepts as dynamic, flexible, context-dependent, and distributedly coded. That is argued to contrast with many technical implementations assuming concepts as categories, whilst explains limitations when grounding amodal symbols, or in unifying learning, perception and reasoning. The characteristics of concepts are linked to methods of active inference, self-organization, and deep learning to address challenges posed and to reinterpret emerging techniques. In a second part, an architecture based on deep generative models is presented to illustrate arguments elaborated. It is evaluated in a navigation task, showing that sufficient representations are created regarding situated behaviours with no semantics imposed on data. Moreover, adequate behaviours are achieved through a dynamic integration of perception and action in a single representational domain and process. © 2017 Elsevier B.V.","Artificial intelligence; Cognition; Concepts; Conceptual representations; Machine Learning; Robotics","Artificial intelligence; Robotics; Robots; Semantics; Cognition; Concepts; Conceptual processing; Conceptual representations; Embodied cognition; Perception and actions; Self organizations; Technical implementation; Article; behavior assessment; behavioral research; cognition; conceptual framework; dynamics; evaluation study; human; integration; learning; mental health; neuroimaging; prediction; proprioception; psychology; self concept; semantics; sensorimotor function; social belief; social support; systematic review (topic); Learning systems","Elsevier B.V.","13890417","","CSROA","","Article","Scopus","2-s2.0-85017450328"
"Witoonchart P.; Chongstitvatana P.","Witoonchart, Peerajak (7801599908); Chongstitvatana, Prabhas (6602703083)","7801599908; 6602703083","Application of structured support vector machine backpropagation to a convolutional neural network for human pose estimation","2017","Neural Networks","21","10.1016/j.neunet.2017.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017507304&doi=10.1016%2fj.neunet.2017.02.005&partnerID=40&md5=3d5a5cce8a6271331cc758be29cf4e02","Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, 17th floor, Engineering 4 Building (Charoenvidsavakham), Phayathai Road, Wang Mai, Pathumwan, Bangkok, 10330, Thailand","Witoonchart P., Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, 17th floor, Engineering 4 Building (Charoenvidsavakham), Phayathai Road, Wang Mai, Pathumwan, Bangkok, 10330, Thailand; Chongstitvatana P., Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, 17th floor, Engineering 4 Building (Charoenvidsavakham), Phayathai Road, Wang Mai, Pathumwan, Bangkok, 10330, Thailand","In this study, for the first time, we show how to formulate a structured support vector machine (SSVM) as two layers in a convolutional neural network, where the top layer is a loss augmented inference layer and the bottom layer is the normal convolutional layer. We show that a deformable part model can be learned with the proposed structured SVM neural network by backpropagating the error of the deformable part model to the convolutional neural network. The forward propagation calculates the loss augmented inference and the backpropagation calculates the gradient from the loss augmented inference layer to the convolutional layer. Thus, we obtain a new type of convolutional neural network called an Structured SVM convolutional neural network, which we applied to the human pose estimation problem. This new neural network can be used as the final layers in deep learning. Our method jointly learns the structural model parameters and the appearance model parameters. We implemented our method as a new layer in the existing Caffe library. © 2017 Elsevier Ltd","Back propagation; Convolutional neural network; Deformable part model; Human pose estimation; Structured support vector machine","Biometric Identification; Humans; Neural Networks (Computer); Posture; Support Vector Machine; Backpropagation; Convolution; Convolutional neural networks; Deep learning; Support vector machines; Appearance modeling; Bottom layers; Deformable part models; Forward propagation; Human pose estimations; Structural model parameters; Structured supports; Structured SVM; analytic method; Article; artificial neural network; back propagation; feasibility study; human; human pose estimation problem; learning algorithm; mathematical parameters; priority journal; structural model; support vector machine; biometry; body position; procedures; Multilayer neural networks","Elsevier Ltd","08936080","","NNETE","28433431","Article","Scopus","2-s2.0-85017507304"
"Li S.; Jiang H.; Pang W.","Li, Siqi (57192949847); Jiang, Huiyan (14628756900); Pang, Wenbo (57193774375)","57192949847; 14628756900; 57193774375","Joint multiple fully connected convolutional neural network with extreme learning machine for hepatocellular carcinoma nuclei grading","2017","Computers in Biology and Medicine","55","10.1016/j.compbiomed.2017.03.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016498274&doi=10.1016%2fj.compbiomed.2017.03.017&partnerID=40&md5=5a305b62f41d5147be5a56d5d4022389","Software College, Northeastern University, Shenyang, 110819, China","Li S., Software College, Northeastern University, Shenyang, 110819, China; Jiang H., Software College, Northeastern University, Shenyang, 110819, China; Pang W., Software College, Northeastern University, Shenyang, 110819, China","Accurate cell grading of cancerous tissue pathological image is of great importance in medical diagnosis and treatment. This paper proposes a joint multiple fully connected convolutional neural network with extreme learning machine (MFC-CNN-ELM) architecture for hepatocellular carcinoma (HCC) nuclei grading. First, in preprocessing stage, each grayscale image patch with the fixed size is obtained using center-proliferation segmentation (CPS) method and the corresponding labels are marked under the guidance of three pathologists. Next, a multiple fully connected convolutional neural network (MFC-CNN) is designed to extract the multi-form feature vectors of each input image automatically, which considers multi-scale contextual information of deep layer maps sufficiently. After that, a convolutional neural network extreme learning machine (CNN-ELM) model is proposed to grade HCC nuclei. Finally, a back propagation (BP) algorithm, which contains a new up-sample method, is utilized to train MFC-CNN-ELM architecture. The experiment comparison results demonstrate that our proposed MFC-CNN-ELM has superior performance compared with related works for HCC nuclei grading. Meanwhile, external validation using ICPR 2014 HEp-2 cell dataset shows the good generalization of our MFC-CNN-ELM architecture. © 2017 Elsevier Ltd","Back propagation; Convolutional neural network; Extreme learning machine; Hepatocellular carcinoma nuclei grading; Multiple fully connected layers","Algorithms; Biopsy, Needle; Carcinoma, Hepatocellular; Diagnosis, Computer-Assisted; Histocytochemistry; Humans; Liver; Liver Neoplasms; Machine Learning; Neoplasm Grading; Neural Networks (Computer); Backpropagation; Backpropagation algorithms; Convolution; Diagnosis; Grading; Image processing; Image segmentation; Knowledge acquisition; Medical imaging; Network architecture; Neural networks; eosin; hematoxylin; Comparison result; Contextual information; Convolutional neural network; Extreme learning machine; Gray-scale images; Hepatocellular carcinoma; Multiple fully connected layers; Pathological images; Article; back propagation; cancer diagnosis; cancer grading; cancer patient; cancer tissue; cell nucleus membrane; comparative study; convolutional neural network; diagnostic accuracy; diagnostic imaging; evaluation study; extreme learning machine; golgi membrane; Hep-2 cell line; human; human cell; human tissue; image segmentation; liver cell carcinoma; liver tissue; machine learning; major clinical study; measurement precision; multiple fully connected layer; needle biopsy; priority journal; sensitivity and specificity; tissue slice; tumor biopsy; algorithm; artificial neural network; cancer grading; computer assisted diagnosis; cytochemistry; liver; liver cell carcinoma; liver tumor; pathology; procedures; Learning systems","Elsevier Ltd","00104825","","CBMDA","28365546","Article","Scopus","2-s2.0-85016498274"
"Coutinho E.; Schuller B.","Coutinho, Eduardo (13007931400); Schuller, Björn (6603767415)","13007931400; 6603767415","Shared acoustic codes underlie emotional communication in music and speech—evidence from deep transfer learning","2017","PLoS ONE","21","10.1371/journal.pone.0179289","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021649937&doi=10.1371%2fjournal.pone.0179289&partnerID=40&md5=431c17e776a2fc6f937bdd7008b71812","Department of Music, University of Liverpool, Liverpool, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom","Coutinho E., Department of Music, University of Liverpool, Liverpool, United Kingdom, Department of Computing, Imperial College London, London, United Kingdom; Schuller B., Department of Computing, Imperial College London, London, United Kingdom","Music and speech exhibit striking similarities in the communication of emotions in the acoustic domain, in such a way that the communication of specific emotions is achieved, at least to a certain extent, by means of shared acoustic patterns. From an Affective Sciences points of view, determining the degree of overlap between both domains is fundamental to understand the shared mechanisms underlying such phenomenon. From a Machine learning perspective, the overlap between acoustic codes for emotional expression in music and speech opens new possibilities to enlarge the amount of data available to develop music and speech emotion recognition systems. In this article, we investigate time-continuous predictions of emotion (Arousal and Valence) in music and speech, and the Transfer Learning between these domains. We establish a comparative framework including intra- (i.e., models trained and tested on the same modality, either music or speech) and cross-domain experiments (i.e., models trained in one modality and tested on the other). In the cross-domain context, we evaluated two strategies—the direct transfer between domains, and the contribution of Transfer Learning techniques (feature-representation-transfer based on Denoising Auto Encoders) for reducing the gap in the feature space distributions. Our results demonstrate an excellent cross-domain generalisation performance with and without feature representation transfer in both directions. In the case of music, cross-domain approaches outperformed intra-domain models for Valence estimation, whereas for Speech intra-domain models achieve the best performance. This is the first demonstration of shared acoustic codes for emotional expression in music and speech in the time-continuous domain. © 2017 Coutinho Schuller. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Acoustics; Emotions; Female; Humans; Learning; Male; Music; Speech; arousal; human; human experiment; learning; model; music; prediction; speech; acoustics; emotion; female; learning; male; music; psychology; speech","Public Library of Science","19326203","","POLNC","28658285","Article","Scopus","2-s2.0-85021649937"
"Boža V.; Brejová B.; Vinař T.","Boža, Vladimír (56316290500); Brejová, Broňa (6602915857); Vinař, Tomáš (6507894445)","56316290500; 6602915857; 6507894445","DeepNano: Deep recurrent neural networks for base calling in MinION Nanopore reads","2017","PLoS ONE","137","10.1371/journal.pone.0178751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020469555&doi=10.1371%2fjournal.pone.0178751&partnerID=40&md5=c91f0bc76c370151ef5ca585a35f6acb","Faculty of Mathematics, Physics and Informatics, Comenius University, Bratislava, Slovakia","Boža V., Faculty of Mathematics, Physics and Informatics, Comenius University, Bratislava, Slovakia; Brejová B., Faculty of Mathematics, Physics and Informatics, Comenius University, Bratislava, Slovakia; Vinař T., Faculty of Mathematics, Physics and Informatics, Comenius University, Bratislava, Slovakia","The MinION device by Oxford Nanopore produces very long reads (reads over 100 kBp were reported); however it suffers from high sequencing error rate. We present an opensource DNA base caller based on deep recurrent neural networks and show that the accuracy of base calling is much dependent on the underlying software and can be improved by considering modern machine learning methods. By employing carefully crafted recurrent neural networks, our tool significantly improves base calling accuracy on data from R7.3 version of the platform compared to the default base caller supplied by the manufacturer. On R9 version, we achieve results comparable to Nanonet base caller provided by Oxford Nanopore. Availability of an open source tool with high base calling accuracy will be useful for development of new applications of the MinION device, including infectious disease detection and custom target enrichment during sequencing. © 2017 Boža et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Datasets as Topic; Escherichia coli; High-Throughput Nucleotide Sequencing; Klebsiella pneumoniae; Nanopores; Neural Networks (Computer); Sequence Analysis, DNA; Software; DNA base; accuracy; Article; artificial neural network; base calling; data mining; DeepNano database; DNA fragmentation; DNA sequence; DNA strand; electric current; error; genetic database; information processing; MinION database; nanopore; velocity; Escherichia coli; genetics; high throughput sequencing; information processing; Klebsiella pneumoniae; procedures; software; statistics and numerical data","Public Library of Science","19326203","","POLNC","28582401","Article","Scopus","2-s2.0-85020469555"
"Ibrahim W.; Abadeh M.S.","Ibrahim, Wisam (57212543538); Abadeh, Mohammad Saniee (55663643400)","57212543538; 55663643400","Extracting features from protein sequences to improve deep extreme learning machine for protein fold recognition","2017","Journal of Theoretical Biology","17","10.1016/j.jtbi.2017.03.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016254423&doi=10.1016%2fj.jtbi.2017.03.023&partnerID=40&md5=cdbad2c89388223fe1e547e4cf828c1e","Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","Ibrahim W., Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Abadeh M.S., Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","Protein fold recognition is an important problem in bioinformatics to predict three-dimensional structure of a protein. One of the most challenging tasks in protein fold recognition problem is the extraction of efficient features from the amino-acid sequences to obtain better classifiers. In this paper, we have proposed six descriptors to extract features from protein sequences. These descriptors are applied in the first stage of a three-stage framework PCA-DELM-LDA to extract feature vectors from the amino-acid sequences. Principal Component Analysis PCA has been implemented to reduce the number of extracted features. The extracted feature vectors have been used with original features to improve the performance of the Deep Extreme Learning Machine DELM in the second stage. Four new features have been extracted from the second stage and used in the third stage by Linear Discriminant Analysis LDA to classify the instances into 27 folds. The proposed framework is implemented on the independent and combined feature sets in SCOP datasets. The experimental results show that extracted feature vectors in the first stage could improve the performance of DELM in extracting new useful features in second stage. © 2017 Elsevier Ltd","Extreme learning machine; Feature extraction; Protein descriptor; Protein fold recognition","Amino Acid Sequence; Computational Biology; Datasets as Topic; Machine Learning; Principal Component Analysis; Protein Conformation; Protein Folding; Sequence Analysis, Protein; Sequence Homology, Amino Acid; amino acid; bioinformatics; machine learning; pattern recognition; protein; accuracy; amino acid sequence; Article; auto covariance; autocorrelation descriptor; bioinformatics; classification accuracy; classifier; conjoint triad; controlled study; correlation coefficient; data extraction; deep extreme learning machine; feature extraction; Geary autocorrelation; linear discriminant analysis; local descriptor; machine learning; Matthew correlation coefficient; Moran autocorrelation; Moreau Broto autocorrelation; physical chemistry; principal component analysis; protein analysis; protein database; protein fold recognition; sensitivity and specificity; sequence analysis; statistical analysis; statistical parameters; structure activity relation; structure analysis; amino acid sequence; biology; information processing; protein conformation; protein folding; sequence analysis; sequence homology","Academic Press","00225193","","JTBIA","28351701","Article","Scopus","2-s2.0-85016254423"
"Xu Y.; Jia Z.; Wang L.-B.; Ai Y.; Zhang F.; Lai M.; Chang E.I.-C.","Xu, Yan (57192065052); Jia, Zhipeng (56939734100); Wang, Liang-Bo (57188741922); Ai, Yuqing (56940045000); Zhang, Fang (56939455900); Lai, Maode (7401808601); Chang, Eric I-Chao (7401837784)","57192065052; 56939734100; 57188741922; 56940045000; 56939455900; 7401808601; 7401837784","Large scale tissue histopathology image classification, segmentation, and visualization via deep convolutional activation features","2017","BMC Bioinformatics","302","10.1186/s12859-017-1685-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019707351&doi=10.1186%2fs12859-017-1685-x&partnerID=40&md5=a4970cc9766e3f3841ca65a77000a0aa","State Key Laboratory of Software Development Environment, Key Laboratory of Biomechanics and Mechanobiology of Ministry of Education and Research, Institute of Beihang University in Shenzhen, Beijing, China; Microsoft Research, Beijing, China; Tsinghua University, Institute for Interdisciplinary Information Sciences, Beijing, China; National Taiwan University, Graduate Institute of Biomedical Electronics and Bioinformatics, Taipei, Taiwan; Zhejiang University, Department of Pathology, School of Medicine, Hangzhou, China","Xu Y., State Key Laboratory of Software Development Environment, Key Laboratory of Biomechanics and Mechanobiology of Ministry of Education and Research, Institute of Beihang University in Shenzhen, Beijing, China, Microsoft Research, Beijing, China; Jia Z., Microsoft Research, Beijing, China, Tsinghua University, Institute for Interdisciplinary Information Sciences, Beijing, China; Wang L.-B., Microsoft Research, Beijing, China, National Taiwan University, Graduate Institute of Biomedical Electronics and Bioinformatics, Taipei, Taiwan; Ai Y., Microsoft Research, Beijing, China, Tsinghua University, Institute for Interdisciplinary Information Sciences, Beijing, China; Zhang F., Microsoft Research, Beijing, China, Tsinghua University, Institute for Interdisciplinary Information Sciences, Beijing, China; Lai M., Zhejiang University, Department of Pathology, School of Medicine, Hangzhou, China; Chang E.I.-C., Microsoft Research, Beijing, China","Background: Histopathology image analysis is a gold standard for cancer recognition and diagnosis. Automatic analysis of histopathology images can help pathologists diagnose tumor and cancer subtypes, alleviating the workload of pathologists. There are two basic types of tasks in digital histopathology image analysis: image classification and image segmentation. Typical problems with histopathology images that hamper automatic analysis include complex clinical representations, limited quantities of training images in a dataset, and the extremely large size of singular images (usually up to gigapixels). The property of extremely large size for a single image also makes a histopathology image dataset be considered large-scale, even if the number of images in the dataset is limited. Results: In this paper, we propose leveraging deep convolutional neural network (CNN) activation features to perform classification, segmentation and visualization in large-scale tissue histopathology images. Our framework transfers features extracted from CNNs trained by a large natural image database, ImageNet, to histopathology images. We also explore the characteristics of CNN features by visualizing the response of individual neuron components in the last hidden layer. Some of these characteristics reveal biological insights that have been verified by pathologists. According to our experiments, the framework proposed has shown state-of-the-art performance on a brain tumor dataset from the MICCAI 2014 Brain Tumor Digital Pathology Challenge and a colon cancer histopathology image dataset. Conclusions: The framework proposed is a simple, efficient and effective system for histopathology image automatic analysis. We successfully transfer ImageNet knowledge as deep convolutional activation features to the classification and segmentation of histopathology images with little training data. CNN features are significantly more powerful than expert-designed features. © 2017 The Author(s).","Classification; Deep convolution activation feature; Deep learning; Feature learning; Segmentation","Algorithms; Brain Neoplasms; Carcinoma; Colonic Neoplasms; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Support Vector Machine; Brain; Chemical activation; Classification (of information); Convolution; Deep learning; Deep neural networks; Diagnosis; Diseases; Image analysis; Image classification; Neural networks; Tissue; Tumors; Visualization; Automatic analysis; Biological insight; Convolutional neural network; Deep convolution activation feature; Digital pathologies; Feature learning; Natural image database; State-of-the-art performance; algorithm; artificial neural network; Brain Neoplasms; carcinoma; Colonic Neoplasms; human; image processing; pathology; procedures; support vector machine; Image segmentation","BioMed Central Ltd.","14712105","","BBMIC","28549410","Article","Scopus","2-s2.0-85019707351"
"Arista-Jalife A.; Calderón-Auza G.; Fierro-Radilla A.; Nakano M.","Arista-Jalife, Antonio (55337950600); Calderón-Auza, Gustavo (57189683596); Fierro-Radilla, Atoany (56126272500); Nakano, Mariko (8553290700)","55337950600; 57189683596; 56126272500; 8553290700","Classification of urban aerial images: A comparison between low-semantic descriptors and deep learning; [Clasificación de imágenes urbanas aéreas: Comparación entre descriptores de bajo nivel y aprendizaje profundo]","2017","Informacion Tecnologica","3","10.4067/S0718-07642017000300021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020469792&doi=10.4067%2fS0718-07642017000300021&partnerID=40&md5=82bf2e379dfe00264db81228a428e608","Sección de Estudio de Posgrado e Investigación, ESIME-Culhuacán, Instituto Politécnico Nacional, Av. Santa Ana No. 1000, Coyoacán, Ciudad de México, C.P. 04420, Mexico","Arista-Jalife A., Sección de Estudio de Posgrado e Investigación, ESIME-Culhuacán, Instituto Politécnico Nacional, Av. Santa Ana No. 1000, Coyoacán, Ciudad de México, C.P. 04420, Mexico; Calderón-Auza G., Sección de Estudio de Posgrado e Investigación, ESIME-Culhuacán, Instituto Politécnico Nacional, Av. Santa Ana No. 1000, Coyoacán, Ciudad de México, C.P. 04420, Mexico; Fierro-Radilla A., Sección de Estudio de Posgrado e Investigación, ESIME-Culhuacán, Instituto Politécnico Nacional, Av. Santa Ana No. 1000, Coyoacán, Ciudad de México, C.P. 04420, Mexico; Nakano M., Sección de Estudio de Posgrado e Investigación, ESIME-Culhuacán, Instituto Politécnico Nacional, Av. Santa Ana No. 1000, Coyoacán, Ciudad de México, C.P. 04420, Mexico","This paper presents a comparison between different low-semantic descriptive algorithms coupled with a support vector machine and the deep learning algorithm, for the task of recognition and classification of aerial images. For this task, a database composed of 1200 images is used to fulfill the supervised trainings. The objective consists on classifying images in six categories that are commonly found on urban areas, in order to be used in any part of the world. The results show that with 150 samples of each class, the deep learning algorithm is capable of classifying images of avenues, buildings, industries, natural areas, residential areas and water bodies with an 87% of accuracy. Experimental results also prove that the labeled images as industry and buildings are the most complex ones to distinguish among these two classes, both for low-level descriptors and deep learning techniques.","Aerial images; Database; Deep learning; Support vector machine; Texture descriptors","Database systems; Deep learning; Image classification; Semantics; Support vector machines; Aerial images; Labeled images; Learning techniques; Low level descriptors; Residential areas; Supervised trainings; Texture descriptors; Urban aerial images; Learning algorithms","Centro de Informacion Tecnologica","07168756","","ITECF","","Article","Scopus","2-s2.0-85020469792"
"Zhang J.; Li S.; Wang R.","Zhang, Jianhua (57057829600); Li, Sunan (57215313619); Wang, Rubin (8704451400)","57057829600; 57215313619; 8704451400","Pattern recognition of momentary mental workload based on multi-channel electrophysiological data and ensemble convolutional neural networks","2017","Frontiers in Neuroscience","30","10.3389/fnins.2017.00310","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020110442&doi=10.3389%2ffnins.2017.00310&partnerID=40&md5=fe5e503eb184c64615bad0f75a80c523","School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; School of Sciences, East China University of Science and Technology, Shanghai, China","Zhang J., School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; Li S., School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; Wang R., School of Sciences, East China University of Science and Technology, Shanghai, China","In this paper, we deal with the Mental Workload (MWL) classification problem based on the measured physiological data. First we discussed the optimal depth (i.e., the number of hidden layers) and parameter optimization algorithms for the Convolutional Neural Networks (CNN). The base CNNs designed were tested according to five classification performance indices, namely Accuracy, Precision, F-measure, G-mean, and required training time. Then we developed an Ensemble Convolutional Neural Network (ECNN) to enhance the accuracy and robustness of the individual CNN model. For the ECNN design, three model aggregation approaches (weighted averaging, majority voting and stacking) were examined and a resampling strategy was used to enhance the diversity of individual CNN models. The results of MWL classification performance comparison indicated that the proposed ECNN framework can effectively improve MWL classification performance and is featured by entirely automatic feature extraction and MWL classification, when compared with traditional machine learning methods. © 2017 Zhang, Li and Wang. et al.","Convolutional neural network; Deep learning; Electrophysiology; Ensemble learning; Mental workload; Pattern classification","averaging; classification; electrophysiology; extraction; human; human experiment; machine learning; model; nervous system; pattern recognition; workload","Frontiers Research Foundation","16624548","","","","Article","Scopus","2-s2.0-85020110442"
"Yao C.; Cai D.; Bu J.; Chen G.","Yao, Chengwei (55420945300); Cai, Deng (35228598300); Bu, Jiajun (55684269900); Chen, Gencai (14038605200)","55420945300; 35228598300; 55684269900; 14038605200","Pre-training the deep generative models with adaptive hyperparameter optimization","2017","Neurocomputing","35","10.1016/j.neucom.2017.03.058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017377432&doi=10.1016%2fj.neucom.2017.03.058&partnerID=40&md5=700ab7549ff78aa6965a07e67129f24c","College of Computer Science and Technology, Zhejiang University, China; The state key lab of CAD&CG, College of Computer Science and Technology, Zhejiang University, China","Yao C., College of Computer Science and Technology, Zhejiang University, China; Cai D., The state key lab of CAD&CG, College of Computer Science and Technology, Zhejiang University, China; Bu J., College of Computer Science and Technology, Zhejiang University, China; Chen G., College of Computer Science and Technology, Zhejiang University, China","The performance of many machine learning algorithms depends crucially on the hyperparameter settings, especially in Deep Learning. Manually tuning the hyperparameters is laborious and time consuming. To address this issue, Bayesian optimization (BO) methods and their extensions have been proposed to optimize the hyperparameters automatically. However, they still suffer from highly computational expense when applying to deep generative models (DGMs) due to their strategy of the black-box function optimization. This paper provides a new hyperparameter optimization procedure at the pre-training phase of the DGMs, where we avoid combining all layers as one black-box function by taking advantage of the layer-by-layer learning strategy. Following this procedure, we are able to optimize multiple hyperparameters in an adaptive way by using Gaussian process. In contrast to the traditional BO methods, which mainly focus on the supervised models, the pre-training procedure is unsupervised where there is no validation error can be used. To alleviate this problem, this paper proposes a new holdout loss, the free energy gap, which takes into account both factors of the model fitting and over-fitting. The empirical evaluations demonstrate that our method not only speeds up the process of hyperparameter optimization, but also improves the performances of DGMs significantly in both the supervised and unsupervised learning tasks. © 2017 Elsevier B.V.","Contrastive divergence; Deep generative model; Hyperparameter optimization; Sequential model-based optimization","Free energy; Learning systems; Bayesian optimization; Computational expense; Contrastive divergence; Empirical evaluations; Generative model; Hyper-parameter optimizations; Sequential model; Supervised and unsupervised learning; Article; artificial neural network; Bayesian learning; controlled study; data analysis; deep generative model; Gaussian process; hyperparameter optimization; mathematical computing; mathematical model; performance; process optimization; statistical model; unsupervised machine learning; Learning algorithms","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85017377432"
"Belharbi S.; Chatelain C.; Hérault R.; Adam S.; Thureau S.; Chastan M.; Modzelewski R.","Belharbi, Soufiane (57191838341); Chatelain, Clément (56186063500); Hérault, Romain (15057961600); Adam, Sébastien (7102425754); Thureau, Sébastien (24538044800); Chastan, Mathieu (35408531700); Modzelewski, Romain (24605682200)","57191838341; 56186063500; 15057961600; 7102425754; 24538044800; 35408531700; 24605682200","Spotting L3 slice in CT scans using deep convolutional network and transfer learning","2017","Computers in Biology and Medicine","41","10.1016/j.compbiomed.2017.05.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019734911&doi=10.1016%2fj.compbiomed.2017.05.018&partnerID=40&md5=9d9182ccb2f1c273d907d7ff6522a03d","Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France; Henri Becquerel Center, Department of Nuclear Medicine, Rouen, 76000, France; Henri Becquerel Center, Department of Radiotherapy, Rouen, 76000, France","Belharbi S., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France; Chatelain C., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France; Hérault R., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France; Adam S., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France; Thureau S., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France, Henri Becquerel Center, Department of Radiotherapy, Rouen, 76000, France; Chastan M., Henri Becquerel Center, Department of Nuclear Medicine, Rouen, 76000, France; Modzelewski R., Normandie Univ, UNIROUEN, UNIHAVRE, INSA Rouen, LITIS, Rouen, 76000, France, Henri Becquerel Center, Department of Nuclear Medicine, Rouen, 76000, France","In this article, we present a complete automated system for spotting a particular slice in a complete 3D Computed Tomography exam (CT scan). Our approach does not require any assumptions on which part of the patient's body is covered by the scan. It relies on an original machine learning regression approach. Our models are learned using the transfer learning trick by exploiting deep architectures that have been pre-trained on imageNet database, and therefore it requires very little annotation for its training. The whole pipeline consists of three steps: i) conversion of the CT scans into Maximum Intensity Projection (MIP) images, ii) prediction from a Convolutional Neural Network (CNN) applied in a sliding window fashion over the MIP image, and iii) robust analysis of the prediction sequence to predict the height of the desired slice within the whole CT scan. Our approach is applied to the detection of the third lumbar vertebra (L3) slice that has been found to be representative to the whole body composition. Our system is evaluated on a database collected in our clinical center, containing 642 CT scans from different patients. We obtained an average localization error of 1.91±2.69 slices (less than 5 mm) in an average time of less than 2.5 s/CT scan, allowing integration of the proposed system into daily clinical routines. © 2017 Elsevier Ltd","Convolutional neural networks; Deep learning; Maximum intensity projection; Sarcopenia; Slice detection","Humans; Lumbar Vertebrae; Machine Learning; Neural Networks (Computer); Radiology Information Systems; Tomography, X-Ray Computed; Automation; Biochemistry; Convolution; Deep learning; Forecasting; Learning systems; Neural networks; 3d computed tomographies; Convolutional networks; Convolutional neural network; Deep architectures; Localization errors; Maximum intensity projection; Sarcopenia; Transfer learning; Article; body composition; clinical decision making; clinical evaluation; computed tomography scanner; controlled study; human; image analysis; machine learning; major clinical study; pattern recognition; priority journal; radiologist; third lumbar vertebra; x-ray computed tomography; artificial neural network; diagnostic imaging; lumbar vertebra; procedures; radiology information system; validation study; x-ray computed tomography; Computerized tomography","Elsevier Ltd","00104825","","CBMDA","28558319","Article","Scopus","2-s2.0-85019734911"
"Mofavvaz S.; Sohrabi M.R.; Nezamzadeh-Ejhieh A.","Mofavvaz, Shirin (36639808900); Sohrabi, Mahmoud Reza (55761684600); Nezamzadeh-Ejhieh, Alireza (36135685800)","36639808900; 55761684600; 36135685800","New model for prediction binary mixture of antihistamine decongestant using artificial neural networks and least squares support vector machine by spectrophotometry method","2017","Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy","34","10.1016/j.saa.2017.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017441409&doi=10.1016%2fj.saa.2017.04.001&partnerID=40&md5=5836c207cc12e8a6bd7e9e512a60700d","Department of Chemistry, Azad University, Shahreza Branch, Shahreza, Isfahan, Iran; Department of Chemistry, Faculty of Chemistry, Azad University, North Tehran Branch, Tehran, Iran","Mofavvaz S., Department of Chemistry, Azad University, Shahreza Branch, Shahreza, Isfahan, Iran; Sohrabi M.R., Department of Chemistry, Faculty of Chemistry, Azad University, North Tehran Branch, Tehran, Iran; Nezamzadeh-Ejhieh A., Department of Chemistry, Azad University, Shahreza Branch, Shahreza, Isfahan, Iran","In the present study, artificial neural networks (ANNs) and least squares support vector machines (LS-SVM) as intelligent methods based on absorption spectra in the range of 230‐300 nm have been used for determination of antihistamine decongestant contents. In the first step, one type of network (feed-forward back-propagation) from the artificial neural network with two different training algorithms, Levenberg–Marquardt (LM) and gradient descent with momentum and adaptive learning rate back-propagation (GDX) algorithm, were employed and their performance was evaluated. The performance of the LM algorithm was better than the GDX algorithm. In the second one, the radial basis network was utilized and results compared with the previous network. In the last one, the other intelligent method named least squares support vector machine was proposed to construct the antihistamine decongestant prediction model and the results were compared with two of the aforementioned networks. The values of the statistical parameters mean square error (MSE), Regression coefficient (R2), correlation coefficient (r) and also mean recovery (%), relative standard deviation (RSD) used for selecting the best model between these methods. Moreover, the proposed methods were compared to the high- performance liquid chromatography (HPLC) as a reference method. One way analysis of variance (ANOVA) test at the 95% confidence level applied to the comparison results of suggested and reference methods that there were no significant differences between them. © 2017 Elsevier B.V.","Antihistamine decongestant; Artificial neural networks; Backpropagation GDX algorithm, least square support vector machine; Lavenberg-Marquardt algorithm; Spectrophotometric","Algorithms; Histamine Antagonists; Least-Squares Analysis; Linear Models; Nasal Decongestants; Neural Networks (Computer); Reproducibility of Results; Sensitivity and Specificity; Spectrophotometry; Support Vector Machine; Analysis of variance (ANOVA); Backpropagation; Backpropagation algorithms; Binary mixtures; Chromatography; Deep neural networks; High performance liquid chromatography; Liquid chromatography; Mean square error; Neural networks; Spectrophotometry; Statistical methods; Support vector machines; Vectors; antihistaminic agent; decongestive agent; Antihistamine decongestant; Feed-forward back propagation; Lavenberg-Marquardt algorithm; Least square support vector machines; Least squares support vector machines; Relative standard deviations; Spectrophotometric; Spectrophotometry methods; algorithm; artificial neural network; least square analysis; procedures; reproducibility; sensitivity and specificity; spectrophotometry; statistical model; support vector machine; Least squares approximations","Elsevier B.V.","13861425","","SAMCA","28412664","Article","Scopus","2-s2.0-85017441409"
"Altae-Tran H.; Ramsundar B.; Pappu A.S.; Pande V.","Altae-Tran, Han (55693993200); Ramsundar, Bharath (56097570200); Pappu, Aneesh S. (57195244828); Pande, Vijay (7004966384)","55693993200; 56097570200; 57195244828; 7004966384","Low Data Drug Discovery with One-Shot Learning","2017","ACS Central Science","503","10.1021/acscentsci.6b00367","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026486382&doi=10.1021%2facscentsci.6b00367&partnerID=40&md5=00581be217a12b3477a11c2abbfdad74","Department of Biological Engineering, Massachusetts Institute of Technology, Cambridge, 02139-4307, MA, United States; Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Department of Chemistry, Stanford University, Stanford, 94305, CA, United States","Altae-Tran H., Department of Biological Engineering, Massachusetts Institute of Technology, Cambridge, 02139-4307, MA, United States; Ramsundar B., Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Pappu A.S., Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Pande V., Department of Chemistry, Stanford University, Stanford, 94305, CA, United States","Recent advances in machine learning have made significant contributions to drug discovery. Deep neural networks in particular have been demonstrated to provide significant boosts in predictive power when inferring the properties and activities of small-molecule compounds (Ma, J. et al. J. Chem. Inf. Model. 2015, 55, 263-274). However, the applicability of these techniques has been limited by the requirement for large amounts of training data. In this work, we demonstrate how one-shot learning can be used to significantly lower the amounts of data required to make meaningful predictions in drug discovery applications. We introduce a new architecture, the iterative refinement long short-term memory, that, when combined with graph convolutional neural networks, significantly improves learning of meaningful distance metrics over small-molecules. We open source all models introduced in this work as part of DeepChem, an open-source framework for deep-learning in drug discovery (Ramsundar, B. deepchem.io. https://github.com/deepchem/deepchem, 2016). © 2017 American Chemical Society.","","Deep neural networks; Iterative methods; Molecules; Neural networks; Convolutional neural network; Distance metrics; Drug discovery applications; Iterative refinement; One-shot learning; Open source frameworks; Predictive power; Small molecules; Outsourcing","American Chemical Society","23747943","","","","Article","Scopus","2-s2.0-85026486382"
"Ghosh S.; Sathis Kumar B.; Deivanai K.","Ghosh, Saheb (57195107192); Sathis Kumar, B. (57143498600); Deivanai, Kathir (56111726600)","57195107192; 57143498600; 56111726600","Detection of whales using deep learning methods and neural networks","2017","Asian Journal of Pharmaceutical and Clinical Research","1","10.22159/ajpcr.2017.v10s1.20767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025458384&doi=10.22159%2fajpcr.2017.v10s1.20767&partnerID=40&md5=204fa468774479dfecae7fcd2ee77aed","Department of Computer Science, VIT University, Chennai, Tamil Nadu, India","Ghosh S., Department of Computer Science, VIT University, Chennai, Tamil Nadu, India; Sathis Kumar B., Department of Computer Science, VIT University, Chennai, Tamil Nadu, India; Deivanai K., Department of Computer Science, VIT University, Chennai, Tamil Nadu, India","Deep learning methods are a great machine learning technique which is mostly used in artificial neural networks for pattern recognition. This project is to identify the Whales from under water Bioacoustics network using an efficient algorithm and data model, so that location of the whales can be send to the Ships travelling in the same region in order to avoid collision with the whale or disturbing their natural habitat as much as possible. This paper shows application of unsupervised machine learning techniques with help of deep belief network and manual feature extraction model for better results. © 2017 The Authors.","Deep learning; Machine learning; Neural network; Whale detection","accuracy; acoustics; Article; artificial neural network; automated pattern recognition; back propagation; calculation; Cetacea; classification algorithm; data extraction; deep learning method; Fourier transformation; habitat; machine learning; nonhuman; nonlinear system; receiver operating characteristic; voice","Innovare Academics Sciences Pvt. Ltd","09742441","","","","Article","Scopus","2-s2.0-85025458384"
"Fang L.; Cunefare D.; Wang C.; Guymer R.H.; Li S.; Farsiu S.","Fang, Leyuan (36739090900); Cunefare, David (56768202400); Wang, Chong (57563838900); Guymer, Robyn H. (6603688370); Li, Shutao (7409240361); Farsiu, Sina (6603132896)","36739090900; 56768202400; 57563838900; 6603688370; 7409240361; 6603132896","Automatic segmentation of nine retinal layer boundaries in OCT images of non-exudative AMD patients using deep learning and graph search","2017","Biomedical Optics Express","416","10.1364/BOE.8.002732","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019034945&doi=10.1364%2fBOE.8.002732&partnerID=40&md5=8ccca9ea84f58b39fb51a2030b322a6e","Departments of Biomedical Engineering, Duke University, Durham, 27708, NC, United States; College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China; Centre for Eye Research Australia University of Melbourne, Department of Surgery, Royal Victorian Eye and Ear Hospital, 3002, VIC, Australia; Department of Ophthalmology, Duke University Medical Center, Durham, 27710, NC, United States","Fang L., Departments of Biomedical Engineering, Duke University, Durham, 27708, NC, United States, College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China; Cunefare D., Departments of Biomedical Engineering, Duke University, Durham, 27708, NC, United States; Wang C., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China; Guymer R.H., Centre for Eye Research Australia University of Melbourne, Department of Surgery, Royal Victorian Eye and Ear Hospital, 3002, VIC, Australia; Li S., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China; Farsiu S., Departments of Biomedical Engineering, Duke University, Durham, 27708, NC, United States, Department of Ophthalmology, Duke University Medical Center, Durham, 27710, NC, United States","We present a novel framework combining convolutional neural networks (CNN) and graph search methods (termed as CNN-GS) for the automatic segmentation of nine layer boundaries on retinal optical coherence tomography (OCT) images. CNN-GS first utilizes a CNN to extract features of specific retinal layer boundaries and train a corresponding classifier to delineate a pilot estimate of the eight layers. Next, a graph search method uses the probability maps created from the CNN to find the final boundaries. We validated our proposed method on 60 volumes (2915 B-scans) from 20 human eyes with non-exudative age-related macular degeneration (AMD), which attested to effectiveness of our proposed technique. © 2017 Optical Society of America.","Image analysis; Image processing; Optical coherence tomography","Deep learning; Image analysis; Image processing; Neural networks; Ophthalmology; Optical data processing; Optical tomography; Tomography; Age-related macular degeneration; Automatic segmentations; Convolutional neural network; Graph search methods; Layer boundaries; Probability maps; Retinal layers; Retinal optical coherence tomography; age related macular degeneration; algorithm; Article; artificial neural network; B scan; Bruch membrane; conceptual framework; drusen; human; image segmentation; machine learning; nerve cell; optical coherence tomography; retinal inner nuclear layer; retinal nerve fiber layer thickness; retinal outer plexiform layer; retinal pigment epithelium; retinal thickness; spectral domain optical coherence tomography; Image segmentation","OSA - The Optical Society","21567085","","","","Article","Scopus","2-s2.0-85019034945"
"Lu K.; An X.; Li J.; He H.","Lu, Keyu (56121576200); An, Xiangjing (15623271900); Li, Jian (55910561300); He, Hangen (34769709600)","56121576200; 15623271900; 55910561300; 34769709600","Efficient deep network for vision-based object detection in robotic applications","2017","Neurocomputing","27","10.1016/j.neucom.2017.03.050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016429396&doi=10.1016%2fj.neucom.2017.03.050&partnerID=40&md5=31b28004e0db927b4a97a4d1dde75299","College of Mechatronic Engineering and Automation, National University of Defense Technology, Changsha, 410073, Hunan, China","Lu K., College of Mechatronic Engineering and Automation, National University of Defense Technology, Changsha, 410073, Hunan, China; An X., College of Mechatronic Engineering and Automation, National University of Defense Technology, Changsha, 410073, Hunan, China; Li J., College of Mechatronic Engineering and Automation, National University of Defense Technology, Changsha, 410073, Hunan, China; He H., College of Mechatronic Engineering and Automation, National University of Defense Technology, Changsha, 410073, Hunan, China","Vision-based object detection is essential for a multitude of robotic applications. However, it is also a challenging job due to the diversity of the environments in which such applications are required to operate, and the strict constraints that apply to many robot systems in terms of run-time, power and space. To meet these special requirements of robotic applications, we propose an efficient deep network for vision-based object detection. More specifically, for a given image captured by a robot mount camera, we first introduce a novel proposal layer to efficiently generate potential object bounding-boxes. The proposal layer consists of efficient on-line convolutions and effective off-line optimization. Afterwards, we construct a robust detection layer which contains a multiple population genetic algorithm-based convolutional neural network (MPGA-based CNN) module and a TLD-based multi-frame fusion procedure. Unlike most deep learning based approaches, which rely on GPU, all of the on-line processes in our system are able to run efficiently without GPU support. We perform several experiments to validate each component of our proposed object detection approach and compare the approach with some recently published state-of-the-art object detection algorithms on widely used datasets. The experimental results demonstrate that the proposed network exhibits high efficiency and robustness in object detection tasks. © 2017 Elsevier B.V.","Computer vision; Deep network; MPGA; Object detection; Robotic application","Convolution; Convolutional neural networks; Deep learning; Genetic algorithms; Multilayer neural networks; Object detection; Object recognition; Robotics; Robots; Detection approach; Learning-based approach; MPGA; Multiple population genetic algorithms; Object detection algorithms; Off-line optimization; Robotic applications; Strict constraint; Article; artificial neural network; clinical effectiveness; genetic algorithm; image analysis; information processing; machine learning; mathematical computing; multiple population genetic algorithm based convolutional neural network; process development; process optimization; robotics; validation process; vision based object detection; Computer vision","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85016429396"
"Vareka L.; Mautner P.","Vareka, Lukáš (57209340326); Mautner, Pavel (6507028373)","57209340326; 6507028373","Stacked autoencoders for the P300 component detection","2017","Frontiers in Neuroscience","48","10.3389/fnins.2017.00302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020069785&doi=10.3389%2ffnins.2017.00302&partnerID=40&md5=9abc2e73aa130b9520dc92f47ef85141","Neuroinformatics Research Group, Department of Computer Science and Engineering, Faculty of Applied Sciences, University of West Bohemia, Pilsen, Czech Republic","Vareka L., Neuroinformatics Research Group, Department of Computer Science and Engineering, Faculty of Applied Sciences, University of West Bohemia, Pilsen, Czech Republic; Mautner P., Neuroinformatics Research Group, Department of Computer Science and Engineering, Faculty of Applied Sciences, University of West Bohemia, Pilsen, Czech Republic","Novel neural network training methods (commonly referred to as deep learning) have emerged in recent years. Using a combination of unsupervised pre-training and subsequent fine-tuning, deep neural networks have become one of the most reliable classification methods. Since deep neural networks are especially powerful for high-dimensional and non-linear feature vectors, electroencephalography (EEG) and event-related potentials (ERPs) are one of the promising applications. Furthermore, to the authors' best knowledge, there are very few papers that study deep neural networks for EEG/ERP data. The aim of the experiments subsequently presented was to verify if deep learning-based models can also perform well for single trial P300 classification with possible application to P300-based brain-computer interfaces. The P300 data used were recorded in the EEG/ERP laboratory at the Department of Computer Science and Engineering, University of West Bohemia, and are publicly available. Stacked autoencoders (SAEs) were implemented and compared with some of the currently most reliable state-of-the-art methods, such as LDA and multi-layer perceptron (MLP). The parameters of stacked autoencoders were optimized empirically. The layers were inserted one by one and at the end, the last layer was replaced by a supervised softmax classifier. Subsequently, fine-tuning using backpropagation was performed. The architecture of the neural network was 209-130-100-50-20-2. The classifiers were trained on a dataset merged from four subjects and subsequently tested on different 11 subjects without further training. The trained SAE achieved 69.2% accuracy that was higher (p < 0.01) than the accuracy of MLP (64.9%) and LDA (65.9%). The recall of 58.8% was slightly higher when compared with MLP (56.2%) and LDA (58.4%). Therefore, SAEs could be preferable to other state-of-the-art classifiers for high-dimensional event-related potential feature vectors. 2017 Vareka and Mautner. et al.","Brain-computer interfaces; Deep learning; Event-related potentials; Machine learning; P300; Stacked autoencoders","Article; artificial neural network; brain computer interface; classifier; computer model; discriminant analysis; electroencephalography; event related potential; linear discriminant analysis; machine learning; measurement accuracy; perceptron; process optimization; reliability; stacked autoencoder","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85020069785"
"Romo-Bucheli D.; Janowczyk A.; Gilmore H.; Romero E.; Madabhushi A.","Romo-Bucheli, David (56904277300); Janowczyk, Andrew (26531344300); Gilmore, Hannah (16039479600); Romero, Eduardo (58398542500); Madabhushi, Anant (6603019206)","56904277300; 26531344300; 16039479600; 58398542500; 6603019206","A deep learning based strategy for identifying and associating mitotic activity with gene expression derived risk categories in estrogen receptor positive breast cancers","2017","Cytometry Part A","49","10.1002/cyto.a.23065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013113389&doi=10.1002%2fcyto.a.23065&partnerID=40&md5=f086923545ea1d08dd08220c8858618b","Engineering Faculty, Universidad Nacional de Colombia, Bogotá, DC, Colombia; Biomedical Engineering Department, Case Western Reserve University, Cleveland, OH, United States; Department of Pathology, University Hospitals Cleveland Medical Center, Cleveland, OH, United States","Romo-Bucheli D., Engineering Faculty, Universidad Nacional de Colombia, Bogotá, DC, Colombia; Janowczyk A., Biomedical Engineering Department, Case Western Reserve University, Cleveland, OH, United States; Gilmore H., Department of Pathology, University Hospitals Cleveland Medical Center, Cleveland, OH, United States; Romero E., Engineering Faculty, Universidad Nacional de Colombia, Bogotá, DC, Colombia; Madabhushi A., Biomedical Engineering Department, Case Western Reserve University, Cleveland, OH, United States","The treatment and management of early stage estrogen receptor positive (ER+) breast cancer is hindered by the difficulty in identifying patients who require adjuvant chemotherapy in contrast to those that will respond to hormonal therapy. To distinguish between the more and less aggressive breast tumors, which is a fundamental criterion for the selection of an appropriate treatment plan, Oncotype DX (ODX) and other gene expression tests are typically employed. While informative, these gene expression tests are expensive, tissue destructive, and require specialized facilities. Bloom-Richardson (BR) grade, the common scheme employed in breast cancer grading, has been shown to be correlated with the Oncotype DX risk score. Unfortunately, studies have also shown that the BR grade determined experiences notable inter-observer variability. One of the constituent categories in BR grading is the mitotic index. The goal of this study was to develop a deep learning (DL) classifier to identify mitotic figures from whole slides images of ER+ breast cancer, the hypothesis being that the number of mitoses identified by the DL classifier would correlate with the corresponding Oncotype DX risk categories. The mitosis detector yielded an average F-score of 0.556 in the AMIDA mitosis dataset using a 6-fold validation setup. For a cohort of 174 whole slide images with early stage ER+ breast cancer for which the corresponding Oncotype DX score was available, the distributions of the number of mitoses identified by the DL classifier was found to be significantly different between the high vs low Oncotype DX risk groups (P < 0.01). Comparisons of other risk groups, using both ODX score and histological grade, were also found to present significantly different automated mitoses distributions. Additionally, a support vector machine classifier trained to separate low/high Oncotype DX risk categories using the mitotic count determined by the DL classifier yielded a 83.19% classification accuracy. © 2017 International Society for Advancement of Cytometry. © 2017 International Society for Advancement of Cytometry","breast cancer risk; digital pathology; mitosis detection; whole slide images","Biomarkers, Tumor; Breast Neoplasms; Eosine Yellowish-(YS); Female; Gene Expression; Hematoxylin; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Mitosis; Mitotic Index; Neoplasm Grading; Receptor, ErbB-2; Risk; Support Vector Machine; eosin; epidermal growth factor receptor 2; hematoxylin; tumor marker; breast tumor; cancer grading; computer assisted diagnosis; cytochemistry; female; gene expression; genetics; human; mitosis; mitosis index; pathology; procedures; risk; support vector machine","Wiley-Liss Inc.","15524922","","CPAYA","28192639","Article","Scopus","2-s2.0-85013113389"
"Liu Z.; Yang M.; Wang X.; Chen Q.; Tang B.; Wang Z.; Xu H.","Liu, Zengjian (56488808800); Yang, Ming (57199913759); Wang, Xiaolong (9276464700); Chen, Qingcai (34869206800); Tang, Buzhou (35115621400); Wang, Zhe (55899938200); Xu, Hua (55493876700)","56488808800; 57199913759; 9276464700; 34869206800; 35115621400; 55899938200; 55493876700","Entity recognition from clinical texts via recurrent neural network","2017","BMC Medical Informatics and Decision Making","142","10.1186/s12911-017-0468-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021702868&doi=10.1186%2fs12911-017-0468-7&partnerID=40&md5=7ca7bdc4f23bcdc064309303a40e1a08","Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, China; Pharmacy Department, Shenzhen Second People's Hospital, First Affiliated Hospital, Shenzhen University, Shenzhen, 518035, China; Key Laboratory of Symbolic Computation and Knowledge Engineering, Ministry of Education, Jilin University, Changchun, 130012, China; School of Biomedical Informatics, University of Texas, Health Science Center at Houston, Houston, TX, United States","Liu Z., Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, China; Yang M., Pharmacy Department, Shenzhen Second People's Hospital, First Affiliated Hospital, Shenzhen University, Shenzhen, 518035, China; Wang X., Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, China; Chen Q., Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, China; Tang B., Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, 518055, China, Key Laboratory of Symbolic Computation and Knowledge Engineering, Ministry of Education, Jilin University, Changchun, 130012, China; Wang Z., Key Laboratory of Symbolic Computation and Knowledge Engineering, Ministry of Education, Jilin University, Changchun, 130012, China; Xu H., School of Biomedical Informatics, University of Texas, Health Science Center at Houston, Houston, TX, United States","Background: Entity recognition is one of the most primary steps for text analysis and has long attracted considerable attention from researchers. In the clinical domain, various types of entities, such as clinical entities and protected health information (PHI), widely exist in clinical texts. Recognizing these entities has become a hot topic in clinical natural language processing (NLP), and a large number of traditional machine learning methods, such as support vector machine and conditional random field, have been deployed to recognize entities from clinical texts in the past few years. In recent years, recurrent neural network (RNN), one of deep learning methods that has shown great potential on many problems including named entity recognition, also has been gradually used for entity recognition from clinical texts. Methods: In this paper, we comprehensively investigate the performance of LSTM (long-short term memory), a representative variant of RNN, on clinical entity recognition and protected health information recognition. The LSTM model consists of three layers: input layer - generates representation of each word of a sentence; LSTM layer - outputs another word representation sequence that captures the context information of each word in this sentence; Inference layer - makes tagging decisions according to the output of LSTM layer, that is, outputting a label sequence. Results: Experiments conducted on corpora of the 2010, 2012 and 2014 i2b2 NLP challenges show that LSTM achieves highest micro-average F1-scores of 85.81% on the 2010 i2b2 medical concept extraction, 92.29% on the 2012 i2b2 clinical event detection, and 94.37% on the 2014 i2b2 de-identification, which is considerably competitive with other state-of-the-art systems. Conclusions: LSTM that requires no hand-crafted feature has great potential on entity recognition from clinical texts. It outperforms traditional machine learning methods that suffer from fussy feature engineering. A possible future direction is how to integrate knowledge bases widely existing in the clinical domain into LSTM, which is a case of our future work. Moreover, how to use LSTM to recognize entities in specific formats is also another possible future direction. © 2017 The Author(s).","Clinical notes; Deep learning; Entity recognition; Recurrent neural network; Sequence labeling","Electronic Health Records; Humans; Machine Learning; Medical Informatics; Natural Language Processing; Neural Networks (Computer); extraction; human; human experiment; knowledge base; machine learning; medical information; model; natural language processing; nervous system; short term memory; artificial neural network; electronic health record; medical informatics; natural language processing","BioMed Central Ltd","14726947","","","28699566","Article","Scopus","2-s2.0-85021702868"
"Gao Z.; Ma C.; Song D.; Liu Y.","Gao, Zehai (58339236200); Ma, Cunbao (7402924810); Song, Dong (24779041200); Liu, Yang (58398613400)","58339236200; 7402924810; 24779041200; 58398613400","Deep quantum inspired neural network with application to aircraft fuel system fault diagnosis","2017","Neurocomputing","75","10.1016/j.neucom.2017.01.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011575282&doi=10.1016%2fj.neucom.2017.01.032&partnerID=40&md5=2aa20a7c5b151988a3759a2a1a0cc9f3","School of Aeronautics, Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China","Gao Z., School of Aeronautics, Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China; Ma C., School of Aeronautics, Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China; Song D., School of Aeronautics, Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China; Liu Y., School of Aeronautics, Northwestern Polytechnical University, Xi'an, 710072, Shaanxi, China","Fault diagnosis for aircraft fuel system can not only improve flight security, but also reduce the huge cost due to regular maintenance. It remains a problem because of the complicated system and the heterogeneous failure modes, especially the different failure modes that have similar impacts on the system. This paper uses the deep quantum inspired neural network (DQINN) which is an improved deep quantum network (DQN) to solve such problem. This method is the combination of classical deep belief network (DBN) and quantum inspired neural network (QINN). For the purpose of inheriting the advantages of DBN and QINN, the structure of DQINN is built in a new fashion. From a system perspective, the DQINN is constructed by the linear superposition of multiple DBNs with quantum intervals in the last hidden layer. Experiments conducted on standard datasets show that DQINN outperforms other three classical algorithms. Finally, a normal model of aircraft fuel system is built and four kinds of common failure modes of the core components are injected into this model, respectively. And the DQINN is applied to the aircraft fuel system fault diagnosis. © 2017 Elsevier B.V.","Aircraft fuel system; Deep belief network; Failure mode; Fault diagnosis; Quantum inspired neural network","Aircraft; Aircraft fueling; Aircraft fuels; Deep neural networks; Failure analysis; Failure modes; Fault detection; Fuel systems; Complicated systems; Core components; Deep belief network (DBN); Deep belief networks; Hidden layers; Linear superpositions; Quantum inspired neural networks; Quantum network; aircraft; algorithm; Article; artificial neural network; classical deep belief network; controlled study; deep quantum inspired neural network; flight; machine learning; microelectromechanical system; quantum yield; Neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85011575282"
"Ding C.; Hu Z.; Karmoshi S.; Zhu M.","Ding, Chunhui (56442012300); Hu, Zhengwei (57189306736); Karmoshi, Saleem (56816977500); Zhu, Ming (9238980500)","56442012300; 57189306736; 56816977500; 9238980500","A Novel Two-stage Learning Pipeline for Deep Neural Networks","2017","Neural Processing Letters","4","10.1007/s11063-017-9578-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009841531&doi=10.1007%2fs11063-017-9578-6&partnerID=40&md5=3d3e3f245b0b7a8934cf7d8bb1b47364","University of Science and Technology of China, Hefei, China","Ding C., University of Science and Technology of China, Hefei, China; Hu Z., University of Science and Technology of China, Hefei, China; Karmoshi S., University of Science and Technology of China, Hefei, China; Zhu M., University of Science and Technology of China, Hefei, China","In this work, a training method was proposed for Deep Neural Networks (DNNs) based on a two-stage structure. Local DNN models are trained in all local machines and uploaded to the center with partial training data. These local models are integrated as a new DNN model (combination DNN). With another DNN model (optimization DNN) connected, the combination DNN forms a global DNN model in the center. This results in greater accuracy than local DNN models with smaller amounts of data uploaded. In this case, the bandwidth of the uploaded data is saved, and the accuracy is maintained as well. Experiments are conducted on MNIST dataset, CIFAR-10 dataset and LFW dataset. The results show that with less training data uploaded, the global model produces greater accuracy than local models. Specifically, this method focuses on condition of big data. © 2017, Springer Science+Business Media New York.","Big data; DNN; Two-stage structure","Artificial intelligence; Software engineering; Deep neural networks; Global modeling; Local model; nocv1; Stage structure; Training data; Training methods; Big data","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-85009841531"
"Kraus O.Z.; Grys B.T.; Ba J.; Chong Y.; Frey B.J.; Boone C.; Andrews B.J.","Kraus, Oren Z (56858495300); Grys, Ben T (57192897452); Ba, Jimmy (57189090730); Chong, Yolanda (26533899900); Frey, Brendan J (35459307900); Boone, Charles (55846993600); Andrews, Brenda J (7202643354)","56858495300; 57192897452; 57189090730; 26533899900; 35459307900; 55846993600; 7202643354","Automated analysis of high-content microscopy data with deep learning","2017","Molecular Systems Biology","181","10.15252/msb.20177551","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018293362&doi=10.15252%2fmsb.20177551&partnerID=40&md5=85abfb617992e3a403f3624678fff4a4","Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada; Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, Toronto, ON, Canada; Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada; Cellular Pharmacology, Discovery Sciences, Janssen Pharmaceutical Companies, Johnson & Johnson, Beerse, Belgium; Canadian Institute for Advanced Research, Program on Genetic Networks, Toronto, ON, Canada; Canadian Institute for Advanced Research, Program on Learning in Machines & Brains, Toronto, ON, Canada","Kraus O.Z., Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada, Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, Toronto, ON, Canada; Grys B.T., Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada; Ba J., Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada; Chong Y., Cellular Pharmacology, Discovery Sciences, Janssen Pharmaceutical Companies, Johnson & Johnson, Beerse, Belgium; Frey B.J., Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada, Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, Toronto, ON, Canada, Canadian Institute for Advanced Research, Program on Genetic Networks, Toronto, ON, Canada, Canadian Institute for Advanced Research, Program on Learning in Machines & Brains, Toronto, ON, Canada; Boone C., Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada, Canadian Institute for Advanced Research, Program on Genetic Networks, Toronto, ON, Canada; Andrews B.J., Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, Toronto, ON, Canada, Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada, Canadian Institute for Advanced Research, Program on Genetic Networks, Toronto, ON, Canada","Existing computational pipelines for quantitative analysis of high-content microscopy data rely on traditional machine learning approaches that fail to accurately classify more than a single dataset without substantial tuning and training, requiring extensive analysis. Here, we demonstrate that the application of deep learning to biological image data can overcome the pitfalls associated with conventional machine learning classifiers. Using a deep convolutional neural network (DeepLoc) to analyze yeast cell images, we show improved performance over traditional approaches in the automated classification of protein subcellular localization. We also demonstrate the ability of DeepLoc to classify highly divergent image sets, including images of pheromone-arrested cells with abnormal cellular morphology, as well as images generated in different genetic backgrounds and in different laboratories. We offer an open-source implementation that enables updating DeepLoc on new microscopy datasets. This study highlights deep learning as an important tool for the expedited analysis of high-content microscopy data. © 2017 The Authors. Published under the terms of the CC BY 4.0 license","deep learning; high-content screening; image analysis; machine learning; Saccharomyces cerevisiae","Machine Learning; Microscopy; Neural Networks (Computer); Saccharomyces cerevisiae; Saccharomyces cerevisiae Proteins; Systems Biology; pheromone; protein; Saccharomyces cerevisiae protein; accuracy; actin filament; Article; cell structure; cellular distribution; genetic background; high content microscopy; image analysis; machine learning; microscopy; nonhuman; peroxisome; priority journal; protein localization; spindle pole body; yeast cell; artificial neural network; metabolism; microscopy; procedures; Saccharomyces cerevisiae; systems biology; ultrastructure","Blackwell Publishing Ltd","17444292","","","28420678","Article","Scopus","2-s2.0-85018293362"
"Baig M.M.; Awais M.M.; El-Alfy E.-S.M.","Baig, Mirza M. (57220647902); Awais, Mian.M. (8656394500); El-Alfy, El-Sayed M. (7003943902)","57220647902; 8656394500; 7003943902","AdaBoost-based artificial neural network learning","2017","Neurocomputing","69","10.1016/j.neucom.2017.02.077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016972562&doi=10.1016%2fj.neucom.2017.02.077&partnerID=40&md5=42b098c93bd58ba09dd132d80af2363e","School of Science and Engineering (SSE), Lahore University of Management Sciences (LUMS), Lahore, 54792, Pakistan; Information and Computer Science Department, College of Computer Sciences and Engineering, King Fahd University of Petroleum and Minerals, Dhahran, 31261, Saudi Arabia","Baig M.M., School of Science and Engineering (SSE), Lahore University of Management Sciences (LUMS), Lahore, 54792, Pakistan; Awais M.M., School of Science and Engineering (SSE), Lahore University of Management Sciences (LUMS), Lahore, 54792, Pakistan; El-Alfy E.-S.M., Information and Computer Science Department, College of Computer Sciences and Engineering, King Fahd University of Petroleum and Minerals, Dhahran, 31261, Saudi Arabia","A boosting-based method of learning a feed-forward artificial neural network (ANN) with a single layer of hidden neurons and a single output neuron is presented. Initially, an algorithm called Boostron is described that learns a single-layer perceptron using AdaBoost and decision stumps. It is then extended to learn weights of a neural network with a single hidden layer of linear neurons. Finally, a novel method is introduced to incorporate non-linear activation functions in artificial neural network learning. The proposed method uses series representation to approximate non-linearity of activation functions, learns the coefficients of nonlinear terms by AdaBoost. It adapts the network parameters by a layer-wise iterative traversal of neurons and an appropriate reduction of the problem. A detailed performances comparison of various neural network models learned the proposed methods and those learned using the least mean squared learning (LMS) and the resilient back-propagation (RPROP) is provided in this paper. Several favorable results are reported for 17 synthetic and real-world datasets with different degrees of difficulties for both binary and multi-class problems. © 2017","AdaBoost; Artificial neural network; Boostron; Ensemble learning; Perceptron","Adaptive boosting; Backpropagation; Chemical activation; Deep neural networks; Iterative methods; Neurons; Activation functions; Boostron; Ensemble learning; Feed-forward artificial neural networks; Nonlinear activation functions; Resilient backpropagation; Series representations; Single layer perceptron; Article; artificial neural network; Boostron algorithm; learning algorithm; least mean squared learning; machine learning; mathematical computing; mathematical model; mathematical parameters; nonlinear system; resilient back propagation; Neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85016972562"
"Quellec G.; Charrière K.; Boudi Y.; Cochener B.; Lamard M.","Quellec, Gwenolé (16175788800); Charrière, Katia (56068006100); Boudi, Yassine (57194195161); Cochener, Béatrice (7003946321); Lamard, Mathieu (15843328700)","16175788800; 56068006100; 57194195161; 7003946321; 15843328700","Deep image mining for diabetic retinopathy screening","2017","Medical Image Analysis","355","10.1016/j.media.2017.04.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019077750&doi=10.1016%2fj.media.2017.04.012&partnerID=40&md5=d4f75d81fd8730e3167be6931a16ef85","Inserm, UMR 1101, 22 avenue Camille-Desmoulins, Brest, F-29200, France; IMT Atlantique, Département ITI, Technopôle Brest-Iroise, CS 83818, Brest, F-29609, France; Université de Bretagne Occidentale, 3 rue des Archives, Brest, F-29200, France; Service d'Ophtalmologie, 2 avenue Foch, Brest, F-29200, France","Quellec G., Inserm, UMR 1101, 22 avenue Camille-Desmoulins, Brest, F-29200, France; Charrière K., Inserm, UMR 1101, 22 avenue Camille-Desmoulins, Brest, F-29200, France, IMT Atlantique, Département ITI, Technopôle Brest-Iroise, CS 83818, Brest, F-29609, France; Boudi Y., Inserm, UMR 1101, 22 avenue Camille-Desmoulins, Brest, F-29200, France, IMT Atlantique, Département ITI, Technopôle Brest-Iroise, CS 83818, Brest, F-29609, France; Cochener B., Inserm, UMR 1101, 22 avenue Camille-Desmoulins, Brest, F-29200, France, Université de Bretagne Occidentale, 3 rue des Archives, Brest, F-29200, France, Service d'Ophtalmologie, 2 avenue Foch, Brest, F-29200, France; Lamard M., Inserm, UMR 1101, 22 avenue Camille-Desmoulins, Brest, F-29200, France, Université de Bretagne Occidentale, 3 rue des Archives, Brest, F-29200, France","Deep learning is quickly becoming the leading methodology for medical image analysis. Given a large medical archive, where each image is associated with a diagnosis, efficient pathology detectors or classifiers can be trained with virtually no expert knowledge about the target pathologies. However, deep learning algorithms, including the popular ConvNets, are black boxes: little is known about the local patterns analyzed by ConvNets to make a decision at the image level. A solution is proposed in this paper to create heatmaps showing which pixels in images play a role in the image-level predictions. In other words, a ConvNet trained for image-level classification can be used to detect lesions as well. A generalization of the backpropagation method is proposed in order to train ConvNets that produce high-quality heatmaps. The proposed solution is applied to diabetic retinopathy (DR) screening in a dataset of almost 90,000 fundus photographs from the 2015 Kaggle Diabetic Retinopathy competition and a private dataset of almost 110,000 photographs (e-ophtha). For the task of detecting referable DR, very good detection performance was achieved: Az=0.954 in Kaggle's dataset and Az=0.949 in e-ophtha. Performance was also evaluated at the image level and at the lesion level in the DiaretDB1 dataset, where four types of lesions are manually segmented: microaneurysms, hemorrhages, exudates and cotton-wool spots. For the task of detecting images containing these four lesion types, the proposed detector, which was trained to detect referable DR, outperforms recent algorithms trained to detect those lesions specifically, with pixel-level supervision. At the lesion level, the proposed detector outperforms heatmap generation algorithms for ConvNets. This detector is part of the Messidor® system for mobile eye pathology screening. Because it does not rely on expert knowledge or manual segmentation for detecting relevant patterns, the proposed solution is a promising image mining tool, which has the potential to discover new biomarkers in images. © 2017 Elsevier B.V.","Deep learning; Diabetic retinopathy screening; Image mining; Lesion detection","Algorithms; Artifacts; Data Mining; Diabetic Retinopathy; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Retina; Deep learning; Diagnosis; Eye protection; Image segmentation; Learning algorithms; Medical imaging; Pathology; Photography; Pixels; Detection performance; Diabetic retinopathy; Diabetic retinopathy screening; Fundus photographs; Generation algorithm; Image mining; Lesion detection; Manual segmentation; Article; classifier; convnet; data mining; decision making; diabetic retinopathy; e ophtha train; eye photography; kaggle train; learning algorithm; microaneurysm; prediction; priority journal; random forest; retina hemorrhage; retina image; screening test; sensitivity analysis; algorithm; artifact; computer assisted diagnosis; data mining; diabetic retinopathy; diagnostic imaging; human; machine learning; procedures; retina; Image analysis","Elsevier B.V.","13618415","","MIAEC","28511066","Article","Scopus","2-s2.0-85019077750"
"Naz S.; Umar A.I.; Ahmad R.; Siddiqi I.; Ahmed S.B.; Razzak M.I.; Shafait F.","Naz, Saeeda (55882598700); Umar, Arif I. (56497586200); Ahmad, Riaz (55608904300); Siddiqi, Imran (24768045700); Ahmed, Saad B (55954263400); Razzak, Muhammad I. (57204101897); Shafait, Faisal (23390483600)","55882598700; 56497586200; 55608904300; 24768045700; 55954263400; 57204101897; 23390483600","Urdu Nastaliq recognition using convolutional–recursive deep learning","2017","Neurocomputing","96","10.1016/j.neucom.2017.02.081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015262383&doi=10.1016%2fj.neucom.2017.02.081&partnerID=40&md5=1d1824f1129a339b5fc212bb8b64bae2","Department of Information Technology, Hazara University, Mansehra, Pakistan; GGPGC No.1, Abbottabad, Higher Education Department, Pakistan; University of Kaiserslautern, Germany; Bahria University, Islamabad, Pakistan; King Saud Bin Abdulaziz University for Health Sciences, Riyadh, Saudi Arabia; National University of Sciences and Technology (NUST), Islamabad, Pakistan","Naz S., Department of Information Technology, Hazara University, Mansehra, Pakistan, GGPGC No.1, Abbottabad, Higher Education Department, Pakistan; Umar A.I., Department of Information Technology, Hazara University, Mansehra, Pakistan; Ahmad R., University of Kaiserslautern, Germany; Siddiqi I., Bahria University, Islamabad, Pakistan; Ahmed S.B., King Saud Bin Abdulaziz University for Health Sciences, Riyadh, Saudi Arabia; Razzak M.I., King Saud Bin Abdulaziz University for Health Sciences, Riyadh, Saudi Arabia; Shafait F., National University of Sciences and Technology (NUST), Islamabad, Pakistan","Recent developments in recognition of cursive scripts rely on implicit feature extraction methods that provide better results as compared to traditional hand-crafted feature extraction approaches. We present a hybrid approach based on explicit feature extraction by combining convolutional and recursive neural networks for feature learning and classification of cursive Urdu Nastaliq script. The first layer extracts low-level translational invariant features using Convolutional Neural Networks (CNN) which are then forwarded to Multi-dimensional Long Short-Term Memory Neural Networks (MDLSTM) for contextual feature extraction and learning. Experiments are carried out on the publicly available Urdu Printed Text-line Image (UPTI) dataset using the proposed hierarchical combination of CNN and MDLSTM. A recognition rate of up to 98.12% for 44-classes is achieved outperforming the state-of-the-art results on the UPTI dataset. © 2017","BLSTM; CNN; CTC; MDLSTM; RNN; Urdu OCR","Convolution; Deep learning; Extraction; Feature extraction; Neural networks; BLSTM; Contextual feature; Convolutional neural network; Implicit features; Invariant features; MDLSTM; Multi dimensional; Recursive neural networks; Article; artificial neural network; classification; controlled study; convolutional neural network; data base; experimental study; machine learning; mathematical analysis; mathematical computing; mathematical parameters; methodology; multi dimensional long short term memory neural networks; Long short-term memory","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85015262383"
"Alcantara M.F.; Cao Y.; Liu C.; Liu B.; Brunette M.; Zhang N.; Sun T.; Zhang P.; Chen Q.; Li Y.; Morocho Albarracin C.; Peinado J.; Sanchez Garavito E.; Lecca Garcia L.; Curioso W.H.","Alcantara, Marlon F. (56019383900); Cao, Yu (57209518085); Liu, Chang (7409786429); Liu, Benyuan (7408693142); Brunette, Maria (8612034500); Zhang, Ning (58706890700); Sun, Tong (57190818048); Zhang, Peifeng (57191156886); Chen, Qilei (57212482008); Li, Ying (57218425319); Morocho Albarracin, Cesar (57222565825); Peinado, Jesus (22980805200); Sanchez Garavito, Epifanio (55241775900); Lecca Garcia, Leonid (57749720200); Curioso, Walter H. (6602404688)","56019383900; 57209518085; 7409786429; 7408693142; 8612034500; 58706890700; 57190818048; 57191156886; 57212482008; 57218425319; 57222565825; 22980805200; 55241775900; 57749720200; 6602404688","Improving tuberculosis diagnostics using deep learning and mobile health technologies among resource-poor communities in Perú","2017","Smart Health","44","10.1016/j.smhl.2017.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037668774&doi=10.1016%2fj.smhl.2017.04.003&partnerID=40&md5=00c6842921ff1c1a0528c5cfb8fed2b0","Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Department of Public Health, University of Massachusetts, Lowell, MA, United States; Partners in Health Perú, Carabayllo, Lima, Peru; National Hospital Sergio E, Bernales, Peru; Biomedical and Health Informatics, University of Washington, Seattle, WA, United States","Alcantara M.F., Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Cao Y., Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Liu C., Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Liu B., Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Brunette M., Department of Public Health, University of Massachusetts, Lowell, MA, United States; Zhang N., Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Sun T., Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Zhang P., Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Chen Q., Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Li Y., Department of Computer Science, University of Massachusetts, Lowell, MA, United States; Morocho Albarracin C., Department of Public Health, University of Massachusetts, Lowell, MA, United States; Peinado J., Partners in Health Perú, Carabayllo, Lima, Peru; Sanchez Garavito E., National Hospital Sergio E, Bernales, Peru; Lecca Garcia L., Partners in Health Perú, Carabayllo, Lima, Peru; Curioso W.H., Biomedical and Health Informatics, University of Washington, Seattle, WA, United States","Tuberculosis (TB) an infectious disease and remains a major cause of death globally. The World Health Organization (WHO) estimates that there were 10.4 million new TB cases worldwide in 2015. The majority of the infected populations come from resource-poor and marginalized communities with poor healthcare infrastructure. It is critical to reduce TB diagnosis delay in mitigating disease transmission and minimizing the reproductive rate of the tuberculosis epidemic. To combine machine learning and mobile computing techniques may help to accelerate the TB diagnosis among these communities. The goal of our research is to reduce TB patient wait times for being diagnosed by developing new machine learning techniques and mobile health technologies. In this paper, major technique barriers and proposed system architecture are first introduced. Then two major progresses are reported: (1) To develop an X-ray image database and annotation software dedicated for automated TB screening. The annotation software can help to highlight the TB manifestations, which are very useful for machine learning algorithms; (2) To develop effective and efficient computational models to classify the image into different category of TB manifestations. The model we proposed is a deep convolutional neural networks (CNN)-based models. We have conducted substantial experiments and the results have demonstrated that our approach is promising. We envision our future work includes two research activities. First, we plan to improve the performance of the algorithms with deeper neural networks. Second, we plan to implement our algorithms on mobile device and deploy our system in the city of Carabayllo, a high-burden TB area in Lima, the capital of Perú. © 2017 Elsevier Inc.","Deep convolutional neural networks; Deep learning; Diagnosis; mHealth; Mobile computing; Tuberculosis","Article; artificial neural network; health care system; human; learning algorithm; lowest income group; machine learning; mass screening; mathematical model; mobile application; Peru; pulmonologist; software; support vector machine; thorax radiography; tuberculosis","Elsevier B.V.","23526483","","","","Article","Scopus","2-s2.0-85037668774"
"Liu W.; Wang Z.; Liu X.; Zeng N.; Liu Y.; Alsaadi F.E.","Liu, Weibo (57001851000); Wang, Zidong (55810114200); Liu, Xiaohui (35290922200); Zeng, Nianyin (36703553900); Liu, Yurong (36062331200); Alsaadi, Fuad E. (23566767000)","57001851000; 55810114200; 35290922200; 36703553900; 36062331200; 23566767000","A survey of deep neural network architectures and their applications","2017","Neurocomputing","2364","10.1016/j.neucom.2016.12.038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010651075&doi=10.1016%2fj.neucom.2016.12.038&partnerID=40&md5=2604d57c32f7d54249dbe43ab24c912d","Department of Computer Science, Brunel University London, Uxbridge, UB8 3PH, Middlesex, United Kingdom; Department of Instrumental and Electrical Engineering, Xiamen University, Xiamen, 361005, Fujian, China; Department of Mathematics, Yangzhou University, Yangzhou, 225002, China; Communication Systems and Networks (CSN) Research Group, Faculty of Engineering, King Abdulaziz University, Jeddah, 21589, Saudi Arabia","Liu W., Department of Computer Science, Brunel University London, Uxbridge, UB8 3PH, Middlesex, United Kingdom; Wang Z., Department of Computer Science, Brunel University London, Uxbridge, UB8 3PH, Middlesex, United Kingdom; Liu X., Department of Computer Science, Brunel University London, Uxbridge, UB8 3PH, Middlesex, United Kingdom; Zeng N., Department of Instrumental and Electrical Engineering, Xiamen University, Xiamen, 361005, Fujian, China; Liu Y., Department of Mathematics, Yangzhou University, Yangzhou, 225002, China, Communication Systems and Networks (CSN) Research Group, Faculty of Engineering, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Alsaadi F.E., Communication Systems and Networks (CSN) Research Group, Faculty of Engineering, King Abdulaziz University, Jeddah, 21589, Saudi Arabia","Since the proposal of a fast learning algorithm for deep belief networks in 2006, the deep learning techniques have drawn ever-increasing research interests because of their inherent capability of overcoming the drawback of traditional algorithms dependent on hand-designed features. Deep learning approaches have also been found to be suitable for big data analysis with successful applications to computer vision, pattern recognition, speech recognition, natural language processing, and recommendation systems. In this paper, we discuss some widely-used deep learning architectures and their practical applications. An up-to-date overview is provided on four deep learning architectures, namely, autoencoder, convolutional neural network, deep belief network, and restricted Boltzmann machine. Different types of deep neural networks are surveyed and recent progresses are summarized. Applications of deep learning techniques on some selected areas (speech recognition, pattern recognition and computer vision) are highlighted. A list of future research topics are finally given with clear justifications. © 2016 Elsevier B.V.","Autoencoder; Convolutional neural network; Deep belief network; Deep learning; Restricted Boltzmann machine","Bayesian networks; Computer vision; Convolution; Convolutional neural networks; Deep neural networks; Learning algorithms; Learning systems; Natural language processing systems; Network architecture; Pattern recognition systems; Speech recognition; Surveys; Auto encoders; Deep belief networks; Learning approach; Learning architectures; Learning techniques; NAtural language processing; Research interests; Restricted boltzmann machine; Article; artificial neural network; automated pattern recognition; automatic speech recognition; Boltzmann machine; computer; computer vision; controlled study; deep neural network; limit of quantitation; machine learning; measurement accuracy; measurement precision; natural language processing; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85010651075"
"Nam Y.; Choo O.-S.; Lee Y.-R.; Choung Y.-H.; Shin H.","Nam, Yonghyun (56023641700); Choo, Oak-Sung (55579114100); Lee, Yu-Ri (57194388285); Choung, Yun-Hoon (7004685469); Shin, Hyunjung (55724680900)","56023641700; 55579114100; 57194388285; 7004685469; 55724680900","Cascade recurring deep networks for audible range prediction","2017","BMC Medical Informatics and Decision Making","3","10.1186/s12911-017-0452-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019646765&doi=10.1186%2fs12911-017-0452-2&partnerID=40&md5=cb0333698272efa00d85392938d27eac","Department of Industrial Engineering, Ajou University, Suwon, South Korea; Department of Otolaryngology, Ajou University School of Medicine, Suwon, South Korea","Nam Y., Department of Industrial Engineering, Ajou University, Suwon, South Korea; Choo O.-S., Department of Otolaryngology, Ajou University School of Medicine, Suwon, South Korea; Lee Y.-R., Department of Otolaryngology, Ajou University School of Medicine, Suwon, South Korea; Choung Y.-H., Department of Otolaryngology, Ajou University School of Medicine, Suwon, South Korea; Shin H., Department of Industrial Engineering, Ajou University, Suwon, South Korea","Background: Hearing Aids amplify sounds at certain frequencies to help patients, who have hearing loss, to improve the quality of life. Variables affecting hearing improvement include the characteristics of the patients’ hearing loss, the characteristics of the hearing aids, and the characteristics of the frequencies. Although the two former characteristics have been studied, there are only limited studies predicting hearing gain, after wearing Hearing Aids, with utilizing all three characteristics. Therefore, we propose a new machine learning algorithm that can present the degree of hearing improvement expected from the wearing of hearing aids. Methods: The proposed algorithm consists of cascade structure, recurrent structure and deep network structure. For cascade structure, it reflects correlations between frequency bands. For recurrent structure, output variables in one particular network of frequency bands are reused as input variables for other networks. Furthermore, it is of deep network structure with many hidden layers. We denote such networks as cascade recurring deep network where training consists of two phases; cascade phase and tuning phase. Results: When applied to medical records of 2,182 patients treated for hearing loss, the proposed algorithm reduced the error rate by 58% from the other neural networks. Conclusions: The proposed algorithm is a novel algorithm that can be utilized for signal or sequential data. Clinically, the proposed algorithm can serve as a medical assistance tool that fulfill the patients’ satisfaction. © 2017 The Author(s).","Cascade structure; Deep learning; Hearing Aids; Hearing improvement; Neural networks; Recurrent structure","Algorithms; Hearing Aids; Hearing Loss; Humans; Machine Learning; Neural Networks (Computer); Retrospective Studies; algorithm; artificial neural network; hearing aid; hearing impairment; human; machine learning; retrospective study","BioMed Central Ltd","14726947","","","28539112","Article","Scopus","2-s2.0-85019646765"
"Gargeya R.; Leng T.","Gargeya, Rishab (57193736469); Leng, Theodore (37051202000)","57193736469; 37051202000","Automated Identification of Diabetic Retinopathy Using Deep Learning","2017","Ophthalmology","897","10.1016/j.ophtha.2017.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016221341&doi=10.1016%2fj.ophtha.2017.02.008&partnerID=40&md5=07287985cdbfc42c76a8b6ba19d0594e","The Harker School, San Jose, California, United States; Byers Eye Institute at Stanford, Stanford University School of Medicine, Palo Alto, California, United States","Gargeya R., The Harker School, San Jose, California, United States; Leng T., Byers Eye Institute at Stanford, Stanford University School of Medicine, Palo Alto, California, United States","Purpose Diabetic retinopathy (DR) is one of the leading causes of preventable blindness globally. Performing retinal screening examinations on all diabetic patients is an unmet need, and there are many undiagnosed and untreated cases of DR. The objective of this study was to develop robust diagnostic technology to automate DR screening. Referral of eyes with DR to an ophthalmologist for further evaluation and treatment would aid in reducing the rate of vision loss, enabling timely and accurate diagnoses. Design We developed and evaluated a data-driven deep learning algorithm as a novel diagnostic tool for automated DR detection. The algorithm processed color fundus images and classified them as healthy (no retinopathy) or having DR, identifying relevant cases for medical referral. Methods A total of 75 137 publicly available fundus images from diabetic patients were used to train and test an artificial intelligence model to differentiate healthy fundi from those with DR. A panel of retinal specialists determined the ground truth for our data set before experimentation. We also tested our model using the public MESSIDOR 2 and E-Ophtha databases for external validation. Information learned in our automated method was visualized readily through an automatically generated abnormality heatmap, highlighting subregions within each input fundus image for further clinical review. Main Outcome Measures We used area under the receiver operating characteristic curve (AUC) as a metric to measure the precision–recall trade-off of our algorithm, reporting associated sensitivity and specificity metrics on the receiver operating characteristic curve. Results Our model achieved a 0.97 AUC with a 94% and 98% sensitivity and specificity, respectively, on 5-fold cross-validation using our local data set. Testing against the independent MESSIDOR 2 and E-Ophtha databases achieved a 0.94 and 0.95 AUC score, respectively. Conclusions A fully data-driven artificial intelligence–based grading algorithm can be used to screen fundus photographs obtained from diabetic patients and to identify, with high reliability, which cases should be referred to an ophthalmologist for further evaluation and treatment. The implementation of such an algorithm on a global basis could reduce drastically the rate of vision loss attributed to DR. © 2017 American Academy of Ophthalmology","","Algorithms; Diabetic Retinopathy; Diagnostic Techniques, Ophthalmological; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Ophthalmologists; Reproducibility of Results; ROC Curve; Article; artificial intelligence; cost effectiveness analysis; diabetic patient; diabetic retinopathy; diagnostic imaging; diagnostic test accuracy study; high risk patient; human; learning algorithm; ophthalmologist; predictive value; priority journal; retina exudate; retina hemorrhage; retina image; retina neovascularization; sensitivity and specificity; visual impairment; algorithm; artificial neural network; computer assisted diagnosis; diabetic retinopathy; machine learning; ophthalmologist; procedures; receiver operating characteristic; reproducibility; visual system examination","Elsevier Inc.","01616420","","OPHTD","28359545","Article","Scopus","2-s2.0-85016221341"
"Kumar N.; Verma R.; Sharma S.; Bhargava S.; Vahadane A.; Sethi A.","Kumar, Neeraj (58071541900); Verma, Ruchika (57217427976); Sharma, Sanuj (57195489176); Bhargava, Surabhi (57185001200); Vahadane, Abhishek (56039151700); Sethi, Amit (12775689700)","58071541900; 57217427976; 57195489176; 57185001200; 56039151700; 12775689700","A Dataset and a Technique for Generalized Nuclear Segmentation for Computational Pathology","2017","IEEE Transactions on Medical Imaging","648","10.1109/TMI.2017.2677499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028392498&doi=10.1109%2fTMI.2017.2677499&partnerID=40&md5=ca6274473ce2b3d4d47a0ebf73a989ff","IIT Guwahati, Guwahati, 781039, India","Kumar N., IIT Guwahati, Guwahati, 781039, India; Verma R., IIT Guwahati, Guwahati, 781039, India; Sharma S., IIT Guwahati, Guwahati, 781039, India; Bhargava S., IIT Guwahati, Guwahati, 781039, India; Vahadane A., IIT Guwahati, Guwahati, 781039, India; Sethi A., IIT Guwahati, Guwahati, 781039, India","Nuclear segmentation in digital microscopic tissue images can enable extraction of high-quality features for nuclear morphometrics and other analysis in computational pathology. Conventional image processing techniques, such as Otsu thresholding and watershed segmentation, do not work effectively on challenging cases, such as chromatin-sparse and crowded nuclei. In contrast, machine learning-based segmentation can generalize across various nuclear appearances. However, training machine learning algorithms requires data sets of images, in which a vast number of nuclei have been annotated. Publicly accessible and annotated data sets, along with widely agreed upon metrics to compare techniques, have catalyzed tremendous innovation and progress on other image classification problems, particularly in object recognition. Inspired by their success, we introduce a large publicly accessible data set of hematoxylin and eosin (HE)-stained tissue images with more than 21000 painstakingly annotated nuclear boundaries, whose quality was validated by a medical doctor. Because our data set is taken from multiple hospitals and includes a diversity of nuclear appearances from several patients, disease states, and organs, techniques trained on it are likely to generalize well and work right out-of-the-box on other HE-stained images. We also propose a new metric to evaluate nuclear segmentation results that penalizes object- and pixel-level errors in a unified manner, unlike previous metrics that penalize only one type of error. We also propose a segmentation technique based on deep learning that lays a special emphasis on identifying the nuclear boundaries, including those between the touching or overlapping nuclei, and works well on a diverse set of test images. © 1982-2012 IEEE.","Annotation; boundaries; dataset; deep learning; nuclear segmentation; nuclei","Algorithms; Cell Nucleus; Humans; Image Processing, Computer-Assisted; Machine Learning; Staining and Labeling; Artificial intelligence; Classification (of information); Deep learning; Image processing; Learning algorithms; Learning systems; Medical imaging; Object recognition; Pathology; Quality control; Semiconductor insulator boundaries; Tissue; Annotation; dataset; Image processing technique; nuclei; Publicly accessible; Segmentation results; Segmentation techniques; Watershed segmentation; algorithm; cell nucleus; human; image processing; machine learning; staining; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28287963","Article","Scopus","2-s2.0-85028392498"
"Kalatskaya I.; Trinh Q.M.; Spears M.; McPherson J.D.; Bartlett J.M.S.; Stein L.","Kalatskaya, Irina (6507411114); Trinh, Quang M. (55796630900); Spears, Melanie (25626865900); McPherson, John D. (7102659159); Bartlett, John M.S. (36063907600); Stein, Lincoln (7202575097)","6507411114; 55796630900; 25626865900; 7102659159; 36063907600; 7202575097","ISOWN: Accurate somatic mutation identification in the absence of normal tissue controls","2017","Genome Medicine","39","10.1186/s13073-017-0446-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021325251&doi=10.1186%2fs13073-017-0446-9&partnerID=40&md5=ad11ed2b243f8f4601474fd11454d419","Informatics and Bio-computing, Ontario Institute for Cancer Research, Toronto, ON, Canada; Transformative Pathology, Ontario Institute for Cancer Research, Toronto, ON, Canada; University of Toronto, Department of Laboratory Medicine and Pathobiology, Toronto, ON, Canada; University of Edinburgh, Edinburgh Cancer Research UK Centre, MRC IGMM, Edinburgh, United Kingdom; University of Toronto, Department of Molecular Genetics, Toronto, ON, Canada; University of California Davis, Department of Biochemistry and Molecular Medicine, Sacramento, CA, United States","Kalatskaya I., Informatics and Bio-computing, Ontario Institute for Cancer Research, Toronto, ON, Canada; Trinh Q.M., Informatics and Bio-computing, Ontario Institute for Cancer Research, Toronto, ON, Canada; Spears M., Transformative Pathology, Ontario Institute for Cancer Research, Toronto, ON, Canada, University of Toronto, Department of Laboratory Medicine and Pathobiology, Toronto, ON, Canada; McPherson J.D., University of California Davis, Department of Biochemistry and Molecular Medicine, Sacramento, CA, United States; Bartlett J.M.S., Transformative Pathology, Ontario Institute for Cancer Research, Toronto, ON, Canada, University of Toronto, Department of Laboratory Medicine and Pathobiology, Toronto, ON, Canada, University of Edinburgh, Edinburgh Cancer Research UK Centre, MRC IGMM, Edinburgh, United Kingdom; Stein L., Informatics and Bio-computing, Ontario Institute for Cancer Research, Toronto, ON, Canada, University of Toronto, Department of Molecular Genetics, Toronto, ON, Canada","Background: A key step in cancer genome analysis is the identification of somatic mutations in the tumor. This is typically done by comparing the genome of the tumor to the reference genome sequence derived from a normal tissue taken from the same donor. However, there are a variety of common scenarios in which matched normal tissue is not available for comparison. Results: In this work, we describe an algorithm to distinguish somatic single nucleotide variants (SNVs) in next-generation sequencing data from germline polymorphisms in the absence of normal samples using a machine learning approach. Our algorithm was evaluated using a family of supervised learning classifications across six different cancer types and ~1600 samples, including cell lines, fresh frozen tissues, and formalin-fixed paraffin-embedded tissues; we tested our algorithm with both deep targeted and whole-exome sequencing data. Our algorithm correctly classified between 95 and 98% of somatic mutations with F1-measure ranges from 75.9 to 98.6% depending on the tumor type. We have released the algorithm as a software package called ISOWN (Identification of SOmatic mutations Without matching Normal tissues). Conclusions: In this work, we describe the development, implementation, and validation of ISOWN, an accurate algorithm for predicting somatic mutations in cancer tissues in the absence of matching normal tissues. ISOWN is available as Open Source under Apache License 2.0 from https://github.com/ikalatskaya/ISOWN. © 2017 The Author(s).","Matching normal tissue; Next-generation sequencing; Somatic mutation; Variant classification","DNA Mutational Analysis; High-Throughput Nucleotide Sequencing; Humans; Mutation; Neoplasms; Supervised Machine Learning; accuracy; algorithm; Article; cancer tissue; gene frequency; genetic variation; mutational analysis; next generation sequencing; priority journal; single nucleotide polymorphism; somatic mutation; validation study; whole exome sequencing; dna mutational analysis; genetics; high throughput sequencing; human; mutation; neoplasm; procedures; supervised machine learning","BioMed Central Ltd.","1756994X","","","28659176","Article","Scopus","2-s2.0-85021325251"
"Sadeghi Z.; Testolin A.","Sadeghi, Zahra (58146781900); Testolin, Alberto (55763594100)","58146781900; 55763594100","Learning representation hierarchies by sharing visual features: a computational investigation of Persian character recognition with unsupervised deep learning","2017","Cognitive Processing","8","10.1007/s10339-017-0796-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013784262&doi=10.1007%2fs10339-017-0796-7&partnerID=40&md5=3ff39df76ef8245e9db301206a6b843e","Department of Electrical and Computer Engineering, University of Tehran, Tehran, Iran; Computational Cognitive Neuroscience Lab, University of Padova, Padua, Italy; Department of General Psychology, University of Padova, Via Venezia 12/2, Padua, 35131, Italy","Sadeghi Z., Department of Electrical and Computer Engineering, University of Tehran, Tehran, Iran, Computational Cognitive Neuroscience Lab, University of Padova, Padua, Italy; Testolin A., Computational Cognitive Neuroscience Lab, University of Padova, Padua, Italy, Department of General Psychology, University of Padova, Via Venezia 12/2, Padua, 35131, Italy","In humans, efficient recognition of written symbols is thought to rely on a hierarchical processing system, where simple features are progressively combined into more abstract, high-level representations. Here, we present a computational model of Persian character recognition based on deep belief networks, where increasingly more complex visual features emerge in a completely unsupervised manner by fitting a hierarchical generative model to the sensory data. Crucially, high-level internal representations emerging from unsupervised deep learning can be easily read out by a linear classifier, achieving state-of-the-art recognition accuracy. Furthermore, we tested the hypothesis that handwritten digits and letters share many common visual features: A generative model that captures the statistical structure of the letters distribution should therefore also support the recognition of written digits. To this aim, deep networks trained on Persian letters were used to build high-level representations of Persian digits, which were indeed read out with high accuracy. Our simulations show that complex visual features, such as those mediating the identification of Persian symbols, can emerge from unsupervised learning in multilayered neural networks and can support knowledge transfer across related domains. © 2017, Marta Olivetti Belardinelli and Springer-Verlag Berlin Heidelberg.","Computational modeling; Hierarchical generative models; Persian character recognition; Transfer learning; Unsupervised deep learning; Visual pattern recognition","Computer Simulation; Handwriting; Humans; Learning; Machine Learning; Neural Networks (Computer); Supervised Machine Learning; Transfer (Psychology); Unsupervised Machine Learning; Article; handwriting; human; knowledge; learning; measurement accuracy; nerve cell network; pattern recognition; Persian character recognition; priority journal; sensory analysis; vision; visual system parameters; artificial neural network; computer simulation; handwriting; learning; machine learning; supervised machine learning; transfer of learning; unsupervised machine learning","Springer Verlag","16124782","","","28238168","Article","Scopus","2-s2.0-85013784262"
"Bianco S.; Buzzelli M.; Mazzini D.; Schettini R.","Bianco, Simone (55511749108); Buzzelli, Marco (55744003800); Mazzini, Davide (57203852354); Schettini, Raimondo (56235309600)","55511749108; 55744003800; 57203852354; 56235309600","Deep learning for logo recognition","2017","Neurocomputing","106","10.1016/j.neucom.2017.03.051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016597453&doi=10.1016%2fj.neucom.2017.03.051&partnerID=40&md5=e17b343791c93c297d984b73d71c4620","DISCo - Università degli Studi di Milano-Bicocca, Milano, 20126, Italy","Bianco S., DISCo - Università degli Studi di Milano-Bicocca, Milano, 20126, Italy; Buzzelli M., DISCo - Università degli Studi di Milano-Bicocca, Milano, 20126, Italy; Mazzini D., DISCo - Università degli Studi di Milano-Bicocca, Milano, 20126, Italy; Schettini R., DISCo - Università degli Studi di Milano-Bicocca, Milano, 20126, Italy","In this paper we propose a method for logo recognition using deep learning. Our recognition pipeline is composed of a logo region proposal followed by a Convolutional Neural Network (CNN) specifically trained for logo classification, even if they are not precisely localized. Experiments are carried out on the FlickrLogos-32 database, and we evaluate the effect on recognition performance of synthetic versus real data augmentation, and image pre-processing. Moreover, we systematically investigate the benefits of different training choices such as class-balancing, sample-weighting and explicit modeling the background class (i.e. no-logo regions). Experimental results confirm the feasibility of the proposed method, that outperforms the methods in the state of the art. © 2017 Elsevier B.V.","Convolutional Neural Network; Data augmentation; Deep Learning; FlickrLogos-32; Logo recognition","Convolution; Convolutional neural networks; Deep neural networks; Data augmentation; Explicit modeling; FlickrLogos-32; Image preprocessing; Logo classification; Logo recognition; Sample weighting; State of the art; Article; artificial neural network; class balancing; convolutional neural network; deep learning; image analysis; image processing; imaging and display; information processing; logo recognition; machine learning; process development; process optimization; sample weighting; synthetic data augmentation; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85016597453"
"Yu Q.; Wang J.; Zhang S.; Gong Y.; Zhao J.","Yu, Qinghua (57193137743); Wang, Jinjun (56198011300); Zhang, Shizhou (56198002500); Gong, Yihong (7402475075); Zhao, Jizhong (7410313588)","57193137743; 56198011300; 56198002500; 7402475075; 7410313588","Combining local and global hypotheses in deep neural network for multi-label image classification","2017","Neurocomputing","22","10.1016/j.neucom.2016.12.051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011015027&doi=10.1016%2fj.neucom.2016.12.051&partnerID=40&md5=f7067621cb5a56ed6d1964583eedd70c","Institute of Artificial Intelligence and Robotic, Xi'an Jiaotong University, Xian Ning West Road No. 28, Shaanxi, 710049, China; School of Electronic & Information Engineering, Xi'an Jiaotong University, China","Yu Q., Institute of Artificial Intelligence and Robotic, Xi'an Jiaotong University, Xian Ning West Road No. 28, Shaanxi, 710049, China; Wang J., Institute of Artificial Intelligence and Robotic, Xi'an Jiaotong University, Xian Ning West Road No. 28, Shaanxi, 710049, China; Zhang S., Institute of Artificial Intelligence and Robotic, Xi'an Jiaotong University, Xian Ning West Road No. 28, Shaanxi, 710049, China; Gong Y., Institute of Artificial Intelligence and Robotic, Xi'an Jiaotong University, Xian Ning West Road No. 28, Shaanxi, 710049, China; Zhao J., School of Electronic & Information Engineering, Xi'an Jiaotong University, China","Multi-label image classification is a challenging problem in computer vision. Motivated by the recent development in image classification performance using Deep Neural Networks, in this work, we propose a flexible deep Convolutional Neural Network (CNN) framework, called Local-Global-CNN (LGC), to improve multi-label image classification performance. LGC consists of firstly a local level multi-label classifier which takes object segment hypotheses as inputs to a local CNN. The output results of these local hypotheses are aggregated together with max-pooling and then re-weighted to consider the label co-occurrence or interdependencies information by using a graphical model in the label space. LGC also utilizes a global CNN that is trained by multi-label images to directly predict the multiple labels from the input. The predictions of local and global level classifiers are finally fused together to obtain MAP estimation of the final multi-label prediction. The above LGC framework could benefit from a pre-train process with a large-scale single-label image dataset, e.g., ImageNet. Experimental results have shown that the proposed framework could achieve promising performance on Pascal VOC2007 and VOC2012 multi-label image dataset. © 2016","Convolutional neural network; Deep learning; Multi-label classification","Classification (of information); Convolution; Deep learning; Deep neural networks; Forecasting; Neural networks; Classification performance; Co-occurrence; Convolutional neural network; GraphicaL model; Label images; MAP estimation; Multi label classification; Multiple labels; Article; artificial neural network; classification; classifier; controlled study; convolutional neural network support vector machine; deep neural network; fisher vector; hypotheses convolutional neural network pooling; hypothesis; image processing; information processing; INRIA; intermethod comparison; local global convolutional neural network; PRE 1000C; Image classification","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85011015027"
"Tan L.K.; Liew Y.M.; Lim E.; McLaughlin R.A.","Tan, Li Kuo (12809094600); Liew, Yih Miin (36673421800); Lim, Einly (23389466500); McLaughlin, Robert A. (7202581180)","12809094600; 36673421800; 23389466500; 7202581180","Convolutional neural network regression for short-axis left ventricle segmentation in cardiac cine MR sequences","2017","Medical Image Analysis","134","10.1016/j.media.2017.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018504683&doi=10.1016%2fj.media.2017.04.002&partnerID=40&md5=e39e0ac6222a26d7cbf2c62c55eea2c2","Department of Biomedical Imaging, Faculty of Medicine, University of Malaya, Kuala Lumpur, Malaysia; University Malaya Research Imaging Centre, University of Malaya, Kuala Lumpur, Malaysia; Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Kuala Lumpur, Malaysia; Australian Research Council Centre of Excellence for Nanoscale Biophotonics, School of Medicine, Faculty of Health and Medical Sciences, University of Adelaide, Adelaide, Australia","Tan L.K., Department of Biomedical Imaging, Faculty of Medicine, University of Malaya, Kuala Lumpur, Malaysia, University Malaya Research Imaging Centre, University of Malaya, Kuala Lumpur, Malaysia; Liew Y.M., Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Kuala Lumpur, Malaysia; Lim E., Department of Biomedical Engineering, Faculty of Engineering, University of Malaya, Kuala Lumpur, Malaysia; McLaughlin R.A., Australian Research Council Centre of Excellence for Nanoscale Biophotonics, School of Medicine, Faculty of Health and Medical Sciences, University of Adelaide, Adelaide, Australia","Automated left ventricular (LV) segmentation is crucial for efficient quantification of cardiac function and morphology to aid subsequent management of cardiac pathologies. In this paper, we parameterize the complete (all short axis slices and phases) LV segmentation task in terms of the radial distances between the LV centerpoint and the endo- and epicardial contours in polar space. We then utilize convolutional neural network regression to infer these parameters. Utilizing parameter regression, as opposed to conventional pixel classification, allows the network to inherently reflect domain-specific physical constraints. We have benchmarked our approach primarily against the publicly-available left ventricle segmentation challenge (LVSC) dataset, which consists of 100 training and 100 validation cardiac MRI cases representing a heterogeneous mix of cardiac pathologies and imaging parameters across multiple centers. Our approach attained a.77 Jaccard index, which is the highest published overall result in comparison to other automated algorithms. To test general applicability, we also evaluated against the Kaggle Second Annual Data Science Bowl, where the evaluation metric was the indirect clinical measures of LV volume rather than direct myocardial contours. Our approach attained a Continuous Ranked Probability Score (CRPS) of.0124, which would have ranked tenth in the original challenge. With this we demonstrate the effectiveness of convolutional neural network regression paired with domain-specific features in clinical segmentation. © 2017 Elsevier B.V.","Cardiac MRI; Convolutional neural networks; Deep learning; LV segmentation","Heart Ventricles; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging, Cine; Neural Networks (Computer); Regression Analysis; Reproducibility of Results; Convolution; Deep learning; Magnetic resonance imaging; Natural language processing systems; Neural networks; Pathology; Regression analysis; Automated algorithms; Cardiac MRI; Cardiac pathologies; Continuous ranked probability scores; Convolutional neural network; Parameter regressions; Physical constraints; Pixel classification; algorithm; Article; automation; cardiovascular magnetic resonance; Continuous Ranked Probability Score; endocardium; epicardium; heart left ventricle; heart left ventricle volume; human; image segmentation; nerve cell network; priority journal; scoring system; artificial neural network; cine magnetic resonance imaging; computer assisted diagnosis; diagnostic imaging; heart ventricle; machine learning; procedures; regression analysis; reproducibility; Heart","Elsevier B.V.","13618415","","MIAEC","28437634","Article","Scopus","2-s2.0-85018504683"
"Long H.; Wang M.; Fu H.","Long, HaiXia (32367731600); Wang, Mi (57194578248); Fu, HaiYan (13606577800)","32367731600; 57194578248; 13606577800","Deep convolutional neural networks for predicting hydroxyproline in proteins","2017","Current Bioinformatics","32","10.2174/1574893612666170221152848","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020886623&doi=10.2174%2f1574893612666170221152848&partnerID=40&md5=53d42c0c9be59524e58d8e13312c3f98","Department of Information Science and Technology, HaiNan Normal University, HaiKou, 571158, China; Department of Computer Science, University of Missouri, Columbia, 65211-2060, MO, United States","Long H., Department of Information Science and Technology, HaiNan Normal University, HaiKou, 571158, China, Department of Computer Science, University of Missouri, Columbia, 65211-2060, MO, United States; Wang M., Department of Information Science and Technology, HaiNan Normal University, HaiKou, 571158, China; Fu H., Department of Information Science and Technology, HaiNan Normal University, HaiKou, 571158, China","Background: Protein hydroxyproline is one type of post translational modification (PTM). Because protein sequence contains many uncharacterized residues of P, the question that needs to be answered is: Which ones can be hydroxylated, and which ones cannot? The solution will not only give a deeper understanding of the hydroxylation mechanism but can also lead to drug development. The ever growing demand for better handling of protein sequences in the post-genomic age presents new prediction challenges. Objective: To address these challenges, developing computational methods to identify these sites quickly and accurately is our objective. Method: We propose a new approach for predicting hydroxyproline using the deep learning model known as the convolutional neural network (CNN), and employed a pseudo amino acid composition (PseAAC) to identify these proteins and used the position-specific scoring matrix (PSSM) to represent samples as input to the CNN model. Results and Conclusion: In our experiment, K-fold cross-validation testing on benchmark datasets further demonstrated the potential for CNN identification of protein hydroxyproline as well as other PTM type proteins. © 2017 Bentham Science Publishers.","Convolutional neural network; Deep learning; Position-specific scoring matrix (PSSM); Protein hydroxyproline; Pseudo amino acid composition (PseAAC)","hydroxyproline; amino acid composition; Article; artificial neural network; convolutional neural network; deep learning; machine learning; position weight matrix; prediction; priority journal; protein analysis; receiver operating characteristic","Bentham Science Publishers B.V.","15748936","","","","Article","Scopus","2-s2.0-85020886623"
"Fayek H.M.; Lech M.; Cavedon L.","Fayek, Haytham M. (55347028400); Lech, Margaret (56255313700); Cavedon, Lawrence (24351108100)","55347028400; 56255313700; 24351108100","Evaluating deep learning architectures for Speech Emotion Recognition","2017","Neural Networks","419","10.1016/j.neunet.2017.02.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017190163&doi=10.1016%2fj.neunet.2017.02.013&partnerID=40&md5=328686566fd2c91e252dc5a64891f12b","School of Engineering, RMIT University, Melbourne, 3001, VIC, Australia; School of Science, RMIT University, Melbourne, 3001, VIC, Australia","Fayek H.M., School of Engineering, RMIT University, Melbourne, 3001, VIC, Australia; Lech M., School of Engineering, RMIT University, Melbourne, 3001, VIC, Australia; Cavedon L., School of Science, RMIT University, Melbourne, 3001, VIC, Australia","Speech Emotion Recognition (SER) can be regarded as a static or dynamic classification problem, which makes SER an excellent test bed for investigating and comparing various deep learning architectures. We describe a frame-based formulation to SER that relies on minimal speech processing and end-to-end deep learning to model intra-utterance dynamics. We use the proposed SER system to empirically explore feed-forward and recurrent neural network architectures and their variants. Experiments conducted illuminate the advantages and limitations of these architectures in paralinguistic speech recognition and emotion recognition in particular. As a result of our exploration, we report state-of-the-art results on the IEMOCAP database for speaker-independent SER and present quantitative and qualitative assessments of the models’ performances. © 2017 Elsevier Ltd","Affective computing; Deep learning; Emotion recognition; Neural networks; Speech recognition","Emotions; Machine Learning; Neural Networks (Computer); Speech Recognition Software; Deep learning; Deep neural networks; Network architecture; Neural networks; Recurrent neural networks; Speech processing; Affective Computing; Dynamic classification; Emotion recognition; Learning architectures; Quantitative and qualitative assessments; Speaker independents; Speech emotion recognition; State of the art; Article; artificial neural network; controlled study; deep neural network; discriminant analysis; machine learning; measurement accuracy; principal component analysis; priority journal; qualitative analysis; quantitative analysis; speech emotion recognition; support vector machine; artificial neural network; automatic speech recognition; emotion; Speech recognition","Elsevier Ltd","08936080","","NNETE","28396068","Article","Scopus","2-s2.0-85017190163"
"Silva S.; Peran P.; Kerhuel L.; Malagurski B.; Chauveau N.; Bataille B.; Lotterie J.A.; Celsis P.; Aubry F.; Citerio G.; Jean B.; Chabanne R.; Perlbarg V.; Velly L.; Galanaud D.; Vanhaudenhuyse A.; Fourcade O.; Laureys S.; Puybasset L.","Silva, Stein (24449638900); Peran, Patrice (16320009700); Kerhuel, Lionel (56971306100); Malagurski, Briguita (57193530065); Chauveau, Nicolas (55775330900); Bataille, Benoit (55354425400); Lotterie, Jean Albert (6507287257); Celsis, Pierre (7003418178); Aubry, Florent (7003636179); Citerio, Giuseppe (7003871043); Jean, Betty (8688629200); Chabanne, Russel (40760937500); Perlbarg, Vincent (8390339900); Velly, Lionel (6507630069); Galanaud, Damien (6602600415); Vanhaudenhuyse, Audrey (22987043300); Fourcade, Olivier (6603401726); Laureys, Steven (7004546122); Puybasset, Louis (7004266282)","24449638900; 16320009700; 56971306100; 57193530065; 55775330900; 55354425400; 6507287257; 7003418178; 7003636179; 7003871043; 8688629200; 40760937500; 8390339900; 6507630069; 6602600415; 22987043300; 6603401726; 7004546122; 7004266282","Brain gray matter MRI morphometry for neuroprognostication after cardiac arrest","2017","Critical Care Medicine","18","10.1097/CCM.0000000000002379","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014642030&doi=10.1097%2fCCM.0000000000002379&partnerID=40&md5=2c2f5082f77c144575254d68644e1b93","Department of Anaesthesiology and Critical Care, Critical Care Unit, University Teaching Hospital of Purpan, Place du Dr Baylac, Toulouse Cedex 9, France; Critical Care and Anaesthesiology Department, University Teaching Hospital of Purpan, Place du Dr Baylac, Toulouse Cedex 9, France; Toulouse NeuroImaging Center, Toulouse University, Inserm, UPS, France; Department of Anaesthesiology and Critical Care, Critical Care Unit, Hopital Dieu Hospital, Narbonne, France; Department of Anaesthesiology and Critical Care, School of Medicine and Surgery, University Milano Bicocca and Hospital San Gerardo, Monza, Italy; Department of Neuroradiology, University Hospital of Clermont-Ferrand, Clermont-Ferrand, France; Department of Anaesthesiology and Critical Care, University Hospital of Clermont-Ferrand, Clermont-Ferrand, France; Laboratoire d'Imagerie Biomédicale (UMR S 1146/UMR 7371), Université Pierre-et-Marie-Curie-Paris 06, Paris, France; Critical Care and Anaesthesiology Department, Groupe Hospitalier Pitié-Salpétrière, APHP, Paris, France; Department of Neuroradiology, Groupe Hospitalier Pitié-Salpétrière, APHP, Paris, France; Cyclotron Research Center and Department of Neurology, University Hospital and University of Liège, Liège, Belgium; Algology and Palliative Care Department, University Hospital and University of Liège, Liège, Belgium","Silva S., Department of Anaesthesiology and Critical Care, Critical Care Unit, University Teaching Hospital of Purpan, Place du Dr Baylac, Toulouse Cedex 9, France, Critical Care and Anaesthesiology Department, University Teaching Hospital of Purpan, Place du Dr Baylac, Toulouse Cedex 9, France, Toulouse NeuroImaging Center, Toulouse University, Inserm, UPS, France; Peran P., Toulouse NeuroImaging Center, Toulouse University, Inserm, UPS, France; Kerhuel L., Department of Anaesthesiology and Critical Care, Critical Care Unit, University Teaching Hospital of Purpan, Place du Dr Baylac, Toulouse Cedex 9, France, Critical Care and Anaesthesiology Department, University Teaching Hospital of Purpan, Place du Dr Baylac, Toulouse Cedex 9, France, Toulouse NeuroImaging Center, Toulouse University, Inserm, UPS, France; Malagurski B., Toulouse NeuroImaging Center, Toulouse University, Inserm, UPS, France; Chauveau N., Toulouse NeuroImaging Center, Toulouse University, Inserm, UPS, France; Bataille B., Department of Anaesthesiology and Critical Care, Critical Care Unit, Hopital Dieu Hospital, Narbonne, France; Lotterie J.A., Toulouse NeuroImaging Center, Toulouse University, Inserm, UPS, France; Celsis P., Toulouse NeuroImaging Center, Toulouse University, Inserm, UPS, France; Aubry F., Toulouse NeuroImaging Center, Toulouse University, Inserm, UPS, France; Citerio G., Department of Anaesthesiology and Critical Care, School of Medicine and Surgery, University Milano Bicocca and Hospital San Gerardo, Monza, Italy; Jean B., Department of Neuroradiology, University Hospital of Clermont-Ferrand, Clermont-Ferrand, France; Chabanne R., Department of Anaesthesiology and Critical Care, University Hospital of Clermont-Ferrand, Clermont-Ferrand, France; Perlbarg V., Laboratoire d'Imagerie Biomédicale (UMR S 1146/UMR 7371), Université Pierre-et-Marie-Curie-Paris 06, Paris, France; Velly L., Critical Care and Anaesthesiology Department, Groupe Hospitalier Pitié-Salpétrière, APHP, Paris, France; Galanaud D., Department of Neuroradiology, Groupe Hospitalier Pitié-Salpétrière, APHP, Paris, France; Vanhaudenhuyse A., Cyclotron Research Center and Department of Neurology, University Hospital and University of Liège, Liège, Belgium, Algology and Palliative Care Department, University Hospital and University of Liège, Liège, Belgium; Fourcade O., Critical Care and Anaesthesiology Department, University Teaching Hospital of Purpan, Place du Dr Baylac, Toulouse Cedex 9, France; Laureys S., Cyclotron Research Center and Department of Neurology, University Hospital and University of Liège, Liège, Belgium; Puybasset L., Critical Care and Anaesthesiology Department, Groupe Hospitalier Pitié-Salpétrière, APHP, Paris, France","Objectives: We hypothesize that the combined use of MRI cortical thickness measurement and subcortical gray matter volumetry could provide an early and accurate in vivo assessment of the structural impact of cardiac arrest and therefore could be used for long-term neuroprognostication in this setting. Design: Prospective cohort study. Setting: Five Intensive Critical Care Units affiliated to the University in Toulouse (France), Paris (France), Clermont-Ferrand (France), Liège (Belgium), and Monza (Italy). Patients: High-resolution anatomical T1-weighted images were acquired in 126 anoxic coma patients (""learning"" sample) 16 ± 8 days after cardiac arrest and 70 matched controls. An additional sample of 18 anoxic coma patients, recruited in Toulouse, was used to test predictive model generalization (""test"" sample). All patients were followed up 1 year after cardiac arrest. Interventions: None. Measurements and Main Results: Cortical thickness was computed on the whole cortical ribbon, and deep gray matter volumetry was performed after automatic segmentation. Brain morphometric data were employed to create multivariate predictive models using learning machine techniques. Patients displayed significantly extensive cortical and subcortical brain volumes atrophy compared with controls. The accuracy of a predictive classifier, encompassing cortical and subcortical components, has a significant discriminative power (learning area under the curve = 0.87; test area under the curve = 0.96). The anatomical regions which volume changes were significantly related to patient's outcome were frontal cortex, posterior cingulate cortex, thalamus, putamen, pallidum, caudate, hippocampus, and brain stem. Conclusions: These findings are consistent with the hypothesis of pathologic disruption of a striatopallidal-thalamo-cortical mesocircuit induced by cardiac arrest and pave the way for the use of combined brain quantitative morphometry in this setting. Copyright © 2017 by the Society of Critical Care Medicine and Wolters Kluwer Health, Inc. All Rights Reserved.","cardiac arrest; coma; cortical thickness; prognosis; subcortical volumetry","Adult; Brain; Cerebellar Cortex; Coma; Female; Gray Matter; Heart Arrest; Humans; Magnetic Resonance Imaging; Male; Middle Aged; Prognosis; Prospective Studies; adult; area under the curve; Article; Belgium; brain atrophy; brain size; brain stem; caudate nucleus; cohort analysis; coma; comatose patient; controlled study; cortical thickness (brain); female; France; frontal cortex; globus pallidus; gray matter; health care quality; heart arrest; hippocampus; human; human tissue; intensive care unit; Italy; machine learning; major clinical study; male; morphometry; multicenter study; neuroimaging; nuclear magnetic resonance imaging; posterior cingulate; predictive value; priority journal; putamen; thalamus; volumetry; brain; cerebellum cortex; clinical trial; diagnostic imaging; gray matter; heart arrest; middle aged; nuclear magnetic resonance imaging; pathology; prognosis; prospective study","Lippincott Williams and Wilkins","00903493","","CCMDC","28272153","Article","Scopus","2-s2.0-85014642030"
"Zhuang F.; Zhang Z.; Qian M.; Shi C.; Xie X.; He Q.","Zhuang, Fuzhen (23391452500); Zhang, Zhiqiang (55721664700); Qian, Mingda (57193902645); Shi, Chuan (55447999200); Xie, Xing (35231616500); He, Qing (26643590900)","23391452500; 55721664700; 57193902645; 55447999200; 35231616500; 26643590900","Representation learning via Dual-Autoencoder for recommendation","2017","Neural Networks","97","10.1016/j.neunet.2017.03.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017428311&doi=10.1016%2fj.neunet.2017.03.009&partnerID=40&md5=a2e67d71361cd7e4d9f16349ebc7087e","Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Beijing University of Posts and Telecommunications, Beijing, China; Microsoft Research, China","Zhuang F., Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Zhang Z., Beijing University of Posts and Telecommunications, Beijing, China; Qian M., Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Shi C., Beijing University of Posts and Telecommunications, Beijing, China; Xie X., Microsoft Research, China; He Q., Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China","Recommendation has provoked vast amount of attention and research in recent decades. Most previous works employ matrix factorization techniques to learn the latent factors of users and items. And many subsequent works consider external information, e.g., social relationships of users and items’ attributions, to improve the recommendation performance under the matrix factorization framework. However, matrix factorization methods may not make full use of the limited information from rating or check-in matrices, and achieve unsatisfying results. Recently, deep learning has proven able to learn good representation in natural language processing, image classification, and so on. Along this line, we propose a new representation learning framework called Recommendation via Dual-Autoencoder (ReDa). In this framework, we simultaneously learn the new hidden representations of users and items using autoencoders, and minimize the deviations of training data by the learnt representations of users and items. Based on this framework, we develop a gradient descent method to learn hidden representations. Extensive experiments conducted on several real-world data sets demonstrate the effectiveness of our proposed method compared with state-of-the-art matrix factorization based methods. © 2017 Elsevier Ltd","Dual-Autoencoder; Matrix factorization; Recommendation; Representation learning","Attention; Databases, Factual; Humans; Learning; Machine Learning; Deep learning; Factorization; Gradient methods; Learning systems; Natural language processing systems; Auto encoders; External informations; Gradient Descent method; Matrix factorizations; NAtural language processing; Recommendation; Recommendation performance; Representation learning; Article; automation; computer interface; computer language; computer network; data base; decentralization; information processing; intermethod comparison; machine learning; network learning; nonhuman; attention; factual database; human; learning; machine learning; physiology; trends; Matrix algebra","Elsevier Ltd","08936080","","NNETE","28410513","Article","Scopus","2-s2.0-85017428311"
"Hetherington J.; Lessoway V.; Gunka V.; Abolmaesumi P.; Rohling R.","Hetherington, Jorden (57193795065); Lessoway, Victoria (16145363600); Gunka, Vit (6508059485); Abolmaesumi, Purang (6602170125); Rohling, Robert (7004322927)","57193795065; 16145363600; 6508059485; 6602170125; 7004322927","SLIDE: automatic spine level identification system using a deep convolutional neural network","2017","International Journal of Computer Assisted Radiology and Surgery","63","10.1007/s11548-017-1575-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016640225&doi=10.1007%2fs11548-017-1575-8&partnerID=40&md5=60a73b4ac7e3c44038440fa8a5e97e7e","Department of Electrical and Computer Engineering, The University of British Columbia, 2332 Main Mall, Vancouver, V6T 1Z4, BC, Canada; Department of Mechanical Engineering, The University of British Columbia, 2332 Main Mall, Vancouver, V6T 1Z4, BC, Canada; Department of Ultrasound, BC Women’s Hospital, 4500 Oak Street, Vancouver, V6H 3N1, BC, Canada; Department of Obstetric Anesthesia, BC Women’s Hospital, 4500 Oak Street, Vancouver, V6H 3N1, BC, Canada","Hetherington J., Department of Electrical and Computer Engineering, The University of British Columbia, 2332 Main Mall, Vancouver, V6T 1Z4, BC, Canada; Lessoway V., Department of Ultrasound, BC Women’s Hospital, 4500 Oak Street, Vancouver, V6H 3N1, BC, Canada; Gunka V., Department of Obstetric Anesthesia, BC Women’s Hospital, 4500 Oak Street, Vancouver, V6H 3N1, BC, Canada; Abolmaesumi P., Department of Electrical and Computer Engineering, The University of British Columbia, 2332 Main Mall, Vancouver, V6T 1Z4, BC, Canada; Rohling R., Department of Electrical and Computer Engineering, The University of British Columbia, 2332 Main Mall, Vancouver, V6T 1Z4, BC, Canada, Department of Mechanical Engineering, The University of British Columbia, 2332 Main Mall, Vancouver, V6T 1Z4, BC, Canada","Purpose: Percutaneous spinal needle insertion procedures often require proper identification of the vertebral level to effectively and safely deliver analgesic agents. The current clinical method involves “blind” identification of the vertebral level through manual palpation of the spine, which has only 30% reported accuracy. Therefore, there is a need for better anatomical identification prior to needle insertion. Methods: A real-time system was developed to identify the vertebral level from a sequence of ultrasound images, following a clinical imaging protocol. The system uses a deep convolutional neural network (CNN) to classify transverse images of the lower spine. Several existing CNN architectures were implemented, utilizing transfer learning, and compared for adequacy in a real-time system. In the system, the CNN output is processed, using a novel state machine, to automatically identify vertebral levels as the transducer moves up the spine. Additionally, a graphical display was developed and integrated within 3D Slicer. Finally, an augmented reality display, projecting the level onto the patient’s back, was also designed. A small feasibility study (n= 20) evaluated performance. Results: The proposed CNN successfully discriminates ultrasound images of the sacrum, intervertebral gaps, and vertebral bones, achieving 88% 20-fold cross-validation accuracy. Seventeen of 20 test ultrasound scans had successful identification of all vertebral levels, processed at real-time speed (40 frames/s). Conclusion: A machine learning system is presented that successfully identifies lumbar vertebral levels. The small study on human subjects demonstrated real-time performance. A projection-based augmented reality display was used to show the vertebral level directly on the subject adjacent to the puncture site. © 2017, CARS.","Machine learning; Needle guidance; Ultrasound; Vertebral level","Algorithms; Anesthesia, Epidural; Humans; Image Processing, Computer-Assisted; Lumbar Vertebrae; Neural Networks (Computer); Spine; anatomical variation; Article; artificial neural network; automation; clinical evaluation; computer graphics; convolutional neural network; feasibility study; fifth lumbar vertebra; first lumbar vertebra; fourth lumbar vertebra; human; intermethod comparison; measurement accuracy; priority journal; real time echography; real time tracking system; real time ultrasound scanner; sacral vertebra; software validation; three dimensional imaging; ultrasound transducer; vertebra body; algorithm; diagnostic imaging; epidural anesthesia; evaluation study; image processing; lumbar vertebra; procedures; spine","Springer Verlag","18616410","","","28361323","Article","Scopus","2-s2.0-85016640225"
"Lu N.; Li T.; Ren X.; Miao H.","Lu, Na (39161672600); Li, Tengfei (56532771100); Ren, Xiaodong (56039808100); Miao, Hongyu (8979782400)","39161672600; 56532771100; 56039808100; 8979782400","A Deep Learning Scheme for Motor Imagery Classification based on Restricted Boltzmann Machines","2017","IEEE Transactions on Neural Systems and Rehabilitation Engineering","340","10.1109/TNSRE.2016.2601240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021307758&doi=10.1109%2fTNSRE.2016.2601240&partnerID=40&md5=02b14aa8d772c1d50e648b273371d627","State Key Laboratory for Manufacturing Systems Engineering, Systems Engineering Institute, Xi'an Jiaotong University, Xi'an Shaanxi, 710049, China; Department of Biostatistics, School of Public Health, University of Texas at Houston, Houston, 77030, TX, United States","Lu N., State Key Laboratory for Manufacturing Systems Engineering, Systems Engineering Institute, Xi'an Jiaotong University, Xi'an Shaanxi, 710049, China; Li T., State Key Laboratory for Manufacturing Systems Engineering, Systems Engineering Institute, Xi'an Jiaotong University, Xi'an Shaanxi, 710049, China; Ren X., State Key Laboratory for Manufacturing Systems Engineering, Systems Engineering Institute, Xi'an Jiaotong University, Xi'an Shaanxi, 710049, China; Miao H., Department of Biostatistics, School of Public Health, University of Texas at Houston, Houston, 77030, TX, United States","Motor imagery classification is an important topic in brain-computer interface (BCI) research that enables the recognition of a subject's intension to, e.g., implement prosthesis control. The brain dynamics of motor imagery are usually measured by electroencephalography (EEG) as nonstationary time series of low signal-to-noise ratio. Although a variety of methods have been previously developed to learn EEG signal features, the deep learning idea has rarely been explored to generate new representation of EEG features and achieve further performance improvement for motor imagery classification. In this study, a novel deep learning scheme based on restricted Boltzmann machine (RBM) is proposed. Specifically, frequency domain representations of EEG signals obtained via fast Fourier transform (FFT) and wavelet package decomposition (WPD) are obtained to train three RBMs. These RBMs are then stacked up with an extra output layer to form a four-layer neural network, which is named the frequential deep belief network (FDBN). The output layer employs the softmax regression to accomplish the classification task. Also, the conjugate gradient method and backpropagation are used to fine tune the FDBN. Extensive and systematic experiments have been performed on public benchmark datasets, and the results show that the performance improvement of FDBN over other selected state-of-the-art methods is statistically significant. Also, several findings that may be of significant interest to the BCI community are presented in this article. © 2016 IEEE.","Brain-computer interface (BCI); deep learning; motor imagery; restricted Boltzman machine (RBM)","Algorithms; Brain Mapping; Brain-Computer Interfaces; Electroencephalography; Evoked Potentials, Motor; Fourier Analysis; Humans; Imagination; Intention; Machine Learning; Motor Cortex; Movement; Neural Networks (Computer); Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Signal Processing, Computer-Assisted; Benchmarking; Biomedical signal processing; Brain computer interface; Conjugate gradient method; Deep neural networks; Education; Electroencephalography; Electrophysiology; Fast Fourier transforms; Image classification; Interfaces (computer); Network layers; Signal to noise ratio; Wavelet decomposition; Four-layer neural networks; Frequency-domain representations; Motor imagery; Motor imagery classification; Non-stationary time series; restricted Boltzman machine (RBM); Restricted boltzmann machine; Wavelet package decomposition; Article; artificial neural network; brain computer interface; electroencephalography; electromyography; electrooculography; Fourier transformation; human; human experiment; mathematical model; measurement accuracy; motor imagery classification; normal human; restricted Boltzmann machine; sensitivity and specificity; signal noise ratio; training; weight change; algorithm; automated pattern recognition; behavior; brain computer interface; brain mapping; evaluation study; Fourier analysis; imagination; machine learning; motor cortex; motor evoked potential; movement (physiology); physiology; procedures; reproducibility; signal processing; Deep learning","Institute of Electrical and Electronics Engineers Inc.","15344320","","ITNSB","27542114","Article","Scopus","2-s2.0-85021307758"
"Pouyan M.B.; Nourani M.","Pouyan, Maziyar Baran (35797299700); Nourani, Mehrdad (57204298565)","35797299700; 57204298565","Clustering Single-Cell Expression Data Using Random Forest Graphs","2017","IEEE Journal of Biomedical and Health Informatics","20","10.1109/JBHI.2016.2565561","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023619421&doi=10.1109%2fJBHI.2016.2565561&partnerID=40&md5=9cbf9469bf0a7f015a5b9bdde9605fd1","Quality of Life Technology Laboratory, Department of Electrical Engineering, University of Texas at Dallas, Richardson, 75080, TX, United States","Pouyan M.B., Quality of Life Technology Laboratory, Department of Electrical Engineering, University of Texas at Dallas, Richardson, 75080, TX, United States; Nourani M., Quality of Life Technology Laboratory, Department of Electrical Engineering, University of Texas at Dallas, Richardson, 75080, TX, United States","Complex tissues such as brain and bone marrow are made up of multiple cell types. As the study of biological tissue structure progresses, the role of cell-type-specific research becomes increasingly important. Novel sequencing technology such as single-cell cytometry provides researchers access to valuable biological data. Applying machine-learning techniques to these high-throughput datasets provides deep insights into the cellular landscape of the tissue where those cells are a part of. In this paper, we propose the use of random-forest-based single-cell profiling, a new machine-learning-based technique, to profile different cell types of intricate tissues using single-cell cytometry data. Our technique utilizes random forests to capture cell marker dependences and model the cellular populations using the cell network concept. This cellular network helps us discover what cell types are in the tissue. Our experimental results on public-domain datasets indicate promising performance and accuracy of our technique in extracting cell populations of complex tissues. © 2016 IEEE.","Clustering; random forest (RF); shared nearest neighbor (SNN); single-cell; tissue profiling","Algorithms; Animals; Bone Marrow Cells; Cluster Analysis; Computational Biology; Databases, Factual; Decision Trees; Gene Expression Profiling; Humans; Machine Learning; Mice; Single-Cell Analysis; Bone; Cell culture; Cell proliferation; Cells; Complex networks; Decision trees; Histology; Machine learning; Random forests; CD4 antigen; CD8 antigen; Biological tissues; Cell populations; Cellular populations; Clustering; Machine learning techniques; Multiple cell types; Shared nearest neighbors; Single cells; Article; bone marrow cell; cytometry; flow cytometry; human; information; nonhuman; random forest; single cell analysis; statistical parameters; Young modulus; algorithm; animal; biology; cluster analysis; cytology; decision tree; factual database; gene expression profiling; machine learning; mouse; procedures; single cell analysis; Tissue","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28113735","Article","Scopus","2-s2.0-85023619421"
"Cicero M.; Bilbily A.; Colak E.; Dowdell T.; Gray B.; Perampaladas K.; Barfett J.","Cicero, Mark (57192257936); Bilbily, Alexander (57192235516); Colak, Errol (53864740900); Dowdell, Tim (7801649576); Gray, Bruce (56644017900); Perampaladas, Kuhan (24279869200); Barfett, Joseph (8637104200)","57192257936; 57192235516; 53864740900; 7801649576; 56644017900; 24279869200; 8637104200","Training and Validating a Deep Convolutional Neural Network for Computer-Aided Detection and Classification of Abnormalities on Frontal Chest Radiographs","2017","Investigative Radiology","210","10.1097/RLI.0000000000000341","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001976294&doi=10.1097%2fRLI.0000000000000341&partnerID=40&md5=f6295bcf3feb906b46ef167870c3a6a3","Department of Medical Imaging, St Michael's Hospital, 30 Bond St, Toronto, M5B 1W8, ON, Canada; Department of Pharmaceutical Sciences, University of Toronto, Toronto, ON, Canada","Cicero M., Department of Medical Imaging, St Michael's Hospital, 30 Bond St, Toronto, M5B 1W8, ON, Canada; Bilbily A., Department of Medical Imaging, St Michael's Hospital, 30 Bond St, Toronto, M5B 1W8, ON, Canada; Colak E., Department of Medical Imaging, St Michael's Hospital, 30 Bond St, Toronto, M5B 1W8, ON, Canada; Dowdell T., Department of Medical Imaging, St Michael's Hospital, 30 Bond St, Toronto, M5B 1W8, ON, Canada; Gray B., Department of Medical Imaging, St Michael's Hospital, 30 Bond St, Toronto, M5B 1W8, ON, Canada; Perampaladas K., Department of Pharmaceutical Sciences, University of Toronto, Toronto, ON, Canada; Barfett J., Department of Medical Imaging, St Michael's Hospital, 30 Bond St, Toronto, M5B 1W8, ON, Canada","Objectives: Convolutional neural networks (CNNs) are a subtype of artificial neural network that have shown strong performance in computer vision tasks including image classification. To date, there has been limited application of CNNs to chest radiographs, the most frequently performed medical imaging study. We hypothesize CNNs can learn to classify frontal chest radiographs according to common findings from a sufficiently large data set. Materials and Methods: Our institution's research ethics board approved a single-center retrospective review of 35,038 adult posterior-anterior chest radiographs and final reports performed between 2005 and 2015 (56% men, average age of 56, patient type: 24% inpatient, 39% outpatient, 37% emergency department) with a waiver for informed consent. The GoogLeNet CNN was trained using 3 graphics processing units to automatically classify radiographs as normal (n = 11,702) or into 1 or more of cardiomegaly (n = 9240), consolidation (n = 6788), pleural effusion (n = 7786), pulmonary edema (n = 1286), or pneumothorax (n = 1299). The network's performance was evaluated using receiver operating curve analysis on a test set of 2443 radiographs with the criterion standard being board-certified radiologist interpretation. Results: Using 256 × 256-pixel images as input, the network achieved an overall sensitivity and specificity of 91% with an area under the curve of 0.964 for classifying a study as normal (n = 1203). For the abnormal categories, the sensitivity, specificity, and area under the curve, respectively, were 91%, 91%, and 0.962 for pleural effusion (n = 782), 82%, 82%, and 0.868 for pulmonary edema (n = 356), 74%, 75%, and 0.850 for consolidation (n = 214), 81%, 80%, and 0.875 for cardiomegaly (n = 482), and 78%, 78%, and 0.861 for pneumothorax (n = 167). Conclusions: Current deep CNN architectures can be trained with modest-sized medical data sets to achieve clinically useful performance at detecting and excluding common pathology on chest radiographs. © Copyright 2016 Wolters Kluwer Health, Inc. All rights reserved.","cardiomegaly; machine learning; neural network; pleural effusion; pneumonia; pneumothorax; pulmonary edema; x-ray","Diagnosis, Computer-Assisted; Female; Heart; Heart Diseases; Humans; Lung; Lung Diseases; Male; Middle Aged; Neural Networks (Computer); Radiography, Thoracic; Reproducibility of Results; Retrospective Studies; Sensitivity and Specificity; accuracy; adult; Article; artificial neural network; cardiomegaly; computer assisted diagnosis; congenital malformation; diagnostic imaging; emergency ward; female; hospital patient; human; lung edema; major clinical study; male; medical record review; middle aged; outpatient; pleura effusion; pneumothorax; predictive value; priority journal; radiologist; sensitivity and specificity; thorax radiography; training; validation process; computer assisted diagnosis; heart; heart disease; lung; lung disease; procedures; reproducibility; retrospective study; thorax radiography; validation study","Lippincott Williams and Wilkins","00209996","","INVRA","27922974","Article","Scopus","2-s2.0-85001976294"
"Pärnamaa T.; Parts L.","Pärnamaa, Tanel (57190436927); Parts, Leopold (57195956429)","57190436927; 57195956429","Accurate classification of protein subcellular localization from high-throughput microscopy images using deep learning","2017","G3: Genes, Genomes, Genetics","110","10.1534/g3.116.033654","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019234865&doi=10.1534%2fg3.116.033654&partnerID=40&md5=a98eebcf8efe5956adabbe342b2d732d","Institute of Computer Science, University of Tartu, Tartu, 50409, Estonia; Wellcome Trust Sanger Institute, Hinxton, Cambridgeshire, CB101SA, United Kingdom","Pärnamaa T., Institute of Computer Science, University of Tartu, Tartu, 50409, Estonia; Parts L., Institute of Computer Science, University of Tartu, Tartu, 50409, Estonia, Wellcome Trust Sanger Institute, Hinxton, Cambridgeshire, CB101SA, United Kingdom","High-throughput microscopy of many single cells generates high-dimensional data that are far from straightforward to analyze. One important problem is automatically detecting the cellular compartment where a fluorescently-tagged protein resides, a task relatively simple for an experienced human, but difficult to automate on a computer. Here, we train an 11-layer neural network on data from mapping thousands of yeast proteins, achieving per cell localization classification accuracy of 91%, and per protein accuracy of 99% on held-out images. We confirm that low-level network features correspond to basic image characteristics, while deeper layers separate localization classes. Using this network as a feature calculator, we train standard classifiers that assign proteins to previously unseen compartments after observing only a small number of training examples. Our results are the most accurate subcellular localization classifications to date, and demonstrate the usefulness of deep learning for high-throughput microscopy. © 2017 Parnamaa and Parts.","Deep learning; High-content; Microscopy; ScreeningMachine learning; Yeast","Fungal Proteins; High-Throughput Screening Assays; Image Interpretation, Computer-Assisted; Machine Learning; Microscopy, Fluorescence; Protein Transport; Proteome; Yeasts; fungal protein; proteome; cellular distribution; classification; classifier; human; learning; microscopy; nervous system; nonhuman; yeast; classification; computer assisted diagnosis; fluorescence microscopy; high throughput screening; machine learning; metabolism; procedures; protein transport; ultrastructure; yeast","Genetics Society of America","21601836","","","28391243","Article","Scopus","2-s2.0-85019234865"
"Zhou T.; Han G.; Li B.N.; Lin Z.; Ciaccio E.J.; Green P.H.; Qin J.","Zhou, Teng (58765199500); Han, Guoqiang (7202923324); Li, Bing Nan (55995487400); Lin, Zhizhe (57193890476); Ciaccio, Edward J. (7004846604); Green, Peter H. (57203774948); Qin, Jing (35339855100)","58765199500; 7202923324; 55995487400; 57193890476; 7004846604; 57203774948; 35339855100","Quantitative analysis of patients with celiac disease by video capsule endoscopy: A deep learning method","2017","Computers in Biology and Medicine","118","10.1016/j.compbiomed.2017.03.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017539070&doi=10.1016%2fj.compbiomed.2017.03.031&partnerID=40&md5=43a8619ae3bd7471ed0e0df474a86aa1","School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Department of Biomedical Engineering, Hefei University of Technology, Hefei, 230009, China; Affiliated Shantou Hospital of Sun Yat-sen University, Shantou Central Hospital, Shantou, 515000, China; Center for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong; Department of Medicine, Celiac Disease Center, Columbia University, New York, United States","Zhou T., School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Han G., School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Li B.N., Department of Biomedical Engineering, Hefei University of Technology, Hefei, 230009, China; Lin Z., Affiliated Shantou Hospital of Sun Yat-sen University, Shantou Central Hospital, Shantou, 515000, China; Ciaccio E.J., Department of Medicine, Celiac Disease Center, Columbia University, New York, United States; Green P.H., Department of Medicine, Celiac Disease Center, Columbia University, New York, United States; Qin J., Center for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong","Background. Celiac disease is one of the most common diseases in the world. Capsule endoscopy is an alternative way to visualize the entire small intestine without invasiveness to the patient. It is useful to characterize celiac disease, but hours are need to manually analyze the retrospective data of a single patient. Computer-aided quantitative analysis by a deep learning method helps in alleviating the workload during analysis of the retrospective videos. Method. Capsule endoscopy clips from 6 celiac disease patients and 5 controls were preprocessed for training. The frames with a large field of opaque extraluminal fluid or air bubbles were removed automatically by using a pre-selection algorithm. Then the frames were cropped and the intensity was corrected prior to frame rotation in the proposed new method. The GoogLeNet is trained with these frames. Then, the clips of capsule endoscopy from 5 additional celiac disease patients and 5 additional control patients are used for testing. The trained GoogLeNet was able to distinguish the frames from capsule endoscopy clips of celiac disease patients vs controls. Quantitative measurement with evaluation of the confidence was developed to assess the severity level of pathology in the subjects. Results. Relying on the evaluation confidence, the GoogLeNet achieved 100% sensitivity and specificity for the testing set. The t-test confirmed the evaluation confidence is significant to distinguish celiac disease patients from controls. Furthermore, it is found that the evaluation confidence may also relate to the severity level of small bowel mucosal lesions. Conclusions. A deep convolutional neural network was established for quantitative measurement of the existence and degree of pathology throughout the small intestine, which may improve computer-aided clinical techniques to assess mucosal atrophy and other etiologies in real-time with videocapsule endoscopy. © 2017 Elsevier Ltd","Celiac disease; Deep learning; GoogLeNet; Quantitative analysis; Videocapsule endoscopy","Algorithms; Capsule Endoscopy; Celiac Disease; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Air; Chemical analysis; Computer aided analysis; Computer aided instruction; Deep learning; Disease control; Learning systems; Neural networks; Pathology; Additional control; Celiac disease; Clinical techniques; Convolutional neural network; GoogLeNet; Quantitative measurement; Sensitivity and specificity; Video capsule endoscopies; adult; algorithm; Article; capsule endoscopy; celiac disease; clinical article; controlled study; disease severity; female; gastroenterologist; human; male; middle aged; priority journal; quantitative analysis; retrospective study; training; videoendoscopy; workload; artificial neural network; capsule endoscopy; celiac disease; computer assisted diagnosis; diagnostic imaging; machine learning; procedures; Endoscopy","Elsevier Ltd","00104825","","CBMDA","28412572","Article","Scopus","2-s2.0-85017539070"
"Zhang L.; He Z.; Liu Y.","Zhang, Lei (55648142400); He, Zhenwei (57193330822); Liu, Yan (56856516500)","55648142400; 57193330822; 56856516500","Deep object recognition across domains based on adaptive extreme learning machine","2017","Neurocomputing","50","10.1016/j.neucom.2017.02.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013028730&doi=10.1016%2fj.neucom.2017.02.016&partnerID=40&md5=bcc4d5d3a9819e1ead2f5956cde0e1d4","College of Communication Engineering, Chongqing University, 174 ShaZheng street, ShaPingBa District, Chongqing, 400044, China","Zhang L., College of Communication Engineering, Chongqing University, 174 ShaZheng street, ShaPingBa District, Chongqing, 400044, China; He Z., College of Communication Engineering, Chongqing University, 174 ShaZheng street, ShaPingBa District, Chongqing, 400044, China; Liu Y., College of Communication Engineering, Chongqing University, 174 ShaZheng street, ShaPingBa District, Chongqing, 400044, China","Deep learning with a convolutional neural network (CNN) has been proved to be very effective in feature extraction and representation of images. For image classification problems, this work aims at exploring the capability of extreme learning machine on high-level deep features of images. Additionally, motivated by the biological learning mechanism of ELM, in this paper, an adaptive extreme learning machine (AELM) method is proposed for handling cross-task (domain) learning problems, without loss of its nature of randomization and high efficiency. The proposed AELM is an extension of ELM from single task to cross task learning, by introducing a new error term and Laplacian graph based manifold regularization term in objective function. We have discussed the nearest neighbor, support vector machines and extreme learning machines for image classification under deep convolutional activation feature representation. Specifically, we adopt 4 benchmark object recognition datasets from multiple sources with domain bias for evaluating different classifiers. The deep features of the object dataset are obtained by a well-trained CNN with five convolutional layers and three fully-connected layers on ImageNet. Experiments demonstrate that the proposed AELM is comparable and effective in single and multiple domains based recognition tasks. © 2017 Elsevier B.V.","Deep learning; Extreme learning machine; Image classification; Object recognition; Support vector machine","Classification (of information); Convolution; Convolutional neural networks; Deep learning; Graphic methods; Image classification; Knowledge acquisition; Object recognition; Support vector machines; Biological learning; Extreme learning machine; Feature representation; Learning problem; Manifold regularizations; Multiple domains; Nearest neighbors; Objective functions; adaptive extreme learning machine; algorithm; Article; artificial neural network; benchmarking; classification; classifier; controlled study; information processing; machine learning; object recognition; randomization; support vector machine; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85013028730"
"Li S.; Dong F.; Wu Y.; Zhang S.; Zhang C.; Liu X.; Jiang T.; Zeng J.","Li, Shuya (57216081349); Dong, Fanghong (57196106046); Wu, Yuexin (56580870700); Zhang, Sai (56580715700); Zhang, Chen (58427859100); Liu, Xiao (56528599900); Jiang, Tao (56372739500); Zeng, Jianyang (33468010200)","57216081349; 57196106046; 56580870700; 56580715700; 58427859100; 56528599900; 56372739500; 33468010200","A deep boosting based approach for capturing the sequence binding preferences of RNA-binding proteins from high-throughput CLIP-seq data","2017","Nucleic Acids Research","16","10.1093/NAR/GKX492","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031852511&doi=10.1093%2fNAR%2fGKX492&partnerID=40&md5=40cb003d3e0f07212947e5288de004dd","School of Life Sciences, Tsinghua University, Beijing, 100084, China; Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Department of Computer Science and Engineering, University of California, Riverside, 92521, CA, United States; MOE Key Lab of Bioinformatics and Bioinformatics Division, TNLIST, Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China","Li S., School of Life Sciences, Tsinghua University, Beijing, 100084, China; Dong F., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Wu Y., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Zhang S., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Zhang C., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Liu X., School of Life Sciences, Tsinghua University, Beijing, 100084, China; Jiang T., Department of Computer Science and Engineering, University of California, Riverside, 92521, CA, United States, MOE Key Lab of Bioinformatics and Bioinformatics Division, TNLIST, Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Zeng J., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China","Characterizing the binding behaviors of RNA-binding proteins (RBPs) is important for understanding their functional roles in gene expression regulation. However, current high-throughput experimental methods for identifying RBP targets, such as CLIP-seq and RNAcompete, usually suffer from the false negative issue. Here, we develop a deep boosting based machine learning approach, called DeBooster, to accurately model the binding sequence preferences and identify the corresponding binding targets of RBPs from CLIP-seq data. Comprehensive validation tests have shown that DeBooster can outperform other state-of-the-art approaches in RBP target prediction. In addition, we have demonstrated that DeBooster may provide new insights into understanding the regulatory functions of RBPs, including the binding effects of the RNA helicase MOV10 on mRNA degradation, the potentially different ADAR1 binding behaviors related to its editing activity, as well as the antagonizing effect of RBP binding on miRNA repression. Moreover, DeBooster may provide an effective index to investigate the effect of pathogenic mutations in RBP binding sites, especially those related to splicing events. We expect that DeBooster will be widely applied to analyze large-scale CLIP-seq experimental data and can provide a practically useful tool for novel biological discoveries in understanding the regulatory mechanisms of RBPs. The source code of DeBooster can be downloaded from http://github.com/dongfanghong/deepboost. © The Author(s) 2017","","3' Untranslated Regions; Algorithms; Base Sequence; Binding Sites; Binding, Competitive; Computational Biology; Gene Expression Regulation; High-Throughput Nucleotide Sequencing; Humans; Internet; Machine Learning; Mutation; Nucleotide Motifs; Protein Binding; Reproducibility of Results; RNA-Binding Proteins; messenger RNA; microRNA; RNA binding protein; RNA helicase; RNA helicase MOV10; unclassified drug; 3' untranslated region; protein binding; RNA binding protein; 3' untranslated region; Article; deep learning; ERBB2 gene; gene; high throughput sequencing; online system; prediction; protein RNA binding; RNA degradation; scoring system; software; algorithm; binding competition; binding site; biology; gene expression regulation; genetics; high throughput sequencing; human; Internet; machine learning; metabolism; mutation; nucleotide motif; nucleotide sequence; procedures; reproducibility; statistics and numerical data","Oxford University Press","03051048","","NARHA","28575488","Article","Scopus","2-s2.0-85031852511"
"Fergus P.; Hussain A.; Al-Jumeily D.; Huang D.-S.; Bouguila N.","Fergus, Paul (55905767600); Hussain, Abir (56212648400); Al-Jumeily, Dhiya (57382902800); Huang, De-Shuang (13310398900); Bouguila, Nizar (6603545988)","55905767600; 56212648400; 57382902800; 13310398900; 6603545988","Classification of caesarean section and normal vaginal deliveries using foetal heart rate signals and advanced machine learning algorithms","2017","BioMedical Engineering Online","51","10.1186/s12938-017-0378-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021771027&doi=10.1186%2fs12938-017-0378-z&partnerID=40&md5=5fd8c10399a400095fc3e476529dcf94","Liverpool John Moors University, Applied Computing Research Group, Department of Computer Science, Faculty of Engineering and Technology, Byron Street, Liverpool, L3 3AF, United Kingdom; Tongji University, Institute of Machine Learning and Systems Biology, No. 4800 Caoan Road, Shanghai, 201804, China; Concorida University, Concordia Institute for Information Systems Engineering, 1455 de Maisonneuve Blvd West, EV7.632, Montreal, HJ3G 2W1, QC, Canada","Fergus P., Liverpool John Moors University, Applied Computing Research Group, Department of Computer Science, Faculty of Engineering and Technology, Byron Street, Liverpool, L3 3AF, United Kingdom; Hussain A., Liverpool John Moors University, Applied Computing Research Group, Department of Computer Science, Faculty of Engineering and Technology, Byron Street, Liverpool, L3 3AF, United Kingdom; Al-Jumeily D., Liverpool John Moors University, Applied Computing Research Group, Department of Computer Science, Faculty of Engineering and Technology, Byron Street, Liverpool, L3 3AF, United Kingdom; Huang D.-S., Tongji University, Institute of Machine Learning and Systems Biology, No. 4800 Caoan Road, Shanghai, 201804, China; Bouguila N., Concorida University, Concordia Institute for Information Systems Engineering, 1455 de Maisonneuve Blvd West, EV7.632, Montreal, HJ3G 2W1, QC, Canada","Background: Visual inspection of cardiotocography traces by obstetricians and midwives is the gold standard for monitoring the wellbeing of the foetus during antenatal care. However, inter- and intra-observer variability is high with only a 30% positive predictive value for the classification of pathological outcomes. This has a significant negative impact on the perinatal foetus and often results in cardio-pulmonary arrest, brain and vital organ damage, cerebral palsy, hearing, visual and cognitive defects and in severe cases, death. This paper shows that using machine learning and foetal heart rate signals provides direct information about the foetal state and helps to filter the subjective opinions of medical practitioners when used as a decision support tool. The primary aim is to provide a proof-of-concept that demonstrates how machine learning can be used to objectively determine when medical intervention, such as caesarean section, is required and help avoid preventable perinatal deaths. Methods: This is evidenced using an open dataset that comprises 506 controls (normal virginal deliveries) and 46 cases (caesarean due to pH ≤ 7.20-acidosis, n = 18; pH > 7.20 and pH < 7.25-foetal deterioration, n = 4; or clinical decision without evidence of pathological outcome measures, n = 24). Several machine-learning algorithms are trained, and validated, using binary classifier performance measures. Results: The findings show that deep learning classification achieves sensitivity = 94%, specificity = 91%, Area under the curve = 99%, F-score = 100%, and mean square error = 1%. Conclusions: The results demonstrate that machine learning significantly improves the efficiency for the detection of caesarean section and normal vaginal deliveries using foetal heart rate signals compared with obstetrician and midwife predictions and systems reported in previous studies. © 2017 The Author(s).","Classification; Deep learning; Feature extraction and selection; Intrapartum cardiotocography; Machine learning; Random forest","Adult; Cardiotocography; Cesarean Section; Contraceptive Devices, Female; Discriminant Analysis; Female; Heart Rate, Fetal; Humans; Machine Learning; Nonlinear Dynamics; Pregnancy; Signal Processing, Computer-Assisted; Young Adult; Artificial intelligence; Audition; Biomedical signal processing; Brain; Classification (of information); Decision support systems; Decision trees; Deep learning; Education; Feature extraction; Heart; Learning systems; Area under the curves; Cardiotocography; Decision support tools; Feature extraction and selection; Intra-observer variability; Medical intervention; Positive predictive values; Random forests; adult; Article; cesarean section; classification algorithm; controlled study; female; fetus heart rate; human; machine learning; major clinical study; pH; predictive value; priority journal; receiver operating characteristic; sensitivity and specificity; vaginal delivery; validation study; young adult; cardiotocography; cesarean section; classification; discriminant analysis; female contraceptive device; nonlinear system; pregnancy; signal processing; Learning algorithms","BioMed Central Ltd.","1475925X","","BEOIB","28679415","Article","Scopus","2-s2.0-85021771027"
"Monteiro E.; Costa C.; Oliveira J.L.","Monteiro, Eriksson (55480863200); Costa, Carlos (7201473619); Oliveira, José Luís (57193360895)","55480863200; 7201473619; 57193360895","A De-Identification Pipeline for Ultrasound Medical Images in DICOM Format","2017","Journal of Medical Systems","21","10.1007/s10916-017-0736-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017457466&doi=10.1007%2fs10916-017-0736-1&partnerID=40&md5=aafd5ae0444194a5e6dd238f3f1e7f66","University of Aveiro, DETI/IEETA, Aveiro, Portugal","Monteiro E., University of Aveiro, DETI/IEETA, Aveiro, Portugal; Costa C., University of Aveiro, DETI/IEETA, Aveiro, Portugal; Oliveira J.L., University of Aveiro, DETI/IEETA, Aveiro, Portugal","Clinical data sharing between healthcare institutions, and between practitioners is often hindered by privacy protection requirements. This problem is critical in collaborative scenarios where data sharing is fundamental for establishing a workflow among parties. The anonymization of patient information burned in DICOM images requires elaborate processes somewhat more complex than simple de-identification of textual information. Usually, before sharing, there is a need for manual removal of specific areas containing sensitive information in the images. In this paper, we present a pipeline for ultrasound medical image de-identification, provided as a free anonymization REST service for medical image applications, and a Software-as-a-Service to streamline automatic de-identification of medical images, which is freely available for end-users. The proposed approach applies image processing functions and machine-learning models to bring about an automatic system to anonymize medical images. To perform character recognition, we evaluated several machine-learning models, being Convolutional Neural Networks (CNN) selected as the best approach. For accessing the system quality, 500 processed images were manually inspected showing an anonymization rate of 89.2%. The tool can be accessed at https://bioinformatics.ua.pt/dicom/anonymizer and it is available with the most recent version of Google Chrome, Mozilla Firefox and Safari. A Docker image containing the proposed service is also publicly available for the community. © 2017, Springer Science+Business Media New York.","De-identification; Deep-learning; Medical imaging; Neural networks; OCR","Confidentiality; Data Anonymization; Image Processing, Computer-Assisted; Information Dissemination; Privacy; Software; Ultrasonography; anonymised data; Article; artificial neural network; digital imaging and communications in medicine; echography; image analysis; image processing; image quality; machine learning; anonymization; confidentiality; echography; information dissemination; privacy; software","Springer New York LLC","01485598","","JMSYD","28405948","Article","Scopus","2-s2.0-85017457466"
"Rahnemoonfar M.; Sheppard C.","Rahnemoonfar, Maryam (54411066400); Sheppard, Clay (57194061369)","54411066400; 57194061369","Deep count: Fruit counting based on deep simulated learning","2017","Sensors (Switzerland)","389","10.3390/s17040905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018513324&doi=10.3390%2fs17040905&partnerID=40&md5=ea19a36c9b7fe6a724585ef4afe63197","Department of Computer Science, Texas A&M University-Corpus Christi, Corpus Christi, 78412, TX, United States","Rahnemoonfar M., Department of Computer Science, Texas A&M University-Corpus Christi, Corpus Christi, 78412, TX, United States; Sheppard C., Department of Computer Science, Texas A&M University-Corpus Christi, Corpus Christi, 78412, TX, United States","Recent years have witnessed significant advancement in computer vision research based on deep learning. Success of these tasks largely depends on the availability of a large amount of training samples. Labeling the training samples is an expensive process. In this paper, we present a simulated deep convolutional neural network for yield estimation. Knowing the exact number of fruits, flowers, and trees helps farmers to make better decisions on cultivation practices, plant disease prevention, and the size of harvest labor force. The current practice of yield estimation based on the manual counting of fruits or flowers by workers is a very time consuming and expensive process and it is not practical for big fields. Automatic yield estimation based on robotic agriculture provides a viable solution in this regard. Our network is trained entirely on synthetic data and tested on real data. To capture features on multiple scales, we used a modified version of the Inception-ResNet architecture. Our algorithm counts efficiently even if fruits are under shadow, occluded by foliage, branches, or if there is some degree of overlap amongst fruits. Experimental results show a 91% average test accuracy on real images and 93% on synthetic images. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Agricultural sensors; Deep learning; Simulated learning; Yield estimation","Algorithms; Machine Learning; Neural Networks (Computer); Agriculture; Cultivation; Deep learning; Fruits; Neural networks; Sampling; Convolutional neural network; Current practices; Simulated learning; Synthetic data; Synthetic images; Training sample; Viable solutions; Yield estimation; algorithm; artificial neural network; machine learning; Deep neural networks","MDPI AG","14248220","","","28425947","Article","Scopus","2-s2.0-85018513324"
"Shah S.J.","Shah, Sanjiv J. (12545068000)","12545068000","Precision Medicine for Heart Failure with Preserved Ejection Fraction: An Overview","2017","Journal of Cardiovascular Translational Research","67","10.1007/s12265-017-9756-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020182387&doi=10.1007%2fs12265-017-9756-y&partnerID=40&md5=434d88450203ec200bc5a3d59f930ccd","Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, IL, United States","Shah S.J., Division of Cardiology, Department of Medicine, Northwestern University Feinberg School of Medicine, Chicago, IL, United States","There are few proven therapies for heart failure with preserved ejection fraction (HFpEF). The lack of therapies, along with increased recognition of the disorder and its underlying pathophysiology, has led to the acknowledgement that HFpEF is heterogeneous and is not likely to respond to a one-size-fits-all approach. Thus, HFpEF is a prime candidate to benefit from a precision medicine approach. For this reason, we have assembled a compendium of papers on the topic of precision medicine in HFpEF in the Journal of Cardiovascular Translational Research. These papers cover a variety of topics relevant to precision medicine in HFpEF, including automated identification of HFpEF patients; machine learning, novel molecular approaches, genomics, and deep phenotyping of HFpEF; and clinical trial designs that can be used to advance precision medicine in HFpEF. In this introductory article, we provide an overview of precision medicine in HFpEF with the hope that the work described here and in the other papers in this special theme issue will stimulate investigators and clinicians to advance a more targeted approach to HFpEF classification and treatment. © 2017, Springer Science+Business Media New York.","Cluster analysis; Heart failure with preserved ejection fraction; Machine learning; Precision medicine; Treatment","Cardiovascular Agents; Comorbidity; Genetic Predisposition to Disease; Heart Failure; Humans; Machine Learning; Molecular Diagnostic Techniques; Phenotype; Precision Medicine; Predictive Value of Tests; Risk Factors; Stroke Volume; Systems Biology; Treatment Outcome; cardiovascular agent; Article; automation; cardiometabolic risk; clinical research; drug targeting; genomics; heart failure with preserved ejection fraction; heart right ventricle failure; human; machine learning; molecular genetics; obesity; patient identification; personalized medicine; phenotype; physician; priority journal; study design; comorbidity; genetic predisposition; genetics; heart failure; heart stroke volume; molecular diagnosis; pathophysiology; personalized medicine; predictive value; procedures; risk factor; systems biology; treatment outcome","Springer New York LLC","19375387","","","28585183","Article","Scopus","2-s2.0-85020182387"
"Cocos A.; Fiks A.G.; Masino A.J.","Cocos, Anne (57191845582); Fiks, Alexander G. (16039462300); Masino, Aaron J. (56276469700)","57191845582; 16039462300; 56276469700","Deep learning for pharmacovigilance: Recurrent neural network architectures for labeling adverse drug reactions in Twitter posts","2017","Journal of the American Medical Informatics Association","157","10.1093/jamia/ocw180","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026398638&doi=10.1093%2fjamia%2focw180&partnerID=40&md5=c78eadbc293f4aa460d14357b9951cc3","Department of Biomedical and Health Informatics, The Children's Hospital of Philadelphia, Philadelphia, PA, United States","Cocos A., Department of Biomedical and Health Informatics, The Children's Hospital of Philadelphia, Philadelphia, PA, United States; Fiks A.G., Department of Biomedical and Health Informatics, The Children's Hospital of Philadelphia, Philadelphia, PA, United States; Masino A.J., Department of Biomedical and Health Informatics, The Children's Hospital of Philadelphia, Philadelphia, PA, United States","Objective: Social media is an important pharmacovigilance data source for adverse drug reaction (ADR) identification. Human review of social media data is infeasible due to data quantity, thus natural language processing techniques are necessary. Social media includes informal vocabulary and irregular grammar, which challenge natural language processing methods. Our objective is to develop a scalable, deep-learning approach that exceeds state-of-the-art ADR detection performance in social media. Materials and Methods: We developed a recurrent neural network (RNN) model that labels words in an input sequence with ADR membership tags. The only input features are word-embedding vectors, which can be formed through task-independent pretraining or during ADR detection training. Results: Our best-performing RNN model used pretrained word embeddings created from a large, non- domain-specific Twitter dataset. It achieved an approximate match F-measure of 0.755 for ADR identification on the dataset, compared to 0.631 for a baseline lexicon system and 0.65 for the state-of-the-art conditional random field model. Feature analysis indicated that semantic information in pretrained word embeddings boosted sensitivity and, combined with contextual awareness captured in the RNN, precision. Discussion: Our model required no task-specific feature engineering, suggesting generalizability to additional sequence-labeling tasks. Learning curve analysis showed that our model reached optimal performance with fewer training examples than the other models. Conclusion: ADR detection performance in social media is significantly improved by using a contextually aware model and word embeddings formed from large, unlabeled datasets. The approach reduces manual datalabeling requirements and is scalable to large social media datasets. © The Author 2017. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.","Adverse drug reaction; Natural language processing; Neural networks (computer); Social media; Twitter messaging","Drug-Related Side Effects and Adverse Reactions; Humans; Machine Learning; Natural Language Processing; Neural Networks (Computer); Pharmacovigilance; Social Media; adverse drug reaction; Article; artificial neural network; drug surveillance program; embedding; learning; natural language processing; parasomnia; social media; adverse drug reaction; human; machine learning; natural language processing","Oxford University Press","10675027","","JAMAF","28339747","Article","Scopus","2-s2.0-85026398638"
"Segler M.H.S.; Waller M.P.","Segler, Marwin H. S. (37081859100); Waller, Mark P. (8081467400)","37081859100; 8081467400","Neural-Symbolic Machine Learning for Retrosynthesis and Reaction Prediction","2017","Chemistry - A European Journal","346","10.1002/chem.201605499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013399420&doi=10.1002%2fchem.201605499&partnerID=40&md5=fda916d41fdb4fc791df7cd0f3c4fed4","Organisch-Chemisches Institut and Center for Multiscale Theory and Computation, Westfälische Wilhelms-Universität Münster, Corrensstr. 40, Münster, 48149, Germany; Department of Physics and International Center for Quantum and Molecular Structures, Shanghai University, Shangda Road 99, Shanghai, 200444, China","Segler M.H.S., Organisch-Chemisches Institut and Center for Multiscale Theory and Computation, Westfälische Wilhelms-Universität Münster, Corrensstr. 40, Münster, 48149, Germany; Waller M.P., Organisch-Chemisches Institut and Center for Multiscale Theory and Computation, Westfälische Wilhelms-Universität Münster, Corrensstr. 40, Münster, 48149, Germany, Department of Physics and International Center for Quantum and Molecular Structures, Shanghai University, Shangda Road 99, Shanghai, 200444, China","Reaction prediction and retrosynthesis are the cornerstones of organic chemistry. Rule-based expert systems have been the most widespread approach to computationally solve these two related challenges to date. However, reaction rules often fail because they ignore the molecular context, which leads to reactivity conflicts. Herein, we report that deep neural networks can learn to resolve reactivity conflicts and to prioritize the most suitable transformation rules. We show that by training our model on 3.5 million reactions taken from the collective published knowledge of the entire discipline of chemistry, our model exhibits a top10-accuracy of 95 % in retrosynthesis and 97 % for reaction prediction on a validation set of almost 1 million reactions. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","artificial intelligence; machine learning; retrosynthesis; synthesis design; total synthesis","Artificial intelligence; Deep learning; Deep neural networks; Expert systems; Forecasting; Predictive analytics; Organic Chemistry; Reaction prediction; Retrosynthesis; Rule based expert systems; Symbolic machine learning; Synthesis design; Total synthesis; Transformation rules; article; artificial intelligence; deep neural network; prediction; synthesis; Learning systems","Wiley-VCH Verlag","09476539","","CEUJE","28134452","Article","Scopus","2-s2.0-85013399420"
"Le M.H.; Chen J.; Wang L.; Wang Z.; Liu W.; Cheng K.-T.; Yang X.","Le, Minh Hung (57202381721); Chen, Jingyu (57195284540); Wang, Liang (57221649435); Wang, Zhiwei (57216175393); Liu, Wenyu (8043635200); Cheng, Kwang-Ting (7402997957); Yang, Xin (57203539516)","57202381721; 57195284540; 57221649435; 57216175393; 8043635200; 7402997957; 57203539516","Automated diagnosis of prostate cancer in multi-parametric MRI based on multimodal convolutional neural networks","2017","Physics in Medicine and Biology","121","10.1088/1361-6560/aa7731","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026780215&doi=10.1088%2f1361-6560%2faa7731&partnerID=40&md5=6782d701ccb2236f94fe2de9530f42bf","School of Electronics and Communications, Huazhong University of Science and Technology, Wuhan, China; Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, Wuhan, China; Department of Computer Science, Hong Kong University of Science and Technology, Hong Kong, Hong Kong","Le M.H., School of Electronics and Communications, Huazhong University of Science and Technology, Wuhan, China; Chen J., School of Electronics and Communications, Huazhong University of Science and Technology, Wuhan, China; Wang L., Department of Radiology, Tongji Hospital, Huazhong University of Science and Technology, Wuhan, China; Wang Z., School of Electronics and Communications, Huazhong University of Science and Technology, Wuhan, China; Liu W., School of Electronics and Communications, Huazhong University of Science and Technology, Wuhan, China; Cheng K.-T., Department of Computer Science, Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Yang X., School of Electronics and Communications, Huazhong University of Science and Technology, Wuhan, China","Automated methods for prostate cancer (PCA) diagnosis in multi-parametric magnetic resonance imaging (MP-MRIs) are critical for alleviating requirements for interpretation of radiographs while helping to improve diagnostic accuracy (Artan et al 2010 IEEE Trans. Image Process. 19 2444-55, Litjens et al 2014 IEEE Trans. Med. Imaging 33 1083-92, Liu et al 2013 SPIE Medical Imaging (International Society for Optics and Photonics) p 86701G, Moradi et al 2012 J. Magn. Reson. Imaging 35 1403-13, Niaf et al 2014 IEEE Trans. Image Process. 23 979-91, Niaf et al 2012 Phys. Med. Biol. 57 3833, Peng et al 2013a SPIE Medical Imaging (International Society for Optics and Photonics) p 86701H, Peng et al 2013b Radiology 267 787-96, Wang et al 2014 BioMed. Res. Int. 2014). This paper presents an automated method based on multimodal convolutional neural networks (CNNs) for two PCA diagnostic tasks: (1) distinguishing between cancerous and noncancerous tissues and (2) distinguishing between clinically significant (CS) and indolent PCA. Specifically, our multimodal CNNs effectively fuse apparent diffusion coefficients (ADCs) and T2-weighted MP-MRI images (T2WIs). To effectively fuse ADCs and T2WIs we design a new similarity loss function to enforce consistent features being extracted from both ADCs and T2WIs. The similarity loss is combined with the conventional classification loss functions and integrated into the back-propagation procedure of CNN training. The similarity loss enables better fusion results than existing methods as the feature learning processes of both modalities are mutually guided, jointly facilitating CNN to 'see' the true visual patterns of PCA. The classification results of multimodal CNNs are further combined with the results based on handcrafted features using a support vector machine classifier. To achieve a satisfactory accuracy for clinical use, we comprehensively investigate three critical factors which could greatly affect the performance of our multimodal CNNs but have not been carefully studied previously. (1) Given limited training data, how can these be augmented in sufficient numbers and variety for fine-tuning deep CNN networks for PCA diagnosis? (2) How can multimodal MP-MRI information be effectively combined in CNNs? (3) What is the impact of different CNN architectures on the accuracy of PCA diagnosis? Experimental results on extensive clinical data from 364 patients with a total of 463 PCA lesions and 450 identified noncancerous image patches demonstrate that our system can achieve a sensitivity of 89.85% and a specificity of 95.83% for distinguishing cancer from noncancerous tissues and a sensitivity of 100% and a specificity of 76.92% for distinguishing indolent PCA from CS PCA. This result is significantly superior to the state-of-the-art method relying on handcrafted features. © 2017 Institute of Physics and Engineering in Medicine.","convolutional neural networks; data augmentation; multi-parametric MRI; multimodal fusion; prostate cancer diagnosis","Aged; Aged, 80 and over; Algorithms; Automation; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Neural Networks (Computer); Prostatic Hyperplasia; Prostatic Neoplasms; Support Vector Machine; Aluminum; Automation; Backpropagation; Convolution; Diagnosis; Diseases; Histology; Image processing; Magnetic levitation vehicles; Medical imaging; Neural networks; Optical data processing; Surface diffusion; Tissue; Urology; Apparent diffusion coefficient; Classification results; Convolutional neural network; Data augmentation; Multi-modal fusion; Prostate cancers; State-of-the-art methods; Support vector machine classifiers; aged; algorithm; artificial neural network; automation; computer assisted diagnosis; diagnostic imaging; human; male; middle aged; nuclear magnetic resonance imaging; procedures; prostate hypertrophy; prostate tumor; support vector machine; very elderly; Magnetic resonance imaging","Institute of Physics Publishing","00319155","","PHMBA","28582269","Article","Scopus","2-s2.0-85026780215"
"Nagaraj S.B.; Biswal S.; Boyle E.J.; Zhou D.W.; McClain L.M.; Bajwa E.K.; Quraishi S.A.; Akeju O.; Barbieri R.; Purdon P.L.; Brandon Westover M.","Nagaraj, Sunil B. (57038365500); Biswal, Siddharth (57038270500); Boyle, Emily J. (57189599348); Zhou, David W. (56844149100); McClain, Lauren M. (56661968400); Bajwa, Ednan K. (8743453200); Quraishi, Sadeq A. (6603840182); Akeju, Oluwaseun (57196402615); Barbieri, Riccardo (35483096800); Purdon, Patrick L. (57207551612); Brandon Westover, M. (55384180400)","57038365500; 57038270500; 57189599348; 56844149100; 56661968400; 8743453200; 6603840182; 57196402615; 35483096800; 57207551612; 55384180400","Patient-Specific Classification of ICU Sedation Levels from Heart Rate Variability","2017","Critical Care Medicine","25","10.1097/CCM.0000000000002364","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018688966&doi=10.1097%2fCCM.0000000000002364&partnerID=40&md5=03db6fc9bf4708e93ccd6b6e91f1dbab","Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Department of Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Department of Anesthesia, Critical Care and Pain Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Department of Electronics, Informatics and Bioengineering, Politecnico di Milano, Milan, Italy","Nagaraj S.B., Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Biswal S., Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Boyle E.J., Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Zhou D.W., Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; McClain L.M., Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Bajwa E.K., Department of Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Quraishi S.A., Department of Anesthesia, Critical Care and Pain Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Akeju O., Department of Anesthesia, Critical Care and Pain Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Barbieri R., Department of Anesthesia, Critical Care and Pain Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States, Department of Electronics, Informatics and Bioengineering, Politecnico di Milano, Milan, Italy; Purdon P.L., Department of Anesthesia, Critical Care and Pain Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Brandon Westover M., Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States","Objective: To develop a personalizable algorithm to discriminate between sedation levels in ICU patients based on heart rate variability. Design: Multicenter, pilot study. Setting: Several ICUs at Massachusetts General Hospital, Boston, MA. Patients: We gathered 21,912 hours of routine electrocardiogram recordings from a heterogenous group of 70 adult ICU patients. All patients included in the study were mechanically ventilated and were receiving sedatives. Measurements and Main Results: As ""ground truth"" for developing our method, we used Richmond Agitation Sedation Scale scores grouped into four levels denoted ""comatose"" (-5), ""deeply sedated"" (-4 to-3), ""lightly sedated"" (-2 to 0), and ""agitated"" (+1 to +4). We trained a support vector machine learning algorithm to calculate the probability of each sedation level from heart rate variability measures derived from the electrocardiogram. To estimate algorithm performance, we calculated leave-one-subject out cross-validated accuracy. The patient-independent version of the proposed system discriminated between the four sedation levels with an overall accuracy of 59%. Upon personalizing the system supplementing the training data with patient-specific calibration data, consisting of an individual's labeled heart rate variability epochs from the preceding 24 hours, accuracy improved to 67%. The personalized system discriminated between light-and deep-sedation states with an average accuracy of 75%. Conclusions: With further refinement, the methodology reported herein could lead to a fully automated system for depth of sedation monitoring. By enabling monitoring to be continuous, such technology may help clinical staff to monitor sedation levels more effectively and to reduce complications related to over-and under sedation. © 2017 by the Society of Critical Care Medicine and Wolters Kluwer Health, Inc. All Rights Reserved.","heart rate variability; intensive care; Richmond Agitation Sedation Scale; sedation monitoring; support vector machine","Aged; Algorithms; Anesthesia; Boston; Electrocardiography; Female; Heart Rate; Humans; Intensive Care Units; Male; Middle Aged; Pilot Projects; Respiration, Artificial; Support Vector Machine; sedative agent; accuracy; adult; aged; algorithm; Article; artificial ventilation; clinical classification; electrocardiogram; female; heart rate variability; human; intensive care unit; learning algorithm; major clinical study; male; multicenter study; pilot study; priority journal; Richmond Agitation Sedation Scale; sedation; training; ventilated patient; anesthesia; clinical trial; electrocardiography; heart rate; intensive care unit; Massachusetts; middle aged; physiology; procedures; support vector machine","Lippincott Williams and Wilkins","00903493","","CCMDC","28441231","Article","Scopus","2-s2.0-85018688966"
"Lee S.-W.; Lee C.-Y.; Kwak D.-H.; Ha J.-W.; Kim J.; Zhang B.-T.","Lee, Sang-Woo (56025161100); Lee, Chung-Yeon (57229998900); Kwak, Dong-Hyun (57210132688); Ha, Jung-Woo (55430349200); Kim, Jeonghee (57188875346); Zhang, Byoung-Tak (55765845700)","56025161100; 57229998900; 57210132688; 55430349200; 57188875346; 55765845700","Dual-memory neural networks for modeling cognitive activities of humans via wearable sensors","2017","Neural Networks","7","10.1016/j.neunet.2017.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014999216&doi=10.1016%2fj.neunet.2017.02.008&partnerID=40&md5=acb685c75949ec8f572f226449fca682","School of Computer Science and Engineering, Seoul National University, Seoul, 08826, South Korea; Interdisciplinary Program in Neuroscience, Seoul National University, Seoul, 08826, South Korea; NAVER LABS, NAVER Corp., Bundang, 13561, South Korea; Surromind Robotics, 1 Gwanak-ro Gwanak-gu, Seoul, 08826, South Korea","Lee S.-W., School of Computer Science and Engineering, Seoul National University, Seoul, 08826, South Korea; Lee C.-Y., School of Computer Science and Engineering, Seoul National University, Seoul, 08826, South Korea; Kwak D.-H., Interdisciplinary Program in Neuroscience, Seoul National University, Seoul, 08826, South Korea; Ha J.-W., NAVER LABS, NAVER Corp., Bundang, 13561, South Korea; Kim J., NAVER LABS, NAVER Corp., Bundang, 13561, South Korea; Zhang B.-T., School of Computer Science and Engineering, Seoul National University, Seoul, 08826, South Korea, Interdisciplinary Program in Neuroscience, Seoul National University, Seoul, 08826, South Korea, Surromind Robotics, 1 Gwanak-ro Gwanak-gu, Seoul, 08826, South Korea","Wearable devices, such as smart glasses and watches, allow for continuous recording of everyday life in a real world over an extended period of time or lifelong. This possibility helps better understand the cognitive behavior of humans in real life as well as build human-aware intelligent agents for practical purposes. However, modeling the human cognitive activity from wearable-sensor data stream is challenging because learning new information often results in loss of previously acquired information, causing a problem known as catastrophic forgetting. Here we propose a deep-learning neural network architecture that resolves the catastrophic forgetting problem. Based on the neurocognitive theory of the complementary learning systems of the neocortex and hippocampus, we introduce a dual memory architecture (DMA) that, on one hand, slowly acquires the structured knowledge representations and, on the other hand, rapidly learns the specifics of individual experiences. The DMA system learns continuously through incremental feature adaptation and weight transfer. We evaluate the performance on two real-life datasets, the CIFAR-10 image-stream dataset and the 46-day Lifelog dataset collected from Google Glass, showing that the proposed model outperforms other online learning methods. © 2017 Elsevier Ltd","Complementary learning systems; Deep neural networks; Dual memory architecture; Hypernetworks; Lifelog dataset; Online learning","Brain; Cognition; Humans; Microcomputers; Models, Neurological; Neural Networks (Computer); Deep learning; Deep neural networks; E-learning; Glass; Intelligent agents; Knowledge representation; Learning systems; Memory architecture; Network architecture; Online systems; Wearable technology; Catastrophic forgetting; Catastrophic forgetting problem; Complementary learning; Hypernetworks; Learning neural networks; Life log; On-line learning methods; Online learning; Article; artificial neural network; cognition; controlled study; deep neural network; dual memory neural network; hippocampus; intermethod comparison; kernel method; learning; machine learning; mathematical model; neocortex; priority journal; sensor; biological model; brain; human; microcomputer; physiology; Wearable sensors","Elsevier Ltd","08936080","","NNETE","28318904","Article","Scopus","2-s2.0-85014999216"
"Shen D.; Wu G.; Suk H.-I.","Shen, Dinggang (7401738392); Wu, Guorong (13905214600); Suk, Heung-Il (56332955800)","7401738392; 13905214600; 56332955800","Deep Learning in Medical Image Analysis","2017","Annual Review of Biomedical Engineering","2971","10.1146/annurev-bioeng-071516-044442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021145223&doi=10.1146%2fannurev-bioeng-071516-044442&partnerID=40&md5=a670ff68ec3b922362937e271e5df6fc","Department of Radiology, University of North Carolina, Chapel Hill, 27599, NC, United States; Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, South Korea","Shen D., Department of Radiology, University of North Carolina, Chapel Hill, 27599, NC, United States, Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, South Korea; Wu G., Department of Radiology, University of North Carolina, Chapel Hill, 27599, NC, United States; Suk H.-I., Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, South Korea","This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement. © 2017 by Annual Reviews. All rights reserved.","Deep learning; Medical image analysis; Unsupervised feature learning","Algorithms; Diagnostic Imaging; Image Enhancement; Image Interpretation, Computer-Assisted; Neural Networks (Computer); Pattern Recognition, Automated; Unsupervised Machine Learning; Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Diagnosis; Education; Image analysis; Image segmentation; Learning systems; Medical applications; Medical imaging; Cellular structure; Computer-assisted analysis; Disease diagnosis; Domain-specific knowledge; Hierarchical features; Learning methods; Tissue segmentation; Unsupervised feature learning; anatomical concepts; Article; artificial neural network; computer assisted diagnosis; diagnostic imaging; image analysis; image segmentation; learning; prognosis; algorithm; artificial neural network; automated pattern recognition; diagnostic imaging; image enhancement; procedures; unsupervised machine learning; Deep learning","Annual Reviews Inc.","15239829","","ARBEF","28301734","Article","Scopus","2-s2.0-85021145223"
"Mazo C.; Alegre E.; Trujillo M.","Mazo, Claudia (55348155300); Alegre, Enrique (55901820900); Trujillo, Maria (23393938300)","55348155300; 55901820900; 23393938300","Classification of cardiovascular tissues using LBP based descriptors and a cascade SVM","2017","Computer Methods and Programs in Biomedicine","27","10.1016/j.cmpb.2017.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020917949&doi=10.1016%2fj.cmpb.2017.06.003&partnerID=40&md5=7471fc15b34ffc9b6a00b640385890e9","University of Valle, Computer and Systems Engineering School, Cali, Colombia; University of León, Industrial and Informatics Engineering School, León, Spain","Mazo C., University of Valle, Computer and Systems Engineering School, Cali, Colombia; Alegre E., University of León, Industrial and Informatics Engineering School, León, Spain; Trujillo M., University of Valle, Computer and Systems Engineering School, Cali, Colombia","Background and Objective: Histological images have characteristics, such as texture, shape, colour and spatial structure, that permit the differentiation of each fundamental tissue and organ. Texture is one of the most discriminative features. The automatic classification of tissues and organs based on histology images is an open problem, due to the lack of automatic solutions when treating tissues without pathologies. Method: In this paper, we demonstrate that it is possible to automatically classify cardiovascular tissues using texture information and Support Vector Machines (SVM). Additionally, we realised that it is feasible to recognise several cardiovascular organs following the same process. The texture of histological images was described using Local Binary Patterns (LBP), LBP Rotation Invariant (LBPri), Haralick features and different concatenations between them, representing in this way its content. Using a SVM with linear kernel, we selected the more appropriate descriptor that, for this problem, was a concatenation of LBP and LBPri. Due to the small number of the images available, we could not follow an approach based on deep learning, but we selected the classifier who yielded the higher performance by comparing SVM with Random Forest and Linear Discriminant Analysis. Once SVM was selected as the classifier with a higher area under the curve that represents both higher recall and precision, we tuned it evaluating different kernels, finding that a linear SVM allowed us to accurately separate four classes of tissues: (i) cardiac muscle of the heart, (ii) smooth muscle of the muscular artery, (iii) loose connective tissue, and (iv) smooth muscle of the large vein and the elastic artery. The experimental validation was conducted using 3000 blocks of 100 × 100 sized pixels, with 600 blocks per class and the classification was assessed using a 10-fold cross-validation. Results: using LBP as the descriptor, concatenated with LBPri and a SVM with linear kernel, the main four classes of tissues were recognised with an AUC higher than 0.98. A polynomial kernel was then used to separate the elastic artery and vein, yielding an AUC in both cases superior to 0.98. Conclusion: Following the proposed approach, it is possible to separate with very high precision (AUC greater than 0.98) the fundamental tissues of the cardiovascular system along with some organs, such as the heart, arteries and veins. © 2017 Elsevier B.V.","Automatic classification; Fundamental tissues; Histology images; Image processing; Organs of the cardiovascular system","Algorithms; Arteries; Connective Tissue; Discriminant Analysis; Humans; Muscle, Smooth; Myocardium; Support Vector Machine; Veins; Cardiovascular system; Classification (of information); Collagen; Decision trees; Deep learning; Discriminant analysis; Histology; Image processing; Image texture; Muscle; Musculoskeletal system; Separation; Support vector machines; 10-fold cross-validation; Automatic classification; Cardiovascular tissues; Discriminative features; Experimental validations; Histology images; Linear discriminant analysis; Loose connective tissues; area under the curve; artery; cardiac muscle; cardiovascular tissue; case report; discriminant analysis; histology; human; human tissue; image processing; learning; organ; random forest; recall; rotation; smooth muscle; support vector machine; validation process; vein; algorithm; artery; cardiac muscle; connective tissue; smooth muscle; Tissue","Elsevier Ireland Ltd","01692607","","CMPBE","28734525","Article","Scopus","2-s2.0-85020917949"
"Wen M.; Zhang Z.; Niu S.; Sha H.; Yang R.; Yun Y.; Lu H.","Wen, Ming (56113633700); Zhang, Zhimin (56125415400); Niu, Shaoyu (57203821610); Sha, Haozhi (57193849507); Yang, Ruihan (57191286879); Yun, Yonghuan (55521299900); Lu, Hongmei (8389639500)","56113633700; 56125415400; 57203821610; 57193849507; 57191286879; 55521299900; 8389639500","Deep-Learning-Based Drug-Target Interaction Prediction","2017","Journal of Proteome Research","370","10.1021/acs.jproteome.6b00618","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017108822&doi=10.1021%2facs.jproteome.6b00618&partnerID=40&md5=310e598e2d98f05d51c3e8d8de7ec5b5","College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; Institute of Environment and Plant Protection, Chinese Academy of Tropical Agricultural Sciences, Haikou, 571101, China","Wen M., College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; Zhang Z., College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; Niu S., College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; Sha H., College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; Yang R., College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China; Yun Y., Institute of Environment and Plant Protection, Chinese Academy of Tropical Agricultural Sciences, Haikou, 571101, China; Lu H., College of Chemistry and Chemical Engineering, Central South University, Changsha, 410083, China","Identifying interactions between known drugs and targets is a major challenge in drug repositioning. In silico prediction of drug-target interaction (DTI) can speed up the expensive and time-consuming experimental work by providing the most potent DTIs. In silico prediction of DTI can also provide insights about the potential drug-drug interaction and promote the exploration of drug side effects. Traditionally, the performance of DTI prediction depends heavily on the descriptors used to represent the drugs and the target proteins. In this paper, to accurately predict new DTIs between approved drugs and targets without separating the targets into different classes, we developed a deep-learning-based algorithmic framework named DeepDTIs. It first abstracts representations from raw input descriptors using unsupervised pretraining and then applies known label pairs of interaction to build a classification model. Compared with other methods, it is found that DeepDTIs reaches or outperforms other state-of-the-art methods. The DeepDTIs can be further used to predict whether a new drug targets to some existing targets or whether a new target interacts with some existing drugs. © 2017 American Chemical Society.","deep learning; deep-delief network; drug-target interaction prediction; feature extraction; semisupervised learning","Algorithms; Amino Acid Sequence; Computer Simulation; Databases, Pharmaceutical; Drug Discovery; Drug Interactions; Humans; Models, Theoretical; Molecular Targeted Therapy; Proteins; new drug; protein; algorithm; amino acid composition; amino acid sequence; Article; computer model; decision tree; drug development; drug interaction; drug protein binding; drug repositioning; drug structure; machine learning; partition coefficient; prediction; priority journal; quantitative structure activity relation; random forest; chemistry; computer simulation; drug database; drug interaction; genetics; human; molecularly targeted therapy; theoretical model","American Chemical Society","15353893","","JPROB","28264154","Article","Scopus","2-s2.0-85017108822"
"Wahab N.; Khan A.; Lee Y.S.","Wahab, Noorul (57189507980); Khan, Asifullah (8510710900); Lee, Yeon Soo (57207015154)","57189507980; 8510710900; 57207015154","Two-phase deep convolutional neural network for reducing class skewness in histopathological images based breast cancer detection","2017","Computers in Biology and Medicine","133","10.1016/j.compbiomed.2017.04.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018982142&doi=10.1016%2fj.compbiomed.2017.04.012&partnerID=40&md5=da02bb7bcda199ef2c31ace60f95ae81","Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences Islamabad, Pakistan; Department of Biomedical Engineering, College of Medical Science, Catholic University of Daegu, Gyoungsangbuk-do, Zip 38430, South Korea","Wahab N., Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences Islamabad, Pakistan; Khan A., Department of Computer and Information Sciences, Pakistan Institute of Engineering and Applied Sciences Islamabad, Pakistan; Lee Y.S., Department of Biomedical Engineering, College of Medical Science, Catholic University of Daegu, Gyoungsangbuk-do, Zip 38430, South Korea","Different types of breast cancer are affecting lives of women across the world. Common types include Ductal carcinoma in situ (DCIS), Invasive ductal carcinoma (IDC), Tubular carcinoma, Medullary carcinoma, and Invasive lobular carcinoma (ILC). While detecting cancer, one important factor is mitotic count – showing how rapidly the cells are dividing. But the class imbalance problem, due to the small number of mitotic nuclei in comparison to the overwhelming number of non-mitotic nuclei, affects the performance of classification models. This work presents a two-phase model to mitigate the class biasness issue while classifying mitotic and non-mitotic nuclei in breast cancer histopathology images through a deep convolutional neural network (CNN). First, nuclei are segmented out using blue ratio and global binary thresholding. In Phase-1 a CNN is then trained on the segmented out 80×80 pixel patches based on a standard dataset. Hard non-mitotic examples are identified and augmented; mitotic examples are oversampled by rotation and flipping; whereas non-mitotic examples are undersampled by blue ratio histogram based k-means clustering. Based on this information from Phase-1, the dataset is modified for Phase-2 in order to reduce the effects of class imbalance. The proposed CNN architecture and data balancing technique yielded an F-measure of 0.79, and outperformed all the methods relying on specific handcrafted features, as well as those using a combination of handcrafted and CNN-generated features. © 2017 Elsevier Ltd","Breast cancer; Class imbalance; Convolutional neural networks; Deep learning; Histopathology; Mitosis count","Algorithms; Breast Neoplasms; Cell Nucleus; Female; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Mitosis; Neural Networks (Computer); ROC Curve; Convolution; Deep learning; Diseases; Medical imaging; Neural networks; Statistical methods; Two term control systems; Breast Cancer; Class imbalance; Convolutional neural network; Histopathology; Mitosis count; anaphase; Article; breast cancer; cancer diagnosis; convolutional neural network; histogram; histopathology; human; human cell; image segmentation; machine learning; metaphase; mitosis; priority journal; prophase; telophase; algorithm; artificial neural network; breast tumor; cell nucleus; computer assisted diagnosis; cytochemistry; diagnostic imaging; female; machine learning; pathology; procedures; receiver operating characteristic; Deep neural networks","Elsevier Ltd","00104825","","CBMDA","28477446","Article","Scopus","2-s2.0-85018982142"
"Mohr D.C.; Zhang M.; Schueller S.M.","Mohr, David C. (55614489700); Zhang, Mi (55799025900); Schueller, Stephen M. (35491626800)","55614489700; 55799025900; 35491626800","Personal Sensing: Understanding Mental Health Using Ubiquitous Sensors and Machine Learning","2017","Annual Review of Clinical Psychology","426","10.1146/annurev-clinpsy-032816-044949","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019136128&doi=10.1146%2fannurev-clinpsy-032816-044949&partnerID=40&md5=6c14caabec473b64c2b5ccb382e1076d","Center for Behavioral Intervention Technologies, Department of Preventive Medicine, Northwestern University, Chicago, 60611, IL, United States; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824, MI, United States","Mohr D.C., Center for Behavioral Intervention Technologies, Department of Preventive Medicine, Northwestern University, Chicago, 60611, IL, United States; Zhang M., Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824, MI, United States; Schueller S.M., Center for Behavioral Intervention Technologies, Department of Preventive Medicine, Northwestern University, Chicago, 60611, IL, United States","Sensors in everyday devices, such as our phones, wearables, and computers, leave a stream of digital traces. Personal sensing refers to collecting and analyzing data from sensors embedded in the context of daily life with the aim of identifying human behaviors, thoughts, feelings, and traits. This article provides a critical review of personal sensing research related to mental health, focused principally on smartphones, but also including studies of wearables, social media, and computers. We provide a layered, hierarchical model for translating raw sensor data into markers of behaviors and states related to mental health. Also discussed are research methods as well as challenges, including privacy and problems of dimensionality. Although personal sensing is still in its infancy, it holds great promise as a method for conducting mental health research and as a clinical tool for monitoring at-risk populations and providing the foundation for the next generation of mobile health (or mHealth) interventions. © 2017 by Annual Reviews. All rights reserved.","Machine learning; Mental health; MHealth; Pervasive health; Sensors; Wearables","Humans; Machine Learning; Mental Disorders; Neurophysiological Monitoring; Telemedicine; biological marker; active machine learning; Article; behavior; behavior therapy; bipolar disorder; computer; data analysis; data extraction; data mining; deep machine learning; depression; epidemiological data; ethics; expiration date; general device; human; information processing; integration; knowledge; machine learning; measurement accuracy; medical technology; mental health; mental health care; mobile phone; mood; nonhuman; privacy; quality control; reproducibility; schizophrenia; semisupervised machine learning; sensor; sleep; social environment; social media; stress; supervised machine learning; uncertainty; unsupervised machine learning; wearable device; mental disease; neurophysiological monitoring; telemedicine","Annual Reviews Inc.","15485943","","","28375728","Article","Scopus","2-s2.0-85019136128"
"Shu X.; Cai Y.; Yang L.; Zhang L.; Tang J.","Shu, Xiangbo (57072538400); Cai, Yunfei (26636882500); Yang, Liu (57198988467); Zhang, Liyan (35301390900); Tang, Jinhui (56364850900)","57072538400; 26636882500; 57198988467; 35301390900; 56364850900","Computational face reader based on facial attribute estimation","2017","Neurocomputing","12","10.1016/j.neucom.2016.09.110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008660748&doi=10.1016%2fj.neucom.2016.09.110&partnerID=40&md5=13aacf386d02c6197a7c84774108c73a","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China; West China Hospital of Stomatology, Sichuan University, Chengdu, 610041, China","Shu X., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China; Cai Y., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China; Yang L., West China Hospital of Stomatology, Sichuan University, Chengdu, 610041, China; Zhang L., College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China; Tang J., School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China","Chinese face reading has demonstrated the often satisfying capabilities to tell the characteristics (mostly exaggerated as fortune) of a person by reading his/her face, i.e. understanding the fine-grained facial attributes (e.g., length of nose, single/double-fold eyelid, density of eyebrows, etc.). Thus, a smart face reading system should estimate the fine-grained facial attributes well. Therefore, In this paper, we first study the fine-grained facial attribute estimation problem and propose a novel deep convolutional network equipped with a new facial region pooling layer (called FRP-net), to accurately estimate the fine-grained facial attributes. To capture the characteristics of fine-grained facial attributes, the embedded FRP layer implements the pooling operation on the searched facial region windows (locates the region of each facial attribute) instead of the commonly-used sliding windows. Further, we push the proposed fine-grained facial attribute estimation method into the face reading problem and present a computational face reader system to automatically infer the characteristics of a person based on his/her face. For example, it can estimate the attractive and easy-going characteristics of a Chinese person from his/her big eyes according to the Chinese anthroposcopy literature. The experimental results on facial attribute estimation demonstrate the superiority of the proposed FRP-net compared to the baselines, and the qualitative and quantitative evaluations on face reading validate the excellence of the presented face reader system. © 2017 Elsevier B.V.","Chinese anthroposcopy; Chinese face reading; Deep convolutional neural networks; Facial attribute estimation; Facial region pooling layer","Neural networks; Chinese anthroposcopy; Convolutional networks; Convolutional neural network; Estimation methods; Estimation problem; Face readings; Facial regions; Quantitative evaluation; analysis of variance; Article; artificial neural network; computational face reader; computer system; controlled study; deep boltzmann machine; deep convolutional neural network; fine grained facial attribute estimation problem; machine learning; mathematical analysis; measurement accuracy; natural language processing; qualitative analysis; quantitative analysis; Convolution","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85008660748"
"Mezgec S.; Seljak B.K.","Mezgec, Simon (57194651739); Seljak, Barbara Koroušić (55667062500)","57194651739; 55667062500","Nutrinet: A deep learning food and drink image recognition system for dietary assessment","2017","Nutrients","173","10.3390/nu9070657","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021448531&doi=10.3390%2fnu9070657&partnerID=40&md5=0d0c1d1e765bc241e353b6670a7cb9bd","Information and Communication Technologies, Jožef Stefan International Postgraduate School, Jamova Cesta 39, Ljubljana, 1000, Slovenia; Computer Systems Department, Jožef Stefan Institute, Jamova Cesta 39, Ljubljana, 1000, Slovenia","Mezgec S., Information and Communication Technologies, Jožef Stefan International Postgraduate School, Jamova Cesta 39, Ljubljana, 1000, Slovenia; Seljak B.K., Computer Systems Department, Jožef Stefan Institute, Jamova Cesta 39, Ljubljana, 1000, Slovenia","Automatic food image recognition systems are alleviating the process of food-intake estimation and dietary assessment. However, due to the nature of food images, their recognition is a particularly challenging task, which is why traditional approaches in the field have achieved a low classification accuracy. Deep neural networks have outperformed such solutions, and we present a novel approach to the problem of food and drink image detection and recognition that uses a newly-defined deep convolutional neural network architecture, called NutriNet. This architecture was tuned on a recognition dataset containing 225,953 512 × 512 pixel images of 520 different food and drink items from a broad spectrum of food groups, on which we achieved a classification accuracy of 86.72%, along with an accuracy of 94.47% on a detection dataset containing 130,517 images. We also performed a real-world test on a dataset of self-acquired images, combined with images from Parkinson’s disease patients, all taken using a smartphone camera, achieving a top-five accuracy of 55%, which is an encouraging result for real-world images. Additionally, we tested NutriNet on the University of Milano-Bicocca 2016 (UNIMIB2016) food image dataset, on which we improved upon the provided baseline recognition result. An online training component was implemented to continually fine-tune the food and drink recognition model on new images. The model is being used in practice as part of a mobile app for the dietary assessment of Parkinson’s disease patients. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Deep convolutional neural networks; Deep learning; Drink detection; Drink recognition; Food detection; Food recognition; NutriNet; Parkinson’s disease","Algorithms; Beverages; Computer Simulation; Food; Image Processing, Computer-Assisted; Internet; Machine Learning; Mobile Applications; Neural Networks (Computer); Nutrition Assessment; Smartphone; Article; energy drink; food; food intake; human; mobile application; nerve cell network; nutritional assessment; nutritional status; Parkinson disease; recognition; support vector machine; training; algorithm; artificial neural network; beverage; computer simulation; image processing; Internet; machine learning; smartphone","MDPI AG","20726643","","","28653995","Article","Scopus","2-s2.0-85021448531"
"Carneiro G.; Peng T.; Bayer C.; Navab N.","Carneiro, Gustavo (23003641100); Peng, Tingying (56245821000); Bayer, Christine (36927349800); Navab, Nassir (7003458998)","23003641100; 56245821000; 36927349800; 7003458998","Automatic Quantification of Tumour Hypoxia from Multi-Modal Microscopy Images Using Weakly-Supervised Learning Methods","2017","IEEE Transactions on Medical Imaging","4","10.1109/TMI.2017.2677479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028419410&doi=10.1109%2fTMI.2017.2677479&partnerID=40&md5=c048b649b82c80e7893a545531fe9b4a","Australian Centre for Visual Technologies, University of Adelaide, Adelaide, 5005, SA, Australia; Computer Aided Medical Procedures, Technische Universität München, Garching bei München, 85748, Germany; Department of Radiation Oncology, Technische Universität München, Garching bei München, 85748, Germany; Johns Hopkins University, Baltimore, 21218, MD, United States","Carneiro G., Australian Centre for Visual Technologies, University of Adelaide, Adelaide, 5005, SA, Australia; Peng T., Computer Aided Medical Procedures, Technische Universität München, Garching bei München, 85748, Germany; Bayer C., Department of Radiation Oncology, Technische Universität München, Garching bei München, 85748, Germany; Navab N., Computer Aided Medical Procedures, Technische Universität München, Garching bei München, 85748, Germany, Johns Hopkins University, Baltimore, 21218, MD, United States","In recently published clinical trial results, hypoxia-modified therapies have shown to provide more positive outcomes to cancer patients, compared with standard cancer treatments. The development and validation of these hypoxia-modified therapies depend on an effective way of measuring tumor hypoxia, but a standardized measurement is currently unavailable in clinical practice. Different types of manual measurements have been proposed in clinical research, but in this paper we focus on a recently published approach that quantifies the number and proportion of hypoxic regions using high resolution (immuno-)fluorescence (IF) and hematoxylin and eosin (HE) stained images of a histological specimen of a tumor. We introduce new machine learning-based methodologies to automate this measurement, where the main challenge is the fact that the clinical annotations available for training the proposed methodologies consist of the total number of normoxic, chronically hypoxic, and acutely hypoxic regions without any indication of their location in the image. Therefore, this represents a weakly-supervised structured output classification problem, where training is based on a high-order loss function formed by the norm of the difference between the manual and estimated annotations mentioned above. We propose four methodologies to solve this problem: 1) a naive method that uses a majority classifier applied on the nodes of a fixed grid placed over the input images; 2) a baseline method based on a structured output learning formulation that relies on a fixed grid placed over the input images; 3) an extension to this baseline based on a latent structured output learning formulation that uses a graph that is flexible in terms of the amount and positions of nodes; and 4) a pixel-wise labeling based on a fully-convolutional neural network. Using a data set of 89 weakly annotated pairs of IF and HE images from eight tumors, we show that the quantitative results of methods (3) and (4) above are equally competitive and superior to the naive (1) and baseline (2) methods. All proposed methodologies show high correlation values with respect to the clinical annotations. © 1982-2012 IEEE.","deep learning; high-order loss functions; Microscopy; structured output learning; weakly-supervised training","Humans; Microscopy; Neural Networks (Computer); Supervised Machine Learning; Tumor Hypoxia; Deep learning; Diseases; Learning systems; Microscopic examination; Neural networks; Automatic quantification; Convolutional neural network; Learning formulation; Loss functions; Standardized measurement; structured output learning; Weakly supervised learning; Weakly supervised trainings; artificial neural network; human; microscopy; supervised machine learning; tumor hypoxia; Tumors","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28278461","Article","Scopus","2-s2.0-85028419410"
"Angermueller C.; Lee H.J.; Reik W.; Stegle O.","Angermueller, Christof (56270539900); Lee, Heather J. (16316055200); Reik, Wolf (7007161076); Stegle, Oliver (57202754050)","56270539900; 16316055200; 7007161076; 57202754050","DeepCpG: Accurate prediction of single-cell DNA methylation states using deep learning","2017","Genome Biology","312","10.1186/s13059-017-1189-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018466550&doi=10.1186%2fs13059-017-1189-z&partnerID=40&md5=6e6343ee0e7cd819acb06850495a9c27","European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge, CB10 1SD, United Kingdom; Epigenetics Programme, Babraham Institute, Cambridge, United Kingdom; Wellcome Trust Sanger Institute, Wellcome Genome Campus, Hinxton, Cambridge, CB10 1SA, United Kingdom","Angermueller C., European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge, CB10 1SD, United Kingdom; Lee H.J., Epigenetics Programme, Babraham Institute, Cambridge, United Kingdom, Wellcome Trust Sanger Institute, Wellcome Genome Campus, Hinxton, Cambridge, CB10 1SA, United Kingdom; Reik W., Epigenetics Programme, Babraham Institute, Cambridge, United Kingdom, Wellcome Trust Sanger Institute, Wellcome Genome Campus, Hinxton, Cambridge, CB10 1SA, United Kingdom; Stegle O., European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge, CB10 1SD, United Kingdom","Recent technological advances have enabled DNA methylation to be assayed at single-cell resolution. However, current protocols are limited by incomplete CpG coverage and hence methods to predict missing methylation states are critical to enable genome-wide analyses. We report DeepCpG, a computational approach based on deep neural networks to predict methylation states in single cells. We evaluate DeepCpG on single-cell methylation data from five cell types generated using alternative sequencing protocols. DeepCpG yields substantially more accurate predictions than previous methods. Additionally, we show that the model parameters can be interpreted, thereby providing insights into how sequence composition affects methylation variability. © 2017 The Author(s).","Artificial neural network; Deep learning; DNA methylation; Epigenetics; Machine learning; Single-cell genomics","Article; artificial neural network; computer analysis; controlled study; CpG island; DNA methylation; DNA sequence; intermethod comparison; machine learning; mathematical model; mathematical parameters; measurement accuracy; prediction","BioMed Central Ltd.","14747596","","GNBLF","28395661","Article","Scopus","2-s2.0-85018466550"
"Kline T.L.; Korfiatis P.; Edwards M.E.; Blais J.D.; Czerwiec F.S.; Harris P.C.; King B.F.; Torres V.E.; Erickson B.J.","Kline, Timothy L. (26648884000); Korfiatis, Panagiotis (23397073600); Edwards, Marie E. (57188804797); Blais, Jaime D. (56723598500); Czerwiec, Frank S. (36741892900); Harris, Peter C. (57199412320); King, Bernard F. (7402688644); Torres, Vicente E. (55553766300); Erickson, Bradley J. (7201472755)","26648884000; 23397073600; 57188804797; 56723598500; 36741892900; 57199412320; 7402688644; 55553766300; 7201472755","Performance of an Artificial Multi-observer Deep Neural Network for Fully Automated Segmentation of Polycystic Kidneys","2017","Journal of Digital Imaging","108","10.1007/s10278-017-9978-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019772759&doi=10.1007%2fs10278-017-9978-1&partnerID=40&md5=55e7ea9ab409afdd7994c3a576668fb4","Department of Radiology, Mayo Clinic College of Medicine, 200 First St SW, Rochester, 55905, MN, United States; Division of Nephrology and Hypertension, Mayo Clinic College of Medicine, Rochester, MN, United States; Otsuka Pharmaceutical Development & Commercialization Inc., Rockville, MD, United States","Kline T.L., Department of Radiology, Mayo Clinic College of Medicine, 200 First St SW, Rochester, 55905, MN, United States; Korfiatis P., Department of Radiology, Mayo Clinic College of Medicine, 200 First St SW, Rochester, 55905, MN, United States; Edwards M.E., Division of Nephrology and Hypertension, Mayo Clinic College of Medicine, Rochester, MN, United States; Blais J.D., Otsuka Pharmaceutical Development & Commercialization Inc., Rockville, MD, United States; Czerwiec F.S., Otsuka Pharmaceutical Development & Commercialization Inc., Rockville, MD, United States; Harris P.C., Division of Nephrology and Hypertension, Mayo Clinic College of Medicine, Rochester, MN, United States; King B.F., Department of Radiology, Mayo Clinic College of Medicine, 200 First St SW, Rochester, 55905, MN, United States; Torres V.E., Division of Nephrology and Hypertension, Mayo Clinic College of Medicine, Rochester, MN, United States; Erickson B.J., Department of Radiology, Mayo Clinic College of Medicine, 200 First St SW, Rochester, 55905, MN, United States","Deep learning techniques are being rapidly applied to medical imaging tasks—from organ and lesion segmentation to tissue and tumor classification. These techniques are becoming the leading algorithmic approaches to solve inherently difficult image processing tasks. Currently, the most critical requirement for successful implementation lies in the need for relatively large datasets that can be used for training the deep learning networks. Based on our initial studies of MR imaging examinations of the kidneys of patients affected by polycystic kidney disease (PKD), we have generated a unique database of imaging data and corresponding reference standard segmentations of polycystic kidneys. In the study of PKD, segmentation of the kidneys is needed in order to measure total kidney volume (TKV). Automated methods to segment the kidneys and measure TKV are needed to increase measurement throughput and alleviate the inherent variability of human-derived measurements. We hypothesize that deep learning techniques can be leveraged to perform fast, accurate, reproducible, and fully automated segmentation of polycystic kidneys. Here, we describe a fully automated approach for segmenting PKD kidneys within MR images that simulates a multi-observer approach in order to create an accurate and robust method for the task of segmentation and computation of TKV for PKD patients. A total of 2000 cases were used for training and validation, and 400 cases were used for testing. The multi-observer ensemble method had mean ± SD percent volume difference of 0.68 ± 2.2% compared with the reference standard segmentations. The complete framework performs fully automated segmentation at a level comparable with interobserver variability and could be considered as a replacement for the task of segmentation of PKD kidneys by a human. © 2017, The Author(s).","Autosomal dominant polycystic kidney disease; Deep learning; Magnetic resonance imaging; Planimetry; Segmentation; Total kidney volume","Datasets as Topic; Humans; Image Processing, Computer-Assisted; Kidney; Machine Learning; Observer Variation; Polycystic Kidney Diseases; Automation; Deep learning; Deep neural networks; Image processing; Learning algorithms; Learning systems; Magnetic levitation vehicles; Magnetic resonance imaging; Medical imaging; Algorithmic approach; Inherent variability; Interobserver variability; Lesion segmentations; Planimetry; Polycystic kidney disease; Total kidney volume; Tumor classification; diagnostic imaging; human; image processing; information processing; kidney; kidney polycystic disease; machine learning; observer variation; Image segmentation","Springer New York LLC","08971889","","JDIME","28550374","Article","Scopus","2-s2.0-85019772759"
"Perez Velazquez J.L.","Perez Velazquez, Jose L. (7004741797)","7004741797","Dynamiceuticals: The next stage in personalized medicine","2017","Frontiers in Neuroscience","4","10.3389/fnins.2017.00329","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020725545&doi=10.3389%2ffnins.2017.00329&partnerID=40&md5=686a8e9d73daa2dda615fee6fc425bdb","Neuroscience and Mental Health Program, Division of Neurology, Department of Paediatrics, Institute of Medical Science, The Hospital for Sick Children, University of Toronto, Toronto, ON, Canada","Perez Velazquez J.L., Neuroscience and Mental Health Program, Division of Neurology, Department of Paediatrics, Institute of Medical Science, The Hospital for Sick Children, University of Toronto, Toronto, ON, Canada","The surge in the interest in personalized medicine necessitates a corresponding rational approach for implementing such individualized therapies. Dynamiceuticals represents a natural extension of the Pharmaceutical and Electroceutical fields, where the precise determination of the dynamical regimes of the pathophysiology will guide to devise therapies that ameliorate the pathology in a well-controlled manner, thus being precisely tailored toward the implementation of individualized medicine. This approach foretells to lessen side-effects and achieve superior efficacy as compared with current trial-and-error or open-loop strategies. But does the current state of knowledge and technology allow this scheme to offer what it claims?. © 2017 Perez Velazquez.","Deep brain stimulation; Dynamical systems; Epilepsy; Machine learning; Neuromodulation; Personalized medicine; Translational medicine","Article; brain function; drug efficacy; drug industry; dynamiceutical; electrotherapy; heart function; human; intermethod comparison; intersectoral collaboration; learning algorithm; machine learning; medical decision making; nerve stimulation; neurophysiology; nonhuman; pathophysiology; personalized medicine","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85020725545"
"Kim S.; Yu Z.; Lee M.","Kim, Sangwook (57169169400); Yu, Zhibin (36999020600); Lee, Minho (57191730119)","57169169400; 36999020600; 57191730119","Understanding human intention by connecting perception and action learning in artificial agents","2017","Neural Networks","11","10.1016/j.neunet.2017.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015022239&doi=10.1016%2fj.neunet.2017.01.009&partnerID=40&md5=d6191c64b0fe2bc79bcd95e1313c0068","School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; College of Information Science and Engineering, Ocean University of China (OUC), 238 Songling Road Qingdao, China","Kim S., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; Yu Z., College of Information Science and Engineering, Ocean University of China (OUC), 238 Songling Road Qingdao, China; Lee M., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea","To develop an advanced human–robot interaction system, it is important to first understand how human beings learn to perceive, think, and act in an ever-changing world. In this paper, we propose an intention understanding system that uses an Object Augmented-Supervised Multiple Timescale Recurrent Neural Network (OA-SMTRNN) and demonstrate the effects of perception–action connected learning in an artificial agent, which is inspired by psychological and neurological phenomena in humans. We believe that action and perception are not isolated processes in human mental development, and argue that these psychological and neurological interactions can be replicated in a human–machine scenario. The proposed OA-SMTRNN consists of perception and action modules and their connection, which are constructed of supervised multiple timescale recurrent neural networks and the deep auto-encoder, respectively, and connects their perception and action for understanding human intention. Our experimental results show the effects of perception–action connected learning, and demonstrate that robots can understand human intention with OA-SMTRNN through perception–action connected learning. © 2017 Elsevier Ltd","Affordance; Cognitive agent; Human–robot interaction; Intention understanding; Object-Augmented Multiple Timescale Recurrent Neural Network; Perception-action connected learning","Biometric Identification; Humans; Intention; Movement; Neural Networks (Computer); Posture; Support Vector Machine; Deep neural networks; Man machine systems; Neurology; Recurrent neural networks; Robots; Affordances; Cognitive agents; Intention understanding; Multiple timescale recurrent neural networks; Perception-action; Article; artificial intelligence; artificial neural network; behavior; cognition; computer model; human; human computer interaction; measurement accuracy; mental development; mental task; Object Augmented Supervised Multiple Timescale Recurrent Neural Network; perception; priority journal; recognition; artificial neural network; biometry; body position; movement (physiology); procedures; support vector machine; Human robot interaction","Elsevier Ltd","08936080","","NNETE","28318903","Article","Scopus","2-s2.0-85015022239"
"Whiteside D.; Reid M.","Whiteside, David (55174110000); Reid, Machar (15136884800)","55174110000; 15136884800","Spatial characteristics of professional tennis serves with implications for serving aces: A machine learning approach","2017","Journal of Sports Sciences","38","10.1080/02640414.2016.1183805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969287169&doi=10.1080%2f02640414.2016.1183805&partnerID=40&md5=b9e38878b6cc223882020a1e25bf3d61","Game Insight Group, Tennis Australia, Melbourne, Australia; Institute of Sport, Exercise and Active Living, Victoria University, Melbourne, Australia; School of Sport Science, Exercise and Health, University of Western Australia, Crawley, Australia","Whiteside D., Game Insight Group, Tennis Australia, Melbourne, Australia, Institute of Sport, Exercise and Active Living, Victoria University, Melbourne, Australia; Reid M., Game Insight Group, Tennis Australia, Melbourne, Australia, School of Sport Science, Exercise and Health, University of Western Australia, Crawley, Australia","This study sought to determine the features of an ideal serve in men’s professional tennis. A total of 25,680 first serves executed by 151 male tennis players during Australian Open competition were classified as either aces or returned into play. Spatiotemporal (impact location, speed, projection angles, landing location and relative player locations) and contextual (score) features of each serve were extracted from Hawk-Eye data and used to construct a classification tree model (with decision rules) that predicted serve outcome. k-means clustering was applied to the landing locations to quantify optimal landing locations for aces. The classification tree revealed that (1) serve directionality, relative to the returner; (2) the ball’s landing proximity to the nearest service box line and (3) serve speed classified aces with an accuracy of 87.02%. Hitting aces appeared more contingent on accuracy than speed, with serves directed >5.88° from the returner and landing <15.27 cm from a service box line most indicative of an ace. k-means clustering revealed four distinct locations (≈0.73 m wide × 2.35 m deep) in the corners of the service box that corresponded to aces. These landing locations provide empirically derived target locations for players to adhere to during practice and competition. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","ace; biomechanics; Coaching; decision tree; k-means; rule induction","Athletic Performance; Australia; Biomechanical Phenomena; Cluster Analysis; Competitive Behavior; Humans; Machine Learning; Male; Motor Skills; Movement; Physical Education and Training; Spatial Analysis; Spatial Behavior; Task Performance and Analysis; Tennis; biomechanics; classification; competition; decision tree; human; machine learning; model; quantitative study; tennis; velocity; athletic performance; Australia; biomechanics; cluster analysis; competitive behavior; machine learning; male; motor performance; movement (physiology); physical education; spatial analysis; spatial behavior; task performance","Routledge","02640414","","JSSCE","27189847","Article","Scopus","2-s2.0-84969287169"
"Cang Z.; Wei G.","Cang, Zixuan (57195259931); Wei, Guowei (7402848203)","57195259931; 7402848203","TopologyNet: Topology based deep convolutional and multi-task neural networks for biomolecular property predictions","2017","PLoS Computational Biology","184","10.1371/journal.pcbi.1005690","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026627894&doi=10.1371%2fjournal.pcbi.1005690&partnerID=40&md5=1f1a6e584fc9e24605a1a4e3094be21b","Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States; Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, 48824, MI, United States; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824, MI, United States","Cang Z., Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States; Wei G., Department of Mathematics, Michigan State University, East Lansing, 48824, MI, United States, Department of Biochemistry and Molecular Biology, Michigan State University, East Lansing, 48824, MI, United States, Department of Electrical and Computer Engineering, Michigan State University, East Lansing, 48824, MI, United States","Although deep learning approaches have had tremendous success in image, video and audio processing, computer vision, and speech recognition, their applications to three-dimensional (3D) biomolecular structural data sets have been hindered by the geometric and biological complexity. To address this problem we introduce the element-specific persistent homology (ESPH) method. ESPH represents 3D complex geometry by one-dimensional (1D) topological invariants and retains important biological information via a multichannel image-like representation. This representation reveals hidden structure-function relationships in biomolecules. We further integrate ESPH and deep convolutional neural networks to construct a multichannel topological neural network (TopologyNet) for the predictions of protein-ligand binding affinities and protein stability changes upon mutation. To overcome the deep learning limitations from small and noisy training sets, we propose a multi-task multichannel topological convolutional neural network (MM-TCNN). We demonstrate that TopologyNet outperforms the latest methods in the prediction of protein-ligand binding affinities, mutation induced globular protein folding free energy changes, and mutation induced membrane protein folding free energy changes. © 2017 Cang, Wei.","","Computational Biology; Image Processing, Computer-Assisted; Machine Learning; Membrane Proteins; Models, Statistical; Molecular Dynamics Simulation; Neural Networks (Computer); Protein Binding; Protein Folding; Binding energy; Complex networks; Convolution; Deep neural networks; Free energy; Ligands; Molecular biology; Protein folding; Three dimensional computer graphics; Topology; membrane protein; protein binding; Bio-molecular; Convolutional neural network; Element specific; Free energy change; Multi channel; Multi tasks; Neural-networks; Persistent homology; Protein foldings; Protein-ligand binding affinities; Article; artificial neural network; binding affinity; geometry; ligand binding; multi task multichannel topological convolutional neural network; mutation; prediction; protein folding; protein stability; software; TopologyNet; biology; chemistry; image processing; machine learning; metabolism; molecular dynamics; physiology; procedures; statistical model; Forecasting","Public Library of Science","1553734X","","","28749969","Article","Scopus","2-s2.0-85026627894"
"Han X.","Han, Xiao (55286810300)","55286810300","MR-based synthetic CT generation using a deep convolutional neural network method:","2017","Medical Physics","569","10.1002/mp.12155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021308439&doi=10.1002%2fmp.12155&partnerID=40&md5=f831c6e85a298753ccdff50f66ec3ef8","Elekta Inc., Maryland Heights, 63043, MO, United States","Han X., Elekta Inc., Maryland Heights, 63043, MO, United States","Purpose: Interests have been rapidly growing in the field of radiotherapy to replace CT with magnetic resonance imaging (MRI), due to superior soft tissue contrast offered by MRI and the desire to reduce unnecessary radiation dose. MR-only radiotherapy also simplifies clinical workflow and avoids uncertainties in aligning MR with CT. Methods, however, are needed to derive CT-equivalent representations, often known as synthetic CT (sCT), from patient MR images for dose calculation and DRR-based patient positioning. Synthetic CT estimation is also important for PET attenuation correction in hybrid PET-MR systems. We propose in this work a novel deep convolutional neural network (DCNN) method for sCT generation and evaluate its performance on a set of brain tumor patient images. Methods: The proposed method builds upon recent developments of deep learning and convolutional neural networks in the computer vision literature. The proposed DCNN model has 27 convolutional layers interleaved with pooling and unpooling layers and 35 million free parameters, which can be trained to learn a direct end-to-end mapping from MR images to their corresponding CTs. Training such a large model on our limited data is made possible through the principle of transfer learning and by initializing model weights from a pretrained model. Eighteen brain tumor patients with both CT and T1-weighted MR images are used as experimental data and a sixfold cross-validation study is performed. Each sCT generated is compared against the real CT image of the same patient on a voxel-by-voxel basis. Comparison is also made with respect to an atlas-based approach that involves deformable atlas registration and patch-based atlas fusion. Results: The proposed DCNN method produced a mean absolute error (MAE) below 85 HU for 13 of the 18 test subjects. The overall average MAE was 84.8 ± 17.3 HU for all subjects, which was found to be significantly better than the average MAE of 94.5 ± 17.8 HU for the atlas-based method. The DCNN method also provided significantly better accuracy when being evaluated using two other metrics: the mean squared error (188.6 ± 33.7 versus 198.3 ± 33.0) and the Pearson correlation coefficient(0.906 ± 0.03 versus 0.896 ± 0.03). Although training a DCNN model can be slow, training only need be done once. Applying a trained model to generate a complete sCT volume for each new patient MR image only took 9 s, which was much faster than the atlas-based approach. Conclusions: A DCNN model method was developed, and shown to be able to produce highly accurate sCT estimations from conventional, single-sequence MR images in near real time. Quantitative results also showed that the proposed method competed favorably with an atlas-based method, in terms of both accuracy and computation speed at test time. Further validation on dose computation accuracy and on a larger patient cohort is warranted. Extensions of the method are also possible to further improve accuracy or to handle multi-sequence MR images. © 2017 American Association of Physicists in Medicine.","convolutional neural network; deep learning; MRI; radiation therapy; synthetic CT","Breast Neoplasms; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Neural Networks (Computer); Time Factors; Tomography, X-Ray Computed; Brain; Computerized tomography; Convolution; Correlation methods; Deep neural networks; Deformation; Mean square error; Neural network models; Radiotherapy; Tumors; Atlas-based methods; Brain tumors; Convolutional neural network; Deep learning; Mean absolute error; MR-images; Neural network method; Neural network model; Synthetic CT; Tumor patient; Article; brain tumor; clinical article; computed tomography scanner; computer assisted tomography; controlled study; diagnostic accuracy; diagnostic error; diagnostic test accuracy study; human; image analysis; machine learning; neuroimaging; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; qualitative analysis; quantitative analysis; synthetic computer assisted tomography; artificial neural network; breast tumor; diagnostic imaging; image processing; procedures; three dimensional imaging; time factor; x-ray computed tomography; Magnetic resonance imaging","John Wiley and Sons Ltd","00942405","","MPHYA","28192624","Article","Scopus","2-s2.0-85021308439"
"Du X.; Sun S.; Hu C.; Yao Y.; Yan Y.; Zhang Y.","Du, Xiuquan (26321470100); Sun, Shiwei (7404509946); Hu, Changlin (57192953191); Yao, Yu (57194624095); Yan, Yuanting (55926021100); Zhang, Yanping (35303881100)","26321470100; 7404509946; 57192953191; 57194624095; 55926021100; 35303881100","DeepPPI: Boosting Prediction of Protein-Protein Interactions with Deep Neural Networks","2017","Journal of Chemical Information and Modeling","163","10.1021/acs.jcim.7b00028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021271169&doi=10.1021%2facs.jcim.7b00028&partnerID=40&md5=7075da09f513a868b787895e5d2aa7c7","Key Laboratory of Intelligent Computing and Signal Processing, Ministry of Education, Anhui University, Hefei, Anhui, 230601, China; School of Computer Science and Technology, Anhui University, Hefei, Anhui, 230601, China; Center of Information Support and Assurance Technology, Anhui University, Hefei, Anhui, 230601, China","Du X., Key Laboratory of Intelligent Computing and Signal Processing, Ministry of Education, Anhui University, Hefei, Anhui, 230601, China, School of Computer Science and Technology, Anhui University, Hefei, Anhui, 230601, China, Center of Information Support and Assurance Technology, Anhui University, Hefei, Anhui, 230601, China; Sun S., School of Computer Science and Technology, Anhui University, Hefei, Anhui, 230601, China; Hu C., School of Computer Science and Technology, Anhui University, Hefei, Anhui, 230601, China; Yao Y., School of Computer Science and Technology, Anhui University, Hefei, Anhui, 230601, China; Yan Y., Key Laboratory of Intelligent Computing and Signal Processing, Ministry of Education, Anhui University, Hefei, Anhui, 230601, China, School of Computer Science and Technology, Anhui University, Hefei, Anhui, 230601, China, Center of Information Support and Assurance Technology, Anhui University, Hefei, Anhui, 230601, China; Zhang Y., Key Laboratory of Intelligent Computing and Signal Processing, Ministry of Education, Anhui University, Hefei, Anhui, 230601, China, School of Computer Science and Technology, Anhui University, Hefei, Anhui, 230601, China, Center of Information Support and Assurance Technology, Anhui University, Hefei, Anhui, 230601, China","The complex language of eukaryotic gene expression remains incompletely understood. Despite the importance suggested by many proteins variants statistically associated with human disease, nearly all such variants have unknown mechanisms, for example, protein-protein interactions (PPIs). In this study, we address this challenge using a recent machine learning advance-deep neural networks (DNNs). We aim at improving the performance of PPIs prediction and propose a method called DeepPPI (Deep neural networks for Protein-Protein Interactions prediction), which employs deep neural networks to learn effectively the representations of proteins from common protein descriptors. The experimental results indicate that DeepPPI achieves superior performance on the test data set with an Accuracy of 92.50%, Precision of 94.38%, Recall of 90.56%, Specificity of 94.49%, Matthews Correlation Coefficient of 85.08% and Area Under the Curve of 97.43%, respectively. Extensive experiments show that DeepPPI can learn useful features of proteins pairs by a layer-wise abstraction, and thus achieves better prediction performance than existing methods. The source code of our approach can be available via http://ailab.ahu.edu.cn:8087/DeepPPI/index.html. © 2017 American Chemical Society.","","Neural Networks (Computer); Protein Interaction Mapping; Saccharomyces cerevisiae; Deep neural networks; Forecasting; Gene expression; Proteins; Statistical tests; Area under the curves; Correlation coefficient; Descriptors; Eukaryotic gene expression; Human disease; Prediction performance; Protein-protein interactions; Source codes; artificial neural network; metabolism; procedures; protein analysis; Saccharomyces cerevisiae; Neural networks","American Chemical Society","15499596","","JCISD","28514151","Article","Scopus","2-s2.0-85021271169"
"Zhong J.; Chen D.Q.; Nantes J.C.; Holmes S.A.; Hodaie M.; Koski L.","Zhong, Jidan (56861606700); Chen, David Qixiang (36157038800); Nantes, Julia C. (56862292600); Holmes, Scott A. (39863151900); Hodaie, Mojgan (6506463954); Koski, Lisa (6701368559)","56861606700; 36157038800; 56862292600; 39863151900; 6506463954; 6701368559","Combined structural and functional patterns discriminating upper limb motor disability in multiple sclerosis using multivariate approaches","2017","Brain Imaging and Behavior","20","10.1007/s11682-016-9551-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965043202&doi=10.1007%2fs11682-016-9551-4&partnerID=40&md5=d208a27b20bf8cac612db9691b48b5eb","Research Institute of the McGill University Health Centre, Montreal, QC, Canada; Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada; Toronto Western Hospital, 399 Bathurst Street, Toronto, M5T 2S8, ON, Canada; Institute of Medical Science, University of Toronto, Toronto, ON, Canada; Division of Brain, Imaging and Behaviour-Systems, Neuroscience, Krembil Research Institute, University Health Network, Toronto, ON, Canada; Integrated Program in Neuroscience, McGill University, Montreal, QC, Canada; Division of Neurosurgery, Toronto Western Hospital & University of Toronto, Toronto, ON, Canada; Department of Psychology, McGill University, Montreal, QC, Canada","Zhong J., Research Institute of the McGill University Health Centre, Montreal, QC, Canada, Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada, Toronto Western Hospital, 399 Bathurst Street, Toronto, M5T 2S8, ON, Canada; Chen D.Q., Institute of Medical Science, University of Toronto, Toronto, ON, Canada, Division of Brain, Imaging and Behaviour-Systems, Neuroscience, Krembil Research Institute, University Health Network, Toronto, ON, Canada; Nantes J.C., Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada, Integrated Program in Neuroscience, McGill University, Montreal, QC, Canada; Holmes S.A., Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada, Integrated Program in Neuroscience, McGill University, Montreal, QC, Canada; Hodaie M., Institute of Medical Science, University of Toronto, Toronto, ON, Canada, Division of Brain, Imaging and Behaviour-Systems, Neuroscience, Krembil Research Institute, University Health Network, Toronto, ON, Canada, Division of Neurosurgery, Toronto Western Hospital & University of Toronto, Toronto, ON, Canada; Koski L., Research Institute of the McGill University Health Centre, Montreal, QC, Canada, Department of Neurology and Neurosurgery, McGill University, Montreal, QC, Canada, Department of Psychology, McGill University, Montreal, QC, Canada","A structural or functional pattern of neuroplasticity that could systematically discriminate between people with impaired and preserved motor performance could help us to understand the brain networks contributing to preservation or compensation of behavior in multiple sclerosis (MS). This study aimed to (1) investigate whether a machine learning-based technique could accurately classify MS participants into groups defined by upper extremity function (i.e. motor function preserved (MP) vs. motor function impaired (MI)) based on their regional grey matter measures (GMM, cortical thickness and deep grey matter volume) and inter-regional functional connection (FC), (2) investigate which features (GMM, FC, or GMM + FC) could classify groups more accurately, and (3) identify the multivariate patterns of GMM and FCs that are most discriminative between MP and MI participants, and between each of these groups and the healthy controls (HCs). With 26 MP, 25 MI, and 21 HCs (age and sex matched) underwent T1-weighted and resting-state functional MRI at 3 T, we applied support vector machine (SVM) based classification to learn discriminant functions indicating regions in which GMM or between which FCs were most discriminative between groups. This study demonstrates that there exist structural and FC patterns sufficient for correct classification of upper limb motor ability of people with MS. The classifier with GMM + FC features yielded the highest accuracy of 85.61 % (p < 0.001) to distinguish between the MS groups using leave-one-out cross-validation. It suggests that a machine-learning approach combining structural and functional features is useful for identifying the specific neural substrates that are necessary and sufficient to preserve motor function among people with MS. © 2016, Springer Science+Business Media New York.","Cortical thickness; Deep grey matter volume; Functional connectivity; Motor disability; Multiple sclerosis; Multivariate analysis; Support vector machine","Area Under Curve; Diagnosis, Differential; Female; Functional Laterality; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Motor Activity; Movement Disorders; Multiple Sclerosis; Multivariate Analysis; Organ Size; ROC Curve; Support Vector Machine; Upper Extremity; beta1a interferon; ceralifimod; fingolimod; glatiramer; natalizumab; siponimod; adult; anterior cingulate; Article; association cortex; brain atrophy; brain region; brain size; cerebellum cortex; cerebral crus; cerebral peduncle; cingulate gyrus; clinical article; controlled study; cortical thickness (brain); cuneus; diagnostic accuracy; diagnostic test accuracy study; diencephalon; discriminant analysis; entorhinal cortex; Expanded Disability Status Scale; female; frontal lobe; functional connectivity; functional disease; functional magnetic resonance imaging; functional neuroimaging; fusiform gyrus; geniculate nucleus; globus pallidus; gray matter; human; hypothalamus; image processing; image quality; imaging software; inferior frontal gyrus; inferior temporal gyrus; insula; lateral geniculate body; lateral orbitofrontal cortex; left hemisphere; lenticular fasciculus; lingual gyrus; male; mammillary body; medial lemniscus; middle aged; middle frontal gyrus; motor dysfunction; motor performance; multiple sclerosis; multivariate analysis; nuclear magnetic resonance scanner; nucleus accumbens; occipital cortex; occipital lobe; patient coding; pericalcarine sulcus; precentral sulcus; priority journal; putamen; red nucleus; retrospective study; right hemisphere; subcortex; substantia nigra; subthalamic nucleus; superior parietal lobule; superior temporal gyrus; support vector machine; supramarginal gyrus; temporal lobe; thalamus; upper limb; ventral diencephalon; white matter; white matter lesion; zona incerta; area under the curve; classification; computer assisted diagnosis; diagnostic imaging; differential diagnosis; hemispheric dominance; motor activity; motor dysfunction; multiple sclerosis; multivariate analysis; nuclear magnetic resonance imaging; organ size; pathophysiology; procedures; receiver operating characteristic; support vector machine; upper limb","Springer New York LLC","19317557","","","27146291","Article","Scopus","2-s2.0-84965043202"
"Koutsoukas A.; Monaghan K.J.; Li X.; Huan J.","Koutsoukas, Alexios (38862155600); Monaghan, Keith J. (57194650752); Li, Xiaoli (35487931000); Huan, Jun (57195633346)","38862155600; 57194650752; 35487931000; 57195633346","Deep-learning: Investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data","2017","Journal of Cheminformatics","214","10.1186/s13321-017-0226-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021424291&doi=10.1186%2fs13321-017-0226-y&partnerID=40&md5=f5266008176e0406ae24b632802d2beb","Department of Electrical Engineering and Computer Sciences, University of Kansas, Lawrence, 66047-7621, KS, United States","Koutsoukas A., Department of Electrical Engineering and Computer Sciences, University of Kansas, Lawrence, 66047-7621, KS, United States; Monaghan K.J., Department of Electrical Engineering and Computer Sciences, University of Kansas, Lawrence, 66047-7621, KS, United States; Li X., Department of Electrical Engineering and Computer Sciences, University of Kansas, Lawrence, 66047-7621, KS, United States; Huan J., Department of Electrical Engineering and Computer Sciences, University of Kansas, Lawrence, 66047-7621, KS, United States","Background: In recent years, research in artificial neural networks has resurged, now under the deep-learning umbrella, and grown extremely popular. Recently reported success of DL techniques in crowd-sourced QSAR and predictive toxicology competitions has showcased these methods as powerful tools in drug-discovery and toxicology research. The aim of this work was dual, first large number of hyper-parameter configurations were explored to investigate how they affect the performance of DNNs and could act as starting points when tuning DNNs and second their performance was compared to popular methods widely employed in the field of cheminformatics namely Naïve Bayes, k-nearest neighbor, random forest and support vector machines. Moreover, robustness of machine learning methods to different levels of artificially introduced noise was assessed. The open-source Caffe deep-learning framework and modern NVidia GPU units were utilized to carry out this study, allowing large number of DNN configurations to be explored. Results: We show that feed-forward deep neural networks are capable of achieving strong classification performance and outperform shallow methods across diverse activity classes when optimized. Hyper-parameters that were found to play critical role are the activation function, dropout regularization, number hidden layers and number of neurons. When compared to the rest methods, tuned DNNs were found to statistically outperform, with p value <0.01 based on Wilcoxon statistical test. DNN achieved on average MCC units of 0.149 higher than NB, 0.092 than kNN, 0.052 than SVM with linear kernel, 0.021 than RF and finally 0.009 higher than SVM with radial basis function kernel. When exploring robustness to noise, non-linear methods were found to perform well when dealing with low levels of noise, lower than or equal to 20%, however when dealing with higher levels of noise, higher than 30%, the Naïve Bayes method was found to perform well and even outperform at the highest level of noise 50% more sophisticated methods across several datasets. © 2017 The Author(s).","Cheminformatics; Data-mining; Deep learning; kNN; Machine-learning; Naïve Bayes; Random forest; SARs; Support vector machines","","BioMed Central Ltd.","17582946","","","","Article","Scopus","2-s2.0-85021424291"
"Borah R.; Rajarajeswari S.","Borah, Rima (57195107095); Rajarajeswari, S. (56153115300)","57195107095; 56153115300","A study on application of machine learning and computer vision for retail projects","2017","Asian Journal of Pharmaceutical and Clinical Research","1","10.22159/ajpcr.2017.v10s1.20522","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025426531&doi=10.22159%2fajpcr.2017.v10s1.20522&partnerID=40&md5=861e7a41a39528b8aa1c64ca4bb71b9f","Department of Computing Science and Enineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India","Borah R., Department of Computing Science and Enineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India; Rajarajeswari S., Department of Computing Science and Enineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India","The motivation for developing computer vision is the human vision system which is the richest sense that we have. To us, vision seems an easy task of just seeing objects in daily life and identifying them, but in reality, our eyes along with the brain are processing information of around 50 images every second with millions of pixels in each image. Most of these images obtained are currently just looked at by people. The challenging task is to process images from all these cameras and allow automation of tasks never before considered. Neural networks help us in making cameras intelligent enough to understand the images it captures. Convolutional neural networks (CNN) are trained to give image classification results of good accuracy, with the challenge to improve utilization of computing resources. Google Net is in its essence a deep CNN that uses inception architecture to attain leading edge results for classification and detection problems. In this paper, a study was made on applications of computer vision techniques in retail and customer strategic projects. Further, it was analyzed that if cameras trained with CNN can work well enough to be deployed in retail market scenarios to automate sales and stock supervision. © 2017 The Authors.","Computer vision; Convolutional neural network; Deep learning; Inception architecture; Neural network","automation; classification; human; machine learning; market; nervous system; vision","Innovare Academics Sciences Pvt. Ltd","09742441","","","","Article","Scopus","2-s2.0-85025426531"
"Li R.; Zeng T.; Peng H.; Ji S.","Li, Rongjian (55975033200); Zeng, Tao (56222150100); Peng, Hanchuan (15061795400); Ji, Shuiwang (18935244900)","55975033200; 56222150100; 15061795400; 18935244900","Deep Learning Segmentation of Optical Microscopy Images Improves 3-D Neuron Reconstruction","2017","IEEE Transactions on Medical Imaging","100","10.1109/TMI.2017.2679713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028365655&doi=10.1109%2fTMI.2017.2679713&partnerID=40&md5=1aaf3c8964b4ad1cc71c8ea70d368348","School of Electrical Engineering and Computer Science, Washington State University, Pullman, 99164, WA, United States; Allen Institute for Brain Science, Seattle, 98109, WA, United States","Li R., School of Electrical Engineering and Computer Science, Washington State University, Pullman, 99164, WA, United States; Zeng T., School of Electrical Engineering and Computer Science, Washington State University, Pullman, 99164, WA, United States; Peng H., Allen Institute for Brain Science, Seattle, 98109, WA, United States; Ji S., School of Electrical Engineering and Computer Science, Washington State University, Pullman, 99164, WA, United States","Digital reconstruction, or tracing, of 3-D neuron structure from microscopy images is a critical step toward reversing engineering the wiring and anatomy of a brain. Despite a number of prior attempts, this task remains very challenging, especially when images are contaminated by noises or have discontinued segments of neurite patterns. An approach for addressing such problems is to identify the locations of neuronal voxels using image segmentation methods, prior to applying tracing or reconstruction techniques. This preprocessing step is expected to remove noises in the data, thereby leading to improved reconstruction results. In this paper, we proposed to use 3-D convolutional neural networks (CNNs) for segmenting the neuronal microscopy images. Specifically, we designed a novel CNN architecture, that takes volumetric images as the inputs and their voxel-wise segmentation maps as the outputs. The developed architecture allows us to train and predict using large microscopy images in an end-to-end manner. We evaluated the performance of our model on a variety of challenging 3-D microscopy images from different organisms. Results showed that the proposed methods improved the tracing performance significantly when combined with different reconstruction algorithms. © 1982-2012 IEEE.","BigNeuron; Deep learning; image denoising; image segmentation; neuron reconstruction","Algorithms; Brain; Imaging, Three-Dimensional; Machine Learning; Microscopy; Neural Networks (Computer); Neurons; Deep learning; Image denoising; Image processing; Image reconstruction; Network architecture; Neural networks; Neurons; BigNeuron; Convolutional neural network; Digital reconstruction; Neuron reconstruction; Reconstruction algorithms; Reconstruction techniques; Reversing engineerings; Segmentation methods; image segmentation; learning; microscopy; model; nerve cell; noise; algorithm; artificial neural network; brain; machine learning; microscopy; nerve cell; three dimensional imaging; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28287966","Article","Scopus","2-s2.0-85028365655"
"Yuan Y.; Meng M.Q.-H.","Yuan, Yixuan (55932867600); Meng, Max Q.-H. (7102739136)","55932867600; 7102739136","Deep learning for polyp recognition in wireless capsule endoscopy images:","2017","Medical Physics","147","10.1002/mp.12147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021389338&doi=10.1002%2fmp.12147&partnerID=40&md5=ab020537f536ca275a5bd75ca0a9d72c","Department of Electronic Engineering, Chinese University of Hong Kong, Hong Kong","Yuan Y., Department of Electronic Engineering, Chinese University of Hong Kong, Hong Kong; Meng M.Q.-H., Department of Electronic Engineering, Chinese University of Hong Kong, Hong Kong","Purpose: Wireless capsule endoscopy (WCE) enables physicians to examine the digestive tract without any surgical operations, at the cost of a large volume of images to be analyzed. In the computer-aided diagnosis of WCE images, the main challenge arises from the difficulty of robust characterization of images. This study aims to provide discriminative description of WCE images and assist physicians to recognize polyp images automatically. Methods: We propose a novel deep feature learning method, named stacked sparse autoencoder with image manifold constraint (SSAEIM), to recognize polyps in the WCE images. Our SSAEIM differs from the traditional sparse autoencoder (SAE) by introducing an image manifold constraint, which is constructed by a nearest neighbor graph and represents intrinsic structures of images. The image manifold constraint enforces that images within the same category share similar learned features and images in different categories should be kept far away. Thus, the learned features preserve large intervariances and small intravariances among images. Results: The average overall recognition accuracy (ORA) of our method for WCE images is 98.00%. The accuracies for polyps, bubbles, turbid images, and clear images are 98.00%, 99.50%, 99.00%, and 95.50%, respectively. Moreover, the comparison results show that our SSAEIM outperforms existing polyp recognition methods with relative higher ORA. Conclusion: The comprehensive results have demonstrated that the proposed SSAEIM can provide descriptive characterization for WCE images and recognize polyps in a WCE video accurately. This method could be further utilized in the clinical trials to help physicians from the tedious image reading work. © 2017 American Association of Physicists in Medicine.","image manifold information; polyp recognition; stacked sparse autoencoder with image manifold (SSAEIM); wireless capsule endoscopy images","Capsule Endoscopy; Image Processing, Computer-Assisted; Machine Learning; Polyps; Deep learning; Endoscopy; Surgery; Auto encoders; Image manifold information; Image manifolds; Manifold constraints; Polyp recognition; Recognition accuracy; Stacked sparse autoencoder with image manifold; Wireless capsule endoscopy; Wireless capsule endoscopy image; Article; capsule endoscopy; colorectal polyp; controlled study; diagnostic accuracy; human; image analysis; image processing; learning algorithm; machine learning; Polyps; procedures; Computer aided diagnosis","John Wiley and Sons Ltd","00942405","","MPHYA","28160514","Article","Scopus","2-s2.0-85021389338"
"Kruskal J.B.; Berkowitz S.; Geis J.R.; Kim W.; Nagy P.; Dreyer K.","Kruskal, Jonathan B. (35594037800); Berkowitz, Seth (56054064300); Geis, J. Raymond (6602850280); Kim, Woojin (57199881098); Nagy, Paul (35253892000); Dreyer, Keith (7006172475)","35594037800; 56054064300; 6602850280; 57199881098; 35253892000; 7006172475","Big Data and Machine Learning—Strategies for Driving This Bus: A Summary of the 2016 Intersociety Summer Conference","2017","Journal of the American College of Radiology","43","10.1016/j.jacr.2017.02.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016406632&doi=10.1016%2fj.jacr.2017.02.019&partnerID=40&md5=ef446e936e0bc5760b2fcfb04726d482","Department of Radiology, Beth Israel Deaconess Medical Center, Boston, Massachusetts, United States; Advanced Medical Imaging Consultants, Fort Collins, Colorado, United States; Nuance Communications, Inc., Los Angeles, California, United States; Department of Radiology, Johns Hopkins Medical Institute, Baltimore, Maryland, United States; Department of Radiology, Massachusetts General Hospital, Boston, Massachusetts, United States","Kruskal J.B., Department of Radiology, Beth Israel Deaconess Medical Center, Boston, Massachusetts, United States; Berkowitz S., Department of Radiology, Beth Israel Deaconess Medical Center, Boston, Massachusetts, United States; Geis J.R., Advanced Medical Imaging Consultants, Fort Collins, Colorado, United States; Kim W., Nuance Communications, Inc., Los Angeles, California, United States; Nagy P., Department of Radiology, Johns Hopkins Medical Institute, Baltimore, Maryland, United States; Dreyer K., Department of Radiology, Massachusetts General Hospital, Boston, Massachusetts, United States","The 38th radiology Intersociety Committee reviewed the current state and future direction of clinical data science and its application to radiology practice. The assembled participants discussed the need to use current technology to better generate and demonstrate radiologists’ value for our patients and referring providers. The attendants grappled with the potentially disruptive applications of machine learning to image analysis. Although the prospect of algorithms’ interpreting images automatically initially shakes the core of the radiology profession, the group emerged with tremendous optimism about the future of radiology. Emerging technologies will provide enormous opportunities for radiologists to augment and improve the quality of care they provide to their patients. Radiologists must maintain an active role in guiding the development of these technologies. The conference ended with a call to action to develop educational strategies for future leaders, communicate optimism for our profession's future, and engage with industry to ensure the ethics and clinical relevance of developing technologies. © 2017 American College of Radiology","ACR; big data; data science; deep learning; imaging informatics; Intersociety Committee; machine learning; radiology","Algorithms; Database Management Systems; Forecasting; Humans; Machine Learning; Radiology; Radiology Information Systems; Societies, Medical; doctor patient relation; ethics; human; image analysis; imaging; information science; leadership; machine learning; occupation; optimism; radiologist; radiology; summer; algorithm; database management system; forecasting; medical society; radiology information system","Elsevier B.V.","15461440","","","28372961","Article","Scopus","2-s2.0-85016406632"
"Ghazaei G.; Alameer A.; Degenaar P.; Morgan G.; Nazarpour K.","Ghazaei, Ghazal (57190424340); Alameer, Ali (57190429643); Degenaar, Patrick (9636467400); Morgan, Graham (9133666100); Nazarpour, Kianoush (23390436100)","57190424340; 57190429643; 9636467400; 9133666100; 23390436100","Deep learning-based artificial vision for grasp classification in myoelectric hands","2017","Journal of Neural Engineering","129","10.1088/1741-2552/aa6802","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020424183&doi=10.1088%2f1741-2552%2faa6802&partnerID=40&md5=610dbe3f532f23d4c80e30bbeaa42971","School of Electrical and Electronic Engineering, Newcastle University, Newcastle-upon-Tyne, NE1 7RU, United Kingdom; Institute of Neuroscience, Newcastle University, Newcastle-upon-Tyne, NE2 4HH, United Kingdom; School of Computing Science, Newcastle University, Newcastle-upon-Tyne, NE1 7RU, United Kingdom","Ghazaei G., School of Electrical and Electronic Engineering, Newcastle University, Newcastle-upon-Tyne, NE1 7RU, United Kingdom; Alameer A., School of Electrical and Electronic Engineering, Newcastle University, Newcastle-upon-Tyne, NE1 7RU, United Kingdom; Degenaar P., School of Electrical and Electronic Engineering, Newcastle University, Newcastle-upon-Tyne, NE1 7RU, United Kingdom, Institute of Neuroscience, Newcastle University, Newcastle-upon-Tyne, NE2 4HH, United Kingdom; Morgan G., School of Computing Science, Newcastle University, Newcastle-upon-Tyne, NE1 7RU, United Kingdom; Nazarpour K., School of Electrical and Electronic Engineering, Newcastle University, Newcastle-upon-Tyne, NE1 7RU, United Kingdom, Institute of Neuroscience, Newcastle University, Newcastle-upon-Tyne, NE2 4HH, United Kingdom","Objective. Computer vision-based assistive technology solutions can revolutionise the quality of care for people with sensorimotor disorders. The goal of this work was to enable trans-radial amputees to use a simple, yet efficient, computer vision system to grasp and move common household objects with a two-channel myoelectric prosthetic hand. Approach. We developed a deep learning-based artificial vision system to augment the grasp functionality of a commercial prosthesis. Our main conceptual novelty is that we classify objects with regards to the grasp pattern without explicitly identifying them or measuring their dimensions. A convolutional neural network (CNN) structure was trained with images of over 500 graspable objects. For each object, 72 images, at intervals, were available. Objects were categorised into four grasp classes, namely: pinch, tripod, palmar wrist neutral and palmar wrist pronated. The CNN setting was first tuned and tested offline and then in realtime with objects or object views that were not included in the training set. Main results. The classification accuracy in the offline tests reached for the seen and for the novel objects; reflecting the generalisability of grasp classification. We then implemented the proposed framework in realtime on a standard laptop computer and achieved an overall score of in classifying a set of novel as well as seen but randomly-rotated objects. Finally, the system was tested with two trans-radial amputee volunteers controlling an i-limb UltraTM prosthetic hand and a motion controlTM prosthetic wrist; augmented with a webcam. After training, subjects successfully picked up and moved the target objects with an overall success of up to . In addition, we show that with training, subjects' performance improved in terms of time required to accomplish a block of 24 trials despite a decreasing level of visual feedback. Significance. The proposed design constitutes a substantial conceptual improvement for the control of multi-functional prosthetic hands. We show for the first time that deep-learning based computer vision systems can enhance the grip functionality of myoelectric hands considerably. © 2017 IOP Publishing Ltd.","convolutional neural network; grasp classification; myoelectric hand prosthesis","Amputees; Artificial Limbs; Electromyography; Feedback, Sensory; Hand; Hand Strength; Humans; Imaging, Three-Dimensional; Machine Learning; Man-Machine Systems; Movement; Muscle, Skeletal; Pattern Recognition, Visual; Psychomotor Performance; Artificial limbs; Computer vision; Convolution; Deep learning; Laptop computers; Neural networks; Prosthetics; Vision; Visual communication; Artificial vision system; Assistive technology; Classification accuracy; Computer vision system; Convolutional neural network; Hand prosthesis; Multi-functional; Prosthetic wrists; adult; Article; artificial vision; assistive technology; computer; convolutional neural network; grip strength; hand prosthesis; household; human; machine learning; male; middle aged; myoelectric control; myoelectrically controlled prosthesis; object manipulation; priority journal; vision; visual feedback; wrist prosthesis; amputee; electromyography; hand; hand strength; innervation; limb prosthesis; machine learning; man machine interaction; movement (physiology); pathophysiology; pattern recognition; psychomotor performance; rehabilitation; sensory feedback; skeletal muscle; three dimensional imaging; Myoelectrically controlled prosthetics","Institute of Physics Publishing","17412560","","","28467317","Article","Scopus","2-s2.0-85020424183"
"Lee C.S.; Baughman D.M.; Lee A.Y.","Lee, Cecilia S. (56472056400); Baughman, Doug M. (57191822884); Lee, Aaron Y. (26635526200)","56472056400; 57191822884; 26635526200","Deep Learning Is Effective for Classifying Normal versus Age-Related Macular Degeneration OCT Images","2017","Ophthalmology Retina","430","10.1016/j.oret.2016.12.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027881492&doi=10.1016%2fj.oret.2016.12.009&partnerID=40&md5=65f468ee1e86d8be9c734f442690a98e","Department of Ophthalmology, University of Washington School of Medicine, Seattle, Washington, United States","Lee C.S., Department of Ophthalmology, University of Washington School of Medicine, Seattle, Washington, United States; Baughman D.M., Department of Ophthalmology, University of Washington School of Medicine, Seattle, Washington, United States; Lee A.Y., Department of Ophthalmology, University of Washington School of Medicine, Seattle, Washington, United States","Purpose The advent of electronic medical records (EMRs) with large electronic imaging databases along with advances in deep neural networks with machine learning has provided a unique opportunity to achieve milestones in automated image analysis. Optical coherence tomography is the most common imaging modality in ophthalmology and represents a dense and rich data set when combined with labels derived from the EMR. We sought to determine whether deep learning could be utilized to distinguish normal OCT images from images from patients with age-related macular degeneration (AMD). Design EMR and OCT database study. Subjects Normal and AMD patients who underwent macular OCT. Methods Automated extraction of an OCT database was performed and linked to clinical end points from the EMR. Optical coherence tomography scans of the macula were obtained by Heidelberg Spectralis, and each OCT scan was linked to EMR clinical end points extracted from EPIC. The central 11 images were selected from each OCT scan of 2 cohorts of patients: normal and AMD. Cross-validation was performed using a random subset of patients. Receiver operating characteristic (ROC) curves were constructed at an independent image level, macular OCT level, and patient level. Main Outcome Measure Area under the ROC curve. Results Of a recent extraction of 2.6 million OCT images linked to clinical data points from the EMR, 52 690 normal macular OCT images and 48 312 AMD macular OCT images were selected. A deep neural network was trained to categorize images as either normal or AMD. At the image level, we achieved an area under the ROC curve of 92.78% with an accuracy of 87.63%. At the macula level, we achieved an area under the ROC curve of 93.83% with an accuracy of 88.98%. At a patient level, we achieved an area under the ROC curve of 97.45% with an accuracy of 93.45%. Peak sensitivity and specificity with optimal cutoffs were 92.64% and 93.69%, respectively. Conclusions The deep learning technique achieves high accuracy and is effective as a new image classification technique. These findings have important implications in utilizing OCT in automated screening and the development of computer-aided diagnosis tools in the future. © 2016 American Academy of Ophthalmology","","","Elsevier Inc.","24686530","","","","Article","Scopus","2-s2.0-85027881492"
"Lee H.; Tajmir S.; Lee J.; Zissen M.; Yeshiwas B.A.; Alkasab T.K.; Choy G.; Do S.","Lee, Hyunkwang (57193528962); Tajmir, Shahein (57000496000); Lee, Jenny (57193538533); Zissen, Maurice (8268466700); Yeshiwas, Bethel Ayele (57193529155); Alkasab, Tarik K. (7801646987); Choy, Garry (7003722847); Do, Synho (24173146300)","57193528962; 57000496000; 57193538533; 8268466700; 57193529155; 7801646987; 7003722847; 24173146300","Fully Automated Deep Learning System for Bone Age Assessment","2017","Journal of Digital Imaging","332","10.1007/s10278-017-9955-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014613499&doi=10.1007%2fs10278-017-9955-8&partnerID=40&md5=fbbbe21b13971e1c66025ab98c4cf775","Massachusetts General Hospital and Harvard Medical School, Radiology, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States","Lee H., Massachusetts General Hospital and Harvard Medical School, Radiology, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Tajmir S., Massachusetts General Hospital and Harvard Medical School, Radiology, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Lee J., Massachusetts General Hospital and Harvard Medical School, Radiology, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Zissen M., Massachusetts General Hospital and Harvard Medical School, Radiology, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Yeshiwas B.A., Massachusetts General Hospital and Harvard Medical School, Radiology, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Alkasab T.K., Massachusetts General Hospital and Harvard Medical School, Radiology, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Choy G., Massachusetts General Hospital and Harvard Medical School, Radiology, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States; Do S., Massachusetts General Hospital and Harvard Medical School, Radiology, 25 New Chardon Street, Suite 400B, Boston, 02114, MA, United States","Skeletal maturity progresses through discrete phases, a fact that is used routinely in pediatrics where bone age assessments (BAAs) are compared to chronological age in the evaluation of endocrine and metabolic disorders. While central to many disease evaluations, little has changed to improve the tedious process since its introduction in 1950. In this study, we propose a fully automated deep learning pipeline to segment a region of interest, standardize and preprocess input radiographs, and perform BAA. Our models use an ImageNet pretrained, fine-tuned convolutional neural network (CNN) to achieve 57.32 and 61.40% accuracies for the female and male cohorts on our held-out test images. Female test radiographs were assigned a BAA within 1 year 90.39% and within 2 years 98.11% of the time. Male test radiographs were assigned 94.18% within 1 year and 99.00% within 2 years. Using the input occlusion method, attention maps were created which reveal what features the trained model uses to perform BAA. These correspond to what human experts look at when manually performing BAA. Finally, the fully automated BAA system was deployed in the clinical environment as a decision supporting system for more accurate and efficient BAAs at much faster interpretation time (<2 s) than the conventional method. © 2017, The Author(s).","Artificial intelligence; Artificial neural networks (ANNs); Automated measurement; Automated object detection; Bone-age; Classification; Clinical workflow; Computer vision; Computer-aided diagnosis (CAD); Data collection; Decision support; Digital X-ray radiogrammetry; Efficiency; Machine learning; Structured reporting","Adolescent; Adult; Age Determination by Skeleton; Child; Decision Support Systems, Clinical; Female; Hand; Humans; Machine Learning; Male; Neural Networks (Computer); Software; Artificial intelligence; Automation; Bone; Classification (of information); Computer aided instruction; Computer vision; Decision support systems; Deep learning; Diagnosis; Efficiency; Image segmentation; Learning systems; Neural networks; Radiography; Automated measurement; Bone age; Clinical workflow; Computer Aided Diagnosis(CAD); Data collection; Decision supports; Digital X-ray radiogrammetry; Structured reporting; adolescent; adult; artificial neural network; bone age determination; child; clinical decision support system; diagnostic imaging; female; hand; human; machine learning; male; procedures; software; Computer aided diagnosis","Springer New York LLC","08971889","","JDIME","28275919","Article","Scopus","2-s2.0-85014613499"
"Forsberg D.; Sjöblom E.; Sunshine J.L.","Forsberg, Daniel (36608093000); Sjöblom, Erik (57192938042); Sunshine, Jeffrey L. (7004318093)","36608093000; 57192938042; 7004318093","Detection and Labeling of Vertebrae in MR Images Using Deep Learning with Clinical Annotations as Training Data","2017","Journal of Digital Imaging","78","10.1007/s10278-017-9945-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009268742&doi=10.1007%2fs10278-017-9945-x&partnerID=40&md5=3a7758286f9f0a360048e03e97060e5d","Sectra, Teknikringen 20, Linköping, 583 30, SE, Sweden; Department of Radiology, Case Western Reserve University and University Hospitals Cleveland Medical Center, 11100 Euclid Avenue, Cleveland, 44106, OH, United States","Forsberg D., Sectra, Teknikringen 20, Linköping, 583 30, SE, Sweden, Department of Radiology, Case Western Reserve University and University Hospitals Cleveland Medical Center, 11100 Euclid Avenue, Cleveland, 44106, OH, United States; Sjöblom E., Sectra, Teknikringen 20, Linköping, 583 30, SE, Sweden; Sunshine J.L., Department of Radiology, Case Western Reserve University and University Hospitals Cleveland Medical Center, 11100 Euclid Avenue, Cleveland, 44106, OH, United States","The purpose of this study was to investigate the potential of using clinically provided spine label annotations stored in a single institution image archive as training data for deep learning-based vertebral detection and labeling pipelines. Lumbar and cervical magnetic resonance imaging cases with annotated spine labels were identified and exported from an image archive. Two separate pipelines were configured and trained for lumbar and cervical cases respectively, using the same setup with convolutional neural networks for detection and parts-based graphical models to label the vertebrae. The detection sensitivity, precision and accuracy rates ranged between 99.1–99.8, 99.6–100, and 98.8–99.8% respectively, the average localization error ranges were 1.18–1.24 and 2.38–2.60 mm for cervical and lumbar cases respectively, and with a labeling accuracy of 96.0–97.0%. Failed labeling results typically involved failed S1 detections or missed vertebrae that were not fully visible on the image. These results show that clinically annotated image data from one image archive is sufficient to train a deep learning-based pipeline for accurate detection and labeling of MR images depicting the spine. Further, these results support using deep learning to assist radiologists in their work by providing highly accurate labels that only require rapid confirmation. © 2017, Society for Imaging Informatics in Medicine.","Archive; Artificial neural networks (ANNs); Machine learning; Magnetic resonance imaging","Cervical Vertebrae; Humans; Lumbar Vertebrae; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Radiology Information Systems; Sensitivity and Specificity; Spine; Thoracic Vertebrae; Learning systems; Magnetic levitation vehicles; Magnetic resonance imaging; Musculoskeletal system; Neural networks; Pipelines; Archive; Convolutional neural network; Detection sensitivity; GraphicaL model; Highly accurate; Image archives; Labeling accuracies; Localization errors; artificial neural network; cervical vertebra; diagnostic imaging; human; lumbar vertebra; machine learning; nuclear magnetic resonance imaging; radiology information system; sensitivity and specificity; spine; thoracic vertebra; Image processing","Springer New York LLC","08971889","","JDIME","28083827","Article","Scopus","2-s2.0-85009268742"
"Shrivastava R.; Mahalingam H.; Dutta N.N.","Shrivastava, Rahul (57190421517); Mahalingam, Hari (8654529800); Dutta, N.N. (35567843400)","57190421517; 8654529800; 35567843400","Application and Evaluation of Random Forest Classifier Technique for Fault Detection in Bioreactor Operation","2017","Chemical Engineering Communications","32","10.1080/00986445.2017.1292259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016254966&doi=10.1080%2f00986445.2017.1292259&partnerID=40&md5=8108e380b41b31839d1062433fc522c2","Department of Chemical Engineering, Jaypee University of Engineering and Technology, Raghogarh, Guna (MP), India; Department of Chemical Engineering, National Institute of Technology Karnataka, Surathkal, India","Shrivastava R., Department of Chemical Engineering, Jaypee University of Engineering and Technology, Raghogarh, Guna (MP), India; Mahalingam H., Department of Chemical Engineering, National Institute of Technology Karnataka, Surathkal, India; Dutta N.N., Department of Chemical Engineering, Jaypee University of Engineering and Technology, Raghogarh, Guna (MP), India","Bioreactors and associated bioprocesses are quite complex and nonlinear in nature. A small change in initial condition can greatly alter the output product quality. It is pretty difficult at times to model the system mathematically. In this work, the fault detection problem is studied in the context of bioreactors, mainly, a reactor from the penicillin production process. It is very important to identify the faults in a live process to avoid product quality deterioration. We have focused on the process history-based methods to identify the faults in a bioreactor. We want to introduce random forest (RF), a powerful machine learning algorithm, to identify several types of faults in a bioreactor. The algorithm is simple, easy to use, shows very good generalization ability without compromising much on the classification accuracies, and also has an ability to give variable importance as a part of the algorithm output. We compared its performance with two popular methods, namely support vector machines (SVM) and artificial neural networks (ANN), and found that the overall performance is superior in terms of classification accuracies and generalization ability. © 2017, Copyright © Taylor & Francis Group, LLC.","Bioreactor; Fault detection; Neural network; Random forest; Support vector machine","Bioconversion; Bioreactors; Decision trees; Deep neural networks; Learning algorithms; Learning systems; Neural networks; Quality control; Support vector machines; Classification accuracy; Fault detection problem; Generalization ability; Penicillin production; Quality deteriorations; Random forest classifier; Random forests; Variable importances; Fault detection","Taylor and Francis Ltd.","00986445","","CEGCA","","Article","Scopus","2-s2.0-85016254966"
"Zhang J.; Nawata K.","Zhang, Jie (57196354027); Nawata, Kazumitsu (7005316310)","57196354027; 7005316310","A comparative study on predicting influenza outbreaks","2017","BioScience Trends","28","10.5582/bst.2017.01257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032728417&doi=10.5582%2fbst.2017.01257&partnerID=40&md5=19e890759fa86493fb208825223c0a42","Graduate School of Engineering, University of Tokyo, Tokyo, Japan","Zhang J., Graduate School of Engineering, University of Tokyo, Tokyo, Japan; Nawata K., Graduate School of Engineering, University of Tokyo, Tokyo, Japan","Worldwide, influenza is estimated to result in approximately 3 to 5 million annual cases of severe illness and approximately 250,000 to 500,000 deaths. We need an accurate time-series model to predict the number of influenza patients. Although time-series models with different time lags as feature spaces could lead to varied accuracy, past studies simply adopted a time lag in their models without comparing or selecting an appropriate number of time lags. We investigated the performance of adopting 6 different time lags in 6 different models: Auto- Regressive Integrated Moving Average (ARIMA), Support Vector Regression (SVR), Random Forest (RF), Gradient Boosting (GB), Artificial Neural Network (ANN), and Long Short Term Memory (LSTM) with hyperparameter adjustment. To the best of our knowledge, this is the first time that LSTM has been used to predict influenza outbreaks. As a result, we found that the time lag of 52 weeks led to the lowest Mean Absolute Percentage Error (MAPE) in the ARIMA, ANN and LSTM, while the machine learning models (SVR, RF, GB) achieved the lowest MAPEs with a time lag of 4 weeks. We also found that the MAPEs of the machine learning models were less than ARIMA, and the MAPEs of the deep learning models (ANN, LSTM) were less than those of the machine learning models. In all the models, the LSTM model of 4 layers reached the lowest MAPE of 5.4%, and the LSTM model of 5 layers with regularization reached the lowest root mean squared error (RMSE) of 0.00210.","Influenza-Like Illness; Long Short Term Memory (LSTM); Time lag; Time series","Disease Outbreaks; Forecasting; Humans; Influenza, Human; Models, Statistical; Time Factors; comparative study; epidemic; forecasting; human; influenza; procedures; statistical model; statistics and numerical data; time factor","International Advancement Center for Medicine and Health Research Co., Ltd.","18817815","","","29070762","Article","Scopus","2-s2.0-85032728417"
"Kainz P.; Pfeiffer M.; Urschler M.","Kainz, Philipp (55735071900); Pfeiffer, Michael (41662180000); Urschler, Martin (8554711200)","55735071900; 41662180000; 8554711200","Segmentation and classification of colon glands with deep convolutional neural networks and total variation regularization","2017","PeerJ","98","10.7717/peerj.3874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030308315&doi=10.7717%2fpeerj.3874&partnerID=40&md5=9601ccae0e0fb429761373c22aab4339","Institute of Biophysics, Center for Physiological Medicine, Medical University of Graz, Graz, Austria; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Ludwig Boltzmann Institute for Clinical Forensic Imaging, Graz, Austria; Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria; BioTechMed-Graz, Graz, Austria","Kainz P., Institute of Biophysics, Center for Physiological Medicine, Medical University of Graz, Graz, Austria, Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Pfeiffer M., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Urschler M., Ludwig Boltzmann Institute for Clinical Forensic Imaging, Graz, Austria, Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria, BioTechMed-Graz, Graz, Austria","Segmentation of histopathology sections is a necessary preprocessing step for digital pathology. Due to the large variability of biological tissue, machine learning techniques have shown superior performance over conventional image processing methods. Here we present our deep neural network-based approach for segmentation and classification of glands in tissue of benign and malignant colorectal cancer, which was developed to participate in the GlaS@MICCAI2015 colon gland segmentation challenge. We use two distinct deep convolutional neural networks (CNN) for pixel-wise classification of Hematoxylin-Eosin stained images. While the first classifier separates glands from background, the second classifier identifies gland-separating structures. In a subsequent step, a figure-ground segmentation based on weighted total variation produces the final segmentation result by regularizing the CNN predictions. We present both quantitative and qualitative segmentation results on the recently released and publicly available Warwick-QU colon adenocarcinoma dataset associated with the GlaS@MICCAI2015 challenge and compare our approach to the simultaneously developed other approaches that participated in the same challenge. On two test sets, we demonstrate our segmentation performance and show that we achieve a tissue classification accuracy of 98% and 95%, making use of the inherent capability of our system to distinguish between benign and malignant tissue. Our results show that deep learning approaches can yield highly accurate and reproducible results for biomedical image analysis, with the potential to significantly improve the quality and speed of medical diagnoses. © 2017 Kainz et al.","Colon glands; Deep learning; Malignancy classification; Segmentation","adenocarcinoma; Article; colorectal cancer; entropy; image analysis; image processing; machine learning; nerve cell network; nonhuman; physical performance; probability; tissue structure","PeerJ Inc.","21678359","","","","Article","Scopus","2-s2.0-85030308315"
"Dalmiş M.U.; Litjens G.; Holland K.; Setio A.; Mann R.; Karssemeijer N.; Gubern-Mérida A.","Dalmiş, Mehmet Ufuk (56257647300); Litjens, Geert (36622356600); Holland, Katharina (56259164800); Setio, Arnaud (53264801600); Mann, Ritse (23397838900); Karssemeijer, Nico (24332021400); Gubern-Mérida, Albert (42261661300)","56257647300; 36622356600; 56259164800; 53264801600; 23397838900; 24332021400; 42261661300","Using deep learning to segment breast and fibroglandular tissue in MRI volumes:","2017","Medical Physics","172","10.1002/mp.12079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015580937&doi=10.1002%2fmp.12079&partnerID=40&md5=669f14eee7f7394144b429a58f395b93","Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands","Dalmiş M.U., Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Litjens G., Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Holland K., Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Setio A., Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Mann R., Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Karssemeijer N., Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands; Gubern-Mérida A., Radboud University Medical Center, Geert Grooteplein 10, Nijmegen, 6525 GA, Netherlands","Purpose: Automated segmentation of breast and fibroglandular tissue (FGT) is required for various computer-aided applications of breast MRI. Traditional image analysis and computer vision techniques, such atlas, template matching, or, edge and surface detection, have been applied to solve this task. However, applicability of these methods is usually limited by the characteristics of the images used in the study datasets, while breast MRI varies with respect to the different MRI protocols used, in addition to the variability in breast shapes. All this variability, in addition to various MRI artifacts, makes it a challenging task to develop a robust breast and FGT segmentation method using traditional approaches. Therefore, in this study, we investigated the use of a deep-learning approach known as ""U-net."" Materials and methods: We used a dataset of 66 breast MRI's randomly selected from our scientific archive, which includes five different MRI acquisition protocols and breasts from four breast density categories in a balanced distribution. To prepare reference segmentations, we manually segmented breast and FGT for all images using an in-house developed workstation. We experimented with the application of U-net in two different ways for breast and FGT segmentation. In the first method, following the same pipeline used in traditional approaches, we trained two consecutive (2C) U-nets: first for segmenting the breast in the whole MRI volume and the second for segmenting FGT inside the segmented breast. In the second method, we used a single 3-class (3C) U-net, which performs both tasks simultaneously by segmenting the volume into three regions: nonbreast, fat inside the breast, and FGT inside the breast. For comparison, we applied two existing and published methods to our dataset: an atlas-based method and a sheetness-based method. We used Dice Similarity Coefficient (DSC) to measure the performances of the automated methods, with respect to the manual segmentations. Additionally, we computed Pearson's correlation between the breast density values computed based on manual and automated segmentations. Results: The average DSC values for breast segmentation were 0.933, 0.944, 0.863, and 0.848 obtained from 3C U-net, 2C U-nets, atlas-based method, and sheetness-based method, respectively. The average DSC values for FGT segmentation obtained from 3C U-net, 2C U-nets, and atlas-based methods were 0.850, 0.811, and 0.671, respectively. The correlation between breast density values based on 3C U-net and manual segmentations was 0.974. This value was significantly higher than 0.957 as obtained from 2C U-nets (P < 0.0001, Steiger's Z-test with Bonferoni correction) and 0.938 as obtained from atlas-based method (P = 0.0016). Conclusions: In conclusion, we applied a deep-learning method, U-net, for segmenting breast and FGT in MRI in a dataset that includes a variety of MRI protocols and breast densities. Our results showed that U-net-based methods significantly outperformed the existing algorithms and resulted in significantly more accurate breast density computation. © 2016 American Association of Physicists in Medicine.","breast segmentation; deep learning; MRI","Adult; Aged; Artifacts; Atlases as Topic; Breast Density; Datasets as Topic; Female; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Mammography; Middle Aged; Pattern Recognition, Automated; Skin; Automation; Correlation methods; Deep learning; Image segmentation; Medical imaging; Template matching; Tissue; Atlas-based methods; Breast density; Breast MRI; Breast segmentation; Breast tissues; Deep learning; Fibroglandular tissue; Manual segmentation; Similarity coefficients; Tissue segmentation; artifact; breast density; case report; controlled clinical trial; controlled study; human; human tissue; information center; learning; nuclear magnetic resonance imaging; pipeline; randomized controlled trial; adult; aged; automated pattern recognition; book; breast density; diagnostic imaging; female; image processing; information processing; machine learning; mammography; middle aged; nuclear magnetic resonance imaging; procedures; skin; Magnetic resonance imaging","Wiley Blackwell","00942405","","MPHYA","28035663","Article","Scopus","2-s2.0-85015580937"
"Li H.; Chen J.; Lu H.; Chi Z.","Li, Hongyang (57189660250); Chen, Jiang (57192821957); Lu, Huchuan (8218163400); Chi, Zhizhen (57192586483)","57189660250; 57192821957; 8218163400; 57192586483","CNN for saliency detection with low-level feature integration","2017","Neurocomputing","84","10.1016/j.neucom.2016.11.056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008256639&doi=10.1016%2fj.neucom.2016.11.056&partnerID=40&md5=a2c483b40cdb83394cffe5b2e0a49b4e","The Chinese University of Hong Kong, New Territories, Hong Kong; SAP SE, Beijing, China; Dalian University of Technology, Liaoning, China","Li H., The Chinese University of Hong Kong, New Territories, Hong Kong; Chen J., SAP SE, Beijing, China; Lu H., Dalian University of Technology, Liaoning, China; Chi Z., Dalian University of Technology, Liaoning, China","Feature matters. In this paper, a novel deep neural network framework integrated with low-level features for salient object detection is proposed for complex images. We utilise the advantage of convolutional neural networks to automatically learn the high-level features that capture the structured information and semantic context in the image. In order to better adapt a CNN model into the saliency task, we redesign the network architecture based on typical saliency datasets, which is relatively small-scale compared to ImageNet. Several low-level features are extracted, which can effectively capture contrast and spatial information in the salient regions, and incorporated to compensate with the learned high-level features at the output of the very last fully connected layer. The concatenated feature vector is further fed into a hinge-loss SVM detector in a joint discriminative learning manner and the final saliency score of each region within the bounding box is obtained by the linear combination of the detector's weights. Experiments on three challenging benchmarks demonstrate our algorithm to be effective and superior than most low-level oriented state-of-the-arts in terms of precision-recall curves, F-measure and mean absolute errors. Moreover, a series of ablation studies are conducted to verify our algorithm's simplicity and efficiency from different aspects. © 2016 Elsevier B.V.","Convolutional neural networks; Saliency detection","Complex networks; Convolution; Network architecture; Neural networks; Semantics; Convolutional neural network; Deep neural networks; Discriminative learning; Mean absolute error; Saliency detection; Salient object detection; Spatial informations; Structured information; accuracy; Article; artificial neural network; biotransformation; convolutional neural network; discrimination learning; image analysis; image processing; mathematical parameters; priority journal; probability; quantitative analysis; salience network; support vector machine; Feature extraction","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85008256639"
"Gao M.; Igata H.; Takeuchi A.; Sato K.; Ikegaya Y.","Gao, Mengxuan (57193308865); Igata, Hideyoshi (57130806800); Takeuchi, Aoi (57193309457); Sato, Kaoru (55495488400); Ikegaya, Yuji (7007098841)","57193308865; 57130806800; 57193309457; 55495488400; 7007098841","Machine learning-based prediction of adverse drug effects: An example of seizure-inducing compounds","2017","Journal of Pharmacological Sciences","40","10.1016/j.jphs.2017.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012912643&doi=10.1016%2fj.jphs.2017.01.003&partnerID=40&md5=bcfe177b5db8cf4da7bf0aa95cfc118a","Graduate School of Pharmaceutical Sciences, The University of Tokyo, Tokyo, 113-0033, Japan; iPS-non Clinical Experiments for Nervous System (iNCENS) Project, Japan; Division of Pharmacology, National Institute of Health Sciences, Tokyo, 158-8501, Japan; Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, 565-0871, Japan","Gao M., Graduate School of Pharmaceutical Sciences, The University of Tokyo, Tokyo, 113-0033, Japan, iPS-non Clinical Experiments for Nervous System (iNCENS) Project, Japan; Igata H., Graduate School of Pharmaceutical Sciences, The University of Tokyo, Tokyo, 113-0033, Japan; Takeuchi A., Graduate School of Pharmaceutical Sciences, The University of Tokyo, Tokyo, 113-0033, Japan; Sato K., iPS-non Clinical Experiments for Nervous System (iNCENS) Project, Japan, Division of Pharmacology, National Institute of Health Sciences, Tokyo, 158-8501, Japan; Ikegaya Y., Graduate School of Pharmaceutical Sciences, The University of Tokyo, Tokyo, 113-0033, Japan, iPS-non Clinical Experiments for Nervous System (iNCENS) Project, Japan, Center for Information and Neural Networks, National Institute of Information and Communications Technology, Osaka, 565-0871, Japan","Various biological factors have been implicated in convulsive seizures, involving side effects of drugs. For the preclinical safety assessment of drug development, it is difficult to predict seizure-inducing side effects. Here, we introduced a machine learning-based in vitro system designed to detect seizure-inducing side effects. We recorded local field potentials from the CA1 alveus in acute mouse neocortico-hippocampal slices, while 14 drugs were bath-perfused at 5 different concentrations each. For each experimental condition, we collected seizure-like neuronal activity and merged their waveforms as one graphic image, which was further converted into a feature vector using Caffe, an open framework for deep learning. In the space of the first two principal components, the support vector machine completely separated the vectors (i.e., doses of individual drugs) that induced seizure-like events and identified diphenhydramine, enoxacin, strychnine and theophylline as “seizure-inducing” drugs, which indeed were reported to induce seizures in clinical situations. Thus, this artificial intelligence-based classification may provide a new platform to detect the seizure-inducing side effects of preclinical drugs. © 2017 The Authors","Artificial intelligence; Clinical; Epilepsy; Side effect; Toxicity","Animals; CA1 Region, Hippocampal; Diphenhydramine; Enoxacin; In Vitro Techniques; Male; Mice; Mice, Inbred ICR; Seizures; Strychnine; Support Vector Machine; Theophylline; acetylsalicylic acid; cimetidine; dextran; diazepam; diphenhydramine; enoxacin; ibuprofen; imipramine; isoniazid; ketamine; methamphetamine; metoclopramide; oseltamivir; picrotoxin; strychnine; theophylline; diphenhydramine; enoxacin; strychnine; theophylline; alveus; animal tissue; Article; controlled study; electric potential; hippocampal CA1 region; hippocampal slice; in vitro study; machine learning; male; mouse; nonhuman; prediction; seizure; support vector machine; animal; chemically induced; drug effects; Institute for Cancer Research mouse; seizure; support vector machine","Japanese Pharmacological Society","13478613","","JPSTG","28215473","Article","Scopus","2-s2.0-85012912643"
"Neftci E.O.; Augustine C.; Paul S.; Detorakis G.","Neftci, Emre O. (36444841100); Augustine, Charles (24779266100); Paul, Somnath (57203710705); Detorakis, Georgios (56300810300)","36444841100; 24779266100; 57203710705; 56300810300","Event-driven random back-propagation: Enabling neuromorphic deep learning machines","2017","Frontiers in Neuroscience","185","10.3389/fnins.2017.00324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021217191&doi=10.3389%2ffnins.2017.00324&partnerID=40&md5=f8998a1dcc8744d86a93e06a8ef80939","Neuromorphic Machine Intelligence Laboratory, Department of Cognitive Sciences, University of California, Irvine, Irvine, CA, United States; Circuit Research Lab, Intel Corporation, Hilsboro, OR, United States","Neftci E.O., Neuromorphic Machine Intelligence Laboratory, Department of Cognitive Sciences, University of California, Irvine, Irvine, CA, United States; Augustine C., Circuit Research Lab, Intel Corporation, Hilsboro, OR, United States; Paul S., Circuit Research Lab, Intel Corporation, Hilsboro, OR, United States; Detorakis G., Neuromorphic Machine Intelligence Laboratory, Department of Cognitive Sciences, University of California, Irvine, Irvine, CA, United States","An ongoing challenge in neuromorphic computing is to devise general and computationally efficient models of inference and learning which are compatible with the spatial and temporal constraints of the brain. One increasingly popular and successful approach is to take inspiration from inference and learning algorithms used in deep neural networks. However, the workhorse of deep learning, the gradient descent Gradient Back Propagation (BP) rule, often relies on the immediate availability of network-wide information stored with high-precision memory during learning, and precise operations that are difficult to realize in neuromorphic hardware. Remarkably, recent work showed that exact backpropagated gradients are not essential for learning deep representations. Building on these results, we demonstrate an event-driven random BP (eRBP) rule that uses an error-modulated synaptic plasticity for learning deep representations. Using a two-compartment Leaky Integrate & Fire (I&F) neuron, the rule requires only one addition and two comparisons for each synaptic weight, making it very suitable for implementation in digital or mixed-signal neuromorphic hardware. Our results show that using eRBP, deep representations are rapidly learned, achieving classification accuracies on permutation invariant datasets comparable to those obtained in artificial neural network simulations on GPUs, while being robust to neural and synaptic state quantizations during learning. © 2017 Neftci, Augustine, Paul and Detorakis.","Backpropagation algorithm; Embedded cognition; Feedback alignment; Spiking neural networks; Stochastic processes","artificial neural network; back propagation; classification; machine learning; Markov chain; nerve cell plasticity; simulation","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-85021217191"
"Cunningham R.J.; Harding P.J.; Loram I.D.","Cunningham, Ryan J. (15623049400); Harding, Peter J. (55613468600); Loram, Ian D. (6507540900)","15623049400; 55613468600; 6507540900","Real-Time Ultrasound Segmentation, Analysis and Visualisation of Deep Cervical Muscle Structure","2017","IEEE Transactions on Medical Imaging","30","10.1109/TMI.2016.2623819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012226043&doi=10.1109%2fTMI.2016.2623819&partnerID=40&md5=722da3c5dede13e92a157c07178c7353","Manchester Metropolitan University, Manchester, M1 5GD, United Kingdom; School of Healthcare Science, Cognitive Motor Function Research Group, John Dalton Building Manchester Metropolitan University, Manchester, M1 5GD, United Kingdom","Cunningham R.J., Manchester Metropolitan University, Manchester, M1 5GD, United Kingdom, School of Healthcare Science, Cognitive Motor Function Research Group, John Dalton Building Manchester Metropolitan University, Manchester, M1 5GD, United Kingdom; Harding P.J., Manchester Metropolitan University, Manchester, M1 5GD, United Kingdom, School of Healthcare Science, Cognitive Motor Function Research Group, John Dalton Building Manchester Metropolitan University, Manchester, M1 5GD, United Kingdom; Loram I.D., Manchester Metropolitan University, Manchester, M1 5GD, United Kingdom, School of Healthcare Science, Cognitive Motor Function Research Group, John Dalton Building Manchester Metropolitan University, Manchester, M1 5GD, United Kingdom","Despite widespread availability of ultrasound and a need for personalised muscle diagnosis (neck/back pain-injury, work related disorder, myopathies, neuropathies), robust, online segmentation of muscles within complex groups remains unsolved by existing methods. For example, Cervical Dystonia (CD) is a prevalent neurological condition causing painful spasticity in one or multiple muscles in the cervical muscle system. Clinicians currently have no method for targeting/monitoring treatment of deep muscles. Automated methods of muscle segmentation would enable clinicians to study, target, and monitor the deep cervical muscles via ultrasound. We have developed a method for segmenting five bilateral cervical muscles and the spine via ultrasound alone, in real-time. Magnetic Resonance Imaging (MRI) and ultrasound data were collected from 22 participants (age: 29.0±6.6, male: 12). To acquire ultrasound muscle segment labels, a novel multimodal registration method was developed, involving MRI image annotation, and shape registration to MRI-matched ultrasound images, via approximation of the tissue deformation. We then applied polynomial regression to transform our annotations and textures into a mean space, before using shape statistics to generate a texture-to-shape dictionary. For segmentation, test images were compared to dictionary textures giving an initial segmentation, and then we used a customized Active Shape Model to refine the fit. Using ultrasound alone, on unseen participants, our technique currently segments a single image in ∼ 0.45s to over 86% accuracy (Jaccard index). We propose this approach is applicable generally to segment, extrapolate and visualise deep muscle structure, and analyse statistical features online. © 2016 IEEE.","Cervical dystonia; electromyography; generative shape model; MRI; multifidus; pattern recognition; rotatores; segmentation; semispinalis; shape model; skeletal muscle; splenius; trapezius; ultrasound","Adult; Algorithms; Female; Humans; Magnetic Resonance Imaging; Male; Muscle, Skeletal; Neck; Spine; Ultrasonography; Electromyography; Magnetic resonance imaging; Muscle; Pattern recognition; Ultrasonic applications; Ultrasonics; cod liver oil; Cervical dystonia; multifidus; rotatores; semispinalis; Shape model; Skeletal muscle; splenius; trapezius; adult; Article; cervical dystonia; clinical article; cross-sectional study; diagnostic imaging; female; human; image analysis; image quality; image segmentation; machine learning; male; neck muscle; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; pattern recognition; real time echography; soft tissue; spasticity; trapezius muscle; algorithm; echography; neck; nuclear magnetic resonance imaging; skeletal muscle; spine; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","27831867","Article","Scopus","2-s2.0-85012226043"
"Li L.; Zheng J.; Wan J.","Li, Lishuang (8985775300); Zheng, Jieqiong (56515719600); Wan, Jia (57193354052)","8985775300; 56515719600; 57193354052","Dynamic extended tree conditioned LSTM-based biomedical event extraction","2017","International Journal of Data Mining and Bioinformatics","8","10.1504/IJDMB.2017.085283","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026229480&doi=10.1504%2fIJDMB.2017.085283&partnerID=40&md5=08cf697ebb510bd15f644ba4fad2a318","School of Computer Science and Technology, Dalian University of Technology, No. 2, Linggong Road, Hi-Tech Zone, Dalian, 116024, China","Li L., School of Computer Science and Technology, Dalian University of Technology, No. 2, Linggong Road, Hi-Tech Zone, Dalian, 116024, China; Zheng J., School of Computer Science and Technology, Dalian University of Technology, No. 2, Linggong Road, Hi-Tech Zone, Dalian, 116024, China; Wan J., School of Computer Science and Technology, Dalian University of Technology, No. 2, Linggong Road, Hi-Tech Zone, Dalian, 116024, China","Extracting knowledge from unstructured text has become essential to the text mining and knowledge discovery tasks in biomedical field. In this paper, we propose a novel Long Short Term Memory (LSTM) networks framework DET-BLSTM to extract biomedical events among biotope and bacteria from biomedical literature. In our framework, a dynamic extended tree is introduced as the input instead of the original sentences, which utilises the syntactic information. Furthermore, the POS and distance embeddings are added to enrich input information. In final, considering that shallow machine learning methods can effectively take advantage of the domain expert experience, the predictions of SVM are used for post-processing. Our DETBLSTM model with post-processing achieves 58.09% F-score in the test set, which is better than all official submissions to BioNLP-ST 2016 and 2.29% higher than the best system. © 2017 Inderscience Enterprises Ltd.","Biomedical event extraction; Deep learning; Dynamic extended tree; Long short term memory; SVM","biotope; embedding; extract; extraction; human; human experiment; machine learning; model; prediction; short term memory","Inderscience Publishers","17485673","","","","Article","Scopus","2-s2.0-85026229480"
"Xu J.; Xu B.; Wang P.; Zheng S.; Tian G.; Zhao J.; Xu B.","Xu, Jiaming (55898934000); Xu, Bo (56424377800); Wang, Peng (56192920100); Zheng, Suncong (55838664300); Tian, Guanhua (56403942200); Zhao, Jun (57190004147); Xu, Bo (37022633100)","55898934000; 56424377800; 56192920100; 55838664300; 56403942200; 57190004147; 37022633100","Self-Taught convolutional neural networks for short text clustering","2017","Neural Networks","174","10.1016/j.neunet.2016.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011067310&doi=10.1016%2fj.neunet.2016.12.008&partnerID=40&md5=31ee3d3712ff61177324f3b1f72c5c2a","Institute of Automation, Chinese Academy of Sciences (CAS), Beijing, China; National Laboratory of Pattern Recognition (NLPR), Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, CAS, China","Xu J., Institute of Automation, Chinese Academy of Sciences (CAS), Beijing, China; Xu B., Institute of Automation, Chinese Academy of Sciences (CAS), Beijing, China; Wang P., Institute of Automation, Chinese Academy of Sciences (CAS), Beijing, China; Zheng S., Institute of Automation, Chinese Academy of Sciences (CAS), Beijing, China; Tian G., Institute of Automation, Chinese Academy of Sciences (CAS), Beijing, China; Zhao J., Institute of Automation, Chinese Academy of Sciences (CAS), Beijing, China, National Laboratory of Pattern Recognition (NLPR), Beijing, China; Xu B., Institute of Automation, Chinese Academy of Sciences (CAS), Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, CAS, China","Short text clustering is a challenging problem due to its sparseness of text representation. Here we propose a flexible Self-Taught Convolutional neural network framework for Short Text Clustering (dubbed STC2), which can flexibly and successfully incorporate more useful semantic features and learn non-biased deep text representation in an unsupervised manner. In our framework, the original raw text features are firstly embedded into compact binary codes by using one existing unsupervised dimensionality reduction method. Then, word embeddings are explored and fed into convolutional neural networks to learn deep feature representations, meanwhile the output units are used to fit the pre-trained binary codes in the training process. Finally, we get the optimal clusters by employing K-means to cluster the learned representations. Extensive experimental results demonstrate that the proposed framework is effective, flexible and outperform several popular clustering methods when tested on three public short text datasets. © 2017 Elsevier Ltd","Neural networks; Semantic clustering; Short text; Unsupervised learning","Cluster Analysis; Data Mining; Humans; Neural Networks (Computer); Binary codes; Bins; Cluster analysis; Convolution; Neural networks; Semantics; Unsupervised learning; Clustering methods; Convolutional neural network; Dimensionality reduction method; Feature representation; Semantic clustering; Semantic features; Short texts; Text representation; accuracy; Article; artificial neural network; classification; cluster analysis; intermethod comparison; K means analysis; machine learning; mathematical computing; mathematical model; process development; reproducibility; self taught convolutional neural network; short text clustering; social media; text messaging; data mining; human; procedures; Deep neural networks","Elsevier Ltd","08936080","","NNETE","28157556","Article","Scopus","2-s2.0-85011067310"
"Ho K.C.; Speier W.; El-Saden S.; Arnold C.W.","Ho, King Chung (57194193885); Speier, William (36870001000); El-Saden, Suzie (35508689700); Arnold, Corey W. (18436092400)","57194193885; 36870001000; 35508689700; 18436092400","Classifying Acute Ischemic Stroke Onset Time using Deep Imaging Features","2017","AMIA ... Annual Symposium proceedings. AMIA Symposium","46","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056255365&partnerID=40&md5=919c4f748206818d0cb58901a9c284d6","Department of Bioengineering; University of California, Los Angeles, CA; Medical Imaging Informatics; University of California, Los Angeles, CA; Department of Radiological Sciences, University of California, Los Angeles, CA, United States","Ho K.C., Department of Bioengineering; University of California, Los Angeles, CA, Medical Imaging Informatics; University of California, Los Angeles, CA; Speier W., Medical Imaging Informatics; University of California, Los Angeles, CA; El-Saden S., Medical Imaging Informatics; University of California, Los Angeles, CA; Arnold C.W., Department of Bioengineering; University of California, Los Angeles, CA, Medical Imaging Informatics; University of California, Los Angeles, CA, Department of Radiological Sciences, University of California, Los Angeles, CA, United States","Models have been developed to predict stroke outcomes (e.g., mortality) in attempt to provide better guidance for stroke treatment. However, there is little work in developing classification models for the problem of unknown time-since-stroke (TSS), which determines a patient's treatment eligibility based on a clinical defined cutoff time point (i.e., <4.5hrs). In this paper, we construct and compare machine learning methods to classify TSS<4.5hrs using magnetic resonance (MR) imaging features. We also propose a deep learning model to extract hidden representations from the MR perfusion-weighted images and demonstrate classification improvement by incorporating these additional imaging features. Finally, we discuss a strategy to visualize the learned features from the proposed deep learning model. The cross-validation results show that our best classifier achieved an area under the curve of 0.68, which improves significantly over current clinical methods (0.58), demonstrating the potential benefit of using advanced machine learning methods in TSS classification.","","Aged; Area Under Curve; Brain Ischemia; Deep Learning; Female; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Middle Aged; Prognosis; Regression Analysis; ROC Curve; Sensitivity and Specificity; Stroke; Support Vector Machine; aged; area under the curve; brain ischemia; cerebrovascular accident; comparative study; diagnostic imaging; female; human; machine learning; male; middle aged; nuclear magnetic resonance imaging; prognosis; receiver operating characteristic; regression analysis; sensitivity and specificity; support vector machine","NLM (Medline)","1942597X","","","29854156","Article","Scopus","2-s2.0-85056255365"
"Lu F.; Wu F.; Hu P.; Peng Z.; Kong D.","Lu, Fang (56471118900); Wu, Fa (55820004700); Hu, Peijun (56957586500); Peng, Zhiyi (56307402500); Kong, Dexing (7202350810)","56471118900; 55820004700; 56957586500; 56307402500; 7202350810","Automatic 3D liver location and segmentation via convolutional neural network and graph cut","2017","International Journal of Computer Assisted Radiology and Surgery","239","10.1007/s11548-016-1467-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986243843&doi=10.1007%2fs11548-016-1467-3&partnerID=40&md5=74e2494c12dee89048afe161f4ddd943","School of Mathematical Sciences, Zhejiang University, Hangzhou, 310027, China; Department of Radiology, First Affiliated Hospital of Zhejiang University, Hangzhou, 310003, China","Lu F., School of Mathematical Sciences, Zhejiang University, Hangzhou, 310027, China; Wu F., School of Mathematical Sciences, Zhejiang University, Hangzhou, 310027, China; Hu P., School of Mathematical Sciences, Zhejiang University, Hangzhou, 310027, China; Peng Z., Department of Radiology, First Affiliated Hospital of Zhejiang University, Hangzhou, 310003, China; Kong D., School of Mathematical Sciences, Zhejiang University, Hangzhou, 310027, China","Purpose: Segmentation of the liver from abdominal computed tomography (CT) images is an essential step in some computer-assisted clinical interventions, such as surgery planning for living donor liver transplant, radiotherapy and volume measurement. In this work, we develop a deep learning algorithm with graph cut refinement to automatically segment the liver in CT scans. Methods: The proposed method consists of two main steps: (i) simultaneously liver detection and probabilistic segmentation using 3D convolutional neural network; (ii) accuracy refinement of the initial segmentation with graph cut and the previously learned probability map. Results: The proposed approach was validated on forty CT volumes taken from two public databases MICCAI-Sliver07 and 3Dircadb1. For the MICCAI-Sliver07 test dataset, the calculated mean ratios of volumetric overlap error (VOE), relative volume difference (RVD), average symmetric surface distance (ASD), root-mean-square symmetric surface distance (RMSD) and maximum symmetric surface distance (MSD) are 5.9, 2.7 %, 0.91, 1.88 and 18.94 mm, respectively. For the 3Dircadb1 dataset, the calculated mean ratios of VOE, RVD, ASD, RMSD and MSD are 9.36, 0.97 %, 1.89, 4.15 and 33.14 mm, respectively. Conclusions: The proposed method is fully automatic without any user interaction. Quantitative results reveal that the proposed approach is efficient and accurate for hepatic volume estimation in a clinical setup. The high correlation between the automatic and manual references shows that the proposed method can be good enough to replace the time-consuming and nonreproducible manual segmentation method. © 2016, CARS.","3D convolution neural network; CT images; Graph cut; Liver segmentation","Abdomen; Algorithms; Databases, Factual; Humans; Imaging, Three-Dimensional; Liver; Neural Networks (Computer); Organ Size; Tomography, X-Ray Computed; Article; average symmetric surface distance; computer assisted tomography; convolutional neural network; graph cut; hepatography; human; image segmentation; learning algorithm; machine learning; maximum symmetric surface distance; priority journal; radiological parameters; relative volume difference; root mean square symmetric surface distance; three dimensional imaging; volumetric overlap error; abdomen; algorithm; artificial neural network; diagnostic imaging; factual database; liver; organ size; procedures; three dimensional imaging; x-ray computed tomography","Springer Verlag","18616410","","","27604760","Article","Scopus","2-s2.0-84986243843"
"Sun Y.; Liu Y.; Wang G.; Zhang H.","Sun, Yu (56176987100); Liu, Yuan (57192568038); Wang, Guan (57194706582); Zhang, Haiyan (57192238143)","56176987100; 57192568038; 57194706582; 57192238143","Deep Learning for Plant Identification in Natural Environment","2017","Computational Intelligence and Neuroscience","201","10.1155/2017/7361042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021748295&doi=10.1155%2f2017%2f7361042&partnerID=40&md5=9d287ef972676888a330c259a44e822a","School of Information Science and Technology, Beijing Forestry University, Beijing, 100083, China","Sun Y., School of Information Science and Technology, Beijing Forestry University, Beijing, 100083, China; Liu Y., School of Information Science and Technology, Beijing Forestry University, Beijing, 100083, China; Wang G., School of Information Science and Technology, Beijing Forestry University, Beijing, 100083, China; Zhang H., School of Information Science and Technology, Beijing Forestry University, Beijing, 100083, China","Plant image identification has become an interdisciplinary focus in both botanical taxonomy and computer vision. The first plant image dataset collected by mobile phone in natural scene is presented, which contains 10,000 images of 100 ornamental plant species in Beijing Forestry University campus. A 26-layer deep learning model consisting of 8 residual building blocks is designed for large-scale plant classification in natural environment. The proposed model achieves a recognition rate of 91.78% on the BJFU100 dataset, demonstrating that deep learning is a promising technology for smart forestry. © 2017 Yu Sun et al.","","Cell Phone; China; Classification; Datasets as Topic; Environment; Forestry; Machine Learning; Photography; Plants; Universities; Education; Forestry; Timber; Building blockes; Image identification; Learning models; Natural environments; Ornamental plants; Plant classification; Plant identification; University campus; China; classification; environment; forestry; information processing; machine learning; mobile phone; photography; plant; procedures; university; Deep learning","Hindawi Limited","16875265","","","28611840","Article","Scopus","2-s2.0-85021748295"
"Xue-juan C.; Xiang W.; Zhong-qiang Y.; Xiang C.; Yu-wu Z.; Chun-xiang C.","Xue-juan, Chen (57193827601); Xiang, Wu (57193826624); Zhong-qiang, Yuan (57193826778); Xiang, Chen (57193832343); Yu-wu, Zhang (57193831974); Chun-xiang, Cao (57193827846)","57193827601; 57193826624; 57193826778; 57193832343; 57193831974; 57193827846","Spectral characteristics and species identification of rhododendrons using a discriminative restricted Boltzmann machine","2017","Spectroscopy Letters","4","10.1080/00387010.2017.1278709","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016956939&doi=10.1080%2f00387010.2017.1278709&partnerID=40&md5=664fbd998aec8cd05ae79343fe0f4481","State Key Laboratory of Remote Sensing Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Resources and Environment, University of Electronic Science and Technology of China (UESTC), Chengdu, China; Institute of Biology, Guizhou Academy of Sciences, Guiyang, China","Xue-juan C., State Key Laboratory of Remote Sensing Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Xiang W., Institute of Automation, Chinese Academy of Sciences, Beijing, China; Zhong-qiang Y., School of Resources and Environment, University of Electronic Science and Technology of China (UESTC), Chengdu, China; Xiang C., Institute of Biology, Guizhou Academy of Sciences, Guiyang, China; Yu-wu Z., Institute of Biology, Guizhou Academy of Sciences, Guiyang, China; Chun-xiang C., State Key Laboratory of Remote Sensing Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China","Rhododendrons are an important genus of alpine flowering plant used ornamentally worldwide. The purpose of this study is to improve the application of remote-sensing technology for investigating and monitoring mountain rhododendron germplasm. Research area is the Baili Rhododendron National Forest Park located in the karst region of Guizhou Province, China. Field spectrometry was used to acquire spectral data for 20 samples extracted from eight rhododendron species. A deep-learning algorithm from a discriminative restricted Boltzmann machine was used with the original spectral data from the different rhododendron species to obtain the optimal parameters for the model. Simultaneously, the data processing methodology from the discriminative restricted Boltzmann machine was used to recognize the original spectra, the noise smoothed spectra, and the first- and second-order spectral derivatives with accuracies of 88.54%, 88.54%, 93.75%, and 90.62%, respectively. The results show that the discriminative restricted Boltzmann machine is effective in recognizing spectral information for different rhododendron species. Changes in the first-order derivative gave the most accurate classification, but changes in the second-order derivative significantly reduced the sample training time. Changes in both derivatives therefore proved useful in recognizing and extracting particular features of the plant species. This research may therefore further support the use of hyperspectral remote-sensing imagery for investigating and monitoring germplasm, species classification, and physiological parameter inversions for rhododendrons from various mountain regions of China. © 2017 Taylor & Francis.","Discriminative restricted Boltzmann machine; rhododendron; spectral recognition; vegetation spectrum","","Taylor and Francis Inc.","00387010","","SPLEB","","Article","Scopus","2-s2.0-85016956939"
"Ohno M.; Kimura D.; Matsuura K.","Ohno, Munekazu (7402908510); Kimura, Daichi (57198812698); Matsuura, Kiyotaka (35445942800)","7402908510; 57198812698; 35445942800","Prediction of microsegregation behavior in fe-based alloys based on machine learning","2017","Tetsu-To-Hagane/Journal of the Iron and Steel Institute of Japan","4","10.2355/tetsutohagane.TETSU-2017-028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037132227&doi=10.2355%2ftetsutohagane.TETSU-2017-028&partnerID=40&md5=431347aa7ab1db18751829ef353025a0","Faculty of Engineering, Hokkaido University, Kita 13 Nishi 8, Kita-ku Sapporo Hokkaido, 060-8628, Japan; Graduate School of Engineering, Hokkaido University, Now NTT Communications Corporation, Japan","Ohno M., Faculty of Engineering, Hokkaido University, Kita 13 Nishi 8, Kita-ku Sapporo Hokkaido, 060-8628, Japan; Kimura D., Graduate School of Engineering, Hokkaido University, Now NTT Communications Corporation, Japan; Matsuura K., Faculty of Engineering, Hokkaido University, Kita 13 Nishi 8, Kita-ku Sapporo Hokkaido, 060-8628, Japan","Synopsis: A prediction method for microsegregation in Fe-based alloys was developed based on an approach of machine learning called Deep Learning. A set of model and algorithm of Deep Learning suitable for description of microsegregation was constructed by employing training data obtained by one-dimensional finite difference calculations for interdendritic microsegregation. It is shown that the developed method enables accurate prediction of the microsegregation behavior in Fe-based binary and ternary alloys with the solute atoms of C, Si, Mn, P and S. The present results demonstrate that Deep Learning offers a promising way of constructing an easy-To-use approach for prediction of microsegregation with high accuracy. Importantly, it is expected that the present method can be extended to describe effects of microstructural processes on microsegregation behavior.","Casting; Deep learning; Microsegregation; Simulation.; Solidification","Artificial intelligence; Binary alloys; Casting; Deep learning; Forecasting; Iron alloys; Learning systems; Manganese; Solidification; Ternary alloys; Accurate prediction; Fe-based alloys; Finite difference calculations; Micro-segregation; Micro-structural; Model and algorithms; Prediction methods; Simulation; Segregation (metallography)","Iron and Steel Institute of Japan","00211575","","TEHAA","","Article","Scopus","2-s2.0-85037132227"
"Wang C.; Elazab A.; Wu J.; Hu Q.","Wang, Changmiao (57226651647); Elazab, Ahmed (56523141500); Wu, Jianhuang (9746889000); Hu, Qingmao (7403214583)","57226651647; 56523141500; 9746889000; 7403214583","Lung nodule classification using deep feature fusion in chest radiography","2017","Computerized Medical Imaging and Graphics","99","10.1016/j.compmedimag.2016.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008152020&doi=10.1016%2fj.compmedimag.2016.11.004&partnerID=40&md5=af53e46097e222f608512494952bfe7b","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Boulevard, Shenzhen, 518055, China; University of Chinese Academy of Sciences, 52 Sanlihe Road, Beijing, 100864, China; Key Laboratory of Human-Machine Intelligence Synergy Systems, 1068 Xueyuan Boulevard, Shenzhen, 518055, China","Wang C., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Boulevard, Shenzhen, 518055, China, University of Chinese Academy of Sciences, 52 Sanlihe Road, Beijing, 100864, China; Elazab A., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Boulevard, Shenzhen, 518055, China, University of Chinese Academy of Sciences, 52 Sanlihe Road, Beijing, 100864, China; Wu J., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Boulevard, Shenzhen, 518055, China; Hu Q., Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, 1068 Xueyuan Boulevard, Shenzhen, 518055, China, Key Laboratory of Human-Machine Intelligence Synergy Systems, 1068 Xueyuan Boulevard, Shenzhen, 518055, China","Lung nodules are small, round, or oval-shaped masses of tissue in the lung region. Early diagnosis and treatment of lung nodules can significantly improve the quality of patients’ lives. Because of their small size and the interlaced nature of chest anatomy, detection of lung nodules using different medical imaging techniques becomes challenging. Recently, several methods for computer aided diagnosis (CAD) were proposed to improve the detection of lung nodules with good performances. However, the current methods are unable to achieve high sensitivity and high specificity. In this paper, we propose using deep feature fusion from the non-medical training and hand-crafted features to reduce the false positive results. Based on our experimentation of the public dataset, our results show that, the deep fusion feature can achieve promising results in terms of sensitivity and specificity (69.3% and 96.2%) at 1.19 false positive per image, which is better than the single hand-crafted features (62% and 95.4%) at 1.45 false positive per image. As it stands, fusion features that were used to classify our candidate nodules have resulted in a more promising outcome as compared to the single features from deep learning features and the hand-crafted features. This will improve the current CAD method based on the use of deep feature fusion to more effectively diagnose the presence of lung nodules. © 2016 Elsevier Ltd","Computer aided diagnosis; Deep learning; Feature fusion; Lung nodule","False Positive Reactions; Humans; Lung; Lung Neoplasms; Machine Learning; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Sensitivity and Specificity; Biological organs; Computer aided diagnosis; Computer aided instruction; Diagnosis; Imaging techniques; Medical imaging; Patient treatment; Chest radiography; Computer Aided Diagnosis(CAD); Deep learning; Detection of lung nodules; Feature fusion; High sensitivity; Lung nodule; Sensitivity and specificity; Article; computer assisted diagnosis; controlled study; deep feature fusion; disease classification; false positive result; human; image analysis; image processing; lung nodule; machine learning; major clinical study; priority journal; random forest; sensitivity and specificity; thorax radiography; x-ray computed tomography; classification; computer assisted diagnosis; diagnostic imaging; lung; lung tumor; pathology; procedures; thorax radiography; Classification (of information)","Elsevier Ltd","08956111","","CMIGE","27986379","Article","Scopus","2-s2.0-85008152020"
"Sun W.; Tseng T.-L.B.; Zhang J.; Qian W.","Sun, Wenqing (56091845500); Tseng, Tzu-Liang Bill (23393519800); Zhang, Jianying (55597909500); Qian, Wei (36842193500)","56091845500; 23393519800; 55597909500; 36842193500","Enhancing deep convolutional neural network scheme for breast cancer diagnosis with unlabeled data","2017","Computerized Medical Imaging and Graphics","205","10.1016/j.compmedimag.2016.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997173216&doi=10.1016%2fj.compmedimag.2016.07.004&partnerID=40&md5=2ac5b3e5c4c1f965cae5956dc7e188a9","Department of Electrical and Computer Engineering, University of Texas at El Paso, 500 West University Avenue, El Paso, 79968, TX, United States; Department of Industrial, Manufacturing & Systems Engineering, University of Texas at El Paso, 500 West University Avenue, El Paso, 79968, TX, United States; Department of Biological Sciences, University of Texas at El Paso, 500 West University Avenue, El Paso, 9968, TX, United States; Sino-Dutch Biomedical and Information Engineering School, Northeastern University, No. 11, Lane 3, Wenhua Road, Heping District, Shenyang, 10819, Liaoning, China","Sun W., Department of Electrical and Computer Engineering, University of Texas at El Paso, 500 West University Avenue, El Paso, 79968, TX, United States; Tseng T.-L.B., Department of Industrial, Manufacturing & Systems Engineering, University of Texas at El Paso, 500 West University Avenue, El Paso, 79968, TX, United States; Zhang J., Department of Biological Sciences, University of Texas at El Paso, 500 West University Avenue, El Paso, 9968, TX, United States, Sino-Dutch Biomedical and Information Engineering School, Northeastern University, No. 11, Lane 3, Wenhua Road, Heping District, Shenyang, 10819, Liaoning, China; Qian W., Department of Electrical and Computer Engineering, University of Texas at El Paso, 500 West University Avenue, El Paso, 79968, TX, United States, Sino-Dutch Biomedical and Information Engineering School, Northeastern University, No. 11, Lane 3, Wenhua Road, Heping District, Shenyang, 10819, Liaoning, China","In this study we developed a graph based semi-supervised learning (SSL) scheme using deep convolutional neural network (CNN) for breast cancer diagnosis. CNN usually needs a large amount of labeled data for training and fine tuning the parameters, and our proposed scheme only requires a small portion of labeled data in training set. Four modules were included in the diagnosis system: data weighing, feature selection, dividing co-training data labeling, and CNN. 3158 region of interests (ROIs) with each containing a mass extracted from 1874 pairs of mammogram images were used for this study. Among them 100 ROIs were treated as labeled data while the rest were treated as unlabeled. The area under the curve (AUC) observed in our study was 0.8818, and the accuracy of CNN is 0.8243 using the mixed labeled and unlabeled data. © 2016","Computer aided diagnosis; Convolutional neural network; Deep learning; Semi-supervised learning; Unlabeled data","Adult; Aged; Area Under Curve; Breast Neoplasms; Diagnosis, Computer-Assisted; Female; Humans; Mammography; Middle Aged; Neural Networks (Computer); Supervised Machine Learning; Computer aided instruction; Convolution; Diseases; Graphic methods; Neural networks; Supervised learning; Area under the curves; Breast cancer diagnosis; Convolutional neural network; Deep learning; Labeled and unlabeled data; Semi- supervised learning; Semi-supervised learning (SSL); Unlabeled data; adult; aged; Article; artificial neural network; breast cancer; cancer diagnosis; comparative study; deep convolutional neural network; diagnostic accuracy; digital mammography; human; image analysis; learning algorithm; major clinical study; priority journal; sensitivity and specificity; support vector machine; area under the curve; breast tumor; computer assisted diagnosis; diagnostic imaging; female; mammography; middle aged; pathology; procedures; supervised machine learning; Computer aided diagnosis","Elsevier Ltd","08956111","","CMIGE","27475279","Article","Scopus","2-s2.0-84997173216"
"Zou X.; Wang G.; Yu G.","Zou, Xianchun (26322935300); Wang, Guijun (57193409727); Yu, Guoxian (35175184400)","26322935300; 57193409727; 35175184400","Protein Function Prediction Using Deep Restricted Boltzmann Machines","2017","BioMed Research International","10","10.1155/2017/1729301","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023602064&doi=10.1155%2f2017%2f1729301&partnerID=40&md5=8bb578e3293cc4c7799b577001dd4baa","College of Computer and Information Science, Southwest University, Chongqing, China","Zou X., College of Computer and Information Science, Southwest University, Chongqing, China; Wang G., College of Computer and Information Science, Southwest University, Chongqing, China; Yu G., College of Computer and Information Science, Southwest University, Chongqing, China","Accurately annotating biological functions of proteins is one of the key tasks in the postgenome era. Many machine learning based methods have been applied to predict functional annotations of proteins, but this task is rarely solved by deep learning techniques. Deep learning techniques recently have been successfully applied to a wide range of problems, such as video, images, and nature language processing. Inspired by these successful applications, we investigate deep restricted Boltzmann machines (DRBM), a representative deep learning technique, to predict the missing functional annotations of partially annotated proteins. Experimental results on Homo sapiens, Saccharomyces cerevisiae, Mus musculus, and Drosophila show that DRBM achieves better performance than other related methods across different evaluation metrics, and it also runs faster than these comparing methods. © 2017 Xianchun Zou et al.","","Algorithms; Animals; Computational Biology; Databases, Protein; Drosophila; Gene Ontology; Humans; Mice; Molecular Sequence Annotation; Proteins; Saccharomyces cerevisiae; Statistics as Topic; protein; controlled study; Drosophila; experimental model; human; learning; machine; mouse; Mus musculus; nonhuman; prediction; protein function; Saccharomyces cerevisiae; algorithm; animal; biology; gene ontology; metabolism; molecular genetics; procedures; protein database; statistics","Hindawi Limited","23146133","","","28744460","Article","Scopus","2-s2.0-85023602064"
"Hughes M.; Li I.; Kotoulas S.; Suzumura T.","Hughes, Mark (57194128758); Li, Irene (57207861716); Kotoulas, Spyros (16238993900); Suzumura, Toyotaro (6603022117)","57194128758; 57207861716; 16238993900; 6603022117","Medical Text Classification Using Convolutional Neural Networks","2017","Studies in Health Technology and Informatics","162","10.3233/978-1-61499-753-5-246","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018829622&doi=10.3233%2f978-1-61499-753-5-246&partnerID=40&md5=088023eb6941c46d6784c6fb1f6d8681","IBM Research Lab, 7 Hanover Quay, Dublin, Ireland; Japan Science and Technology Agency, Tokyo, Japan; IBM TJ Watson Research Center, New York, United States","Hughes M., IBM Research Lab, 7 Hanover Quay, Dublin, Ireland, Japan Science and Technology Agency, Tokyo, Japan; Li I., IBM Research Lab, 7 Hanover Quay, Dublin, Ireland; Kotoulas S., Japan Science and Technology Agency, Tokyo, Japan, IBM TJ Watson Research Center, New York, United States; Suzumura T., IBM Research Lab, 7 Hanover Quay, Dublin, Ireland","We present an approach to automatically classify clinical text at a sentence level. We are using deep convolutional neural networks to represent complex features. We train the network on a dataset providing a broad categorization of health information. Through a detailed evaluation, we demonstrate that our method outperforms several approaches widely used in natural language processing tasks by about 15%. © 2017 European Federation for Medical Informatics (EFMI) and IOS Press.","Clinical text; convolutional neural network; semantic clinical classification; sentence classification","Machine Learning; Natural Language Processing; Neural Networks (Computer); Semantics; clinical classification; human; human experiment; medical information; natural language processing; nervous system; artificial neural network; machine learning; natural language processing; semantics","IOS Press","09269630","978-161499752-8","","28423791","Article","Scopus","2-s2.0-85018829622"
"Long N.P.; Jung K.H.; Yoon S.J.; Anh N.H.; Nghi T.D.; Kang Y.P.; Yan H.H.; Min J.E.; Hong S.-S.; Kwon S.W.","Long, Nguyen Phuoc (57678369800); Jung, Kyung Hee (15845471700); Yoon, Sang Jun (56912647000); Anh, Nguyen Hoang (56386977000); Nghi, Tran Diem (56387425000); Kang, Yun Pyo (57208558215); Yan, Hong Hua (55509591800); Min, Jung Eun (57146192800); Hong, Soon-Sun (35731187900); Kwon, Sung Won (7102749488)","57678369800; 15845471700; 56912647000; 56386977000; 56387425000; 57208558215; 55509591800; 57146192800; 35731187900; 7102749488","Systematic assessment of cervical cancer initiation and progression uncovers genetic panels for deep learning-based early diagnosis and proposes novel diagnostic and prognostic biomarkers","2017","Oncotarget","34","10.18632/oncotarget.22689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037676482&doi=10.18632%2foncotarget.22689&partnerID=40&md5=0d48c36a96884454b94b1c2987da8f00","College of Pharmacy, Seoul National University, Seoul, 08826, South Korea; Department of Drug Development, College of Medicine, Inha University, Incheon, 22212, South Korea; School of Medicine, Vietnam National University, Ho Chi Minh, 70000, Viet Nam; Research Institute of Pharmaceutical Sciences, Seoul National University, Seoul, 08826, South Korea","Long N.P., College of Pharmacy, Seoul National University, Seoul, 08826, South Korea; Jung K.H., Department of Drug Development, College of Medicine, Inha University, Incheon, 22212, South Korea; Yoon S.J., College of Pharmacy, Seoul National University, Seoul, 08826, South Korea; Anh N.H., School of Medicine, Vietnam National University, Ho Chi Minh, 70000, Viet Nam; Nghi T.D., School of Medicine, Vietnam National University, Ho Chi Minh, 70000, Viet Nam; Kang Y.P., College of Pharmacy, Seoul National University, Seoul, 08826, South Korea; Yan H.H., Department of Drug Development, College of Medicine, Inha University, Incheon, 22212, South Korea; Min J.E., College of Pharmacy, Seoul National University, Seoul, 08826, South Korea; Hong S.-S., Department of Drug Development, College of Medicine, Inha University, Incheon, 22212, South Korea; Kwon S.W., College of Pharmacy, Seoul National University, Seoul, 08826, South Korea, Research Institute of Pharmaceutical Sciences, Seoul National University, Seoul, 08826, South Korea","Although many outstanding achievements in the management of cervical cancer (CxCa) have obtained, it still imposes a major burden which has prompted scientists to discover and validate new CxCa biomarkers to improve the diagnostic and prognostic assessment of CxCa. In this study, eight different gene expression data sets containing 202 cancer, 115 cervical intraepithelial neoplasia (CIN), and 105 normal samples were utilized for an integrative systems biology assessment in a multi-stage carcinogenesis manner. Deep learning-based diagnostic models were established based on the genetic panels of intrinsic genes of cervical carcinogenesis as well as on the unbiased variable selection approach. Survival analysis was also conducted to explore the potential biomarker candidates for prognostic assessment. Our results showed that cell cycle, RNA transport, mRNA surveillance, and one carbon pool by folate were the key regulatory mechanisms involved in the initiation, progression, and metastasis of CxCa. Various genetic panels combined with machine learning algorithms successfully differentiated CxCa from CIN and normalcy in cross-study normalized data sets. In particular, the 168-gene deep learning model for the differentiation of cancer from normalcy achieved an externally validated accuracy of 97.96% (99.01% sensitivity and 95.65% specificity). Survival analysis revealed that ZNF281 and EPHB6 were the two most promising prognostic genetic markers for CxCa among others. Our findings open new opportunities to enhance current understanding of the characteristics of CxCa pathobiology. In addition, the combination of transcriptomics-based signatures and deep learning classification may become an important approach to improve CxCa diagnosis and management in clinical practice. © Long et al.","Cervical cancer; Deep learning; Meta-analysis; Survival analysis; Transcriptomics","carbon; folic acid; messenger RNA; tumor marker; Article; cancer growth; cancer prognosis; cancer staging; cancer survival; carcinogenesis; cell cycle; clinical practice; controlled study; early cancer diagnosis; EPHB6 gene; female; gene; gene expression regulation; genetic association; genetic selection; human; human tissue; machine learning; major clinical study; metastasis; RNA transport; sensitivity and specificity; transcriptomics; uterine cervix cancer; uterine cervix carcinoma in situ; validation study; ZNF281 gene","Impact Journals LLC","19492553","","","29312619","Article","Scopus","2-s2.0-85037676482"
"Qin Q.; Feng J.","Qin, Qian (55990667800); Feng, Jianxing (55468527500)","55990667800; 55468527500","Imputation for transcription factor binding predictions based on deep learning","2017","PLoS Computational Biology","64","10.1371/journal.pcbi.1005403","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014167143&doi=10.1371%2fjournal.pcbi.1005403&partnerID=40&md5=2a1423fff08f3c49f20885007b4ef876","Department of Bioinformatics, School of Life Sciences and Technology, Tongji University, Shanghai, China","Qin Q., Department of Bioinformatics, School of Life Sciences and Technology, Tongji University, Shanghai, China; Feng J., Department of Bioinformatics, School of Life Sciences and Technology, Tongji University, Shanghai, China","Understanding the cell-specific binding patterns of transcription factors (TFs) is fundamental to studying gene regulatory networks in biological systems, for which ChIP-seq not only provides valuable data but is also considered as the gold standard. Despite tremendous efforts from the scientific community to conduct TF ChIP-seq experiments, the available data represent only a limited percentage of ChIP-seq experiments, considering all possible combinations of TFs and cell lines. In this study, we demonstrate a method for accurately predicting cell-specific TF binding for TF-cell line combinations based on only a small fraction (4%) of the combinations using available ChIP-seq data. The proposed model, termed TFImpute, is based on a deep neural network with a multi-task learning setting to borrow information across transcription factors and cell lines. Compared with existing methods, TFImpute achieves comparable accuracy on TF-cell line combinations with ChIP-seq data; moreover, TFImpute achieves better accuracy on TF-cell line combinations without ChIP-seq data. This approach can predict cell line specific enhancer activities in K562 and HepG2 cell lines, as measured by massively parallel reporter assays, and predicts the impact of SNPs on TF binding. © 2017 Qin, Feng.","","Binding Sites; Chromatin Immunoprecipitation; Hep G2 Cells; High-Throughput Nucleotide Sequencing; Humans; K562 Cells; Machine Learning; Neural Networks (Computer); Protein Binding; Protein Interaction Mapping; Reproducibility of Results; Sensitivity and Specificity; Transcription Factors; Cell culture; Deep neural networks; Forecasting; Transcription; deoxyribonuclease I; immunoglobulin enhancer binding protein; transcription factor; protein binding; transcription factor; Binding pattern; Cell lines; Gene regulatory networks; Gold standards; Learning settings; Multitask learning; Prediction-based; Scientific community; Specific binding; Transcription factor binding; allele; analytic method; area under the curve; Article; artificial neural network; binding affinity; cell line; controlled study; deep learning method; DNA sequence; embedding; intermethod comparison; measurement accuracy; molecular model; parameters; prediction; protein binding; recall rate; running time; single nucleotide polymorphism; binding site; chromatin immunoprecipitation; genetics; Hep-G2 cell line; high throughput sequencing; human; K-562 cell line; machine learning; metabolism; procedures; protein analysis; reproducibility; sensitivity and specificity; Transcription factors","Public Library of Science","1553734X","","","28234893","Article","Scopus","2-s2.0-85014167143"
"Falissard L.","Falissard, Louis (57195618124)","57195618124","Text analysis applications to psychiatry; [Analyse de données textuelles en psychiatrie]","2017","Journal de Medecine Legale Droit Medical","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068611068&partnerID=40&md5=642c6aff4a14393e8f3322afa0649864","Oxford University, Nuffield Department of Surgical Sciences, Computational Neuroscience, United Kingdom","Falissard L., Oxford University, Nuffield Department of Surgical Sciences, Computational Neuroscience, United Kingdom","The advent of social network and messenger apps has led to the digitalization of a significant part of our social interactions, specifically toward a textual format. The quantitative analysis of these huge textual dataset, through the use of machine learning, and more specifically deep neural networks, led to numerous technological innovations which are now used daily by millions of users. As diagnosis in psychiatry is based, at least partly, on language, it only seems natural to investigate the use of these technologies in mental health. Consequently, an interrogation on the different available approaches, whether methodological or analytical, as well as their potential applications in psychiatry, is necessary. © 2017, Editions Alexandre Lacassagne. All rights reserved.","Artificial neural networks; Data analysis; Deep learning; Machine learning; Natural language processing; Psychiatry","article; data analysis; deep learning; deep neural network; human; human experiment; mental health; natural language processing; psychiatry; quantitative analysis; social interaction; social network","Editions Alexandre Lacassagne","02496208","","JMLMD","","Article","Scopus","2-s2.0-85068611068"
"Jaccard N.; Rogers T.W.; Morton E.J.; Griffin L.D.","Jaccard, Nicolas (15135989700); Rogers, Thomas W. (56411613900); Morton, Edward J. (36954754400); Griffin, Lewis D. (7102753156)","15135989700; 56411613900; 36954754400; 7102753156","Detection of concealed cars in complex cargo X-ray imagery using Deep Learning","2017","Journal of X-Ray Science and Technology","52","10.3233/XST-16199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020704251&doi=10.3233%2fXST-16199&partnerID=40&md5=4bea453f5c99e5c3953874852b5bf826","Department of Computer Science London, University College London, London, WC1E 6BT, United Kingdom; Department of Security and Crime Sciences, University College London, London, United Kingdom; Rapiscan Systems Ltd., Stoke-On-Trent, United Kingdom","Jaccard N., Department of Computer Science London, University College London, London, WC1E 6BT, United Kingdom; Rogers T.W., Department of Computer Science London, University College London, London, WC1E 6BT, United Kingdom, Department of Security and Crime Sciences, University College London, London, United Kingdom; Morton E.J., Rapiscan Systems Ltd., Stoke-On-Trent, United Kingdom; Griffin L.D., Department of Computer Science London, University College London, London, WC1E 6BT, United Kingdom","BACKGROUND: Non-intrusive inspection systems based on X-ray radiography techniques are routinely used at transport hubs to ensure the conformity of cargo content with the supplied shipping manifest. As trade volumes increase and regulations become more stringent, manual inspection by trained operators is less and less viable due to low throughput. Machine vision techniques can assist operators in their task by automating parts of the inspection workflow. Since cars are routinely involved in trafficking, export fraud, and tax evasion schemes, they represent an attractive target for automated detection and flagging for subsequent inspection by operators. OBJECTIVE: Development and evaluation of a novel method for the automated detection of cars in complex X-ray cargo imagery. METHODS: X-ray cargo images from a stream-of-commerce dataset were classified using a window-based scheme. The limited number of car images was addressed by using an oversampling scheme. Different Convolutional Neural Network (CNN) architectures were compared with well-established bag of words approaches. In addition, robustness to concealment was evaluated by projection of objects into car images. RESULTS: CNN approaches outperformed all other methods evaluated, achieving 100 car image classification rate for a false positive rate of 1-in-454. Cars that were partially or completely obscured by other goods, a modus operandi frequently adopted by criminals, were correctly detected. CONCLUSIONS: We believe that this level of performance suggests that the method is suitable for deployment in the field. It is expected that the generic object detection workflow described can be extended to other object classes given the availability of suitable training data. © 2017 - IOS Press and the authors. All rights reserved.","Classification; Deep Learning; Security; X-ray cargo image","Automobiles; Humans; Machine Learning; Radiographic Image Enhancement; Radiography; Security Measures; Classification (of information); Complex networks; Crime; Deep learning; Inspection; Laws and legislation; Neural networks; Object detection; Object recognition; Automated detection; Convolutional neural network; False positive rates; Manual inspection; Modus operandi; Non-intrusive inspection; Security; X-ray imagery; classification; fraud; human; imagery; learning; nervous system; offender; workflow; X ray; car; image enhancement; machine learning; organization and management; procedures; radiography; X ray radiography","IOS Press","08953996","","JXSTE","28157116","Article","Scopus","2-s2.0-85020704251"
"Li X.; Peng L.; Yao X.; Cui S.; Hu Y.; You C.; Chi T.","Li, Xiang (57126877800); Peng, Ling (56506111400); Yao, Xiaojing (56510788700); Cui, Shaolong (57195578378); Hu, Yuan (57191506471); You, Chengzeng (57194097272); Chi, Tianhe (7005693588)","57126877800; 56506111400; 56510788700; 57195578378; 57191506471; 57194097272; 7005693588","Long short-term memory neural network for air pollutant concentration predictions: Method development and evaluation","2017","Environmental Pollution","467","10.1016/j.envpol.2017.08.114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028944487&doi=10.1016%2fj.envpol.2017.08.114&partnerID=40&md5=9600c1badac120286629fa172ce7a25d","Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China; University of Chinese Academy of Sciences, Beijing, 100049, China","Li X., Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Peng L., Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China; Yao X., Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China; Cui S., Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China; Hu Y., Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China, University of Chinese Academy of Sciences, Beijing, 100049, China; You C., Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Chi T., Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, 100094, China","Air pollutant concentration forecasting is an effective method of protecting public health by providing an early warning against harmful air pollutants. However, existing methods of air pollutant concentration prediction fail to effectively model long-term dependencies, and most neglect spatial correlations. In this paper, a novel long short-term memory neural network extended (LSTME) model that inherently considers spatiotemporal correlations is proposed for air pollutant concentration prediction. Long short-term memory (LSTM) layers were used to automatically extract inherent useful features from historical air pollutant data, and auxiliary data, including meteorological data and time stamp data, were merged into the proposed model to enhance the performance. Hourly PM2.5 (particulate matter with an aerodynamic diameter less than or equal to 2.5 μm) concentration data collected at 12 air quality monitoring stations in Beijing City from Jan/01/2014 to May/28/2016 were used to validate the effectiveness of the proposed LSTME model. Experiments were performed using the spatiotemporal deep learning (STDL) model, the time delay neural network (TDNN) model, the autoregressive moving average (ARMA) model, the support vector regression (SVR) model, and the traditional LSTM NN model, and a comparison of the results demonstrated that the LSTME model is superior to the other statistics-based models. Additionally, the use of auxiliary data improved model performance. For the one-hour prediction tasks, the proposed model performed well and exhibited a mean absolute percentage error (MAPE) of 11.93%. In addition, we conducted multiscale predictions over different time spans and achieved satisfactory performance, even for 13–24 h prediction tasks (MAPE = 31.47%). © 2017 Elsevier Ltd","Air pollutant concentration predictions; Long short-term memory neural network (LSTM NN); Multiscale prediction; Recurrent neural network; Spatiotemporal correlation","Air Pollutants; Air Pollution; Beijing; Cities; Environmental Monitoring; Forecasting; Models, Statistical; Models, Theoretical; Neural Networks (Computer); Particulate Matter; Beijing [Beijing (ADS)]; Beijing [China]; China; Air quality; Autoregressive moving average model; Brain; Deep learning; Forecasting; Meteorology; Recurrent neural networks; Salinity measurement; Support vector regression; Air pollutant concentrations; Air quality monitoring stations; Autoregressive moving average; Mean absolute percentage error; Multiscale predictions; Spatiotemporal correlation; Support vector regression (SVR); Time delay neural networks; air quality; artificial neural network; atmospheric pollution; concentration (composition); monitoring system; particulate matter; prediction; spatiotemporal analysis; support vector machine; air pollutant; air quality; China; learning; monitoring; nervous system; particulate matter; prediction; short term memory; statistics; support vector machine; air pollutant; air pollution; analysis; artificial neural network; city; environmental monitoring; forecasting; procedures; statistical model; statistics and numerical data; theoretical model; Long short-term memory","Elsevier Ltd","02697491","","ENPOE","28898956","Article","Scopus","2-s2.0-85028944487"
"Kim J.; Kim J.; Jang G.-J.; Lee M.","Kim, Jihun (56024681400); Kim, Jonghong (57022250500); Jang, Gil-Jin (7102646102); Lee, Minho (57191730119)","56024681400; 57022250500; 7102646102; 57191730119","Fast learning method for convolutional neural networks using extreme learning machine and its application to lane detection","2017","Neural Networks","162","10.1016/j.neunet.2016.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009956041&doi=10.1016%2fj.neunet.2016.12.002&partnerID=40&md5=f3610b894eb55dea58730ca9a7a17075","School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea","Kim J., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; Kim J., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; Jang G.-J., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; Lee M., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea","Deep learning has received significant attention recently as a promising solution to many problems in the area of artificial intelligence. Among several deep learning architectures, convolutional neural networks (CNNs) demonstrate superior performance when compared to other machine learning methods in the applications of object detection and recognition. We use a CNN for image enhancement and the detection of driving lanes on motorways. In general, the process of lane detection consists of edge extraction and line detection. A CNN can be used to enhance the input images before lane detection by excluding noise and obstacles that are irrelevant to the edge detection result. However, training conventional CNNs requires considerable computation and a big dataset. Therefore, we suggest a new learning algorithm for CNNs using an extreme learning machine (ELM). The ELM is a fast learning method used to calculate network weights between output and hidden layers in a single iteration and thus, can dramatically reduce learning time while producing accurate results with minimal training data. A conventional ELM can be applied to networks with a single hidden layer; as such, we propose a stacked ELM architecture in the CNN framework. Further, we modify the backpropagation algorithm to find the targets of hidden layers and effectively learn network weights while maintaining performance. Experimental results confirm that the proposed method is effective in reducing learning time and improving performance. © 2016 Elsevier Ltd","Advanced driver assistance system; Convolutional neural network; Extreme learning machine; Lane detection","Algorithms; Artificial Intelligence; Humans; Image Enhancement; Machine Learning; Neural Networks (Computer); Advanced driver assistance systems; Artificial intelligence; Automobile drivers; Backpropagation algorithms; Big data; Convolution; Edge detection; Iterative methods; Knowledge acquisition; Learning algorithms; Network architecture; Neural networks; Object recognition; Convolutional neural network; Extreme learning machine; Improving performance; ITS applications; Lane detection; Machine learning methods; Minimal training; Object detection and recognition; algorithm; Article; artificial neural network; convolutional neural network; data base; extreme learning machine; highway; image enhancement; information processing; lane detection; machine learning; mathematical analysis; measurement accuracy; traffic and transport; artificial intelligence; human; procedures; Learning systems","Elsevier Ltd","08936080","","NNETE","28110106","Article","Scopus","2-s2.0-85009956041"
"Pan X.; Shen H.-B.","Pan, Xiaoyong (35273382000); Shen, Hong-Bin (8964541700)","35273382000; 8964541700","RNA-protein binding motifs mining with a new hybrid deep learning based cross-domain knowledge integration approach","2017","BMC Bioinformatics","144","10.1186/s12859-017-1561-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014099241&doi=10.1186%2fs12859-017-1561-8&partnerID=40&md5=f4b984c0266c2def436f1e148e30a54c","University of Copenhagen, Department of Veterinary Clinical and Animal Sciences, Copenhagen, Denmark; Ministry of Education of China, Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, and Key Laboratory of System Control and Information Processing, Shanghai, China","Pan X., University of Copenhagen, Department of Veterinary Clinical and Animal Sciences, Copenhagen, Denmark; Shen H.-B., Ministry of Education of China, Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, and Key Laboratory of System Control and Information Processing, Shanghai, China","Background: RNAs play key roles in cells through the interactions with proteins known as the RNA-binding proteins (RBP) and their binding motifs enable crucial understanding of the post-transcriptional regulation of RNAs. How the RBPs correctly recognize the target RNAs and why they bind specific positions is still far from clear. Machine learning-based algorithms are widely acknowledged to be capable of speeding up this process. Although many automatic tools have been developed to predict the RNA-protein binding sites from the rapidly growing multi-resource data, e.g. sequence, structure, their domain specific features and formats have posed significant computational challenges. One of current difficulties is that the cross-source shared common knowledge is at a higher abstraction level beyond the observed data, resulting in a low efficiency of direct integration of observed data across domains. The other difficulty is how to interpret the prediction results. Existing approaches tend to terminate after outputting the potential discrete binding sites on the sequences, but how to assemble them into the meaningful binding motifs is a topic worth of further investigation. Results: In viewing of these challenges, we propose a deep learning-based framework (iDeep) by using a novel hybrid convolutional neural network and deep belief network to predict the RBP interaction sites and motifs on RNAs. This new protocol is featured by transforming the original observed data into a high-level abstraction feature space using multiple layers of learning blocks, where the shared representations across different domains are integrated. To validate our iDeep method, we performed experiments on 31 large-scale CLIP-seq datasets, and our results show that by integrating multiple sources of data, the average AUC can be improved by 8% compared to the best single-source-based predictor; and through cross-domain knowledge integration at an abstraction level, it outperforms the state-of-the-art predictors by 6%. Besides the overall enhanced prediction performance, the convolutional neural network module embedded in iDeep is also able to automatically capture the interpretable binding motifs for RBPs. Large-scale experiments demonstrate that these mined binding motifs agree well with the experimentally verified results, suggesting iDeep is a promising approach in the real-world applications. Conclusion: The iDeep framework not only can achieve promising performance than the state-of-the-art predictors, but also easily capture interpretable binding motifs. iDeep is available at http://www.csbio.sjtu.edu.cn/bioinf/iDeep © 2017 The Author(s).","CLIP-seq; Convolutional neural network; Deep belief network; Multimodal deep learning; RNA-binding protein","Algorithms; Binding Sites; Data Mining; Machine Learning; Neural Networks (Computer); Nucleotide Motifs; Protein Binding; RNA; RNA-Binding Proteins; Sequence Analysis, RNA; Abstracting; Binding sites; Bins; Biochemistry; Convolution; Data integration; Deep neural networks; Forecasting; Integration; Learning systems; Metadata; Natural language processing systems; Neural networks; Nucleic acids; Proteins; RNA; protein binding; RNA; RNA binding protein; CLIP-seq; Convolutional neural network; Deep belief networks; Multi-modal; RNA-binding protein; algorithm; artificial neural network; binding site; chemistry; data mining; machine learning; metabolism; nucleotide motif; procedures; sequence analysis; validation study; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","28245811","Article","Scopus","2-s2.0-85014099241"
"Schütt K.T.; Arbabzadah F.; Chmiela S.; Müller K.R.; Tkatchenko A.","Schütt, Kristof T. (55496060500); Arbabzadah, Farhad (35094938500); Chmiela, Stefan (57192920615); Müller, Klaus R. (15042362900); Tkatchenko, Alexandre (57203071200)","55496060500; 35094938500; 57192920615; 15042362900; 57203071200","Quantum-chemical insights from deep tensor neural networks","2017","Nature Communications","914","10.1038/ncomms13890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009110385&doi=10.1038%2fncomms13890&partnerID=40&md5=30f05ed5bca99a020a93b16a9a5c2c79","Machine Learning Group, Technische Universita't Berlin, Marchstr. 23, Berlin, 10587, Germany; Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 136-713, South Korea; Theory Department, Fritz-Haber-Institut der Max-Planck-Gesellschaft, Faradayweg 4-6, Berlin, D-14195, Germany; Physics and Materials Science Research Unit, University of Luxembourg, Luxembourg, L-1511, Luxembourg","Schütt K.T., Machine Learning Group, Technische Universita't Berlin, Marchstr. 23, Berlin, 10587, Germany; Arbabzadah F., Machine Learning Group, Technische Universita't Berlin, Marchstr. 23, Berlin, 10587, Germany; Chmiela S., Machine Learning Group, Technische Universita't Berlin, Marchstr. 23, Berlin, 10587, Germany; Müller K.R., Machine Learning Group, Technische Universita't Berlin, Marchstr. 23, Berlin, 10587, Germany, Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 136-713, South Korea; Tkatchenko A., Theory Department, Fritz-Haber-Institut der Max-Planck-Gesellschaft, Faradayweg 4-6, Berlin, D-14195, Germany, Physics and Materials Science Research Unit, University of Luxembourg, Luxembourg, L-1511, Luxembourg","Learning from data has led to paradigm shifts in a multitude of disciplines, including web, text and image search, speech recognition, as well as bioinformatics. Can machine learning enable similar breakthroughs in understanding quantum many-body systems? Here we develop an efficient deep learning approach that enables spatially and chemically resolved insights into quantum-mechanical observables of molecular systems. We unify concepts from many-body Hamiltonians with purpose-designed deep tensor neural networks, which leads to size-extensive and uniformly accurate (1 kcal mol -1) predictions in compositional and configurational chemical space for molecules of intermediate size. As an example of chemical relevance, the model reveals a classification of aromatic rings with respect to their stability. Further applications of our model for predicting atomic energies and local chemical potentials in molecules, reliable isomer energies, and molecules with peculiar electronic structure demonstrate the potential of machine learning for revealing insights into complex quantum-chemical systems. © The Author(s) 2017.","","artificial neural network; bioinformatics; chemical analysis; machine learning; molecular analysis; numerical model; quantum mechanics; chemistry; classification; isomer; machine learning; model; nervous system; prediction","Nature Publishing Group","20411723","","","28067221","Article","Scopus","2-s2.0-85009110385"
"Suk H.-I.; Lee S.-W.; Shen D.","Suk, Heung-Il (56332955800); Lee, Seong-Whan (7601390519); Shen, Dinggang (7401738392)","56332955800; 7601390519; 7401738392","Deep ensemble learning of sparse regression models for brain disease diagnosis","2017","Medical Image Analysis","227","10.1016/j.media.2017.01.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012254441&doi=10.1016%2fj.media.2017.01.008&partnerID=40&md5=a9045bb325503f8d42b2dfa3a2ffbfd2","Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea; Biomedical Research Imaging Center and Department of Radiology, University of North Carolina at Chapel Hill, NC 27599, United States","Suk H.-I., Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea; Lee S.-W., Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea; Shen D., Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea, Biomedical Research Imaging Center and Department of Radiology, University of North Carolina at Chapel Hill, NC 27599, United States","Recent studies on brain imaging analysis witnessed the core roles of machine learning techniques in computer-assisted intervention for brain disease diagnosis. Of various machine-learning techniques, sparse regression models have proved their effectiveness in handling high-dimensional data but with a small number of training samples, especially in medical problems. In the meantime, deep learning methods have been making great successes by outperforming the state-of-the-art performances in various applications. In this paper, we propose a novel framework that combines the two conceptually different methods of sparse regression and deep learning for Alzheimer's disease/mild cognitive impairment diagnosis and prognosis. Specifically, we first train multiple sparse regression models, each of which is trained with different values of a regularization control parameter. Thus, our multiple sparse regression models potentially select different feature subsets from the original feature set; thereby they have different powers to predict the response values, i.e., clinical label and clinical scores in our work. By regarding the response values from our sparse regression models as target-level representations, we then build a deep convolutional neural network for clinical decision making, which thus we call ‘Deep Ensemble Sparse Regression Network.’ To our best knowledge, this is the first work that combines sparse regression models with deep neural network. In our experiments with the ADNI cohort, we validated the effectiveness of the proposed method by achieving the highest diagnostic accuracies in three classification tasks. We also rigorously analyzed our results and compared with the previous studies on the ADNI cohort in the literature. © 2017 Elsevier B.V.","Alzheimer's disease; Convolutional neural network; Deep ensemble learning; Sparse regression model","Aged; Alzheimer Disease; Brain; Clinical Decision-Making; Cognitive Dysfunction; Female; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Prognosis; Regression Analysis; Reproducibility of Results; Sensitivity and Specificity; Brain mapping; Clustering algorithms; Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Convolution; Convolutional neural networks; Decision making; Deep neural networks; Learning systems; Medical problems; Neurodegenerative diseases; Regression analysis; Alzheimer's disease; Clinical decision making; Diagnosis and prognosis; Ensemble learning; High dimensional data; Machine learning techniques; Sparse regression; State-of-the-art performance; aged; Alzheimer disease; Article; brain disease; clinical decision making; clinical effectiveness; deep ensemble learning; female; human; learning algorithm; major clinical study; male; mathematical computing; mild cognitive impairment; nerve cell network; predictive value; priority journal; prognosis; regression analysis; scoring system; sparse regression model; brain; cognitive defect; diagnostic imaging; machine learning; nuclear magnetic resonance imaging; procedures; reproducibility; sensitivity and specificity; Deep learning","Elsevier B.V.","13618415","","MIAEC","28167394","Article","Scopus","2-s2.0-85012254441"
"Nunes Pinto C.L.; Nobre C.N.; Zárate L.E.","Nunes Pinto, Cristiano Lacerda (57193170687); Nobre, Cristiane Neri (7004027375); Zárate, Luis Enrique (6603853028)","57193170687; 7004027375; 6603853028","Transductive learning as an alternative to translation initiation site identification","2017","BMC Bioinformatics","5","10.1186/s12859-017-1502-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011383007&doi=10.1186%2fs12859-017-1502-6&partnerID=40&md5=d1b50e6387ee2f1bd14e89139121bfcd","School of Engeneering of Minas Gerais - EMGE, Belo Horizonte, 30150-250, Brazil; Pontifical Catholic University of Minas Gerais - PUC-MG, 255, Walter Ianni Street, Belo Horizonte, 31980-110, Brazil","Nunes Pinto C.L., School of Engeneering of Minas Gerais - EMGE, Belo Horizonte, 30150-250, Brazil; Nobre C.N., Pontifical Catholic University of Minas Gerais - PUC-MG, 255, Walter Ianni Street, Belo Horizonte, 31980-110, Brazil; Zárate L.E., Pontifical Catholic University of Minas Gerais - PUC-MG, 255, Walter Ianni Street, Belo Horizonte, 31980-110, Brazil","Background: The correct protein coding region identification is an important and latent problem in the molecular biology field. This problem becomes a challenge due to the lack of deep knowledge about the biological systems and unfamiliarity of conservative characteristics in the messenger RNA (mRNA). Therefore, it is fundamental to research for computational methods aiming to help the patterns discovery for identification of the Translation Initiation Sites (TIS). In the field of Bioinformatics, machine learning methods have been widely applied based on the inductive inference, as Inductive Support Vector Machine (ISVM). On the other hand, not so much attention has been given to transductive inference-based machine learning methods such as Transductive Support Vector Machine (TSVM). The transductive inference performs well for problems in which the amount of unlabeled sequences is considerably greater than the labeled ones. Similarly, the problem of predicting the TIS may take advantage of transductive methods due to the fact that the amount of new sequences grows rapidly with the progress of Genome Project that allows the study of new organisms. Consequently, this work aims to investigate the transductive learning towards TIS identification and compare the results with those obtained in inductive method. Results: The transductive inference presents better results both in F-measure and in sensitivity in comparison with the inductive method for predicting the TIS. Additionally, it presents the least failure rate for identifying the TIS, presenting a smaller number of False Negatives (FN) than the ISVM. The ISVM and TSVM methods were validated with the molecules from the most representative organisms contained in the RefSeq database: Rattus norvegicus, Mus musculus, Homo sapiens, Drosophila melanogaster and Arabidopsis thaliana. The transductive method presented F-measure and sensitivity higher than 90% and also higher than the results obtained with ISVM. The ISVM and TSVM approaches were implemented in the TransduTIS tool, TransduTIS-I and TransduTIS-T respectively, available in a web interface. These approaches were compared with the TISHunter, TIS Miner, NetStart tools, presenting satisfactory results. Conclusions: In relation to precision, the results are similar for the ISVM and TSVM classifiers. However, the results show that the application of TSVM approach ensured an improvement, specially for F-measure and sensitivity. Moreover, it was possible to identify a potential for the application of TSVM, which is for organisms in the initial study phase with few identified sequences in the databases. © 2017 The Author(s).","Machine learning; MRNA; SVM; Transductive learning; Translation initiation site; TSVM","Animals; Arabidopsis; Computational Biology; Drosophila melanogaster; Humans; Mice; Peptide Chain Initiation, Translational; Rats; Software; Support Vector Machine; Biology; DNA sequences; Failure analysis; Learning systems; Molecular biology; Nucleic acids; RNA; Support vector machines; Drosophila melanogaster; Machine learning methods; MRNA; Protein coding regions; Transductive learning; Transductive support vector machine; Translation initiation site; TSVM; Arabidopsis thaliana; attention; bioinformatics; data base; Drosophila melanogaster; false negative result; genome; human; intermethod comparison; machine learning; miner; mouse; Mus musculus; nonhuman; rat; Rattus norvegicus; support vector machine; translation initiation; animal; Arabidopsis; biology; genetics; procedures; software; validation study; Artificial intelligence","BioMed Central Ltd.","14712105","","BBMIC","28152994","Article","Scopus","2-s2.0-85011383007"
"Janowczyk A.; Basavanhally A.; Madabhushi A.","Janowczyk, Andrew (26531344300); Basavanhally, Ajay (18633580900); Madabhushi, Anant (6603019206)","26531344300; 18633580900; 6603019206","Stain Normalization using Sparse AutoEncoders (StaNoSA): Application to digital pathology","2017","Computerized Medical Imaging and Graphics","159","10.1016/j.compmedimag.2016.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978410533&doi=10.1016%2fj.compmedimag.2016.05.003&partnerID=40&md5=f7d6fe43edd967035c92a5e9387ed8a0","Case Western Reserve University, Cleveland, OH, United States; Inspirata, Inc., Tampa, FL, United States","Janowczyk A., Case Western Reserve University, Cleveland, OH, United States; Basavanhally A., Inspirata, Inc., Tampa, FL, United States; Madabhushi A., Case Western Reserve University, Cleveland, OH, United States","Digital histopathology slides have many sources of variance, and while pathologists typically do not struggle with them, computer aided diagnostic algorithms can perform erratically. This manuscript presents Stain Normalization using Sparse AutoEncoders (StaNoSA) for use in standardizing the color distributions of a test image to that of a single template image. We show how sparse autoencoders can be leveraged to partition images into tissue sub-types, so that color standardization for each can be performed independently. StaNoSA was validated on three experiments and compared against five other color standardization approaches and shown to have either comparable or superior results. © 2016 Elsevier Ltd","Deep learning; Digital histopathology; Image processing; Stain Normalization","Biopsy; Breast; Color; Diagnosis, Computer-Assisted; Histological Techniques; Humans; Image Processing, Computer-Assisted; Machine Learning; Pathology, Clinical; Staining and Labeling; Color; Image processing; Standardization; Autoencoders; Color distribution; Computer aided diagnostics; Deep learning; Digital histopathology; Digital pathologies; Stain Normalization; Template images; algorithm; Article; breast biopsy; color; computer assisted diagnosis; digital imaging; digital pathology; histogram; histopathology; human; human tissue; image analysis; intestine biopsy; priority journal; Stain Normalization using Sparse AutoEncoder; staining; standardization; stomach biopsy; biopsy; breast; color; diagnostic imaging; histology; image processing; machine learning; pathology; procedures; staining; validation study; Learning systems","Elsevier Ltd","08956111","","CMIGE","27373749","Article","Scopus","2-s2.0-84978410533"
"Perez M.; Avila S.; Moreira D.; Moraes D.; Testoni V.; Valle E.; Goldenstein S.; Rocha A.","Perez, Mauricio (56411467000); Avila, Sandra (55644034300); Moreira, Daniel (56411685600); Moraes, Daniel (24577735700); Testoni, Vanessa (25655637100); Valle, Eduardo (24479959000); Goldenstein, Siome (6602436600); Rocha, Anderson (16643616700)","56411467000; 55644034300; 56411685600; 24577735700; 25655637100; 24479959000; 6602436600; 16643616700","Video pornography detection through deep learning techniques and motion information","2017","Neurocomputing","112","10.1016/j.neucom.2016.12.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007578936&doi=10.1016%2fj.neucom.2016.12.017&partnerID=40&md5=e2243bac203532e9bddb193dad7a466b","Institute of Computing, University of Campinas, Brazil; School of Electrical and Computing Engineering, University of Campinas, Brazil; Samsung Research Institute Brazil, Brazil","Perez M., Institute of Computing, University of Campinas, Brazil; Avila S., School of Electrical and Computing Engineering, University of Campinas, Brazil; Moreira D., Institute of Computing, University of Campinas, Brazil; Moraes D., Institute of Computing, University of Campinas, Brazil; Testoni V., Samsung Research Institute Brazil, Brazil; Valle E., School of Electrical and Computing Engineering, University of Campinas, Brazil; Goldenstein S., Institute of Computing, University of Campinas, Brazil; Rocha A., Institute of Computing, University of Campinas, Brazil","Recent literature has explored automated pornographic detection – a bold move to replace humans in the tedious task of moderating online content. Unfortunately, on scenes with high skin exposure, such as people sunbathing and wrestling, the state of the art can have many false alarms. This paper is based on the premise that incorporating motion information in the models can alleviate the problem of mapping skin exposure to pornographic content, and advances the bar on automated pornography detection with the use of motion information and deep learning architectures. Deep Learning, especially in the form of Convolutional Neural Networks, have striking results on computer vision, but their potential for pornography detection is yet to be fully explored through the use of motion information. We propose novel ways for combining static (picture) and dynamic (motion) information using optical flow and MPEG motion vectors. We show that both methods provide equivalent accuracies, but that MPEG motion vectors allow a more efficient implementation. The best proposed method yields a classification accuracy of 97.9% – an error reduction of 64.4% when compared to the state of the art – on a dataset of 800 challenging test cases. Finally, we present and discuss results on a larger, and more challenging, dataset. © 2016 Elsevier B.V.","Deep learning and motion information; MPEG motion vectors; Optical flow; Pornography classification; Sensitive video classification","Computer vision; Information use; Motion analysis; Motion Picture Experts Group standards; Neural networks; Optical flows; Statistical tests; Video streaming; Classification accuracy; Convolutional neural network; Efficient implementation; Motion information; Motion Vectors; On-line contents; Pornography detections; Video classification; accuracy; Article; artificial neural network; automation; classification; computer system; convolutional neural network; exposure; information processing; machine learning; measurement accuracy; measurement error; motion analysis system; optic flow; pornography use; vision; Classification (of information)","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85007578936"
"Feng Y.; Yuan Y.; Lu X.","Feng, Yachuang (56677051400); Yuan, Yuan (57203237779); Lu, Xiaoqiang (35180125200)","56677051400; 57203237779; 35180125200","Learning deep event models for crowd anomaly detection","2017","Neurocomputing","153","10.1016/j.neucom.2016.09.063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999040371&doi=10.1016%2fj.neucom.2016.09.063&partnerID=40&md5=ee233f7361937352c9626510195325a3","Center for OPTical IMagery Analysis and Learning (OPTIMAL), State Key Laboratory of Transient Optics and Photonics, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an, 710119, Shaanxi, China; University of Chinese Academy of Sciences, Beijing, 100049, China","Feng Y., Center for OPTical IMagery Analysis and Learning (OPTIMAL), State Key Laboratory of Transient Optics and Photonics, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an, 710119, Shaanxi, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Yuan Y., Center for OPTical IMagery Analysis and Learning (OPTIMAL), State Key Laboratory of Transient Optics and Photonics, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an, 710119, Shaanxi, China; Lu X., Center for OPTical IMagery Analysis and Learning (OPTIMAL), State Key Laboratory of Transient Optics and Photonics, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an, 710119, Shaanxi, China","Abnormal event detection in video surveillance is extremely important, especially for crowded scenes. In recent years, many algorithms have been proposed based on hand-crafted features. However, it still remains challenging to decide which kind of feature is suitable for a specific situation. In addition, it is hard and time-consuming to design an effective descriptor. In this paper, video events are automatically represented and modeled in unsupervised fashions. Specifically, appearance and motion features are simultaneously extracted using a PCANet from 3D gradients. In order to model event patterns, a deep Gaussian mixture model (GMM) is constructed with observed normal events. The deep GMM is a scalable deep generative model which stacks multiple GMM-layers on top of each other. As a result, the proposed method acquires competitive performance with relatively few parameters. In the testing phase, the likelihood is calculated to judge whether a video event is abnormal or not. In this paper, the proposed method is verified on two publicly available datasets and compared with state-of-the-art algorithms. Experimental results show that the deep model is effective for abnormal event detection in video surveillance. © 2016 Elsevier B.V.","Abnormal event detection; Crowded scene; Deep GMM; Deep neural network; PCANet; Video surveillance","Gaussian distribution; Image segmentation; Monitoring; Motion analysis; Real time systems; Abnormal event detections; Crowded scene; Deep GMM; Deep neural networks; PCANet; Video surveillance; algorithm; Article; image processing; machine learning; mathematical analysis; normal distribution; principal component analysis; priority journal; videorecording; Security systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84999040371"
"Tomczak J.M.; Gonczarek A.","Tomczak, Jakub M. (36471022200); Gonczarek, Adam (12544668700)","36471022200; 12544668700","Learning Invariant Features Using Subspace Restricted Boltzmann Machine","2017","Neural Processing Letters","12","10.1007/s11063-016-9519-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964057082&doi=10.1007%2fs11063-016-9519-9&partnerID=40&md5=3a33a9a47312b650b8cb2e58e82fd73a","Department of Computer Science, Faculty of Computer Science and Management, Wrocław University of Science and Technology, wybrzeże Wyspiańskiego 27, Wrocław, 50-370, Poland","Tomczak J.M., Department of Computer Science, Faculty of Computer Science and Management, Wrocław University of Science and Technology, wybrzeże Wyspiańskiego 27, Wrocław, 50-370, Poland; Gonczarek A., Department of Computer Science, Faculty of Computer Science and Management, Wrocław University of Science and Technology, wybrzeże Wyspiańskiego 27, Wrocław, 50-370, Poland","The subspace restricted Boltzmann machine (subspaceRBM) is a third-order Boltzmann machine where multiplicative interactions are between one visible and two hidden units. There are two kinds of hidden units, namely, gate units and subspace units. The subspace units reflect variations of a pattern in data and the gate unit is responsible for activating the subspace units. Additionally, the gate unit can be seen as a pooling feature. We evaluate the behavior of subspaceRBM through experiments with MNIST digit recognition task and Caltech 101 Silhouettes image corpora, measuring cross-entropy reconstruction error and classification error. © 2016, The Author(s).","Deep model; Feature learning; Invariant features; Subspace features; Unsupervised learning","Artificial intelligence; Software engineering; Unsupervised learning; Boltzmann machines; Classification errors; Cross entropy; Digit recognition; Feature learning; Invariant features; Restricted boltzmann machine; Subspace features; Reconfigurable hardware","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-84964057082"
"Ohno M.; Kimura D.; Matsuura K.","Ohno, Munekazu (7402908510); Kimura, Daichi (57198812698); Matsuura, Kiyotaka (35445942800)","7402908510; 57198812698; 35445942800","Prediction of microsegregation based on machine learning and its extension to a macrosegregation simulation","2017","Tetsu-To-Hagane/Journal of the Iron and Steel Institute of Japan","3","10.2355/tetsutohagane.TETSU-2017-040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037077346&doi=10.2355%2ftetsutohagane.TETSU-2017-040&partnerID=40&md5=477b25eaed904313a7feb1ab50e09e92","Faculty of Engineering, Hokkaido University, Kita 13 Nishi 8, Kita-ku Sapporo Hokkaido, 060-8628, Japan; Graduate School of Engineering, Hokkaido University, Now NTT Communications Corporation, Japan","Ohno M., Faculty of Engineering, Hokkaido University, Kita 13 Nishi 8, Kita-ku Sapporo Hokkaido, 060-8628, Japan; Kimura D., Graduate School of Engineering, Hokkaido University, Now NTT Communications Corporation, Japan; Matsuura K., Faculty of Engineering, Hokkaido University, Kita 13 Nishi 8, Kita-ku Sapporo Hokkaido, 060-8628, Japan","Synopsis : An approach of machine learning called Deep Learning is utilized for construction of a prediction method of microsegregation behavior in Febased binary alloys with solute atoms of C, Si, Mn and P. Training data for the machine learning are obtained by quantitative phase-field simulations for directional solidification. Therefore, effects of microstructural evolutions on the microsegregation behavior are taken into account in the present method. Importantly, this method can be coupled with a macrosegregation model. The simulation result of the macrosegregation model is quite different from those obtained by a conventional macrosegregation model with the Scheil model and a model with a prediction method constructed from the training data of one-dimensional finite difference calculations for the microsegregation. This fact highlights the importance of accurate description of microsegregation behavior in prediction of macrosegregation.","Deep learning; Macrosegregation; Microsegregation; Phase-field simulation; Solidification","Artificial intelligence; Binary alloys; Deep learning; Forecasting; Manganese; Segregation (metallography); Solidification; Finite difference calculations; Macrosegregation model; Macrosegregations; Micro-segregation; Phase-field simulation; Prediction methods; Quantitative phase-field simulations; Training data; Learning systems","Iron and Steel Institute of Japan","00211575","","TEHAA","","Article","Scopus","2-s2.0-85037077346"
"Jha M.; Kawale A.; Verma C.K.","Jha, Manoj (57211391505); Kawale, Akshaykumar (57200228249); Verma, Chandan Kumar (57188688236)","57211391505; 57200228249; 57188688236","Interpretable model for antibiotic resistance prediction in bacteria using deep learning","2017","Biomedical and Pharmacology Journal","3","10.13005/bpj/1316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040359439&doi=10.13005%2fbpj%2f1316&partnerID=40&md5=5625b05c8d7d72d3609719da0c21ef92","Department of Mathematics, Bioinformatics, Computer Applications, MANIT, Bhopal, India; Department of Bioinformatics, MANIT, Bhopal, India","Jha M., Department of Mathematics, Bioinformatics, Computer Applications, MANIT, Bhopal, India; Kawale A., Department of Bioinformatics, MANIT, Bhopal, India; Verma C.K., Department of Mathematics, Bioinformatics, Computer Applications, MANIT, Bhopal, India","The identification of Antibiotic resistance in bacteria is a key step of improvement in the field of drug discovery and vaccinology We present a method for this task that relies on a k-mer representation of genomes and a deep learning algorithm that produces interpretable models. The method is computationally accessible and well-suited for whole genome sequencing studies. Deep learning is an application of machine learning that uses a cascade of many layers of nonlinear processing units for extracting features and transforming it. The existing approaches for predicting antibiotic resistance genes in bacteria is not efficient enough whereas machine learning proves to be more effective than traditional methods. Our study relies on a k-mer representation method. In computational genomics, k-mer refers to all the possible subsequence (of length k) from a read obtained through DNA sequencing. The study generates the result with the help of features like coverage and depth that tells us about resistivity of the bacteria against the antibiotic. The accuracy of the model varies from 93% to 97%. The method was validated by generating models that predicted the antibiotic resistance of bacteria. The model is accurate, faithful to biological pathways targeted by the antibiotics, and they provide insight into the process of resistance acquisition. The model is computationally scalable and well suited for whole genome sequencing studies.","Antibiotic Resistance; Bacteria; Deep Learning; Genomics; Machine learning","fosfomycin; macrolide; quinoline derived antiinfective agent; tetracycline; antibiotic resistance; antibiotic resistance gene; antibiotic sensitivity; Article; bacterium contamination; Clostridioides difficile; Clostridium difficile infection; computer model; diagnostic accuracy; DNA sequence; drug development; gene; learning algorithm; machine learning; nonhuman; structural bioinformatics; whole genome sequencing","Oriental Scientific Publishing Company","09746242","","","","Article","Scopus","2-s2.0-85040359439"
"Trevathan J.K.; Yousefi A.; Park H.O.; Bartoletta J.J.; Ludwig K.A.; Lee K.H.; Lujan J.L.","Trevathan, James K. (55649209500); Yousefi, Ali (6701439525); Park, Hyung Ook (57193424001); Bartoletta, John J. (57193416977); Ludwig, Kip A. (8555844900); Lee, Kendall H. (8076565200); Lujan, J. Luis (24830859800)","55649209500; 6701439525; 57193424001; 57193416977; 8555844900; 8076565200; 24830859800","Computational Modeling of Neurotransmitter Release Evoked by Electrical Stimulation: Nonlinear Approaches to Predicting Stimulation-Evoked Dopamine Release","2017","ACS Chemical Neuroscience","22","10.1021/acschemneuro.6b00319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013750825&doi=10.1021%2facschemneuro.6b00319&partnerID=40&md5=5e09fbcf6faa74a0b20ea3c5272316d8","Mayo Graduate School, 200 First Street SW, Rochester, 55905, Minnesota, United States; Department of Neurologic Surgery, 200 First Street SW, Rochester, 55905, Minnesota, United States; Department of Physiology and Biomedical Engineering, 200 First Street SW, Rochester, 55905, Minnesota, United States; Department of Physical Medicine, Rehabilitation Mayo Clinic, 200 First Street SW, Rochester, 55905, Minnesota, United States; Department of Neurologic Surgery, Massachusetts General Hospital, Harvard Medical School, 25 Shattuck Street, Boston, 02115, Massachusetts, United States","Trevathan J.K., Mayo Graduate School, 200 First Street SW, Rochester, 55905, Minnesota, United States; Yousefi A., Department of Neurologic Surgery, Massachusetts General Hospital, Harvard Medical School, 25 Shattuck Street, Boston, 02115, Massachusetts, United States; Park H.O., Department of Neurologic Surgery, 200 First Street SW, Rochester, 55905, Minnesota, United States; Bartoletta J.J., Department of Neurologic Surgery, 200 First Street SW, Rochester, 55905, Minnesota, United States; Ludwig K.A., Department of Neurologic Surgery, 200 First Street SW, Rochester, 55905, Minnesota, United States; Lee K.H., Department of Neurologic Surgery, 200 First Street SW, Rochester, 55905, Minnesota, United States, Department of Physiology and Biomedical Engineering, 200 First Street SW, Rochester, 55905, Minnesota, United States, Department of Physical Medicine, Rehabilitation Mayo Clinic, 200 First Street SW, Rochester, 55905, Minnesota, United States; Lujan J.L., Department of Neurologic Surgery, 200 First Street SW, Rochester, 55905, Minnesota, United States, Department of Physiology and Biomedical Engineering, 200 First Street SW, Rochester, 55905, Minnesota, United States","Neurochemical changes evoked by electrical stimulation of the nervous system have been linked to both therapeutic and undesired effects of neuromodulation therapies used to treat obsessive-compulsive disorder, depression, epilepsy, Parkinson’s disease, stroke, hypertension, tinnitus, and many other indications. In fact, interest in better understanding the role of neurochemical signaling in neuromodulation therapies has been a focus of recent government- and industry-sponsored programs whose ultimate goal is to usher in an era of personalized medicine by creating neuromodulation therapies that respond to real-time changes in patient status. A key element to achieving these precision therapeutic interventions is the development of mathematical modeling approaches capable of describing the nonlinear transfer function between neuromodulation parameters and evoked neurochemical changes. Here, we propose two computational modeling frameworks, based on artificial neural networks (ANNs) and Volterra kernels, that can characterize the input/output transfer functions of stimulation-evoked neurochemical release. We evaluate the ability of these modeling frameworks to characterize subject-specific neurochemical kinetics by accurately describing stimulation-evoked dopamine release across rodent (R2 = 0.83 Volterra kernel, R2 = 0.86 ANN), swine (R2 = 0.90 Volterra kernel, R2 = 0.93 ANN), and non-human primate (R2 = 0.98 Volterra kernel, R2 = 0.96 ANN) models of brain stimulation. Ultimately, these models will not only improve understanding of neurochemical signaling in healthy and diseased brains but also facilitate the development of neuromodulation strategies capable of controlling neurochemical release via closed-loop strategies. © 2017 American Chemical Society.","artificial neural network; deep brain stimulation; dopamine; Fast scan cyclic voltammetry; machine learning; neurochemical sensing; Volterra kernels","Animals; Brain; Computer Simulation; Deep Brain Stimulation; Electrochemical Techniques; Female; Macaca mulatta; Models, Biological; Neurotransmitter Agents; Nonlinear Dynamics; Predictive Value of Tests; Principal Component Analysis; Rats; Rats, Sprague-Dawley; Swine; Time Factors; dopamine; agents interacting with transmitter, hormone or drug receptors; adult; animal experiment; Article; artificial neural network; brain depth stimulation; compartment model; controlled study; dopamine release; dopaminergic nerve cell; electrostimulation; experimental pig; extracellular matrix; female; kernel method; male; mathematical model; neurochemistry; neuromodulation; nonhuman; priority journal; rat; rhesus monkey; time series analysis; Volterra kernel; young adult; animal; biological model; brain; computer simulation; electrochemical analysis; metabolism; nonlinear system; pig; predictive value; principal component analysis; Sprague Dawley rat; time factor","American Chemical Society","19487193","","ACNCD","28076681","Article","Scopus","2-s2.0-85013750825"
"El-Askary H.; Lahaye N.; Linstead E.; Sprigg W.A.; Yacoub M.","El-Askary, Hesham (6602228395); Lahaye, Nick (57193030569); Linstead, Erik (16307496400); Sprigg, William A. (8921670600); Yacoub, Magdi (36041927900)","6602228395; 57193030569; 16307496400; 8921670600; 36041927900","Remote sensing observation of annual dust cycles and possible causality of Kawasaki disease outbreaks in Japan","2017","Global Cardiology Science and Practice","12","10.21542/gcsp.2017.22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064668818&doi=10.21542%2fgcsp.2017.22&partnerID=40&md5=af90b033954fa0459dbd8d8a761c9376","Schmid College of Science and Technology, Chapman University, Orange, CA, United States; Center of Excellence in Earth Systems Modeling and Observations, Chapman University, Orange, CA, United States; Department of Environmental Sciences, Faculty of Science, Alexandria University, Moharem Bek, Alexandria, Egypt; Jet Propulsion Laboratory, California Institute of Technology, CA, United States; Institute for Atmospheric Physics, University of Arizona, Tucson, AZ, United States; Faculty of Medicine, National Heart and Lung Institute, Imperial College of London, United Kingdom","El-Askary H., Schmid College of Science and Technology, Chapman University, Orange, CA, United States, Center of Excellence in Earth Systems Modeling and Observations, Chapman University, Orange, CA, United States, Department of Environmental Sciences, Faculty of Science, Alexandria University, Moharem Bek, Alexandria, Egypt; Lahaye N., Schmid College of Science and Technology, Chapman University, Orange, CA, United States, Jet Propulsion Laboratory, California Institute of Technology, CA, United States; Linstead E., Schmid College of Science and Technology, Chapman University, Orange, CA, United States; Sprigg W.A., Institute for Atmospheric Physics, University of Arizona, Tucson, AZ, United States; Yacoub M., Faculty of Medicine, National Heart and Lung Institute, Imperial College of London, United Kingdom","Kawasaki disease (KD) is a rare vascular disease that, if left untreated, can result in irreparable cardiac damage in children. While the symptoms of KD are well-known, as are best practices for treatment, the etiology of the disease and the factors contributing to KD outbreaks remain puzzling to both medical practitioners and scientists alike. Recently, a fungus known as Candida, originating in the farmlands of China, has been blamed for outbreaks in China and Japan, with the hypothesis that it can be transported over long ranges via different wind mechanisms. This paper provides evidence to understand the transport mechanisms of dust at different geographic locations and the cause of the annual spike of KD in Japan. Candida is carried along with many other dusts, particles or aerosols, of various sizes in major seasonal wind currents. The evidence is based upon particle categorization using the Moderate Resolution Imaging Spectrometer (MODIS) Aerosol Optical Depth (AOD), Fine Mode Fraction (FMF) and Ångström Exponent (AE), the Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation (CALIPSO) attenuated backscatter and aerosol subtype, and the Aerosol Robotic Network's (AERONET) derived volume concentration. We found that seasonality associated with aerosol size distribution at different geographic locations plays a role in identifying dominant abundance at each location. Knowing the typical size of the Candida fungus, and analyzing aerosol characteristics using AERONET data reveals possible particle transport association with KD events at different locations. Thus, understanding transport mechanisms and accurate identification of aerosol sources is important in order to understand possible triggers to outbreaks of KD. This work provides future opportunities to leverage machine learning, including state-of-The-Art deep architectures, to build predictive models of KD outbreaks, with the ultimate goal of early forecasting and intervention within a nascent global health early-warning system. © 2017 The Author(s), licensee Magdi Yacoub Institute.","","aerosol; air quality; Article; atmospheric transport; Candida; causal attribution; climate; Coccidioides; Coccidioides immitis; Coccidioides posadasii; concentration (parameters); disease association; dust; environmental factor; environmental monitoring; epidemic; geographic distribution; human; industrialization; Japan; mucocutaneous lymph node syndrome; nonhuman; observation; remote sensing; satellite imagery; seasonal variation; urbanization; wind; winter","HBKU Press","23057823","","","","Article","Scopus","2-s2.0-85064668818"
"Pavel M.S.; Schulz H.; Behnke S.","Pavel, Mircea Serban (57014657100); Schulz, Hannes (24470137900); Behnke, Sven (13007277900)","57014657100; 24470137900; 13007277900","Object class segmentation of RGB-D video using recurrent convolutional neural networks","2017","Neural Networks","22","10.1016/j.neunet.2017.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013301363&doi=10.1016%2fj.neunet.2017.01.003&partnerID=40&md5=4d2f9385b3042f4446e3f089a8090969","Universität Bonn, Computer Science Institute VI, Friedrich-Ebert-Allee 144, Bonn, 53113, Germany","Pavel M.S., Universität Bonn, Computer Science Institute VI, Friedrich-Ebert-Allee 144, Bonn, 53113, Germany; Schulz H., Universität Bonn, Computer Science Institute VI, Friedrich-Ebert-Allee 144, Bonn, 53113, Germany; Behnke S., Universität Bonn, Computer Science Institute VI, Friedrich-Ebert-Allee 144, Bonn, 53113, Germany","Object class segmentation is a computer vision task which requires labeling each pixel of an image with the class of the object it belongs to. Deep convolutional neural networks (DNN) are able to learn and take advantage of local spatial correlations required for this task. They are, however, restricted by their small, fixed-sized filters, which limits their ability to learn long-range dependencies. Recurrent Neural Networks (RNN), on the other hand, do not suffer from this restriction. Their iterative interpretation allows them to model long-range dependencies by propagating activity. This property is especially useful when labeling video sequences, where both spatial and temporal long-range dependencies occur. In this work, a novel RNN architecture for object class segmentation is presented. We investigate several ways to train such a network. We evaluate our models on the challenging NYU Depth v2 dataset for object class segmentation and obtain competitive results. © 2017 Elsevier Ltd","Computer vision; Object class-segmentation; Recurrent neural networks","Artificial Intelligence; Humans; Neural Networks (Computer); Pattern Recognition, Automated; Video Recording; Computer vision; Convolution; Convolutional neural networks; Deep neural networks; Image segmentation; Long-range dependencies; Object class; Recurrent neural network (RNN); Spatial correlations; Video sequences; Article; artificial neural network; computer analysis; controlled study; image analysis; image processing; machine learning; object class segmentation; positive feedback; recurrent convolutional neural network; statistical analysis; videorecording; artificial intelligence; automated pattern recognition; human; procedures; videorecording; Recurrent neural networks","Elsevier Ltd","08936080","","NNETE","28232260","Article","Scopus","2-s2.0-85013301363"
"Munoz-Organero M.; Ruiz-Blazquez R.","Munoz-Organero, Mario (26030525600); Ruiz-Blazquez, Ramona (57193276227)","26030525600; 57193276227","Time-elastic generative model for acceleration time series in human activity recognition","2017","Sensors (Switzerland)","17","10.3390/s17020319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012302508&doi=10.3390%2fs17020319&partnerID=40&md5=e31c3f57ca3624e077d054aeeb99d422","Telematics Engineering Department, Universidad Carlos III de Madrid, Av. Universidad, 30, Leganes, 28911, Spain","Munoz-Organero M., Telematics Engineering Department, Universidad Carlos III de Madrid, Av. Universidad, 30, Leganes, 28911, Spain; Ruiz-Blazquez R., Telematics Engineering Department, Universidad Carlos III de Madrid, Av. Universidad, 30, Leganes, 28911, Spain","Body-worn sensors in general and accelerometers in particular have been widely used in order to detect human movements and activities. The execution of each type of movement by each particular individual generates sequences of time series of sensed data from which specific movement related patterns can be assessed. Several machine learning algorithms have been used over windowed segments of sensed data in order to detect such patterns in activity recognition based on intermediate features (either hand-crafted or automatically learned from data). The underlying assumption is that the computed features will capture statistical differences that can properly classify different movements and activities after a training phase based on sensed data. In order to achieve high accuracy and recall rates (and guarantee the generalization of the system to new users), the training data have to contain enough information to characterize all possible ways of executing the activity or movement to be detected. This could imply large amounts of data and a complex and time-consuming training phase, which has been shown to be even more relevant when automatically learning the optimal features to be used. In this paper, we present a novel generative model that is able to generate sequences of time series for characterizing a particular movement based on the time elasticity properties of the sensed data. The model is used to train a stack of auto-encoders in order to learn the particular features able to detect human movements. The results of movement detection using a newly generated database with information on five users performing six different movements are presented. The generalization of results using an existing database is also presented in the paper. The results show that the proposed mechanism is able to obtain acceptable recognition rates (F = 0.77) even in the case of using different people executing a different sequence of movements and using different hardware. © 2017 by the authors; licensee MDPI, Basel, Switzerland.","Accelerometer sensors; Auto-encoders; Generative models for training deep learning algorithms; human activity recognition","Acceleration; Algorithms; Human Activities; Humans; Movement; Pattern Recognition, Automated; Accelerometers; Deep learning; Feature extraction; Image recognition; Signal encoding; Time series; Wearable sensors; Acceleration time series; Accelerometer sensor; Activity recognition; Auto encoders; Generative model; Human activity recognition; Large amounts of data; Statistical differences; acceleration; algorithm; automated pattern recognition; human; human activities; movement (physiology); Learning algorithms","MDPI AG","14248220","","","28208736","Article","Scopus","2-s2.0-85012302508"
"Sun K.; Zhang J.; Zhang C.; Hu J.","Sun, Kai (57193093191); Zhang, Jiangshe (9737712100); Zhang, Chunxia (55703936800); Hu, Junying (56729343000)","57193093191; 9737712100; 55703936800; 56729343000","Generalized extreme learning machine autoencoder and a new deep neural network","2017","Neurocomputing","132","10.1016/j.neucom.2016.12.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010723396&doi=10.1016%2fj.neucom.2016.12.027&partnerID=40&md5=f740b0db93009e2e140c58b1a47ef6dc","School of Mathematics and Statistics, Xi'an Jiaotong University, China","Sun K., School of Mathematics and Statistics, Xi'an Jiaotong University, China; Zhang J., School of Mathematics and Statistics, Xi'an Jiaotong University, China; Zhang C., School of Mathematics and Statistics, Xi'an Jiaotong University, China; Hu J., School of Mathematics and Statistics, Xi'an Jiaotong University, China","Extreme learning machine (ELM) is an efficient learning algorithm of training single layer feed-forward neural networks (SLFNs). With the development of unsupervised learning in recent years, integrating ELM with autoencoder has become a new perspective for extracting feature using unlabeled data. In this paper, we propose a new variant of extreme learning machine autoencoder (ELM-AE) called generalized extreme learning machine autoencoder (GELM-AE) which adds the manifold regularization to the objective of ELM-AE. Some experiments carried out on real-world data sets show that GELM-AE outperforms some state-of-the-art unsupervised learning algorithms, including k-means, laplacian embedding (LE), spectral clustering (SC) and ELM-AE. Furthermore, we also propose a new deep neural network called multilayer generalized extreme learning machine autoencoder (ML-GELM) by stacking several GELM-AE to detect more abstract representations. The experiments results show that ML-GELM outperforms ELM and many other deep models, such as multilayer ELM autoencoder (ML-ELM), deep belief network (DBN) and stacked autoencoder (SAE). Due to the utilization of ELM, ML-GELM is also faster than DBN and SAE. © 2016 Elsevier B.V.","Deep neural network; Extreme learning machine; Generalized extreme learning machine autoencoder; Manifold regularization; Multilayer generalized extreme learning machine autoencoder","Clustering algorithms; Knowledge acquisition; Learning algorithms; Multilayers; Unsupervised learning; Virtual reality; Abstract representation; Auto encoders; Deep belief network (DBN); Deep neural networks; Extracting features; Extreme learning machine; Manifold regularizations; Single layer feed-forward neural networks; Article; artificial neural network; generalized extreme learning machine autoencoder; information processing; k means algorithm; laplacian embedding algorithm; learning algorithm; mathematical computing; mathematical model; multilayer generalized extreme learning machine autoencoder; spectral clustering algorithm; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85010723396"
"Burlina P.; Pacheco K.D.; Joshi N.; Freund D.E.; Bressler N.M.","Burlina, Philippe (6603713214); Pacheco, Katia D. (56578134400); Joshi, Neil (57193277131); Freund, David E. (7007157970); Bressler, Neil M. (7005055349)","6603713214; 56578134400; 57193277131; 7007157970; 7005055349","Comparing humans and deep learning performance for grading AMD: A study in using universal deep features and transfer learning for automated AMD analysis","2017","Computers in Biology and Medicine","164","10.1016/j.compbiomed.2017.01.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012245192&doi=10.1016%2fj.compbiomed.2017.01.018&partnerID=40&md5=a507b78e962a7b02b6ee372365a71577","Applied Physics Laboratory, The Johns Hopkins University, MD, United States; Retina Division, Wilmer Eye Institute, Johns Hopkins University School of Medicine, United States; Department of Computer Science, The Johns Hopkins University, MD, United States; Retina Division, Brazilian Center of Vision Eye Hospital, DF, Brazil","Burlina P., Applied Physics Laboratory, The Johns Hopkins University, MD, United States, Retina Division, Wilmer Eye Institute, Johns Hopkins University School of Medicine, United States, Department of Computer Science, The Johns Hopkins University, MD, United States; Pacheco K.D., Retina Division, Brazilian Center of Vision Eye Hospital, DF, Brazil; Joshi N., Applied Physics Laboratory, The Johns Hopkins University, MD, United States; Freund D.E., Applied Physics Laboratory, The Johns Hopkins University, MD, United States; Bressler N.M., Retina Division, Wilmer Eye Institute, Johns Hopkins University School of Medicine, United States","Background When left untreated, age-related macular degeneration (AMD) is the leading cause of vision loss in people over fifty in the US. Currently it is estimated that about eight million US individuals have the intermediate stage of AMD that is often asymptomatic with regard to visual deficit. These individuals are at high risk for progressing to the advanced stage where the often treatable choroidal neovascular form of AMD can occur. Careful monitoring to detect the onset and prompt treatment of the neovascular form as well as dietary supplementation can reduce the risk of vision loss from AMD, therefore, preferred practice patterns recommend identifying individuals with the intermediate stage in a timely manner. Methods Past automated retinal image analysis (ARIA) methods applied on fundus imagery have relied on engineered and hand-designed visual features. We instead detail the novel application of a machine learning approach using deep learning for the problem of ARIA and AMD analysis. We use transfer learning and universal features derived from deep convolutional neural networks (DCNN). We address clinically relevant 4-class, 3-class, and 2-class AMD severity classification problems. Results Using 5664 color fundus images from the NIH AREDS dataset and DCNN universal features, we obtain values for accuracy for the (4-, 3-, 2-) class classification problem of (79.4%, 81.5%, 93.4%) for machine vs. (75.8%, 85.0%, 95.2%) for physician grading. Discussion This study demonstrates the efficacy of machine grading based on deep universal features/transfer learning when applied to ARIA and is a promising step in providing a pre-screener to identify individuals with intermediate AMD and also as a tool that can facilitate identifying such individuals for clinical studies aimed at developing improved therapies. It also demonstrates comparable performance between computer and physician grading. © 2017 Elsevier Ltd","Age-related macular degeneration, (AMD); Deep Convolutional Neural Networks, (DCNNs); Deep learning; Retinal image analysis; Transfer learning; Universal features","Algorithms; Early Diagnosis; Fluorescein Angiography; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Macular Degeneration; Observer Variation; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Severity of Illness Index; Aldehydes; Classification (of information); Convolution; Deep neural networks; Dietary supplements; Grading; Image analysis; Learning systems; Neural networks; Ophthalmology; Vision; Age-related macular degeneration; Convolutional neural network; Retinal image analysis; Transfer learning; Universal features; accuracy; age related macular degeneration; Article; artificial neural network; automated retinal image analysis; automation; classification algorithm; eye fundus; human; image analysis; machine learning; priority journal; retina image; scoring system; support vector machine; algorithm; automated pattern recognition; classification; comparative study; computer assisted diagnosis; diagnostic imaging; early diagnosis; evaluation study; fluorescence angiography; macular degeneration; observer variation; pathology; procedures; reproducibility; sensitivity and specificity; severity of illness index; Deep learning","Elsevier Ltd","00104825","","CBMDA","28167406","Article","Scopus","2-s2.0-85012245192"
"Chen S.; Qin J.; Ji X.; Lei B.; Wang T.; Ni D.; Cheng J.-Z.","Chen, Sihong (57192065868); Qin, Jing (35339855100); Ji, Xing (57192064992); Lei, Baiying (26422280400); Wang, Tianfu (55602702200); Ni, Dong (26023577500); Cheng, Jie-Zhi (9845624100)","57192065868; 35339855100; 57192064992; 26422280400; 55602702200; 26023577500; 9845624100","Automatic Scoring of Multiple Semantic Attributes with Multi-Task Feature Leverage: A Study on Pulmonary Nodules in CT Images","2017","IEEE Transactions on Medical Imaging","116","10.1109/TMI.2016.2629462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015080978&doi=10.1109%2fTMI.2016.2629462&partnerID=40&md5=1cae6c5b76968039f9709fc1114617a5","National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, School of Medicine, Shenzhen, 518060, China; Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong","Chen S., National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, School of Medicine, Shenzhen, 518060, China; Qin J., National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, School of Medicine, Shenzhen, 518060, China; Ji X., Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Lei B., National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, School of Medicine, Shenzhen, 518060, China; Wang T., National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, School of Medicine, Shenzhen, 518060, China; Ni D., National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, School of Medicine, Shenzhen, 518060, China; Cheng J.-Z., National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, School of Medicine, Shenzhen, 518060, China","The gap between the computational and semantic features is the one of major factors that bottlenecks the computer-aided diagnosis (CAD) performance from clinical usage. To bridge this gap, we exploit three multi-task learning (MTL) schemes to leverage heterogeneous computational features derived from deep learning models of stacked denoising autoencoder (SDAE) and convolutional neural network (CNN), as well as hand-crafted Haar-like and HoG features, for the description of 9 semantic features for lung nodules in CT images. We regard that there may exist relations among the semantic features of 'spiculation', 'texture', 'margin', etc., that can be explored with the MTL. The Lung Image Database Consortium (LIDC) data is adopted in this study for the rich annotation resources. The LIDC nodules were quantitatively scored w.r.t. 9 semantic features from 12 radiologists of several institutes in U.S.A. By treating each semantic feature as an individual task, the MTL schemes select and map the heterogeneous computational features toward the radiologists' ratings with cross validation evaluation schemes on the randomly selected 2400 nodules from the LIDC dataset. The experimental results suggest that the predicted semantic scores from the three MTL schemes are closer to the radiologists' ratings than the scores from single-task LASSO and elastic net regression methods. The proposed semantic attribute scoring scheme may provide richer quantitative assessments of nodules for better support of diagnostic decision and management. Meanwhile, the capability of the automatic association of medical image contents with the clinical semantic terms by our method may also assist the development of medical search engine. © 2016 IEEE.","Computed tomography (CT); Computer-aided diagnosis (CAD); Deep Learning; Feature learning; Lung nodule; Multi-task learning","Algorithms; Humans; Lung Neoplasms; Machine Learning; Neural Networks (Computer); Radiographic Image Interpretation, Computer-Assisted; Solitary Pulmonary Nodule; Tomography, X-Ray Computed; Biological organs; Computer aided instruction; Computerized tomography; Deep learning; Deep neural networks; Diagnosis; Learning systems; Linearization; Medical imaging; Neural networks; Regression analysis; Search engines; Semantics; Computational features; Computer Aided Diagnosis(CAD); Convolutional neural network; Feature learning; Lung nodule; Medical search engines; Multitask learning; Quantitative assessments; algorithm; Article; automation; computer aided design; convolutional neural network; hand crafted feature; histogram; human; lung nodule; machine learning; multi task learning scheme; multi task linear regression; neuron crafted feature; prediction; quantitative analysis; radiologist; random forest; search engine; semantics; stacked denoising autoencoder; x-ray computed tomography; algorithm; artificial neural network; computer assisted diagnosis; diagnostic imaging; lung nodule; lung tumor; procedures; x-ray computed tomography; Computer aided diagnosis","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","28113928","Article","Scopus","2-s2.0-85015080978"
"Cheng P.M.; Malhi H.S.","Cheng, Phillip M. (8693313300); Malhi, Harshawn S. (56410721300)","8693313300; 56410721300","Transfer Learning with Convolutional Neural Networks for Classification of Abdominal Ultrasound Images","2017","Journal of Digital Imaging","189","10.1007/s10278-016-9929-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997666818&doi=10.1007%2fs10278-016-9929-2&partnerID=40&md5=700728a742510e24ea8eda3a3b0ddfcd","Department of Radiology, Keck School of Medicine of USC, Los Angeles, CA, United States; USC Norris Cancer Center and Hospital, 1441 Eastlake Avenue, Suite 2315B, Los Angeles, 90033-0377, CA, United States","Cheng P.M., Department of Radiology, Keck School of Medicine of USC, Los Angeles, CA, United States, USC Norris Cancer Center and Hospital, 1441 Eastlake Avenue, Suite 2315B, Los Angeles, 90033-0377, CA, United States; Malhi H.S., Department of Radiology, Keck School of Medicine of USC, Los Angeles, CA, United States","The purpose of this study is to evaluate transfer learning with deep convolutional neural networks for the classification of abdominal ultrasound images. Grayscale images from 185 consecutive clinical abdominal ultrasound studies were categorized into 11 categories based on the text annotation specified by the technologist for the image. Cropped images were rescaled to 256 × 256 resolution and randomized, with 4094 images from 136 studies constituting the training set, and 1423 images from 49 studies constituting the test set. The fully connected layers of two convolutional neural networks based on CaffeNet and VGGNet, previously trained on the 2012 Large Scale Visual Recognition Challenge data set, were retrained on the training set. Weights in the convolutional layers of each network were frozen to serve as fixed feature extractors. Accuracy on the test set was evaluated for each network. A radiologist experienced in abdominal ultrasound also independently classified the images in the test set into the same 11 categories. The CaffeNet network classified 77.3% of the test set images accurately (1100/1423 images), with a top-2 accuracy of 90.4% (1287/1423 images). The larger VGGNet network classified 77.9% of the test set accurately (1109/1423 images), with a top-2 accuracy of VGGNet was 89.7% (1276/1423 images). The radiologist classified 71.7% of the test set images correctly (1020/1423 images). The differences in classification accuracies between both neural networks and the radiologist were statistically significant (p < 0.001). The results demonstrate that transfer learning with convolutional neural networks may be used to construct effective classifiers for abdominal ultrasound images. © 2016, Society for Imaging Informatics in Medicine.","Artificial neural networks; Classification; Deep learning; Digital image processing; Machine learning","Abdomen; Female; Humans; Learning Curve; Male; Neural Networks (Computer); Radiology; Ultrasonography; Artificial intelligence; Classification (of information); Convolution; Image processing; Learning systems; Network layers; Neural networks; Testing; Ultrasonics; Abdominal ultrasound images; Classification accuracy; Convolutional neural network; Deep learning; Feature extractor; Gray-scale images; Transfer learning; Visual recognition; abdomen; artificial neural network; classification; diagnostic imaging; echography; education; female; human; learning curve; male; radiology; Image classification","Springer New York LLC","08971889","","JDIME","27896451","Article","Scopus","2-s2.0-84997666818"
"Arbabshirani M.R.; Plis S.; Sui J.; Calhoun V.D.","Arbabshirani, Mohammad R. (36135424000); Plis, Sergey (8970496000); Sui, Jing (56579803600); Calhoun, Vince D. (57898536200)","36135424000; 8970496000; 56579803600; 57898536200","Single subject prediction of brain disorders in neuroimaging: Promises and pitfalls","2017","NeuroImage","598","10.1016/j.neuroimage.2016.02.079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962787673&doi=10.1016%2fj.neuroimage.2016.02.079&partnerID=40&md5=02c435791465a7d077ad0db2d5ba2137","The Mind Research Network, Albuquerque, 87106, NM, United States; Geisinger Health System, Danville, 17822, PA, United States; Brainnetome Center and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; Department of ECE, University of New Mexico, Albuquerque, NM, United States","Arbabshirani M.R., The Mind Research Network, Albuquerque, 87106, NM, United States, Geisinger Health System, Danville, 17822, PA, United States; Plis S., The Mind Research Network, Albuquerque, 87106, NM, United States; Sui J., The Mind Research Network, Albuquerque, 87106, NM, United States, Brainnetome Center and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; Calhoun V.D., The Mind Research Network, Albuquerque, 87106, NM, United States, Department of ECE, University of New Mexico, Albuquerque, NM, United States","Neuroimaging-based single subject prediction of brain disorders has gained increasing attention in recent years. Using a variety of neuroimaging modalities such as structural, functional and diffusion MRI, along with machine learning techniques, hundreds of studies have been carried out for accurate classification of patients with heterogeneous mental and neurodegenerative disorders such as schizophrenia and Alzheimer's disease. More than 500 studies have been published during the past quarter century on single subject prediction focused on a multiple brain disorders. In the first part of this study, we provide a survey of more than 200 reports in this field with a focus on schizophrenia, mild cognitive impairment (MCI), Alzheimer's disease (AD), depressive disorders, autism spectrum disease (ASD) and attention-deficit hyperactivity disorder (ADHD). Detailed information about those studies such as sample size, type and number of extracted features and reported accuracy are summarized and discussed. To our knowledge, this is by far the most comprehensive review of neuroimaging-based single subject prediction of brain disorders. In the second part, we present our opinion on major pitfalls of those studies from a machine learning point of view. Common biases are discussed and suggestions are provided. Moreover, emerging trends such as decentralized data sharing, multimodal brain imaging, differential diagnosis, disease subtype classification and deep learning are also discussed. Based on this survey, there is extensive evidence showing the great potential of neuroimaging data for single subject prediction of various disorders. However, the main bottleneck of this exciting field is still the limited sample size, which could be potentially addressed by modern data sharing models such as the ones discussed in this paper. Emerging big data technologies and advanced data-intensive machine learning methodologies such as deep learning have coincided with an increasing need for accurate, robust and generalizable single subject prediction of brain disorders during an exciting time. In this report, we survey the past and offer some opinions regarding the road ahead. © 2016 Elsevier Inc.","Brain disorders; Classification; Machine learning; Neuroimaging; Prediction","Brain Diseases; Humans; Machine Learning; Neuroimaging; accuracy; Alzheimer disease; Article; attention deficit disorder; autism; brain disease; cognitive defect; depression; differential diagnosis; disease classification; health survey; human; intermethod comparison; machine learning; mild cognitive impairment; neuroimaging; nuclear magnetic resonance imaging; prediction; priority journal; process optimization; risk factor; schizophrenia; brain disease; classification; diagnostic imaging; machine learning","Academic Press Inc.","10538119","","NEIME","27012503","Article","Scopus","2-s2.0-84962787673"
"Kondo T.; Kondo S.; Ueno J.; Takao S.","Kondo, Tadashi (55450770300); Kondo, Sayaka (57192074965); Ueno, Junji (7003362675); Takao, Shoichiro (16313930600)","55450770300; 57192074965; 7003362675; 16313930600","Medical image diagnosis of kidney regions by deep feedback GMDH-type neural network using principal component-regression analysis","2017","Artificial Life and Robotics","0","10.1007/s10015-016-0337-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996508944&doi=10.1007%2fs10015-016-0337-y&partnerID=40&md5=d9cbceda872b73e05908a49f98be0f9e","Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan; Tokushima Medical Informatics Laboratory, 264-5 Otubo, Hachiman-cho, Tokushima, 770-8079, Japan","Kondo T., Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan; Kondo S., Tokushima Medical Informatics Laboratory, 264-5 Otubo, Hachiman-cho, Tokushima, 770-8079, Japan; Ueno J., Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan; Takao S., Graduate School of Health Sciences, Tokushima University, 3-18-15 Kuramoto-cho, Tokushima, 770-8509, Japan","The deep feedback Group Method of Data Handling (GMDH)-type neural network is applied to the medical image recognition of kidney regions. In this algorithm, the principal component-regression analysis is used for the learning calculation of the neural network, and the accurate and stable predicted values are obtained. The neural network architecture is automatically organized so as to fit the complexity of the medical images using the prediction error criterion defined as Akaike’s Information Criterion (AIC) or Prediction Sum of Squares (PSS). The recognition results show that the deep feedback GMDH-type neural network algorithm is useful for the medical image recognition of kidney regions, because the optimum neural network architecture is automatically organized. © 2016, ISAROB.","Deep neural network; Evolutionary computation; GMDH; GMDH-type neural network; Machine learning; Medical image diagnosis","Agricultural robots; Data handling; Deep learning; Deep neural networks; Diagnosis; Evolutionary algorithms; Image recognition; Learning systems; Medical imaging; Network architecture; Regression analysis; GMDH; GMDH-type neural networks; Group method of data handling; Information criterion; Medical image diagnosis; Prediction errors; Principal component regression analysis; Sum of squares; Neural networks","Springer Japan","14335298","","","","Article","Scopus","2-s2.0-84996508944"
"Wu Y.; Jiang M.; Xu J.; Zhi D.; Xu H.","Wu, Yonghui (55645924700); Jiang, Min (43161193700); Xu, Jun (57188810997); Zhi, Degui (57211105610); Xu, Hua (55493876700)","55645924700; 43161193700; 57188810997; 57211105610; 55493876700","Clinical Named Entity Recognition Using Deep Learning Models","2017","AMIA ... Annual Symposium proceedings. AMIA Symposium","78","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058766468&partnerID=40&md5=304d586673abdf44ac9fe4dd1b71748e","School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States","Wu Y., School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States; Jiang M., School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States; Xu J., School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States; Zhi D., School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States; Xu H., School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States","Clinical Named Entity Recognition (NER) is a critical natural language processing (NLP) task to extract important concepts (named entities) from clinical narratives. Researchers have extensively investigated machine learning models for clinical NER. Recently, there have been increasing efforts to apply deep learning models to improve the performance of current clinical NER systems. This study examined two popular deep learning architectures, the Convolutional Neural Network (CNN) and the Recurrent Neural Network (RNN), to extract concepts from clinical texts. We compared the two deep neural network architectures with three baseline Conditional Random Fields (CRFs) models and two state-of-the-art clinical NER systems using the i2b2 2010 clinical concept extraction corpus. The evaluation results showed that the RNN model trained with the word embeddings achieved a new state-of-the- art performance (a strict F1 score of 85.94%) for the defined clinical NER task, outperforming the best-reported system that used both manually defined and unsupervised learning features. This study demonstrates the advantage of using deep neural network architectures for clinical concept extraction, including distributed feature representation, automatic feature learning, and long-term dependencies capture. This is one of the first studies to compare the two widely used deep learning models and demonstrate the superior performance of the RNN model for clinical NER.","","Datasets as Topic; Deep Learning; Medical Records; Natural Language Processing; Neural Networks (Computer); artificial neural network; comparative study; information processing; medical record; natural language processing","NLM (Medline)","1942597X","","","29854252","Article","Scopus","2-s2.0-85058766468"
"Jiang M.; Pan Z.; Tang Z.","Jiang, Mingxin (36634408600); Pan, Zhigeng (7402644439); Tang, Zhenzhou (24072211700)","36634408600; 7402644439; 24072211700","Visual object tracking based on cross-modality Gaussian-Bernoulli deep Boltzmann machines with RGB-D sensors","2017","Sensors (Switzerland)","13","10.3390/s17010121","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009799696&doi=10.3390%2fs17010121&partnerID=40&md5=c86fd759853d8440e8bfdca7d22521dd","Faculty of Computer and Software Engineering, Huaiyin Institute of Technology, Huai’an, 223003, China; Digital Media &Interaction Research Center, Hangzhou Normal University, Hangzhou, 310012, China; College of Physics and Electronic Information Engineering, Wenzhou University, Wenzhou, 325035, China","Jiang M., Faculty of Computer and Software Engineering, Huaiyin Institute of Technology, Huai’an, 223003, China; Pan Z., Digital Media &Interaction Research Center, Hangzhou Normal University, Hangzhou, 310012, China; Tang Z., College of Physics and Electronic Information Engineering, Wenzhou University, Wenzhou, 325035, China","Visual object tracking technology is one of the key issues in computer vision. In this paper, we propose a visual object tracking algorithm based on cross-modality featuredeep learning using Gaussian-Bernoulli deep Boltzmann machines (DBM) with RGB-D sensors. First, a cross-modality featurelearning network based on aGaussian-Bernoulli DBM is constructed, which can extract cross-modality features of the samples in RGB-D video data. Second, the cross-modality features of the samples are input into the logistic regression classifier, andthe observation likelihood model is established according to the confidence score of the classifier. Finally, the object tracking results over RGB-D data are obtained using aBayesian maximum a posteriori (MAP) probability estimation algorithm. The experimental results show that the proposed method has strong robustness to abnormal changes (e.g., occlusion, rotation, illumination change, etc.). The algorithm can steadily track multiple targets and has higher accuracy. © 2017 by the authors; licensee MDPI, Basel, Switzerland.","Bayesian MAP; Cross-modality features; Gaussian-Bernoulli deep Boltzmann machines; Visual object tracking","Gaussian distribution; Image processing; Maximum likelihood estimation; Bayesian MAP; Bernoulli; Cross modality; Deep boltzmann machines; Logistic regression classifier; Maximum A posteriori probabilities; Track multiple targets; Visual object tracking; Tracking (position)","MDPI AG","14248220","","","28075373","Article","Scopus","2-s2.0-85009799696"
"Pitti A.; Gaussier P.; Quoy M.","Pitti, Alexandre (24402125400); Gaussier, Philippe (7004105798); Quoy, Mathias (57203005814)","24402125400; 7004105798; 57203005814","Iterative free-energy optimization for recurrent neural networks (INFERNO)","2017","PLoS ONE","9","10.1371/journal.pone.0173684","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015241908&doi=10.1371%2fjournal.pone.0173684&partnerID=40&md5=d2edfd120fbe7f0c1c0cfc46e23f218d","ETIS Laboratory, CNRS UMR 8051, University of Cergy-Pontoise, ENSEA, Paris-Seine, Cergy-Pontoise, France","Pitti A., ETIS Laboratory, CNRS UMR 8051, University of Cergy-Pontoise, ENSEA, Paris-Seine, Cergy-Pontoise, France; Gaussier P., ETIS Laboratory, CNRS UMR 8051, University of Cergy-Pontoise, ENSEA, Paris-Seine, Cergy-Pontoise, France; Quoy M., ETIS Laboratory, CNRS UMR 8051, University of Cergy-Pontoise, ENSEA, Paris-Seine, Cergy-Pontoise, France","The intra-parietal lobe coupled with the Basal Ganglia forms a working memory that demonstrates strong planning capabilities for generating robust yet flexible neuronal sequences. Neurocomputational models however, often fails to control long range neural synchrony in recurrent spiking networks due to spontaneous activity. As a novel framework based on the free-energy principle, we propose to see the problem of spikes' synchrony as an optimization problem of the neurons sub-threshold activity for the generation of long neuronal chains. Using a stochastic gradient descent, a reinforcement signal (presumably dopaminergic) evaluates the quality of one input vector to move the recurrent neural network to a desired activity; depending on the error made, this input vector is strengthened to hill-climb the gradient or elicited to search for another solution. This vector can be learned then by one associative memory as a model of the basal-ganglia to control the recurrent neural network. Experiments on habit learning and on sequence retrieving demonstrate the capabilities of the dual system to generate very long and precise spatiooral sequences, above two hundred iterations. Its features are applied then to the sequential planning of arm movements. In line with neurobiological theories, we discuss its relevance for modeling the cortico- basal working memory to initiate flexible goal-directed neuronal chains of causation and its relation to novel architectures such as Deep Networks, Neural Turing Machines and the Free-Energy Principle. © 2017 Pitti et al.This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Arm; Artificial Limbs; Brain; Humans; Memory, Short-Term; Models, Neurological; Nerve Net; Neural Networks (Computer); Reinforcement (Psychology); Robotics; Stochastic Processes; arm movement; associative memory; basal ganglion; machine; nerve cell; parietal lobe; reinforcement; spike; stochastic model; working memory; algorithm; arm; artificial neural network; biological model; brain; human; limb prosthesis; Markov chain; nerve cell network; physiology; robotics; short term memory","Public Library of Science","19326203","","POLNC","28282439","Article","Scopus","2-s2.0-85015241908"
"Wang Z.; Wu Q.","Wang, Zheng (57195327685); Wu, Qingbiao (12646898900)","57195327685; 12646898900","Shape Completion Using Deep Boltzmann Machine","2017","Computational Intelligence and Neuroscience","5","10.1155/2017/5705693","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027097200&doi=10.1155%2f2017%2f5705693&partnerID=40&md5=64c6faae4e09ef2bab8a863358851279","School of Mathematical Sciences, Zhejiang University, Hangzhou, Zhejiang, China","Wang Z., School of Mathematical Sciences, Zhejiang University, Hangzhou, Zhejiang, China; Wu Q., School of Mathematical Sciences, Zhejiang University, Hangzhou, Zhejiang, China","Shape completion is an important task in the field of image processing. An alternative method is to capture the shape information and finish the completion by a generative model, such as Deep Boltzmann Machine. With its powerful ability to deal with the distribution of the shapes, it is quite easy to acquire the result by sampling from the model. In this paper, we make use of the hidden activation of the DBM and incorporate it with the convolutional shape features to fit a regression model. We compare the output of the regression model with the incomplete shape feature in order to set a proper and compact mask for sampling from the DBM. The experiment shows that our method can obtain realistic results without any prior information about the incomplete object shape. © 2017 Zheng Wang and Qingbiao Wu.","","Image Processing, Computer-Assisted; Machine Learning; Regression Analysis; Regression analysis; Deep boltzmann machines; Generative model; Object shape; Prior information; Regression model; Shape completions; Shape features; Shape information; image processing; machine learning; procedures; regression analysis; Image processing","Hindawi Limited","16875265","","","28804496","Article","Scopus","2-s2.0-85027097200"
"Banerjee I.; Madhavan S.; Goldman R.E.; Rubin D.L.","Banerjee, Imon (36095937900); Madhavan, Sriraman (57217674238); Goldman, Roger Eric (23008433500); Rubin, Daniel L. (7202307112)","36095937900; 57217674238; 23008433500; 7202307112","Intelligent Word Embeddings of Free-Text Radiology Reports","2017","AMIA ... Annual Symposium proceedings. AMIA Symposium","22","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057020140&partnerID=40&md5=556e3a742f637e6b0c670e5cbf44d4de","Department of Radiology, Stanford University School of Medicine, Stanford, United States","Banerjee I., Department of Radiology, Stanford University School of Medicine, Stanford, United States; Madhavan S., Department of Radiology, Stanford University School of Medicine, Stanford, United States; Goldman R.E., Department of Radiology, Stanford University School of Medicine, Stanford, United States; Rubin D.L., Department of Radiology, Stanford University School of Medicine, Stanford, United States","Radiology reports are a rich resource for advancing deep learning applications in medicine by leveraging the large volume of data continuously being updated, integrated, and shared. However, there are significant challenges as well, largely due to the ambiguity and subtlety of natural language. We propose a hybrid strategy that combines semantic-dictionary mapping and word2vec modeling for creating dense vector embeddings of free-text radiology reports. Our method leverages the benefits of both semantic-dictionary mapping as well as unsupervised learning. Using the vector representation, we automatically classify the radiology reports into three classes denoting confidence in the diagnosis of intracranial hemorrhage by the interpreting radiologist. We performed experiments with varying hyperparameter settings of the word embeddings and a range of different classifiers. Best performance achieved was a weighted precision of 88% and weighted recall of 90%. Our work offers the potential to leverage unstructured electronic health record data by allowing direct analysis of narrative clinical notes.","","Datasets as Topic; Electronic Health Records; Humans; Intracranial Hemorrhages; Machine Learning; Natural Language Processing; Radiology Information Systems; Semantics; brain hemorrhage; diagnostic imaging; electronic health record; human; information processing; machine learning; natural language processing; radiology information system; semantics","NLM (Medline)","1942597X","","","29854105","Article","Scopus","2-s2.0-85057020140"
"Choi E.; Schuetz A.; Stewart W.F.; Sun J.","Choi, Edward (57188811144); Schuetz, Andy (57193731825); Stewart, Walter F. (55549970400); Sun, Jimeng (9737233900)","57188811144; 57193731825; 55549970400; 9737233900","Using recurrent neural network models for early detection of heart failure onset","2017","Journal of the American Medical Informatics Association","553","10.1093/jamia/ocw112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016146323&doi=10.1093%2fjamia%2focw112&partnerID=40&md5=32a063790245dfb2ea0e86a43f4a14b9","Georgia Institute of Technology, Atlanta, United States; Sutter Health, Walnut Creek, CA, United States","Choi E., Georgia Institute of Technology, Atlanta, United States; Schuetz A., Sutter Health, Walnut Creek, CA, United States; Stewart W.F., Sutter Health, Walnut Creek, CA, United States; Sun J., Georgia Institute of Technology, Atlanta, United States","Objective: We explored whether use of deep learning to model temporal relations among events in electronic health records (EHRs) would improve model performance in predicting initial diagnosis of heart failure (HF) compared to conventional methods that ignore temporality. Materials and Methods: Data were from a health system's EHR on 3884 incident HF cases and 28 903 controls, identified as primary care patients, between May 16, 2000, and May 23, 2013. Recurrent neural network (RNN) models using gated recurrent units (GRUs) were adapted to detect relations among time-stamped events (eg, disease diagnosis, medication orders, procedure orders, etc.) with a 12- to 18-month observation window of cases and controls. Model performance metrics were compared to regularized logistic regression, neural network, support vector machine, and K-nearest neighbor classifier approaches. Results: Using a 12-month observation window, the area under the curve (AUC) for the RNN model was 0.777, compared to AUCs for logistic regression (0.747), multilayer perceptron (MLP) with 1 hidden layer (0.765), support vector machine (SVM) (0.743), and K-nearest neighbor (KNN) (0.730). When using an 18-month observation window, the AUC for the RNN model increased to 0.883 and was significantly higher than the 0.834 AUC for the best of the baseline methods (MLP). Conclusion: Deep learning models adapted to leverage temporal relations appear to improve performance of models for detection of incident heart failure with a short observation window of 12-18 months. © The Author 2016. Published by Oxford University Press on behalf of the American Medical Informatics Association.","Deep learning; Electronic health records; Heart failure prediction; Patient progression model; Recurrent neural network","Area Under Curve; Early Diagnosis; Electronic Health Records; Heart Failure; Humans; Logistic Models; Machine Learning; Neural Networks (Computer); Support Vector Machine; area under the curve; Article; artificial neural network; controlled study; early diagnosis; electronic health record; heart failure; human; k nearest neighbor; major clinical study; perceptron; support vector machine; electronic health record; heart failure; machine learning; statistical model","Oxford University Press","10675027","","JAMAF","27521897","Article","Scopus","2-s2.0-85016146323"
"Erickson B.J.; Korfiatis P.; Akkus Z.; Kline T.L.","Erickson, Bradley J. (7201472755); Korfiatis, Panagiotis (23397073600); Akkus, Zeynettin (41560908300); Kline, Timothy L. (26648884000)","7201472755; 23397073600; 41560908300; 26648884000","Machine learning for medical imaging","2017","Radiographics","971","10.1148/rg.2017160130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015225428&doi=10.1148%2frg.2017160130&partnerID=40&md5=2200293a2fc057eee18d4804c07da751","Department of Radiology, Mayo Clinic, 200 First St SW, Rochester, 55905, MN, United States","Erickson B.J., Department of Radiology, Mayo Clinic, 200 First St SW, Rochester, 55905, MN, United States; Korfiatis P., Department of Radiology, Mayo Clinic, 200 First St SW, Rochester, 55905, MN, United States; Akkus Z., Department of Radiology, Mayo Clinic, 200 First St SW, Rochester, 55905, MN, United States; Kline T.L., Department of Radiology, Mayo Clinic, 200 First St SW, Rochester, 55905, MN, United States","Machine learning is a technique for recognizing patterns that can be applied to medical images. Although it is a powerful tool that can help in rendering medical diagnoses, it can be misapplied. Machine learning typically begins with the machine learning algorithm system computing the image features that are believed to be of importance in making the prediction or diagnosis of interest. The machine learning algorithm system then identifies the best combination of these image features for classifying the image or computing some metric for the given image region. There are several methods that can be used, each with different strengths and weaknesses. There are open-source versions of most of these machine learning methods that make them easy to try and apply to images. Several metrics for measuring the performance of an algorithm exist; however, one must be aware of the possible associated pitfalls that can result in misleading metrics. More recently, deep learning has started to be used; this method has the benefit that it does not require image feature identification and calculation as a first step; rather, features are identified as part of the learning process. Machine learning has been used in medical imaging and will have a greater influence in the future. Those working in medical imaging must be aware of how machine learning works. © RSNA, 2017.","","Algorithms; Diagnostic Imaging; Humans; Image Interpretation, Computer-Assisted; Machine Learning; calculation; diagnosis; diagnostic imaging; machine learning; prediction; algorithm; computer assisted diagnosis; human","Radiological Society of North America Inc.","02715333","","","28212054","Article","Scopus","2-s2.0-85015225428"
"Shayanfar N.; Derhami V.; Rezaeian M.","Shayanfar, Nima (57201858923); Derhami, Vali (26434197700); Rezaeian, Mehdi (36697027600)","57201858923; 26434197700; 36697027600","Deep recurrent neural networks in HIV-1 protease cleavage classification","2017","International Journal of Data Mining and Bioinformatics","2","10.1504/IJDMB.2017.091364","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046248873&doi=10.1504%2fIJDMB.2017.091364&partnerID=40&md5=07c79d74655265924c2a0984ea01b9c4","Computer Engineering Department, Faculty of Engineering, Yazd University, Yazd, Iran","Shayanfar N., Computer Engineering Department, Faculty of Engineering, Yazd University, Yazd, Iran; Derhami V., Computer Engineering Department, Faculty of Engineering, Yazd University, Yazd, Iran; Rezaeian M., Computer Engineering Department, Faculty of Engineering, Yazd University, Yazd, Iran","Many of the drugs that are used by HIV infected humans can be catalogued as protease inhibitors. These drugs mainly restrict the protease activity and therefore reduce the formation of mature proteins. By studying the protease and predicting its cleavage sites, one can hope to achieve better drugs. Predicting HIV-1 protease cleavage problem has been addressed by many machine learning approaches but its classification false positive and the lack of an approach with good generalisation remains a challenge. Furthermore, deep neural networks have shown many promising results in machine learning community. Therefore, we present a new deep learning approach to predict protease cleavage sites based on bidirectional Gated Recurrent Units and feed-forward networks. We have tested this approach on several datasets and achieved 89.04% accuracy and 92.45% AUC on average. Copyright © 2017 Inderscience Enterprises Ltd.","Bidirectional recurrent networks; Deep neural network; Gated recurrent unit; HIV protease; Prediction","","Inderscience Publishers","17485673","","","","Article","Scopus","2-s2.0-85046248873"
"Protopapadakis E.; Voulodimos A.; Doulamis A.; Doulamis N.; Dres D.; Bimpas M.","Protopapadakis, Eftychios (55421202900); Voulodimos, Athanasios (25032274400); Doulamis, Anastasios (35565008000); Doulamis, Nikolaos (7003749049); Dres, Dimitrios (6603112291); Bimpas, Matthaios (6507196766)","55421202900; 25032274400; 35565008000; 7003749049; 6603112291; 6507196766","Stacked Autoencoders for Outlier Detection in Over-the-Horizon Radar Signals","2017","Computational Intelligence and Neuroscience","38","10.1155/2017/5891417","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040668168&doi=10.1155%2f2017%2f5891417&partnerID=40&md5=00c57aec2a8ce9eb8bcc5fe0896a8297","National Technical University of Athens, Athens, 15780, Greece; Department of Informatics, Technological Educational Institute of Athens, Athens, 12243, Greece; Telesto Technologies, Cholargos, 15561, Greece","Protopapadakis E., National Technical University of Athens, Athens, 15780, Greece; Voulodimos A., National Technical University of Athens, Athens, 15780, Greece, Department of Informatics, Technological Educational Institute of Athens, Athens, 12243, Greece; Doulamis A., National Technical University of Athens, Athens, 15780, Greece; Doulamis N., National Technical University of Athens, Athens, 15780, Greece; Dres D., Telesto Technologies, Cholargos, 15561, Greece; Bimpas M., Telesto Technologies, Cholargos, 15561, Greece","Detection of outliers in radar signals is a considerable challenge in maritime surveillance applications. High-Frequency Surface-Wave (HFSW) radars have attracted significant interest as potential tools for long-range target identification and outlier detection at over-the-horizon (OTH) distances. However, a number of disadvantages, such as their low spatial resolution and presence of clutter, have a negative impact on their accuracy. In this paper, we explore the applicability of deep learning techniques for detecting deviations from the norm in behavioral patterns of vessels (outliers) as they are tracked from an OTH radar. The proposed methodology exploits the nonlinear mapping capabilities of deep stacked autoencoders in combination with density-based clustering. A comparative experimental evaluation of the approach shows promising results in terms of the proposed methodology's performance. © 2017 Eftychios Protopapadakis et al.","","Algorithms; Cluster Analysis; Humans; Machine Learning; Nonlinear Dynamics; Radar; Signal Processing, Computer-Assisted; Signal-To-Noise Ratio; Wind; Data handling; Deep learning; Learning systems; Radar; Statistics; Surface waves; Behavioral patterns; Density-based Clustering; Detecting deviations; Experimental evaluation; High-frequency surfaces; Learning techniques; Maritime surveillance; Over-the-horizon radar; algorithm; cluster analysis; human; machine learning; nonlinear system; signal noise ratio; signal processing; telecommunication; wind; Tracking radar","Hindawi Limited","16875265","","","29312449","Article","Scopus","2-s2.0-85040668168"
"Tabar Y.R.; Halici U.","Tabar, Yousef Rezaei (57193087364); Halici, Ugur (7003652887)","57193087364; 7003652887","A novel deep learning approach for classification of EEG motor imagery signals","2017","Journal of Neural Engineering","663","10.1088/1741-2560/14/1/016003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010685974&doi=10.1088%2f1741-2560%2f14%2f1%2f016003&partnerID=40&md5=643508265b386375ff712faa91184301","Biomedical Engineering Department, Middle East Technical University, Ankara, Turkey; Department of Electrical and Electronics Engineering, Neuroscience and Neurotechnology, Middle East Technical University, Ankara, Turkey","Tabar Y.R., Biomedical Engineering Department, Middle East Technical University, Ankara, Turkey; Halici U., Department of Electrical and Electronics Engineering, Neuroscience and Neurotechnology, Middle East Technical University, Ankara, Turkey","Objective. Signal classification is an important issue in brain computer interface (BCI) systems. Deep learning approaches have been used successfully in many recent studies to learn features and classify different types of data. However, the number of studies that employ these approaches on BCI applications is very limited. In this study we aim to use deep learning methods to improve classification performance of EEG motor imagery signals. Approach. In this study we investigate convolutional neural networks (CNN) and stacked autoencoders (SAE) to classify EEG Motor Imagery signals. A new form of input is introduced to combine time, frequency and location information extracted from EEG signal and it is used in CNN having one 1D convolutional and one max-pooling layers. We also proposed a new deep network by combining CNN and SAE. In this network, the features that are extracted in CNN are classified through the deep network SAE. Main results. The classification performance obtained by the proposed method on BCI competition IV dataset 2b in terms of kappa value is 0.547. Our approach yields 9% improvement over the winner algorithm of the competition. Significance. Our results show that deep learning methods provide better classification performance compared to other state of art approaches. These methods can be applied successfully to BCI systems where the amount of data is alarge due to daily recording. © 2016 IOP Publishing Ltd.","BCI; convolutional neural networks; deep learning; EEG; motor imagery; stacked autoencoders","Algorithms; Brain-Computer Interfaces; Electroencephalography; Evoked Potentials, Motor; Humans; Imagination; Machine Learning; Movement; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Sensorimotor Cortex; Brain computer interface; Classification (of information); Convolution; Deep learning; Electroencephalography; Image classification; Image enhancement; Interfaces (computer); Neural networks; Autoencoders; Classification performance; Convolutional neural network; Convolutional Neural Networks (CNN); Learning approach; Location information; Motor imagery; Signal classification; accuracy; algorithm; Article; brain computer interface; classifier; electroencephalography; learning; priority journal; validation process; automated pattern recognition; brain computer interface; comparative study; electroencephalography; evaluation study; human; imagination; machine learning; motor evoked potential; movement (physiology); physiology; procedures; reproducibility; sensitivity and specificity; sensorimotor cortex; validation study; Biomedical signal processing","Institute of Physics Publishing","17412560","","","27900952","Article","Scopus","2-s2.0-85010685974"
"Choi H.; Ha S.; Im H.J.; Paek S.H.; Lee D.S.","Choi, Hongyoon (45760940100); Ha, Seunggyun (55702164600); Im, Hyung Jun (57222878808); Paek, Sun Ha (35278434400); Lee, Dong Soo (56580452900)","45760940100; 55702164600; 57222878808; 35278434400; 56580452900","Refining diagnosis of Parkinson's disease with deep learning-based interpretation of dopamine transporter imaging","2017","NeuroImage: Clinical","112","10.1016/j.nicl.2017.09.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029590901&doi=10.1016%2fj.nicl.2017.09.010&partnerID=40&md5=2f97813ac8f7e6a1a42329f4ea070153","Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, South Korea; Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea; Department of Transdisciplinary Studies, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea; Department of Neurosurgery, Seoul National University Hospital, Seoul, South Korea; Korea Brain Research Institute, Daegu, South Korea","Choi H., Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, South Korea, Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea; Ha S., Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, South Korea, Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea; Im H.J., Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, South Korea, Department of Transdisciplinary Studies, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea; Paek S.H., Department of Neurosurgery, Seoul National University Hospital, Seoul, South Korea; Lee D.S., Department of Nuclear Medicine, Seoul National University College of Medicine, Seoul, South Korea, Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea, Korea Brain Research Institute, Daegu, South Korea","Dopaminergic degeneration is a pathologic hallmark of Parkinson's disease (PD), which can be assessed by dopamine transporter imaging such as FP-CIT SPECT. Until now, imaging has been routinely interpreted by human though it can show interobserver variability and result in inconsistent diagnosis. In this study, we developed a deep learning-based FP-CIT SPECT interpretation system to refine the imaging diagnosis of Parkinson's disease. This system trained by SPECT images of PD patients and normal controls shows high classification accuracy comparable with the experts’ evaluation referring quantification results. Its high accuracy was validated in an independent cohort composed of patients with PD and nonparkinsonian tremor. In addition, we showed that some patients clinically diagnosed as PD who have scans without evidence of dopaminergic deficit (SWEDD), an atypical subgroup of PD, could be reclassified by our automated system. Our results suggested that the deep learning-based model could accurately interpret FP-CIT SPECT and overcome variability of human evaluation. It could help imaging diagnosis of patients with uncertain Parkinsonism and provide objective patient group classification, particularly for SWEDD, in further clinical studies. © 2017 The Authors","Deep learning; Deep neural network; FP-CIT; Parkinson's disease; SWEDD","Aged; Algorithms; Dopamine Plasma Membrane Transport Proteins; Female; Humans; Machine Learning; Male; Middle Aged; Neural Networks (Computer); Neuroimaging; Parkinson Disease; Radionuclide Imaging; Tomography, Emission-Computed, Single-Photon; Tropanes; dopamine transporter; 2-carbomethoxy-8-(3-fluoropropyl)-3-(4-iodophenyl)tropane; dopamine transporter; tropane derivative; adult; Article; brain size; controlled study; diagnostic accuracy; drug response; female; follow up; human; major clinical study; male; middle aged; neuroimaging; Parkinson disease; priority journal; retrospective study; single photon emission computed tomography; Unified Parkinson Disease Rating Scale; aged; algorithm; artificial neural network; diagnostic imaging; machine learning; neuroimaging; Parkinson disease; procedures; scintiscanning","Elsevier Inc.","22131582","","","28971009","Article","Scopus","2-s2.0-85029590901"
"Shpacovitch V.; Sidorenko I.; Lenssen J.E.; Temchura V.; Weichert F.; Müller H.; Überla K.; Zybin A.; Schramm A.; Hergenröder R.","Shpacovitch, Victoria (6507599578); Sidorenko, Irina (57197796136); Lenssen, Jan Eric (57193505421); Temchura, Vladimir (6506995680); Weichert, Frank (8708701900); Müller, Heinrich (24399288400); Überla, Klaus (7006244554); Zybin, Alexander (57194375425); Schramm, Alexander (35622254200); Hergenröder, Roland (55903363700)","6507599578; 57197796136; 57193505421; 6506995680; 8708701900; 24399288400; 7006244554; 57194375425; 35622254200; 55903363700","Application of the PAMONO-sensor for quantification of microvesicles and determination of nano-particle size distribution","2017","Sensors (Switzerland)","24","10.3390/s17020244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014352036&doi=10.3390%2fs17020244&partnerID=40&md5=9af078e0f389658c0eac4c448ca51d89","Leibniz Institute für Analytische Wissenschaften, ISAS e.V., Bunsen-Kirchhoff-Straße 11, Dortmund, 44139, Germany; MIVITEC GmbH, Wamslerstraße.4, Munich, 81829, Germany; Department of Computer Science VII, TU Dortmund University, Otto-Hahn-Straße. 16, Dortmund, 44227, Germany; Institute of Clinical and Molecular Virology, University Hospital Erlangen, Friedrich-Alexander University Erlangen-Nürnberg, Schlossgarten 4, Erlangen, 91054, Germany; Children’s Hospital, Oncology Laboratory, University Clinic Essen, Hufelandstraße. 55, Essen, 45122, Germany","Shpacovitch V., Leibniz Institute für Analytische Wissenschaften, ISAS e.V., Bunsen-Kirchhoff-Straße 11, Dortmund, 44139, Germany; Sidorenko I., MIVITEC GmbH, Wamslerstraße.4, Munich, 81829, Germany; Lenssen J.E., Department of Computer Science VII, TU Dortmund University, Otto-Hahn-Straße. 16, Dortmund, 44227, Germany; Temchura V., Institute of Clinical and Molecular Virology, University Hospital Erlangen, Friedrich-Alexander University Erlangen-Nürnberg, Schlossgarten 4, Erlangen, 91054, Germany; Weichert F., Department of Computer Science VII, TU Dortmund University, Otto-Hahn-Straße. 16, Dortmund, 44227, Germany; Müller H., Department of Computer Science VII, TU Dortmund University, Otto-Hahn-Straße. 16, Dortmund, 44227, Germany; Überla K., Institute of Clinical and Molecular Virology, University Hospital Erlangen, Friedrich-Alexander University Erlangen-Nürnberg, Schlossgarten 4, Erlangen, 91054, Germany; Zybin A., Leibniz Institute für Analytische Wissenschaften, ISAS e.V., Bunsen-Kirchhoff-Straße 11, Dortmund, 44139, Germany; Schramm A., Children’s Hospital, Oncology Laboratory, University Clinic Essen, Hufelandstraße. 55, Essen, 45122, Germany; Hergenröder R., Leibniz Institute für Analytische Wissenschaften, ISAS e.V., Bunsen-Kirchhoff-Straße 11, Dortmund, 44139, Germany","The PAMONO-sensor (plasmon assisted microscopy of nano-objects) demonstrated an ability to detect and quantify individual viruses and virus-like particles. However, another group of biological vesicles—microvesicles (100–1000 nm)—also attracts growing interest as biomarkers of different pathologies and needs development of novel techniques for characterization. This work shows the applicability of a PAMONO-sensor for selective detection of microvesicles in aquatic samples. The sensor permits comparison of relative concentrations of microvesicles between samples. We also study a possibility of repeated use of a sensor chip after elution of the microvesicle capturing layer. Moreover, we improve the detection features of the PAMONO-sensor. The detection process utilizes novel machine learning techniques on the sensor image data to estimate particle size distributions of nano-particles in polydisperse samples. Altogether, our findings expand analytical features and the application field of the PAMONO-sensor. They can also serve for a maturation of diagnostic tools based on the PAMONO-sensor platform. © 2017 by the authors; licensee MDPI, Basel, Switzerland.","Deep learning; Extracellular vesicles; Machine learning; Microvesicles; Plasmonic sensors; Surface plasmon resonance","Artificial intelligence; Deep learning; Learning systems; Nanoparticles; Particle size; Particle size analysis; Plasmons; Size distribution; Surface plasmon resonance; Viruses; Extracellular; Machine learning techniques; Microvesicles; Plasmonic sensors; Polydisperse samples; Relative concentration; Selective detection; Virus-like particles; Nanosensors","MDPI AG","14248220","","","28134825","Article","Scopus","2-s2.0-85014352036"
"Dhungel N.; Carneiro G.; Bradley A.P.","Dhungel, Neeraj (56904224600); Carneiro, Gustavo (23003641100); Bradley, Andrew P. (7202846882)","56904224600; 23003641100; 7202846882","A deep learning approach for the analysis of masses in mammograms with minimal user intervention","2017","Medical Image Analysis","263","10.1016/j.media.2017.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012297277&doi=10.1016%2fj.media.2017.01.009&partnerID=40&md5=a3331c652580ebf5f1eee70702aa4b45","Electrical and Computer Engineering, The University of British Columbia, Canada; Australian Centre for Visual Technologies, The University of British Columbia, Canada; ITEE, The University of Queensland, Australia","Dhungel N., Electrical and Computer Engineering, The University of British Columbia, Canada; Carneiro G., Australian Centre for Visual Technologies, The University of British Columbia, Canada; Bradley A.P., ITEE, The University of Queensland, Australia","We present an integrated methodology for detecting, segmenting and classifying breast masses from mammograms with minimal user intervention. This is a long standing problem due to low signal-to-noise ratio in the visualisation of breast masses, combined with their large variability in terms of shape, size, appearance and location. We break the problem down into three stages: mass detection, mass segmentation, and mass classification. For the detection, we propose a cascade of deep learning methods to select hypotheses that are refined based on Bayesian optimisation. For the segmentation, we propose the use of deep structured output learning that is subsequently refined by a level set method. Finally, for the classification, we propose the use of a deep learning classifier, which is pre-trained with a regression to hand-crafted feature values and fine-tuned based on the annotations of the breast mass classification dataset. We test our proposed system on the publicly available INbreast dataset and compare the results with the current state-of-the-art methodologies. This evaluation shows that our system detects 90% of masses at 1 false positive per image, has a segmentation accuracy of around 0.85 (Dice index) on the correctly detected masses, and overall classifies masses as malignant or benign with sensitivity (Se) of 0.98 and specificity (Sp) of 0.7. © 2017 Elsevier B.V.","Bayesian optimisation; Classification; Deep learning; Detection; Mammograms; Masses; Segmentation; Structured output learning; Transfer learning","Bayes Theorem; Breast; Breast Neoplasms; Female; Humans; Machine Learning; Mammography; Radiographic Image Interpretation, Computer-Assisted; Sensitivity and Specificity; Classification (of information); Error detection; Image segmentation; Learning systems; Mammography; Numerical methods; Signal to noise ratio; Statistical tests; Transfer learning; X ray screens; Integrated methodology; Learning classifiers; Low signal-to-noise ratio; Mammograms; Masses; Optimisations; Segmentation accuracy; Structured output learning; Article; Bayesian learning; breast tumor; evaluation study; false positive result; image analysis; intervention study; learning; mammography; mathematical computing; methodology; minimal user intervention; priority journal; sensitivity and specificity; signal noise ratio; tumor classification; Bayes theorem; breast; computer assisted diagnosis; diagnostic imaging; female; human; machine learning; mammography; procedures; Deep learning","Elsevier B.V.","13618415","","MIAEC","28171807","Article","Scopus","2-s2.0-85012297277"
"Zhang S.-W.; Jin X.-Y.; Zhang T.","Zhang, Shao-Wu (7409372742); Jin, Xiang-Yang (57200426543); Zhang, Teng (57200424164)","7409372742; 57200426543; 57200424164","Gene Prediction in Metagenomic Fragments with Deep Learning","2017","BioMed Research International","16","10.1155/2017/4740354","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041250379&doi=10.1155%2f2017%2f4740354&partnerID=40&md5=3b7db042fd409d1773cb736c956cffd9","Key Laboratory of Information Fusion Technology of Ministry of Education, School of Automation, Northwestern Polytechnical University, Xi'an, 710072, China","Zhang S.-W., Key Laboratory of Information Fusion Technology of Ministry of Education, School of Automation, Northwestern Polytechnical University, Xi'an, 710072, China; Jin X.-Y., Key Laboratory of Information Fusion Technology of Ministry of Education, School of Automation, Northwestern Polytechnical University, Xi'an, 710072, China; Zhang T., Key Laboratory of Information Fusion Technology of Ministry of Education, School of Automation, Northwestern Polytechnical University, Xi'an, 710072, China","Next generation sequencing technologies used in metagenomics yield numerous sequencing fragments which come from thousands of different species. Accurately identifying genes from metagenomics fragments is one of the most fundamental issues in metagenomics. In this article, by fusing multifeatures (i.e., monocodon usage, monoamino acid usage, ORF length coverage, and Z-curve features) and using deep stacking networks learning model, we present a novel method (called Meta-MFDL) to predict the metagenomic genes. The results with 10 CV and independent tests show that Meta-MFDL is a powerful tool for identifying genes from metagenomic fragments. © 2017 Shao-Wu Zhang et al.","","Bacteria; Databases, Genetic; Genes, Bacterial; Machine Learning; Metagenomics; Models, Statistical; Sequence Analysis, DNA; article; learning; metagenomics; open reading frame; prediction; bacterial gene; bacterium; classification; DNA sequence; genetic database; genetics; machine learning; metagenomics; procedures; statistical model","Hindawi Limited","23146133","","","29250541","Article","Scopus","2-s2.0-85041250379"
"Hanson J.; Yang Y.; Paliwal K.; Zhou Y.","Hanson, Jack (57194425812); Yang, Yuedong (8439078900); Paliwal, Kuldip (7005281122); Zhou, Yaoqi (7405366766)","57194425812; 8439078900; 7005281122; 7405366766","Improving protein disorder prediction by deep bidirectional long short-term memory recurrent neural networks","2017","Bioinformatics","224","10.1093/bioinformatics/btw678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017102714&doi=10.1093%2fbioinformatics%2fbtw678&partnerID=40&md5=78bb23d7a4bf228af514466788b820bb","Signal Processing Laboratory, Griffith University, Brisbane, 4122, Australia; Institute for Glycomics, Griffith University, Gold Coast, 4215, Australia","Hanson J., Signal Processing Laboratory, Griffith University, Brisbane, 4122, Australia; Yang Y., Institute for Glycomics, Griffith University, Gold Coast, 4215, Australia; Paliwal K., Signal Processing Laboratory, Griffith University, Brisbane, 4122, Australia; Zhou Y., Institute for Glycomics, Griffith University, Gold Coast, 4215, Australia","Motivation: Capturing long-range interactions between structural but not sequence neighbors of proteins is a long-standing challenging problem in bioinformatics. Recently, long short-term memory (LSTM) networks have significantly improved the accuracy of speech and image classification problems by remembering useful past information in long sequential events. Here, we have implemented deep bidirectional LSTM recurrent neural networks in the problem of protein intrinsic disorder prediction. Results: The new method, named SPOT-Disorder, has steadily improved over a similar method using a traditional, window-based neural network (SPINE-D) in all datasets tested without separate training on short and long disordered regions. Independent tests on four other datasets including the datasets from critical assessment of structure prediction (CASP) techniques and >10 000 annotated proteins from MobiDB, confirmed SPOT-Disorder as one of the best methods in disorder prediction. Moreover, initial studies indicate that the method is more accurate in predicting functional sites in disordered regions. These results highlight the usefulness combining LSTM with deep bidirectional recurrent neural networks in capturing non-local, long-range interactions for bioinformatics applications. © The Author 2016. Published by Oxford University Press. All rights reserved.","","Algorithms; Caspases; Computational Biology; Genetic Diseases, Inborn; Machine Learning; Memory, Short-Term; Neural Networks (Computer); Protein Conformation; Proteins; caspase; protein; algorithm; artificial neural network; biology; chemistry; genetic disorder; machine learning; metabolism; procedures; protein conformation; short term memory","Oxford University Press","13674803","","BOINF","28011771","Article","Scopus","2-s2.0-85017102714"
"Suárez-Paniagua V.; Segura-Bedmar I.; Martínez P.","Suárez-Paniagua, Víctor (57193332712); Segura-Bedmar, Isabel (35303400800); Martínez, Paloma (7202906176)","57193332712; 35303400800; 7202906176","Exploring convolutional neural networks for drug–drug interaction extraction","2017","Database","18","10.1093/database/bax019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032377041&doi=10.1093%2fdatabase%2fbax019&partnerID=40&md5=0b2e6cff09e5a5a7e47e4752842decc4","Department of Computer Science, University Carlos III of Madrid, Leganés, Madrid, 28911, Spain","Suárez-Paniagua V., Department of Computer Science, University Carlos III of Madrid, Leganés, Madrid, 28911, Spain; Segura-Bedmar I., Department of Computer Science, University Carlos III of Madrid, Leganés, Madrid, 28911, Spain; Martínez P., Department of Computer Science, University Carlos III of Madrid, Leganés, Madrid, 28911, Spain","Drug–drug interaction (DDI), which is a specific type of adverse drug reaction, occurs when a drug influences the level or activity of another drug. Natural language processing techniques can provide health-care professionals with a novel way of reducing the time spent reviewing the literature for potential DDIs. The current state-of-the-art for the extraction of DDIs is based on feature-engineering algorithms (such as support vector machines), which usually require considerable time and effort. One possible alternative to these approaches includes deep learning. This technique aims to automatically learn the best feature representation from the input data for a given task. The purpose of this paper is to examine whether a convolutional neural network (CNN), which only uses word embeddings as input features, can be applied successfully to classify DDIs from biomedical texts. Proposed herein, is a CNN architecture with only one hidden layer, thus making the model more computationally efficient, and we perform detailed experiments in order to determine the best settings of the model. The goal is to determine the best parameter of this basic CNN that should be considered for future research. The experimental results show that the proposed approach is promising because it attained the second position in the 2013 rankings of the DDI extraction challenge. However, it obtained worse results than previous works using neural networks with more complex architectures. © The Author(s) 2017. Published by Oxford University Press.","","Automatic Data Processing; Data Mining; Drug Interactions; Models, Theoretical; Natural Language Processing; Neural Networks (Computer); Support Vector Machine; artificial neural network; data mining; drug interaction; information processing; natural language processing; procedures; support vector machine; theoretical model","Oxford University Press","17580463","","","28605776","Article","Scopus","2-s2.0-85032377041"
"Feng Y.; Zhang H.; Hao W.; Chen G.","Feng, Yuntian (56403659600); Zhang, Hongjun (55833123500); Hao, Wenning (36650519400); Chen, Gang (57206726091)","56403659600; 55833123500; 36650519400; 57206726091","Joint extraction of entities and relations using reinforcement learning and deep learning","2017","Computational Intelligence and Neuroscience","26","10.1155/2017/7643065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028655932&doi=10.1155%2f2017%2f7643065&partnerID=40&md5=c0ab47437aed805289ee65b7e54b95b7","Institute of Command Information System, PLA University of Science and Technology, Nanjing, Jiangsu, 210007, China","Feng Y., Institute of Command Information System, PLA University of Science and Technology, Nanjing, Jiangsu, 210007, China; Zhang H., Institute of Command Information System, PLA University of Science and Technology, Nanjing, Jiangsu, 210007, China; Hao W., Institute of Command Information System, PLA University of Science and Technology, Nanjing, Jiangsu, 210007, China; Chen G., Institute of Command Information System, PLA University of Science and Technology, Nanjing, Jiangsu, 210007, China","We use both reinforcement learning and deep learning to simultaneously extract entities and relations from unstructured texts. For reinforcement learning, we model the task as a two-step decision process. Deep learning is used to automatically capture the most important information from unstructured texts, which represent the state in the decision process. By designing the reward function per step, our proposed method can pass the information of entity extraction to relation extraction and obtain feedback in order to extract entities and relations simultaneously. Firstly, we use bidirectional LSTM to model the context information, which realizes preliminary entity extraction. On the basis of the extraction results, attention based method can represent the sentences that include target entity pair to generate the initial state in the decision process. Then we use Tree-LSTM to represent relation mentions to generate the transition state in the decision process. Finally, we employ Q-Learning algorithm to get control policy π in the two-step decision process. Experiments on ACE2005 demonstrate that our method attains better performance than the state-of-the-art method and gets a 2.4% increase in recall-score. © 2017 Yuntian Feng et al.","","Feedback; Machine Learning; Reinforcement (Psychology); Reward; Translations; Data mining; Deep learning; Extraction; Learning algorithms; Context information; Decision process; Entity extractions; Q-learning algorithms; Relation extraction; State-of-the-art methods; Transition state; Unstructured texts; feedback system; machine learning; publication; reinforcement; reward; Reinforcement learning","Hindawi Limited","16875265","","","28894463","Article","Scopus","2-s2.0-85028655932"
"Rouhollahi K.; Emadi Andani M.; Karbassi S.M.; Izadi I.","Rouhollahi, Korosh (57190390687); Emadi Andani, Mehran (23388145200); Karbassi, Seyed Mahdi (6602311729); Izadi, Iman (6505538821)","57190390687; 23388145200; 6602311729; 6505538821","Design of robust adaptive controller and feedback error learning for rehabilitation in Parkinson's disease: A simulation study","2017","IET Systems Biology","16","10.1049/iet-syb.2016.0014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015658520&doi=10.1049%2fiet-syb.2016.0014&partnerID=40&md5=b6608267ca5062d136e579197e00ff58","Department of Applied Mathematics, Yazd University, Yazd, Iran; Department of Biomedical Engineering, University of Isfahan, Isfahan, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, 84156-83111, Iran","Rouhollahi K., Department of Applied Mathematics, Yazd University, Yazd, Iran; Emadi Andani M., Department of Biomedical Engineering, University of Isfahan, Isfahan, Iran; Karbassi S.M., Department of Applied Mathematics, Yazd University, Yazd, Iran; Izadi I., Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, 84156-83111, Iran","Deep brain stimulation (DBS) is an efficient therapy to control movement disorders of Parkinson's tremor. Stimulation of one area of basal ganglia (BG) by DBS with no feedback is the prevalent opinion. Reduction of additional stimulatory signal delivered to the brain is the advantage of using feedback. This results in reduction of side effects caused by the excessive stimulation intensity. In fact, the stimulatory intensity of controllers is decreased proportional to reduction of hand tremor. The objective of this study is to design a new controller structure to decrease three indicators: (i) the hand tremor; (ii) the level of delivered stimulation in disease condition; and (iii) the ratio of the level of delivered stimulation in health condition to disease condition. For this purpose, the authors offer a new closed-loop control structure to stimulate two areas of BG simultaneously. One area (STN: subthalamic nucleus) is stimulated by an adaptive controller with feedback error learning. The other area (GPi: globus pallidus internal) is stimulated by a partial state feedback (PSF) controller. Considering the three indicators, the results show that, stimulating two areas simultaneously leads to better performance compared with stimulating one area only. It is shown that both PSF and adaptive controllers are robust regarding system parameter uncertainties. In addition, a method is proposed to update the parameters of the BG model in real time. As a result, the parameters of the controllers can be updated based on the new parameters of the BG model. © The Institution of Engineering and Technology.","","Basal Ganglia; Biofeedback, Psychology; Deep Brain Stimulation; Feedback, Physiological; Humans; Machine Learning; Neurological Rehabilitation; Parkinson Disease; Therapy, Computer-Assisted; Treatment Outcome; Adaptive control systems; Controllers; Feedback control; Neurosurgery; State feedback; Structural design; Surgery; Closed loop control structure; Controller structures; Deep brain stimulation; Feedback error learning; Parameter uncertainty; Partial state feedback; Robust adaptive controller; Stimulation intensity; basal ganglion; biofeedback; brain depth stimulation; computer assisted therapy; human; machine learning; neurorehabilitation; Parkinson disease; pathophysiology; physiological feedback; procedures; treatment outcome; Feedback","Institution of Engineering and Technology","17518849","","","28303790","Article","Scopus","2-s2.0-85015658520"
"Stahl K.; Schneider M.; Brock O.","Stahl, Kolja (57193490161); Schneider, Michael (58355435200); Brock, Oliver (6602822080)","57193490161; 58355435200; 6602822080","EPSILON-CP: Using deep learning to combine information from multiple sources for protein contact prediction","2017","BMC Bioinformatics","27","10.1186/s12859-017-1713-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027545007&doi=10.1186%2fs12859-017-1713-x&partnerID=40&md5=51946a034b7255fbc7e3973fb1c9d2be","Robotics and Biology Laboratory, Department of Electrical Engineering and Computer Science, Technische Universität Berlin, Marchstraße 23, Berlin, 10587, Germany","Stahl K., Robotics and Biology Laboratory, Department of Electrical Engineering and Computer Science, Technische Universität Berlin, Marchstraße 23, Berlin, 10587, Germany; Schneider M., Robotics and Biology Laboratory, Department of Electrical Engineering and Computer Science, Technische Universität Berlin, Marchstraße 23, Berlin, 10587, Germany; Brock O., Robotics and Biology Laboratory, Department of Electrical Engineering and Computer Science, Technische Universität Berlin, Marchstraße 23, Berlin, 10587, Germany","Background: Accurately predicted contacts allow to compute the 3D structure of a protein. Since the solution space of native residue-residue contact pairs is very large, it is necessary to leverage information to identify relevant regions of the solution space, i.e. correct contacts. Every additional source of information can contribute to narrowing down candidate regions. Therefore, recent methods combined evolutionary and sequence-based information as well as evolutionary and physicochemical information. We develop a new contact predictor (EPSILON-CP) that goes beyond current methods by combining evolutionary, physicochemical, and sequence-based information. The problems resulting from the increased dimensionality and complexity of the learning problem are combated with a careful feature analysis, which results in a drastically reduced feature set. The different information sources are combined using deep neural networks. Results: On 21 hard CASP11 FM targets, EPSILON-CP achieves a mean precision of 35.7% for top-L/10 predicted long-range contacts, which is 11% better than the CASP11 winning version of MetaPSICOV. The improvement on 1.5L is 17%. Furthermore, in this study we find that the amino acid composition, a commonly used feature, is rendered ineffective in the context of meta approaches. The size of the refined feature set decreased by 75%, enabling a significant increase in training data for machine learning, contributing significantly to the observed improvements. Conclusions: Exploiting as much and diverse information as possible is key to accurate contact prediction. Simply merging the information introduces new challenges. Our study suggests that critical feature analysis can improve the performance of contact prediction methods that combine multiple information sources. EPSILON-CP is available as a webservice: http://compbio.robotics.tu-berlin.de/epsilon/. © The Author(s). 2017.","Contact prediction; Deep learning; Meta algorithms","Computational Biology; Protein Binding; Protein Conformation; Proteins; Software; Deep neural networks; Forecasting; Learning systems; Proteins; protein; protein binding; Amino acid compositions; Critical feature analysis; Feature analysis; Information sources; Learning problem; Long range contacts; Meta-algorithms; Prediction methods; biology; chemistry; metabolism; procedures; protein conformation; software; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","28623886","Article","Scopus","2-s2.0-85027545007"
"Tang P.; Wang H.; Kwong S.","Tang, Pengjie (57192544370); Wang, Hanli (12783633400); Kwong, Sam (7005601503)","57192544370; 12783633400; 7005601503","G-MS2F: GoogLeNet based multi-stage feature fusion of deep CNN for scene recognition","2017","Neurocomputing","194","10.1016/j.neucom.2016.11.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006801871&doi=10.1016%2fj.neucom.2016.11.023&partnerID=40&md5=b1b2185850889c9e5b93fabf34121af2","Department of Computer Science & Technology, Tongji University, Shanghai, 201804, China; Key Laboratory of Embedded System and Service Computing, Ministry of Education, Tongji University, Shanghai, 200092, China; College of Math & Physics, Jinggangshan University, Ji'an, 343009, China; Department of Computer Science, City University of Hong Kong, Hong Kong","Tang P., Department of Computer Science & Technology, Tongji University, Shanghai, 201804, China, Key Laboratory of Embedded System and Service Computing, Ministry of Education, Tongji University, Shanghai, 200092, China, College of Math & Physics, Jinggangshan University, Ji'an, 343009, China; Wang H., Department of Computer Science & Technology, Tongji University, Shanghai, 201804, China, Key Laboratory of Embedded System and Service Computing, Ministry of Education, Tongji University, Shanghai, 200092, China; Kwong S., Department of Computer Science, City University of Hong Kong, Hong Kong","Scene recognition plays an important role in the task of visual information retrieval, segmentation and image/video understanding. Traditional approaches for scene recognition usually utilize handcrafted features and have the drawbacks of poor representation ability, which can be improved by employing deep convolutional neural network (CNN) features that contain more semantic and structure information and thus possess more discriminative ability via multiple linear and non-linear transformations. However, an amount of detailed information may be lost when only the final output features which have gone through a certain number of transformations are applied to scene recognition. The features which are generated from the intermediate layers are not fully utilized. In this work, the GoogLeNet model is employed and divided into three parts of layers from bottom to top. The output features from each of the three parts are applied for scene recognition, which leads to the proposed GoogLeNet based multi-stage feature fusion (G-MS2F). What's more, the product rule is used to generate the final decision for scene recognition from the three outputs corresponding to the three parts of the proposed model. The experimental results demonstrate that the proposed model is superior to a number of state-of-the-art CNN models for scene recognition, and obtains the recognition accuracy of 92.90%, 79.63% and 64.06% on the benchmark scene recognition datasets Scene15, MIT67 and SUN397, respectively. © 2016 Elsevier B.V.","Convolutional neural network; Feature fusion; GoogLeNet; Multi-stage feature; Scene recognition","Convolution; Image segmentation; Mathematical transformations; Neural networks; Semantics; Convolutional neural network; Feature fusion; GoogLeNet; Multi stage; Scene recognition; accuracy; Article; artificial neural network; classification; classifier; computer model; deep convolutional neural network; GoogLeNet based multi stage feature fusion; Internet; machine learning; priority journal; recognition; support vector machine; Linear transformations","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-85006801871"
"Yang H.; Hu B.; Pan X.; Yan S.; Feng Y.; Zhang X.; Yin L.; Hu C.","Yang, Huihua (8676488300); Hu, Baichao (57190019893); Pan, Xipeng (55973002800); Yan, Shengke (57190026207); Feng, Yanchun (36748130300); Zhang, Xuebo (56380836900); Yin, Lihui (14829863400); Hu, Changqin (55550117800)","8676488300; 57190019893; 55973002800; 57190026207; 36748130300; 56380836900; 14829863400; 55550117800","Deep belief network-based drug identification using near infrared spectroscopy","2017","Journal of Innovative Optical Health Sciences","23","10.1142/S1793545816300111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976563163&doi=10.1142%2fS1793545816300111&partnerID=40&md5=28bb310346b5e3d72a38e88b14d027ef","College of Electronic Engineering and Automation, Guilin University of Electronic Technology, 1 Jinji Road, Guilin, 541004, China; Automation School Beijing University of Posts and Telecommunications, 10 Xitucheng Road, Beijing, 100876, China; National Institutes for Food and Drug Control, 10 Tiantanxili Road, Beijing, 100050, China","Yang H., College of Electronic Engineering and Automation, Guilin University of Electronic Technology, 1 Jinji Road, Guilin, 541004, China, Automation School Beijing University of Posts and Telecommunications, 10 Xitucheng Road, Beijing, 100876, China; Hu B., College of Electronic Engineering and Automation, Guilin University of Electronic Technology, 1 Jinji Road, Guilin, 541004, China; Pan X., Automation School Beijing University of Posts and Telecommunications, 10 Xitucheng Road, Beijing, 100876, China; Yan S., College of Electronic Engineering and Automation, Guilin University of Electronic Technology, 1 Jinji Road, Guilin, 541004, China; Feng Y., National Institutes for Food and Drug Control, 10 Tiantanxili Road, Beijing, 100050, China; Zhang X., National Institutes for Food and Drug Control, 10 Tiantanxili Road, Beijing, 100050, China; Yin L., National Institutes for Food and Drug Control, 10 Tiantanxili Road, Beijing, 100050, China; Hu C., National Institutes for Food and Drug Control, 10 Tiantanxili Road, Beijing, 100050, China","Near infrared spectroscopy (NIRS) analysis technology, combined with chemometrics, can be effectively used in quick and nondestructive analysis of quality and category. In this paper, an effective drug identification method by using deep belief network (DBN) with dropout mechanism (dropout-DBN) to model NIRS is introduced, in which dropout is employed to overcome the overfitting problem coming from the small sample. This paper tests proposed method under datasets of different sizes with the example of near infrared diffuse reflectance spectroscopy of erythromycin ethylsuccinate drugs and other drugs, aluminum and nonaluminum packaged. Meanwhile, it gives experiments to compare the proposed method's performance with back propagation (BP) neural network, support vector machines (SVMs) and sparse denoising auto-encoder (SDAE). The results show that for both binary classification and multi-classification, dropout mechanism can improve the classification accuracy, and dropout-DBN can achieve best classification accuracy in almost all cases. SDAE is similar to dropout-DBN in the aspects of classification accuracy and algorithm stability, which are higher than that of BP neural network and SVM methods. In terms of training time, dropout-DBN model is superior to SDAE model, but inferior to BP neural network and SVM methods. Therefore, dropout-DBN can be used as a modeling tool with effective binary and multi-class classification performance on a spectrum sample set of small size. © 2017 The Author(s).","Deep belief networks; dropout; drug classification; near infrared spectroscopy","Backpropagation; Bayesian networks; Bins; Fisher information matrix; Learning systems; Near infrared spectroscopy; Neural networks; Quality control; Spectrum analysis; Support vector machines; aluminum; erythromycin ethylsuccinate; Back propagation neural networks; Deep belief network (DBN); Deep belief networks; dropout; Multi-class classification; Near infrared diffuse reflectance; Non-destructive analysis; Support vector machine (SVMs); Article; back propagation; controlled study; deep belief network; machine learning; near infrared spectroscopy; support vector machine; Infrared devices","World Scientific Publishing Co. Pte Ltd","17935458","","","","Article","Scopus","2-s2.0-84976563163"
"Chen H.; Qi X.; Yu L.; Dou Q.; Qin J.; Heng P.-A.","Chen, Hao (56493367600); Qi, Xiaojuan (57189658166); Yu, Lequan (56903335400); Dou, Qi (56903795500); Qin, Jing (35339855100); Heng, Pheng-Ann (7006677755)","56493367600; 57189658166; 56903335400; 56903795500; 35339855100; 7006677755","DCAN: Deep contour-aware networks for object instance segmentation from histology images","2017","Medical Image Analysis","378","10.1016/j.media.2016.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997796752&doi=10.1016%2fj.media.2016.11.004&partnerID=40&md5=e2e2a16f58c542af33843959d8949a81","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; School of Nursing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong","Chen H., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Qi X., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Yu L., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Dou Q., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Qin J., School of Nursing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Heng P.-A., Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong","In histopathological image analysis, the morphology of histological structures, such as glands and nuclei, has been routinely adopted by pathologists to assess the malignancy degree of adenocarcinomas. Accurate detection and segmentation of these objects of interest from histology images is an essential prerequisite to obtain reliable morphological statistics for quantitative diagnosis. While manual annotation is error-prone, time-consuming and operator-dependant, automated detection and segmentation of objects of interest from histology images can be very challenging due to the large appearance variation, existence of strong mimics, and serious degeneration of histological structures. In order to meet these challenges, we propose a novel deep contour-aware network (DCAN) under a unified multi-task learning framework for more accurate detection and segmentation. In the proposed network, multi-level contextual features are explored based on an end-to-end fully convolutional network (FCN) to deal with the large appearance variation. We further propose to employ an auxiliary supervision mechanism to overcome the problem of vanishing gradients when training such a deep network. More importantly, our network can not only output accurate probability maps of histological objects, but also depict clear contours simultaneously for separating clustered object instances, which further boosts the segmentation performance. Our method ranked the first in two histological object segmentation challenges, including 2015 MICCAI Gland Segmentation Challenge and 2015 MICCAI Nuclei Segmentation Challenge. Extensive experiments on these two challenging datasets demonstrate the superior performance of our method, surpassing all the other methods by a significant margin. © 2016 Elsevier B.V.","Deep contour-aware network; Deep learning; Histopathological image analysis; Instance segmentation; Object detection; Transfer learning","Colorectal Neoplasms; Histological Techniques; Humans; Machine Learning; Deep learning; Histology; Object detection; Automated detection; Convolutional networks; Histological structure; Histopathological image analysis; Quantitative diagnosis; Segmentation performance; Supervision mechanisms; Transfer learning; accuracy; Article; deep contour aware network; evaluation study; fully convolutional network; histopathology; human; image analysis; image processing; image segmentation; morphometrics; priority journal; probability; qualitative analysis; quantitative analysis; colorectal tumor; diagnostic imaging; histology; machine learning; pathology; procedures; Image segmentation","Elsevier B.V.","13618415","","MIAEC","27898306","Article","Scopus","2-s2.0-84997796752"
"Park W.B.; Chung J.; Jung J.; Sohn K.; Singh S.P.; Pyo M.; Shin N.; Sohn K.-S.","Park, Woon Bae (37087628000); Chung, Jiyong (57194727563); Jung, Jaeyoung (57194727964); Sohn, Keemin (57195612543); Singh, Satendra Pal (36497538200); Pyo, Myoungho (56217130500); Shin, Namsoo (7005109330); Sohn, Kee-Sun (56067767800)","37087628000; 57194727563; 57194727964; 57195612543; 36497538200; 56217130500; 7005109330; 56067767800","Classification of crystal structure using a convolutional neural network","2017","IUCrJ","149","10.1107/S205225251700714X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021812753&doi=10.1107%2fS205225251700714X&partnerID=40&md5=92305f80c7c22fa691ccddb66de8f74f","Faculty of Nanotechnology and Advanced Materials Engineering, Sejong University, Seoul, 143-747, South Korea; Laboratory of Big-data Applications for Public Sector, Chung-Ang University, 221 Heukseok-dong, Dongjak-gu, Seoul, 156-756, South Korea; Department of Printed Electronics Engineering, Sunchon National University, Chonnam, 540-742, South Korea; Deep Solution Inc., 2636 Nambusunhwan-ro, Seocho-gu, Seoul, 06738, South Korea","Park W.B., Faculty of Nanotechnology and Advanced Materials Engineering, Sejong University, Seoul, 143-747, South Korea; Chung J., Laboratory of Big-data Applications for Public Sector, Chung-Ang University, 221 Heukseok-dong, Dongjak-gu, Seoul, 156-756, South Korea; Jung J., Laboratory of Big-data Applications for Public Sector, Chung-Ang University, 221 Heukseok-dong, Dongjak-gu, Seoul, 156-756, South Korea; Sohn K., Laboratory of Big-data Applications for Public Sector, Chung-Ang University, 221 Heukseok-dong, Dongjak-gu, Seoul, 156-756, South Korea; Singh S.P., Faculty of Nanotechnology and Advanced Materials Engineering, Sejong University, Seoul, 143-747, South Korea; Pyo M., Department of Printed Electronics Engineering, Sunchon National University, Chonnam, 540-742, South Korea; Shin N., Deep Solution Inc., 2636 Nambusunhwan-ro, Seocho-gu, Seoul, 06738, South Korea; Sohn K.-S., Faculty of Nanotechnology and Advanced Materials Engineering, Sejong University, Seoul, 143-747, South Korea","A deep machine-learning technique based on a convolutional neural network (CNN) is introduced. It has been used for the classification of powder X-ray diffraction (XRD) patterns in terms of crystal system, extinction group and space group. About 150000 powder XRD patterns were collected and used as input for the CNN with no handcrafted engineering involved, and thereby an appropriate CNN architecture was obtained that allowed determination of the crystal system, extinction group and space group. In sharp contrast with the traditional use of powder XRD pattern analysis, the CNN never treats powder XRD patterns as a deconvoluted and discrete peak position or as intensity data, but instead the XRD patterns are regarded as nothing but a pattern similar to a picture. The CNN interprets features that humans cannot recognize in a powder XRD pattern. As a result, accuracy levels of 81.14, 83.83 and 94.99% were achieved for the space-group, extinction-group and crystal-system classifications, respectively. The well trained CNN was then used for symmetry identification of unknown novel inorganic compounds. © Woon Bae Park et al. 2017.","artificial neural network (ANN); computational modelling; convolutional neural network (CNN); crystal structure prediction; crystal system; inorganic materials; powder X-ray diffraction; properties of solids","","International Union of Crystallography","20522525","","","","Article","Scopus","2-s2.0-85021812753"
"Qiu Y.; Yan S.; Gundreddy R.R.; Wang Y.; Cheng S.; Liu H.; Zheng B.","Qiu, Yuchen (36994032800); Yan, Shiju (15844474000); Gundreddy, Rohith Reddy (56708923300); Wang, Yunzhi (57205302373); Cheng, Samuel (35752985300); Liu, Hong (51563613000); Zheng, Bin (7201781356)","36994032800; 15844474000; 56708923300; 57205302373; 35752985300; 51563613000; 7201781356","A new approach to develop computer-aided diagnosis scheme of breast mass classification using deep learning technology","2017","Journal of X-Ray Science and Technology","88","10.3233/XST-16226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032004301&doi=10.3233%2fXST-16226&partnerID=40&md5=ce85f1d6114857c823cae539db165101","School of Electrical and Computer Engineering, University of Oklahoma, 101 David L. Boren Blvd, Norman, 73019, OK, United States; University of Shanghai for Sciences and Technology, Shanghai, China; School of Electrical and Computer Engineering, University of Oklahoma, Tulsa, OK, United States","Qiu Y., School of Electrical and Computer Engineering, University of Oklahoma, 101 David L. Boren Blvd, Norman, 73019, OK, United States; Yan S., University of Shanghai for Sciences and Technology, Shanghai, China; Gundreddy R.R., School of Electrical and Computer Engineering, University of Oklahoma, 101 David L. Boren Blvd, Norman, 73019, OK, United States; Wang Y., School of Electrical and Computer Engineering, University of Oklahoma, 101 David L. Boren Blvd, Norman, 73019, OK, United States; Cheng S., School of Electrical and Computer Engineering, University of Oklahoma, Tulsa, OK, United States; Liu H., School of Electrical and Computer Engineering, University of Oklahoma, 101 David L. Boren Blvd, Norman, 73019, OK, United States; Zheng B., School of Electrical and Computer Engineering, University of Oklahoma, 101 David L. Boren Blvd, Norman, 73019, OK, United States","PURPOSE: To develop and test a deep learning based computer-aided diagnosis (CAD) scheme of mammograms for classifying between malignant and benign masses. METHODS: An image dataset involving 560 regions of interest (ROIs) extracted from digital mammograms was used. After down-sampling each ROI from 512×512 to 64×64 pixel size, we applied an 8 layer deep learning network that involves 3 pairs of convolution-max-pooling layers for automatic feature extraction and a multiple layer perceptron (MLP) classifier for feature categorization to process ROIs. The 3 pairs of convolution layers contain 20, 10, and 5 feature maps, respectively. Each convolution layer is connected with a max-pooling layer to improve the feature robustness. The output of the sixth layer is fully connected with a MLP classifier, which is composed of one hidden layer and one logistic regression layer. The network then generates a classification score to predict the likelihood of ROI depicting a malignant mass. A four-fold cross validation method was applied to train and test this deep learning network. RESULTS: The results revealed that this CAD scheme yields an area under the receiver operation characteristic curve (AUC) of 0.696 ± 0.044, 0.802 ± 0.037, 0.836 ± 0.036, and 0.822 ± 0.035 for fold 1 to 4 testing datasets, respectively. The overall AUC of the entire dataset is 0.790 ± 0.019. CONCLUSIONS: This study demonstrates the feasibility of applying a deep learning based CAD scheme to classify between malignant and benign breast masses without a lesion segmentation, image feature computation and selection process. © 2017 - IOS Press and the authors. All rights reserved.","breast mass classification; Computer aided diagnosis (CAD); convolution neuron networks; deep learning","Algorithms; Breast Neoplasms; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Mammography; Neural Networks (Computer); Computer aided instruction; Convolution; Deep learning; Feature extraction; Image processing; Image segmentation; Learning systems; Mammography; Medical imaging; Network layers; X ray screens; Automatic feature extraction; Breast mass; Computer Aided Diagnosis(CAD); Cross-validation methods; Lesion segmentations; Multiple layer perceptron; Neuron networks; Receiver operation characteristic curves; algorithm; artificial neural network; breast tumor; computer assisted diagnosis; diagnostic imaging; female; human; machine learning; mammography; procedures; Computer aided diagnosis","IOS Press","08953996","","JXSTE","28436410","Article","Scopus","2-s2.0-85032004301"
"Volkova K.V.; Dagaev N.I.; Kiselev A.S.; Kasumov V.R.; Aleksandrov M.V.; Osadchiy A.E.","Volkova, K.V. (57200205669); Dagaev, N.I. (56049676100); Kiselev, A.S. (57200200601); Kasumov, V.R. (14045450100); Aleksandrov, M.V. (7004578812); Osadchiy, A.E. (57200203650)","57200205669; 56049676100; 57200200601; 14045450100; 7004578812; 57200203650","The brain-computer interface: The experience of building, using, and possible ways to improve performance","2017","Zhurnal Vysshei Nervnoi Deyatelnosti Imeni I.P. Pavlova","8","10.7868/S0044467717040128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040196300&doi=10.7868%2fS0044467717040128&partnerID=40&md5=19793814de44b993ed98f824e641cfdd","Center for Neuroeconomics and Cognitive Research, National Research University, Higher School of Economics, Russian Federation; Moscow Institute of Physics and Technology, State University, Russian Federation; Russian Neurosurgical Research Institute. Prof. A.L. Polenova, SZFMITS named after VA Almazov, Russian Federation","Volkova K.V., Center for Neuroeconomics and Cognitive Research, National Research University, Higher School of Economics, Russian Federation; Dagaev N.I., Center for Neuroeconomics and Cognitive Research, National Research University, Higher School of Economics, Russian Federation; Kiselev A.S., Moscow Institute of Physics and Technology, State University, Russian Federation; Kasumov V.R., Russian Neurosurgical Research Institute. Prof. A.L. Polenova, SZFMITS named after VA Almazov, Russian Federation; Aleksandrov M.V., Russian Neurosurgical Research Institute. Prof. A.L. Polenova, SZFMITS named after VA Almazov, Russian Federation; Osadchiy A.E., Center for Neuroeconomics and Cognitive Research, National Research University, Higher School of Economics, Russian Federation","Brain-computer interfaces find application in a number of different areas and have the potential to be used for research as well as for practical purposes. The clinical use of BCI includes current studies on neurorehabilitation ([Frolov et al., 2013; Ang et al., 2010]), and there is the prospect of using BCI to restore movement and communication capabilities, providing alternative effective pathways to those that may be lost due to injury or illness. The processing of electrophysiological data requires analysis of high-dimensional, nonstationary, noisy signals reflecting complex underlying processes and structures. We have shown that for non-invasive neuroimaging methods such as EEG the potential improvement lies in the field of machine learning and involves designing data analysis algorithms that can model physiological and psychoemotional variability of the user. The development of such algorithms can be conducted in different ways, including the classical Bayesian paradigm as well as modern deep learning architectures. The interpretation of nonlinear decision rules implemented by multilayer structures would enable automatic and objective knowledge extraction from the neurocognitive experiments data. Despite the advantages of non-invasive neuroimaging methods, a radical increase in the bandwidth of the BCI communication channel and the use of this technology for the prosthesis control is possible only through invasive technologies. Electrocorticogram (ECoG) is the least invasive of such technologies, and in the final part of this work we demonstrate the possibility of using ECoG to decode the kinematic characteristics of the finger movement.","Brain-computer interface; Deep learning; ECoG; EEG; Mu-rhythm","","Maik Nauka-Interperiodica Publishing","00444677","","ZVNDA","","Article","Scopus","2-s2.0-85040196300"
"Abdolmanafi A.; Duong L.; Dahdah N.; Cheriet F.","Abdolmanafi, Atefeh (57199506980); Duong, Luc (7006651505); Dahdah, Nagib (6603701805); Cheriet, Farida (6602858148)","57199506980; 7006651505; 6603701805; 6602858148","Deep feature learning for automatic tissue classification of coronary artery using optical coherence tomography","2017","Biomedical Optics Express","108","10.1364/BOE.8.001203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011565816&doi=10.1364%2fBOE.8.001203&partnerID=40&md5=c42f5f265791ec7dbd79887d02018d46","Dept. of Software and IT Engineering, École de Technologie Supérieure, Montréal, Canada; Div. of Pediatric Cardiology and Research Center, Centre Hospitalier Universitaire Sainte-Justine, Montréal, Canada; Dept. of Computer Engineering, École Polytechnique de Montréal, Montréal, Canada","Abdolmanafi A., Dept. of Software and IT Engineering, École de Technologie Supérieure, Montréal, Canada; Duong L., Dept. of Software and IT Engineering, École de Technologie Supérieure, Montréal, Canada; Dahdah N., Div. of Pediatric Cardiology and Research Center, Centre Hospitalier Universitaire Sainte-Justine, Montréal, Canada; Cheriet F., Dept. of Computer Engineering, École Polytechnique de Montréal, Montréal, Canada","Kawasaki disease (KD) is an acute childhood disease complicated by coronary artery aneurysms, intima thickening, thrombi, stenosis, lamellar calcifications, and disappearance of the media border. Automatic classification of the coronary artery layers (intima, media, and scar features) is important for analyzing optical coherence tomography (OCT) images recorded in pediatric patients. OCT has been known as an intracoronary imaging modality using near-infrared light which has recently been used to image the inner coronary artery tissues of pediatric patients, providing high spatial resolution (ranging from 10 to 20 μm). This study aims to develop a robust and fully automated tissue classification method by using the convolutional neural networks (CNNs) as feature extractor and comparing the predictions of three state-of-the-art classifiers, CNN, random forest (RF), and support vector machine (SVM). The results show the robustness of CNN as the feature extractor and random forest as the classifier with classification rate up to 96%, especially to characterize the second layer of coronary arteries (media), which is a very thin layer and it is challenging to be recognized and specified from other tissues. © 2017 Optical Society of America.","","Biomineralization; Blood vessels; Decision trees; Deep learning; Heart; Histology; Infrared devices; Neural networks; Optical tomography; Pediatrics; Support vector machines; Automatic classification; Classification rates; Convolutional neural network; Deep feature learning; High spatial resolution; Near infrared light; Pediatric patients; Tissue classification; artery intima proliferation; artery occlusion; artery thrombosis; Article; classification; clinical article; coronary artery; coronary artery aneurysm; human; image analysis; image segmentation; machine learning; measurement accuracy; mucocutaneous lymph node syndrome; nerve cell network; optical coherence tomography; random forest; sensitivity and specificity; support vector machine; tuning curve; validation process; Tissue","OSA - The Optical Society","21567085","","","","Article","Scopus","2-s2.0-85011565816"
"Charlyn Pushpa Latha G.; Mohana Priya M.","Charlyn Pushpa Latha, G. (56429606500); Mohana Priya, M. (57217124318)","56429606500; 57217124318","A novel and enhanced facial electromyogram based human emotion recognition using convolution neural network model with multirate signal processing features","2017","Journal of Computational and Theoretical Nanoscience","6","10.1166/jctn.2017.6480","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021712570&doi=10.1166%2fjctn.2017.6480&partnerID=40&md5=15330ea60b94725f0b30710e92e78c31","Faculty of Engineering, Karpagam University, Coimbatore, 641021, India","Charlyn Pushpa Latha G., Faculty of Engineering, Karpagam University, Coimbatore, 641021, India; Mohana Priya M., Faculty of Engineering, Karpagam University, Coimbatore, 641021, India","In recent era, emotion recognition plays a vital role in human-machine interaction. Service robots identify the significant aspects of human behavior by analyzing the emotions of human beings and make use of these emotions to communicate with humans which make the human-robot interaction faster. Human emotional states are different and they are exhibited instinctively which are not easily recognized by the self-service robots. This paper attempts to develop a novel and enhanced multimodal emotion recognition system which could easily identify the six emotions namely anger, disgust, fear, happy, neutral and sad of an individual. The developed FEMG model could be interfaced with any service robot so that the human-machine interaction could be made faster. Facial Electromyogram (FEMG) signals are acquired from 20 subjects. Multirate signal processing features namely Multidecimate, Multidownsample and Upfirdn are applied to the FEMG signals. A deep learning technique namely, Convolutional Neural Network (CNN) model is applied to the feature extracted signals and the highest classification accuracy obtained was 99.79%. Also the developed FEMG based CNN model also reduces the training time employed in the experiments. © 2017 American Scientific Publishers All rights reserved.","Convolution Neural Networks; Deep Belief Networks; Deep Learning; Multidecimate; Multidownsample; Stacked Auto Encoders; Upfirdn","","American Scientific Publishers","15461955","","","","Article","Scopus","2-s2.0-85021712570"
"Eltanboly A.; Ismail M.; Shalaby A.; Switala A.; El-Baz A.; Schaal S.; Gimel’farb G.; El-Azab M.","Eltanboly, Ahmed (57189265602); Ismail, Marwa (36613249900); Shalaby, Ahmed (57197612511); Switala, Andy (6602638626); El-Baz, Ayman (6602350405); Schaal, Shlomit (9844132900); Gimel’farb, Georgy (57854190600); El-Azab, Magdi (6603604506)","57189265602; 36613249900; 57197612511; 6602638626; 6602350405; 9844132900; 57854190600; 6603604506","A computer-aided diagnostic system for detecting diabetic retinopathy in optical coherence tomography images","2017","Medical Physics","87","10.1002/MP.12071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016289983&doi=10.1002%2fMP.12071&partnerID=40&md5=0600973ce6d2558106e731520627e413","Department of Mathematical Engineering, Mansoura University, Mansoura, 35516, Egypt; Department of Bioengineering, University of Louisville, Louisville, 40292, KY, United States; Department of Ophthalmology and Visual Sciences, School of Medicine, University of Louisville, Louisville, 40202, KY, United States; Intelligent Vision Systems Laboratory, Department of Computer Science, University of Auckland, Auckland, 1142, New Zealand; Department of Mathematics and Physical Engineering, Mansoura University, Mansoura, 35516, Egypt","Eltanboly A., Department of Mathematical Engineering, Mansoura University, Mansoura, 35516, Egypt, Department of Bioengineering, University of Louisville, Louisville, 40292, KY, United States; Ismail M., Department of Bioengineering, University of Louisville, Louisville, 40292, KY, United States; Shalaby A., Department of Bioengineering, University of Louisville, Louisville, 40292, KY, United States; Switala A., Department of Bioengineering, University of Louisville, Louisville, 40292, KY, United States; El-Baz A., Department of Bioengineering, University of Louisville, Louisville, 40292, KY, United States; Schaal S., Department of Ophthalmology and Visual Sciences, School of Medicine, University of Louisville, Louisville, 40202, KY, United States; Gimel’farb G., Intelligent Vision Systems Laboratory, Department of Computer Science, University of Auckland, Auckland, 1142, New Zealand; El-Azab M., Department of Mathematics and Physical Engineering, Mansoura University, Mansoura, 35516, Egypt","Purpose: Detection (diagnosis) of diabetic retinopathy (DR) in optical coherence tomography (OCT) images for patients with type 2 diabetes, but almost clinically normal retina appearances. Methods: The proposed computer-aided diagnostic (CAD) system detects the DR in three steps: (a) localizing and segmenting 12 distinct retinal layers on the OCT image; (b) deriving features of the segmented layers, and (c) learning most discriminative features and classifying each subject as normal or diabetic. To localise and segment the retinal layers, signals (intensities) of the OCT image are described with a joint Markov-Gibbs random field (MGRF) model of intensities and shape descriptors. Each segmented layer is characterized with cumulative probability distribution functions (CDF) of its locally extracted features, such as reflectivity, curvature, and thickness. A multistage deep fusion classification network (DFCN) with a stack of non-negativity-constrained autoencoders (NCAE) is trained to select the most discriminative retinal layers’ features and use their CDFs for detecting the DR. A training atlas was built using the OCT scans for 12 normal subjects and their maps of layers hand-drawn by retina experts. Results: Preliminary experiments on 52 clinical OCT scans (26 normal and 26 with early-stage DR, balanced between 40–79 yr old males and females; 40 training and 12 test subjects) gave the DR detection accuracy, sensitivity, and specificity of 92%; 83%, and 100%, respectively. The 100% accuracy, sensitivity, and specificity have been obtained in the leave-one-out cross-validation test for all the 52 subjects. Conclusion: Both the quantitative and visual assessments confirmed the high accuracy of the proposed computer-assisted diagnostic system for early DR detection using the OCT retinal images. © 2016 American Association of Physicists in Medicine.","diabetic retinopathy (DR); joint image-region-map model; Markov–Gibbs random field (MGRF); non-negativity-constrained autoencoder (NCAE); optical coherence tomography (OCT)","Adult; Aged; Diabetic Retinopathy; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Male; Middle Aged; Pattern Recognition, Automated; Retina; Sensitivity and Specificity; Tomography, Optical Coherence; Aldehydes; Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Distribution functions; Eye protection; Feature extraction; Image segmentation; Learning algorithms; Learning systems; Optical tomography; Statistical methods; Auto encoders; Diabetic retinopathy; Image regions; Joint image-region-map model; Markov-Gibbs random fields; Markov–gibbs random field; Non-negativity; Non-negativity-constrained autoencoder; Optical coherence tomography; adult; aged; automated pattern recognition; computer assisted diagnosis; diabetic retinopathy; diagnostic imaging; female; human; machine learning; male; middle aged; optical coherence tomography; procedures; retina; sensitivity and specificity; validation study; Ophthalmology","John Wiley and Sons Ltd","00942405","","MPHYA","28035657","Article","Scopus","2-s2.0-85016289983"
"Chai R.; Ling S.H.; San P.P.; Naik G.R.; Nguyen T.N.; Tran Y.; Craig A.; Nguyen H.T.","Chai, Rifai (55308386600); Ling, Sai Ho (24342010000); San, Phyo Phyo (35086755400); Naik, Ganesh R. (14825548600); Nguyen, Tuan N. (35183742900); Tran, Yvonne (56283966500); Craig, Ashley (56962719100); Nguyen, Hung T. (7403322521)","55308386600; 24342010000; 35086755400; 14825548600; 35183742900; 56283966500; 56962719100; 7403322521","Improving EEG-based driver fatigue classification using sparse-deep belief networks","2017","Frontiers in Neuroscience","124","10.3389/fnins.2017.00103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017160837&doi=10.3389%2ffnins.2017.00103&partnerID=40&md5=7fc0f4bd50234898736f82b08834a705","Faculty of Engineering and Information Technology, Centre for Health Technologies, University of Technology, Sydney, NSW, Australia; Data Analytic Department, Institute for Infocomm Research, A-STAR, Singapore; Kolling Institute of Medical Research, Sydney Medical School, The University of Sydney, Sydney, NSW, Australia","Chai R., Faculty of Engineering and Information Technology, Centre for Health Technologies, University of Technology, Sydney, NSW, Australia; Ling S.H., Faculty of Engineering and Information Technology, Centre for Health Technologies, University of Technology, Sydney, NSW, Australia; San P.P., Data Analytic Department, Institute for Infocomm Research, A-STAR, Singapore; Naik G.R., Faculty of Engineering and Information Technology, Centre for Health Technologies, University of Technology, Sydney, NSW, Australia; Nguyen T.N., Faculty of Engineering and Information Technology, Centre for Health Technologies, University of Technology, Sydney, NSW, Australia; Tran Y., Faculty of Engineering and Information Technology, Centre for Health Technologies, University of Technology, Sydney, NSW, Australia, Kolling Institute of Medical Research, Sydney Medical School, The University of Sydney, Sydney, NSW, Australia; Craig A., Kolling Institute of Medical Research, Sydney Medical School, The University of Sydney, Sydney, NSW, Australia; Nguyen H.T., Faculty of Engineering and Information Technology, Centre for Health Technologies, University of Technology, Sydney, NSW, Australia","This paper presents an improvement of classification performance for electroencephalography (EEG)-based driver fatigue classification between fatigue and alert states with the data collected from 43 participants. The system employs autoregressive (AR) modeling as the features extraction algorithm, and sparse-deep belief networks (sparse-DBN) as the classification algorithm. Compared to other classifiers, sparse-DBN is a semi supervised learning method which combines unsupervised learning for modeling features in the pre-training layer and supervised learning for classification in the following layer. The sparsity in sparse-DBN is achieved with a regularization term that penalizes a deviation of the expected activation of hidden units from a fixed low-level prevents the network from overfitting and is able to learn low-level structures as well as high-level structures. For comparison, the artificial neural networks (ANN), Bayesian neural networks (BNN), and original deep belief networks (DBN) classifiers are used. The classification results show that using AR feature extractor and DBN classifiers, the classification performance achieves an improved classification performance with a of sensitivity of 90.8%, a specificity of 90.4%, an accuracy of 90.6%, and an area under the receiver operating curve (AUROC) of 0.94 compared to ANN (sensitivity at 80.8%, specificity at 77.8%, accuracy at 79.3% with AUC-ROC of 0.83) and BNN classifiers (sensitivity at 84.3%, specificity at 83%, accuracy at 83.6% with AUROC of 0.87). Using the sparse-DBN classifier, the classification performance improved further with sensitivity of 93.9%, a specificity of 92.3%, and an accuracy of 93.1% with AUROC of 0.96. Overall, the sparse-DBN classifier improved accuracy by 13.8, 9.5, and 2.5% over ANN, BNN, and DBN classifiers, respectively. © 2017 Chai, Ling, San, Naik, Nguyen, Tran, Craig and Nguyen.","Autoregressive model; Deep belief networks; Driver fatigue; Electroencephalography; Sparse-deep belief networks","alertness; algorithm; Article; artificial neural network; autoregressive modeling; Bayesian learning; classifier; controlled study; diagnostic accuracy; diagnostic test accuracy study; disease classification; electroencephalogram; fatigue; human; intermethod comparison; machine learning; performance; receiver operating characteristic; sensitivity and specificity; sparse deep belief network; statistical model","Frontiers Research Foundation","16624548","","","","Article","Scopus","2-s2.0-85017160837"
"Liu J.; Wang X.; Cheng Y.; Zhang L.","Liu, Jian (57196288075); Wang, Xuesong (56090094900); Cheng, Yuhu (9733966500); Zhang, Lin (57851110400)","57196288075; 56090094900; 9733966500; 57851110400","Tumor gene expression data classification via sample expansionbased deep learning","2017","Oncotarget","55","10.18632/oncotarget.22762","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037711110&doi=10.18632%2foncotarget.22762&partnerID=40&md5=1b9a7d348f1673edd54f8e067ec1fe55","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, 221116, China","Liu J., School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, 221116, China; Wang X., School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, 221116, China; Cheng Y., School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, 221116, China; Zhang L., School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, 221116, China","Since tumor is seriously harmful to human health, effective diagnosis measures are in urgent need for tumor therapy. Early detection of tumor is particularly important for better treatment of patients. A notable issue is how to effectively discriminate tumor samples from normal ones. Many classification methods, such as Support Vector Machines (SVMs), have been proposed for tumor classification. Recently, deep learning has achieved satisfactory performance in the classification task of many areas. However, the application of deep learning is rare in tumor classification due to insufficient training samples of gene expression data. In this paper, a Sample Expansion method is proposed to address the problem. Inspired by the idea of Denoising Autoencoder (DAE), a large number of samples are obtained by randomly cleaning partially corrupted input many times. The expanded samples can not only maintain the merits of corrupted data in DAE but also deal with the problem of insufficient training samples of gene expression data to a certain extent. Since Stacked Autoencoder (SAE) and Convolutional Neural Network (CNN) models show excellent performance in classification task, the applicability of SAE and 1-dimensional CNN (1DCNN) on gene expression data is analyzed. Finally, two deep learning models, Sample Expansion-Based SAE (SESAE) and Sample Expansion-Based 1DCNN (SE1DCNN), are designed to carry out tumor gene expression data classification by using the expanded samples. Experimental studies indicate that SESAE and SE1DCNN are very effective in tumor classification. © Liu et al.","1-dimensional convolutional neural network; Classification; Deep learning; Gene expression data; Sample expansion","cleaning; experimental study; gene expression; human; learning; nervous system; support vector machine; tumor classification; tumor gene; article; controlled study; convolutional neural network; data classification; deep learning; denoising autoencoder; protein expression; stacked autoencoder; tumor classification","Impact Journals LLC","19492553","","","29312636","Article","Scopus","2-s2.0-85037711110"
"Schwartz O.; Gonzalo L.; Giraldo S.","Schwartz, Odelia (7006284113); Gonzalo, Luis (36622287000); Giraldo, Sanchez (57193843729)","7006284113; 36622287000; 57193843729","Behavioral and neural constraints on hierarchical representations","2017","Journal of Vision","2","10.1167/17.3.13.","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017104101&doi=10.1167%2f17.3.13.&partnerID=40&md5=5bf3168b4082651a2889c74b67e767f0","Department of Computer Science, University of Miami, Miami, FL, United States","Schwartz O., Department of Computer Science, University of Miami, Miami, FL, United States; Gonzalo L., Department of Computer Science, University of Miami, Miami, FL, United States; Giraldo S., Department of Computer Science, University of Miami, Miami, FL, United States","Central to behavior and cognition is the way that sensory stimuli are represented in neural systems. The distributions over such stimuli enjoy rich structure; however, how the brain captures and exploits these regularities is unclear. Here, we consider different sources of perhaps the most prevalent form of structure, namely hierarchies, in one of its most prevalent cases, namely the representation of images. We review experimental approaches across a range of subfields, spanning inference, memory recall, and visual adaptation, to investigate how these constrain hierarchical representations. We also discuss progress in building hierarchical models of the representation of images-this has the potential to clarify how the structure of the world is reflected in biological systems. We suggest there is a need for a closer embedding of recent advances in machine learning and computer vision into the design and interpretation of experiments, notably by utilizing the understanding of the structure of natural scenes and through the creation of hierarchically structured synthetic stimuli. © 2017 The Authors.","Deep learning; Hierarchy; Natural scenes; Representation","Animals; Cognition; Humans; Memory, Short-Term; Motor Neurons; Visual Perception; animal; cognition; human; motoneuron; physiology; short term memory; vision","Association for Research in Vision and Ophthalmology Inc.","15347362","","","28319238","Article","Scopus","2-s2.0-85017104101"
"Kim J.; Kang U.; Lee Y.","Kim, Jaekwon (55720129100); Kang, Ungu (14045447600); Lee, Youngho (55192335300)","55720129100; 14045447600; 55192335300","Statistics and deep belief network-based cardiovascular risk prediction","2017","Healthcare Informatics Research","30","10.4258/hir.2017.23.3.169","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027006928&doi=10.4258%2fhir.2017.23.3.169&partnerID=40&md5=1255040c9823441cff40dbd5c9f320c1","Department of Computer and Information Engineering, Inha University, Incheon, South Korea; IT Department, Gachon University, Seongnam, South Korea","Kim J., Department of Computer and Information Engineering, Inha University, Incheon, South Korea; Kang U., IT Department, Gachon University, Seongnam, South Korea; Lee Y., IT Department, Gachon University, Seongnam, South Korea","Objectives: Cardiovascular predictions are related to patients’ quality of life and health. Therefore, a risk prediction model for cardiovascular conditions is needed. Methods: In this paper, we propose a cardiovascular disease prediction model using the sixth Korea National Health and Nutrition Examination Survey (KNHANES-VI) 2013 dataset to analyze cardiovascular-related health data. First, statistical analysis was performed to find variables related to cardiovascular disease using health data related to cardiovascular disease. Second, a model of cardiovascular risk prediction by learning based on the deep belief network (DBN) was developed. Results: The proposed statistical DBN-based prediction model showed accuracy and an ROC curve of 83.9% and 0.790, respectively. Thus, the proposed statistical DBN performed better than other prediction algorithms. Conclusions: The DBN proposed in this study appears to be effective in predicting cardiovascular risk and, in particular, is expected to be applicable to the prediction of cardiovascular disease in Koreans. © 2017 The Korean Society of Medical Informatics.","Cardiovascular diseases; Cardiovascular risk prediction; Deep belief network; KNHANES; Machine learning","","Korean Society of Medical Informatics","20933681","","","","Article","Scopus","2-s2.0-85027006928"
"Pang S.; Yu Z.; Orgun M.A.","Pang, Shuchao (55639762100); Yu, Zhezhou (8938987700); Orgun, Mehmet A. (6603681610)","55639762100; 8938987700; 6603681610","A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images","2017","Computer Methods and Programs in Biomedicine","67","10.1016/j.cmpb.2016.12.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011883667&doi=10.1016%2fj.cmpb.2016.12.019&partnerID=40&md5=3461c46640f53b42561a301ee3e549bd","College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China; Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Faculty of Information Technology, Macau University of Science and Technology, Taipa, Macao","Pang S., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China, Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Yu Z., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China; Orgun M.A., Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia, Faculty of Information Technology, Macau University of Science and Technology, Taipa, Macao","Background and objectives Highly accurate classification of biomedical images is an essential task in the clinical diagnosis of numerous medical diseases identified from those images. Traditional image classification methods combined with hand-crafted image feature descriptors and various classifiers are not able to effectively improve the accuracy rate and meet the high requirements of classification of biomedical images. The same also holds true for artificial neural network models directly trained with limited biomedical images used as training data or directly used as a black box to extract the deep features based on another distant dataset. In this study, we propose a highly reliable and accurate end-to-end classifier for all kinds of biomedical images via deep learning and transfer learning. Methods We first apply domain transferred deep convolutional neural network for building a deep model; and then develop an overall deep learning architecture based on the raw pixels of original biomedical images using supervised training. In our model, we do not need the manual design of the feature space, seek an effective feature vector classifier or segment specific detection object and image patches, which are the main technological difficulties in the adoption of traditional image classification methods. Moreover, we do not need to be concerned with whether there are large training sets of annotated biomedical images, affordable parallel computing resources featuring GPUs or long times to wait for training a perfect deep model, which are the main problems to train deep neural networks for biomedical image classification as observed in recent works. Results With the utilization of a simple data augmentation method and fast convergence speed, our algorithm can achieve the best accuracy rate and outstanding classification ability for biomedical images. We have evaluated our classifier on several well-known public biomedical datasets and compared it with several state-of-the-art approaches. Conclusions We propose a robust automated end-to-end classifier for biomedical images based on a domain transferred deep convolutional neural network model that shows a highly reliable and accurate performance which has been confirmed on several public biomedical image datasets. © 2017 Elsevier Ireland Ltd","Biomedical image classification; Convolutional neural network; Data augmentation; Deep learning; Transfer learning","Diagnostic Imaging; Machine Learning; Models, Theoretical; Neural Networks (Computer); Bioinformatics; Computer aided diagnosis; Convolution; Data mining; Deep learning; Deep neural networks; Diagnosis; Image classification; Image segmentation; Medical imaging; Neural networks; Program processors; Vector spaces; Artificial neural network models; Classification ability; Classification methods; Convolutional neural network; Data augmentation; Fast convergence speed; State-of-the-art approach; Transfer learning; Article; artificial neural network; automation; back propagation; biomedicine; classification algorithm; classifier; controlled study; convolutional neural network; deep learning; diagnostic imaging; high resolution computer tomography; histogram; human; image analysis; image processing; machine learning; medical technology; support vector machine; training; transfer learning; velocity; machine learning; theoretical model; Classification (of information)","Elsevier Ireland Ltd","01692607","","CMPBE","28254085","Article","Scopus","2-s2.0-85011883667"
"Ferroni P.; Zanzotto F.M.; Scarpato N.; Riondino S.; Guadagni F.; Roselli M.","Ferroni, Patrizia (7004552407); Zanzotto, Fabio M. (7801422424); Scarpato, Noemi (25926716200); Riondino, Silvia (6602071793); Guadagni, Fiorella (7006062519); Roselli, Mario (7006382279)","7004552407; 7801422424; 25926716200; 6602071793; 7006062519; 7006382279","Validation of a machine learning approach for venous thromboembolism risk prediction in oncology","2017","Disease Markers","51","10.1155/2017/8781379","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029581331&doi=10.1155%2f2017%2f8781379&partnerID=40&md5=03a4fb5f306eb61b282f5dce09519aad","Department of Human Sciences and Quality of Life Promotion, San Raffaele Roma Open University, Rome, 00166, Italy; Interinstitutional Multidisciplinary Biobank (BioBIM), IRCCS San Raffaele Pisana, Rome, 00166, Italy; Department of Enterprise Engineering, University of Rome 'Tor Vergata', Rome, 00133, Italy; Department of Systems Medicine, Medical Oncology, University of Rome 'Tor Vergata', Rome, 00133, Italy","Ferroni P., Department of Human Sciences and Quality of Life Promotion, San Raffaele Roma Open University, Rome, 00166, Italy, Interinstitutional Multidisciplinary Biobank (BioBIM), IRCCS San Raffaele Pisana, Rome, 00166, Italy; Zanzotto F.M., Department of Enterprise Engineering, University of Rome 'Tor Vergata', Rome, 00133, Italy; Scarpato N., Department of Human Sciences and Quality of Life Promotion, San Raffaele Roma Open University, Rome, 00166, Italy; Riondino S., Interinstitutional Multidisciplinary Biobank (BioBIM), IRCCS San Raffaele Pisana, Rome, 00166, Italy, Department of Systems Medicine, Medical Oncology, University of Rome 'Tor Vergata', Rome, 00133, Italy; Guadagni F., Department of Human Sciences and Quality of Life Promotion, San Raffaele Roma Open University, Rome, 00166, Italy, Interinstitutional Multidisciplinary Biobank (BioBIM), IRCCS San Raffaele Pisana, Rome, 00166, Italy; Roselli M., Department of Systems Medicine, Medical Oncology, University of Rome 'Tor Vergata', Rome, 00133, Italy","Using kernel machine learning (ML) and random optimization (RO) techniques, we recently developed a set of venous thromboembolism (VTE) risk predictors, which could be useful to devise a web interface for VTE risk stratification in chemotherapy-treated cancer patients. This study was designed to validate a model incorporating the two best predictors and to compare their combined performance with that of the currently recommended Khorana score (KS). Age, sex, tumor site/stage, hematological attributes, blood lipids, glycemic indexes, liver and kidney function, BMI, performance status, and supportive and anticancer drugs of 608 cancer outpatients were all entered in the model, with numerical attributes analyzed as continuous values. VTE rate was 7.1%. The VTE risk prediction performance of the combined model resulted in 2.30 positive likelihood ratio (+LR), 0.46 negative LR (-LR), and 4.88 HR (95% CI: 2.54-9.37), with a significant improvement over the KS [HR 1.73 (95% CI: 0.47-6.37)]. These results confirm that a ML approach might be of clinical value for VTE risk stratification in chemotherapy-treated cancer outpatients and suggest that the ML-RO model proposed could be useful to design a web service able to provide physicians with a graphical interface helping in the critical phase of decision making. Copyright © 2017 Patrizia Ferroni et al.","","Adolescent; Adult; Aged; Aged, 80 and over; Antineoplastic Agents; Female; Humans; Machine Learning; Male; Middle Aged; Models, Statistical; Sensitivity and Specificity; Venous Thromboembolism; alanine aminotransferase; anthracycline; antianemic agent; antineoplastic metal complex; aromatase inhibitor; aspartate aminotransferase; bevacizumab; bilirubin; cholesterol; corticosteroid; creatinine; fluoropyrimidine; gamma glutamyltransferase; gemcitabine; glucose; growth factor; hemoglobin; hemoglobin A1c; high density lipoprotein cholesterol; insulin; irinotecan; low density lipoprotein cholesterol; myeloid growth factor; paclitaxel; pemetrexed; protein tyrosine kinase inhibitor; taxane derivative; trastuzumab; triacylglycerol; unclassified drug; antineoplastic agent; adjuvant therapy; adult; age; aged; Article; bile duct cancer; body mass; breast cancer; cancer chemotherapy; cancer patient; cancer prognosis; cancer radiotherapy; cancer staging; cancer survival; cardiovascular disease assessment; cholesterol blood level; cohort analysis; colorectal cancer; deep vein thrombosis; diagnostic test accuracy study; disease association; erythrocyte count; esophagus cancer; estimated glomerular filtration rate; female; follow up; glioblastoma; glycemic index; head and neck cancer; hematocrit; human; kernel method; Khorana score; kidney function; leukocyte count; lipid blood level; liver cancer; liver function; lung embolism; lymphocyte count; major clinical study; male; mathematical model; melanoma; mesothelioma; neuroendocrine tumor; neutrophil count; neutrophil lymphocyte ratio; non small cell lung cancer; outpatient; ovary cancer; pancreas cancer; pilot study; platelet lymphocyte ratio; predictive value; predictor variable; prostate cancer; random optimization; risk assessment; sarcoma; sensitivity and specificity; sex; skin cancer; small cell lung cancer; small intestine cancer; stomach cancer; survival rate; thrombocyte count; thrombocyte volume; urea nitrogen blood level; urogenital tract cancer; validation process; venous thromboembolism; adolescent; machine learning; middle aged; statistical model; validation study; venous thromboembolism; very elderly","Hindawi Limited","02780240","","DMARD","29104344","Article","Scopus","2-s2.0-85029581331"
"Lai Z.; Deng H.","Lai, ZhiFei (57200690733); Deng, HuiFang (7401775498)","57200690733; 7401775498","Multiscale High-Level Feature Fusion for Histopathological Image Classification","2017","Computational and Mathematical Methods in Medicine","2","10.1155/2017/7521846","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042174495&doi=10.1155%2f2017%2f7521846&partnerID=40&md5=3faae86612434f11e0a9170f8df0c7f9","Department of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China","Lai Z., Department of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; Deng H., Department of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China","Histopathological image classification is one of the most important steps for disease diagnosis. We proposed a method for multiclass histopathological image classification based on deep convolutional neural network referred to as coding network. It can gain better representation for the histopathological image than only using coding network. The main process is that training a deep convolutional neural network is to extract high-level feature and fuse two convolutional layers' high-level feature as multiscale high-level feature. In order to gain better performance and high efficiency, we would employ sparse autoencoder (SAE) and principal components analysis (PCA) to reduce the dimensionality of multiscale high-level feature. We evaluate the proposed method on a real histopathological image dataset. Our results suggest that the proposed method is effective and outperforms the coding network. © 2017 ZhiFei Lai and HuiFang Deng.","","Algorithms; Area Under Curve; Diagnosis, Computer-Assisted; Diagnostic Imaging; False Positive Reactions; Image Processing, Computer-Assisted; Machine Learning; Models, Statistical; Neural Networks (Computer); Principal Component Analysis; Reproducibility of Results; ROC Curve; Software; Classification (of information); Computer aided diagnosis; Convolution; Convolutional neural networks; Deep neural networks; Image coding; Multilayer neural networks; Network coding; Auto encoders; Disease diagnosis; High-efficiency; High-level features; Histopathological images; Main process; Principal components analysis; acanthosis; algorithm; Article; artificial neural network; classification; histopathology; human; human tissue; hyperkeratosis; hyperpigmentation; image analysis; lymphocytic infiltration; methodology; model; papillomatosis; parakeratosis; principal component analysis; skin biopsy; sparse autoencoder; area under the curve; artificial neural network; computer assisted diagnosis; diagnostic imaging; false positive result; image processing; machine learning; procedures; receiver operating characteristic; reproducibility; software; statistical model; Image classification","Hindawi Limited","1748670X","","","29463986","Article","Scopus","2-s2.0-85042174495"
"Yu S.; Jia S.; Xu C.","Yu, Shiqi (8403845200); Jia, Sen (7202859948); Xu, Chunyan (55878062700)","8403845200; 7202859948; 55878062700","Convolutional neural networks for hyperspectral image classification","2017","Neurocomputing","503","10.1016/j.neucom.2016.09.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994519156&doi=10.1016%2fj.neucom.2016.09.010&partnerID=40&md5=4db3fadf382d1db026b1e657fcc3cbb9","College of Computer Science and Software Engineering, Shenzhen University, China; School of Computer Science and Technology, Nanjing University of Science and Technology, China","Yu S., College of Computer Science and Software Engineering, Shenzhen University, China; Jia S., College of Computer Science and Software Engineering, Shenzhen University, China; Xu C., School of Computer Science and Technology, Nanjing University of Science and Technology, China","As a powerful visual model, convolutional neural networks (CNNs) have demonstrated remarkable performance in various visual recognition problems, and attracted considerable attention in recent years. However, due to the highly correlated bands and insufficient training samples of hyperspectral image data, it still remains a challenging problem to effectively apply the CNN models on hyperspectral images. In this paper, an efficient CNN architecture has been proposed to boost its discriminative capability for hyperspectral image classification, in which the original data is used as the input and the final CNN outputs are the predicted class-related results. The proposed CNN infrastructure has several distinct advantages. Firstly, different from traditional classification methods those need hand-crafted features, the CNN model used here is designed to deal with the problem of hyperspectral image analysis in an end-to-end way. Secondly, the parameters of the CNN model are optimized from a small training set, while the over-fitting problem of the neural network has been alleviated to some extent. Finally, in order to better deal with the hyperspectral image information, 1 × 1 convolutional layers have been adopted, and an average pooling layer and larger dropout rates have also been employed in the whole CNN procedure. The experiments on three benchmark data sets have demonstrated that the proposed CNN architecture considerably outperforms other state-of-the-art methods. © 2016 Elsevier B.V.","Convolutional neural networks; Deep learning; Hyperspectral image classification","Classification (of information); Convolution; Independent component analysis; Network architecture; Neural networks; Spectroscopy; Classification methods; Convolutional neural network; Deep learning; Hyper-spectral images; Hyperspectral image analysis; Hyperspectral image classification; Hyperspectral image datas; State-of-the-art methods; Article; artificial neural network; controlled study; convolutional neural network; hyperspectral image classification; image analysis; image display; image processing; imaging and display; optical resolution; plots and curves; priority journal; probability; remote sensing; support vector machine; Image classification","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84994519156"
"Korbar B.; Olofson A.; Miraflor A.; Nicka C.; Suriawinata M.; Torresani L.; Suriawinata A.; Hassanpour S.","Korbar, Bruno (57194771754); Olofson, Andrea (57193208631); Miraflor, Allen (56899010500); Nicka, Catherine (57214605955); Suriawinata, Matthew (57195938075); Torresani, Lorenzo (6506606617); Suriawinata, Arief (6701819528); Hassanpour, Saeed (56835377400)","57194771754; 57193208631; 56899010500; 57214605955; 57195938075; 6506606617; 6701819528; 56835377400","Deep learning for classification of colorectal polyps on whole-slide images","2017","Journal of Pathology Informatics","225","10.4103/jpi.jpi_34_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053416127&doi=10.4103%2fjpi.jpi_34_17&partnerID=40&md5=d22bc8adc30b989b3447ec37c7e8f63f","Departments of Biomedical Data Science, United States; Department of Computer Science, Dartmouth College, Hanover, 03755, NH, United States; Pathology and Laboratory Medicine, United States; Departments of Epidemiology, Geisel School of Medicine at Dartmouth, One Medical Center Drive, Lebanon, 03756, NH, United States","Korbar B., Departments of Biomedical Data Science, United States, Department of Computer Science, Dartmouth College, Hanover, 03755, NH, United States; Olofson A., Pathology and Laboratory Medicine, United States; Miraflor A., Pathology and Laboratory Medicine, United States; Nicka C., Pathology and Laboratory Medicine, United States; Suriawinata M., Pathology and Laboratory Medicine, United States; Torresani L., Department of Computer Science, Dartmouth College, Hanover, 03755, NH, United States; Suriawinata A., Pathology and Laboratory Medicine, United States; Hassanpour S., Departments of Biomedical Data Science, United States, Department of Computer Science, Dartmouth College, Hanover, 03755, NH, United States, Departments of Epidemiology, Geisel School of Medicine at Dartmouth, One Medical Center Drive, Lebanon, 03756, NH, United States","Context: Histopathological characterization of colorectal polyps is critical for determining the risk of colorectal cancer and future rates of surveillance for patients. However, this characterization is a challenging task and suffers from significant inter- A nd intra-observer variability. Aims: We built an automatic image analysis method that can accurately classify different types of colorectal polyps on whole-slide images to help pathologists with this characterization and diagnosis. Setting and Design: Our method is based on deep-learning techniques, which rely on numerous levels of abstraction for data representation and have shown state-of-the-art results for various image analysis tasks. Subjects and Methods: Our method covers five common types of polyps (i.e., hyperplastic, sessile serrated, traditional serrated, tubular, and tubulovillous/villous) that are included in the US Multisociety Task Force guidelines for colorectal cancer risk assessment and surveillance. We developed multiple deep-learning approaches by leveraging a dataset of 2074 crop images, which were annotated by multiple domain expert pathologists as reference standards. Statistical Analysis: We evaluated our method on an independent test set of 239 whole-slide images and measured standard machine-learning evaluation metrics of accuracy, precision, recall, and F1 score and their 95% confidence intervals. Results: Our evaluation shows that our method with residual network architecture achieves the best performance for classification of colorectal polyps on whole-slide images (overall accuracy: 93.0%, 95% confidence interval: 89.0%-95.9%). Conclusions: Our method can reduce the cognitive burden on pathologists and improve their efficacy in histopathological characterization of colorectal polyps and in subsequent risk assessment and follow-up recommendations. © 2017 Journal of Pathology Informatics.","Colorectal polyps; deep learning; digital pathology; histopathological characterization","","Wolters Kluwer Medknow Publications","22295089","","","","Article","Scopus","2-s2.0-85053416127"
"Zhang Y.N.","Zhang, Y.N. (57191205493)","57191205493","Can a Smartphone Diagnose Parkinson Disease? A Deep Neural Network Method and Telediagnosis System Implementation","2017","Parkinson's Disease","69","10.1155/2017/6209703","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030776457&doi=10.1155%2f2017%2f6209703&partnerID=40&md5=150f23dcab02afd6f199757c6d3f3420","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, 100081, China; College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin, 300222, China","Zhang Y.N., School of Computer Science and Technology, Beijing Institute of Technology, Beijing, 100081, China, College of Computer Science and Information Engineering, Tianjin University of Science and Technology, Tianjin, 300222, China","Parkinson's disease (PD) is primarily diagnosed by clinical examinations, such as walking test, handwriting test, and MRI diagnostic. In this paper, we propose a machine learning based PD telediagnosis method for smartphone. Classification of PD using speech records is a challenging task owing to the fact that the classification accuracy is still lower than doctor-level. Here we demonstrate automatic classification of PD using time frequency features, stacked autoencoders (SAE), and K nearest neighbor (KNN) classifier. KNN classifier can produce promising classification results from useful representations which were learned by SAE. Empirical results show that the proposed method achieves better performance with all tested cases across classification tasks, demonstrating machine learning capable of classifying PD with a level of competence comparable to doctor. It concludes that a smartphone can therefore potentially provide low-cost PD diagnostic care. This paper also gives an implementation on browser/server system and reports the running time cost. Both advantages and disadvantages of the proposed telediagnosis system are discussed. © 2017 Y. N. Zhang.","","Article; artificial neural network; disease classification; k nearest neighbor; machine learning; Parkinson disease; smartphone; speech disorder; telediagnosis; waveform","Hindawi Limited","20420080","","","","Article","Scopus","2-s2.0-85030776457"
"Mahmood K.; Jung C.-H.; Philip G.; Georgeson P.; Chung J.; Pope B.J.; Park D.J.","Mahmood, Khalid (7005543223); Jung, Chol-Hee (56896655400); Philip, Gayle (13805187700); Georgeson, Peter (57188804248); Chung, Jessica (56941206600); Pope, Bernard J. (7005597341); Park, Daniel J. (57061360800)","7005543223; 56896655400; 13805187700; 57188804248; 56941206600; 7005597341; 57061360800","Variant effect prediction tools assessed using independent, functional assay-based datasets: Implications for discovery and diagnostics","2017","Human Genomics","57","10.1186/s40246-017-0104-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042114543&doi=10.1186%2fs40246-017-0104-8&partnerID=40&md5=7da03ebdfa8cbd94b30e154523747bf8","Melbourne Bioinformatics, University of Melbourne, Melbourne, VIC, Australia","Mahmood K., Melbourne Bioinformatics, University of Melbourne, Melbourne, VIC, Australia; Jung C.-H., Melbourne Bioinformatics, University of Melbourne, Melbourne, VIC, Australia; Philip G., Melbourne Bioinformatics, University of Melbourne, Melbourne, VIC, Australia; Georgeson P., Melbourne Bioinformatics, University of Melbourne, Melbourne, VIC, Australia; Chung J., Melbourne Bioinformatics, University of Melbourne, Melbourne, VIC, Australia; Pope B.J., Melbourne Bioinformatics, University of Melbourne, Melbourne, VIC, Australia; Park D.J., Melbourne Bioinformatics, University of Melbourne, Melbourne, VIC, Australia","Background: Genetic variant effect prediction algorithms are used extensively in clinical genomics and research to determine the likely consequences of amino acid substitutions on protein function. It is vital that we better understand their accuracies and limitations because published performance metrics are confounded by serious problems of circularity and error propagation. Here, we derive three independent, functionally determined human mutation datasets, UniFun, BRCA1-DMS and TP53-TA, and employ them, alongside previously described datasets, to assess the pre-eminent variant effect prediction tools. Results: Apparent accuracies of variant effect prediction tools were influenced significantly by the benchmarking dataset. Benchmarking with the assay-determined datasets UniFun and BRCA1-DMS yielded areas under the receiver operating characteristic curves in the modest ranges of 0.52 to 0.63 and 0.54 to 0.75, respectively, considerably lower than observed for other, potentially more conflicted datasets. Conclusions: These results raise concerns about how such algorithms should be employed, particularly in a clinical setting. Contemporary variant effect prediction tools are unlikely to be as accurate at the general prediction of functional impacts on proteins as reported prior. Use of functional assay-based datasets that avoid prior dependencies promises to be valuable for the ongoing development and accurate benchmarking of such tools. © The Author(s). 2017.","Benchmarking; Functional assays; Functional datasets; Genomic screening; Mutation assessment; Pathogenicity prediction; Protein function; Variant effect prediction","Algorithms; Databases, Genetic; Datasets as Topic; Genes, BRCA1; Genes, p53; Humans; Mutation; Software; protein; algorithm; Article; assay; benchmarking; brca1 deep mutational scanning dataset; cancer inhibition; controlled study; DNA repair; gene mutation; genetic variability; homology directed dna repair; human; information processing; machine learning; measurement accuracy; prediction; tp53 transactivation assay; transactivation assay; unifun dataset; genetic database; mutation; software; tumor suppressor gene","BioMed Central Ltd.","14739542","","","28511696","Article","Scopus","2-s2.0-85042114543"
"Rajkomar A.; Lingam S.; Taylor A.G.; Blum M.; Mongan J.","Rajkomar, Alvin (57034062800); Lingam, Sneha (57191503891); Taylor, Andrew G. (57212317787); Blum, Michael (58323113700); Mongan, John (6601966565)","57034062800; 57191503891; 57212317787; 58323113700; 6601966565","High-Throughput Classification of Radiographs Using Deep Convolutional Neural Networks","2017","Journal of Digital Imaging","110","10.1007/s10278-016-9914-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991063753&doi=10.1007%2fs10278-016-9914-9&partnerID=40&md5=92c084cf3d5e11301036260745180143","Department of Medicine, Division of Hospital Medicine, University of California, San Francisco, 533 Parnassus Ave., Suite 127a, San Francisco, 94143-0131, CA, United States; Center for Digital Health Innovation, University of California, San Francisco, San Francisco, CA, United States; Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, CA, United States","Rajkomar A., Department of Medicine, Division of Hospital Medicine, University of California, San Francisco, 533 Parnassus Ave., Suite 127a, San Francisco, 94143-0131, CA, United States, Center for Digital Health Innovation, University of California, San Francisco, San Francisco, CA, United States; Lingam S., Center for Digital Health Innovation, University of California, San Francisco, San Francisco, CA, United States; Taylor A.G., Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, CA, United States; Blum M., Center for Digital Health Innovation, University of California, San Francisco, San Francisco, CA, United States; Mongan J., Department of Radiology and Biomedical Imaging, University of California, San Francisco, San Francisco, CA, United States","The study aimed to determine if computer vision techniques rooted in deep learning can use a small set of radiographs to perform clinically relevant image classification with high fidelity. One thousand eight hundred eighty-five chest radiographs on 909 patients obtained between January 2013 and July 2015 at our institution were retrieved and anonymized. The source images were manually annotated as frontal or lateral and randomly divided into training, validation, and test sets. Training and validation sets were augmented to over 150,000 images using standard image manipulations. We then pre-trained a series of deep convolutional networks based on the open-source GoogLeNet with various transformations of the open-source ImageNet (non-radiology) images. These trained networks were then fine-tuned using the original and augmented radiology images. The model with highest validation accuracy was applied to our institutional test set and a publicly available set. Accuracy was assessed by using the Youden Index to set a binary cutoff for frontal or lateral classification. This retrospective study was IRB approved prior to initiation. A network pre-trained on 1.2 million greyscale ImageNet images and fine-tuned on augmented radiographs was chosen. The binary classification method correctly classified 100 % (95 % CI 99.73–100 %) of both our test set and the publicly available images. Classification was rapid, at 38 images per second. A deep convolutional neural network created using non-radiological images, and an augmented set of radiographs is effective in highly accurate classification of chest radiograph view type and is a feasible, rapid method for high-throughput annotation. © 2016, The Author(s).","Artificial neural networks; Chest radiographs; Computer vision; Convolutional neural network; Deep learning; Machine learning; Radiography","Humans; Neural Networks (Computer); Radiography; Radiography, Thoracic; Random Allocation; Retrospective Studies; Artificial intelligence; Bins; Classification (of information); Computer aided diagnosis; Computer vision; Convolution; Learning systems; Neural networks; Radiation; Radiography; Radiology; Throughput; Binary classification methods; Chest radiographs; Computer vision techniques; Convolutional networks; Convolutional neural network; Deep learning; Radiological images; Validation sets; artificial neural network; classification; human; radiography; randomization; retrospective study; statistics and numerical data; thorax radiography; Image classification","Springer New York LLC","08971889","","JDIME","27730417","Article","Scopus","2-s2.0-84991063753"
"Wang G.; Sun Y.; Wang J.","Wang, Guan (57194706582); Sun, Yu (56176987100); Wang, Jianxin (55930514400)","57194706582; 56176987100; 55930514400","Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning","2017","Computational Intelligence and Neuroscience","516","10.1155/2017/2917536","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024478063&doi=10.1155%2f2017%2f2917536&partnerID=40&md5=7fbd2fcd7c9388d131dd0d84c2dd7377","School of Information Science and Technology, Beijing Forestry University, Beijing, 100083, China","Wang G., School of Information Science and Technology, Beijing Forestry University, Beijing, 100083, China; Sun Y., School of Information Science and Technology, Beijing Forestry University, Beijing, 100083, China; Wang J., School of Information Science and Technology, Beijing Forestry University, Beijing, 100083, China","Automatic and accurate estimation of disease severity is essential for food security, disease management, and yield loss prediction. Deep learning, the latest breakthrough in computer vision, is promising for fine-grained disease severity classification, as the method avoids the labor-intensive feature engineering and threshold-based segmentation. Using the apple black rot images in the PlantVillage dataset, which are further annotated by botanists with four severity stages as ground truth, a series of deep convolutional neural networks are trained to diagnose the severity of the disease. The performances of shallow networks trained from scratch and deep models fine-tuned by transfer learning are evaluated systemically in this paper. The best model is the deep VGG16 model trained with transfer learning, which yields an overall accuracy of 90.4% on the hold-out test set. The proposed deep learning model may have great potential in disease control for modern agriculture. © 2017 Guan Wang et al.","","Machine Learning; Malus; Neural Networks (Computer); Plant Diseases; Deep neural networks; Disease control; Education; Food supply; Neural networks; Accurate estimation; Convolutional neural network; Disease management; Disease severity; Feature engineerings; Modern agricultures; Overall accuracies; Transfer learning; artificial neural network; classification; machine learning; Malus; microbiology; plant disease; Deep learning","Hindawi Limited","16875265","","","28757863","Article","Scopus","2-s2.0-85024478063"
"Reda I.; Shalaby A.; Elmogy M.; Elfotouh A.A.; Khalifa F.; El-Ghar M.A.; Hosseini-Asl E.; Gimel'farb G.; Werghi N.; El-Baz A.","Reda, Islam (57215835177); Shalaby, Ahmed (57197612511); Elmogy, Mohammed (33567709900); Elfotouh, Ahmed Abou (57192810077); Khalifa, Fahmi (36622321200); El-Ghar, Mohamed Abou (6507285793); Hosseini-Asl, Ehsan (56209258600); Gimel'farb, Georgy (35618719900); Werghi, Naoufel (6603290473); El-Baz, Ayman (6602350405)","57215835177; 57197612511; 33567709900; 57192810077; 36622321200; 6507285793; 56209258600; 35618719900; 6603290473; 6602350405","A comprehensive non-invasive framework for diagnosing prostate cancer","2017","Computers in Biology and Medicine","33","10.1016/j.compbiomed.2016.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008152019&doi=10.1016%2fj.compbiomed.2016.12.010&partnerID=40&md5=8c5d28f28cd8a7cec409d24a0dfb2b0e","Faculty of Computers and Information, Mansoura University, Mansoura, 35516, Egypt; Bioengineering Department, University of Louisville, Louisville, 40292, KY, United States; Electronics and Communication Engineering Department, Mansoura University, Mansoura, Egypt; Radiology Department, Urology and Nephrology Center, University of Mansoura, Egypt; Electrical and Computer Engineering, University of Louisville, Louisville, 40292, KY, United States; Department of Computer Science, University of Auckland, Auckland, New Zealand; Khalifa University of Science Technology and Research, Abu Dhabi, United States","Reda I., Faculty of Computers and Information, Mansoura University, Mansoura, 35516, Egypt, Bioengineering Department, University of Louisville, Louisville, 40292, KY, United States; Shalaby A., Bioengineering Department, University of Louisville, Louisville, 40292, KY, United States; Elmogy M., Faculty of Computers and Information, Mansoura University, Mansoura, 35516, Egypt, Bioengineering Department, University of Louisville, Louisville, 40292, KY, United States; Elfotouh A.A., Faculty of Computers and Information, Mansoura University, Mansoura, 35516, Egypt; Khalifa F., Bioengineering Department, University of Louisville, Louisville, 40292, KY, United States, Electronics and Communication Engineering Department, Mansoura University, Mansoura, Egypt; El-Ghar M.A., Radiology Department, Urology and Nephrology Center, University of Mansoura, Egypt; Hosseini-Asl E., Electrical and Computer Engineering, University of Louisville, Louisville, 40292, KY, United States; Gimel'farb G., Department of Computer Science, University of Auckland, Auckland, New Zealand; Werghi N., Khalifa University of Science Technology and Research, Abu Dhabi, United States; El-Baz A., Bioengineering Department, University of Louisville, Louisville, 40292, KY, United States","Early detection of prostate cancer increases chances of patients' survival. Our automated non-invasive system for computer-aided diagnosis (CAD) of prostate cancer segments the prostate on diffusion-weighted magnetic resonance images (DW-MRI) acquired at different b-values, estimates its apparent diffusion coefficients (ADC), and classifies their descriptors – empirical cumulative distribution functions (CDF) – with a trained deep learning network. To segment the prostate, an evolving geometric (level-set-based) deformable model is guided by a speed function depending on intensity attributes extracted from the DW-MRI with nonnegative matrix factorization (NMF). For a more robust evolution, the attributes are fused with a probabilistic shape prior and estimated spatial dependencies between prostate voxels. To preserve continuity, the ADCs of the segmented prostate volume at different b-values are normalized and refined using a generalized Gauss-Markov random field image model. The CDFs of the refined ADCs at different b-values are considered global water diffusion features and used to distinguish between benign and malignant prostates. A deep learning network of stacked non-negativity-constrained auto-encoders (SNCAE) is trained to classify the benign or malignant prostates on the basis of the constructed CDFs. Our experiments on 53 clinical DW-MRI data sets resulted in 92.3% accuracy, 83.3% sensitivity, and 100% specificity, indicating that the proposed CAD system could be used as a reliable non-invasive diagnostic tool. © 2017 Elsevier Ltd","CAD; DW-MRI; MGRF; NMF; Prostate cancer","Algorithms; Diffusion Magnetic Resonance Imaging; Early Detection of Cancer; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Male; Pattern Recognition, Automated; Prostatic Neoplasms; Reproducibility of Results; ROC Curve; Sensitivity and Specificity; Computer aided design; Computer aided instruction; Diagnosis; Diffusion; Diseases; Distribution functions; Factorization; Gaussian distribution; Learning systems; Magnetic levitation vehicles; Magnetic resonance; Magnetic resonance imaging; Markov processes; Matrix algebra; Noninvasive medical procedures; Surface diffusion; Urology; Apparent diffusion coefficient; Computer Aided Diagnosis(CAD); Diffusion-weighted magnetic resonance; Empirical cumulative distribution functions; Gauss markov random fields; MGRF; Nonnegative matrix factorization; Prostate cancers; Article; cancer diagnosis; diagnostic accuracy; diffusion weighted imaging; human; human tissue; image segmentation; k nearest neighbor; male; multiparametric magnetic resonance imaging; nuclear magnetic resonance scanner; nuclear magnetic resonance spectroscopy; oncological parameters; priority journal; prostate cancer; prostate volume; random forest; sensitivity and specificity; algorithm; automated pattern recognition; computer assisted diagnosis; early cancer diagnosis; evaluation study; machine learning; pathology; procedures; prostate tumor; receiver operating characteristic; reproducibility; Computer aided diagnosis","Elsevier Ltd","00104825","","CBMDA","28063376","Article","Scopus","2-s2.0-85008152019"
"Li J.; Sarma K.V.; Chung Ho K.; Gertych A.; Knudsen B.S.; Arnold C.W.","Li, Jiayun (57202745945); Sarma, Karthik V. (56480098200); Chung Ho, King (57205138655); Gertych, Arkadiusz (7801318586); Knudsen, Beatrice S. (7004937729); Arnold, Corey W. (18436092400)","57202745945; 56480098200; 57205138655; 7801318586; 7004937729; 18436092400","A Multi-scale U-Net for Semantic Segmentation of Histological Images from Radical Prostatectomies","2017","AMIA ... Annual Symposium proceedings. AMIA Symposium","55","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053674575&partnerID=40&md5=464f96ce78d94db936e90712517f20d0","Department of Bioengineering, University of California, Los Angeles, CA, United States; Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States; Department of Surgery, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Department of Pathology and Laboratory Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Department of Biomedical Sciences, Cedars-Sinai Medical Center, Los Angeles, CA, United States","Li J., Department of Bioengineering, University of California, Los Angeles, CA, United States, Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States; Sarma K.V., Department of Bioengineering, University of California, Los Angeles, CA, United States, Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States; Chung Ho K., Department of Bioengineering, University of California, Los Angeles, CA, United States, Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States; Gertych A., Department of Surgery, Cedars-Sinai Medical Center, Los Angeles, CA, United States, Department of Pathology and Laboratory Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Knudsen B.S., Department of Pathology and Laboratory Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States, Department of Biomedical Sciences, Cedars-Sinai Medical Center, Los Angeles, CA, United States; Arnold C.W., Department of Bioengineering, University of California, Los Angeles, CA, United States, Computational Integrated Diagnostics, Departments of Radiological Sciences and Pathology and Laboratory Medicine, University of California, Los Angeles, CA, United States","Gleason grading of histological images is important in risk assessment and treatment planning for prostate cancer patients. Much research has been done in classifying small homogeneous cancer regions within histological images. However, semi-supervised methods published to date depend on pre-selected regions and cannot be easily extended to an image of heterogeneous tissue composition. In this paper, we propose a multi-scale U-Net model to classify images at the pixel-level using 224 histological image tiles from radical prostatectomies of 20 patients. Our model was evaluated by a patient-based 10-fold cross validation, and achieved a mean Jaccard index of 65.8% across 4 classes (stroma, Gleason 3, Gleason 4 and benign glands), and 75.5% for 3 classes (stroma, benign glands, prostate cancer), outperforming other methods.","","Deep Learning; Diagnosis, Computer-Assisted; Humans; Machine Learning; Male; Neoplasm Grading; Prostate; Prostatectomy; Prostatic Neoplasms; Risk Assessment; Semantics; Support Vector Machine; cancer grading; comparative study; computer assisted diagnosis; human; machine learning; male; pathology; prostate; prostate tumor; prostatectomy; risk assessment; semantics; support vector machine","NLM (Medline)","1942597X","","","29854182","Article","Scopus","2-s2.0-85053674575"
"Spampinato C.; Palazzo S.; Giordano D.; Aldinucci M.; Leonardi R.","Spampinato, C. (23391134800); Palazzo, S. (57223706450); Giordano, D. (7005866348); Aldinucci, M. (8844070100); Leonardi, R. (56581432200)","23391134800; 57223706450; 7005866348; 8844070100; 56581432200","Deep learning for automated skeletal bone age assessment in X-ray images","2017","Medical Image Analysis","342","10.1016/j.media.2016.10.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993995751&doi=10.1016%2fj.media.2016.10.010&partnerID=40&md5=b91171a7bcb291ad5fd257671094b417","Pattern Recognition and Computer Vision (PeRCeiVe) Lab, Department of Electrical, Electronics and Computer Engineering, University of Catania, Viale Andrea Doria, 6 - 95125 - Catania, Italy; Computer Science Department, University of Torino, Corso Svizzera, 185 - 10149 - Torino, Italy; Department of Orthodontics, University of Catania, Via Santa Sofia, 78 - 95125 - Catania, Italy","Spampinato C., Pattern Recognition and Computer Vision (PeRCeiVe) Lab, Department of Electrical, Electronics and Computer Engineering, University of Catania, Viale Andrea Doria, 6 - 95125 - Catania, Italy; Palazzo S., Pattern Recognition and Computer Vision (PeRCeiVe) Lab, Department of Electrical, Electronics and Computer Engineering, University of Catania, Viale Andrea Doria, 6 - 95125 - Catania, Italy; Giordano D., Pattern Recognition and Computer Vision (PeRCeiVe) Lab, Department of Electrical, Electronics and Computer Engineering, University of Catania, Viale Andrea Doria, 6 - 95125 - Catania, Italy; Aldinucci M., Computer Science Department, University of Torino, Corso Svizzera, 185 - 10149 - Torino, Italy; Leonardi R., Department of Orthodontics, University of Catania, Via Santa Sofia, 78 - 95125 - Catania, Italy","Skeletal bone age assessment is a common clinical practice to investigate endocrinology, genetic and growth disorders in children. It is generally performed by radiological examination of the left hand by using either the Greulich and Pyle (G&P) method or the Tanner–Whitehouse (TW) one. However, both clinical procedures show several limitations, from the examination effort of radiologists to (most importantly) significant intra- and inter-operator variability. To address these problems, several automated approaches (especially relying on the TW method) have been proposed; nevertheless, none of them has been proved able to generalize to different races, age ranges and genders. In this paper, we propose and test several deep learning approaches to assess skeletal bone age automatically; the results showed an average discrepancy between manual and automatic evaluation of about 0.8 years, which is state-of-the-art performance. Furthermore, this is the first automated skeletal bone age assessment work tested on a public dataset and for all age ranges, races and genders, for which the source code is available, thus representing an exhaustive baseline for future research in the field. Beside the specific application scenario, this paper aims at providing answers to more general questions about deep learning on medical images: from the comparison between deep-learned features and manually-crafted ones, to the usage of deep-learning methods trained on general imagery for medical problems, to how to train a CNN with few images. © 2016","Convolutional neural networks; Deep learning for medical images; Greulich and Pyle; Tanner–Whitehouse","Adolescent; Age Determination by Skeleton; Bone and Bones; Child; Child, Preschool; Female; Humans; Infant; Machine Learning; Male; Neural Networks (Computer); Radiography; Reproducibility of Results; Automation; Bone; Medical imaging; Medical problems; Musculoskeletal system; Neural networks; Racing automobiles; Application scenario; Automated approach; Automatic evaluation; Bone age assessment; Clinical practices; Convolutional neural network; Greulich and Pyle; State-of-the-art performance; age; Article; artificial neural network; automation; bone age determination; bone radiography; convolutional neural network; deep learning method; gender; imagery; machine learning; musculoskeletal system examination; priority journal; race; skeleton; adolescent; artificial neural network; bone; bone age determination; child; diagnostic imaging; female; human; infant; male; preschool child; procedures; radiography; reproducibility; Deep learning","Elsevier B.V.","13618415","","MIAEC","27816861","Article","Scopus","2-s2.0-84993995751"
"Zhao R.; Yan R.; Wang J.; Mao K.","Zhao, Rui (56717092800); Yan, Ruqiang (8222645300); Wang, Jinjiang (49964967100); Mao, Kezhi (7006403609)","56717092800; 8222645300; 49964967100; 7006403609","Learning to monitor machine health with convolutional Bi-directional LSTM networks","2017","Sensors (Switzerland)","588","10.3390/s17020273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011676262&doi=10.3390%2fs17020273&partnerID=40&md5=0a62cfe7457139d0a1f0cf728f6410dd","School of Instrument Science and Engineering, Southeast University, Nanjing, 210009, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, 639798, Singapore; School of Mechanical and Transportation Engineering, China University of Petroleum, Beijing, 102249, China","Zhao R., School of Instrument Science and Engineering, Southeast University, Nanjing, 210009, China, School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, 639798, Singapore; Yan R., School of Instrument Science and Engineering, Southeast University, Nanjing, 210009, China; Wang J., School of Mechanical and Transportation Engineering, China University of Petroleum, Beijing, 102249, China; Mao K., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, 639798, Singapore","In modern manufacturing systems and industries, more and more research efforts have been made in developing effective machine health monitoring systems. Among various machine health monitoring approaches, data-driven methods are gaining in popularity due to the development of advanced sensing and data analytic techniques. However, considering the noise, varying length and irregular sampling behind sensory data, this kind of sequential data cannot be fed into classification and regression models directly. Therefore, previous work focuses on feature extraction/fusion methods requiring expensive human labor and high quality expert knowledge. With the development of deep learning methods in the last few years, which redefine representation learning from raw data, a deep neural network structure named Convolutional Bi-directional Long Short-Term Memory networks (CBLSTM) has been designed here to address raw sensory data. CBLSTM firstly uses CNN to extract local features that are robust and informative from the sequential input. Then, bi-directional LSTM is introduced to encode temporal information. Long Short-Term Memory networks (LSTMs) are able to capture long-term dependencies and model sequential data, and the bi-directional structure enables the capture of past and future contexts. Stacked, fully-connected layers and the linear regression layer are built on top of bi-directional LSTMs to predict the target value. Here, a real-life tool wear test is introduced, and our proposed CBLSTM is able to predict the actual tool wear based on raw sensory data. The experimental results have shown that our model is able to outperform several state-of-the-art baseline methods. © 2017 by the authors; licensee MDPI, Basel, Switzerland.","Bi-directional long-short term memory network; Convolutional neural network; Machine health monitoring; Recurrent neural network; Tool wear prediction","Brain; Convolution; Deep learning; Deep neural networks; Feature extraction; Forecasting; Health; Industrial research; Manufacture; Monitoring; Neural networks; Recurrent neural networks; Regression analysis; Wear of materials; Convolutional neural network; Data-driven methods; Long-term dependencies; Machine health monitoring; Neural network structures; Short term memory; Temporal information; Tool wear; article; convolutional neural network; deep learning; feature extraction; human; linear regression analysis; long short term memory network; noise; prediction; Long short-term memory","MDPI AG","14248220","","","28146106","Article","Scopus","2-s2.0-85011676262"
"Arguello Casteleiro M.; Maseda Fernandez D.; Demetriou G.; Read W.; Fernandez Prieto M.J.; Des Diz J.; Nenadic G.; Keane J.; Stevens R.","Arguello Casteleiro, Mercedes (23466149100); Maseda Fernandez, Diego (57191663099); Demetriou, George (57112065700); Read, Warren (57189593761); Fernandez Prieto, Maria Jesus (26430676400); Des Diz, Julio (23026955100); Nenadic, Goran (6603053052); Keane, John (34975073000); Stevens, Robert (7403201511)","23466149100; 57191663099; 57112065700; 57189593761; 26430676400; 23026955100; 6603053052; 34975073000; 7403201511","A Case Study on Sepsis Using PubMed and Deep Learning for Ontology Learning","2017","Studies in Health Technology and Informatics","8","10.3233/978-1-61499-753-5-516","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018840026&doi=10.3233%2f978-1-61499-753-5-516&partnerID=40&md5=813f9e4ef59f24a7ca6bc36aa91f8175","School of Computer Science, University of Manchester, United Kingdom; Midcheshire Hospital Foundation Trust, NHS England, United Kingdom; Salford Languages, University of Salford, United Kingdom; Hospital Do Salnés de Villagarcia, SERGAS, Spain; Manchester Institute of Biotechnology, University of Manchester, United Kingdom","Arguello Casteleiro M., School of Computer Science, University of Manchester, United Kingdom; Maseda Fernandez D., Midcheshire Hospital Foundation Trust, NHS England, United Kingdom; Demetriou G., School of Computer Science, University of Manchester, United Kingdom; Read W., School of Computer Science, University of Manchester, United Kingdom; Fernandez Prieto M.J., Salford Languages, University of Salford, United Kingdom; Des Diz J., Hospital Do Salnés de Villagarcia, SERGAS, Spain; Nenadic G., School of Computer Science, University of Manchester, United Kingdom, Manchester Institute of Biotechnology, University of Manchester, United Kingdom; Keane J., School of Computer Science, University of Manchester, United Kingdom, Salford Languages, University of Salford, United Kingdom; Stevens R., School of Computer Science, University of Manchester, United Kingdom","We investigate the application of distributional semantics models for facilitating unsupervised extraction of biomedical terms from unannotated corpora. Term extraction is used as the first step of an ontology learning process that aims to (semi-)automatic annotation of biomedical concepts and relations from more than 300K PubMed titles and abstracts. We experimented with both traditional distributional semantics methods such as Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) as well as the neural language models CBOW and Skip-gram from Deep Learning. The evaluation conducted concentrates on sepsis, a major life-Threatening condition, and shows that Deep Learning models outperform LSA and LDA with much higher precision. © 2017 European Federation for Medical Informatics (EFMI) and IOS Press.","Deep Learning; Ontology Learning; OWL; PubMed; SPARQL","Humans; Information Storage and Retrieval; Machine Learning; Natural Language Processing; PubMed; Semantics; Sepsis; human; information retrieval; machine learning; Medline; natural language processing; semantics; sepsis","IOS Press","09269630","978-161499752-8","","28423846","Article","Scopus","2-s2.0-85018840026"
"Zhang Y.-Z.; Yamaguchi R.; Imoto S.; Miyano S.","Zhang, Yao-zhong (57193128713); Yamaguchi, Rui (8868542400); Imoto, Seiya (7102856656); Miyano, Satoru (7102554029)","57193128713; 8868542400; 7102856656; 7102554029","Sequence-specific bias correction for RNA-seq data using recurrent neural networks","2017","BMC Genomics","16","10.1186/s12864-016-3262-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010976159&doi=10.1186%2fs12864-016-3262-5&partnerID=40&md5=001c31e99e2af9c04342d2f183781250","The University of Tokyo, The Institute of Medical Science, Shirokanedai 4-6-1, Minato-ku, Tokyo, 108-8639, Japan","Zhang Y.-Z., The University of Tokyo, The Institute of Medical Science, Shirokanedai 4-6-1, Minato-ku, Tokyo, 108-8639, Japan; Yamaguchi R., The University of Tokyo, The Institute of Medical Science, Shirokanedai 4-6-1, Minato-ku, Tokyo, 108-8639, Japan; Imoto S., The University of Tokyo, The Institute of Medical Science, Shirokanedai 4-6-1, Minato-ku, Tokyo, 108-8639, Japan; Miyano S., The University of Tokyo, The Institute of Medical Science, Shirokanedai 4-6-1, Minato-ku, Tokyo, 108-8639, Japan","Background: The recent success of deep learning techniques in machine learning and artificial intelligence has stimulated a great deal of interest among bioinformaticians, who now wish to bring the power of deep learning to bare on a host of bioinformatical problems. Deep learning is ideally suited for biological problems that require automatic or hierarchical feature representation for biological data when prior knowledge is limited. In this work, we address the sequence-specific bias correction problem for RNA-seq data redusing Recurrent Neural Networks (RNNs) to model nucleotide sequences without pre-determining sequence structures. The sequence-specific bias of a read is then calculated based on the sequence probabilities estimated by RNNs, and used in the estimation of gene abundance. Result: We explore the application of two popular RNN recurrent units for this task and demonstrate that RNN-based approaches provide a flexible way to model nucleotide sequences without knowledge of predetermined sequence structures. Our experiments show that training a RNN-based nucleotide sequence model is efficient and RNN-based bias correction methods compare well with the-state-of-the-art sequence-specific bias correction method on the commonly used MAQC-III data set. Conclustions: RNNs provides an alternative and flexible way to calculate sequence-specific bias without explicitly pre-determining sequence structures. © 2017 The Author(s).","Gene expression analysis; Recurrent neural network; RNA-seq; Sequence-specific bias","Algorithms; Bias (Epidemiology); Computational Biology; Gene Expression Profiling; Humans; Models, Statistical; Neural Networks (Computer); Sequence Analysis, RNA; DNA structure; experimental model; nervous system; nucleotide sequence; probability; algorithm; artificial neural network; biology; gene expression profiling; human; procedures; sequence analysis; standards; statistical bias; statistical model","BioMed Central Ltd.","14712164","","BGMEE","28198674","Article","Scopus","2-s2.0-85010976159"
"Häse F.; Kreisbeck C.; Aspuru-Guzik A.","Häse, Florian (57190341036); Kreisbeck, Christoph (36183997500); Aspuru-Guzik, Alán (6507007526)","57190341036; 36183997500; 6507007526","Machine learning for quantum dynamics: Deep learning of excitation energy transfer properties","2017","Chemical Science","69","10.1039/c7sc03542j","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034847117&doi=10.1039%2fc7sc03542j&partnerID=40&md5=acb529ae6b25aa123e8783befe5f568c","Department of Chemistry and Chemical Biology, Harvard University, Cambridge, 02138, United States","Häse F., Department of Chemistry and Chemical Biology, Harvard University, Cambridge, 02138, United States; Kreisbeck C., Department of Chemistry and Chemical Biology, Harvard University, Cambridge, 02138, United States; Aspuru-Guzik A., Department of Chemistry and Chemical Biology, Harvard University, Cambridge, 02138, United States","Understanding the relationship between the structure of light-harvesting systems and their excitation energy transfer properties is of fundamental importance in many applications including the development of next generation photovoltaics. Natural light harvesting in photosynthesis shows remarkable excitation energy transfer properties, which suggests that pigment-protein complexes could serve as blueprints for the design of nature inspired devices. Mechanistic insights into energy transport dynamics can be gained by leveraging numerically involved propagation schemes such as the hierarchical equations of motion (HEOM). Solving these equations, however, is computationally costly due to the adverse scaling with the number of pigments. Therefore virtual high-throughput screening, which has become a powerful tool in material discovery, is less readily applicable for the search of novel excitonic devices. We propose the use of artificial neural networks to bypass the computational limitations of established techniques for exploring the structure-dynamics relation in excitonic systems. Once trained, our neural networks reduce computational costs by several orders of magnitudes. Our predicted transfer times and transfer efficiencies exhibit similar or even higher accuracies than frequently used approximate methods such as secular Redfield theory. © 2017 The Royal Society of Chemistry.","","Computation theory; Deep learning; Dynamics; Energy transfer; Equations of motion; Learning systems; Neural networks; Quantum theory; Approximate methods; Computational costs; Computational limitations; High throughput screening; Light-harvesting systems; Orders of magnitude; Pigment-protein complexes; Transfer efficiency; Excitation energy","Royal Society of Chemistry","20416520","","CSHCC","","Article","Scopus","2-s2.0-85034847117"
"Chen J.-H.; Zhao Z.-Q.; Shi J.-Y.; Zhao C.","Chen, Jie-Hao (57194532035); Zhao, Zi-Qian (57193561898); Shi, Ji-Yun (57192590743); Zhao, Chong (57192577205)","57194532035; 57193561898; 57192590743; 57192577205","A New Approach for Mobile Advertising Click-Through Rate Estimation Based on Deep Belief Nets","2017","Computational Intelligence and Neuroscience","13","10.1155/2017/7259762","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042176822&doi=10.1155%2f2017%2f7259762&partnerID=40&md5=83999faec11b725cfeec13177e89e5c4","School of Software, Beijing Institute of Technology, Beijing, 100081, China","Chen J.-H., School of Software, Beijing Institute of Technology, Beijing, 100081, China; Zhao Z.-Q., School of Software, Beijing Institute of Technology, Beijing, 100081, China; Shi J.-Y., School of Software, Beijing Institute of Technology, Beijing, 100081, China; Zhao C., School of Software, Beijing Institute of Technology, Beijing, 100081, China","In recent years, with the rapid development of mobile Internet and its business applications, mobile advertising Click-Through Rate (CTR) estimation has become a hot research direction in the field of computational advertising, which is used to achieve accurate advertisement delivery for the best benefits in the three-side game between media, advertisers, and audiences. Current research on the estimation of CTR mainly uses the methods and models of machine learning, such as linear model or recommendation algorithms. However, most of these methods are insufficient to extract the data features and cannot reflect the nonlinear relationship between different features. In order to solve these problems, we propose a new model based on Deep Belief Nets to predict the CTR of mobile advertising, which combines together the powerful data representation and feature extraction capability of Deep Belief Nets, with the advantage of simplicity of traditional Logistic Regression models. Based on the training dataset with the information of over 40 million mobile advertisements during a period of 10 days, our experiments show that our new model has better estimation accuracy than the classic Logistic Regression (LR) model by 5.57% and Support Vector Regression (SVR) model by 5.80%. © 2017 Jie-Hao Chen et al.","","Advertising as Topic; Algorithms; Area Under Curve; Behavior; Humans; Internet; Logistic Models; Machine Learning; Mobile Applications; Models, Statistical; Probability; Stochastic Processes; Learning systems; Marketing; Business applications; Computational advertisings; Extraction capability; Logistic regression models; Mobile advertisement; Non-linear relationships; Recommendation algorithms; Support vector regression (SVR); advertising; algorithm; area under the curve; behavior; human; Internet; machine learning; Markov chain; mobile application; probability; statistical model; Regression analysis","Hindawi Limited","16875265","","","29209363","Article","Scopus","2-s2.0-85042176822"
"Aliper A.; Jellen L.; Cortese F.; Artemov A.; Karpinsky-Semper D.; Moskalev A.; Swick A.G.; Zhavoronkov A.","Aliper, Alexander (54889030500); Jellen, Leslie (41361362800); Cortese, Franco (56295145600); Artemov, Artem (56919393200); Karpinsky-Semper, Darla (56094646800); Moskalev, Alexey (7003730453); Swick, Andrew G. (58440409100); Zhavoronkov, Alex (39862415800)","54889030500; 41361362800; 56295145600; 56919393200; 56094646800; 7003730453; 58440409100; 39862415800","Towards natural mimetics of metformin and rapamycin","2017","Aging","73","10.18632/aging.101319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035767903&doi=10.18632%2faging.101319&partnerID=40&md5=6a8f2dd7007c4a42a059176220c7d165","Insilico Medicine Inc, Research Department, Baltimore, 21218, MD, United States; Biogerontology Research Foundation, Research Department, Oxford, United Kingdom; Department of Biomedical and Molecular Science, Queen's University School of Medicine, Queen's University, Kingston, K7L 3N6, ON, Canada; Life Extension, Ft. Lauderdale, 33308, FL, United States; Laboratory of Molecular Radiobiology and Gerontology, Institute of Biology of Komi Science Center of Ural Branch of Russian Academy of Sciences, Syktyvkar, 167982, Russian Federation","Aliper A., Insilico Medicine Inc, Research Department, Baltimore, 21218, MD, United States; Jellen L., Insilico Medicine Inc, Research Department, Baltimore, 21218, MD, United States; Cortese F., Biogerontology Research Foundation, Research Department, Oxford, United Kingdom, Department of Biomedical and Molecular Science, Queen's University School of Medicine, Queen's University, Kingston, K7L 3N6, ON, Canada; Artemov A., Insilico Medicine Inc, Research Department, Baltimore, 21218, MD, United States; Karpinsky-Semper D., Life Extension, Ft. Lauderdale, 33308, FL, United States; Moskalev A., Laboratory of Molecular Radiobiology and Gerontology, Institute of Biology of Komi Science Center of Ural Branch of Russian Academy of Sciences, Syktyvkar, 167982, Russian Federation; Swick A.G., Life Extension, Ft. Lauderdale, 33308, FL, United States; Zhavoronkov A., Insilico Medicine Inc, Research Department, Baltimore, 21218, MD, United States, Biogerontology Research Foundation, Research Department, Oxford, United Kingdom","Aging is now at the forefront of major challenges faced globally, creating an immediate need for safe, widescale interventions to reduce the burden of chronic disease and extend human healthspan. Metformin and rapamycin are two FDA-approved mTOR inhibitors proposed for this purpose, exhibiting significant anti-cancer and anti-aging properties beyond their current clinical applications. However, each faces issues with approval for off-label, prophylactic use due to adverse effects. Here, we initiate an effort to identify nutraceuticals- safer, naturally-occurring compounds-that mimic the anti-aging effects of metformin and rapamycin without adverse effects. We applied several bioinformatic approaches and deep learning methods to the Library of Integrated Network-based Cellular Signatures (LINCS) dataset to map the gene- and pathway-level signatures of metformin and rapamycin and screen for matches among over 800 natural compounds. We then predicted the safety of each compound with an ensemble of deep neural network classifiers. The analysis revealed many novel candidate metformin and rapamycin mimetics, including allantoin and ginsenoside (metformin), epigallocatechin gallate and isoliquiritigenin (rapamycin), and withaferin A (both). Four relatively unexplored compounds also scored well with rapamycin. This work revealed promising candidates for future experimental validation while demonstrating the applications of powerful screening methods for this and similar endeavors. © Aliper et al.","Compound screening; Deep learning; Geroprotector; Metformin; Natural; Nutraceutical; Rapamycin","Computational Biology; Databases, Genetic; Dietary Supplements; Drug Discovery; Gene Regulatory Networks; High-Throughput Screening Assays; Humans; Machine Learning; Metformin; Molecular Mimicry; Molecular Structure; Molecular Targeted Therapy; Neural Networks (Computer); Protein Interaction Maps; Protein Kinase Inhibitors; Signal Transduction; Sirolimus; Structure-Activity Relationship; TOR Serine-Threonine Kinases; metformin; protein kinase inhibitor; rapamycin; target of rapamycin kinase; antagonists and inhibitors; artificial neural network; biology; chemical structure; chemistry; classification; dietary supplement; drug development; drug effects; gene regulatory network; genetic database; high throughput screening; human; machine learning; molecular mimicry; molecularly targeted therapy; procedures; protein protein interaction; signal transduction; structure activity relation","Impact Journals LLC","19454589","","","29165314","Article","Scopus","2-s2.0-85035767903"
"Hamet P.; Tremblay J.","Hamet, Pavel (35370402400); Tremblay, Johanne (7202646703)","35370402400; 7202646703","Artificial intelligence in medicine","2017","Metabolism: Clinical and Experimental","1106","10.1016/j.metabol.2017.01.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009988949&doi=10.1016%2fj.metabol.2017.01.011&partnerID=40&md5=3eb3be98a66c5418a6700d4b60cfcb43","Centre de recherche, Centre hospitalier de l'Université de Montréal (CRCHUM), Montréal, H2X 0A9, Québec, Canada","Hamet P., Centre de recherche, Centre hospitalier de l'Université de Montréal (CRCHUM), Montréal, H2X 0A9, Québec, Canada; Tremblay J., Centre de recherche, Centre hospitalier de l'Université de Montréal (CRCHUM), Montréal, H2X 0A9, Québec, Canada","Artificial Intelligence (AI) is a general term that implies the use of a computer to model intelligent behavior with minimal human intervention. AI is generally accepted as having started with the invention of robots. The term derives from the Czech word robota, meaning biosynthetic machines used as forced labor. In this field, Leonardo Da Vinci's lasting heritage is today's burgeoning use of robotic-assisted surgery, named after him, for complex urologic and gynecologic procedures. Da Vinci's sketchbooks of robots helped set the stage for this innovation. AI, described as the science and engineering of making intelligent machines, was officially born in 1956. The term is applicable to a broad range of items in medicine such as robotics, medical diagnosis, medical statistics, and human biology—up to and including today's “omics”. AI in medicine, which is the focus of this review, has two main branches: virtual and physical. The virtual branch includes informatics approaches from deep learning information management to control of health management systems, including electronic health records, and active guidance of physicians in their treatment decisions. The physical branch is best represented by robots used to assist the elderly patient or the attending surgeon. Also embodied in this branch are targeted nanorobots, a unique new drug delivery system. The societal and ethical complexities of these applications require further reflection, proof of their medical utility, economic value, and development of interdisciplinary strategies for their wider application. © 2017","Artificial intelligence; Avatars; Future of medicine; Robots","Artificial Intelligence; Decision Making, Computer-Assisted; Drug Delivery Systems; Electronic Health Records; History, 20th Century; History, 21st Century; Humans; Interdisciplinary Communication; Precision Medicine; Robotics; Terminology as Topic; Article; artificial intelligence; automated pattern recognition; classification algorithm; clinical effectiveness; computer prediction; electronic medical record; human; human computer interaction; learning algorithm; medical device; medicine; priority journal; reinforcement; robotics; treatment outcome; artificial intelligence; decision support system; drug delivery system; electronic health record; ethics; history; interdisciplinary communication; nomenclature; personalized medicine; trends","W.B. Saunders","00260495","","METAA","28126242","Article","Scopus","2-s2.0-85009988949"
"Yin Z.; Zhang J.","Yin, Zhong (51061764400); Zhang, Jianhua (57057829600)","51061764400; 57057829600","Cross-session classification of mental workload levels using EEG and an adaptive deep learning model","2017","Biomedical Signal Processing and Control","113","10.1016/j.bspc.2016.11.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996992978&doi=10.1016%2fj.bspc.2016.11.013&partnerID=40&md5=3060eb0185f185272ffc1bfe7315a98f","Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, 200093, China; Department of Automation, East China University of Science and Technology, Shanghai, 200237, China","Yin Z., Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, 200093, China; Zhang J., Department of Automation, East China University of Science and Technology, Shanghai, 200237, China","Evaluation of operator Mental Workload (MW) levels via ongoing electroencephalogram (EEG) is quite promising in Human-Machine (HM) collaborative task environment to alarm the temporal operator performance degradation. However, accurate recognition of MW states via a static pattern classifier with training and testing EEG signals recoded on separate days is particularly challenging as EEG features are differently distributed across different sessions. Motivated by the superiority of the deep learning approaches for stable feature abstractions in higher levels, an adaptive Stacked Denoising AutoEncoder (SDAE) is developed to tackling such cross-session MW classification task in which the weights of the shallow hidden neurons could be adaptively updated during the testing procedure. The generalization capability of the adaptive SDAE is first evaluated under within/cross-session conditions. Then, we compare it with the state of the art MW classifiers under different feature selection and the noise corruption paradigms. The results indicate a higher performance of the adaptive SDAE in dealing with the cross-session EEG features. By analyzing the optimal step length, the data augmentation scheme and the computational cost for iterative tuning, the adaptive SDAE is also demonstrated to be acceptable for online implementation. © 2016 Elsevier Ltd","Deep learning; Electroencephalogram (EEG); Human-machine system; Mental workload; Operator functional states","Electroencephalography; Learning systems; Man machine systems; Classification tasks; Electro-encephalogram (EEG); Generalization capability; Mental workload; Online implementation; Operator functional state; Session classifications; Training and testing; adaptive deep learning model; adult; alpha rhythm; Article; artificial neural network; beta rhythm; classification algorithm; correlation coefficient; electroencephalogram; gamma rhythm; human; human experiment; information processing device; machine learning; mental health; mental workload; normal human; priority journal; statistical model; supervised machine learning; task performance; theta rhythm; workload; young adult; Deep learning","Elsevier Ltd","17468094","","","","Article","Scopus","2-s2.0-84996992978"
"Liu X.; Song J.; Hong Wang S.; Zhao J.; Chen Y.","Liu, Xiang (57192258973); Song, Jialin (55500884900); Hong Wang, Shuo (57193010126); Zhao, Jingwen (57191161942); Chen, Yanqiu (55992300600)","57192258973; 55500884900; 57193010126; 57191161942; 55992300600","Learning to diagnose cirrhosis with liver capsule guided ultrasound image classification","2017","Sensors (Switzerland)","92","10.3390/s17010149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009957951&doi=10.3390%2fs17010149&partnerID=40&md5=a23ef5f28bc1cbac7d69b00bfbe01048","School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, 201203, China; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, 201620, China; Department of ultrasound, Changzheng Hospital Affiliated to Second Military Medical University, Shanghai, 200003, China","Liu X., School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, 201203, China, School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, 201620, China; Song J., Department of ultrasound, Changzheng Hospital Affiliated to Second Military Medical University, Shanghai, 200003, China; Hong Wang S., School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, 201203, China; Zhao J., School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, 201203, China; Chen Y., School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, 201203, China","This paper proposes a computer-aided cirrhosis diagnosis system to diagnose cirrhosis based on ultrasound images. We first propose a method to extract a liver capsule on an ultrasound image, then, based on the extracted liver capsule, we fine-tune a deep convolutional neural network (CNN) model to extract features from the image patches cropped around the liver capsules. Finally, a trained support vector machine (SVM) classifier is applied to classify the sample into normal or abnormal cases. Experimental results show that the proposed method can effectively extract the liver capsules and accurately classify the ultrasound images. © 2017 by the authors; licensee MDPI, Basel, Switzerland.","Cirrhosis; Computer-aided diagnosis; Convolutional neural network; Ultrasound imaging","Humans; Liver Cirrhosis; Neural Networks (Computer); Support Vector Machine; Ultrasonography; Computer aided diagnosis; Convolution; Image processing; Image retrieval; Neural networks; Support vector machines; Ultrasonic imaging; Cirrhosis; Computer aided; Convolutional neural network; Diagnosis systems; Image patches; Liver capsule; Ultrasound images; Ultrasound imaging; artificial neural network; echography; human; liver cirrhosis; support vector machine; Image classification","MDPI AG","14248220","","","28098774","Article","Scopus","2-s2.0-85009957951"
"Testolin A.; De Filippo De Grazia M.; Zorzi M.","Testolin, Alberto (55763594100); De Filippo De Grazia, Michele (55567827900); Zorzi, Marco (7102431895)","55763594100; 55567827900; 7102431895","The role of architectural and learning constraints in neural network models: A case study on visual space coding","2017","Frontiers in Computational Neuroscience","10","10.3389/fncom.2017.00013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018277008&doi=10.3389%2ffncom.2017.00013&partnerID=40&md5=922d514a34aeb1ba5c4669cde1a20ff0","Department of General Psychology and Padova Neuroscience Center, University of Padova, Padova, Italy; San Camillo Hospital IRCCS, Venice, Italy","Testolin A., Department of General Psychology and Padova Neuroscience Center, University of Padova, Padova, Italy; De Filippo De Grazia M., Department of General Psychology and Padova Neuroscience Center, University of Padova, Padova, Italy; Zorzi M., Department of General Psychology and Padova Neuroscience Center, University of Padova, Padova, Italy, San Camillo Hospital IRCCS, Venice, Italy","The recent “deep learning revolution” in artificial neural networks had strong impact and widespread deployment for engineering applications, but the use of deep learning for neurocomputational modeling has been so far limited. In this article we argue that unsupervised deep learning represents an important step forward for improving neurocomputational models of perception and cognition, because it emphasizes the role of generative learning as opposed to discriminative (supervised) learning. As a case study, we present a series of simulations investigating the emergence of neural coding of visual space for sensorimotor transformations. We compare different network architectures commonly used as building blocks for unsupervised deep learning by systematically testing the type of receptive fields and gain modulation developed by the hidden neurons. In particular, we compare Restricted Boltzmann Machines (RBMs), which are stochastic, generative networks with bidirectional connections trained using contrastive divergence, with autoencoders, which are deterministic networks trained using error backpropagation. For both learning architectures we also explore the role of sparse coding, which has been identified as a fundamental principle of neural computation. The unsupervised models are then compared with supervised, feed-forward networks that learn an explicit mapping between different spatial reference frames. Our simulations show that both architectural and learning constraints strongly influenced the emergent coding of visual space in terms of distribution of tuning functions at the level of single neurons. Unsupervised models, and particularly RBMs, were found to more closely adhere to neurophysiological data from single-cell recordings in the primate parietal cortex. These results provide new insights into how basic properties of artificial neural networks might be relevant for modeling neural information processing in biological systems. © 2017 Testolin, De Filippo De Grazia and Zorzi.","Autoencoders; Connectionist modeling; Gain modulation; Restricted Boltzmann machines; Sensorimotor transformations; Space coding; Sparseness; Unsupervised deep learning","Biological systems; Codes (symbols); Deep learning; Learning systems; Modulation; Network coding; Neural networks; Stochastic systems; Autoencoders; Connectionist models; Gain modulation; Restricted boltzmann machine; Sensorimotor transformations; Space coding; Sparseness; artificial neural network; biology; learning; machine; modulation; nerve cell; nonhuman; parietal cortex; primate; receptive field; simulation; stochastic model; Network architecture","Frontiers Research Foundation","16625188","","","","Article","Scopus","2-s2.0-85018277008"
"Kouvaris K.; Clune J.; Kounios L.; Brede M.; Watson R.A.","Kouvaris, Kostas (56997403000); Clune, Jeff (23388416900); Kounios, Loizos (56997445700); Brede, Markus (7003837493); Watson, Richard A. (57197789652)","56997403000; 23388416900; 56997445700; 7003837493; 57197789652","How evolution learns to generalise: Using the principles of learning theory to understand the evolution of developmental organisation","2017","PLoS Computational Biology","52","10.1371/journal.pcbi.1005358","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018293034&doi=10.1371%2fjournal.pcbi.1005358&partnerID=40&md5=d8556766f23f37e5fe8e61bb355ade12","ECS, University of Southampton, Southampton, United Kingdom; University of Wyoming, Laramie, WY, United States","Kouvaris K., ECS, University of Southampton, Southampton, United Kingdom; Clune J., University of Wyoming, Laramie, WY, United States; Kounios L., ECS, University of Southampton, Southampton, United Kingdom; Brede M., ECS, University of Southampton, Southampton, United Kingdom; Watson R.A., ECS, University of Southampton, Southampton, United Kingdom","One of the most intriguing questions in evolution is how organisms exhibit suitable phenotypic variation to rapidly adapt in novel selective environments. Such variability is crucial for evolvability, but poorly understood. In particular, how can natural selection favour developmental organisations that facilitate adaptive evolution in previously unseen environments? Such a capacity suggests foresight that is incompatible with the short-sighted concept of natural selection. A potential resolution is provided by the idea that evolution may discover and exploit information not only about the particular phenotypes selected in the past, but their underlying structural regularities: new phenotypes, with the same underlying regularities, but novel particulars, may then be useful in new environments. If true, we still need to understand the conditions in which natural selection will discover such deep regularities rather than exploiting ‘quick fixes’ (i.e., fixes that provide adaptive phenotypes in the short term, but limit future evolvability). Here we argue that the ability of evolution to discover such regularities is formally analogous to learning principles, familiar in humans and machines, that enable generalisation from past experience. Conversely, natural selection that fails to enhance evolvability is directly analogous to the learning problem of over-fitting and the subsequent failure to generalise. We support the conclusion that evolving systems and learning systems are different instantiations of the same algorithmic principles by showing that existing results from the learning domain can be transferred to the evolution domain. Specifically, we show that conditions that alleviate over-fitting in learning systems successfully predict which biological conditions (e.g., environmental variation, regularity, noise or a pressure for developmental simplicity) enhance evolvability. This equivalence provides access to a well-developed theoretical framework from learning theory that enables a characterisation of the general conditions for the evolution of evolvability. © 2017 Kouvaris et al.","","Biological Evolution; Computational Biology; Environment; Humans; Learning; Machine Learning; Models, Biological; Phenotype; Selection, Genetic; Biology; Adaptive evolution; Condition; Evolvability; Intriguing questions; Learn+; Learning Theory; Natural selection; Overfitting; Phenotypic variations; Structural regularity; animal experiment; animal model; Article; artificial neural network; clinical evaluation; conceptual framework; controlled study; developmental biology; environmental change; evolution; gene expression; gene regulatory network; genetic predisposition; genetic variability; genotype phenotype correlation; geological time; health care cost; health care organization; learning; magnitude estimation method; nonhuman; parsimony analysis; post hoc analysis; probability; reproductive behavior; sensitivity analysis; sequence analysis; biological model; biology; environment; genetic selection; human; learning; machine learning; phenotype; Learning systems","Public Library of Science","1553734X","","","28384156","Article","Scopus","2-s2.0-85018293034"
"Jing L.; Wang T.; Zhao M.; Wang P.","Jing, Luyang (55913195300); Wang, Taiyong (7405563562); Zhao, Ming (56402208400); Wang, Peng (57201553046)","55913195300; 7405563562; 56402208400; 57201553046","An adaptive multi-sensor data fusion method based on deep convolutional neural networks for fault diagnosis of planetary gearbox","2017","Sensors (Switzerland)","318","10.3390/s17020414","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013831942&doi=10.3390%2fs17020414&partnerID=40&md5=174cb226eaaa0aeff55a4247d44c1254","School of Mechanical Engineering, Tianjin University, Tianjin, 300354, China; School of Mechanical Engineering, Xi’an Jiaotong University, Xi’an, 710049, China","Jing L., School of Mechanical Engineering, Tianjin University, Tianjin, 300354, China; Wang T., School of Mechanical Engineering, Tianjin University, Tianjin, 300354, China; Zhao M., School of Mechanical Engineering, Xi’an Jiaotong University, Xi’an, 710049, China; Wang P., School of Mechanical Engineering, Tianjin University, Tianjin, 300354, China","A fault diagnosis approach based on multi-sensor data fusion is a promising tool to deal with complicated damage detection problems of mechanical systems. Nevertheless, this approach suffers from two challenges, which are (1) the feature extraction from various types of sensory data and (2) the selection of a suitable fusion level. It is usually difficult to choose an optimal feature or fusion level for a specific fault diagnosis task, and extensive domain expertise and human labor are also highly required during these selections. To address these two challenges, we propose an adaptive multi-sensor data fusion method based on deep convolutional neural networks (DCNN) for fault diagnosis. The proposed method can learn features from raw data and optimize a combination of different fusion levels adaptively to satisfy the requirements of any fault diagnosis task. The proposed method is tested through a planetary gearbox test rig. Handcraft features, manual-selected fusion levels, single sensory data, and two traditional intelligent models, back-propagation neural networks (BPNN) and a support vector machine (SVM), are used as comparisons in the experiment. The results demonstrate that the proposed method is able to detect the conditions of the planetary gearbox effectively with the best diagnosis accuracy among all comparative methods in the experiment. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Deep convolutional neural networks; Fault diagnosis; Feature learning; Multi-sensor data fusion; Planetary gearbox","Backpropagation; Convolution; Damage detection; Deep neural networks; Failure analysis; Feature extraction; Gears; Neural networks; Sensor data fusion; Support vector machines; Back-propagation neural networks; Comparative methods; Deep convolutional neural networks; Detection problems; Feature learning; Intelligent models; Multisensor data fusion; Planetary gearboxes; Fault detection","MDPI AG","14248220","","","28230767","Article","Scopus","2-s2.0-85013831942"
"Liang Z.; Huang J.X.; Zeng X.; Zhang G.","Liang, Zhaohui (7402177895); Huang, Jimmy Xiangji (35230036000); Zeng, Xing (36478003000); Zhang, Gang (57005637200)","7402177895; 35230036000; 36478003000; 57005637200","DL-ADR: A novel deep learning model for classifying genomic variants into adverse drug reactions","2016","BMC Medical Genomics","14","10.1186/s12920-016-0207-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981288331&doi=10.1186%2fs12920-016-0207-4&partnerID=40&md5=3d06785bb734081a4be8a797879bbda0","School of Information Technology, York University, Toronto, M3J1P3, ON, Canada; Second School of Clinic Medicine, Guangzhou University of Chinese Medicine, Guangzhou, 510120, China; School of Automation, Guangdong University of Technology, Guangzhou, 510006, China","Liang Z., School of Information Technology, York University, Toronto, M3J1P3, ON, Canada; Huang J.X., School of Information Technology, York University, Toronto, M3J1P3, ON, Canada; Zeng X., Second School of Clinic Medicine, Guangzhou University of Chinese Medicine, Guangzhou, 510120, China; Zhang G., School of Automation, Guangdong University of Technology, Guangzhou, 510006, China","Background: Genomic variations are associated with the metabolism and the occurrence of adverse reactions of many therapeutic agents. The polymorphisms on over 2000 locations of cytochrome P450 enzymes (CYP) due to many factors such as ethnicity, mutations, and inheritance attribute to the diversity of response and side effects of various drugs. The associations of the single nucleotide polymorphisms (SNPs), the internal pharmacokinetic patterns and the vulnerability of specific adverse reactions become one of the research interests of pharmacogenomics. The conventional genomewide association studies (GWAS) mainly focuses on the relation of single or multiple SNPs to a specific risk factors which are a one-to-many relation. However, there are no robust methods to establish a many-to-many network which can combine the direct and indirect associations between multiple SNPs and a serial of events (e.g. adverse reactions, metabolic patterns, prognostic factors etc.). In this paper, we present a novel deep learning model based on generative stochastic networks and hidden Markov chain to classify the observed samples with SNPs on five loci of two genes (CYP2D6 and CYP1A2) respectively to the vulnerable population of 14 types of adverse reactions. Methods: A supervised deep learning model is proposed in this study. The revised generative stochastic networks (GSN) model with transited by the hidden Markov chain is used. The data of the training set are collected from clinical observation. The training set is composed of 83 observations of blood samples with the genotypes respectively on CYP2D62,10,14 and CYP1A21C,1 F. The samples are genotyped by the polymerase chain reaction (PCR) method. A hidden Markov chain is used as the transition operator to simulate the probabilistic distribution. The model can perform learning at lower cost compared to the conventional maximal likelihood method because the transition distribution is conditional on the previous state of the hidden Markov chain. A least square loss (LASSO) algorithm and a k-Nearest Neighbors (kNN) algorithm are used as the baselines for comparison and to evaluate the performance of our proposed deep learning model. Results: There are 53 adverse reactions reported during the observation. They are assigned to 14 categories. In the comparison of classification accuracy, the deep learning model shows superiority over the LASSO and kNN model with a rate over 80 %. In the comparison of reliability, the deep learning model shows the best stability among the three models. Conclusions: Machine learning provides a new method to explore the complex associations among genomic variations and multiple events in pharmacogenomics studies. The new deep learning algorithm is capable of classifying various SNPs to the corresponding adverse reactions. We expect that as more genomic variations are added as features and more observations are made, the deep learning model can improve its performance and can act as a black-box but reliable verifier for other GWAS studies. © 2016 The Author(s).","Adverse drug reaction; Deep learning; Genomewide association study; Pharmacogenomics; Single nucleotide polymorphisms","Algorithms; Drug-Related Side Effects and Adverse Reactions; Humans; Machine Learning; Models, Biological; Polymorphism, Single Nucleotide; Stochastic Processes; cytochrome P450 1A2; cytochrome P450 2D6; accuracy; adverse drug reaction; Article; artificial neural network; blood sampling; classification; comparative study; controlled study; CYP1A2 gene; CYP2D6 gene; deep learning model; drug metabolism; gene locus; gene sequence; genome-wide association study; genotype; hidden Markov model; human; machine learning; pharmacogenomics; polymerase chain reaction; prediction; priority journal; probability; reliability; single nucleotide polymorphism; stochastic model; algorithm; biological model; genetics; machine learning; Markov chain","BioMed Central Ltd.","17558794","","","27510822","Article","Scopus","2-s2.0-84981288331"
"Luo Y.; Uzuner Ö.; Szolovits P.","Luo, Yuan (55712619800); Uzuner, Özlem (6507268190); Szolovits, Peter (6701398669)","55712619800; 6507268190; 6701398669","Bridging semantics and syntax with graph algorithms-state-of-the-art of extracting biomedical relations","2017","Briefings in Bioinformatics","63","10.1093/bib/bbw001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015951163&doi=10.1093%2fbib%2fbbw001&partnerID=40&md5=dd9787cde70b135edee39fcc1baefb30","Northwestern University, Department of Preventive Medicine, United States; State University of New York at Albany, Department of Information Studies, United States; Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, United States","Luo Y., Northwestern University, Department of Preventive Medicine, United States; Uzuner Ö., State University of New York at Albany, Department of Information Studies, United States; Szolovits P., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, United States","Research on extracting biomedical relations has received growing attention recently, with numerous biological and clinical applications including those in pharmacogenomics, clinical trial screening and adverse drug reaction detection. The ability to accurately capture both semantic and syntactic structures in text expressing these relations becomes increasingly critical to enable deep understanding of scientific papers and clinical narratives. Shared task challenges have been organized by both bioinformatics and clinical informatics communities to assess and advance the state-of-the-art research. Significant progress has been made in algorithm development and resource construction. In particular, graph-based approaches bridge semantics and syntax, often achieving the best performance in shared tasks. However, a number of problems at the frontiers of biomedical relation extraction continue to pose interesting challenges and present opportunities for great improvement and fruitful research. In this article, we place biomedical relation extraction against the backdrop of its versatile applications, present a gentle introduction to its general pipeline and shared resources, review the current state-of-the-art in methodology advancement, discuss limitations and point out several promising future directions. © The Author 2016.","Biomedical relation extraction; Clinical narratives; Graph mining; Machine learning; Natural language processing; Scientific literature","Algorithms; Computational Biology; Data Mining; Humans; Semantics; algorithm; biology; data mining; human; semantics","Oxford University Press","14675463","","","26851224","Article","Scopus","2-s2.0-85015951163"
"Müller A.T.; Kaymaz A.C.; Gabernet G.; Posselt G.; Wessler S.; Hiss J.A.; Schneider G.","Müller, Alex T. (57164240800); Kaymaz, Aral C. (57191859471); Gabernet, Gisela (55053581000); Posselt, Gernot (14045830100); Wessler, Silja (7102329587); Hiss, Jan A. (16177469500); Schneider, Gisbert (7402466014)","57164240800; 57191859471; 55053581000; 14045830100; 7102329587; 16177469500; 7402466014","Sparse Neural Network Models of Antimicrobial Peptide-Activity Relationships","2016","Molecular Informatics","14","10.1002/minf.201600029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994338597&doi=10.1002%2fminf.201600029&partnerID=40&md5=94bdf7fe424869bac54196ccd5fda56b","Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Department of Molecular Biology, Division of Microbiology, Paris Lodron, University of Salzburg, Billrothstr. 11, Salzburg, A-5020, Austria","Müller A.T., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Kaymaz A.C., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Gabernet G., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Posselt G., Department of Molecular Biology, Division of Microbiology, Paris Lodron, University of Salzburg, Billrothstr. 11, Salzburg, A-5020, Austria; Wessler S., Department of Molecular Biology, Division of Microbiology, Paris Lodron, University of Salzburg, Billrothstr. 11, Salzburg, A-5020, Austria; Hiss J.A., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Schneider G., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland","We present an adaptive neural network model for chemical data classification. The method uses an evolutionary algorithm for optimizing the network structure by seeking sparsely connected architectures. The number of hidden layers, the number of neurons in each layer and their connectivity are free variables of the system. We used the method for predicting antimicrobial peptide activity from the amino acid sequence. Visualization of the evolved sparse network structures suggested a high charge density and a low aggregation potential in solution as beneficial for antimicrobial activity. However, different training data sets and peptide representations resulted in greatly varying network structures. Overall, the sparse network models turned out to be less accurate than fully-connected networks. In a prospective application, we synthesized and tested 10 de novo generated peptides that were predicted to either possess antimicrobial activity, or to be inactive. Two of the predicted antibacterial peptides showed cosiderable bacteriostatic effects against both Staphylococcus aureus and Escherichia coli. None of the predicted inactive peptides possessed antibacterial properties. Molecular dynamics simulations of selected peptide structures in water and TFE suggest a pronounced peptide helicity in a hydrophobic environment. The results of this study underscore the applicability of neural networks for guiding the computer-assisted design of new peptides with desired properties. © 2016 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","antibiotic; deep learning; evolutionary algorithm; machine learning; molecular dynamics simulation; structure-activity relationship","Amino Acid Sequence; Anti-Bacterial Agents; Antimicrobial Cationic Peptides; Computer-Aided Design; Escherichia coli; Hydrophobic and Hydrophilic Interactions; Microbial Sensitivity Tests; Molecular Dynamics Simulation; Neural Networks (Computer); Prospective Studies; Staphylococcus aureus; Structure-Activity Relationship; Bioinformatics; Computer aided design; Deep learning; Escherichia coli; Evolutionary algorithms; Peptides; amino acid; polypeptide antibiotic agent; antiinfective agent; antimicrobial cationic peptide; Anti-microbial activity; Antimicrobial peptide; Deep learning; Dynamics simulation; Machine-learning; Molecular dynamic simulation; Network structures; Sparse network; Sparse neural networks; Structure-activity relationships; amino acid sequence; antibacterial activity; antimicrobial activity; Article; artificial neural network; bacterial strain; bacteriostasis; computer aided design; connectivity density; connectome; controlled study; cytoarchitecture; Escherichia coli; evolutionary algorithm; hydrophobicity; minimum inhibitory concentration; molecular dynamics; nerve cell; nonhuman; peptide synthesis; priority journal; protein aggregation; protein structure; Staphylococcus aureus; structure activity relation; artificial neural network; chemical phenomena; chemistry; drug effects; microbial sensitivity test; procedures; prospective study; structure activity relation; Molecular dynamics","Wiley-VCH Verlag","18681743","","MIONB","27870247","Article","Scopus","2-s2.0-84994338597"
"Jadoon M.M.; Zhang Q.; Haq I.U.; Butt S.; Jadoon A.","Jadoon, M. Mohsin (57224184170); Zhang, Qianni (55171939100); Haq, Ihsan Ul (55798781700); Butt, Sharjeel (56581478300); Jadoon, Adeel (57193206052)","57224184170; 55171939100; 55798781700; 56581478300; 57193206052","Three-Class Mammogram Classification Based on Descriptive CNN Features","2017","BioMed Research International","120","10.1155/2017/3640901","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011715805&doi=10.1155%2f2017%2f3640901&partnerID=40&md5=9fb821722643e98eb0545d0f346a9dd7","Queen Mary University of London, London, United Kingdom; Faculty of Engineering and Technology, International Islamic University Islamabad, Islamabad, Pakistan","Jadoon M.M., Queen Mary University of London, London, United Kingdom, Faculty of Engineering and Technology, International Islamic University Islamabad, Islamabad, Pakistan; Zhang Q., Queen Mary University of London, London, United Kingdom; Haq I.U., Faculty of Engineering and Technology, International Islamic University Islamabad, Islamabad, Pakistan; Butt S., Faculty of Engineering and Technology, International Islamic University Islamabad, Islamabad, Pakistan; Jadoon A., Faculty of Engineering and Technology, International Islamic University Islamabad, Islamabad, Pakistan","In this paper, a novel classification technique for large data set of mammograms using a deep learning method is proposed. The proposed model targets a three-class classification study (normal, malignant, and benign cases). In our model we have presented two methods, namely, convolutional neural network-discrete wavelet (CNN-DW) and convolutional neural network-curvelet transform (CNN-CT). An augmented data set is generated by using mammogram patches. To enhance the contrast of mammogram images, the data set is filtered by contrast limited adaptive histogram equalization (CLAHE). In the CNN-DW method, enhanced mammogram images are decomposed as its four subbands by means of two-dimensional discrete wavelet transform (2D-DWT), while in the second method discrete curvelet transform (DCT) is used. In both methods, dense scale invariant feature (DSIFT) for all subbands is extracted. Input data matrix containing these subband features of all the mammogram patches is created that is processed as input to convolutional neural network (CNN). Softmax layer and support vector machine (SVM) layer are used to train CNN for classification. Proposed methods have been compared with existing methods in terms of accuracy rate, error rate, and various validation assessment measures. CNN-DW and CNN-CT have achieved accuracy rate of 81.83% and 83.74%, respectively. Simulation results clearly validate the significance and impact of our proposed model as compared to other well-known existing techniques. © 2017 M. Mohsin Jadoon et al.","","Computer Simulation; Databases as Topic; Humans; Image Processing, Computer-Assisted; Mammography; Neural Networks (Computer); Reproducibility of Results; Support Vector Machine; Wavelet Analysis; decomposition; histogram; learning; mammography; nervous system; simulation; support vector machine; tumor model; validation process; artificial neural network; computer simulation; data base; human; image processing; mammography; procedures; reproducibility; support vector machine; wavelet analysis","Hindawi Publishing Corporation","23146133","","","28191461","Article","Scopus","2-s2.0-85011715805"
"Prentašić P.; Lončarić S.","Prentašić, Pavle (36462647000); Lončarić, Sven (57210666401)","36462647000; 57210666401","Detection of exudates in fundus photographs using deep neural networks and anatomical landmark detection fusion","2016","Computer Methods and Programs in Biomedicine","130","10.1016/j.cmpb.2016.09.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991705069&doi=10.1016%2fj.cmpb.2016.09.018&partnerID=40&md5=e897e2ccd2bd8ef10d5dc1194dc61ad8","Faculty of Electrical Engineering and Computing, University of Zagreb, Unska 3, Zagreb, 10000, Croatia","Prentašić P., Faculty of Electrical Engineering and Computing, University of Zagreb, Unska 3, Zagreb, 10000, Croatia; Lončarić S., Faculty of Electrical Engineering and Computing, University of Zagreb, Unska 3, Zagreb, 10000, Croatia","Background and objective Diabetic retinopathy is one of the leading disabling chronic diseases and one of the leading causes of preventable blindness in developed world. Early diagnosis of diabetic retinopathy enables timely treatment and in order to achieve it a major effort will have to be invested into automated population screening programs. Detection of exudates in color fundus photographs is very important for early diagnosis of diabetic retinopathy. Methods We use deep convolutional neural networks for exudate detection. In order to incorporate high level anatomical knowledge about potential exudate locations, output of the convolutional neural network is combined with the output of the optic disc detection and vessel detection procedures. Results In the validation step using a manually segmented image database we obtain a maximum F1 measure of 0.78. Conclusions As manually segmenting and counting exudate areas is a tedious task, having a reliable automated output, such as automated segmentation using convolutional neural networks in combination with other landmark detectors, is an important step in creating automated screening programs for early detection of diabetic retinopathy. © 2016 Elsevier Ireland Ltd","Convolutional neural networks; Diabetic retinopathy; Exudates; Fundus photographs; Machine learning","Algorithms; Diabetic Retinopathy; Exudates and Transudates; Fundus Oculi; Humans; Neural Networks (Computer); Artificial intelligence; Automation; Convolution; Diagnosis; Learning systems; Neural networks; Photography; Program diagnostics; Automated segmentation; Color fundus photograph; Convolutional neural network; Deep neural networks; Diabetic retinopathy; Exudates; Fundus photographs; Optic disc detections; algorithm; analytic method; anatomic landmark; Article; brightness; convolutional neural network; diabetic retinopathy; digital filtering; entropy; eye fundus; eye photography; image analysis; image processing; nerve cell network; optic disk; optic nerve; predictive value; priority journal; probability; process optimization; retina exudate; sensitivity analysis; artificial neural network; exudate; human; Eye protection","Elsevier Ireland Ltd","01692607","","CMPBE","28110732","Article","Scopus","2-s2.0-84991705069"
"van der Burgh H.K.; Schmidt R.; Westeneng H.-J.; de Reus M.A.; van den Berg L.H.; van den Heuvel M.P.","van der Burgh, Hannelore K. (57192702037); Schmidt, Ruben (56055019200); Westeneng, Henk-Jan (45661987000); de Reus, Marcel A. (55578002700); van den Berg, Leonard H. (56843401500); van den Heuvel, Martijn P. (24333539900)","57192702037; 56055019200; 45661987000; 55578002700; 56843401500; 24333539900","Deep learning predictions of survival based on MRI in amyotrophic lateral sclerosis","2017","NeuroImage: Clinical","125","10.1016/j.nicl.2016.10.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007413319&doi=10.1016%2fj.nicl.2016.10.008&partnerID=40&md5=5beddb536c5a434bfbc4bf8889b75b45","Department of Neurology, Brain Center Rudolf Magnus, University Medical Center Utrecht, Heidelberglaan 100, PO Box 85500, Utrecht, 3508, Netherlands; Department of Psychiatry, Brain Center Rudolf Magnus, University Medical Center Utrecht, Heidelberglaan 100, PO Box 85500, Utrecht, 3508, Netherlands","van der Burgh H.K., Department of Neurology, Brain Center Rudolf Magnus, University Medical Center Utrecht, Heidelberglaan 100, PO Box 85500, Utrecht, 3508, Netherlands; Schmidt R., Department of Neurology, Brain Center Rudolf Magnus, University Medical Center Utrecht, Heidelberglaan 100, PO Box 85500, Utrecht, 3508, Netherlands; Westeneng H.-J., Department of Neurology, Brain Center Rudolf Magnus, University Medical Center Utrecht, Heidelberglaan 100, PO Box 85500, Utrecht, 3508, Netherlands; de Reus M.A., Department of Psychiatry, Brain Center Rudolf Magnus, University Medical Center Utrecht, Heidelberglaan 100, PO Box 85500, Utrecht, 3508, Netherlands; van den Berg L.H., Department of Neurology, Brain Center Rudolf Magnus, University Medical Center Utrecht, Heidelberglaan 100, PO Box 85500, Utrecht, 3508, Netherlands; van den Heuvel M.P., Department of Psychiatry, Brain Center Rudolf Magnus, University Medical Center Utrecht, Heidelberglaan 100, PO Box 85500, Utrecht, 3508, Netherlands","Amyotrophic lateral sclerosis (ALS) is a progressive neuromuscular disease, with large variation in survival between patients. Currently, it remains rather difficult to predict survival based on clinical parameters alone. Here, we set out to use clinical characteristics in combination with MRI data to predict survival of ALS patients using deep learning, a machine learning technique highly effective in a broad range of big-data analyses. A group of 135 ALS patients was included from whom high-resolution diffusion-weighted and T1-weighted images were acquired at the first visit to the outpatient clinic. Next, each of the patients was monitored carefully and survival time to death was recorded. Patients were labeled as short, medium or long survivors, based on their recorded time to death as measured from the time of disease onset. In the deep learning procedure, the total group of 135 patients was split into a training set for deep learning (n = 83 patients), a validation set (n = 20) and an independent evaluation set (n = 32) to evaluate the performance of the obtained deep learning networks. Deep learning based on clinical characteristics predicted survival category correctly in 68.8% of the cases. Deep learning based on MRI predicted 62.5% correctly using structural connectivity and 62.5% using brain morphology data. Notably, when we combined the three sources of information, deep learning prediction accuracy increased to 84.4%. Taken together, our findings show the added value of MRI with respect to predicting survival in ALS, demonstrating the advantage of deep learning in disease prognostication. © 2016 The Authors","Amyotrophic lateral sclerosis; Deep learning; Neural network; Prediction; Survival; White matter connectivity","Adult; Aged; Aged, 80 and over; Amyotrophic Lateral Sclerosis; Female; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Middle Aged; Neural Networks (Computer); Prognosis; TAR DNA binding protein; accuracy; adult; aged; amyotrophic lateral sclerosis; Article; connectome; cortical thickness (brain); deep learning; diffusion tensor imaging; disease duration; female; functional connectivity; human; image processing; machine learning; major clinical study; male; neuroimaging; nuclear magnetic resonance imaging; onset age; priority journal; prognosis; survival prediction; white matter; amyotrophic lateral sclerosis; artificial neural network; classification; diagnostic imaging; middle aged; mortality; nuclear magnetic resonance imaging; procedures; very elderly","Elsevier Inc.","22131582","","","28070484","Article","Scopus","2-s2.0-85007413319"
"Li L.; Wang Z.; He P.; Ma S.; Du J.; Jiang R.","Li, Lianshuo (56937316400); Wang, Zicheng (56711508100); He, Peng (55507365900); Ma, Shining (56625413700); Du, Jie (7402575262); Jiang, Rui (57200775668)","56937316400; 56711508100; 55507365900; 56625413700; 7402575262; 57200775668","Construction and Analysis of Functional Networks in the Gut Microbiome of Type 2 Diabetes Patients","2016","Genomics, Proteomics and Bioinformatics","15","10.1016/j.gpb.2016.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994501800&doi=10.1016%2fj.gpb.2016.02.005&partnerID=40&md5=dfb223ce1f3c093e571e6a19b672dbbc","MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST/Department of Automation, Tsinghua University, Beijing, 100084, China; Beijing Anzhen Hospital, Capital Medical University, Beijing Institute of Heart, Lung, and Blood Vessel Diseases, Beijing, 100029, China","Li L., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST/Department of Automation, Tsinghua University, Beijing, 100084, China; Wang Z., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST/Department of Automation, Tsinghua University, Beijing, 100084, China; He P., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST/Department of Automation, Tsinghua University, Beijing, 100084, China; Ma S., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST/Department of Automation, Tsinghua University, Beijing, 100084, China; Du J., Beijing Anzhen Hospital, Capital Medical University, Beijing Institute of Heart, Lung, and Blood Vessel Diseases, Beijing, 100029, China; Jiang R., MOE Key Laboratory of Bioinformatics and Bioinformatics Division, TNLIST/Department of Automation, Tsinghua University, Beijing, 100084, China","Although networks of microbial species have been widely used in the analysis of 16S rRNA sequencing data of a microbiome, the construction and analysis of a complete microbial gene network are in general problematic because of the large number of microbial genes in metagenomics studies. To overcome this limitation, we propose to map microbial genes to functional units, including KEGG orthologous groups and the evolutionary genealogy of genes: Non-supervised Orthologous Groups (eggNOG) orthologous groups, to enable the construction and analysis of a microbial functional network. We devised two statistical methods to infer pairwise relationships between microbial functional units based on a deep sequencing dataset of gut microbiome from type 2 diabetes (T2D) patients as well as healthy controls. Networks containing such functional units and their significant interactions were constructed subsequently. We conducted a variety of analyses of global properties, local properties, and functional modules in the resulting functional networks. Our data indicate that besides the observations consistent with the current knowledge, this study provides novel biological insights into the gut microbiome associated with T2D. © 2016","Functional network; Metagenomics; Microbiome; Network motif; Type 2 diabetes","Diabetes Mellitus, Type 2; Gastrointestinal Microbiome; Gene Expression Regulation, Bacterial; Gene Regulatory Networks; Host-Pathogen Interactions; Humans; Metagenomics; Microbiota; RNA, Ribosomal, 16S; RNA 16S; Article; controlled study; diabetic patient; gene regulatory network; human; intestine flora; machine learning; major clinical study; metagenomics; microbial gene; non insulin dependent diabetes mellitus; gene expression regulation; genetics; host pathogen interaction; immunology; intestine flora; metagenomics; microbiology; microflora; non insulin dependent diabetes mellitus; pathology; procedures","Beijing Genomics Institute","16720229","","","27746285","Article","Scopus","2-s2.0-84994501800"
"Pereira F.; Bueno A.; Rodriguez A.; Perrin D.; Marx G.; Cardinale M.; Salgo I.; Nidob P.D.","Pereira, Franklin (57193383612); Bueno, Alejandra (57210102199); Rodriguez, Andrea (57193391145); Perrin, Douglas (7103279676); Marx, Gerald (7202455039); Cardinale, Michael (37033611700); Salgo, Ivan (6602261598); Nidob, Pedro Del (57193385654)","57193383612; 57210102199; 57193391145; 7103279676; 7202455039; 37033611700; 6602261598; 57193385654","Automated detection of coarctation of aorta in neonates from two-dimensional echocardiograms","2017","Journal of Medical Imaging","24","10.1117/1.JMI.4.1.014502","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013434441&doi=10.1117%2f1.JMI.4.1.014502&partnerID=40&md5=c0f86094d8a779bf4c4d0eed4b0906a3","Philips Ultrasound Inc., 3000 Minuteman Road, Andover, 02176, Massachusetts, United States; Boston Children's Hospital, Department of Cardiovascular Surgery, 300 Longwood Avenue, Boston, 02115, Massachusetts, United States","Pereira F., Philips Ultrasound Inc., 3000 Minuteman Road, Andover, 02176, Massachusetts, United States; Bueno A., Boston Children's Hospital, Department of Cardiovascular Surgery, 300 Longwood Avenue, Boston, 02115, Massachusetts, United States; Rodriguez A., Boston Children's Hospital, Department of Cardiovascular Surgery, 300 Longwood Avenue, Boston, 02115, Massachusetts, United States; Perrin D., Boston Children's Hospital, Department of Cardiovascular Surgery, 300 Longwood Avenue, Boston, 02115, Massachusetts, United States; Marx G., Boston Children's Hospital, Department of Cardiovascular Surgery, 300 Longwood Avenue, Boston, 02115, Massachusetts, United States; Cardinale M., Philips Ultrasound Inc., 3000 Minuteman Road, Andover, 02176, Massachusetts, United States; Salgo I., Philips Ultrasound Inc., 3000 Minuteman Road, Andover, 02176, Massachusetts, United States; Nidob P.D., Boston Children's Hospital, Department of Cardiovascular Surgery, 300 Longwood Avenue, Boston, 02115, Massachusetts, United States","Coarctation of aorta (CoA) is a critical congenital heart defect (CCHD) that requires accurate and immediate diagnosis and treatment. Current newborn screening methods to detect CoA lack both in sensitivity and specificity, and when suspected in a newborn, it must be confirmed using specialized imaging and expert diagnosis, both of which are usually unavailable at tertiary birthing centers. We explore the feasibility of applying machine learning methods to reliably determine the presence of this difficult-to-diagnose cardiac abnormality from ultrasound image data. We propose a framework that uses deep learning-based machine learning methods for fully automated detection of CoA from two-dimensional ultrasound clinical data acquired in the parasternal long axis view, the apical four chamber view, and the suprasternal notch view. On a validation set consisting of 26 CoA and 64 normal patients our algorithm achieved a total error rate of 12.9% (11.5% false-negative error and 13.6% false-positive error) when combining decisions of classifiers over three standard echocardiographic view planes. This compares favorably with published results that combine clinical assessments with pulse oximetry to detect CoA (71% sensitivity). © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","2-D ultrasound; coarctation of aorta; critical congenital heart disease; deep learning; feature extraction; neural networks","algorithm; aorta coarctation; Article; automation; classification; clinical assessment; false negative result; false positive result; feasibility study; heart cycle; human; image processing; machine learning; pulse oximetry; two dimensional echocardiography","SPIE","23294302","","","","Article","Scopus","2-s2.0-85013434441"
"Ebrahimi M.; Suen C.Y.; Ormandjieva O.","Ebrahimi, Mohammadreza (56208183900); Suen, Ching Y. (7102317250); Ormandjieva, Olga (57203257339)","56208183900; 7102317250; 57203257339","Detecting predatory conversations in social media by deep Convolutional Neural Networks","2016","Digital Investigation","57","10.1016/j.diin.2016.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978315688&doi=10.1016%2fj.diin.2016.07.001&partnerID=40&md5=5e259da612f623f8fad4aae8a8a82203","Centre of Pattern Recognition and Machine Intelligence, Concordia University, EV 11.155, 1455 de Maisonneuve West, Montreal, H3G 1M8, Quebec, Canada; Department of Computer Science & Software Engineering, Concordia University, Canada","Ebrahimi M., Centre of Pattern Recognition and Machine Intelligence, Concordia University, EV 11.155, 1455 de Maisonneuve West, Montreal, H3G 1M8, Quebec, Canada; Suen C.Y., Department of Computer Science & Software Engineering, Concordia University, Canada; Ormandjieva O., Department of Computer Science & Software Engineering, Concordia University, Canada","Automatic identification of predatory conversations in chat logs helps the law enforcement agencies act proactively through early detection of predatory acts in cyberspace. In this paper, we describe the novel application of a deep learning method to the automatic identification of predatory chat conversations in large volumes of chat logs. We present a classifier based on Convolutional Neural Network (CNN) to address this problem domain. The proposed CNN architecture outperforms other classification techniques that are common in this domain including Support Vector Machine (SVM) and regular Neural Network (NN) in terms of classification performance, which is measured by F1-score. In addition, our experiments show that using existing pre-trained word vectors are not suitable for this specific domain. Furthermore, since the learning algorithm runs in a massively parallel environment (i.e., general-purpose GPU), the approach can benefit a large number of computation units (neurons) compared to when CPU is used. To the best of our knowledge, this is the first time that CNNs are adapted and applied to this application domain. © 2016 Elsevier Ltd","Convolutional neural network; Deep learning; Language model; Online predator identification; Predatory conversation; Support vector machine; Word embedding","Automation; Convolution; Learning algorithms; Neural networks; Program processors; Social networking (online); Convolutional neural network; Deep learning; Language model; Predatory conversation; Word embedding; Support vector machines","Elsevier Ltd","17422876","","","","Article","Scopus","2-s2.0-84978315688"
"Gulshan V.; Peng L.; Coram M.; Stumpe M.C.; Wu D.; Narayanaswamy A.; Venugopalan S.; Widner K.; Madams T.; Cuadros J.; Kim R.; Raman R.; Nelson P.C.; Mega J.L.; Webster D.R.","Gulshan, Varun (36099993200); Peng, Lily (57192709975); Coram, Marc (14065755100); Stumpe, Martin C. (55754596300); Wu, Derek (57192712467); Narayanaswamy, Arunachalam (24559185300); Venugopalan, Subhashini (56435854800); Widner, Kasumi (57192718343); Madams, Tom (57192710439); Cuadros, Jorge (8425006900); Kim, Ramasamy (57194516901); Raman, Rajiv (10044575200); Nelson, Philip C. (57192712992); Mega, Jessica L. (35452654900); Webster, Dale R. (57192707673)","36099993200; 57192709975; 14065755100; 55754596300; 57192712467; 24559185300; 56435854800; 57192718343; 57192710439; 8425006900; 57194516901; 10044575200; 57192712992; 35452654900; 57192707673","Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs","2016","JAMA - Journal of the American Medical Association","4544","10.1001/jama.2016.17216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007529863&doi=10.1001%2fjama.2016.17216&partnerID=40&md5=e572ed64f0165945d0ce97beb29285eb","Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Department of Computer Science, University of Texas, Austin, United States; EyePACS LLC, San Jose, CA, United States; School of Optometry, Vision Science Graduate Group, University of California, Berkeley, United States; Aravind Medical Research Foundation, Aravind Eye Care System, Madurai, India; Shri Bhagwan Mahavir Vitreoretinal Services, Sankara Nethralaya, Chennai, Tamil Nadu, India; Verily Life Sciences, Mountain View, CA, United States; Cardiovascular Division, Department of Medicine, Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States","Gulshan V., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Peng L., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Coram M., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Stumpe M.C., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Wu D., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Narayanaswamy A., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Venugopalan S., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States, Department of Computer Science, University of Texas, Austin, United States; Widner K., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Madams T., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Cuadros J., EyePACS LLC, San Jose, CA, United States, School of Optometry, Vision Science Graduate Group, University of California, Berkeley, United States; Kim R., Aravind Medical Research Foundation, Aravind Eye Care System, Madurai, India; Raman R., Shri Bhagwan Mahavir Vitreoretinal Services, Sankara Nethralaya, Chennai, Tamil Nadu, India; Nelson P.C., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States; Mega J.L., Verily Life Sciences, Mountain View, CA, United States, Cardiovascular Division, Department of Medicine, Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States; Webster D.R., Google Research Inc, 1600 Amphitheatre Way, Mountain View, 94043, CA, United States","IMPORTANCE Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation. OBJECTIVE To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs. DESIGN AND SETTING A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015. The resultant algorithm was validated in January and February 2016 using 2 separate data sets, both graded by at least 7 US board-certified ophthalmologists with high intragrader consistency. EXPOSURE Deep learning-trained algorithm. MAIN OUTCOMES AND MEASURES The sensitivity and specificity of the algorithm for detecting referable diabetic retinopathy (RDR), defined as moderate and worse diabetic retinopathy, referable diabetic macular edema, or both, were generated based on the reference standard of the majority decision of the ophthalmologist panel. The algorithm was evaluated at 2 operating points selected from the development set, one selected for high specificity and another for high sensitivity. RESULTS The EyePACS-1 data set consisted of 9963 images from 4997 patients (mean age, 54.4 years; 62.2%women; prevalence ofRDR, 683/8878 fully gradable images [7.8%]); the Messidor-2 data set had 1748 images from 874 patients (mean age, 57.6 years; 42.6%women; prevalence ofRDR, 254/1745 fully gradable images [14.6%]). For detectingRDR, the algorithm had an area under the receiver operating curve of0.991 (95%CI,0.988-0.993) for EyePACS-1 and 0.990(95%CI,0.986-0.995) forMessidor-2. Using the first operating cut point with high specificity, for EyePACS-1, the sensitivitywas90.3%(95%CI, 87.5%-92.7%) and the specificity was 98.1%(95%CI, 97.8%-98.5%). ForMessidor-2, the sensitivitywas 87.0%(95%CI, 81.1%-91.0%)and the specificitywas 98.5%(95%CI, 97.7%-99.1%). Using a second operating point with high sensitivity in the development set, for EyePACS-1 the sensitivitywas 97.5%and specificitywas 93.4%and forMessidor-2 the sensitivitywas 96.1%and specificitywas 93.9%. CONCLUSIONS AND RELEVANCE In this evaluation of retinal fundus photographs from adults with diabetes, an algorithm based on deep machine learning had high sensitivity and specificity for detecting referable diabetic retinopathy. Further research is necessary to determine the feasibility of applying this algorithm in the clinical setting and to determine whether use of the algorithm could lead to improved care and outcomes compared with current ophthalmologic assessment.","","Algorithms; Diabetic Retinopathy; Female; Fundus Oculi; Humans; Machine Learning; Macular Edema; Male; Middle Aged; Neural Networks (Computer); Observer Variation; Ophthalmologists; Photography; Sensitivity and Specificity; adult; Article; artificial neural network; controlled study; diabetic macular edema; diabetic retinopathy; disease severity; female; health care quality; human; image analysis; image processing; image quality; learning algorithm; major clinical study; male; ophthalmologist; ophthalmoscopy; outcome assessment; priority journal; resident; retrospective study; sensitivity and specificity; validation process; algorithm; artificial neural network; diabetic retinopathy; diagnostic imaging; eye fundus; machine learning; macular edema; middle aged; observer variation; photography; validation study","American Medical Association","00987484","","JAMAA","27898976","Article","Scopus","2-s2.0-85007529863"
"Liu Y.; Pan Y.; Lai H.; Liu C.; Yin J.","Liu, Ye (56581428000); Pan, Yan (7403340386); Lai, Hanjiang (35867865300); Liu, Cong (35208633300); Yin, Jian (35316639800)","56581428000; 7403340386; 35867865300; 35208633300; 35316639800","Margin-based two-stage supervised hashing for image retrieval","2016","Neurocomputing","8","10.1016/j.neucom.2016.07.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979740762&doi=10.1016%2fj.neucom.2016.07.024&partnerID=40&md5=56fe4fd7a2b232e402b138cc5763ba43","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Information Science and Technology, Sun Yat-sen University, Guangzhou, China; School of Software, Sun Yat-sen University, Guangzhou, China; SYSU-CMU Shunde International Joint Research Institute, Foshan, China; School of Advanced Computing, Sun Yat-sen University, Guangzhou, China; Department of Electronic and Computer Engineering, National University of Singapore, Singapore, Singapore","Liu Y., School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China, School of Information Science and Technology, Sun Yat-sen University, Guangzhou, China; Pan Y., School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China, School of Software, Sun Yat-sen University, Guangzhou, China; Lai H., School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China, School of Information Science and Technology, Sun Yat-sen University, Guangzhou, China, Department of Electronic and Computer Engineering, National University of Singapore, Singapore, Singapore; Liu C., School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China, School of Advanced Computing, Sun Yat-sen University, Guangzhou, China; Yin J., School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China, School of Information Science and Technology, Sun Yat-sen University, Guangzhou, China, SYSU-CMU Shunde International Joint Research Institute, Foshan, China","Similarity-preserving hashing is a widely used method for nearest neighbor search in large-scale image retrieval. Recently, supervised hashing methods are appealing in that they learn compact hash codes with fewer bits by incorporating supervised information. In this paper, we propose a new two-stage supervised hashing methods which decomposes the hash learning process into a stage of learning approximate hash codes followed by a stage of learning hash functions. In the first stage, we propose a margin-based objective to find approximate hash codes such that a pair of hash codes associating to a pair of similar (dissimilar) images has sufficiently small (large) Hamming distance. This objective results in a challenging optimization problem. We develop a coordinate descent algorithm to efficiently solve this optimization problem. In the second stage, we use convolutional neural networks to learn hash functions. We conduct extensive evaluations on several benchmark datasets with different kinds of images. The results show that the proposed margin-based hashing method has substantial improvement upon the state-of-the-art supervised or unsupervised hashing methods. © 2016 Elsevier B.V.","Deep learning; Image hashing; Image retrieval; Neural network; Optimization algorithm","Algorithms; Codes (symbols); Hamming distance; Hash functions; Nearest neighbor search; Neural networks; Optimization; Benchmark datasets; Convolutional neural network; Coordinate descent; Deep learning; Image hashing; Optimization algorithms; Optimization problems; Similarity preserving; Article; artificial neural network; benchmarking; controlled study; data base; Hamming distance; image analysis; image hashing; image retrieval; priority journal; statistical parameters; supervised machine learning; Image retrieval","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84979740762"
"Kumar A.; Kim J.; Lyndon D.; Fulham M.; Feng D.","Kumar, Ashnil (57198890813); Kim, Jinman (55720292700); Lyndon, David (57190741110); Fulham, Michael (7005082387); Feng, Dagan (7401981167)","57198890813; 55720292700; 57190741110; 7005082387; 7401981167","An Ensemble of Fine-Tuned Convolutional Neural Networks for Medical Image Classification","2017","IEEE Journal of Biomedical and Health Informatics","396","10.1109/JBHI.2016.2635663","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014956633&doi=10.1109%2fJBHI.2016.2635663&partnerID=40&md5=c65b22ca65d9f895586c70ab738a2d3e","Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, University of Sydney, Camperdown, 2006, NSW, Australia; Department of Molecular Imaging, Royal Prince Alfred Hospital, Australia and Sydney Medical School, University of Sydney, Camperdown, 2006, NSW, Australia; Med-X Research Institute, Shanghai Jiao Tong University, Minhang, 200240, China","Kumar A., Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, University of Sydney, Camperdown, 2006, NSW, Australia; Kim J., Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, University of Sydney, Camperdown, 2006, NSW, Australia; Lyndon D., Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, University of Sydney, Camperdown, 2006, NSW, Australia; Fulham M., Department of Molecular Imaging, Royal Prince Alfred Hospital, Australia and Sydney Medical School, University of Sydney, Camperdown, 2006, NSW, Australia; Feng D., Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, University of Sydney, Camperdown, 2006, NSW, Australia, Med-X Research Institute, Shanghai Jiao Tong University, Minhang, 200240, China","The availability of medical imaging data from clinical archives, research literature, and clinical manuals, coupled with recent advances in computer vision offer the opportunity for image-based diagnosis, teaching, and biomedical research. However, the content and semantics of an image can vary depending on its modality and as such the identification of image modality is an important preliminary step. The key challenge for automatically classifying the modality of a medical image is due to the visual characteristics of different modalities: some are visually distinct while others may have only subtle differences. This challenge is compounded by variations in the appearance of images based on the diseases depicted and a lack of sufficient training data for some modalities. In this paper, we introduce a new method for classifying medical images that uses an ensemble of different convolutional neural network (CNN) architectures. CNNs are a state-of-the-art image classification technique that learns the optimal image features for a given classification task. We hypothesise that different CNN architectures learn different levels of semantic image representation and thus an ensemble of CNNs will enable higher quality features to be extracted. Our method develops a new feature extractor by fine-tuning CNNs that have been initialized on a large dataset of natural images. The fine-tuning process leverages the generic image features from natural images that are fundamental for all images and optimizes them for the variety of medical imaging modalities. These features are used to train numerous multiclass classifiers whose posterior probabilities are fused to predict the modalities of unseen images. Our experiments on the ImageCLEF 2016 medical image public dataset (30 modalities; 6776 training images, and 4166 test images) show that our ensemble of fine-tuned CNNs achieves a higher accuracy than established CNNs. Our ensemble also achieves a higher accuracy than methods in the literature evaluated on the same benchmark dataset and is only overtaken by those methods that source additional training data. © 2013 IEEE.","Convolutional neural network (CNN); deep learning; ensembles; fine-tuning; image classification","Diagnostic Imaging; Electronic Health Records; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Classification (of information); Clinical research; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Diagnosis; Large dataset; Medical imaging; Network architecture; Semantics; Statistical tests; Biomedical research; Classification tasks; Classification technique; ensembles; Fine tuning; Image-based diagnosis; Multi-class classifier; Posterior probability; accuracy; Article; artificial neural network; classifier; clinical classification; diagnostic imaging; image analysis; image quality; image reconstruction; medical research; microscopy; nervous system; principal component analysis; probability; radiology; sensitivity and specificity; support vector machine; classification; diagnostic imaging; electronic health record; human; image processing; machine learning; procedures; Image classification","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28114041","Article","Scopus","2-s2.0-85014956633"
"Marblestone A.H.; Wayne G.; Kording K.P.","Marblestone, Adam H. (26645104000); Wayne, Greg (56080177300); Kording, Konrad P. (6603812799)","26645104000; 56080177300; 6603812799","Toward an integration of deep learning and neuroscience","2016","Frontiers in Computational Neuroscience","376","10.3389/fncom.2016.00094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989345063&doi=10.3389%2ffncom.2016.00094&partnerID=40&md5=9e9b81f64da9d6c31bf88b06d7b1f182","Synthetic Neurobiology Group, Massachusetts Institute of Technology, Media Lab, Cambridge, MA, United States; Google Deepmind, London, United Kingdom; Rehabilitation Institute of Chicago, Northwestern University, Chicago, IL, United States","Marblestone A.H., Synthetic Neurobiology Group, Massachusetts Institute of Technology, Media Lab, Cambridge, MA, United States; Wayne G., Google Deepmind, London, United Kingdom; Kording K.P., Rehabilitation Institute of Chicago, Northwestern University, Chicago, IL, United States","Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. In support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain's specialized systems can be interpreted as enabling efficient optimization for specific problem classes. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses. © 2016 Marblestone, Wayne and Kording.","Cognitive architecture; Cost functions; Neural networks; Neuroscience","Costs; Deep learning; Digital storage; Electrophysiology; Network architecture; Neural networks; Neurology; Cognitive architectures; Computational problem; Credit assignment; Dedicated systems; Neuroscience; Specialized systems; Specific problems; Training procedures; attention; behavior; brain; learning; long term memory; nerve cell; neuroscience; storage; Cost functions","Frontiers Media S.A.","16625188","","","","Article","Scopus","2-s2.0-84989345063"
"Wen G.; Li H.; Huang J.; Li D.; Xun E.","Wen, Guihua (15043398600); Li, Huihui (57188878205); Huang, Jubing (57193700194); Li, Danyang (57188875666); Xun, Eryang (57193697797)","15043398600; 57188878205; 57193700194; 57188875666; 57193697797","Random Deep Belief Networks for Recognizing Emotions from Speech Signals","2017","Computational Intelligence and Neuroscience","63","10.1155/2017/1945630","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015908409&doi=10.1155%2f2017%2f1945630&partnerID=40&md5=491e11dcbc9644474b688b14063d2f4b","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","Wen G., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Li H., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Huang J., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Li D., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Xun E., School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","Now the human emotions can be recognized from speech signals using machine learning methods; however, they are challenged by the lower recognition accuracies in real applications due to lack of the rich representation ability. Deep belief networks (DBN) can automatically discover the multiple levels of representations in speech signals. To make full of its advantages, this paper presents an ensemble of random deep belief networks (RDBN) method for speech emotion recognition. It firstly extracts the low level features of the input speech signal and then applies them to construct lots of random subspaces. Each random subspace is then provided for DBN to yield the higher level features as the input of the classifier to output an emotion label. All outputted emotion labels are then fused through the majority voting to decide the final emotion label for the input speech signal. The conducted experimental results on benchmark speech emotion databases show that RDBN has better accuracy than the compared methods for speech emotion recognition. © 2017 Guihua Wen et al.","","Algorithms; Emotions; Humans; Nerve Net; Pattern Recognition, Automated; Speech; Task Performance and Analysis; Learning systems; Speech; Speech communication; Deep belief network (DBN); Deep belief networks; Low-level features; Machine learning methods; Real applications; Recognition accuracy; Recognizing emotions; Speech emotion recognition; algorithm; automated pattern recognition; emotion; human; nerve cell network; physiology; procedures; speech; task performance; Speech recognition","Hindawi Limited","16875265","","","28356908","Article","Scopus","2-s2.0-85015908409"
"Cao R.; Bhattacharya D.; Hou J.; Cheng J.","Cao, Renzhi (55619927900); Bhattacharya, Debswapna (55363928300); Hou, Jie (56673336000); Cheng, Jianlin (57203108630)","55619927900; 55363928300; 56673336000; 57203108630","DeepQA: Improving the estimation of single protein model quality with deep belief networks","2016","BMC Bioinformatics","138","10.1186/s12859-016-1405-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000843987&doi=10.1186%2fs12859-016-1405-y&partnerID=40&md5=30e4392d30c206bc17831fd98b6ff801","Pacific Lutheran University, Department of Computer Science, Tacoma, 98447, WA, United States; Wichita State University, Department of Electrical Engineering and Computer Science, Wichita, 67260, KS, United States; University of Missouri, Department of Computer Science, Columbia, 65211, MO, United States; University of Missouri, Informatics Institute, Columbia, 65211, MO, United States","Cao R., Pacific Lutheran University, Department of Computer Science, Tacoma, 98447, WA, United States; Bhattacharya D., Wichita State University, Department of Electrical Engineering and Computer Science, Wichita, 67260, KS, United States; Hou J., University of Missouri, Department of Computer Science, Columbia, 65211, MO, United States; Cheng J., University of Missouri, Department of Computer Science, Columbia, 65211, MO, United States, University of Missouri, Informatics Institute, Columbia, 65211, MO, United States","Background: Protein quality assessment (QA) useful for ranking and selecting protein models has long been viewed as one of the major challenges for protein tertiary structure prediction. Especially, estimating the quality of a single protein model, which is important for selecting a few good models out of a large model pool consisting of mostly low-quality models, is still a largely unsolved problem. Results: We introduce a novel single-model quality assessment method DeepQA based on deep belief network that utilizes a number of selected features describing the quality of a model from different perspectives, such as energy, physio-chemical characteristics, and structural information. The deep belief network is trained on several large datasets consisting of models from the Critical Assessment of Protein Structure Prediction (CASP) experiments, several publicly available datasets, and models generated by our in-house ab initio method. Our experiments demonstrate that deep belief network has better performance compared to Support Vector Machines and Neural Networks on the protein model quality assessment problem, and our method DeepQA achieves the state-of-the-art performance on CASP11 dataset. It also outperformed two well-established methods in selecting good outlier models from a large set of models of mostly low quality generated by ab initio modeling methods. Conclusion: DeepQA is a useful deep learning tool for protein single model quality assessment and protein structure prediction. The source code, executable, document and training/test datasets of DeepQA for Linux is freely available to non-commercial users at http://cactus.rnet.missouri.edu/DeepQA/. © 2016 The Author(s).","Deep belief network; Machine learning; Protein model quality assessment; Protein structure prediction","Algorithms; Data Accuracy; Machine Learning; Models, Molecular; Neural Networks (Computer); Protein Structure, Tertiary; Proteins; Support Vector Machine; Bayesian networks; Computer operating systems; Forecasting; Learning systems; Proteins; protein; Ab initio modeling; Critical assessment of protein structure predictions (CASP); Deep belief networks; Protein modeling; Protein structure prediction; Protein tertiary structure prediction; State-of-the-art performance; Structural information; algorithm; artificial neural network; chemistry; machine learning; measurement accuracy; metabolism; molecular model; protein tertiary structure; support vector machine; Deep learning","BioMed Central Ltd.","14712105","","BBMIC","27919220","Article","Scopus","2-s2.0-85000843987"
"Yang H.-H.; Luo Z.-C.; Jiang S.-J.; Zhang X.-B.; Yin L.-H.","Yang, Hui-Hua (8676488300); Luo, Zhi-Chao (57191273038); Jiang, Shu-Jie (55867711700); Zhang, Xue-Bo (56380836900); Yin, Li-Hui (14829863400)","8676488300; 57191273038; 55867711700; 56380836900; 14829863400","Sparse denoising autoencoder application in identification of counterfeit pharmaceutical","2016","Guang Pu Xue Yu Guang Pu Fen Xi/Spectroscopy and Spectral Analysis","7","10.3964/j.issn.1000-0593(2016)09-2774-06","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988473732&doi=10.3964%2fj.issn.1000-0593%282016%2909-2774-06&partnerID=40&md5=8b1238ae8ec238fd7a55c8d249add275","College of Electronic Engineering and Automation, Guilin University of Electronic Technology, Guilin, 541004, China; College of Automation, Beijing University of Posts & Telecommunications, Beijing, 100876, China; National Institute for Food and Drug Control, Beijing, 100050, China","Yang H.-H., College of Electronic Engineering and Automation, Guilin University of Electronic Technology, Guilin, 541004, China, College of Automation, Beijing University of Posts & Telecommunications, Beijing, 100876, China; Luo Z.-C., College of Electronic Engineering and Automation, Guilin University of Electronic Technology, Guilin, 541004, China; Jiang S.-J., College of Electronic Engineering and Automation, Guilin University of Electronic Technology, Guilin, 541004, China; Zhang X.-B., National Institute for Food and Drug Control, Beijing, 100050, China; Yin L.-H., National Institute for Food and Drug Control, Beijing, 100050, China","Near-infrared(NIR)As a fast and non-destructive testing technology, spectroscopy techniques is very suitable for pharmaceutical discrimination. Autoencoder network, as a hot research topic, has drawn widespread attention in machine learning research in recent years. Compared with traditional surface learning algorithm models, Autoencoder network has more powerful modeling capability as a typical deep networks model. Based on the unsupervised greedy layer-wise pre-training, autoencoder trains the network layer by layer while minimizing the error in reconstructing. Each layer is pre-trained with an unsupervised learning algorithm, learning a nonlinear transformation of the input of each layer which is the output of the previous layer. Pre-whitening process could get the inner structural features of the data more effectively. The supervised fine-tuning is followed with the unsupervised pre-training which sets the stage for a final training phase. The deep architecture is fine-tuned with respect to a supervised training criterion with gradient-based optimization. In this paper, firstly, the preprocessing step and pre-whitening transformation were used to treat near-infrared spectroscopy data of erythromycin ethylsuccinate, The pre-whitening transformation would reduce the correlation of the features, which gave each feature the same variance. Experimental results showed that the pre-whitening process had improved the classification accuracy of Sparse Denoising Autoencoder (SDAE) effectively. The SDAE with two hidden layers combined with pre-whitening was used to build the classification model for the identification of counterfeit pharmaceutical. The BP neural networks was compared with SVM algorithm for the classification accuracy and mean absolute difference (MAD). SDAE algorithm had higher classification accuracy than BP neural networks which had the same network structure with the SDAE networks, and SDAE algorithm also performed better than the SVM algorithm when the train datasets achieved a certain amount. As to the generalization performances, SDAE algorithm had less mean absolute difference of classification accuracy than SVM and BP Neural Networks. This result showed that SDAE algorithm could be effectively used to discriminate the counterfeit pharmaceutical. © 2016, Peking University Press. All right reserved.","Autoencoder; Near-infrared spectroscopy; Pharmaceutical discrimination; Whitening","Algorithms; Machine Learning; Neural Networks (Computer); Spectroscopy, Near-Infrared; Artificial intelligence; Classification (of information); Crime; Infrared devices; Learning systems; Mathematical transformations; Metadata; Near infrared spectroscopy; Network layers; Neural networks; Nondestructive examination; Optimization; Testing; Auto encoders; Generalization performance; Gradient-based optimization; Machine learning research; Mean absolute differences; Non-linear transformations; Whitening; Whitening transformation; algorithm; artificial neural network; machine learning; near infrared spectroscopy; Learning algorithms","Science Press","10000593","","GYGFE","30084593","Article","Scopus","2-s2.0-84988473732"
"Asaoka R.; Murata H.; Iwase A.; Araie M.","Asaoka, Ryo (55901760000); Murata, Hiroshi (37111236600); Iwase, Aiko (7006886580); Araie, Makoto (35405732300)","55901760000; 37111236600; 7006886580; 35405732300","Detecting Preperimetric Glaucoma with Standard Automated Perimetry Using a Deep Learning Classifier","2016","Ophthalmology","191","10.1016/j.ophtha.2016.05.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982243237&doi=10.1016%2fj.ophtha.2016.05.029&partnerID=40&md5=107c84d8a77b1e1310c49313b1712f66","Department of Ophthalmology, The University of Tokyo, Tokyo, Japan; Tajimi Iwase Eye Clinic, Tajimi, Japan; Kanto Central Hospital of the Mutual Aid Association of Public School Teachers, Tokyo, Japan","Asaoka R., Department of Ophthalmology, The University of Tokyo, Tokyo, Japan; Murata H., Department of Ophthalmology, The University of Tokyo, Tokyo, Japan; Iwase A., Tajimi Iwase Eye Clinic, Tajimi, Japan; Araie M., Department of Ophthalmology, The University of Tokyo, Tokyo, Japan, Kanto Central Hospital of the Mutual Aid Association of Public School Teachers, Tokyo, Japan","Purpose To differentiate the visual fields (VFs) of preperimetric open-angle glaucoma (OAG) patients from the VFs of healthy eyes using a deep learning (DL) method. Design Cohort study. Participants One hundred seventy-one preperimetric glaucoma VFs (PPGVFs) from 53 eyes in 51 OAG patients and 108 healthy eyes of 87 healthy participants. Methods Preperimetric glaucoma VFs were defined as all VFs before a first diagnosis of manifest glaucoma (Anderson-Patella's criteria). In total, 171 PPGVFs from 53 eyes in 51 OAG patients and 108 VFs from 108 healthy eyes in 87 healthy participants were analyzed (all VFs were tested using the Humphrey Field Analyzer 30-2 program; Carl Zeiss Meditec, Dublin, CA). The 52 total deviation, mean deviation, and pattern standard deviation values were used as predictors in the DL classifier: a deep feed-forward neural network (FNN), along with other machine learning (ML) methods, including random forests (RF), gradient boosting, support vector machine, and neural network (NN). The area under the receiver operating characteristic curve (AUC) was used to evaluate the accuracy of discrimination for each method. Main Outcome Measures The AUCs obtained with each classifier method. Results A significantly larger AUC of 92.6% (95% confidence interval [CI], 89.8%–95.4%) was obtained using the deep FNN classifier compared with all other ML methods: 79.0% (95% CI, 73.5%–84.5%) with RF, 77.6% (95% CI, 71.7%–83.5%) with gradient boosting, 71.2% (95% CI, 65.0%–77.5%), and 66.7% (95% CI, 60.1%–73.3%) with NN. Conclusions Preperimetric glaucoma VFs can be distinguished from healthy VFs with very high accuracy using a deep FNN classifier. © 2016 American Academy of Ophthalmology","","Adult; Aged; Area Under Curve; Case-Control Studies; Female; Glaucoma, Open-Angle; Humans; Male; Middle Aged; Optic Nerve Diseases; ROC Curve; Sensitivity and Specificity; Tomography, Optical Coherence; Vision Disorders; Visual Field Tests; Visual Fields; adult; Article; artificial neural network; classifier; cohort analysis; controlled study; deep learning classifier; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; female; gradient boosting; human; Humphrey perimeter; intermethod comparison; machine learning; major clinical study; male; middle aged; open angle glaucoma; perimetry; priority journal; random forest; sensitivity and specificity; support vector machine; visual field; aged; area under the curve; case control study; Glaucoma, Open-Angle; Optic Nerve Diseases; optical coherence tomography; pathophysiology; perimetry; physiology; procedures; receiver operating characteristic; Vision Disorders","Elsevier Inc.","01616420","","OPHTD","27395766","Article","Scopus","2-s2.0-84982243237"
"Hasan M.; Kotov A.; Idalski Carcone A.; Dong M.; Naar S.; Brogan Hartlieb K.","Hasan, Mehedi (57204312780); Kotov, Alexander (56284550800); Idalski Carcone, April (14325021000); Dong, Ming (55724049700); Naar, Sylvie (6602805970); Brogan Hartlieb, Kathryn (56520140100)","57204312780; 56284550800; 14325021000; 55724049700; 6602805970; 56520140100","A study of the effectiveness of machine learning methods for classification of clinical interview fragments into a large number of categories","2016","Journal of Biomedical Informatics","41","10.1016/j.jbi.2016.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971224905&doi=10.1016%2fj.jbi.2016.05.004&partnerID=40&md5=f95017560e445b83119463907f2fc73d","Department of Computer Science, Wayne State University, 5057 Woodward Ave, Detroit, 48202, MI, United States; Pediatric Prevention Research Center, School of Medicine, Wayne State University, 540 E Canfield St, Detroit, 48201, MI, United States; Department of Dietetics and Nutrition, Florida International University, 11200 SW 8th St, Miami, 33199, FL, United States","Hasan M., Department of Computer Science, Wayne State University, 5057 Woodward Ave, Detroit, 48202, MI, United States; Kotov A., Department of Computer Science, Wayne State University, 5057 Woodward Ave, Detroit, 48202, MI, United States; Idalski Carcone A., Pediatric Prevention Research Center, School of Medicine, Wayne State University, 540 E Canfield St, Detroit, 48201, MI, United States; Dong M., Department of Computer Science, Wayne State University, 5057 Woodward Ave, Detroit, 48202, MI, United States; Naar S., Pediatric Prevention Research Center, School of Medicine, Wayne State University, 540 E Canfield St, Detroit, 48201, MI, United States; Brogan Hartlieb K., Department of Dietetics and Nutrition, Florida International University, 11200 SW 8th St, Miami, 33199, FL, United States","This study examines the effectiveness of state-of-the-art supervised machine learning methods in conjunction with different feature types for the task of automatic annotation of fragments of clinical text based on codebooks with a large number of categories. We used a collection of motivational interview transcripts consisting of 11,353 utterances, which were manually annotated by two human coders as the gold standard, and experimented with state-of-art classifiers, including Naïve Bayes, J48 Decision Tree, Support Vector Machine (SVM), Random Forest (RF), AdaBoost, DiscLDA, Conditional Random Fields (CRF) and Convolutional Neural Network (CNN) in conjunction with lexical, contextual (label of the previous utterance) and semantic (distribution of words in the utterance across the Linguistic Inquiry and Word Count dictionaries) features. We found out that, when the number of classes is large, the performance of CNN and CRF is inferior to SVM. When only lexical features were used, interview transcripts were automatically annotated by SVM with the highest classification accuracy among all classifiers of 70.8%, 61% and 53.7% based on the codebooks consisting of 17, 20 and 41 codes, respectively. Using contextual and semantic features, as well as their combination, in addition to lexical ones, improved the accuracy of SVM for annotation of utterances in motivational interview transcripts with a codebook consisting of 17 classes to 71.5%, 74.2%, and 75.1%, respectively. Our results demonstrate the potential of using machine learning methods in conjunction with lexical, semantic and contextual features for automatic annotation of clinical interview transcripts with near-human accuracy. © 2016 Elsevier Inc.","Annotation of clinical text; Deep learning; Machine learning; Motivational interviewing; Text classification","Bayes Theorem; Data Curation; Decision Trees; Machine Learning; Semantics; Support Vector Machine; Adaptive boosting; Artificial intelligence; Arts computing; Classification (of information); Classifiers; Decision trees; Neural networks; Random processes; Semantics; Supervised learning; Support vector machines; Text processing; Annotation of clinical text; Conditional random field; Convolutional neural network; Deep learning; Machine learning methods; Motivational interviewing; Supervised machine learning; Text classification; Bayes theorem; decision tree; information processing; machine learning; procedures; semantics; support vector machine; Learning systems","Academic Press Inc.","15320464","","JBIOB","27185608","Article","Scopus","2-s2.0-84971224905"
"Murphy M.C.; Poplawsky A.J.; Vazquez A.L.; Chan K.C.; Kim S.-G.; Fukuda M.","Murphy, Matthew C. (37085526900); Poplawsky, Alexander J. (42062136000); Vazquez, Alberto L. (7202666366); Chan, Kevin C. (34968940300); Kim, Seong-Gi (27167575500); Fukuda, Mitsuhiro (55959421100)","37085526900; 42062136000; 7202666366; 34968940300; 27167575500; 55959421100","Improved spatial accuracy of functional maps in the rat olfactory bulb using supervised machine learning approach","2016","NeuroImage","6","10.1016/j.neuroimage.2016.05.055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973883039&doi=10.1016%2fj.neuroimage.2016.05.055&partnerID=40&md5=0235f859ffc8cdb01a78c5f31f53f623","Department of Ophthalmology, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Department of Bioengineering, University of Pittsburgh, Pittsburgh, PA, United States; Center for Neuroscience Imaging Research, Institute for Basic Science, Sungkyunkwan University, Suwon, South Korea; Department of Biomedical Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Biological Sciences, Sungkyunkwan University, Suwon, South Korea","Murphy M.C., Department of Ophthalmology, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States, Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Poplawsky A.J., Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Vazquez A.L., Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Chan K.C., Department of Ophthalmology, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States, Department of Bioengineering, University of Pittsburgh, Pittsburgh, PA, United States; Kim S.-G., Center for Neuroscience Imaging Research, Institute for Basic Science, Sungkyunkwan University, Suwon, South Korea, Department of Biomedical Engineering, Sungkyunkwan University, Suwon, South Korea, Department of Biological Sciences, Sungkyunkwan University, Suwon, South Korea; Fukuda M., Department of Radiology, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States","Functional MRI (fMRI) is a popular and important tool for noninvasive mapping of neural activity. As fMRI measures the hemodynamic response, the resulting activation maps do not perfectly reflect the underlying neural activity. The purpose of this work was to design a data-driven model to improve the spatial accuracy of fMRI maps in the rat olfactory bulb. This system is an ideal choice for this investigation since the bulb circuit is well characterized, allowing for an accurate definition of activity patterns in order to train the model. We generated models for both cerebral blood volume weighted (CBVw) and blood oxygen level dependent (BOLD) fMRI data. The results indicate that the spatial accuracy of the activation maps is either significantly improved or at worst not significantly different when using the learned models compared to a conventional general linear model approach, particularly for BOLD images and activity patterns involving deep layers of the bulb. Furthermore, the activation maps computed by CBVw and BOLD data show increased agreement when using the learned models, lending more confidence to their accuracy. The models presented here could have an immediate impact on studies of the olfactory bulb, but perhaps more importantly, demonstrate the potential for similar flexible, data-driven models to improve the quality of activation maps calculated using fMRI data. © 2016 Elsevier Inc.","","Algorithms; Animals; Brain Mapping; Electric Stimulation; Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Olfactory Bulb; Pattern Recognition, Automated; Rats; Rats, Sprague-Dawley; Reproducibility of Results; Sensitivity and Specificity; Smell; Spatio-Temporal Analysis; Supervised Machine Learning; accuracy; animal experiment; Article; BOLD signal; brain blood volume; calculation; controlled study; functional magnetic resonance imaging; image analysis; image processing; machine learning; male; mathematical analysis; nonhuman; olfactory bulb; priority journal; rat; algorithm; animal; automated pattern recognition; brain mapping; computer assisted diagnosis; electrostimulation; evaluation study; image enhancement; nuclear magnetic resonance imaging; odor; olfactory bulb; physiology; procedures; reproducibility; sensitivity and specificity; spatiotemporal analysis; Sprague Dawley rat; supervised machine learning","Academic Press Inc.","10538119","","NEIME","27236085","Article","Scopus","2-s2.0-84973883039"
"Samala R.K.; Chan H.-P.; Hadjiiski L.; Helvie M.A.; Wei J.; Cha K.","Samala, Ravi K. (23005865500); Chan, Heang-Ping (7403402896); Hadjiiski, Lubomir (7003646513); Helvie, Mark A. (7005819436); Wei, Jun (35281144100); Cha, Kenny (55955567400)","23005865500; 7403402896; 7003646513; 7005819436; 35281144100; 55955567400","Mass detection in digital breast tomosynthesis: Deep convolutional neural network with transfer learning from mammography","2016","Medical Physics","220","10.1118/1.4967345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000788384&doi=10.1118%2f1.4967345&partnerID=40&md5=2194be94584187c6aa1b87fbca2a0a55","Department of Radiology, University of Michigan, Ann Arbor, 48109, MI, United States","Samala R.K., Department of Radiology, University of Michigan, Ann Arbor, 48109, MI, United States; Chan H.-P., Department of Radiology, University of Michigan, Ann Arbor, 48109, MI, United States; Hadjiiski L., Department of Radiology, University of Michigan, Ann Arbor, 48109, MI, United States; Helvie M.A., Department of Radiology, University of Michigan, Ann Arbor, 48109, MI, United States; Wei J., Department of Radiology, University of Michigan, Ann Arbor, 48109, MI, United States; Cha K., Department of Radiology, University of Michigan, Ann Arbor, 48109, MI, United States","Purpose: Develop a computer-aided detection (CAD) system for masses in digital breast tomosynthesis (DBT) volume using a deep convolutional neural network (DCNN) with transfer learning from mammograms. Methods: A data set containing 2282 digitized film and digital mammograms and 324 DBT volumes were collected with IRB approval. The mass of interest on the images was marked by an experienced breast radiologist as reference standard. The data set was partitioned into a training set (2282 mammograms with 2461 masses and 230 DBT views with 228 masses) and an independent test set (94 DBT views with 89 masses). For DCNN training, the region of interest (ROI) containing the mass (true positive) was extracted from each image. False positive (FP) ROIs were identified at prescreening by their previously developed CAD systems. After data augmentation, a total of 45 072 mammographic ROIs and 37 450 DBT ROIs were obtained. Data normalization and reduction of non-uniformity in the ROIs across heterogeneous data was achieved using a background correction method applied to each ROI. A DCNN with four convolutional layers and three fully connected (FC) layers was first trained on the mammography data. Jittering and dropout techniques were used to reduce overfitting. After training with the mammographic ROIs, all weights in the first three convolutional layers were frozen, and only the last convolution layer and the FC layers were randomly initialized again and trained using the DBT training ROIs. The authors compared the performances of two CAD systems for mass detection in DBT: one used the DCNN-based approach and the other used their previously developed feature-based approach for FP reduction. The prescreening stage was identical in both systems, passing the same set of mass candidates to the FP reduction stage. For the feature-based CAD system, 3D clustering and active contour method was used for segmentation; morphological, gray level, and texture features were extracted and merged with a linear discriminant classifier to score the detected masses. For the DCNN-based CAD system, ROIs from five consecutive slices centered at each candidate were passed through the trained DCNN and a mass likelihood score was generated. The performances of the CAD systems were evaluated using free-response ROC curves and the performance difference was analyzed using a non-parametric method. Results: Before transfer learning, the DCNN trained only on mammograms with an AUC of 0.99 classified DBT masses with an AUC of 0.81 in the DBT training set. After transfer learning with DBT, the AUC improved to 0.90. For breast-based CAD detection in the test set, the sensitivity for the feature-based and the DCNN-based CAD systems was 83% and 91%, respectively, at 1 FP/DBT volume. The difference between the performances for the two systems was statistically significant (p-value > 0.05). Conclusions: The image patterns learned from the mammograms were transferred to the mass detection on DBT slices through the DCNN. This study demonstrated that large data sets collected from mammography are useful for developing new CAD systems for DBT, alleviating the problem and effort of collecting entirely new large data sets for the new modality. © 2016 American Association of Physicists in Medicine.","computer-aided detection; convolutional neural network; deep-learning; digital breast tomosynthesis; mass; transfer learning","Breast Neoplasms; Diagnosis, Computer-Assisted; Image Processing, Computer-Assisted; Machine Learning; Mammography; Neural Networks (Computer); Computer aided diagnosis; Computer aided instruction; Convolution; Data reduction; Deep neural networks; E-learning; Feature extraction; Image segmentation; Statistical tests; Tomography; X ray screens; Computer aided detection; Computer aided detection systems; Convolutional neural network; Data set; Deep-learning; Digital breast tomosynthesis; Mass; Mass detection; Performance; Transfer learning; classifier; clinical article; diagnostic test accuracy study; digital breast tomosynthesis; human; learning; nervous system; radiologist; receiver operating characteristic; screening; statistical model; statistical significance; artificial neural network; breast tumor; computer assisted diagnosis; diagnostic imaging; image processing; machine learning; mammography; procedures; Mammography","AAPM - American Association of Physicists in Medicine","00942405","","MPHYA","27908154","Article","Scopus","2-s2.0-85000788384"
"Sturm I.; Lapuschkin S.; Samek W.; Müller K.-R.","Sturm, Irene (35184153600); Lapuschkin, Sebastian (57190868412); Samek, Wojciech (40762215900); Müller, Klaus-Robert (15042362900)","35184153600; 57190868412; 40762215900; 15042362900","Interpretable deep neural networks for single-trial EEG classification","2016","Journal of Neuroscience Methods","272","10.1016/j.jneumeth.2016.10.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993965279&doi=10.1016%2fj.jneumeth.2016.10.008&partnerID=40&md5=de9149169a1391ec990f8c9ef646c365","Machine Learning Group, Berlin Institute of Technology, Marchstr. 23, Berlin, 10587, Germany; Machine Learning Group, Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany; Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 136-713, South Korea","Sturm I., Machine Learning Group, Berlin Institute of Technology, Marchstr. 23, Berlin, 10587, Germany; Lapuschkin S., Machine Learning Group, Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany; Samek W., Machine Learning Group, Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany; Müller K.-R., Machine Learning Group, Berlin Institute of Technology, Marchstr. 23, Berlin, 10587, Germany, Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, 136-713, South Korea","Background In cognitive neuroscience the potential of deep neural networks (DNNs) for solving complex classification tasks is yet to be fully exploited. The most limiting factor is that DNNs as notorious ‘black boxes’ do not provide insight into neurophysiological phenomena underlying a decision. Layer-wise relevance propagation (LRP) has been introduced as a novel method to explain individual network decisions. New method We propose the application of DNNs with LRP for the first time for EEG data analysis. Through LRP the single-trial DNN decisions are transformed into heatmaps indicating each data point's relevance for the outcome of the decision. Results DNN achieves classification accuracies comparable to those of CSP-LDA. In subjects with low performance subject-to-subject transfer of trained DNNs can improve the results. The single-trial LRP heatmaps reveal neurophysiologically plausible patterns, resembling CSP-derived scalp maps. Critically, while CSP patterns represent class-wise aggregated information, LRP heatmaps pinpoint neural patterns to single time points in single trials. Comparison with existing method(s) We compare the classification performance of DNNs to that of linear CSP-LDA on two data sets related to motor-imaginary BCI. Conclusion We have demonstrated that DNN is a powerful non-linear tool for EEG analysis. With LRP a new quality of high-resolution assessment of neural activity can be reached. LRP is a potential remedy for the lack of interpretability of DNNs that has limited their utility in neuroscientific applications. The extreme specificity of the LRP-derived heatmaps opens up new avenues for investigating neural activity underlying complex perception or decision-related processes. © 2016 Elsevier B.V.","Brain–computer interfacing; Interpretability; Neural networks","Animals; Brain; Brain Mapping; Brain Waves; Electroencephalography; Humans; Nerve Net; Neurons; Article; deep neural network; electroencephalogram; eye movement; layer wise relevance propagation; machine learning; neurophysiology; priority journal; vision; animal; brain; brain mapping; classification; cytology; electroencephalogram; electroencephalography; human; nerve cell; nerve cell network; physiology; procedures","Elsevier B.V.","01650270","","JNMED","27746229","Article","Scopus","2-s2.0-84993965279"
"Wang S.; Li W.; Liu S.; Xu J.","Wang, Sheng (58428221300); Li, Wei (57194739096); Liu, Shiwang (7409460407); Xu, Jinbo (57203521425)","58428221300; 57194739096; 7409460407; 57203521425","RaptorX-Property: a web server for protein structure property prediction","2016","Nucleic Acids Research","366","10.1093/nar/gkw306","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018959942&doi=10.1093%2fnar%2fgkw306&partnerID=40&md5=bf17cb901eff24b4935dd1c75c4331ec","Toyota Technological Institute at Chicago, Chicago, IL, United States; Department of Human Genetics, University of Chicago, Chicago, IL, United States; School of Biological and Chemical Engineering, Zhejiang University of Science and Technology, Zhejiang, China","Wang S., Toyota Technological Institute at Chicago, Chicago, IL, United States, Department of Human Genetics, University of Chicago, Chicago, IL, United States; Li W., School of Biological and Chemical Engineering, Zhejiang University of Science and Technology, Zhejiang, China; Liu S., School of Biological and Chemical Engineering, Zhejiang University of Science and Technology, Zhejiang, China; Xu J., Toyota Technological Institute at Chicago, Chicago, IL, United States","RaptorX Property (http://raptorx2.uchicago.edu/StructurePropertyPred/predict/) is a web server predicting structure property of a protein sequence without using any templates. It outperforms other servers, especially for proteins without close homologs in PDB or with very sparse sequence profile (i.e. carries little evolutionary information). This server employs a powerful in-house deep learning model DeepCNF (Deep Convolutional Neural Fields) to predict secondary structure (SS), solvent accessibility (ACC) and disorder regions (DISO). DeepCNF not only models complex sequence–structure relationship by a deep hierarchical architecture, but also interdependency between adjacent property labels. Our experimental results show that, tested on CASP10, CASP11 and the other benchmarks, this server can obtain ∼84% Q3 accuracy for 3-state SS, ∼72% Q8 accuracy for 8-state SS, ∼66% Q3 accuracy for 3-state solvent accessibility, and ∼0.89 area under the ROC curve (AUC) for disorder prediction. © The Author(s) 2016.","","Amino Acid Sequence; Area Under Curve; Caspases; Databases, Protein; Internet; Machine Learning; Neural Networks (Computer); Protein Structure, Secondary; Proteins; ROC Curve; Software; Solvents; Time Factors; caspase 10; caspase 11; solvent; caspase; protein; accuracy; amino acid sequence; area under the curve; Article; controlled study; convolutional neural network; deep learning; experimental study; Internet; machine learning; prediction; protein secondary structure; protein structure; receiver operating characteristic; sequence analysis; structure activity relation; structure analysis; artificial neural network; chemistry; protein database; software; time factor","Oxford University Press","03051048","","NARHA","27112573","Article","Scopus","2-s2.0-85018959942"
"Havaei M.; Davy A.; Warde-Farley D.; Biard A.; Courville A.; Bengio Y.; Pal C.; Jodoin P.-M.; Larochelle H.","Havaei, Mohammad (55579219900); Davy, Axel (57207796143); Warde-Farley, David (24472176000); Biard, Antoine (57189620066); Courville, Aaron (6507291186); Bengio, Yoshua (7003958245); Pal, Chris (15056677600); Jodoin, Pierre-Marc (6507483969); Larochelle, Hugo (14827997400)","55579219900; 57207796143; 24472176000; 57189620066; 6507291186; 7003958245; 15056677600; 6507483969; 14827997400","Brain tumor segmentation with Deep Neural Networks","2017","Medical Image Analysis","2291","10.1016/j.media.2016.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973442994&doi=10.1016%2fj.media.2016.05.004&partnerID=40&md5=91051269c3c6e210c566cbd3cd0559e2","Université de Sherbrooke, Sherbrooke, QC, Canada; École Normale supérieure, Paris, France; Université de Montréal, Montréal, Canada; École polytechnique, Palaiseau, France; École Polytechnique de Montréal, Canada","Havaei M., Université de Sherbrooke, Sherbrooke, QC, Canada; Davy A., École Normale supérieure, Paris, France; Warde-Farley D., Université de Montréal, Montréal, Canada; Biard A., Université de Montréal, Montréal, Canada, École polytechnique, Palaiseau, France; Courville A., Université de Montréal, Montréal, Canada; Bengio Y., Université de Montréal, Montréal, Canada; Pal C., Université de Montréal, Montréal, Canada, École Polytechnique de Montréal, Canada; Jodoin P.-M., Université de Sherbrooke, Sherbrooke, QC, Canada; Larochelle H., Université de Sherbrooke, Sherbrooke, QC, Canada","In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we've found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data.We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test data-set reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster. © 2016 Elsevier B.V.","Brain tumor segmentation; Cascaded convolutional neural networks; Convolutional neural networks; Deep neural networks","Brain Neoplasms; Glioblastoma; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Brain; Convolution; Magnetic resonance imaging; Network architecture; Neural networks; Statistical tests; Tumors; Brain tumor segmentation; Cascade architecture; Competitive performance; Convolutional neural network; Convolutional Neural Networks (CNN); Different architectures; Fully-connected layers; Training procedures; Article; brain tumor; brain tumor segmentation; glioblastoma; image analysis; machine learning; nerve cell network; priority journal; artificial neural network; brain tumor; diagnostic imaging; human; image processing; machine learning; nuclear magnetic resonance imaging; procedures; Deep neural networks","Elsevier B.V.","13618415","","MIAEC","27310171","Article","Scopus","2-s2.0-84973442994"
"Zhang J.; Ding S.; Zhang N.; Xue Y.","Zhang, Jian (56637434200); Ding, Shifei (24314525600); Zhang, Nan (56994194400); Xue, Yu (56501123700)","56637434200; 24314525600; 56994194400; 56501123700","Weight Uncertainty in Boltzmann Machine","2016","Cognitive Computation","13","10.1007/s12559-016-9429-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984817956&doi=10.1007%2fs12559-016-9429-1&partnerID=40&md5=e79b48e0f39f530b537313c77549c0c6","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; College of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, 210044, China","Zhang J., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Ding S., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Zhang N., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Xue Y., College of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, 210044, China","Background: Based on restricted Boltzmann machine (RBM), the deep learning models can be roughly divided into deep belief networks (DBNs) and deep Boltzmann machine (DBM). However, the overfitting problems commonly exist in neural networks and RBM models. In order to alleviate the overfitting problem, lots of research has been done. This paper alleviated the overfitting problem in RBM and proposed the weight uncertainty semi-restricted Boltzmann machine (WSRBM) to improve the ability of image recognition and image reconstruction. Methods: First, this paper built weight uncertainty RBM model based on maximum likelihood estimation. And in the experimental section, this paper verified the effectiveness of the weight uncertainty deep belief network and the weight uncertainty deep Boltzmann machine. Second, in order to obtain better reconstructed images, this paper used the semi-restricted Boltzmann machine (SRBM) as the feature extractor and built the WSRBM. Lastly, this paper used hybrid Monte Carlo sampling and cRBM to improve the classification ability of WSDBM. Results: The experiments showed that the weight uncertainty RBM, weight uncertainty DBN and weight uncertainty DBM were effective compared with the dropout method. And the WSDBM model performed well in image recognition and image reconstruction as well. Conclusions: This paper introduced the weight uncertainty method to RBM, and proposed a WSDBM model, which was effective in image recognition and image reconstruction. © 2016, Springer Science+Business Media New York.","DBM; DBN; RBM; Weight uncertainty","Bayesian networks; Database systems; Image processing; Image recognition; Maximum likelihood; Maximum likelihood estimation; Monte Carlo methods; Classification ability; Deep belief networks; Deep boltzmann machines; Experimental section; Over fitting problem; Reconstructed image; Restricted boltzmann machine; Weight uncertainty; Image reconstruction","Springer New York LLC","18669956","","","","Article","Scopus","2-s2.0-84984817956"
"Grzegorczyk K.; Kurdziel M.; Wójcik P.I.","Grzegorczyk, Karol (57189297003); Kurdziel, Marcin (10641814700); Wójcik, Piotr Iwo (56608927400)","57189297003; 10641814700; 56608927400","Encouraging orthogonality between weight vectors in pretrained deep neural networks","2016","Neurocomputing","14","10.1016/j.neucom.2016.03.044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969269136&doi=10.1016%2fj.neucom.2016.03.044&partnerID=40&md5=776c3a7271cb80769cee7e67aee8ee43","AGH University of Science and Technology, Faculty of Computer Science, Electronics and Telecommunications, Department of Computer Science, al. A. Mickiewicza 30, Krakow, 30-059, Poland","Grzegorczyk K., AGH University of Science and Technology, Faculty of Computer Science, Electronics and Telecommunications, Department of Computer Science, al. A. Mickiewicza 30, Krakow, 30-059, Poland; Kurdziel M., AGH University of Science and Technology, Faculty of Computer Science, Electronics and Telecommunications, Department of Computer Science, al. A. Mickiewicza 30, Krakow, 30-059, Poland; Wójcik P.I., AGH University of Science and Technology, Faculty of Computer Science, Electronics and Telecommunications, Department of Computer Science, al. A. Mickiewicza 30, Krakow, 30-059, Poland","Deep neural networks have recently shown impressive performance in several machine learning tasks. An important approach to training deep networks, useful especially when labeled data is scarce, relies on unsupervised pretraining of hidden layers followed by supervised finetuning. One of the most widely used approaches to unsupervised pretraining is to train each layer with the Contrastive Divergence (CD) algorithm. In this work we present a modification to CD with the goal of learning more diverse sets of features in hidden layers. In particular, we extend the CD learning rule to penalize cosines of the angles between weight vectors, which in turn encourages orthogonality between the learned features. We demonstrate experimentally that this extension to CD improves performance of pretrained deep networks on image recognition and document retrieval tasks. © 2016 Elsevier B.V.","Contrastive Divergence; Orthogonalization; Unsupervised pretraining","Artificial intelligence; Image recognition; Contrastive divergence; Deep neural networks; Document Retrieval; Hidden layers; Learning rules; Orthogonalization; Pre-training; Sets of features; Article; artificial neural network; contrastive divergence; deep neural network; image processing; information retrieval; learning algorithm; mathematical computing; mathematical model; mathematical phenomena; orthogonality; priority journal; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84969269136"
"Ekins S.","Ekins, Sean (57203197233)","57203197233","The Next Era: Deep Learning in Pharmaceutical Research","2016","Pharmaceutical Research","165","10.1007/s11095-016-2029-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986243956&doi=10.1007%2fs11095-016-2029-7&partnerID=40&md5=1155e781961defc72af02e8b86d6ca60","Collaborations Pharmaceuticals, Inc, 5616 Hilltop Needmore Road, Fuquay-Varina, 27526, NC, United States; Collaborative Drug Discovery, 1633 Bayshore Highway, Suite 342, Burlingame, 94010, CA, United States","Ekins S., Collaborations Pharmaceuticals, Inc, 5616 Hilltop Needmore Road, Fuquay-Varina, 27526, NC, United States, Collaborative Drug Discovery, 1633 Bayshore Highway, Suite 342, Burlingame, 94010, CA, United States","Over the past decade we have witnessed the increasing sophistication of machine learning algorithms applied in daily use from internet searches, voice recognition, social network software to machine vision software in cameras, phones, robots and self-driving cars. Pharmaceutical research has also seen its fair share of machine learning developments. For example, applying such methods to mine the growing datasets that are created in drug discovery not only enables us to learn from the past but to predict a molecule’s properties and behavior in future. The latest machine learning algorithm garnering significant attention is deep learning, which is an artificial neural network with multiple hidden layers. Publications over the last 3 years suggest that this algorithm may have advantages over previous machine learning methods and offer a slight but discernable edge in predictive performance. The time has come for a balanced review of this technique but also to apply machine learning methods such as deep learning across a wider array of endpoints relevant to pharmaceutical research for which the datasets are growing such as physicochemical property prediction, formulation prediction, absorption, distribution, metabolism, excretion and toxicity (ADME/Tox), target prediction and skin permeation, etc. We also show that there are many potential applications of deep learning beyond cheminformatics. It will be important to perform prospective testing (which has been carried out rarely to date) in order to convince skeptics that there will be benefits from investing in this technique. © 2016, Springer Science+Business Media New York.","artificial intelligence; deep Learning; drug discovery; machine learning; pharmaceutics","Algorithms; Drug Discovery; Machine Learning; Neural Networks (Computer); Pharmaceutical Research; Software; Article; artificial neural network; bioinformatics; drug development; human; machine learning; nonhuman; pharmaceutics; priority journal; quantitative structure activity relation; support vector machine; algorithm; drug research; procedures; software","Springer New York LLC","07248741","","PHREE","27599991","Article","Scopus","2-s2.0-84986243956"
"Blein-Nicolas M.; Zivy M.","Blein-Nicolas, Mélisande (55357799900); Zivy, Michel (6603857783)","55357799900; 6603857783","Thousand and one ways to quantify and compare protein abundances in label-free bottom-up proteomics","2016","Biochimica et Biophysica Acta - Proteins and Proteomics","56","10.1016/j.bbapap.2016.02.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961231161&doi=10.1016%2fj.bbapap.2016.02.019&partnerID=40&md5=88ec35b1b079c12d02ef7dc452e24d7c","GQE-Le Moulon, INRA, Univ Paris-Sud, CNRS, AgroParisTech, Université Paris-Saclay, Gif-sur-Yvette, F-91190, France","Blein-Nicolas M., GQE-Le Moulon, INRA, Univ Paris-Sud, CNRS, AgroParisTech, Université Paris-Saclay, Gif-sur-Yvette, F-91190, France; Zivy M., GQE-Le Moulon, INRA, Univ Paris-Sud, CNRS, AgroParisTech, Université Paris-Saclay, Gif-sur-Yvette, F-91190, France","How to process and analyze MS data to quantify and statistically compare protein abundances in bottom-up proteomics has been an open debate for nearly fifteen years. Two main approaches are generally used: the first is based on spectral data generated during the process of identification (e.g. peptide counting, spectral counting), while the second makes use of extracted ion currents to quantify chromatographic peaks and infer protein abundances based on peptide quantification. These two approaches actually refer to multiple methods which have been developed during the last decade, but were submitted to deep evaluations only recently. In this paper, we compiled these different methods as exhaustively as possible. We also summarized the way they address the different problems raised by bottom-up protein quantification such as normalization, the presence of shared peptides, unequal peptide measurability and missing data. This article is part of a Special Issue entitled: Plant Proteomics— a bridge between fundamental processes and crop production, edited by Dr. Hans-Peter Mock. © 2016 Elsevier B.V.","Data processing; Mass spectrometry; Peptide; Statistics","Crops, Agricultural; Mass Spectrometry; Peptides; Plant Proteins; Proteomics; peptide; plant protein; Article; consensus; crop production; hydrophobicity; isoelectric point; machine learning; molecular weight; nonhuman; peptide counting; principal component analysis; priority journal; protein analysis; protein expression; proteomics; quantitative analysis; reproducibility; signal noise ratio; spectral counting; statistical analysis; statistical model; transcriptomics; chemistry; crop; mass spectrometry; metabolism; procedures; proteomics","Elsevier B.V.","15709639","","BBAPB","26947242","Article","Scopus","2-s2.0-84961231161"
"Cao L.; Jiang Q.; Cheng M.; Wang C.","Cao, Liujuan (35749499000); Jiang, Qilin (57190285773); Cheng, Ming (55711573900); Wang, Cheng (36990982800)","35749499000; 57190285773; 55711573900; 36990982800","Robust vehicle detection by combining deep features with exemplar classification","2016","Neurocomputing","20","10.1016/j.neucom.2016.03.094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978805832&doi=10.1016%2fj.neucom.2016.03.094&partnerID=40&md5=0d6e0da05ea7fe34ac85de48a2f41d15","Fujian Key Laboratory of Sensing and Computing for Smart City, Fujian, China; School of Information Science and Engineering, Xiamen University, Xiamen, China","Cao L., Fujian Key Laboratory of Sensing and Computing for Smart City, Fujian, China, School of Information Science and Engineering, Xiamen University, Xiamen, China; Jiang Q., Fujian Key Laboratory of Sensing and Computing for Smart City, Fujian, China, School of Information Science and Engineering, Xiamen University, Xiamen, China; Cheng M., Fujian Key Laboratory of Sensing and Computing for Smart City, Fujian, China, School of Information Science and Engineering, Xiamen University, Xiamen, China; Wang C., Fujian Key Laboratory of Sensing and Computing for Smart City, Fujian, China, School of Information Science and Engineering, Xiamen University, Xiamen, China","Very recently, vehicle detection in satellite images has become an emerging research topic with various applications ranging from military to commercial systems. However, it retains as an open problem, mainly due to the complex variations in imaging conditions, object intra-class changes, as well as due to its low-resolution. Coming with the rapid advances in deep learning for feature representation, in this paper we investigate the possibility to exploit deep neural features towards robust vehicle detection. In addition, along with the rapid growth in the data volume, new classification methodology is also demanded to explicitly handle the intra-class variations. In this paper, we propose a vehicle detection framework, which combines Deep Convolutional Neural Network (DNN) based feature learning with Exemplar-SVMs (E-SVMS) based, robust instance classifier to achieve robust vehicle detection in satellite images. In particular, we adopt DNN to learn discriminative image features, which has a high learning capacity. In our practice, the leverage of DNN has achieve significant performance boost by comparing to a serial of handcraft designed features. In addition, we adopt E-SVMs based robust classifier to further improve the classification robustness, which can be considered as an instance-specific metric learning scheme. By conducting extensive experiments with comparisons to a serial of state-of-the-art and alternative works, we further show that the combination of both schemes can benefit from each other to jointly improve the detection accuracy and effectiveness. © 2016 Elsevier B.V.","Deep Neural Network; Exemplar SVMs; Robust classification; SLIC; Superpixel segmentation; Vehicle detection","Classification (of information); Commercial vehicles; Complex networks; Military applications; Military photography; Military vehicles; Neural networks; Object detection; Support vector machines; Tracking (position); Vehicles; Deep neural networks; Exemplar SVMs; Robust classification; SLIC; Superpixel segmentations; Vehicle detection; Article; artificial neural network; classification; controlled study; deep convolutional neural network; exemplar support vector machine; image analysis; learning algorithm; measurement accuracy; motor vehicle; priority journal; satellite imagery; support vector machine; Feature extraction","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84978805832"
"Bocquelet F.; Hueber T.; Girin L.; Savariaux C.; Yvert B.","Bocquelet, Florent (55022905600); Hueber, Thomas (25645997900); Girin, Laurent (6602388299); Savariaux, Christophe (6508351508); Yvert, Blaise (6602521727)","55022905600; 25645997900; 6602388299; 6508351508; 6602521727","Real-Time Control of an Articulatory-Based Speech Synthesizer for Brain Computer Interfaces","2016","PLoS Computational Biology","55","10.1371/journal.pcbi.1005119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999828343&doi=10.1371%2fjournal.pcbi.1005119&partnerID=40&md5=de5ddfcee7f26d1b5a18f30562230bcf","INSERM, BrainTech Laboratory U1205, Grenoble, France; Univ. Grenoble Alpes, BrainTech Laboratory U1205, Grenoble, France; CNRS, GIPSA-Lab, Saint-Martin-d'Hères, France; Univ. Grenoble Alpes, GIPSA-Lab, Saint-Martin-d'Hères, France; INRIA Grenoble Rhône-Alpes, Montbonnot, France","Bocquelet F., INSERM, BrainTech Laboratory U1205, Grenoble, France, Univ. Grenoble Alpes, BrainTech Laboratory U1205, Grenoble, France, CNRS, GIPSA-Lab, Saint-Martin-d'Hères, France, Univ. Grenoble Alpes, GIPSA-Lab, Saint-Martin-d'Hères, France; Hueber T., CNRS, GIPSA-Lab, Saint-Martin-d'Hères, France, Univ. Grenoble Alpes, GIPSA-Lab, Saint-Martin-d'Hères, France; Girin L., Univ. Grenoble Alpes, GIPSA-Lab, Saint-Martin-d'Hères, France, INRIA Grenoble Rhône-Alpes, Montbonnot, France; Savariaux C., CNRS, GIPSA-Lab, Saint-Martin-d'Hères, France, Univ. Grenoble Alpes, GIPSA-Lab, Saint-Martin-d'Hères, France; Yvert B., INSERM, BrainTech Laboratory U1205, Grenoble, France, Univ. Grenoble Alpes, BrainTech Laboratory U1205, Grenoble, France","Restoring natural speech in paralyzed and aphasic people could be achieved using a Brain-Computer Interface (BCI) controlling a speech synthesizer in real-time. To reach this goal, a prerequisite is to develop a speech synthesizer producing intelligible speech in real-time with a reasonable number of control parameters. We present here an articulatory-based speech synthesizer that can be controlled in real-time for future BCI applications. This synthesizer converts movements of the main speech articulators (tongue, jaw, velum, and lips) into intelligible speech. The articulatory-to-acoustic mapping is performed using a deep neural network (DNN) trained on electromagnetic articulography (EMA) data recorded on a reference speaker synchronously with the produced speech signal. This DNN is then used in both offline and online modes to map the position of sensors glued on different speech articulators into acoustic parameters that are further converted into an audio signal using a vocoder. In offline mode, highly intelligible speech could be obtained as assessed by perceptual evaluation performed by 12 listeners. Then, to anticipate future BCI applications, we further assessed the real-time control of the synthesizer by both the reference speaker and new speakers, in a closed-loop paradigm using EMA data recorded in real time. A short calibration period was used to compensate for differences in sensor positions and articulatory differences between new speakers and the reference speaker. We found that real-time synthesis of vowels and consonants was possible with good intelligibility. In conclusion, these results open to future speech BCI applications using such articulatory-based speech synthesizer. © 2016 Bocquelet et al.","","Biofeedback, Psychology; Brain-Computer Interfaces; Communication Aids for Disabled; Computer Systems; Humans; Neural Networks (Computer); Phonetics; Sound Spectrography; Speech Acoustics; Speech Intelligibility; Speech Production Measurement; Audio acoustics; Deep neural networks; Interfaces (computer); Linguistics; Real time control; Speech communication; Speech synthesis; Acoustic mapping; Brain-computer interface applications; Control parameters; Electromagnetic articulography; Natural speech; Offline modes; Real- time; Real-time control; Speech signals; Speech synthesizer; accuracy; acoustics; adult; Article; brain computer interface; calibration; consonant; deep neural network; female; human; human experiment; jaw; lip; machine learning; male; soft palate; speech articulation; tongue; vowel; artificial neural network; biofeedback; communication aid; computer system; devices; phonetics; procedures; sound detection; speech; speech analysis; speech intelligibility; Brain computer interface","Public Library of Science","1553734X","","","27880768","Article","Scopus","2-s2.0-84999828343"
"Du T.; Liao L.; Wu C.H.; Sun B.","Du, Tianchuan (56473340000); Liao, Li (35787422600); Wu, Cathy H. (58071565800); Sun, Bilin (57141375100)","56473340000; 35787422600; 58071565800; 57141375100","Prediction of residue-residue contact matrix for protein-protein interaction with Fisher score features and deep learning","2016","Methods","36","10.1016/j.ymeth.2016.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994577876&doi=10.1016%2fj.ymeth.2016.06.001&partnerID=40&md5=dbbfc3a6828789ffe6d55ac3938fde72","Department of Computer and Information Sciences, University of Delaware, Newark, DE, United States; Center for Bioinformatics & Computational Biology, University of Delaware, Newark, DE, United States","Du T., Department of Computer and Information Sciences, University of Delaware, Newark, DE, United States; Liao L., Department of Computer and Information Sciences, University of Delaware, Newark, DE, United States; Wu C.H., Department of Computer and Information Sciences, University of Delaware, Newark, DE, United States, Center for Bioinformatics & Computational Biology, University of Delaware, Newark, DE, United States; Sun B., Department of Computer and Information Sciences, University of Delaware, Newark, DE, United States","Protein-protein interactions play essential roles in many biological processes. Acquiring knowledge of the residue-residue contact information of two interacting proteins is not only helpful in annotating functions for proteins, but also critical for structure-based drug design. The prediction of the protein residue-residue contact matrix of the interfacial regions is challenging. In this work, we introduced deep learning techniques (specifically, stacked autoencoders) to build deep neural network models to tackled the residue-residue contact prediction problem. In tandem with interaction profile Hidden Markov Models, which was used first to extract Fisher score features from protein sequences, stacked autoencoders were deployed to extract and learn hidden abstract features. The deep learning model showed significant improvement over the traditional machine learning model, Support Vector Machines (SVM), with the overall accuracy increased by 15% from 65.40% to 80.82%. We showed that the stacked autoencoders could extract novel features, which can be utilized by deep neural networks and other classifiers to enhance learning, out of the Fisher score features. It is further shown that deep neural networks have significant advantages over SVM in making use of the newly extracted features. © 2016","Contact matrix; Deep learning; Deep neural networks; Machine learning; Protein-protein interaction; Stacked autoencoders","Amino Acid Sequence; Computational Biology; Machine Learning; Protein Interaction Mapping; Protein Interaction Maps; Software; amino acid sequence; Article; artificial neural network; classifier; computer prediction; data extraction; deep learning; deep neural network; Fisher exact test; hidden Markov model; machine learning; measurement accuracy; priority journal; protein protein interaction; protein residue residue contact; stacked autoencoder; support vector machine; biology; genetics; machine learning; procedures; protein analysis; protein protein interaction; software","Academic Press Inc.","10462023","","MTHDE","27282356","Article","Scopus","2-s2.0-84994577876"
"Karabulut E.M.; Ibrikci T.","Karabulut, Esra Mahsereci (36975809800); Ibrikci, Turgay (25121107400)","36975809800; 25121107400","Discriminative deep belief networks for microarray based cancer classification","2017","Biomedical Research (India)","26","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013287742&partnerID=40&md5=8278a43fa36dd15e5a1fbfc79526ff86","Technical Sciences Vocational School, Gaziantep University, Gaziantep, 27310, Turkey; Department of Electrical-Electronics Engineering, Cukurova University, Adana, 01330, Turkey","Karabulut E.M., Technical Sciences Vocational School, Gaziantep University, Gaziantep, 27310, Turkey; Ibrikci T., Department of Electrical-Electronics Engineering, Cukurova University, Adana, 01330, Turkey","Accurate diagnosis of cancer is of great importance due to the global increase in new cancer cases. Cancer researches show that diagnosis by using microarray gene expression data is more effective compared to the traditional methods. This study presents an extensive evaluation of a variant of Deep Belief Networks - Discriminative Deep Belief Networks (DDBN) - in cancer data analysis. This new neural network architecture consists Restricted Boltzman Machines in each layer. The network is trained in two phases; in the first phase the network weights take their initial values by unsupervised greedy layer-wise technique, and in the second phase the values of the network weights are fine-tuned by back propagation algorithm. We included the test results of the model that is conducted over microarray gene expression data of laryngeal, bladder and colorectal cancer. High dimensionality and imbalanced class distribution are two main problems inherent in the gene expression data. To deal with them, two preprocessing steps are applied; Information Gain for selection of predictive genes, and Synthetic Minority Over-Sampling Technique for oversampling the minority class samples. All the results are compared with the corresponding results of Support Vector Machines which has previously been proved to be robust by machine learning studies. In terms of average values DDBN has outperformed SVM in all metrics with accuracy, sensitivity and specificity values of 0.933, 0.950 and 0.905, respectively. © 2017, Scientific Publishers of India. All rights reserved.","Cancer classification; Discriminative deep belief networks; Feature selection; Gene expression data; Support vector machines","Article; artificial neural network; back propagation; bladder cancer; cancer classification; colorectal cancer; controlled study; diagnostic test accuracy study; discriminative deep belief network; gene expression; human; larynx cancer; measurement accuracy; microarray analysis; sensitivity and specificity; support vector machine","Scientific Publishers of India","0970938X","","BIRSE","","Article","Scopus","2-s2.0-85013287742"
"Liskowski P.; Krawiec K.","Liskowski, Pawel (55826649900); Krawiec, Krzysztof (57195670693)","55826649900; 57195670693","Segmenting Retinal Blood Vessels with Deep Neural Networks","2016","IEEE Transactions on Medical Imaging","758","10.1109/TMI.2016.2546227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011656447&doi=10.1109%2fTMI.2016.2546227&partnerID=40&md5=2a2bf7261ceec7c3694ee4bed9ecfc0f","Institute of Computing Science, Poznan University of Technology, Poznan, Poland","Liskowski P., Institute of Computing Science, Poznan University of Technology, Poznan, Poland; Krawiec K., Institute of Computing Science, Poznan University of Technology, Poznan, Poland","The condition of the vascular network of human eye is an important diagnostic factor in ophthalmology. Its segmentation in fundus imaging is a nontrivial task due to variable size of vessels, relatively low contrast, and potential presence of pathologies like microaneurysms and hemorrhages. Many algorithms, both unsupervised and supervised, have been proposed for this purpose in the past. We propose a supervised segmentation technique that uses a deep neural network trained on a large (up to 400 000) sample of examples preprocessed with global contrast normalization, zero-phase whitening, and augmented using geometric transformations and gamma corrections. Several variants of the method are considered, including structured prediction, where a network classifies multiple pixels simultaneously. When applied to standard benchmarks of fundus imaging, the DRIVE, STARE, and CHASE databases, the networks significantly outperform the previous algorithms on the area under ROC curve measure (up to > 0.99) and accuracy of classification (up to > 0.97). The method is also resistant to the phenomenon of central vessel reflex, sensitive in detection of fine vessels (sensitivity > 0.87), and fares well on pathological cases. © 2016 IEEE.","Classification; deep learning; feature learning; fundus; neural networks; retina; retinopathy; structured prediction; Vessel segmentation","Databases, Factual; Humans; Image Interpretation, Computer-Assisted; Neural Networks (Computer); Retinal Vessels; Supervised Machine Learning; Blood vessels; Classification (of information); Deep learning; Mathematical transformations; Neural networks; Ophthalmology; Feature learning; fundus; retina; retinopathy; Structured prediction; Vessel segmentation; adult; aged; algorithm; anatomical concepts; area under the curve; Article; artificial neural network; blood vessel; controlled study; data base; diagnostic imaging; eye examination; eye fundus; fundus camera; fundus imaging; geometry; human; image analysis; image processing; image segmentation; machine learning; major clinical study; receiver operating characteristic; retina blood vessel; standard; computer assisted diagnosis; factual database; procedures; retina blood vessel; supervised machine learning; Deep neural networks","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","27046869","Article","Scopus","2-s2.0-85011656447"
"Van Valen D.A.; Kudo T.; Lane K.M.; Macklin D.N.; Quach N.T.; DeFelice M.M.; Maayan I.; Tanouchi Y.; Ashley E.A.; Covert M.W.","Van Valen, David A. (26327043800); Kudo, Takamasa (57189466380); Lane, Keara M. (7102659879); Macklin, Derek N. (54955445500); Quach, Nicolas T. (57194009394); DeFelice, Mialy M. (57192177307); Maayan, Inbal (57205431701); Tanouchi, Yu (24765824300); Ashley, Euan A. (7004338939); Covert, Markus W. (6602080065)","26327043800; 57189466380; 7102659879; 54955445500; 57194009394; 57192177307; 57205431701; 24765824300; 7004338939; 6602080065","Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments","2016","PLoS Computational Biology","346","10.1371/journal.pcbi.1005177","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999836246&doi=10.1371%2fjournal.pcbi.1005177&partnerID=40&md5=221e23bf5b359d888cc5c0c0fa1b4b91","Department of Bioengineering, Stanford University, Stanford, California, United States; Department of Chemical and Systems Biology, Stanford University, Stanford, California, United States; Department of Genetics, Stanford University, Stanford, California, United States; Department of Cardiovascular Medicine, Stanford University, Stanford, California, United States","Van Valen D.A., Department of Bioengineering, Stanford University, Stanford, California, United States; Kudo T., Department of Chemical and Systems Biology, Stanford University, Stanford, California, United States; Lane K.M., Department of Bioengineering, Stanford University, Stanford, California, United States; Macklin D.N., Department of Bioengineering, Stanford University, Stanford, California, United States; Quach N.T., Department of Bioengineering, Stanford University, Stanford, California, United States; DeFelice M.M., Department of Bioengineering, Stanford University, Stanford, California, United States; Maayan I., Department of Bioengineering, Stanford University, Stanford, California, United States; Tanouchi Y., Department of Bioengineering, Stanford University, Stanford, California, United States; Ashley E.A., Department of Genetics, Stanford University, Stanford, California, United States, Department of Cardiovascular Medicine, Stanford University, Stanford, California, United States; Covert M.W., Department of Bioengineering, Stanford University, Stanford, California, United States, Department of Chemical and Systems Biology, Stanford University, Stanford, California, United States","Live-cell imaging has opened an exciting window into the role cellular heterogeneity plays in dynamic, living systems. A major critical challenge for this class of experiments is the problem of image segmentation, or determining which parts of a microscope image correspond to which individual cells. Current approaches require many hours of manual curation and depend on approaches that are difficult to share between labs. They are also unable to robustly segment the cytoplasms of mammalian cells. Here, we show that deep convolutional neural networks, a supervised machine learning method, can solve this challenge for multiple cell types across the domains of life. We demonstrate that this approach can robustly segment fluorescent images of cell nuclei as well as phase images of the cytoplasms of individual bacterial and mammalian cells from phase contrast images without the need for a fluorescent cytoplasmic marker. These networks also enable the simultaneous segmentation and identification of different mammalian cell types grown in co-culture. A quantitative comparison with prior methods demonstrates that convolutional neural networks have improved accuracy and lead to a significant reduction in curation time. We relay our experience in designing and optimizing deep convolutional neural networks for this task and outline several design rules that we found led to robust performance. We conclude that deep convolutional neural networks are an accurate method that require less curation time, are generalizable to a multiplicity of cell types, from bacteria to mammalian cells, and expand live-cell imaging capabilities to include multi-cell type systems. © 2016 Van Valen et al.","","Cell Tracking; Image Enhancement; Image Interpretation, Computer-Assisted; Intravital Microscopy; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Cells; Convolution; Cytology; Deep neural networks; Fluorescence; Image segmentation; Supervised learning; Cell types; Cellulars; Convolutional neural network; Critical challenges; Curation; Imaging experiments; Individual cells; Live-cell imaging; Living systems; Mammalian cells; bacterial cell; cell nucleus; coculture; cytoplasm; imaging; intermethod comparison; mammal cell; nervous system; quantitative analysis; quantitative study; supervised machine learning; artificial neural network; automated pattern recognition; cell tracking; computer assisted diagnosis; image enhancement; intravital microscopy; machine learning; procedures; reproducibility; sensitivity and specificity; Mammals","Public Library of Science","1553734X","","","27814364","Article","Scopus","2-s2.0-84999836246"
"Wang X.; Duan X.; Bai X.","Wang, Xinggang (36100811100); Duan, Xiong (57189761371); Bai, Xiang (15130916600)","36100811100; 57189761371; 15130916600","Deep sketch feature for cross-domain image retrieval","2016","Neurocomputing","39","10.1016/j.neucom.2016.04.046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975131375&doi=10.1016%2fj.neucom.2016.04.046&partnerID=40&md5=df5d1dd8cb1de6e63f5b082ab769d65b","School of Electronic Information and Communications, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, 430074, Hubei Province, China","Wang X., School of Electronic Information and Communications, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, 430074, Hubei Province, China; Duan X., School of Electronic Information and Communications, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, 430074, Hubei Province, China; Bai X., School of Electronic Information and Communications, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, 430074, Hubei Province, China","Deep learning has been proven to be very effective for various image recognition tasks, e.g., image classification, semantic segmentation, image retrieval, shape classification, etc. However, existing works on deep learning for image recognition mainly focus on either natural image data or binary shape data. In this paper, we show that deep convolutional neural networks (DCNN) is also suitable for cross-domain image recognition, i.e., using sketch as query to retrieve natural images in a large dataset. To solve this kind of cross-domain problem, we propose to train CNN jointly using image data and sketch data in a novel way. The learned deep feature is effective for cross-domain image retrieval – using simple Euclidean distance on the learned feature can significantly outperform the previous state-of-the-arts. In addition, we find that pre-training and a feasible data-argumentation for DCNN can largely surpass human-level performance in the standard sketch classification benchmark. © 2016 Elsevier B.V.","Deep learning; Image retrieval; Sketch recognition","Benchmarking; Discrete cosine transforms; Image recognition; Image retrieval; Image segmentation; Neural networks; Semantics; Convolutional neural network; Deep learning; Euclidean distance; Human-level performance; Semantic segmentation; Shape classification; Sketch recognition; State of the art; Article; classification; classifier; deep convolutional neural network; drawing; image analysis; image processing; image quality; image retrieval; image segmentation; machine learning; priority journal; semantics; Image classification","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84975131375"
"Meyer S.; Mueller K.; Stuke K.; Bisenius S.; Diehl-Schmid J.; Jessen F.; Kassubek J.; Kornhuber J.; Ludolph A.C.; Prudlo J.; Schneider A.; Schuemberg K.; Yakushev I.; Otto M.; Schroeter M.L.","Meyer, Sebastian (57193651188); Mueller, Karsten (35574245300); Stuke, Katharina (56527042000); Bisenius, Sandrine (56790076000); Diehl-Schmid, Janine (14318959100); Jessen, Frank (7006672877); Kassubek, Jan (7003511907); Kornhuber, Johannes (7007179429); Ludolph, Albert C. (26643359400); Prudlo, Johannes (6602701382); Schneider, Anja (7402385294); Schuemberg, Katharina (56465966400); Yakushev, Igor (57221908730); Otto, Markus (7201539859); Schroeter, Matthias L. (7005735585)","57193651188; 35574245300; 56527042000; 56790076000; 14318959100; 7006672877; 7003511907; 7007179429; 26643359400; 6602701382; 7402385294; 56465966400; 57221908730; 7201539859; 7005735585","Predicting behavioral variant frontotemporal dementia with pattern classification in multi-center structural MRI data","2017","NeuroImage: Clinical","60","10.1016/j.nicl.2017.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015396246&doi=10.1016%2fj.nicl.2017.02.001&partnerID=40&md5=5f398078f0cb8c36bd474885f0061398","Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Clinic for Psychiatry and Psychotherapy, Technical University of Munich, Germany; Clinic for Psychiatry and Psychotherapy, University Bonn, Germany; Clinic for Neurology, University of Ulm, Germany; Department of Psychiatry and Psychotherapy, Friedrich-Alexander-University Erlangen-Nuremberg, Germany; Department of Neurology, Rostock University Medical Center, Rostock, Germany; German Center for Neurodegenerative Diseases (DZNE), Rostock, Germany; Clinic for Psychiatry and Psychotherapy, University of Goettingen, Germany; Clinic for Nuclear Medicine, Technical University of Munich, Germany; Clinic for Cognitive Neurology, University Hospital Leipzig, Germany","Meyer S., Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Mueller K., Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Stuke K., Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Bisenius S., Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Diehl-Schmid J., Clinic for Psychiatry and Psychotherapy, Technical University of Munich, Germany; Jessen F., Clinic for Psychiatry and Psychotherapy, University Bonn, Germany; Kassubek J., Clinic for Neurology, University of Ulm, Germany; Kornhuber J., Department of Psychiatry and Psychotherapy, Friedrich-Alexander-University Erlangen-Nuremberg, Germany; Ludolph A.C., Clinic for Neurology, University of Ulm, Germany; Prudlo J., Department of Neurology, Rostock University Medical Center, Rostock, Germany, German Center for Neurodegenerative Diseases (DZNE), Rostock, Germany; Schneider A., Clinic for Psychiatry and Psychotherapy, University of Goettingen, Germany; Schuemberg K., Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Yakushev I., Clinic for Nuclear Medicine, Technical University of Munich, Germany; Otto M., Clinic for Neurology, University of Ulm, Germany; Schroeter M.L., Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany, Clinic for Cognitive Neurology, University Hospital Leipzig, Germany","Purpose Frontotemporal lobar degeneration (FTLD) is a common cause of early onset dementia. Behavioral variant frontotemporal dementia (bvFTD), its most common subtype, is characterized by deep alterations in behavior and personality. In 2011, new diagnostic criteria were suggested that incorporate imaging criteria into diagnostic algorithms. The study aimed at validating the potential of imaging criteria to individually predict diagnosis with machine learning algorithms. Materials & methods Brain atrophy was measured with structural magnetic resonance imaging (MRI) at 3 Tesla in a multi-centric cohort of 52 bvFTD patients and 52 healthy control subjects from the German FTLD Consortium's Study. Beside group comparisons, diagnosis bvFTD vs. controls was individually predicted in each subject with support vector machine classification in MRI data across the whole brain or in frontotemporal, insular regions, and basal ganglia known to be mainly affected based on recent meta-analyses. Multi-center effects were controlled for with a new method, “leave one center out” conjunction analyses, i.e. repeatedly excluding subjects from each center from the analysis. Results Group comparisons revealed atrophy in, most consistently, the frontal lobe in bvFTD beside alterations in the insula, basal ganglia and temporal lobe. Most remarkably, support vector machine classification enabled predicting diagnosis in single patients with a high accuracy of up to 84.6%, where accuracy was highest in a region-of-interest approach focusing on frontotemporal, insular regions, and basal ganglia in comparison with the whole brain approach. Conclusion Our study demonstrates that MRI, a widespread imaging technology, can individually identify bvFTD with high accuracy in multi-center imaging data, paving the road to personalized diagnostic approaches in the future. © 2017 The Authors","Atrophy; Behavioral variant frontotemporal dementia; Diagnostic criteria; Frontotemporal lobar degeneration; MRI; Pattern classification","Aged; Atrophy; Brain; Brain Mapping; Cohort Studies; Female; Frontotemporal Dementia; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Predictive Value of Tests; Support Vector Machine; adult; amygdala; angular gyrus; anterior cingulate; Article; basal ganglion; brain atrophy; cerebellum; cohort analysis; comparative study; controlled study; female; frontal lobe; frontal variant frontotemporal dementia; globus pallidus; human; insula; major clinical study; male; middle aged; middle temporal gyrus; nuclear magnetic resonance imaging; nucleus accumbens; postcentral gyrus; primary motor cortex; priority journal; putamen; sensitivity and specificity; support vector machine; supramarginal gyrus; temporal cortex; temporal lobe; aged; atrophy; brain; brain mapping; clinical trial; diagnostic imaging; frontotemporal dementia; image processing; multicenter study; pathology; pathophysiology; predictive value; procedures","Elsevier Inc.","22131582","","","28348957","Article","Scopus","2-s2.0-85015396246"
"Ravi D.; Wong C.; Deligianni F.; Berthelot M.; Andreu-Perez J.; Lo B.; Yang G.-Z.","Ravi, Daniele (57201696886); Wong, Charence (7404953598); Deligianni, Fani (6506096408); Berthelot, Melissa (57014873400); Andreu-Perez, Javier (55653526300); Lo, Benny (15834859900); Yang, Guang-Zhong (55539304100)","57201696886; 7404953598; 6506096408; 57014873400; 55653526300; 15834859900; 55539304100","Deep Learning for Health Informatics","2017","IEEE Journal of Biomedical and Health Informatics","1299","10.1109/JBHI.2016.2636665","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014952213&doi=10.1109%2fJBHI.2016.2636665&partnerID=40&md5=97a54622283c57870922c78af5037c9c","Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom","Ravi D., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Wong C., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Deligianni F., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Berthelot M., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Andreu-Perez J., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Lo B., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Yang G.-Z., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom","With a massive influx of multimodality data, the role of data analytics in health informatics has grown rapidly in the last decade. This has also prompted increasing interests in the generation of analytical, data driven models based on machine learning in health informatics. Deep learning, a technique with its foundation in artificial neural networks, is emerging in recent years as a powerful tool for machine learning, promising to reshape the future of artificial intelligence. Rapid improvements in computational power, fast data storage, and parallelization have also contributed to the rapid uptake of the technology in addition to its predictive power and ability to generate automatically optimized high-level features and semantic interpretation from the input data. This article presents a comprehensive up-to-date review of research employing deep learning in health informatics, providing a critical analysis of the relative merit, and potential pitfalls of the technique as well as its future outlook. The paper mainly focuses on key applications of deep learning in the fields of translational bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health. © 2013 IEEE.","Bioinformatics; deep learning; health informatics; machine learning; medical imaging; public health; wearable devices","Computational Biology; Humans; Machine Learning; Medical Informatics; Monitoring, Ambulatory; Public Health; Bioinformatics; Data Analytics; Digital storage; Learning systems; Medical imaging; Medical informatics; Public health; Semantics; Computational power; Critical analysis; Data-driven model; High-level features; Parallelizations; Pervasive sensing; Semantic interpretation; Wearable devices; artificial intelligence; artificial neural network; bioinformatics; diagnostic imaging; machine learning; medical informatics; ambulatory monitoring; biology; human; medical informatics; procedures; public health; Deep learning","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28055930","Article","Scopus","2-s2.0-85014952213"
"Ma T.; Li H.; Yang H.; Lv X.; Li P.; Liu T.; Yao D.; Xu P.","Ma, Teng (56443263100); Li, Hui (57847144300); Yang, Hao (57191995169); Lv, Xulin (56747111200); Li, Peiyang (55585509900); Liu, Tiejun (55727725200); Yao, Dezhong (55558568500); Xu, Peng (56939689500)","56443263100; 57847144300; 57191995169; 56747111200; 55585509900; 55727725200; 55558568500; 56939689500","The extraction of motion-onset VEP BCI features based on deep learning and compressed sensing","2017","Journal of Neuroscience Methods","66","10.1016/j.jneumeth.2016.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995757605&doi=10.1016%2fj.jneumeth.2016.11.002&partnerID=40&md5=87898a9cb4bac70db444a866c24e25bc","Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China; Center for Information in BioMedicine, University of Electronic Science and Technology of China, Chengdu, 610054, China","Ma T., Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China; Li H., Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China; Yang H., Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China; Lv X., Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China; Li P., Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China; Liu T., Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China, Center for Information in BioMedicine, University of Electronic Science and Technology of China, Chengdu, 610054, China; Yao D., Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China, Center for Information in BioMedicine, University of Electronic Science and Technology of China, Chengdu, 610054, China; Xu P., Key Laboratory for NeuroInformation of Ministry of Education, School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, 610054, China, Center for Information in BioMedicine, University of Electronic Science and Technology of China, Chengdu, 610054, China","Background Motion-onset visual evoked potentials (mVEP) can provide a softer stimulus with reduced fatigue, and it has potential applications for brain computer interface(BCI)systems. However, the mVEP waveform is seriously masked in the strong background EEG activities, and an effective approach is needed to extract the corresponding mVEP features to perform task recognition for BCI control. New method In the current study, we combine deep learning with compressed sensing to mine discriminative mVEP information to improve the mVEP BCI performance. Results The deep learning and compressed sensing approach can generate the multi-modality features which can effectively improve the BCI performance with approximately 3.5% accuracy incensement over all 11 subjects and is more effective for those subjects with relatively poor performance when using the conventional features. Comparison with existing methods Compared with the conventional amplitude-based mVEP feature extraction approach, the deep learning and compressed sensing approach has a higher classification accuracy and is more effective for subjects with relatively poor performance. Conclusions According to the results, the deep learning and compressed sensing approach is more effective for extracting the mVEP feature to construct the corresponding BCI system, and the proposed feature extraction framework is easy to extend to other types of BCIs, such as motor imagery (MI), steady-state visual evoked potential (SSVEP)and P300. © 2016 Elsevier B.V.","Brain computer interface; Compressed sensing; Deep learning; Motion-onset VEP; Multi-modality feature","Brain; Brain-Computer Interfaces; Electroencephalography; Evoked Potentials, Visual; Female; Humans; Machine Learning; Male; Motion Perception; Signal Processing, Computer-Assisted; Young Adult; accuracy; adult; Article; brain computer interface; clinical article; decomposition; electroencephalogram; extraction; female; genetic algorithm; human; learning; male; motion; priority journal; recognition; task performance; visual evoked potential; waveform; young adult; brain; electroencephalography; machine learning; movement perception; physiology; procedures; signal processing; visual evoked potential","Elsevier B.V.","01650270","","JNMED","27845150","Article","Scopus","2-s2.0-84995757605"
"Kooi T.; Litjens G.; van Ginneken B.; Gubern-Mérida A.; Sánchez C.I.; Mann R.; den Heeten A.; Karssemeijer N.","Kooi, Thijs (41261813100); Litjens, Geert (36622356600); van Ginneken, Bram (55759608800); Gubern-Mérida, Albert (42261661300); Sánchez, Clara I. (8543425100); Mann, Ritse (23397838900); den Heeten, Ard (6506696213); Karssemeijer, Nico (24332021400)","41261813100; 36622356600; 55759608800; 42261661300; 8543425100; 23397838900; 6506696213; 24332021400","Large scale deep learning for computer aided detection of mammographic lesions","2017","Medical Image Analysis","730","10.1016/j.media.2016.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980350859&doi=10.1016%2fj.media.2016.07.007&partnerID=40&md5=3fa22e532f7aff5ecb2f02fbe7d9dfb0","Diagnostic Image Analysis Group, Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands; Department of Radiology, University Medical Centre Amsterdam, Amsterdam, Netherlands","Kooi T., Diagnostic Image Analysis Group, Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands; Litjens G., Diagnostic Image Analysis Group, Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands; van Ginneken B., Diagnostic Image Analysis Group, Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands; Gubern-Mérida A., Diagnostic Image Analysis Group, Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands; Sánchez C.I., Diagnostic Image Analysis Group, Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands; Mann R., Diagnostic Image Analysis Group, Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands; den Heeten A., Department of Radiology, University Medical Centre Amsterdam, Amsterdam, Netherlands; Karssemeijer N., Diagnostic Image Analysis Group, Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands","Recent advances in machine learning yielded new techniques to train deep neural networks, which resulted in highly successful applications in many pattern recognition tasks such as object detection and speech recognition. In this paper we provide a head-to-head comparison between a state-of-the art in mammography CAD system, relying on a manually designed feature set and a Convolutional Neural Network (CNN), aiming for a system that can ultimately read mammograms independently. Both systems are trained on a large data set of around 45,000 images and results show the CNN outperforms the traditional CAD system at low sensitivity and performs comparable at high sensitivity. We subsequently investigate to what extent features such as location and patient information and commonly used manual features can still complement the network and see improvements at high specificity over the CNN especially with location and context features, which contain information not available to the CNN. Additionally, a reader study was performed, where the network was compared to certified screening radiologists on a patch level and we found no significant difference between the network and the readers. © 2016 Elsevier B.V.","Breast cancer; Computer aided detection; Convolutional neural networks; Deep learning; Machine learning; Mammography","Breast; Breast Neoplasms; Humans; Machine Learning; Mammography; Neural Networks (Computer); Radiographic Image Interpretation, Computer-Assisted; Sensitivity and Specificity; Artificial intelligence; Computer aided instruction; Convolution; Learning systems; Mammography; Neural networks; Pattern recognition; Speech recognition; Breast Cancer; Computer aided detection; Convolutional neural network; Deep learning; Deep neural networks; High sensitivity; High specificity; Patient information; Article; comparative study; computer aided design; controlled study; convolutional neural network; digital mammography; human; machine learning; major clinical study; patient information; priority journal; radiologist; sensitivity analysis; support vector machine; artificial neural network; breast; breast tumor; computer assisted diagnosis; diagnostic imaging; mammography; pathology; procedures; sensitivity and specificity; Computer aided diagnosis","Elsevier B.V.","13618415","","MIAEC","27497072","Article","Scopus","2-s2.0-84980350859"
"Dürr O.; Sick B.","Dürr, Oliver (22943371200); Sick, Beate (7003387576)","22943371200; 7003387576","Single-cell phenotype classification using deep convolutional neural networks","2016","Journal of Biomolecular Screening","65","10.1177/1087057116631284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988526163&doi=10.1177%2f1087057116631284&partnerID=40&md5=23ca2256b7b215765d5934641480747a","Zurich University of Applied Sciences, School of Engineering, Rosenstrasse 3, Winterthur, 8401, Switzerland","Dürr O., Zurich University of Applied Sciences, School of Engineering, Rosenstrasse 3, Winterthur, 8401, Switzerland; Sick B., Zurich University of Applied Sciences, School of Engineering, Rosenstrasse 3, Winterthur, 8401, Switzerland","Deep learning methods are currently outperforming traditional state-of-the-art computer vision algorithms in diverse applications and recently even surpassed human performance in object recognition. Here we demonstrate the potential of deep learning methods to high-content screening-based phenotype classification. We trained a deep learning classifier in the form of convolutional neural networks with approximately 40,000 publicly available single-cell images from samples treated with compounds from four classes known to lead to different phenotypes. The input data consisted of multichannel images. The construction of appropriate feature definitions was part of the training and carried out by the convolutional network, without the need for expert knowledge or handcrafted features. We compare our results against the recent state-of-the-art pipeline in which predefined features are extracted from each cell using specialized software and then fed into various machine learning algorithms (support vector machine, Fisher linear discriminant, random forest) for classification. The performance of all classification approaches is evaluated on an untouched test image set with known phenotype classes. Compared to the best reference machine learning algorithm, the misclassification rate is reduced from 8.9% to 6.6%. © Society for Laboratory Automation and Screening.","cell-based assays; deep learning; high-content screening; single-cell classification","Algorithms; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Single-Cell Analysis; Software; Support Vector Machine; cardenolide; digoxin; fenbendazole; fluphenazine; lanatoside C; metoclopramide; oxibendazole; paclitaxel; peruvoside; procaine; algorithm; Article; cell nucleus; controlled study; deep convolutional neural network; discriminant analysis; drug mechanism; endoplasmic reticulum; Golgi complex; human; learning; machine learning; mitochondrion; nerve cell network; object relation; pattern recognition; phenotype; priority journal; random forest; support vector machine; artificial neural network; image processing; procedures; single cell analysis; software; statistics and numerical data","SAGE Publications Inc.","10870571","","JBISF","26950929","Article","Scopus","2-s2.0-84988526163"
"Hamanaka M.; Taneishi K.; Iwata H.; Ye J.; Pei J.; Hou J.; Okuno Y.","Hamanaka, Masatoshi (35253968400); Taneishi, Kei (12777775200); Iwata, Hiroaki (56526057000); Ye, Jun (57190581218); Pei, Jianguo (57190584255); Hou, Jinlong (57188576506); Okuno, Yasushi (7202193433)","35253968400; 12777775200; 56526057000; 57190581218; 57190584255; 57188576506; 7202193433","CGBVS-DNN: Prediction of Compound-protein Interactions Based on Deep Learning","2017","Molecular Informatics","56","10.1002/minf.201600045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981328261&doi=10.1002%2fminf.201600045&partnerID=40&md5=fb790a79e011e19db151dbb96d614b59","Graduate School of Medicine, Kyoto University, Shogoin-kawaharacho, city/>Sakyo-ku Kyoto, 606-8507, Japan; Advanced Institute for Computational Science, RIKEN, 7-1-28, Minatojima-minami-machi, Chuo-ku, Kobe, Hyogo, 650-0047, Japan; Foundation for Biomedical Research and Innovation, 1-6-5, Minatojima-Minamimachi Chuo-ku, Kobe, 650-0047, Japan; Software and Services Group, Intel Corporation, Shanghai, China","Hamanaka M., Graduate School of Medicine, Kyoto University, Shogoin-kawaharacho, city/>Sakyo-ku Kyoto, 606-8507, Japan; Taneishi K., Advanced Institute for Computational Science, RIKEN, 7-1-28, Minatojima-minami-machi, Chuo-ku, Kobe, Hyogo, 650-0047, Japan; Iwata H., Foundation for Biomedical Research and Innovation, 1-6-5, Minatojima-Minamimachi Chuo-ku, Kobe, 650-0047, Japan; Ye J., Software and Services Group, Intel Corporation, Shanghai, China; Pei J., Software and Services Group, Intel Corporation, Shanghai, China; Hou J., Software and Services Group, Intel Corporation, Shanghai, China; Okuno Y., Graduate School of Medicine, Kyoto University, Shogoin-kawaharacho, city/>Sakyo-ku Kyoto, 606-8507, Japan","Computational prediction of compound-protein interactions (CPIs) is of great importance for drug design as the first step in in-silico screening. We previously proposed chemical genomics-based virtual screening (CGBVS), which predicts CPIs by using a support vector machine (SVM). However, the CGBVS has problems when training using more than a million datasets of CPIs since SVMs require an exponential increase in the calculation time and computer memory. To solve this problem, we propose the CGBVS-DNN, in which we use deep neural networks, a kind of deep learning technique, instead of the SVM. Deep learning does not require learning all input data at once because the network can be trained with small mini-batches. Experimental results show that the CGBVS-DNN outperformed the original CGBVS with a quarter million CPIs. Results of cross-validation show that the accuracy of the CGBVS-DNN reaches up to 98.2 % (σ<0.01) with 4 million CPIs. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","chemical genomics-based virtual screening (cgbvs); compound-protein interactions (cpis); deep learning; in-silico screening; support vector machine","Binding Sites; Machine Learning; Molecular Docking Simulation; Protein Binding; Proteome; Software; Deep neural networks; E-learning; Proteins; Support vector machines; chemical compound; protein; protein binding; proteome; Chemical genomic-based virtual screening; Compound-protein interaction; Computational predictions; Deep learning; Drug Design; Genomics; In-silico screening; Protein interaction; Support vectors machine; Virtual Screening; Article; binding affinity; chemical genomics based virtual screening; compound protein interaction; computer memory; computer model; computer prediction; drug protein binding; drug screening; genomics; machine learning; priority journal; protein interaction; support vector machine; virtual reality; binding site; chemistry; metabolism; molecular docking; procedures; software; standards; Genome","Wiley-VCH Verlag","18681743","","MIONB","27515489","Article","Scopus","2-s2.0-84981328261"
"Lake B.M.; Ullman T.D.; Tenenbaum J.B.; Gershman S.J.","Lake, Brenden M. (56123187100); Ullman, Tomer D. (38461789300); Tenenbaum, Joshua B. (7006818404); Gershman, Samuel J. (35108983800)","56123187100; 38461789300; 7006818404; 35108983800","Building machines that learn and think like people","2017","Behavioral and Brain Sciences","1218","10.1017/S0140525X16001837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996868095&doi=10.1017%2fS0140525X16001837&partnerID=40&md5=832c562ef0aa364c55edd9bee453a867","Department of Psychology and Center for Data Science, New York University, New York, 10011, NY, United States; Department of Brain and Cognitive Sciences, Center for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States; Department of Psychology and Center for Brain Science, Harvard University, Cambridge, 02138, MA, United States; Center for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States","Lake B.M., Department of Psychology and Center for Data Science, New York University, New York, 10011, NY, United States; Ullman T.D., Department of Brain and Cognitive Sciences, Center for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States; Tenenbaum J.B., Department of Psychology and Center for Brain Science, Harvard University, Cambridge, 02138, MA, United States; Gershman S.J., Department of Psychology and Center for Brain Science, Harvard University, Cambridge, 02138, MA, United States, Center for Brains, Minds and Machines, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States","Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models. © 2017 Cambridge University Press.","","Achievement; Artificial Intelligence; Humans; Intelligence; Neural Networks (Computer); Thinking; Visual Perception; Article; artificial intelligence; causality; cognition; human; language; learning; achievement; artificial neural network; intelligence; thinking; vision","Cambridge University Press","0140525X","","BBSCD","27881212","Article","Scopus","2-s2.0-84996868095"
"Duan G.; Hu W.; Wang J.","Duan, Ganglong (56217509500); Hu, Wenxiu (25632346500); Wang, Jianren (35729623900)","56217509500; 25632346500; 35729623900","Research on the natural image super-resolution reconstruction algorithm based on compressive perception theory and deep learning model","2016","Neurocomputing","20","10.1016/j.neucom.2015.12.125","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986570783&doi=10.1016%2fj.neucom.2015.12.125&partnerID=40&md5=1f5de4c9e3a88279c71d83acc52e9ecb","Xi׳an University of Technology, 710054, Shaanxi, China","Duan G., Xi׳an University of Technology, 710054, Shaanxi, China; Hu W., Xi׳an University of Technology, 710054, Shaanxi, China; Wang J., Xi׳an University of Technology, 710054, Shaanxi, China","With the bursting development of machine learning and artificial intelligence, the pattern recognition based image processing techniques are growing faster than ever before. In this paper, we conduct theoretical analysis on the natural image super-resolution reconstruction algorithm based on compressive perception theory and deep learning model. The image restoration is the purpose of the degraded image processing which make its recovery as it had been before the degradation of ideal image. According to the views of Fourier optics, optical imaging system is a low pass filter, due to the general influence of optical diffraction. The deep neural network with hierarchical unsupervised training method stratified greed training beforehand matter will be the result of the training as the novel learning supervision probability model of the initial value to make good use of the optical imaging system. The adopted compressed sensing theory points out that as long as signal is compressible or sparse, so, if there is a transformation matrix is not related observation matrix on signal can directly obtain compressed form of the original signal. Our research adopts the advances of the mentioned technique, in the training step, we use deep neural network to automatically capture the features and in the reconstruction procedure we use the compressive sensing and dictionary learning theory to reconstruct the high resolution image. By enhancing both of the steps, our experimental result indicates the feasibility of the novel algorithm. The prospect is also discussed in the final part. © 2016 Elsevier B.V.","Compressive perception and sensing; Deep learning model; Image restoration; Image super-resolution; Natural images; Neural network structure; Optimization","Algorithms; Artificial intelligence; Compressed sensing; Discrete cosine transforms; Image reconstruction; Imaging systems; Imaging techniques; Learning algorithms; Learning systems; Linear transformations; Low pass filters; Optical data processing; Optical image storage; Optical resolving power; Optimization; Pattern recognition; Restoration; Signal reconstruction; Structural optimization; Compressive perception and sensing; Deep learning; Image super resolutions; Natural images; Neural network structures; Article; artificial neural network; compressive perception theory; controlled study; deep learning model; feasibility study; image processing; image reconstruction; imaging system; measurement accuracy; measurement precision; natural image super resolution reconstruction algorithm; normal distribution; priority journal; probability; simulation; theory; Image processing","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84986570783"
"Annunziata R.; Trucco E.","Annunziata, Roberto (56647818600); Trucco, Emanuele (57201786780)","56647818600; 57201786780","Accelerating Convolutional Sparse Coding for Curvilinear Structures Segmentation by Refining SCIRD-TS Filter Banks","2016","IEEE Transactions on Medical Imaging","36","10.1109/TMI.2016.2570123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994494435&doi=10.1109%2fTMI.2016.2570123&partnerID=40&md5=a65992bcd5e3f7bedb72b31982acb412","School of Science and Engineering, University of Dundee, Dundee, DD14HN, United Kingdom","Annunziata R., School of Science and Engineering, University of Dundee, Dundee, DD14HN, United Kingdom; Trucco E., School of Science and Engineering, University of Dundee, Dundee, DD14HN, United Kingdom","Deep learning has shown great potential for curvilinear structure (e.g., retinal blood vessels and neurites) segmentation as demonstrated by a recent auto-context regression architecture based on filter banks learned by convolutional sparse coding. However, learning such filter banks is very time-consuming, thus limiting the amount of filters employed and the adaptation to other data sets (i.e., slow re-training). We address this limitation by proposing a novel acceleration strategy to speed-up convolutional sparse coding filter learning for curvilinear structure segmentation. Our approach is based on a novel initialisation strategy (warm start), and therefore it is different from recent methods improving the optimisation itself. Our warm-start strategy is based on carefully designed hand-crafted filters (SCIRD-TS), modelling appearance properties of curvilinear structures which are then refined by convolutional sparse coding. Experiments on four diverse data sets, including retinal blood vessels and neurites, suggest that the proposed method reduces significantly the time taken to learn convolutional filter banks (i.e., up to-82%) compared to conventional initialisation strategies. Remarkably, this speed-up does not worsen performance; in fact, filters learned with the proposed strategy often achieve a much lower reconstruction error and match or exceed the segmentation performance of random and DCT-based initialisation, when used as input to a random forest classifier. © 2016 IEEE.","Convolutional sparse coding; neurites; retinal blood vessels; segmentation","Algorithms; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Neural Networks (Computer); Neurites; Retinal Vessels; Bandpass filters; Calcification (biochemistry); Codes (symbols); Convolution; Decision trees; Filter banks; Image segmentation; Ophthalmology; Acceleration strategies; Curvilinear structures; Neurites; Random forest classifier; Reconstruction error; Retinal blood vessels; Segmentation performance; Sparse coding; Article; filter; fundus camera; human; image filter; image processing; image reconstruction; machine learning; model; neurite; random forest; retina blood vessel; algorithm; artificial neural network; computer assisted diagnosis; diagnostic imaging; physiology; procedures; Blood vessels","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","27214893","Article","Scopus","2-s2.0-84994494435"
"Adel T.; Cohen T.; Caan M.; Welling M.","Adel, Tameem (57192975847); Cohen, Taco (7202415785); Caan, Matthan (55908175900); Welling, Max (55907170700)","57192975847; 7202415785; 55908175900; 55907170700","3D scattering transforms for disease classification in neuroimaging","2017","NeuroImage: Clinical","4","10.1016/j.nicl.2017.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014419253&doi=10.1016%2fj.nicl.2017.02.004&partnerID=40&md5=ab0c96114f1470b8fba7f0e880abfa5d","Machine Learning Lab, University of Amsterdam, Netherlands; Scyfer B. V., Amsterdam, Netherlands; Department of Radiology, Academic Medical Center (AMC), University of Amsterdam, Netherlands","Adel T., Machine Learning Lab, University of Amsterdam, Netherlands; Cohen T., Machine Learning Lab, University of Amsterdam, Netherlands, Scyfer B. V., Amsterdam, Netherlands; Caan M., Department of Radiology, Academic Medical Center (AMC), University of Amsterdam, Netherlands; Welling M., Machine Learning Lab, University of Amsterdam, Netherlands, Scyfer B. V., Amsterdam, Netherlands","Classifying neurodegenerative brain diseases in MRI aims at correctly assigning discrete labels to MRI scans. Such labels usually refer to a diagnostic decision a learner infers based on what it has learned from a training sample of MRI scans. Classification from MRI voxels separately typically does not provide independent evidence towards or against a class; the information relevant for classification is only present in the form of complicated multivariate patterns (or “features”). Deep learning solves this problem by learning a sequence of non-linear transformations that result in feature representations that are better suited to classification. Such learned features have been shown to drastically outperform hand-engineered features in computer vision and audio analysis domains. However, applying the deep learning approach to the task of MRI classification is extremely challenging, because it requires a very large amount of data which is currently not available. We propose to instead use a three dimensional scattering transform, which resembles a deep convolutional neural network but has no learnable parameters. Furthermore, the scattering transform linearizes diffeomorphisms (due to e.g. residual anatomical variability in MRI scans), making the different disease states more easily separable using a linear classifier. In experiments on brain morphometry in Alzheimer's disease, and on white matter microstructural damage in HIV, scattering representations are shown to be highly effective for the task of disease classification. For instance, in semi-supervised learning of progressive versus stable MCI, we reach an accuracy of 82.7%. We also present a visualization method to highlight areas that provide evidence for or against a certain class, both on an individual and group level. © 2017 The Authors","Feature extraction; MRI classification; Scattering representation","Algorithms; Brain; Brain Mapping; Cohort Studies; Databases, Factual; Female; HIV Infections; Humans; Imaging, Three-Dimensional; Machine Learning; Magnetic Resonance Imaging; Male; Neurodegenerative Diseases; Principal Component Analysis; ROC Curve; adult; Alzheimer disease; Article; brain size; computer; controlled study; diagnostic accuracy; diffusion weighted imaging; disease classification; fractional anisotropy; gray matter; human; Human immunodeficiency virus infection; independent component analysis; major clinical study; mild cognitive impairment; morphometry; nerve cell network; neuroimaging; nuclear magnetic resonance scanner; principal component analysis; priority journal; sound analysis; support vector machine; three dimensional imaging; vision; white matter; algorithm; brain; brain mapping; classification; cohort analysis; complication; degenerative disease; diagnostic imaging; factual database; female; machine learning; male; nuclear magnetic resonance imaging; receiver operating characteristic; statistics and numerical data","Elsevier Inc.","22131582","","","28289601","Article","Scopus","2-s2.0-85014419253"
"Buggenthin F.; Buettner F.; Hoppe P.S.; Endele M.; Kroiss M.; Strasser M.; Schwarzfischer M.; Loeffler D.; Kokkaliaris K.D.; Hilsenbeck O.; Schroeder T.; Theis F.J.; Marr C.","Buggenthin, Felix (35589534500); Buettner, Florian (23099125500); Hoppe, Philipp S. (55748392100); Endele, Max (35310217600); Kroiss, Manuel (57193342443); Strasser, Michael (54883884900); Schwarzfischer, Michael (54793536400); Loeffler, Dirk (54789039100); Kokkaliaris, Konstantinos D. (42261999700); Hilsenbeck, Oliver (55871457800); Schroeder, Timm (7202054176); Theis, Fabian J. (6701364934); Marr, Carsten (10539477500)","35589534500; 23099125500; 55748392100; 35310217600; 57193342443; 54883884900; 54793536400; 54789039100; 42261999700; 55871457800; 7202054176; 6701364934; 10539477500","Prospective identification of hematopoietic lineage choice by deep learning","2017","Nature Methods","129","10.1038/nmeth.4182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013149570&doi=10.1038%2fnmeth.4182&partnerID=40&md5=e2059f81327dcb47b38c96f8f6305072","Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, United Kingdom; Department of Biosystems Science and Engineering, Eidgenössische Technische Hochschule (ETH) Zurich, Basel, Switzerland; Research Unit Stem Cell Dynamics, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Department of Mathematics, Technische Universität München, Garching, Germany","Buggenthin F., Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Buettner F., Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany, European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, United Kingdom; Hoppe P.S., Department of Biosystems Science and Engineering, Eidgenössische Technische Hochschule (ETH) Zurich, Basel, Switzerland, Research Unit Stem Cell Dynamics, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Endele M., Department of Biosystems Science and Engineering, Eidgenössische Technische Hochschule (ETH) Zurich, Basel, Switzerland; Kroiss M., Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Strasser M., Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Schwarzfischer M., Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Loeffler D., Department of Biosystems Science and Engineering, Eidgenössische Technische Hochschule (ETH) Zurich, Basel, Switzerland, Research Unit Stem Cell Dynamics, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Kokkaliaris K.D., Department of Biosystems Science and Engineering, Eidgenössische Technische Hochschule (ETH) Zurich, Basel, Switzerland, Research Unit Stem Cell Dynamics, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Hilsenbeck O., Department of Biosystems Science and Engineering, Eidgenössische Technische Hochschule (ETH) Zurich, Basel, Switzerland, Research Unit Stem Cell Dynamics, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Schroeder T., Department of Biosystems Science and Engineering, Eidgenössische Technische Hochschule (ETH) Zurich, Basel, Switzerland, Research Unit Stem Cell Dynamics, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Theis F.J., Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany, Department of Mathematics, Technische Universität München, Garching, Germany; Marr C., Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany","Differentiation alters molecular properties of stem and progenitor cells, leading to changes in their shape and movement characteristics. We present a deep neural network that prospectively predicts lineage choice in differentiating primary hematopoietic progenitors using image patches from brightfield microscopy and cellular movement. Surprisingly, lineage choice can be detected up to three generations before conventional molecular markers are observable. Our approach allows identification of cells with differentially expressed lineage-specifying genes without molecular labeling.","","Animals; Area Under Curve; Biomarkers; Cell Differentiation; Cell Lineage; Gene Knock-In Techniques; Hematopoietic Stem Cells; Image Processing, Computer-Assisted; Machine Learning; Male; Mice, Mutant Strains; Neural Networks (Computer); Proto-Oncogene Proteins; Time-Lapse Imaging; Trans-Activators; CD16 antigen; CD32 antigen; molecular marker; transcription factor GATA 1; transcription factor PU 1; biological marker; oncoprotein; proto-oncogene protein Spi-1; transactivator protein; animal cell; animal experiment; Article; cell differentiation; cell fate; cell lineage; cell motion; cell structure; hematopoietic stem cell; mouse; nerve cell network; nonhuman; priority journal; protein expression; time-lapse microscopy; animal; area under the curve; artificial neural network; cell differentiation; cell lineage; cytology; gene targeting; genetics; hematopoietic stem cell; image processing; machine learning; male; metabolism; mutant mouse strain; physiology; procedures; time lapse imaging","Nature Publishing Group","15487091","","","28218899","Article","Scopus","2-s2.0-85013149570"
"Jiao Z.; Gao X.; Wang Y.; Li J.","Jiao, Zhicheng (57189091634); Gao, Xinbo (7403873424); Wang, Ying (57207001725); Li, Jie (7410068291)","57189091634; 7403873424; 57207001725; 7410068291","A deep feature based framework for breast masses classification","2016","Neurocomputing","259","10.1016/j.neucom.2016.02.060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965100889&doi=10.1016%2fj.neucom.2016.02.060&partnerID=40&md5=440f9ac699a151bd7d0af98472df6047","Lab of Video and Image Processing Systems, School of Electronic Engineering, Xidian University, Xi'an, China","Jiao Z., Lab of Video and Image Processing Systems, School of Electronic Engineering, Xidian University, Xi'an, China; Gao X., Lab of Video and Image Processing Systems, School of Electronic Engineering, Xidian University, Xi'an, China; Wang Y., Lab of Video and Image Processing Systems, School of Electronic Engineering, Xidian University, Xi'an, China; Li J., Lab of Video and Image Processing Systems, School of Electronic Engineering, Xidian University, Xi'an, China","Characteristic classification of mass plays a role of vital importance in diagnosis of breast cancer. The existing computer aided diagnosis (CAD) methods used to benefit a lot from low-level or middle-level features which are not that good at the simulation of real diagnostic processes, adding difficulties in improving the classification performance. In this paper, we design a deep feature based framework for breast mass classification task. It mainly contains a convolutional neural network (CNN) and a decision mechanism. Combining intensity information and deep features automatically extracted by the trained CNN from the original image, our proposed method could better simulate the diagnostic procedure operated by doctors and achieved state-of-art performance. In this framework, doctors[U+05F3] global and local impressions left by mass images were represented by deep features extracted from two different layers called high-level and middle-level features. Meanwhile, the original images were regarded as detailed descriptions of the breast mass. Then, classifiers based on features above were used in combination to predict classes of test images. And outcomes of classifiers based on different features were analyzed jointly to determine the types of test images. With the help of two kinds of feature visualization methods, deep features extracted from different layers illustrate effective in classification performance and diagnosis simulation. In addition, our method was applied to DDSM dataset and achieved high accuracy under two objective evaluation measures. © 2016 Elsevier B.V.","Breast mass classification; Computer-aided diagnosis; Convolutional neural network; Deep learning; Feature visualization","Classification (of information); Computer aided instruction; Convolution; Image processing; Medical imaging; Neural networks; Visualization; Breast mass; Classification performance; Computer Aided Diagnosis(CAD); Convolutional neural network; Deep learning; Intensity information; State-of-art performance; Visualization method; algorithm; Article; artificial neural network; breast tumor; classifier; computer assisted diagnosis; conceptual framework; convolutional neural network; decision support system; diagnosis; image analysis; information processing; language processing; learning; mammography; priority journal; receptive field; stochastic model; support vector machine; tumor classification; X ray analysis; Computer aided diagnosis","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84965100889"
"Sharan R.V.; Moir T.J.","Sharan, Roneel V. (55542266400); Moir, Tom J. (7003630644)","55542266400; 7003630644","An overview of applications and advancements in automatic sound recognition","2016","Neurocomputing","71","10.1016/j.neucom.2016.03.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979470063&doi=10.1016%2fj.neucom.2016.03.020&partnerID=40&md5=fc05135a953acff98238cf111275d8c7","School of Engineering, Auckland University of Technology, Private Bag 92006, Auckland, 1142, New Zealand","Sharan R.V., School of Engineering, Auckland University of Technology, Private Bag 92006, Auckland, 1142, New Zealand; Moir T.J., School of Engineering, Auckland University of Technology, Private Bag 92006, Auckland, 1142, New Zealand","Automatic sound recognition (ASR) has attracted increased and wide ranging interests in recent years. In this paper, we carry out a review of some important contributions in ASR techniques, mainly over the last one and a half decades. Similar to speech recognition systems, the robustness of an ASR system largely depends on the choice of feature(s) and classifier(s). We take a wider perspective in providing an overview of the features and classifiers used in ASR systems starting from early works in content-based audio classification to more recent developments in applications such as sound event recognition, audio surveillance, and environmental sound recognition. We also review techniques that have been utilized in noise robust sound recognition systems and feature optimization methods. Finally, some of the less commonly known applications of ASR are discussed. © 2016 Elsevier B.V.","Automatic sound recognition; Cepstral coefficients; Deep neural networks; Sound event recognition; Support vector machines; Time-frequency image","Audio systems; Classification (of information); Speech recognition; Support vector machines; Cepstral coefficients; Deep neural networks; Sound event recognition; Sound recognition; Time-frequency images; algorithm; Article; artificial neural network; auditory discrimination; automatic sound recognition; contrastive divergence algorithm; controlled study; decision tree; image analysis; image processing; kernel method; machine learning; measurement accuracy; priority journal; signal noise ratio; signal processing; support vector machine; Audio acoustics","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84979470063"
"Nguyen P.; Tran T.; Wickramasinghe N.; Venkatesh S.","Nguyen, Phuoc (57645164500); Tran, Truyen (56948264600); Wickramasinghe, Nilmini (12795213000); Venkatesh, Svetha (56204854900)","57645164500; 56948264600; 12795213000; 56204854900","Deepr: A Convolutional Net for Medical Records","2017","IEEE Journal of Biomedical and Health Informatics","241","10.1109/JBHI.2016.2633963","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014933330&doi=10.1109%2fJBHI.2016.2633963&partnerID=40&md5=d3f0b4a0d8c262eadd8d24e51234974e","Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, Geelong, 3217, VIC, Australia; Health Informatics Management, Deakin University, Geelong, 3217, VIC, Australia; Health Information Management, Epworth HealthCare, Richmond, 3121, VIC, Australia","Nguyen P., Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, Geelong, 3217, VIC, Australia; Tran T., Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, Geelong, 3217, VIC, Australia; Wickramasinghe N., Health Informatics Management, Deakin University, Geelong, 3217, VIC, Australia, Health Information Management, Epworth HealthCare, Richmond, 3121, VIC, Australia; Venkatesh S., Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, Geelong, 3217, VIC, Australia","Feature engineering remains a major bottleneck when creating predictive systems from electronic medical records. At present, an important missing element is detecting predictive regular clinical motifs from irregular episodic records. We present Deepr (short for Deep record), a new end-to-end deep learning system that learns to extract features from medical records and predicts future risk automatically. Deepr transforms a record into a sequence of discrete elements separated by coded time gaps and hospital transfers. On top of the sequence is a convolutional neural net that detects and combines predictive local clinical motifs to stratify the risk. Deepr permits transparent inspection and visualization of its inner working. We validate Deepr on hospital data to predict unplanned readmission after discharge. Deepr achieves superior accuracy compared to traditional techniques, detects meaningful clinical motifs, and uncovers the underlying structure of the disease and intervention space. © 2013 IEEE.","Convolutional neural networks; deep learning; medical records","Artificial Intelligence; Databases, Factual; Electronic Health Records; Humans; Medical Informatics; Models, Theoretical; Neural Networks (Computer); Software; Convolution; Deep learning; Deep neural networks; Hospitals; Learning systems; Medical computing; Discrete elements; Electronic medical record; End to end; Feature engineerings; Medical record; Predictive systems; Time gap; Traditional techniques; Article; conceptual framework; data base; deep learning system; deep record; embedding; hospital readmission; human; machine learning; mathematical phenomena; medical record; nerve cell network; scoring system; semantics; training; artificial intelligence; artificial neural network; electronic health record; factual database; medical informatics; procedures; software; theoretical model; Convolutional neural networks","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","27913366","Article","Scopus","2-s2.0-85014933330"
"Takerkart S.; Auzias G.; Brun L.; Coulon O.","Takerkart, Sylvain (6506808297); Auzias, Guillaume (24765872800); Brun, Lucile (56519534200); Coulon, Olivier (6602175894)","6506808297; 24765872800; 56519534200; 6602175894","Structural graph-based morphometry: A multiscale searchlight framework based on sulcal pits","2017","Medical Image Analysis","12","10.1016/j.media.2016.04.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973659595&doi=10.1016%2fj.media.2016.04.011&partnerID=40&md5=658ca2e85561d484ef314af3faa63334","Institut de Neurosciences de la Timone UMR 7289, Aix-Marseille Université, CNRS Faculté de Médecine, 27 boulevard Jean Moulin, Marseille, 13005, France; Aix-Marseille Université, CNRS, Laboratoire d'Informatique Fondamentale UMR 7279 Faculté des Sciences, 163 avenue de Luminy, Case 901, Marseille, 13009, France; Aix-Marseille Université, CNRS, LSIS laboratory, UMR 7296 Bâtiment Polytech Saint Jérôme, Avenue Escadrille Normandie-Niemen, Marseille, 13013, France","Takerkart S., Institut de Neurosciences de la Timone UMR 7289, Aix-Marseille Université, CNRS Faculté de Médecine, 27 boulevard Jean Moulin, Marseille, 13005, France, Aix-Marseille Université, CNRS, Laboratoire d'Informatique Fondamentale UMR 7279 Faculté des Sciences, 163 avenue de Luminy, Case 901, Marseille, 13009, France; Auzias G., Institut de Neurosciences de la Timone UMR 7289, Aix-Marseille Université, CNRS Faculté de Médecine, 27 boulevard Jean Moulin, Marseille, 13005, France, Aix-Marseille Université, CNRS, LSIS laboratory, UMR 7296 Bâtiment Polytech Saint Jérôme, Avenue Escadrille Normandie-Niemen, Marseille, 13013, France; Brun L., Institut de Neurosciences de la Timone UMR 7289, Aix-Marseille Université, CNRS Faculté de Médecine, 27 boulevard Jean Moulin, Marseille, 13005, France, Aix-Marseille Université, CNRS, LSIS laboratory, UMR 7296 Bâtiment Polytech Saint Jérôme, Avenue Escadrille Normandie-Niemen, Marseille, 13013, France; Coulon O., Institut de Neurosciences de la Timone UMR 7289, Aix-Marseille Université, CNRS Faculté de Médecine, 27 boulevard Jean Moulin, Marseille, 13005, France, Aix-Marseille Université, CNRS, LSIS laboratory, UMR 7296 Bâtiment Polytech Saint Jérôme, Avenue Escadrille Normandie-Niemen, Marseille, 13013, France","Studying the topography of the cortex has proved valuable in order to characterize populations of subjects. In particular, the recent interest towards the deepest parts of the cortical sulci - the so-called sulcal pits - has opened new avenues in that regard. In this paper, we introduce the first fully automatic brain morphometry method based on the study of the spatial organization of sulcal pits - Structural Graph-Based Morphometry (SGBM). Our framework uses attributed graphs to model local patterns of sulcal pits, and further relies on three original contributions. First, a graph kernel is defined to provide a new similarity measure between pit-graphs, with few parameters that can be efficiently estimated from the data. Secondly, we present the first searchlight scheme dedicated to brain morphometry, yielding dense information maps covering the full cortical surface. Finally, a multi-scale inference strategy is designed to jointly analyze the searchlight information maps obtained at different spatial scales. We demonstrate the effectiveness of our framework by studying gender differences and cortical asymmetries: we show that SGBM can both localize informative regions and estimate their spatial scales, while providing results which are consistent with the literature. Thanks to the modular design of our kernel and the vast array of available kernel methods, SGBM can easily be extended to include a more detailed description of the sulcal patterns and solve different statistical problems. Therefore, we suggest that our SGBM framework should be useful for both reaching a better understanding of the normal brain and defining imaging biomarkers in clinical settings. © 2016 Elsevier B.V.","Brain; Graph kernel; Morphometry; Multi-scale methods; Searchlight; Sulcal pits","Adolescent; Adult; Algorithms; Cerebral Cortex; Female; Humans; Magnetic Resonance Imaging; Male; Reproducibility of Results; Sensitivity and Specificity; Young Adult; Graphic methods; Searchlights; Topography; Gender differences; Graph kernels; Morphometry; Multiscale method; Similarity measure; Spatial organization; Statistical problems; Sulcal pits; adult; aged; Article; brain cortex; brain mapping; brain region; female; human; imaging software; imaging system; kernel method; left hemisphere; machine learning; male; neuroimaging; normal human; nuclear magnetic resonance imaging; priority journal; right hemisphere; sex difference; structural graph based morphometry; sulcal pits; adolescent; algorithm; anatomy and histology; diagnostic imaging; procedures; reproducibility; sensitivity and specificity; young adult; Brain","Elsevier B.V.","13618415","","MIAEC","27310172","Article","Scopus","2-s2.0-84973659595"
"Kadurin A.; Aliper A.; Kazennov A.; Mamoshina P.; Vanhaelen Q.; Khrabrov K.; Zhavoronkov A.","Kadurin, Artur (57193309438); Aliper, Alexander (54889030500); Kazennov, Andrey (56626862100); Mamoshina, Polina (56893719500); Vanhaelen, Quentin (54790233000); Khrabrov, Kuzma (57193310691); Zhavoronkov, Alex (39862415800)","57193309438; 54889030500; 56626862100; 56893719500; 54790233000; 57193310691; 39862415800","The cornucopia of meaningful leads: Applying deep adversarial autoencoders for new molecule development in oncology","2017","Oncotarget","231","10.18632/oncotarget.14073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012890514&doi=10.18632%2foncotarget.14073&partnerID=40&md5=995eab9f2b8831bd46171a8c1f56f3ff","Search Department, Mail.Ru Group Ltd., Moscow, Russian Federation; Pharmaceutical Artificial Intelligence Department, Insilico Medicine Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Big Data and Text Analysis Laboratory, Kazan Federal University, Kazan, Republic of Tatarstan, Russian Federation; St. Petersburg Department of V.A. Steklov Inst. of Mathematics of the Russian Academy of Sciences, Petersburg, Russian Federation; Department of Computer Science, University of Oxford, Oxford, United Kingdom; The Biogerontology Research Foundation, Trevissome Park, Truro, TR4 8UN, United Kingdom; Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation","Kadurin A., Search Department, Mail.Ru Group Ltd., Moscow, Russian Federation, Pharmaceutical Artificial Intelligence Department, Insilico Medicine Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Big Data and Text Analysis Laboratory, Kazan Federal University, Kazan, Republic of Tatarstan, Russian Federation, St. Petersburg Department of V.A. Steklov Inst. of Mathematics of the Russian Academy of Sciences, Petersburg, Russian Federation; Aliper A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Kazennov A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation; Mamoshina P., Pharmaceutical Artificial Intelligence Department, Insilico Medicine Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, Department of Computer Science, University of Oxford, Oxford, United Kingdom; Vanhaelen Q., Pharmaceutical Artificial Intelligence Department, Insilico Medicine Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States; Khrabrov K., Search Department, Mail.Ru Group Ltd., Moscow, Russian Federation; Zhavoronkov A., Pharmaceutical Artificial Intelligence Department, Insilico Medicine Inc., Emerging Technology Centers, Johns Hopkins University at Eastern, Baltimore, MD, United States, The Biogerontology Research Foundation, Trevissome Park, Truro, TR4 8UN, United Kingdom, Moscow Institute of Physics and Technology, Dolgoprudny, Russian Federation","Recent advances in deep learning and specifically in generative adversarial networks have demonstrated surprising results in generating new images and videos upon request even using natural language as input. In this paper we present the first application of generative adversarial autoencoders (AAE) for generating novel molecular fingerprints with a defined set of parameters. We developed a 7-layer AAE architecture with the latent middle layer serving as a discriminator. As an input and output the AAE uses a vector of binary fingerprints and concentration of the molecule. In the latent layer we also introduced a neuron responsible for growth inhibition percentage, which when negative indicates the reduction in the number of tumor cells after the treatment. To train the AAE we used the NCI-60 cell line assay data for 6252 compounds profiled on MCF-7 cell line. The output of the AAE was used to screen 72 million compounds in PubChem and select candidate molecules with potential anticancer properties. This approach is a proof of concept of an artificially-intelligent drug discovery engine, where AAEs are used to generate new molecular fingerprints with the desired molecular properties.","Adversarial autoencoder; Artificial intelligence; Deep learning; Drug discovery; Generative adversarian networks","Antineoplastic Agents; Cell Line, Tumor; Drug Screening Assays, Antitumor; Drug Therapy; High-Throughput Screening Assays; Humans; K562 Cells; Machine Learning; MCF-7 Cells; Neural Networks (Computer); Reproducibility of Results; antineoplastic agent; adversarial autoencoder; Article; artificial neural network; cell assay; controlled study; deep neural network; growth inhibition; human; human cell; information processing; MCF-7 cell line; measurement accuracy; measurement precision; molecular fingerprint; molecular genetics; quantitative structure activity relation; artificial neural network; drug screening; drug therapy; high throughput screening; K-562 cell line; machine learning; procedures; reproducibility; tumor cell line","Impact Journals LLC","19492553","","","28029644","Article","Scopus","2-s2.0-85012890514"
"Sun X.; Li C.; Ren F.","Sun, Xiao (7405624387); Li, Chengcheng (55977634100); Ren, Fuji (7202066506)","7405624387; 55977634100; 7202066506","Sentiment analysis for Chinese microblog based on deep neural networks with convolutional extension features","2016","Neurocomputing","60","10.1016/j.neucom.2016.02.077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991256807&doi=10.1016%2fj.neucom.2016.02.077&partnerID=40&md5=fd6ffb8552755b84851c066cf3831b7f","School of Computer and Information, Hefei University of Technology, TunXi Road No. 193, Hefei, 230009, Anhui, China; Faculty of Engineering, The University of Tokushima, Tokushima, 770-8506, Japan","Sun X., School of Computer and Information, Hefei University of Technology, TunXi Road No. 193, Hefei, 230009, Anhui, China; Li C., School of Computer and Information, Hefei University of Technology, TunXi Road No. 193, Hefei, 230009, Anhui, China; Ren F., School of Computer and Information, Hefei University of Technology, TunXi Road No. 193, Hefei, 230009, Anhui, China, Faculty of Engineering, The University of Tokushima, Tokushima, 770-8506, Japan","Related research for sentiment analysis on Chinese microblog is aiming at the analysis procedure of posts. The length of short microblog text limits feature extraction of microblog. Tweeting is the process of communication with friends, so that microblog comments are important reference information for related post. A contents extension framework is proposed in this paper combining posts and related comments into a microblog conversation for features extraction. A novel convolutional auto encoder is adopted which can extract contextual information from microblog conversation as features for the post. A customized DNN (Deep Neural Network) model, which is stacked with several layers of RBM (Restricted Boltzmann Machine), is implemented to initialize the structure of neural network. The RBM layers can take probability distribution samples of input data to learn hidden structures for better high level features representation. A ClassRBM (Classification RBM) layer, which is stacked on top of RBM layers, is adopted to achieve the final sentiment classification label for the post. Experimental results show that, with proper structure and parameters, the performance of proposed DNN on sentiment classification is better than state-of-the-art surface learning models such as SVM or NB, which proves that the proposed DNN model is suitable for short-length document classification with the proposed feature dimensionality extension method. © 2016 Elsevier B.V.","ClassRBM; DNN; Microblog conversation; RBM; Sentiment analysis","Convolution; Data mining; Extraction; Feature extraction; Information retrieval systems; Probability distributions; ClassRBM; Contextual information; Deep neural networks; Document Classification; Micro-blog; Restricted boltzmann machine; Sentiment analysis; Sentiment classification; analysis; Article; artificial neural network; classification; controlled study; conversation; data processing; deep neural network; feature dimensionality extension method; features extraction; information processing device; information retrieval; machine learning; measurement accuracy; microblog; priority journal; restricted boltzmann machine; sentiment analysis; software; Classification (of information)","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84991256807"
"Arik S.Ö.; Ibragimov B.; Xing L.","Arik, Sercan Ö. (57201791321); Ibragimov, Bulat (40761505000); Xing, Lei (7103349003)","57201791321; 40761505000; 7103349003","Fully automated quantitative cephalometry using convolutional neural networks","2017","Journal of Medical Imaging","177","10.1117/1.JMI.4.1.014501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009516223&doi=10.1117%2f1.JMI.4.1.014501&partnerID=40&md5=cf7d1c0d8da1a9c5d88645b5b2203e36","Baidu USA, 1195 Bordeaux Drive, Sunnyvale, 94089, CA, United States; Stanford University, Department of Radiation Oncology, School of Medicine, 875 Blake Wilbur Drive, Stanford, 94305, CA, United States","Arik S.Ö., Baidu USA, 1195 Bordeaux Drive, Sunnyvale, 94089, CA, United States; Ibragimov B., Stanford University, Department of Radiation Oncology, School of Medicine, 875 Blake Wilbur Drive, Stanford, 94305, CA, United States; Xing L., Stanford University, Department of Radiation Oncology, School of Medicine, 875 Blake Wilbur Drive, Stanford, 94305, CA, United States","Quantitative cephalometry plays an essential role in clinical diagnosis, treatment, and surgery. Development of fully automated techniques for these procedures is important to enable consistently accurate computerized analyses. We study the application of deep convolutional neural networks (CNNs) for fully automated quantitative cephalometry for the first time. The proposed framework utilizes CNNs for detection of landmarks that describe the anatomy of the depicted patient and yield quantitative estimation of pathologies in the jaws and skull base regions. We use a publicly available cephalometric x-ray image dataset to train CNNs for recognition of landmark appearance patterns. CNNs are trained to output probabilistic estimations of different landmark locations, which are combined using a shape-based model. We evaluate the overall framework on the test set and compare with other proposed techniques. We use the estimated landmark locations to assess anatomically relevant measurements and classify them into different anatomical types. Overall, our results demonstrate high anatomical landmark detection accuracy (∼1% to 2% higher success detection rate for a 2-mm range compared with the top benchmarks in the literature) and high anatomical type classification accuracy (∼76% average classification accuracy for test set). We demonstrate that CNNs, which merely input raw image patches, are promising for accurate quantitative cephalometry. © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","artificial neural networks; feed-forward neural networks; image recognition; machine vision; predictive models; statistical learning; supervised learning; x-ray applications","anatomy; artificial neural network; classification; human; jaw; learning; machine; nervous system; pathology; quantitative study; skull base; vision; X ray","SPIE","23294302","","","","Article","Scopus","2-s2.0-85009516223"
"Hua Y.; Tian H.","Hua, Yan (55884401400); Tian, Hu (55885346900)","55884401400; 55885346900","Depth estimation with convolutional conditional random field network","2016","Neurocomputing","24","10.1016/j.neucom.2016.06.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992522002&doi=10.1016%2fj.neucom.2016.06.029&partnerID=40&md5=8ed1914cfea4caad1825a6c8180cff32","Communication University of China, No. 1 Dingfuzhuang East Street, Chaoyang District, Beijing, China; Fujitsu R & D Center, Beijing, China","Hua Y., Communication University of China, No. 1 Dingfuzhuang East Street, Chaoyang District, Beijing, China; Tian H., Fujitsu R & D Center, Beijing, China","In this paper, we tackle the problem of depth estimation from a single image, which is essential for understanding 3D scene structure and can promote the development of visual applications. Markov Random Field (MRF) related depth estimation methods have attracted extensive attentions due to their ability of building structural relationships on outputs. Almost all of them employed engineered low-level absolute and relative features for constructing MRF. However, the engineered features are not capable of producing accurate depths for various scenes. In this paper, we propose Convolutional Conditional Random Field Network (CCRFN) consisting of feature learning and depth tuning components. In feature learning component, we build two Convolutional Neural Network (CNN) architectures to learn absolute and relative features from raw images. In depth tuning component, the learned features are fed into Conditional Random Field (CRF) to generate the depths of all pixels in an image by optimizing a well-defined energy function. CCRFN has two advantages that (1) it does not need hand-crafted features and (2) it models the depths at individual points as well as the relationship between them in the deep model. Experiments on widely used Make3D dataset show that CCRFN outperforms state-of-the-art methods on three evaluation criteria and generates more accurate depth maps with sharper object boundaries. © 2016 Elsevier B.V.","Conditional random field; Convolutional neural network; Deep architecture; Depth estimation","Convolution; Image segmentation; Markov processes; Neural networks; Random processes; Building structural; Conditional random field; Convolutional neural network; Deep architectures; Depth Estimation; Markov Random Fields; State-of-the-art methods; Visual applications; algorithm; Article; artificial neural network; convolutional conditional random field network; depth estimation algorithm; image analysis; intermethod comparison; learning algorithm; linear regression analysis; machine learning; Markov random field; measurement accuracy; measurement error; priority journal; probability; validation process; Network architecture","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84992522002"
"Arevalo J.; González F.A.; Ramos-Pollán R.; Oliveira J.L.; Guevara Lopez M.A.","Arevalo, John (55348307900); González, Fabio A. (7401692221); Ramos-Pollán, Raúl (36667383300); Oliveira, Jose L. (57193360895); Guevara Lopez, Miguel Angel (36999281000)","55348307900; 7401692221; 36667383300; 57193360895; 36999281000","Representation learning for mammography mass lesion classification with convolutional neural networks","2016","Computer Methods and Programs in Biomedicine","373","10.1016/j.cmpb.2015.12.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955570567&doi=10.1016%2fj.cmpb.2015.12.014&partnerID=40&md5=a2546f955ff481765fb5c9a3f33a089a","Universidad Nacional de Colombia, Bogotá, Colombia; Universidad Industrial de Santander, Bucaramanga, Colombia; DETI-IEETA, Universidade de Aveiro, Portugal; CCG, Computer Graphics Center, Portugal","Arevalo J., Universidad Nacional de Colombia, Bogotá, Colombia; González F.A., Universidad Nacional de Colombia, Bogotá, Colombia; Ramos-Pollán R., Universidad Industrial de Santander, Bucaramanga, Colombia; Oliveira J.L., DETI-IEETA, Universidade de Aveiro, Portugal; Guevara Lopez M.A., CCG, Computer Graphics Center, Portugal","Background and objective The automatic classification of breast imaging lesions is currently an unsolved problem. This paper describes an innovative representation learning framework for breast cancer diagnosis in mammography that integrates deep learning techniques to automatically learn discriminative features avoiding the design of specific hand-crafted image-based feature detectors. Methods A new biopsy proven benchmarking dataset was built from 344 breast cancer patients’ cases containing a total of 736 film mammography (mediolateral oblique and craniocaudal) views, representative of manually segmented lesions associated with masses: 426 benign lesions and 310 malignant lesions. The developed method comprises two main stages: (i) preprocessing to enhance image details and (ii) supervised training for learning both the features and the breast imaging lesions classifier. In contrast to previous works, we adopt a hybrid approach where convolutional neural networks are used to learn the representation in a supervised way instead of designing particular descriptors to explain the content of mammography images. Results Experimental results using the developed benchmarking breast cancer dataset demonstrated that our method exhibits significant improved performance when compared to state-of-the-art image descriptors, such as histogram of oriented gradients (HOG) and histogram of the gradient divergence (HGD), increasing the performance from 0.787 to 0.822 in terms of the area under the ROC curve (AUC). Interestingly, this model also outperforms a set of hand-crafted features that take advantage of additional information from segmentation by the radiologist. Finally, the combination of both representations, learned and hand-crafted, resulted in the best descriptor for mass lesion classification, obtaining 0.826 in the AUC score. Conclusions A novel deep learning based framework to automatically address classification of breast mass lesions in mammography was developed. © 2015 Elsevier Ireland Ltd","Breast cancer; Computer-aided diagnosis; Convolutional neural networks; Feature learning; Mammography","Biopsy; Breast Neoplasms; Female; Humans; Machine Learning; Mammography; Neural Networks (Computer); Benchmarking; Computer aided diagnosis; Computer aided instruction; Convolution; Diagnosis; Diseases; Feature extraction; Graphic methods; Mammography; Neural networks; Area under the ROC curve; Automatic classification; Breast Cancer; Breast cancer diagnosis; Convolutional neural network; Discriminative features; Feature learning; Histogram of oriented gradients (HOG); adult; aged; area under the curve; Article; artificial neural network; benchmarking; breast biopsy; breast cancer; breast lesion; cancer classification; cancer incidence; cancer patient; comparative study; computer assisted diagnosis; controlled study; digital mammography; female; histogram; human; image processing; image segmentation; major clinical study; male; radiodiagnosis; receiver operating characteristic; supervised machine learning; tumor biopsy; biopsy; Breast Neoplasms; machine learning; mammography; pathology; Medical imaging","Elsevier Ireland Ltd","01692607","","CMPBE","26826901","Article","Scopus","2-s2.0-84955570567"
"Wang Y.; Di K.; Zhang S.; Shang C.; Huang D.","Wang, Yuhong (55734119400); Di, Kesong (57219370783); Zhang, Shan (57770810200); Shang, Chao (55839423100); Huang, Dexian (55839074000)","55734119400; 57219370783; 57770810200; 55839423100; 55839074000","Melt index prediction of polypropylene based on DBN-ELM","2016","Huagong Xuebao/CIESC Journal","14","10.11949/j.issn.0438-1157.20161280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057868354&doi=10.11949%2fj.issn.0438-1157.20161280&partnerID=40&md5=c0834b889b3f71f6cce9106bb1d2cb90","College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, Shandong, China; Department of Automation, Tsinghua University, Beijing, 100084, China","Wang Y., College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, Shandong, China; Di K., College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, Shandong, China; Zhang S., College of Information and Control Engineering, China University of Petroleum, Qingdao, 266580, Shandong, China; Shang C., Department of Automation, Tsinghua University, Beijing, 100084, China; Huang D., Department of Automation, Tsinghua University, Beijing, 100084, China","To solve the issue of low accuracy of the traditional soft sensor methods of polypropylene melt index, an approach based on deep belief network and extreme learning machine (DBN-ELM) was used to the melt index prediction of polypropylene. Traditional deep belief network (DBN) applied the deep learning to the learning process of the deep neural networks. Different from traditional deep belief network, this approach applied the extreme learning machine algorithm (ELM) to the learning process of DBN to improve the DBN model. Firstly, deep belief network was employed to extract effective features from vibration data by numerical analysis. Then, the effective features were put into the extreme learning machine to proceed model training to obtain the soft sensor model. The experimental validation showed that the method was more accuracy than the traditional method. © All Right Reserved.","Algorithm; Deep belief network; Experimental validation; Extreme learning machine; Feature extraction; Numerical analysis","Algorithms; Deep learning; Deep neural networks; Feature extraction; Knowledge acquisition; Learning algorithms; Numerical analysis; Polypropylenes; Vibration analysis; Deep belief network (DBN); Deep belief networks; Experimental validations; Extreme learning machine; Learning process; Melt index predictions; Polypropylene melts; Soft sensor models; Learning systems","Materials China","04381157","","HUKHA","","Article","Scopus","2-s2.0-85057868354"
"Wang W.; Chang Q.; Li Q.; Shi Z.; Chen W.","Wang, Weiping (7501765704); Chang, Qiang (57200718180); Li, Qun (7405862038); Shi, Zesen (57188726289); Chen, Wei (57206954472)","7501765704; 57200718180; 7405862038; 57188726289; 57206954472","Indoor-outdoor detection using a smart phone sensor","2016","Sensors (Switzerland)","55","10.3390/s16101563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988909648&doi=10.3390%2fs16101563&partnerID=40&md5=e5b585dc7e16240a822ab014cf5720ad","College of Information Systems and Management, National University of Defense Technology, Changsha, 410073, China","Wang W., College of Information Systems and Management, National University of Defense Technology, Changsha, 410073, China; Chang Q., College of Information Systems and Management, National University of Defense Technology, Changsha, 410073, China; Li Q., College of Information Systems and Management, National University of Defense Technology, Changsha, 410073, China; Shi Z., College of Information Systems and Management, National University of Defense Technology, Changsha, 410073, China; Chen W., College of Information Systems and Management, National University of Defense Technology, Changsha, 410073, China","In the era of mobile internet, Location Based Services (LBS) have developed dramatically. Seamless Indoor and Outdoor Navigation and Localization (SNAL) has attracted a lot of attention. No single positioning technology was capable of meeting the various positioning requirements in different environments. Selecting different positioning techniques for different environments is an alternative method. Detecting the users’ current environment is crucial for this technique. In this paper, we proposed to detect the indoor/outdoor environment automatically without high energy consumption. The basic idea was simple: we applied a machine learning algorithm to classify the neighboring Global System for Mobile (GSM) communication cellular base station’s signal strength in different environments, and identified the users’ current context by signal pattern recognition. We tested the algorithm in four different environments. The results showed that the proposed algorithm was capable of identifying open outdoors, semi-outdoors, light indoors and deep indoors environments with 100% accuracy using the signal strength of four nearby GSM stations. The required hardware and signal are widely available in our daily lives, implying its high compatibility and availability. © 2016 by the authors; licensee MDPI, Basel, Switzerland.","GSM; Indoor/outdoor detection; Machine learning; Seamless positioning","Artificial intelligence; Energy utilization; Global system for mobile communications; Learning algorithms; Learning systems; Location based services; Mobile telecommunication systems; Pattern recognition; Pattern recognition systems; Smartphones; Telecommunication services; Cellular base stations; Global system for mobiles; High energy consumption; Indoor/outdoor; Outdoor navigation; Positioning techniques; Positioning technologies; Seamless positioning; Indoor positioning systems","MDPI AG","14248220","","","","Article","Scopus","2-s2.0-84988909648"
"Xue H.; Liu Y.; Cai D.; He X.","Xue, Hongyang (57188993631); Liu, Yao (57197801482); Cai, Deng (35228598300); He, Xiaofei (36164098600)","57188993631; 57197801482; 35228598300; 36164098600","Tracking people in RGBD videos using deep learning and motion clues","2016","Neurocomputing","63","10.1016/j.neucom.2015.06.112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964658345&doi=10.1016%2fj.neucom.2015.06.112&partnerID=40&md5=04ec1fe984066d10e26c008e3dcbc843","State Key Lab of CAD and CG, Zhejiang University, Hangzhou, Zhejiang, 310058, China","Xue H., State Key Lab of CAD and CG, Zhejiang University, Hangzhou, Zhejiang, 310058, China; Liu Y., State Key Lab of CAD and CG, Zhejiang University, Hangzhou, Zhejiang, 310058, China; Cai D., State Key Lab of CAD and CG, Zhejiang University, Hangzhou, Zhejiang, 310058, China; He X., State Key Lab of CAD and CG, Zhejiang University, Hangzhou, Zhejiang, 310058, China","Tracking people in videos is an important topic in surveillance. We consider the problem of human tracking in RGBD videos filmed by sensors such as MS Kinect and Primesense. Our goal is to track persons where the crowd of people is known in advance or all persons in the video have appeared in the very beginning. Thus we can train a classifier to help classify and track persons across the video. A deep learning model trained with big data has been proved to be an effective classifier for various kinds of objects. We propose to train a deep convolutional neural network, which improves tracking performance, to classify people. And a motion model based on spatial and kinetic clues is combined with the network to track people in the scene. We demonstrate the effectiveness of our method by evaluating it on several datasets and comparing with traditional methods like SVM. © 2016 Elsevier B.V.","Convolutional neural network; Deep learning; Human tracking; Pedestrian trajectory; RGB-D","Big data; Convolution; Motion analysis; Neural networks; Security systems; Convolutional neural network; Deep learning; Human Tracking; Motion modeling; MS-Kinect; Pedestrian trajectories; Tracking performance; Article; artificial neural network; association; biological monitoring; biosensor; classification; classifier; data processing; intermethod comparison; kinetics; machine learning; motion; priority journal; RGBD video; statistical model; support vector machine; videorecording; Target tracking","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84964658345"
"Kosciolek T.; Jones D.T.","Kosciolek, Tomasz (57201380493); Jones, David T. (57203189821)","57201380493; 57203189821","Accurate contact predictions using covariation techniques and machine learning","2016","Proteins: Structure, Function and Bioinformatics","39","10.1002/prot.24863","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939515755&doi=10.1002%2fprot.24863&partnerID=40&md5=6e2f4b0da6dca13cb3327e81ff5b5bcc","Department of Computer Science, Bioinformatics Group, University College London, Gower Street, London, WC1E 6BT, United Kingdom","Kosciolek T., Department of Computer Science, Bioinformatics Group, University College London, Gower Street, London, WC1E 6BT, United Kingdom; Jones D.T., Department of Computer Science, Bioinformatics Group, University College London, Gower Street, London, WC1E 6BT, United Kingdom","Here we present the results of residue–residue contact predictions achieved in CASP11 by the CONSIP2 server, which is based around our MetaPSICOV contact prediction method. On a set of 40 target domains with a median family size of around 40 effective sequences, our server achieved an average top-L/5 long-range contact precision of 27%. MetaPSICOV method bases on a combination of classical contact prediction features, enhanced with three distinct covariation methods embedded in a two-stage neural network predictor. Some unique features of our approach are (1) the tuning between the classical and covariation features depending on the depth of the input alignment and (2) a hybrid approach to generate deepest possible multiple-sequence alignments by combining jackHMMer and HHblits. We discuss the CONSIP2 pipeline, our results and show that where the method underperformed, the major factor was relying on a fixed set of parameters for the initial sequence alignments and not attempting to perform domain splitting as a preprocessing step. Proteins 2016; 84(Suppl 1):145–151. © 2015 The Authors. Proteins: Structure, Function, and Bioinformatics Published by Wiley Periodicals, Inc. © 2015 The Authors. Proteins: Structure, Function, and Bioinformatics Published by Wiley Periodicals, Inc.","ab initio prediction; amino acid covariation; CASP; protein structure prediction; residue–residue contact prediction","Amino Acid Sequence; Bacteria; Computational Biology; Computer Simulation; Databases, Protein; Humans; Internet; Machine Learning; Models, Molecular; Models, Statistical; Neural Networks (Computer); Protein Folding; Protein Interaction Domains and Motifs; Protein Structure, Secondary; Proteins; Sequence Alignment; Software; Viruses; protein; amino acid sequence; artificial neural network; bacterium; biology; chemistry; computer simulation; human; Internet; machine learning; molecular model; procedures; protein database; protein domain; protein folding; protein secondary structure; sequence alignment; software; statistical model; statistics and numerical data; virus","John Wiley and Sons Inc.","08873585","","","26205532","Article","Scopus","2-s2.0-84939515755"
"Aliper A.; Plis S.; Artemov A.; Ulloa A.; Mamoshina P.; Zhavoronkov A.","Aliper, Alexander (54889030500); Plis, Sergey (8970496000); Artemov, Artem (56919393200); Ulloa, Alvaro (55539532900); Mamoshina, Polina (56893719500); Zhavoronkov, Alex (39862415800)","54889030500; 8970496000; 56919393200; 55539532900; 56893719500; 39862415800","Deep learning applications for predicting pharmacological properties of drugs and drug repurposing using transcriptomic data","2016","Molecular Pharmaceutics","374","10.1021/acs.molpharmaceut.6b00248","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979019529&doi=10.1021%2facs.molpharmaceut.6b00248&partnerID=40&md5=3bf39f0becde376a31f2a87bb36f76ac","Insilico Medicine, ETC, B301, Johns Hopkins University, Baltimore, 21218, MD, United States; Datalytic Solutions, 1101 Yale Boulevard NE, Albuquerque, 87106, NM, United States; Mind Research Network, Albuquerque, 87106, NM, United States; Biogerontology Research Foundation, Oxford, United Kingdom","Aliper A., Insilico Medicine, ETC, B301, Johns Hopkins University, Baltimore, 21218, MD, United States; Plis S., Datalytic Solutions, 1101 Yale Boulevard NE, Albuquerque, 87106, NM, United States, Mind Research Network, Albuquerque, 87106, NM, United States; Artemov A., Insilico Medicine, ETC, B301, Johns Hopkins University, Baltimore, 21218, MD, United States; Ulloa A., Mind Research Network, Albuquerque, 87106, NM, United States; Mamoshina P., Insilico Medicine, ETC, B301, Johns Hopkins University, Baltimore, 21218, MD, United States; Zhavoronkov A., Insilico Medicine, ETC, B301, Johns Hopkins University, Baltimore, 21218, MD, United States, Biogerontology Research Foundation, Oxford, United Kingdom","Deep learning is rapidly advancing many areas of science and technology with multiple success stories in image, text, voice and video recognition, robotics, and autonomous driving. In this paper we demonstrate how deep neural networks (DNN) trained on large transcriptional response data sets can classify various drugs to therapeutic categories solely based on their transcriptional profiles. We used the perturbation samples of 678 drugs across A549, MCF-7, and PC-3 cell lines from the LINCS Project and linked those to 12 therapeutic use categories derived from MeSH. To train the DNN, we utilized both gene level transcriptomic data and transcriptomic data processed using a pathway activation scoring algorithm, for a pooled data set of samples perturbed with different concentrations of the drug for 6 and 24 hours. In both pathway and gene level classification, DNN achieved high classification accuracy and convincingly outperformed the support vector machine (SVM) model on every multiclass classification problem, however, models based on pathway level data performed significantly better. For the first time we demonstrate a deep learning neural net trained on transcriptomic data to recognize pharmacological properties of multiple drugs across different biological systems and conditions. We also propose using deep neural net confusion matrices for drug repositioning. This work is a proof of principle for applying deep learning to drug discovery and development. © 2016 American Chemical Society.","confusion matrix; deep learning; deep neural networks; DNN; drug discovery; drug repurposing; predictor","A549 Cells; Algorithms; Drug Discovery; Drug Repositioning; Humans; MCF-7 Cells; Neural Networks (Computer); Support Vector Machine; Transcriptome; antiinfective agent; antiinflammatory agent; antilipemic agent; antineoplastic agent; cardiovascular agent; central nervous system agents; contraceptive agent; dermatological agent; gastrointestinal agent; hematologic agent; respiratory tract agent; urinary tract agent; transcriptome; A549 cell line; accuracy; Article; artificial neural network; cell line; classification algorithm; deep neural network; drug classification; drug repositioning; female; human; human cell; intermethod comparison; MCF 7 cell line; Medical Subject Headings; PC 3 cell line; prediction; priority journal; support vector machine; transcriptomics; A-549 cell line; algorithm; artificial neural network; drug development; drug repositioning; genetics; MCF-7 cell line; procedures","American Chemical Society","15438384","","MPOHB","27200455","Article","Scopus","2-s2.0-84979019529"
"Wang F.; Gong H.; Liu G.; Li M.; Yan C.; Xia T.; Li X.; Zeng J.","Wang, Feng (57221087955); Gong, Huichao (56581084000); Liu, Gaochao (57191531255); Li, Meijing (58740518700); Yan, Chuangye (35204292500); Xia, Tian (7101653319); Li, Xueming (37034553000); Zeng, Jianyang (33468010200)","57221087955; 56581084000; 57191531255; 58740518700; 35204292500; 7101653319; 37034553000; 33468010200","DeepPicker: A deep learning approach for fully automated particle picking in cryo-EM","2016","Journal of Structural Biology","125","10.1016/j.jsb.2016.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991394143&doi=10.1016%2fj.jsb.2016.07.006&partnerID=40&md5=8d1451a71c61f8124cd4ee378b9bc29c","School of Life Sciences, Tsinghua University, Beijing, 100084, China; Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Beijing Advanced Innovation Center for Structure Biology, Tsinghua University, Beijing, 100084, China; Tsinghua-Peking Joint Center for Life Sciences, Tsinghua University, Beijing, 100084, China","Wang F., School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Gong H., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Liu G., School of Life Sciences, Tsinghua University, Beijing, 100084, China, Beijing Advanced Innovation Center for Structure Biology, Tsinghua University, Beijing, 100084, China; Li M., School of Life Sciences, Tsinghua University, Beijing, 100084, China, Beijing Advanced Innovation Center for Structure Biology, Tsinghua University, Beijing, 100084, China; Yan C., School of Life Sciences, Tsinghua University, Beijing, 100084, China, Tsinghua-Peking Joint Center for Life Sciences, Tsinghua University, Beijing, 100084, China; Xia T., School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, 430074, China; Li X., School of Life Sciences, Tsinghua University, Beijing, 100084, China, Beijing Advanced Innovation Center for Structure Biology, Tsinghua University, Beijing, 100084, China, Tsinghua-Peking Joint Center for Life Sciences, Tsinghua University, Beijing, 100084, China; Zeng J., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China","Particle picking is a time-consuming step in single-particle analysis and often requires significant interventions from users, which has become a bottleneck for future automated electron cryo-microscopy (cryo-EM). Here we report a deep learning framework, called DeepPicker, to address this problem and fill the current gaps toward a fully automated cryo-EM pipeline. DeepPicker employs a novel cross-molecule training strategy to capture common features of particles from previously-analyzed micrographs, and thus does not require any human intervention during particle picking. Tests on the recently-published cryo-EM data of three complexes have demonstrated that our deep learning based scheme can successfully accomplish the human-level particle picking process and identify a sufficient number of particles that are comparable to those picked manually by human experts. These results indicate that DeepPicker can provide a practically useful tool to significantly reduce the time and manual effort spent in single-particle analysis and thus greatly facilitate high-resolution cryo-EM structure determination. DeepPicker is released as an open-source program, which can be downloaded from https://github.com/nejyeah/DeepPicker-python. © 2016 Elsevier Inc.","Automation; Cryo-EM; Deep learning; Particle picking","Algorithms; Amyloid Precursor Protein Secretases; Cryoelectron Microscopy; Data Interpretation, Statistical; Imaging, Three-Dimensional; Machine Learning; Models, Molecular; Software; TRPV Cation Channels; secretase; vanilloid receptor; analysis; analytical parameters; Article; automation; controlled study; cryoelectron microscopy; intermethod comparison; machine learning; particle picking; priority journal; single particle analysis; software; algorithm; chemistry; cryoelectron microscopy; machine learning; molecular model; procedures; software; statistical analysis; three dimensional imaging; ultrastructure","Academic Press Inc.","10478477","","JSBIE","27424268","Article","Scopus","2-s2.0-84991394143"
"Liu N.; Kan J.-M.","Liu, Nian (56649804900); Kan, Jiang-ming (16205203800)","56649804900; 16205203800","Improved deep belief networks and multi-feature fusion for leaf identification","2016","Neurocomputing","58","10.1016/j.neucom.2016.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994469223&doi=10.1016%2fj.neucom.2016.08.005&partnerID=40&md5=3bbc36fce3362990b925b4fda4cb7b96","School of Technology, Beijing Forestry University, 35# Qinghua East Road,Haidian District, Beijing, 100083, China","Liu N., School of Technology, Beijing Forestry University, 35# Qinghua East Road,Haidian District, Beijing, 100083, China; Kan J.-M., School of Technology, Beijing Forestry University, 35# Qinghua East Road,Haidian District, Beijing, 100083, China","Plant identification based on digital leaf images is a hot topic in the automatic classification of plants. However, due to the increase in the number of plant species, the leaf recognition rate is low because the traditional classification methods extract the few characteristics or use the classifiers with simple structures. This paper applied a combination of texture features and shape features for identification. Texture features include local binary patterns, Gabor filters and gray level co-occurrence matrices, while the shape feature vector is modeled using Hu moment invariants and Fourier descriptors. Improved deep belief networks (DBNs) with dropout, which use proportion integration differentiation control (PID) to decrease the reconstruction error in the process of pre-training, are used as the classifiers. The proposed algorithm was tested on the ICL dataset, and the average recognition rate is 93.9% for 220 types of leaves. The experimental results show that the proposed method has a higher recognition rate and is more robust than the traditional methods, and the training process is completed in a shorter time. © 2016 Elsevier B.V.","DBNs; Leaf identification; PID; Shape feature; Texture feature","Content based retrieval; Gabor filters; Image segmentation; Plants (botany); Automatic classification; Classification methods; DBNs; Gray-level co-occurrence matrix; Leaf identification; Proportion integration differentiation control(PID); Shape features; Texture features; Article; artificial neural network; automated pattern recognition; Bayesian learning; controlled study; deep belief network; image processing; leaf morphology; mathematical model; plant leaf; priority journal; support vector machine; Image processing","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84994469223"
"Dolz J.; Betrouni N.; Quidet M.; Kharroubi D.; Leroy H.A.; Reyns N.; Massoptier L.; Vermandel M.","Dolz, Jose (56578010400); Betrouni, Nacim (8684908200); Quidet, Mathilde (56676341800); Kharroubi, Dris (56554229600); Leroy, Henri A. (54782810900); Reyns, Nicolas (6602707079); Massoptier, Laurent (23389715000); Vermandel, Maximilien (57205977134)","56578010400; 8684908200; 56676341800; 56554229600; 54782810900; 6602707079; 23389715000; 57205977134","Stacking denoising auto-encoders in a deep network to segment the brainstem on MRI in brain cancer patients: A clinical study","2016","Computerized Medical Imaging and Graphics","43","10.1016/j.compmedimag.2016.03.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969856115&doi=10.1016%2fj.compmedimag.2016.03.003&partnerID=40&md5=37c9d8e7c76cbabd7204a8ca186374d7","AQUILAB, Loos-les-Lille, France; Univ. Lille, Inserm, CHU Lille, U1189 - ONCO-THAI - Image Assisted Laser Therapy for Oncology, Lille, F-59000, France; Neurosurgery Department, University Hospital Lille, Lille, France","Dolz J., AQUILAB, Loos-les-Lille, France, Univ. Lille, Inserm, CHU Lille, U1189 - ONCO-THAI - Image Assisted Laser Therapy for Oncology, Lille, F-59000, France; Betrouni N., Univ. Lille, Inserm, CHU Lille, U1189 - ONCO-THAI - Image Assisted Laser Therapy for Oncology, Lille, F-59000, France; Quidet M., Univ. Lille, Inserm, CHU Lille, U1189 - ONCO-THAI - Image Assisted Laser Therapy for Oncology, Lille, F-59000, France; Kharroubi D., Univ. Lille, Inserm, CHU Lille, U1189 - ONCO-THAI - Image Assisted Laser Therapy for Oncology, Lille, F-59000, France; Leroy H.A., Univ. Lille, Inserm, CHU Lille, U1189 - ONCO-THAI - Image Assisted Laser Therapy for Oncology, Lille, F-59000, France, Neurosurgery Department, University Hospital Lille, Lille, France; Reyns N., Univ. Lille, Inserm, CHU Lille, U1189 - ONCO-THAI - Image Assisted Laser Therapy for Oncology, Lille, F-59000, France, Neurosurgery Department, University Hospital Lille, Lille, France; Massoptier L., AQUILAB, Loos-les-Lille, France; Vermandel M., Univ. Lille, Inserm, CHU Lille, U1189 - ONCO-THAI - Image Assisted Laser Therapy for Oncology, Lille, F-59000, France, Neurosurgery Department, University Hospital Lille, Lille, France","Delineation of organs at risk (OARs) is a crucial step in surgical and treatment planning in brain cancer, where precise OARs volume delineation is required. However, this task is still often manually performed, which is time-consuming and prone to observer variability. To tackle these issues a deep learning approach based on stacking denoising auto-encoders has been proposed to segment the brainstem on magnetic resonance images in brain cancer context. Additionally to classical features used in machine learning to segment brain structures, two new features are suggested. Four experts participated in this study by segmenting the brainstem on 9 patients who underwent radiosurgery. Analysis of variance on shape and volume similarity metrics indicated that there were significant differences (p < 0.05) between the groups of manual annotations and automatic segmentations. Experimental evaluation also showed an overlapping higher than 90% with respect to the ground truth. These results are comparable, and often higher, to those of the state of the art segmentation methods but with a considerably reduction of the segmentation time. © 2016 Elsevier Ltd.","Brain cancer; Deep learning; Machine learning; MRI segmentation","Brain Neoplasms; Brain Stem; Humans; Machine Learning; Magnetic Resonance Imaging; Brain; Diseases; Image segmentation; Learning systems; Magnetic resonance; Magnetic resonance imaging; Network coding; Automatic segmentations; Brain cancer; Experimental evaluation; MRI segmentation; Observer variability; Segmentation methods; Similarity metrics; Treatment planning; Article; artificial neural network; brain cancer; brain size; brain stem; cancer patient; human; image analysis; machine learning; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; priority journal; signal noise ratio; support vector machine; brain stem; brain tumor; diagnostic imaging; machine learning; nuclear magnetic resonance imaging; procedures; Deep learning","Elsevier Ltd","08956111","","CMIGE","27236370","Article","Scopus","2-s2.0-84969856115"
"Howard J.T.; Janak J.C.; Hinojosa-Laborde C.; Convertino V.A.","Howard, Jeffrey T. (56471144600); Janak, Jud C. (56940297700); Hinojosa-Laborde, Carmen (6603772842); Convertino, Victor A. (7005858036)","56471144600; 56940297700; 6603772842; 7005858036","Specificity of Compensatory Reserve and Tissue Oxygenation as Early Predictors of Tolerance to Progressive Reductions in Central Blood Volume","2016","Shock","36","10.1097/SHK.0000000000000632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964058302&doi=10.1097%2fSHK.0000000000000632&partnerID=40&md5=872528ab886e1be831cbdf8805f6fb04","United States Army Institute of Surgical Research, JBSA Fort Sam Houston, Bldg. 3611, 3698 Chambers Pass, San Antonio, 78234, TX, United States","Howard J.T., United States Army Institute of Surgical Research, JBSA Fort Sam Houston, Bldg. 3611, 3698 Chambers Pass, San Antonio, 78234, TX, United States; Janak J.C., United States Army Institute of Surgical Research, JBSA Fort Sam Houston, Bldg. 3611, 3698 Chambers Pass, San Antonio, 78234, TX, United States; Hinojosa-Laborde C., United States Army Institute of Surgical Research, JBSA Fort Sam Houston, Bldg. 3611, 3698 Chambers Pass, San Antonio, 78234, TX, United States; Convertino V.A., United States Army Institute of Surgical Research, JBSA Fort Sam Houston, Bldg. 3611, 3698 Chambers Pass, San Antonio, 78234, TX, United States","We previously reported that measurements of muscle oxygen saturation (SmO 2) and the compensatory reserve index (CRI) provided earlier indication of reduced central blood volume than standard vital signs (e.g., blood pressure, heart rate, arterial oxygen saturation). In the present study, we hypothesized that the CRI would provide greater sensitivity and specificity to detect progressive decrease in central circulating blood volume compared with SmO 2. Continuous noninvasive measures of CRI (calculated from feature changes in the photoplethysmographic arterial waveforms) were collected from 55 healthy volunteer subjects before and during stepwise lower body negative pressure (LBNP) to the onset of hemodynamic decompensation. Near infrared spectroscopy was used on the forearm to obtain deep SmO 2, hydrogen ion concentration ([H + ]), and hemoglobin volume (HbT; decreases reflect vasoconstriction). CRI decreased by 97% in a linear fashion across progressive blood volume loss, with no clinically significant alterations in vital signs. The receiver operating characteristic (ROC) area under the curve (AUC) for the CRI was 0.91, with a sensitivity of 0.87 and specificity of 0.80, when predicting decompensation at progressive levels of LBNP. In comparison, SmO 2, [H + ], and HbT had significantly lower ROC AUC, sensitivity and specificity values for detecting the same outcome. Consistent with our hypothesis, CRI detected central hypovolemia with significantly greater specificity than measures of tissue metabolism. Single measurement of CRI may enable more accurate triage, while CRI monitoring may allow for earlier detection of casualty deterioration. Copyright © 2016 by the Shock Society.","Blood loss; compensatory reserve; hemorrhage; hypovolemia; near infrared spectroscopy; pH; prehospital; tissue oxygen saturation; triage; vasoconstriction","Adult; Area Under Curve; Blood Pressure; Blood Volume; Female; Heart Rate; Hemodynamics; Humans; Hydrogen-Ion Concentration; Hypovolemia; Lower Body Negative Pressure; Machine Learning; Male; Spectroscopy, Near-Infrared; Young Adult; hemoglobin; adult; Article; blood volume; compensatory reserve index; female; forearm; hemodynamic parameters; human; human experiment; hypovolemia; lower body negative pressure; male; near infrared spectroscopy; non invasive procedure; normal human; oxygen saturation; photoelectric plethysmography; sensitivity and specificity; tissue oxygenation; vasoconstriction; waveform; area under the curve; blood pressure; blood volume; genetics; heart rate; hemodynamics; hypovolemia; machine learning; pathophysiology; pH; physiology; young adult","Lippincott Williams and Wilkins","10732322","","SAGUA","27058052","Article","Scopus","2-s2.0-84964058302"
"Zeng N.; Wang Z.; Zhang H.; Liu W.; Alsaadi F.E.","Zeng, Nianyin (36703553900); Wang, Zidong (55810114200); Zhang, Hong (57163176600); Liu, Weibo (57001851000); Alsaadi, Fuad E. (23566767000)","36703553900; 55810114200; 57163176600; 57001851000; 23566767000","Deep Belief Networks for Quantitative Analysis of a Gold Immunochromatographic Strip","2016","Cognitive Computation","147","10.1007/s12559-016-9404-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964598999&doi=10.1007%2fs12559-016-9404-x&partnerID=40&md5=80538dd7f52ebfd3e81b484e7ece07d5","Department of Mechanical and Electrical Engineering, Xiamen University, Xiamen, 361005, Fujian, China; Department of Computer Science, Brunel University London, Uxbridge, UB8 3PH, Middlesex, United Kingdom; Communication Systems and Networks (CSN) Research Group, Faculty of Engineering, King Abdulaziz University, Jeddah, 21589, Saudi Arabia","Zeng N., Department of Mechanical and Electrical Engineering, Xiamen University, Xiamen, 361005, Fujian, China; Wang Z., Department of Computer Science, Brunel University London, Uxbridge, UB8 3PH, Middlesex, United Kingdom, Communication Systems and Networks (CSN) Research Group, Faculty of Engineering, King Abdulaziz University, Jeddah, 21589, Saudi Arabia; Zhang H., Department of Mechanical and Electrical Engineering, Xiamen University, Xiamen, 361005, Fujian, China; Liu W., Department of Computer Science, Brunel University London, Uxbridge, UB8 3PH, Middlesex, United Kingdom; Alsaadi F.E., Communication Systems and Networks (CSN) Research Group, Faculty of Engineering, King Abdulaziz University, Jeddah, 21589, Saudi Arabia","Gold immunochromatographic strip (GICS) has become a popular membrane-based diagnostic tool in a variety of settings due to its sensitivity, simplicity and rapidness. This paper aimed to develop a framework of automatic image inspection to further improve the sensitivity as well as the quantitative performance of the GICS systems. As one of the latest methodologies in machine learning, the deep belief network (DBN) is applied, for the first time, to quantitative analysis of GICS images with hope to segment the test and control lines with a high accuracy. It is remarkable that the exploited DBN is capable of simultaneously learning three proposed features including intensity, distance and difference to distinguish the test and control lines from the region of interest that are obtained by preprocessing the GICS images. Several indices are proposed to evaluate the proposed method. The experiment results show the feasibility and effectiveness of the DBN in the sense that it provides a robust image processing methodology for quantitative analysis of GICS. © 2016, Springer Science+Business Media New York.","Deep belief networks (DBNs); Gold immunochromatographic strip; Image segmentation; Quantitative analysis; Restricted Boltzmann machine (RBM)","Artificial intelligence; Bayesian networks; Chemical analysis; Gold; Image analysis; Image processing; Learning systems; Deep belief network (DBN); Deep belief networks; Diagnostic tools; Gold immunochromatographic strips; Image inspection; Membrane-based; Region of interest; Restricted boltzmann machine; Image segmentation","Springer New York LLC","18669956","","","","Article","Scopus","2-s2.0-84964598999"
"Saez Y.; Baldominos A.; Isasi P.","Saez, Yago (8848712400); Baldominos, Alejandro (56203599600); Isasi, Pedro (7004613522)","8848712400; 56203599600; 7004613522","A comparison study of classifier algorithms for cross-person physical activity recognition","2017","Sensors (Switzerland)","42","10.3390/s17010066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008173333&doi=10.3390%2fs17010066&partnerID=40&md5=ebab0356a01c41304cb81fde03941825","Department of Computer Science, Universidad Carlos III de Madrid, Leganés, 28911, Spain","Saez Y., Department of Computer Science, Universidad Carlos III de Madrid, Leganés, 28911, Spain; Baldominos A., Department of Computer Science, Universidad Carlos III de Madrid, Leganés, 28911, Spain; Isasi P., Department of Computer Science, Universidad Carlos III de Madrid, Leganés, 28911, Spain","Physical activity is widely known to be one of the key elements of a healthy life. The many benefits of physical activity described in the medical literature include weight loss and reductions in the risk factors for chronic diseases. With the recent advances in wearable devices, such as smartwatches or physical activity wristbands, motion tracking sensors are becoming pervasive, which has led to an impressive growth in the amount of physical activity data available and an increasing interest in recognizing which specific activity a user is performing. Moreover, big data and machine learning are now cross-fertilizing each other in an approach called “deep learning”, which consists of massive artificial neural networks able to detect complicated patterns from enormous amounts of input data to learn classification models. This work compares various state-of-the-art classification techniques for automatic cross-person activity recognition under different scenarios that vary widely in how much information is available for analysis. We have incorporated deep learning by using Google’s TensorFlow framework. The data used in this study were acquired from PAMAP2 (Physical Activity Monitoring in the Ageing Population), a publicly available dataset containing physical activity data. To perform cross-person prediction, we used the leave-one-subject-out (LOSO) cross-validation technique. When working with large training sets, the best classifiers obtain very high average accuracies (e.g., 96% using extra randomized trees). However, when the data volume is drastically reduced (where available data are only 0.001% of the continuous data), deep neural networks performed the best, achieving 60% in overall prediction accuracy. We found that even when working with only approximately 22.67% of the full dataset, we can statistically obtain the same results as when working with the full dataset. This finding enables the design of more energy-efficient devices and facilitates cold starts and big data processing of physical activity records. © 2016 by the authors; licensee MDPI, Basel, Switzerland.","Biomedical signal processing; Classification; Deep learning; Machine learning; Physical activity recognition; Time series analysis","Algorithms; Artificial Intelligence; Exercise; Humans; Machine Learning; Neural Networks (Computer); Artificial intelligence; Biomedical signal processing; Classification (of information); Data handling; Energy efficiency; Learning systems; Neural networks; Pattern recognition; Population statistics; Signal processing; Time series analysis; Classification models; Classification technique; Classifier algorithms; Cross-validation technique; Deep learning; Deep neural networks; Physical activity; Physical activity monitoring; algorithm; artificial intelligence; artificial neural network; exercise; human; machine learning; physiology; Big data","MDPI AG","14248220","","","28042838","Article","Scopus","2-s2.0-85008173333"
"Seguí S.; Drozdzal M.; Pascual G.; Radeva P.; Malagelada C.; Azpiroz F.; Vitrià J.","Seguí, Santi (23398674000); Drozdzal, Michal (36469902700); Pascual, Guillem (57191913382); Radeva, Petia (56208405900); Malagelada, Carolina (15122524600); Azpiroz, Fernando (57207592894); Vitrià, Jordi (7003477071)","23398674000; 36469902700; 57191913382; 56208405900; 15122524600; 57207592894; 7003477071","Generic feature learning for wireless capsule endoscopy analysis","2016","Computers in Biology and Medicine","84","10.1016/j.compbiomed.2016.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994750589&doi=10.1016%2fj.compbiomed.2016.10.011&partnerID=40&md5=af2249e60543e2b0c7e72eec0959b3ec","Dept. Matemàtiques i Informàtica, Universitat de Barcelona, Barcelona, Spain; Computer Vision Center (CVC), Barcelona, Spain; Medtronic GI, Yoqneam, Israel; Digestive System Research Unit, Hospital Vall d'Hebron, Barcelona, Spain","Seguí S., Dept. Matemàtiques i Informàtica, Universitat de Barcelona, Barcelona, Spain, Computer Vision Center (CVC), Barcelona, Spain; Drozdzal M., Medtronic GI, Yoqneam, Israel; Pascual G., Dept. Matemàtiques i Informàtica, Universitat de Barcelona, Barcelona, Spain; Radeva P., Dept. Matemàtiques i Informàtica, Universitat de Barcelona, Barcelona, Spain, Computer Vision Center (CVC), Barcelona, Spain; Malagelada C., Digestive System Research Unit, Hospital Vall d'Hebron, Barcelona, Spain; Azpiroz F., Digestive System Research Unit, Hospital Vall d'Hebron, Barcelona, Spain; Vitrià J., Dept. Matemàtiques i Informàtica, Universitat de Barcelona, Barcelona, Spain, Computer Vision Center (CVC), Barcelona, Spain","The interpretation and analysis of wireless capsule endoscopy (WCE) recordings is a complex task which requires sophisticated computer aided decision (CAD) systems to help physicians with video screening and, finally, with the diagnosis. Most CAD systems used in capsule endoscopy share a common system design, but use very different image and video representations. As a result, each time a new clinical application of WCE appears, a new CAD system has to be designed from the scratch. This makes the design of new CAD systems very time consuming. Therefore, in this paper we introduce a system for small intestine motility characterization, based on Deep Convolutional Neural Networks, which circumvents the laborious step of designing specific features for individual motility events. Experimental results show the superiority of the learned features over alternative classifiers constructed using state-of-the-art handcrafted features. In particular, it reaches a mean classification accuracy of 96% for six intestinal motility events, outperforming the other classifiers by a large margin (a 14% relative performance increase). © 2016 Elsevier Ltd","Deep learning; Feature learning; Motility analysis; Wireless capsule endoscopy","Algorithms; Capsule Endoscopy; Gastrointestinal Motility; Humans; Image Processing, Computer-Assisted; Machine Learning; Complex networks; Computer aided analysis; Computer aided diagnosis; Neural networks; Video signal processing; Convolutional neural network; Deep learning; Feature learning; Intestinal motilities; Motility analysis; Relative performance; Video representations; Wireless capsule endoscopy; accuracy; Article; artificial neural network; capsule endoscope; capsule endoscopy; computer assisted diagnosis; human; intestine motility; learning; priority journal; small intestine; algorithm; capsule endoscopy; gastrointestinal motility; image processing; machine learning; physiology; procedures; Endoscopy","Elsevier Ltd","00104825","","CBMDA","27810622","Article","Scopus","2-s2.0-84994750589"
"Chowdhury A.; Kautz E.; Yener B.; Lewis D.","Chowdhury, Aritra (57210017456); Kautz, Elizabeth (57190135662); Yener, Bülent (7003714752); Lewis, Daniel (57190942076)","57210017456; 57190135662; 7003714752; 57190942076","Image driven machine learning methods for microstructure recognition","2016","Computational Materials Science","238","10.1016/j.commatsci.2016.05.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977650344&doi=10.1016%2fj.commatsci.2016.05.034&partnerID=40&md5=0bcace3acd1c39ce11d36b99d4b88981","Computer Science Department, Rensselaer Polytechnic Institute, Troy, 12180, NY, United States; Materials Science and Engineering Department, Rensselaer Polytechnic Institute, Troy, 12180, NY, United States","Chowdhury A., Computer Science Department, Rensselaer Polytechnic Institute, Troy, 12180, NY, United States; Kautz E., Materials Science and Engineering Department, Rensselaer Polytechnic Institute, Troy, 12180, NY, United States; Yener B., Computer Science Department, Rensselaer Polytechnic Institute, Troy, 12180, NY, United States; Lewis D., Materials Science and Engineering Department, Rensselaer Polytechnic Institute, Troy, 12180, NY, United States","Computer vision and machine learning methods were applied to the challenge of automatic microstructure recognition. Here, a case study on dendritic morphologies was performed. Two classification tasks were completed, and involved distinguishing between micrographs that depict dendritic morphologies from those that do not contain this particular microstructural feature (Task 1), and from those micrographs identified as depicting dendrites, different cross-sectional views (longitudinal or transverse) were identified (Task 2). Data sets were comprised of images taken over a range of magnifications, from materials with different compositions and varying orientations of microstructural features. Feature extraction and dimensionality reduction were performed prior to training machine learning algorithms to classify microstructural image data. Visual bag of words, texture and shape statistics, and pre-trained convolutional neural networks (deep learning algorithms) were used for feature extraction. Classification was then performed using support vector machine, voting, nearest neighbors, and random forest models. For each model, classification was completed using full (original size) and reduced feature vectors for each feature extraction method tested. Performance comparisons were done to evaluate all possible combinations of feature extraction, selection, and classifiers for the task of micrograph classification. Results demonstrate that pre-trained neural networks represent microstructure image data well, and when used for feature extraction yield the highest classification accuracies for the majority of classifier and feature selection methods tested. Thus, deep learning algorithms can successfully be applied to micrograph recognition tasks. Maximum classification accuracies of 91.85 ± 4.25% and 97.37 ± 3.33% for Tasks 1 and 2 respectively, were achieved. This work is a broad investigation of computer vision and machine learning methods that acts as a step towards applying these established methods to more sophisticated materials recognition or characterization tasks. The approach presented here could offer improvements over established stereological measurements by removing the requirement of expert knowledge (bias) for interpretation of image data prior to characterization. © 2016 Elsevier B.V.","Classification; Computer vision; Convolutional neural networks; Machine learning; Micrograph; Microstructure","Artificial intelligence; Characterization; Classification (of information); Computer vision; Convolution; Decision trees; Extraction; Feature extraction; Image processing; Learning systems; Microstructural evolution; Microstructure; Neural networks; Convolutional neural network; Dimensionality reduction; Feature extraction methods; Feature selection methods; Machine learning methods; Micrograph; Microstructural features; Trained neural networks; Learning algorithms","Elsevier B.V.","09270256","","CMMSE","","Article","Scopus","2-s2.0-84977650344"
"Subramanian G.; Ramsundar B.; Pande V.; Denny R.A.","Subramanian, Govindan (7103332145); Ramsundar, Bharath (56097570200); Pande, Vijay (7004966384); Denny, Rajiah Aldrin (35423283700)","7103332145; 56097570200; 7004966384; 35423283700","Computational Modeling of β-Secretase 1 (BACE-1) Inhibitors Using Ligand Based Approaches","2016","Journal of Chemical Information and Modeling","171","10.1021/acs.jcim.6b00290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992694543&doi=10.1021%2facs.jcim.6b00290&partnerID=40&md5=9dda9b62f72297da2dc22c4271427d63","VMRD Global Discovery, Zoetis, 333 Portage Street, Kalamazoo, 49007, MI, United States; Department of Computer Science, Stanford University, 318 Campus Drive, Stanford, 94305, CA, United States; Department of Chemistry, Stanford University, 318 Campus Drive, Stanford, 94305, CA, United States; Worldwide Medicinal Chemistry Pfizer Inc., 610 Main Street, Cambridge, 02139, MA, United States","Subramanian G., VMRD Global Discovery, Zoetis, 333 Portage Street, Kalamazoo, 49007, MI, United States; Ramsundar B., Department of Computer Science, Stanford University, 318 Campus Drive, Stanford, 94305, CA, United States; Pande V., Department of Chemistry, Stanford University, 318 Campus Drive, Stanford, 94305, CA, United States; Denny R.A., Worldwide Medicinal Chemistry Pfizer Inc., 610 Main Street, Cambridge, 02139, MA, United States","The binding affinities (IC50) reported for diverse structural and chemical classes of human β-secretase 1 (BACE-1) inhibitors in literature were modeled using multiple in silico ligand based modeling approaches and statistical techniques. The descriptor space encompasses simple binary molecular fingerprint, one- and two-dimensional constitutional, physicochemical, and topological descriptors, and sophisticated three-dimensional molecular fields that require appropriate structural alignments of varied chemical scaffolds in one universal chemical space. The affinities were modeled using qualitative classification or quantitative regression schemes involving linear, nonlinear, and deep neural network (DNN) machine-learning methods used in the scientific literature for quantitative-structure activity relationships (QSAR). In a departure from tradition, ∼20% of the chemically diverse data set (205 compounds) was used to train the model with the remaining ∼80% of the structural and chemical analogs used as part of an external validation (1273 compounds) and prospective test (69 compounds) sets respectively to ascertain the model performance. The machine-learning methods investigated herein performed well in both the qualitative classification (∼70% accuracy) and quantitative IC50 predictions (RMSE ∼ 1 log). The success of the 2D descriptor based machine learning approach when compared against the 3D field based technique pursued for hBACE-1 inhibitors provides a strong impetus for systematically applying such methods during the lead identification and optimization efforts for other protein families as well. © 2016 American Chemical Society.","","Amyloid Precursor Protein Secretases; Aspartic Acid Endopeptidases; Computer Simulation; Drug Discovery; Humans; Ligands; Machine Learning; Models, Molecular; Neural Networks (Computer); Quantitative Structure-Activity Relationship; Small Molecule Libraries; Binding energy; Computational chemistry; Deep learning; Deep neural networks; Ligands; Molecular graphics; Statistical tests; aspartic proteinase; BACE1 protein, human; ligand; molecular library; secretase; Machine learning approaches; Machine learning methods; Molecular fingerprint; Qualitative classification; Quantitative structure-activity relationships; Scientific literature; Statistical techniques; Topological descriptors; antagonists and inhibitors; artificial neural network; chemistry; computer simulation; drug development; human; machine learning; metabolism; molecular library; molecular model; pharmacology; procedures; quantitative structure activity relation; Learning systems","American Chemical Society","15499596","","JCISD","27689393","Article","Scopus","2-s2.0-84992694543"
"Valsky D.; Marmor-Levin O.; Deffains M.; Eitan R.; Blackwell K.T.; Bergman H.; Israel Z.","Valsky, Dan (6507243167); Marmor-Levin, Odeya (55780126600); Deffains, Marc (30667473600); Eitan, Renana (14048278300); Blackwell, Kim T. (7005536162); Bergman, Hagai (7102552858); Israel, Zvi (7003749250)","6507243167; 55780126600; 30667473600; 14048278300; 7005536162; 7102552858; 7003749250","Stop! border ahead: Automatic detection of subthalamic exit during deep brain stimulation surgery","2017","Movement Disorders","61","10.1002/mds.26806","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990841545&doi=10.1002%2fmds.26806&partnerID=40&md5=6ca509caa18fc0b7a183b794551d68ad","The Edmond and Lily Safra Center for Brain Research (ELSC), The Hebrew University, Jerusalem, Israel; Department of Medical Neurobiology (Physiology), Institute of Medical Research – Israel-Canada (IMRIC), The Hebrew University-Hadassah Medical School, Jerusalem, Israel; Department of Psychiatry, Hadassah-Hebrew University Medical Center, Jerusalem, Israel; Krasnow Institute for Advanced Study, George Mason University, Fairfax, VA, United States; Center for Functional & Restorative Neurosurgery, Department of Neurosurgery, Hadassah-Hebrew University Medical Center, Jerusalem, Israel","Valsky D., The Edmond and Lily Safra Center for Brain Research (ELSC), The Hebrew University, Jerusalem, Israel, Department of Medical Neurobiology (Physiology), Institute of Medical Research – Israel-Canada (IMRIC), The Hebrew University-Hadassah Medical School, Jerusalem, Israel; Marmor-Levin O., Department of Medical Neurobiology (Physiology), Institute of Medical Research – Israel-Canada (IMRIC), The Hebrew University-Hadassah Medical School, Jerusalem, Israel; Deffains M., Department of Medical Neurobiology (Physiology), Institute of Medical Research – Israel-Canada (IMRIC), The Hebrew University-Hadassah Medical School, Jerusalem, Israel; Eitan R., Department of Psychiatry, Hadassah-Hebrew University Medical Center, Jerusalem, Israel; Blackwell K.T., Krasnow Institute for Advanced Study, George Mason University, Fairfax, VA, United States; Bergman H., The Edmond and Lily Safra Center for Brain Research (ELSC), The Hebrew University, Jerusalem, Israel, Department of Medical Neurobiology (Physiology), Institute of Medical Research – Israel-Canada (IMRIC), The Hebrew University-Hadassah Medical School, Jerusalem, Israel; Israel Z., Center for Functional & Restorative Neurosurgery, Department of Neurosurgery, Hadassah-Hebrew University Medical Center, Jerusalem, Israel","Background: Microelectrode recordings along preplanned trajectories are often used for accurate definition of the subthalamic nucleus (STN) borders during deep brain stimulation (DBS) surgery for Parkinson's disease. Usually, the demarcation of the STN borders is performed manually by a neurophysiologist. The exact detection of the borders is difficult, especially detecting the transition between the STN and the substantia nigra pars reticulata. Consequently, demarcation may be inaccurate, leading to suboptimal location of the DBS lead and inadequate clinical outcomes. Methods: We present machine-learning classification procedures that use microelectrode recording power spectra and allow for real-time, high-accuracy discrimination between the STN and substantia nigra pars reticulata. Results: A support vector machine procedure was tested on microelectrode recordings from 58 trajectories that included both STN and substantia nigra pars reticulata that achieved a 97.6% consistency with human expert classification (evaluated by 10-fold cross-validation). We used the same data set as a training set to find the optimal parameters for a hidden Markov model using both microelectrode recording features and trajectory history to enable real-time classification of the ventral STN border (STN exit). Seventy-three additional trajectories were used to test the reliability of the learned statistical model in identifying the exit from the STN. The hidden Markov model procedure identified the STN exit with an error of 0.04 ± 0.18 mm and detection reliability (error < 1 mm) of 94%. Conclusions: The results indicate that robust, accurate, and automatic real-time electrophysiological detection of the ventral STN border is feasible. © 2016 International Parkinson and Movement Disorder Society. © 2016 International Parkinson and Movement Disorder Society","deep brain stimulation; microelectrode recording; Parkinson's disease; substantia nigra; subthalamic nucleus","Aged; Deep Brain Stimulation; Electrodes, Implanted; Electrophysiological Phenomena; Female; Humans; Male; Markov Chains; Microelectrodes; Middle Aged; Parkinson Disease; Signal Processing, Computer-Assisted; Substantia Nigra; Subthalamic Nucleus; Support Vector Machine; adult; Article; brain depth stimulation; classification algorithm; female; hidden Markov model; human; machine learning; major clinical study; male; microelectrode; middle aged; Parkinson disease; power spectrum; priority journal; substantia nigra pars reticulata; subthalamus; support vector machine; aged; anatomy and histology; brain depth stimulation; electrode implant; electrophysiology; Markov chain; Parkinson disease; physiology; procedures; signal processing; substantia nigra; subthalamic nucleus; support vector machine","John Wiley and Sons Inc.","08853185","","MOVDE","27709666","Article","Scopus","2-s2.0-84990841545"
"Yu L.; Chen H.; Dou Q.; Qin J.; Heng P.A.","Yu, Lequan (56903335400); Chen, Hao (56493367600); Dou, Qi (56903795500); Qin, Jing (35339855100); Heng, Pheng Ann (7006677755)","56903335400; 56493367600; 56903795500; 35339855100; 7006677755","Integrating Online and Offline Three-Dimensional Deep Learning for Automated Polyp Detection in Colonoscopy Videos","2017","IEEE Journal of Biomedical and Health Informatics","184","10.1109/JBHI.2016.2637004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014899291&doi=10.1109%2fJBHI.2016.2637004&partnerID=40&md5=09bfdc37b6f0e7ca87a7fd7383bd86e7","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hong Kong; Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China","Yu L., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Chen H., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Dou Q., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Qin J., Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hong Kong; Heng P.A., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China","Automated polyp detection in colonoscopy videos has been demonstrated to be a promising way for colorectal cancer prevention and diagnosis. Traditional manual screening is time consuming, operator dependent, and error prone; hence, automated detection approach is highly demanded in clinical practice. However, automated polyp detection is very challenging due to high intraclass variations in polyp size, color, shape, and texture, and low interclass variations between polyps and hard mimics. In this paper, we propose a novel offline and online three-dimensional (3-D) deep learning integration framework by leveraging the 3-D fully convolutional network (3D-FCN) to tackle this challenging problem. Compared with the previous methods employing hand-crafted features or 2-D convolutional neural network, the 3D-FCN is capable of learning more representative spatio-temporal features from colonoscopy videos, and hence has more powerful discrimination capability. More importantly, we propose a novel online learning scheme to deal with the problem of limited training data by harnessing the specific information of an input video in the learning process. We integrate offline and online learning to effectively reduce the number of false positives generated by the offline network and further improve the detection performance. Extensive experiments on the dataset of MICCAI 2015 Challenge on Polyp Detection demonstrated the better performance of our method when compared with other competitors. © 2013 IEEE.","Automated polyp detection; colonoscopy video; computer-aided diagnosis; convolutional neural networks (CNNs); deep learning","Colonic Polyps; Colonoscopy; Humans; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Neural Networks (Computer); Video Recording; Automation; Computer aided diagnosis; Computer aided instruction; Convolution; Convolutional neural networks; Deep neural networks; Diseases; E-learning; Endoscopy; Learning systems; Textures; Colonoscopy; Convolutional networks; Integration frameworks; Intra-class variation; Online learning scheme; Polyp detection; Spatio temporal features; Threedimensional (3-d); architecture; Article; artificial neural network; cancer diagnosis; clinical practice; colonoscopy; colorectal cancer; machine learning; measurement precision; polyp; software; three dimensional deep learning; training; artificial neural network; colon polyp; colonoscopy; computer assisted diagnosis; diagnostic imaging; human; procedures; three dimensional imaging; videorecording; Deep learning","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28114049","Article","Scopus","2-s2.0-85014899291"
"Donné S.; De Vylder J.; Goossens B.; Philips W.","Donné, Simon (56349104900); De Vylder, Jonas (35110984500); Goossens, Bart (23396430300); Philips, Wilfried (7005218159)","56349104900; 35110984500; 23396430300; 7005218159","MATE: Machine learning for adaptive calibration template detection","2016","Sensors (Switzerland)","29","10.3390/s16111858","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995403795&doi=10.3390%2fs16111858&partnerID=40&md5=b9486a770e1ea1c1159eee2120d244fe","iMinds - IPI, Ghent University, Ghent, B-9000, Belgium","Donné S., iMinds - IPI, Ghent University, Ghent, B-9000, Belgium; De Vylder J., iMinds - IPI, Ghent University, Ghent, B-9000, Belgium; Goossens B., iMinds - IPI, Ghent University, Ghent, B-9000, Belgium; Philips W., iMinds - IPI, Ghent University, Ghent, B-9000, Belgium","The problem of camera calibration is two-fold. On the one hand, the parameters are estimated from known correspondences between the captured image and the real world. On the other, these correspondences themselves—typically in the form of chessboard corners—need to be found. Many distinct approaches for this feature template extraction are available, often of large computational and/or implementational complexity. We exploit the generalized nature of deep learning networks to detect checkerboard corners: our proposed method is a convolutional neural network (CNN) trained on a large set of example chessboard images, which generalizes several existing solutions. The network is trained explicitly against noisy inputs, as well as inputs with large degrees of lens distortion. The trained network that we evaluate is as accurate as existing techniques while offering improved execution time and increased adaptability to specific situations with little effort. The proposed method is not only robust against the types of degradation present in the training set (lens distortions, and large amounts of sensor noise), but also to perspective deformations, e.g., resulting from multi-camera set-ups. © 2016 by the authors; licensee MDPI, Basel, Switzerland.","Camera calibration; Checkerboard detection; Computer vision; Deep learning","Calibration; Cameras; Computer vision; Edge detection; Neural networks; Adaptive calibration; Camera calibration; Convolutional Neural Networks (CNN); Execution time; Feature template; Learning network; Lens distortion; Template detection; Deep learning","MDPI AG","14248220","","","","Article","Scopus","2-s2.0-84995403795"
"Yang W.; Chen Y.; Liu Y.; Zhong L.; Qin G.; Lu Z.; Feng Q.; Chen W.","Yang, Wei (56982069100); Chen, Yingyin (57196266311); Liu, Yunbi (57190948977); Zhong, Liming (56966065200); Qin, Genggeng (35785080200); Lu, Zhentai (22835908900); Feng, Qianjin (14826518100); Chen, Wufan (7409640550)","56982069100; 57196266311; 57190948977; 56966065200; 35785080200; 22835908900; 14826518100; 7409640550","Cascade of multi-scale convolutional neural networks for bone suppression of chest radiographs in gradient domain","2017","Medical Image Analysis","99","10.1016/j.media.2016.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984611707&doi=10.1016%2fj.media.2016.08.004&partnerID=40&md5=b6dcf9cc97306f0e66671e6a323d315e","Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Radiology Department, Nanfang Hospital, Southern Medical University, Guangzhou, China","Yang W., Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Chen Y., Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Liu Y., Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Zhong L., Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Qin G., Radiology Department, Nanfang Hospital, Southern Medical University, Guangzhou, China; Lu Z., Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Feng Q., Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China; Chen W., Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China","Suppression of bony structures in chest radiographs (CXRs) is potentially useful for radiologists and computer-aided diagnostic schemes. In this paper, we present an effective deep learning method for bone suppression in single conventional CXR using deep convolutional neural networks (ConvNets) as basic prediction units. The deep ConvNets were adapted to learn the mapping between the gradients of the CXRs and the corresponding bone images. We propose a cascade architecture of ConvNets (called CamsNet) to refine progressively the predicted bone gradients in which the ConvNets work at successively increased resolutions. The predicted bone gradients at different scales from the CamsNet are fused in a maximum-a-posteriori framework to produce the final estimation of a bone image. This estimation of a bone image is subtracted from the original CXR to produce a soft-tissue image in which the bone components are eliminated. Our method was evaluated on a dataset that consisted of 504 cases of real two-exposure dual-energy subtraction chest radiographs (404 cases for training and 100 cases for test). The results demonstrate that our method can produce high-quality and high-resolution bone and soft-tissue images. The average relative mean absolute error of the produced bone images and peak signal-to-noise ratio of the produced soft-tissue images were 3.83% and 38.7 dB, respectively. The average bone suppression ratio of our method was 83.8% for the CXRs with pixel sizes of nearly 0.194 mm. Furthermore, we apply the trained CamsNet model on the CXRs acquired by various types of X-ray machines, including scanned films, and our method can also produce visually appealing bone and soft-tissue images. © 2016 Elsevier B.V.","Bone suppression; Chest radiography; Convolutional neural network; Dual-energy subtraction","Algorithms; Bone and Bones; Diagnosis, Computer-Assisted; Neural Networks (Computer); Radiography, Thoracic; Convolution; Neural networks; Radiography; Signal to noise ratio; Statistical tests; Tissue; X ray radiography; Cascade architecture; Chest radiography; Computer aided diagnostics; Convolutional neural network; Dual-energy subtraction; Maximum a posteriori; Mean absolute error; Peak signal to noise ratio; adult; aged; Article; artificial neural network; convolutional neural network; female; human; image analysis; image subtraction; male; middle aged; prediction; priority journal; signal noise ratio; thorax radiography; algorithm; bone; computer assisted diagnosis; procedures; thorax radiography; Bone","Elsevier B.V.","13618415","","MIAEC","27589577","Article","Scopus","2-s2.0-84984611707"
"Kearnes S.; McCloskey K.; Berndl M.; Pande V.; Riley P.","Kearnes, Steven (56024189200); McCloskey, Kevin (57190844718); Berndl, Marc (7801530630); Pande, Vijay (7004966384); Riley, Patrick (7201512537)","56024189200; 57190844718; 7801530630; 7004966384; 7201512537","Molecular graph convolutions: moving beyond fingerprints","2016","Journal of Computer-Aided Molecular Design","1005","10.1007/s10822-016-9938-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983438115&doi=10.1007%2fs10822-016-9938-8&partnerID=40&md5=80608e98bc37c14925e971cc490df9cb","Stanford University, 318 Campus Dr. S296, Stanford, 94305, CA, United States; Google Inc., 1600 Amphitheatre Pkwy, Mountain View, 94043, CA, United States","Kearnes S., Stanford University, 318 Campus Dr. S296, Stanford, 94305, CA, United States; McCloskey K., Google Inc., 1600 Amphitheatre Pkwy, Mountain View, 94043, CA, United States; Berndl M., Google Inc., 1600 Amphitheatre Pkwy, Mountain View, 94043, CA, United States; Pande V., Stanford University, 318 Campus Dr. S296, Stanford, 94305, CA, United States; Riley P., Google Inc., 1600 Amphitheatre Pkwy, Mountain View, 94043, CA, United States","Molecular “fingerprints” encoding structural information are the workhorse of cheminformatics and machine learning in drug discovery applications. However, fingerprint representations necessarily emphasize particular aspects of the molecular structure while ignoring others, rather than allowing the model to make data-driven decisions. We describe molecular graph convolutions, a machine learning architecture for learning from undirected graphs, specifically small molecules. Graph convolutions use a simple encoding of the molecular graph—atoms, bonds, distances, etc.—which allows the model to take greater advantage of information in the graph structure. Although graph convolutions do not outperform all fingerprint-based methods, they (along with other graph-based methods) represent a new paradigm in ligand-based virtual screening with exciting opportunities for future improvement. © 2016, Springer International Publishing Switzerland.","Artificial neural networks; Deep learning; Machine learning; Molecular descriptors; Virtual screening","Computer Graphics; Computer-Aided Design; Drug Design; Ligands; Machine Learning; Molecular Structure; Neural Networks (Computer); Pharmaceutical Preparations; Deep neural networks; E-learning; Encoding (symbols); Graphic methods; Signal encoding; drug; ligand; Cheminformatics; Deep learning; Drug discovery applications; Encodings; Machine-learning; Molecular descriptors; Molecular fingerprint; Molecular graphs; Structural information; Virtual Screening; Article; atom; histogram; machine learning; molecular graph convolution; molecular model; molecule; priority journal; artificial neural network; chemical structure; chemistry; computer aided design; computer graphics; drug design; Convolution","Springer International Publishing","0920654X","","JCADE","27558503","Article","Scopus","2-s2.0-84983438115"
"Tomczak J.M.","Tomczak, Jakub M. (36471022200)","36471022200","Learning Informative Features from Restricted Boltzmann Machines","2016","Neural Processing Letters","12","10.1007/s11063-015-9491-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949498013&doi=10.1007%2fs11063-015-9491-9&partnerID=40&md5=cfd7e5a2c64b1264beedf7e35f7b5c03","Wrocław Universtity of Technology, Wybrzeże Wyspiańskiego 27, Wrocław, 50-370, Poland","Tomczak J.M., Wrocław Universtity of Technology, Wybrzeże Wyspiańskiego 27, Wrocław, 50-370, Poland","In recent years deep learning paradigm achieved important empirical success in a number of practical applications such as object recognition, speech recognition and natural language processing. A lot of effort has been put on understanding theoretical aspects of this success, however, still there is no common view on how deep architectures should be trained and thus many open questions remain. One hypothesis focuses on formulating good criterion (prior) that may help to learn a set of features capable of disentangling hidden factors. Following this line of thinking, in this paper, we propose to add a penalty (regularization) term to the log-likelihood function that enforces hidden units to maximize entropy and to be pairwise uncorrelated, for given observables. We hypothesize that the proposed framework for learning informative features results in more discriminative data representation that maintains its generative capabilities. In order to verify our hypothesis we apply the regularization term to the Restricted Boltzmann Machine (RBM) and carry out empirical study on three classification problems: character recognition, object recognition, and document classification. The experiments confirm that the proposed approach indeed increases discriminative and generative performance in comparison to RBM trained without any regularization and with the weight-decay, the sparse regularization, the max-norm regularization, Dropout and Dropconnect. © 2015, The Author(s).","Entropy-based regularization; Orthonormality regularization; Restricted Boltzmann machine; Unsupervised learning","Character recognition; Entropy; Information retrieval systems; Natural language processing systems; Object recognition; Unsupervised learning; Data representations; Document Classification; Entropy-based; Log-likelihood functions; NAtural language processing; Orthonormality; Restricted boltzmann machine; Sparse regularizations; Speech recognition","Springer New York LLC","13704621","","NPLEF","","Article","Scopus","2-s2.0-84949498013"
"Hannink J.; Kautz T.; Pasluosta C.F.; Gasmann K.-G.; Klucken J.; Eskofier B.M.","Hannink, Julius (56352302600); Kautz, Thomas (56610128200); Pasluosta, Cristian F. (23051695200); Gasmann, Karl-Gunter (57193561894); Klucken, Jochen (6603201965); Eskofier, Bjoern M. (26428080900)","56352302600; 56610128200; 23051695200; 57193561894; 6603201965; 26428080900","Sensor-Based Gait Parameter Extraction with Deep Convolutional Neural Networks","2017","IEEE Journal of Biomedical and Health Informatics","132","10.1109/JBHI.2016.2636456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014939929&doi=10.1109%2fJBHI.2016.2636456&partnerID=40&md5=e38738f0f631f58b06ab562ceb377c1b","Digital Sports Group, Pattern Recognition Lab, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Geriatrics Center Erlangen, Waldkrankenhaus St. Marien, Erlangen, Germany; Department of Molecular Neurology, University Hospital Erlangen, University of Erlangen-Nürnberg (FAU), Erlangen, Germany","Hannink J., Digital Sports Group, Pattern Recognition Lab, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Kautz T., Digital Sports Group, Pattern Recognition Lab, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Pasluosta C.F., Digital Sports Group, Pattern Recognition Lab, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Gasmann K.-G., Geriatrics Center Erlangen, Waldkrankenhaus St. Marien, Erlangen, Germany; Klucken J., Department of Molecular Neurology, University Hospital Erlangen, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Eskofier B.M., Digital Sports Group, Pattern Recognition Lab, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany","Measurement of stride-related, biomechanical parameters is the common rationale for objective gait impairment scoring. State-of-the-art double-integration approaches to extract these parameters from inertial sensor data are, however, limited in their clinical applicability due to the underlying assumptions. To overcome this, we present a method to translate the abstract information provided by wearable sensors to context-related expert features based on deep convolutional neural networks. Regarding mobile gait analysis, this enables integration-free and data-driven extraction of a set of eight spatio-temporal stride parameters. To this end, two modeling approaches are compared: a combined network estimating all parameters of interest and an ensemble approach that spawns less complex networks for each parameter individually. The ensemble approach is outperforming the combined modeling in the current application. On a clinically relevant and publicly available benchmark dataset, we estimate stride length, width and medio-lateral change in foot angle up to -0.15 ± 6.09 cm, -0.09 ± 4.22 cm and 0.13 ± 3.78° respectively. Stride, swing and stance time as well as heel and toe contact times are estimated up to ± 0.07, ± 0.05, ± 0.07, ± 0.07 and ± 0.12 s respectively. This is comparable to and in parts outperforming or defining state of the art. Our results further indicate that the proposed change in the methodology could substitute assumption-driven double-integration methods and enable mobile assessment of spatio-temporal stride parameters in clinically critical situations as, e.g., in the case of spastic gait impairments. © 2013 IEEE.","Convolutional neural networks (CNNs); deep learning; mobile gait analysis; regression; spatio-temporal gait parameters","Accelerometry; Foot; Gait; Humans; Machine Learning; Neural Networks (Computer); Regression Analysis; Signal Processing, Computer-Assisted; Walking; Complex networks; Convolution; Data integration; Data mining; Deep learning; Deep neural networks; Extraction; Gait analysis; Integration; Parameter estimation; Wearable sensors; Benchmark datasets; Biomechanical parameters; Double-integration; Ensemble approaches; Gait parameters; Mobile gait analysis; regression; State of the art; architecture; Article; clinical assessment; conceptual framework; coronary artery disease; gait; heart arrhythmia; human; hypertension; nerve cell network; network architecture; sensor; training; accelerometry; artificial neural network; devices; foot; gait; machine learning; physiology; regression analysis; signal processing; walking; Convolutional neural networks","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28103196","Article","Scopus","2-s2.0-85014939929"
"Park J.-G.; Jo S.","Park, Jung-Guk (57190884359); Jo, Sungho (36922784600)","57190884359; 36922784600","Approximate Bayesian MLP regularization for regression in the presence of noise","2016","Neural Networks","24","10.1016/j.neunet.2016.07.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983781027&doi=10.1016%2fj.neunet.2016.07.010&partnerID=40&md5=6f69e2c2cbbf729f27b2fb403c79a03f","School of Computing, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 305-701, South Korea","Park J.-G., School of Computing, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 305-701, South Korea; Jo S., School of Computing, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 305-701, South Korea","We present a novel regularization method for a multilayer perceptron (MLP) that learns a regression function in the presence of noise regardless of how smooth the function is. Unlike general MLP regularization methods assuming that a regression function is smooth, the proposed regularization method is also valid when a regression function has discontinuities (non-smoothness). Since a true regression function to be learned is unknown, we examine a training set with our Bayesian approach that identifies non-smooth data, analyzing discontinuities in a regression function. The use of a Bayesian probability distribution identifies the non-smooth data. These identified data is used in a proposed objective function to fit an MLP response to the desired regression function regardless of its smoothness and noise. Experimental simulations show that the MLP with our presented training method yields more accurate fits to non-smooth functions than other MLP training methods. Further, we show that the suggested training methodology can be incorporated with deep learning models. © 2016 Elsevier Ltd","Bayesian method; Multilayer perceptron training; Non-smooth regression; Regularization; Weight-decay","Bayes Theorem; Machine Learning; Models, Theoretical; Neural Networks (Computer); Bayesian networks; Dynamic loads; Multilayers; Probability distributions; Approximate Bayesian; Bayesian methods; Experimental simulations; Multi layer perceptron; Non-smooth regression; Regularization; Regularization methods; Weight decay; Article; Bayesian learning; Gauss Newton Bayes regularization; information processing; Levenberg Marquard training; Limited memory Broyden Fletcher Goldfarb Shanno training; measurement accuracy; noise; perceptron; priority journal; probability; real world dataset; regression analysis; regression function; simulation; synthetic dataset; time series prediction; training dataset; artificial neural network; Bayes theorem; machine learning; theoretical model; Regression analysis","Elsevier Ltd","08936080","","NNETE","27584575","Article","Scopus","2-s2.0-84983781027"
"Zhang C.-Y.; Chen C.L.P.; Chen D.; NG K.T.","Zhang, Chun-Yang (56072612200); Chen, C.L. Philip (47861886300); Chen, Dewang (56066187200); NG, Kin Tek (57189340635)","56072612200; 47861886300; 56066187200; 57189340635","MapReduce based distributed learning algorithm for Restricted Boltzmann Machine","2016","Neurocomputing","29","10.1016/j.neucom.2015.09.129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969567992&doi=10.1016%2fj.neucom.2015.09.129&partnerID=40&md5=8ea4ffe0cccee2e57abe3245064d755c","College of Mathematics and Computer Science, Fuzhou University, China; Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macao","Zhang C.-Y., College of Mathematics and Computer Science, Fuzhou University, China, Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macao; Chen C.L.P., Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macao; Chen D., College of Mathematics and Computer Science, Fuzhou University, China; NG K.T., Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macao","Deep learning is recently regarded as the closest artificial intelligence model to human brain. It is about learning multiple levels of representation and abstraction that help to make sense of data such as images, sound, and text. One deep model often consists of a hierarchical architecture that has the capability to model super non-linear and stochastic problems. Restricted Boltzmann Machine (RBM) is the main constructing block of current deep networks, as most of deep architectures are built with it. Based on MapReduce framework and Hadoop distributed file system, this paper proposes a distributed algorithm for training the RBM model. Its implementation and performance are evaluated on Big Data platform-Hadoop. The main contribution of the new learning algorithm is that it solves the scalability problem that limits the development of deep learning. The intelligence growing process of human brain requires learning from Big Data. The distributed learning mechanism for RBM makes it possible to abstract sophisticated and informative features from Big Data to achieve high-level intelligence. The evaluations of the proposed learning algorithm are carried out on image inpainting and classification problems based on the BAS dataset and MNIST hand-written digits dataset. © 2016 Elsevier B.V.","Big data; Deep learning; MapReduce; Restricted boltzmann machine","Abstracting; Algorithms; Artificial intelligence; Big data; Brain; Classification (of information); File organization; Network architecture; Stochastic models; Stochastic systems; Deep learning; Distributed learning; Distributed learning algorithms; Hadoop distributed file systems; Hierarchical architectures; Map-reduce; Restricted boltzmann machine; Scalability problems; Article; artificial intelligence; artificial neural network; computer interface; computer program; controlled study; information processing; learning algorithm; measurement accuracy; priority journal; process design; Restricted Boltzmann Machine; Learning algorithms","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84969567992"
"Winkler D.A.; Le T.C.","Winkler, David A. (7102950474); Le, Tu C. (55573713700)","7102950474; 55573713700","Performance of Deep and Shallow Neural Networks, the Universal Approximation Theorem, Activity Cliffs, and QSAR","2017","Molecular Informatics","86","10.1002/minf.201600118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999748027&doi=10.1002%2fminf.201600118&partnerID=40&md5=97dcb709ad78737e04c0f5efd4bc056e","CSIRO Manufacturing, Clayton, 3168, Australia; Monash Institute of Pharmaceutical Sciences, Monash University, Parkville, 3052, Australia; Latrobe Institute for Molecular Science, Latrobe University, Bundoora, 3082, Australia; School of Chemical and Physical Science, Flinders University, Bedford Park, 5042, Australia","Winkler D.A., CSIRO Manufacturing, Clayton, 3168, Australia, Monash Institute of Pharmaceutical Sciences, Monash University, Parkville, 3052, Australia, Latrobe Institute for Molecular Science, Latrobe University, Bundoora, 3082, Australia, School of Chemical and Physical Science, Flinders University, Bedford Park, 5042, Australia; Le T.C., CSIRO Manufacturing, Clayton, 3168, Australia","Neural networks have generated valuable Quantitative Structure-Activity/Property Relationships (QSAR/QSPR) models for a wide variety of small molecules and materials properties. They have grown in sophistication and many of their initial problems have been overcome by modern mathematical techniques. QSAR studies have almost always used so-called “shallow” neural networks in which there is a single hidden layer between the input and output layers. Recently, a new and potentially paradigm-shifting type of neural network based on Deep Learning has appeared. Deep learning methods have generated impressive improvements in image and voice recognition, and are now being applied to QSAR and QSAR modelling. This paper describes the differences in approach between deep and shallow neural networks, compares their abilities to predict the properties of test sets for 15 large drug data sets (the kaggle set), discusses the results in terms of the Universal Approximation theorem for neural networks, and describes how DNN may ameliorate or remove troublesome “activity cliffs” in QSAR data sets. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","activity cliff; Bayesian regularized neural network; deep learning; deep neural network; shallow neural network; universal approximation theorem","Drug Design; Machine Learning; Molecular Docking Simulation; Quantitative Structure-Activity Relationship; Small Molecule Libraries; Approximation theory; Bayesian networks; Computational chemistry; Image enhancement; Landforms; Materials properties; Multilayer neural networks; Statistical tests; Activity cliff; Approximation theorem; Bayesian; Bayesian regularized neural network; Deep learning; Neural-networks; Regularized neural networks; Shallow neural network; Universal approximation; Universal approximation theorem; algorithm; Article; artificial neural network; automatic speech recognition; Bayes theorem; data analysis; deep learning; machine learning; mathematical analysis; prediction; priority journal; quantitative structure activity relation; random forest; chemistry; comparative study; drug design; machine learning; molecular docking; molecular library; pharmacology; procedures; standards; Deep neural networks","Wiley-VCH Verlag","18681743","","MIONB","27783464","Article","Scopus","2-s2.0-84999748027"
"Henriksson A.; Zhao J.; Dalianis H.; Boström H.","Henriksson, Aron (52463615100); Zhao, Jing (57188829771); Dalianis, Hercules (6506899838); Boström, Henrik (7006594020)","52463615100; 57188829771; 6506899838; 7006594020","Ensembles of randomized trees using diverse distributed representations of clinical events","2016","BMC Medical Informatics and Decision Making","17","10.1186/s12911-016-0309-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978923841&doi=10.1186%2fs12911-016-0309-0&partnerID=40&md5=434a2f3b8c6b87f22afc4c7c53f9fe7e","Department of Computer and Systems Sciences, Stockholm University, Borgarfjordsgatan 12, Kista, SE-16407, Sweden","Henriksson A., Department of Computer and Systems Sciences, Stockholm University, Borgarfjordsgatan 12, Kista, SE-16407, Sweden; Zhao J., Department of Computer and Systems Sciences, Stockholm University, Borgarfjordsgatan 12, Kista, SE-16407, Sweden; Dalianis H., Department of Computer and Systems Sciences, Stockholm University, Borgarfjordsgatan 12, Kista, SE-16407, Sweden; Boström H., Department of Computer and Systems Sciences, Stockholm University, Borgarfjordsgatan 12, Kista, SE-16407, Sweden","Background: Learning deep representations of clinical events based on their distributions in electronic health records has been shown to allow for subsequent training of higher-performing predictive models compared to the use of shallow, count-based representations. The predictive performance may be further improved by utilizing multiple representations of the same events, which can be obtained by, for instance, manipulating the representation learning procedure. The question, however, remains how to make best use of a set of diverse representations of clinical events - modeled in an ensemble of semantic spaces - for the purpose of predictive modeling. Methods: Three different ways of exploiting a set of (ten) distributed representations of four types of clinical events - diagnosis codes, drug codes, measurements, and words in clinical notes - are investigated in a series of experiments using ensembles of randomized trees. Here, the semantic space ensembles are obtained by varying the context window size in the representation learning procedure. The proposed method trains a forest wherein each tree is built from a bootstrap replicate of the training set whose entire original feature set is represented in a randomly selected set of semantic spaces - corresponding to the considered data types - of a given context window size. Results: The proposed method significantly outperforms concatenating the multiple representations of the bagged dataset; it also significantly outperforms representing, for each decision tree, only a subset of the features in a randomly selected set of semantic spaces. A follow-up analysis indicates that the proposed method exhibits less diversity while significantly improving average tree performance. It is also shown that the size of the semantic space ensemble has a significant impact on predictive performance and that performance tends to improve as the size increases. Conclusions: The strategy for utilizing a set of diverse distributed representations of clinical events when constructing ensembles of randomized trees has a significant impact on predictive performance. The most successful strategy - significantly outperforming the considered alternatives - involves randomly sampling distributed representations of the clinical events when building each decision tree in the forest. © 2016 The Author(s).","Adverse drug events; Distributional semantics; Electronic health records; Heterogeneous data; Pharmacovigilance; Random forest","Decision Trees; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Humans; Machine Learning; Models, Theoretical; Pharmacovigilance; Semantics; adverse drug reaction; decision tree; drug surveillance program; electronic health record; human; machine learning; semantics; theoretical model","BioMed Central Ltd","14726947","","","27459846","Article","Scopus","2-s2.0-84978923841"
"Lekadir K.; Galimzianova A.; Betriu A.; Del Mar Vila M.; Igual L.; Rubin D.L.; Fernandez E.; Radeva P.; Napel S.","Lekadir, Karim (15042517700); Galimzianova, Alfiia (37007345800); Betriu, Angels (7005111275); Del Mar Vila, Maria (57193564866); Igual, Laura (13612560000); Rubin, Daniel L. (7202307112); Fernandez, Elvira (57214647191); Radeva, Petia (56208405900); Napel, Sandy (7004386852)","15042517700; 37007345800; 7005111275; 57193564866; 13612560000; 7202307112; 57214647191; 56208405900; 7004386852","A Convolutional Neural Network for Automatic Characterization of Plaque Composition in Carotid Ultrasound","2017","IEEE Journal of Biomedical and Health Informatics","157","10.1109/JBHI.2016.2631401","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014891180&doi=10.1109%2fJBHI.2016.2631401&partnerID=40&md5=de5402744facbe92d7f170eff8fd66b7","Department of Radiology, Stanford University, School of Medicine, Stanford, 94305, CA, United States; Computer Vision Center, Barcelona, 08193, Spain; Unit for the Detection and Treatment of Atherothrombotic Diseases, Institute of Biomedical Research, Lleida, 25198, Spain; Cardiovascular Epidemiology and Genetics Research Group, Hospital Del Mar Medical Research Institute, Barcelona, 08003, Spain; Department of Mathematics and Computer Science, Universitat de Barcelona, 08007, Spain","Lekadir K., Department of Radiology, Stanford University, School of Medicine, Stanford, 94305, CA, United States, Computer Vision Center, Barcelona, 08193, Spain; Galimzianova A., Department of Radiology, Stanford University, School of Medicine, Stanford, 94305, CA, United States; Betriu A., Unit for the Detection and Treatment of Atherothrombotic Diseases, Institute of Biomedical Research, Lleida, 25198, Spain; Del Mar Vila M., Cardiovascular Epidemiology and Genetics Research Group, Hospital Del Mar Medical Research Institute, Barcelona, 08003, Spain; Igual L., Computer Vision Center, Barcelona, 08193, Spain, Department of Mathematics and Computer Science, Universitat de Barcelona, 08007, Spain; Rubin D.L., Department of Radiology, Stanford University, School of Medicine, Stanford, 94305, CA, United States; Fernandez E., Unit for the Detection and Treatment of Atherothrombotic Diseases, Institute of Biomedical Research, Lleida, 25198, Spain; Radeva P., Computer Vision Center, Barcelona, 08193, Spain, Department of Mathematics and Computer Science, Universitat de Barcelona, 08007, Spain; Napel S., Department of Radiology, Stanford University, School of Medicine, Stanford, 94305, CA, United States","Characterization of carotid plaque composition, more specifically the amount of lipid core, fibrous tissue, and calcified tissue, is an important task for the identification of plaques that are prone to rupture, and thus for early risk estimation of cardiovascular and cerebrovascular events. Due to its low costs and wide availability, carotid ultrasound has the potential to become the modality of choice for plaque characterization in clinical practice. However, its significant image noise, coupled with the small size of the plaques and their complex appearance, makes it difficult for automated techniques to discriminate between the different plaque constituents. In this paper, we propose to address this challenging problem by exploiting the unique capabilities of the emerging deep learning framework. More specifically, and unlike existing works which require a priori definition of specific imaging features or thresholding values, we propose to build a convolutional neural network (CNN) that will automatically extract from the images the information that is optimal for the identification of the different plaque constituents. We used approximately 90 000 patches extracted from a database of images and corresponding expert plaque characterizations to train and to validate the proposed CNN. The results of cross-validation experiments show a correlation of about 0.90 with the clinical assessment for the estimation of lipid core, fibrous cap, and calcified tissue areas, indicating the potential of deep learning for the challenging task of automatic characterization of plaque composition in carotid ultrasound. © 2013 IEEE.","Atherosclerosis; carotid artery; convolutional neural networks (CNNs); plaque composition; ultrasound","Carotid Arteries; Carotid Artery Diseases; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Plaque, Atherosclerotic; Ultrasonography; Convolution; Deep learning; Image processing; Risk perception; Tissue; Ultrasonics; Atherosclerosis; Automated techniques; Carotid artery; Carotid ultrasounds; Clinical assessments; Clinical practices; Learning frameworks; Plaque characterizations; Article; carotid atherosclerosis; clinical assessment; conceptual framework; data base; deep learning framework; echography; human; machine learning; measurement accuracy; nerve cell network; prediction; sensitivity and specificity; support vector machine; training; artificial neural network; atherosclerotic plaque; carotid artery; carotid artery disease; diagnostic imaging; echography; image processing; procedures; Convolutional neural networks","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","27893402","Article","Scopus","2-s2.0-85014891180"
"Schneider P.; Müller A.T.; Gabernet G.; Button A.L.; Posselt G.; Wessler S.; Hiss J.A.; Schneider G.","Schneider, Petra (55156775800); Müller, Alex T. (57164240800); Gabernet, Gisela (55053581000); Button, Alexander L. (57164561500); Posselt, Gernot (14045830100); Wessler, Silja (7102329587); Hiss, Jan A. (16177469500); Schneider, Gisbert (7402466014)","55156775800; 57164240800; 55053581000; 57164561500; 14045830100; 7102329587; 16177469500; 7402466014","Hybrid Network Model for “Deep Learning” of Chemical Data: Application to Antimicrobial Peptides","2017","Molecular Informatics","38","10.1002/minf.201600011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960539870&doi=10.1002%2fminf.201600011&partnerID=40&md5=f4f475c01a393fe00a188f21c9afd914","Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; inSili.com LLC, Segantinisteig 3, Zurich, CH-8049, Switzerland; Paris-Lodron Universität Salzburg, Division of Microbiology, Billroth Str. 11, Salzburg, A-5020, Austria","Schneider P., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland, inSili.com LLC, Segantinisteig 3, Zurich, CH-8049, Switzerland; Müller A.T., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Gabernet G., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Button A.L., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Posselt G., Paris-Lodron Universität Salzburg, Division of Microbiology, Billroth Str. 11, Salzburg, A-5020, Austria; Wessler S., Paris-Lodron Universität Salzburg, Division of Microbiology, Billroth Str. 11, Salzburg, A-5020, Austria; Hiss J.A., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland; Schneider G., Swiss Federal Institute of Technology (ETH), Department of Chemistry and Applied Biosciences, Vladimir-Prelog-Weg 4, Zurich, CH-8093, Switzerland","We present a “deep” network architecture for chemical data analysis and classification together with a prospective proof-of-concept application. The model features a self-organizing map (SOM) as the input layer of a feedforward neural network. The SOM converts molecular descriptors to a two-dimensional image for further processing. We implemented lateral neuron inhibition for contrast enhancement. The model achieved improved classification accuracy and predictive robustness compared to feedforward network classifiers lacking the SOM layer. By nonlinear dimensionality reduction the networks extracted meaningful chemical features from the data and outperformed linear principal component analysis (PCA). The learning machine was trained on the sequence-length independent recognition of antibacterial peptides and correctly predicted the killing activity of a synthetic test peptide against Staphylococcus aureus in an in vitro experiment. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","dimensionality reduction; machine learning; membrane; neural network; peptide design","Antimicrobial Cationic Peptides; Machine Learning; Principal Component Analysis; Staphylococcus aureus; Bacteria; Computerized tomography; Conformal mapping; Deep learning; Feedforward neural networks; Network architecture; Peptides; Principal component analysis; polypeptide antibiotic agent; trifluoroethanol; antimicrobial cationic peptide; Antimicrobial peptide; Chemical data; Data application; Dimensionality reduction; Hybrid network models; Machine-learning; Neural-networks; Peptide design; Prospectives; Self-organizing-maps; accuracy; amino acid sequence; antimicrobial activity; Article; artificial neural network; bactericidal activity; circular dichroism; classification; contrast enhancement; controlled study; data analysis; in vitro study; machine learning; nonhuman; pharmacophore; prediction; principal component analysis; priority journal; self organizing map; Staphylococcus aureus; structure activity relation; chemistry; drug effect; machine learning; Self organizing maps","Wiley-VCH Verlag","18681743","","MIONB","28124834","Article","Scopus","2-s2.0-84960539870"
"Zhu Z.; Wang X.; Bai S.; Yao C.; Bai X.","Zhu, Zhuotun (56473072700); Wang, Xinggang (36100811100); Bai, Song (57206839797); Yao, Cong (55336187500); Bai, Xiang (15130916600)","56473072700; 36100811100; 57206839797; 55336187500; 15130916600","Deep Learning Representation using Autoencoder for 3D Shape Retrieval","2016","Neurocomputing","107","10.1016/j.neucom.2015.08.127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965113078&doi=10.1016%2fj.neucom.2015.08.127&partnerID=40&md5=ff45830d2f7894238ab8d9ba6161b462","School of Electronic Information and Communications, Huazhong Univerisity of Science and Technology, 1037 Luoyu Road, Wuhan, Hubei Province, 430074, China","Zhu Z., School of Electronic Information and Communications, Huazhong Univerisity of Science and Technology, 1037 Luoyu Road, Wuhan, Hubei Province, 430074, China; Wang X., School of Electronic Information and Communications, Huazhong Univerisity of Science and Technology, 1037 Luoyu Road, Wuhan, Hubei Province, 430074, China; Bai S., School of Electronic Information and Communications, Huazhong Univerisity of Science and Technology, 1037 Luoyu Road, Wuhan, Hubei Province, 430074, China; Yao C., School of Electronic Information and Communications, Huazhong Univerisity of Science and Technology, 1037 Luoyu Road, Wuhan, Hubei Province, 430074, China; Bai X., School of Electronic Information and Communications, Huazhong Univerisity of Science and Technology, 1037 Luoyu Road, Wuhan, Hubei Province, 430074, China","We study the problem of how to build a deep learning representation for 3D shape. Deep learning has shown to be very effective in variety of visual applications, such as image classification and object detection. However, it has not been successfully applied to 3D shape recognition. This is because 3D shape has complex structure in 3D space and there are limited number of 3D shapes for feature learning. To address these problems, we project 3D shapes into 2D space and use autoencoder for feature learning on the 2D images. High accuracy 3D shape retrieval performance is obtained by aggregating the features learned on 2D images. In addition, we show the proposed deep learning feature is complementary to conventional local image descriptors. By combing the global deep learning representation and the local descriptor representation, our method can obtain the state-of-the-art performance on 3D shape retrieval benchmarks. © 2016.","3D Shape Matching; 3D Shape Retrieval; Autoencoder; Shape Representation","Benchmarking; Image processing; Learning systems; Object recognition; 3D shape matching; 3D shape recognition; 3D shape retrieval; Auto encoders; Local image descriptors; Shape representation; State-of-the-art performance; Visual applications; accuracy; Article; automation; classification; image display; image processing; information retrieval; machine learning; mathematical analysis; mathematical computing; priority journal; statistical analysis; structure analysis; three dimensional imaging; Image classification","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84965113078"
"Ravi D.; Wong C.; Lo B.; Yang G.-Z.","Ravi, Daniele (57201696886); Wong, Charence (7404953598); Lo, Benny (15834859900); Yang, Guang-Zhong (55539304100)","57201696886; 7404953598; 15834859900; 55539304100","A Deep Learning Approach to on-Node Sensor Data Analytics for Mobile or Wearable Devices","2017","IEEE Journal of Biomedical and Health Informatics","324","10.1109/JBHI.2016.2633287","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014926848&doi=10.1109%2fJBHI.2016.2633287&partnerID=40&md5=d5c1fae049b95e2613653be676e5d5bc","Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom","Ravi D., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Wong C., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Lo B., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Yang G.-Z., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom","The increasing popularity of wearable devices in recent years means that a diverse range of physiological and functional data can now be captured continuously for applications in sports, wellbeing, and healthcare. This wealth of information requires efficient methods of classification and analysis where deep learning is a promising technique for large-scale data analytics. While deep learning has been successful in implementations that utilize high-performance computing platforms, its use on low-power wearable devices is limited by resource constraints. In this paper, we propose a deep learning methodology, which combines features learned from inertial sensor data together with complementary information from a set of shallow features to enable accurate and real-time activity classification. The design of this combined method aims to overcome some of the limitations present in a typical deep learning framework where on-node computation is required. To optimize the proposed method for real-time on-node computation, spectral domain preprocessing is used before the data are passed onto the deep learning framework. The classification accuracy of our proposed deep learning approach is evaluated against state-of-the-art methods using both laboratory and real world activity datasets. Our results show the validity of the approach on different human activity datasets, outperforming other methods, including the two methods used within our combined pipeline. We also demonstrate that the computation times for the proposed method are consistent with the constraints of real-time on-node processing on smartphones and a wearable sensor platform. © 2013 IEEE.","ActiveMiles; deep learning; Human Activity Recognition (HAR); Internet-of-Things (IoT); low-power devices; wearable","Human Activities; Humans; Machine Learning; Monitoring, Ambulatory; Neural Networks (Computer); Signal Processing, Computer-Assisted; Classification (of information); Data Analytics; Internet of things; Learning systems; mHealth; Wearable sensors; ActiveMiles; Human activity recognition; Internet of Things (IOT); Low-power devices; wearable; Article; convolutional neural network; deep belief network; deep learning approach; electrocardiography; electromyography; gait; health care; learning algorithm; machine learning; measurement accuracy; mobile phone; physical activity; restricted Boltzmann machine; sport; support vector machine; wellbeing; ambulatory monitoring; artificial neural network; classification; devices; human; human activities; machine learning; procedures; signal processing; Deep learning","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28026792","Article","Scopus","2-s2.0-85014926848"
"Choi H.; Jin K.H.","Choi, Hongyoon (45760940100); Jin, Kyong Hwan (55153576800)","45760940100; 55153576800","Fast and robust segmentation of the striatum using deep convolutional neural networks","2016","Journal of Neuroscience Methods","62","10.1016/j.jneumeth.2016.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994012280&doi=10.1016%2fj.jneumeth.2016.10.007&partnerID=40&md5=a012fe01e8506873f2c70e639e4fe189","Department of Nuclear Medicine, Cheonan Public Health Center, Chungnam, South Korea; Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, 1015, Switzerland","Choi H., Department of Nuclear Medicine, Cheonan Public Health Center, Chungnam, South Korea; Jin K.H., Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, 1015, Switzerland","Background Automated segmentation of brain structures is an important task in structural and functional image analysis. We developed a fast and accurate method for the striatum segmentation using deep convolutional neural networks (CNN). New method T1 magnetic resonance (MR) images were used for our CNN-based segmentation, which require neither image feature extraction nor nonlinear transformation. We employed two serial CNN, Global and Local CNN The Global CNN determined approximate locations of the striatum. It performed a regression of input MR images fitted to smoothed segmentation maps of the striatum. From the output volume of Global CNN, cropped MR volumes which included the striatum were extracted. The cropped MR volumes and the output volumes of Global CNN were used for inputs of Local CNN. Local CNN predicted the accurate label of all voxels. Segmentation results were compared with a widely used segmentation method, FreeSurfer. Results Our method showed higher Dice Similarity Coefficient (DSC) (0.893 ± 0.017 vs. 0.786 ± 0.015) and precision score (0.905 ± 0.018 vs. 0.690 ± 0.022) than FreeSurfer-based striatum segmentation (p = 0.06). Our approach was also tested using another independent dataset, which showed high DSC (0.826 ± 0.038) comparable with that of FreeSurfer. Comparison with existing method Segmentation performance of our proposed method was comparable with that of FreeSurfer. The running time of our approach was approximately three seconds. Conclusion We suggested a fast and accurate deep CNN-based segmentation for small brain structures which can be widely applied to brain image analysis. © 2016 Elsevier B.V.","Convolutional neural network; Deep learning; MRI; Segmentation; Striatum","Adult; Brain Mapping; Corpus Striatum; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Models, Neurological; Nerve Net; Young Adult; adult; Article; brain region; brain tissue; convolutional neural network; corpus striatum; female; human; image analysis; image processing; image segmentation; imaging software; machine learning; male; normal human; nuclear magnetic resonance imaging; priority journal; task performance; young adult; anatomy and histology; biological model; brain mapping; corpus striatum; diagnostic imaging; nerve cell network; physiology","Elsevier B.V.","01650270","","JNMED","27777000","Article","Scopus","2-s2.0-84994012280"
"Stone J.R.; Wilde E.A.; Taylor B.A.; Tate D.F.; Levin H.; Bigler E.D.; Scheibel R.S.; Newsome M.R.; Mayer A.R.; Abildskov T.; Black G.M.; Lennon M.J.; York G.E.; Agarwal R.; DeVillasante J.; Ritter J.L.; Walker P.B.; Ahlers S.T.; Tustison N.J.","Stone, James R. (55728822200); Wilde, Elisabeth A. (8397084400); Taylor, Brian A. (23487261200); Tate, David F. (7103286989); Levin, Harvey (24448317100); Bigler, Erin D. (35228854600); Scheibel, Randall S. (6603684079); Newsome, Mary R. (6602089995); Mayer, Andrew R. (7201374794); Abildskov, Tracy (6505936159); Black, Garrett M. (56091903700); Lennon, Michael J. (56047394100); York, Gerald E. (7005085503); Agarwal, Rajan (55977128200); DeVillasante, Jorge (17342271700); Ritter, John L. (54886505800); Walker, Peter B. (39062323100); Ahlers, Stephen T. (6701708888); Tustison, Nicholas J. (6505987446)","55728822200; 8397084400; 23487261200; 7103286989; 24448317100; 35228854600; 6603684079; 6602089995; 7201374794; 6505936159; 56091903700; 56047394100; 7005085503; 55977128200; 17342271700; 54886505800; 39062323100; 6701708888; 6505987446","Supervised learning technique for the automated identification of white matter hyperintensities in traumatic brain injury","2016","Brain Injury","21","10.1080/02699052.2016.1222080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995489262&doi=10.1080%2f02699052.2016.1222080&partnerID=40&md5=32d3a515202e5d87ebfa69a2bc12af79","Department of Radiology and Medical Imaging, University of Virginia, Charlottesville, VA, United States; Department of Neurological Surgery, University of Virginia, Charlottesville, VA, United States; Michael E. DeBakey Veterans Affairs Medical Center, Houston, TX, United States; Department of Physical Medicine and Rehabilitation, Houston, TX, United States; Department of Neurology, Houston, TX, United States; Department of Radiology, Baylor College of Medicine, Houston, TX, United States; Missouri Institute of Mental Health, University of Missouri, St. Louis, MO, United States; Department of Psychology, Brigham Young University, Provo, UT, United States; Department of Translational Neuroscience, The Mind Research Network, Albuquerque, NM, United States; Department of Neurology, University of New Mexico Health Center, Albuquerque, NM, United States; Hunter Holmes McGuire Veterans Affairs Medical Center, Richmond, VA, United States; Alaska Radiology Associates, Anchorage, AK, United States; Department of Radiology, USF Morsani College of Medicine, Tampa, FL, United States; Department of Radiology, San Antonio Military Medical Center, San Antonio, TX, United States; Department of Radiology and Radiological Sciences, Uniformed Services University of the Health Sciences, Washington, DC, United States; Naval Medical Research Center, Silver Spring, MD, United States","Stone J.R., Department of Radiology and Medical Imaging, University of Virginia, Charlottesville, VA, United States, Department of Neurological Surgery, University of Virginia, Charlottesville, VA, United States; Wilde E.A., Michael E. DeBakey Veterans Affairs Medical Center, Houston, TX, United States, Department of Physical Medicine and Rehabilitation, Houston, TX, United States, Department of Neurology, Houston, TX, United States, Department of Radiology, Baylor College of Medicine, Houston, TX, United States; Taylor B.A., Michael E. DeBakey Veterans Affairs Medical Center, Houston, TX, United States, Department of Physical Medicine and Rehabilitation, Houston, TX, United States, Department of Radiology, Baylor College of Medicine, Houston, TX, United States; Tate D.F., Missouri Institute of Mental Health, University of Missouri, St. Louis, MO, United States; Levin H., Michael E. DeBakey Veterans Affairs Medical Center, Houston, TX, United States, Department of Physical Medicine and Rehabilitation, Houston, TX, United States, Department of Neurology, Houston, TX, United States; Bigler E.D., Department of Psychology, Brigham Young University, Provo, UT, United States; Scheibel R.S., Michael E. DeBakey Veterans Affairs Medical Center, Houston, TX, United States, Department of Physical Medicine and Rehabilitation, Houston, TX, United States; Newsome M.R., Michael E. DeBakey Veterans Affairs Medical Center, Houston, TX, United States, Department of Physical Medicine and Rehabilitation, Houston, TX, United States; Mayer A.R., Department of Translational Neuroscience, The Mind Research Network, Albuquerque, NM, United States, Department of Neurology, University of New Mexico Health Center, Albuquerque, NM, United States; Abildskov T., Department of Psychology, Brigham Young University, Provo, UT, United States; Black G.M., Department of Physical Medicine and Rehabilitation, Houston, TX, United States, Department of Psychology, Brigham Young University, Provo, UT, United States; Lennon M.J., Hunter Holmes McGuire Veterans Affairs Medical Center, Richmond, VA, United States; York G.E., Alaska Radiology Associates, Anchorage, AK, United States; Agarwal R., Michael E. DeBakey Veterans Affairs Medical Center, Houston, TX, United States; DeVillasante J., Department of Radiology, USF Morsani College of Medicine, Tampa, FL, United States; Ritter J.L., Department of Radiology, San Antonio Military Medical Center, San Antonio, TX, United States, Department of Radiology and Radiological Sciences, Uniformed Services University of the Health Sciences, Washington, DC, United States; Walker P.B., Naval Medical Research Center, Silver Spring, MD, United States; Ahlers S.T., Naval Medical Research Center, Silver Spring, MD, United States; Tustison N.J., Department of Radiology and Medical Imaging, University of Virginia, Charlottesville, VA, United States","Background: White matter hyperintensities (WMHs) are foci of abnormal signal intensity in white matter regions seen with magnetic resonance imaging (MRI). WMHs are associated with normal ageing and have shown prognostic value in neurological conditions such as traumatic brain injury (TBI). The impracticality of manually quantifying these lesions limits their clinical utility and motivates the utilization of machine learning techniques for automated segmentation workflows. Methods: This study develops a concatenated random forest framework with image features for segmenting WMHs in a TBI cohort. The framework is built upon the Advanced Normalization Tools (ANTs) and ANTsR toolkits. MR (3D FLAIR, T2- and T1-weighted) images from 24 service members and veterans scanned in the Chronic Effects of Neurotrauma Consortium’s (CENC) observational study were acquired. Manual annotations were employed for both training and evaluation using a leave-one-out strategy. Performance measures include sensitivity, positive predictive value, F1 score and relative volume difference. Results: Final average results were: sensitivity = 0.68 ± 0.38, positive predictive value = 0.51 ± 0.40, F1 = 0.52 ± 0.36, relative volume difference = 43 ± 26%. In addition, three lesion size ranges are selected to illustrate the variation in performance with lesion size. Conclusion: Paired with correlative outcome data, supervised learning methods may allow for identification of imaging features predictive of diagnosis and prognosis in individual TBI patients. ©, This article not subject to US copyright.","brain imaging; deep learning; machine learning; magnetic resonance imaging; Neuroimaging; random forest decision tree; TBI","Adolescent; Adult; Automatic Data Processing; Brain Injuries, Traumatic; Brain Mapping; Cohort Studies; Female; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Supervised Machine Learning; White Matter; Young Adult; adult; Article; automation; clinical article; conceptual framework; human; image segmentation; machine learning; nervous system parameters; nuclear magnetic resonance imaging; predictive value; radiological parameters; random forest; relative volume difference; sensitivity analysis; traumatic brain injury; veteran; white matter lesion; workflow; adolescent; brain mapping; cohort analysis; computer assisted diagnosis; diagnostic imaging; female; information processing; male; middle aged; nuclear magnetic resonance imaging; supervised machine learning; traumatic brain injury; white matter; young adult","Taylor and Francis Ltd","02699052","","BRAIE","27834541","Article","Scopus","2-s2.0-84995489262"
"Wang S.; Sun S.; Li Z.; Zhang R.; Xu J.","Wang, Sheng (58428221300); Sun, Siqi (57056718200); Li, Zhen (57788458100); Zhang, Renyu (57193161476); Xu, Jinbo (57203521425)","58428221300; 57056718200; 57788458100; 57193161476; 57203521425","Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model","2017","PLoS Computational Biology","644","10.1371/journal.pcbi.1005324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011370897&doi=10.1371%2fjournal.pcbi.1005324&partnerID=40&md5=a533598e33ce233d8643b53c27d06ac9","Toyota Technological Institute at Chicago, Chicago, IL, United States","Wang S., Toyota Technological Institute at Chicago, Chicago, IL, United States; Sun S., Toyota Technological Institute at Chicago, Chicago, IL, United States; Li Z., Toyota Technological Institute at Chicago, Chicago, IL, United States; Zhang R., Toyota Technological Institute at Chicago, Chicago, IL, United States; Xu J., Toyota Technological Institute at Chicago, Chicago, IL, United States","Motivation: Protein contacts contain key information for the understanding of protein structure and function and thus, contact prediction from sequence is an important problem. Recently exciting progress has been made on this problem, but the predicted contacts for proteins without many sequence homologs is still of low quality and not very useful for de novo structure prediction. Method: This paper presents a new deep learning method that predicts contacts by integrating both evolutionary coupling (EC) and sequence conservation information through an ultra-deep neural network formed by two deep residual neural networks. The first residual network conducts a series of 1-dimensional convolutional transformation of sequential features; the second residual network conducts a series of 2-dimensional convolutional transformation of pairwise information including output of the first residual network, EC information and pairwise potential. By using very deep residual networks, we can accurately model contact occurrence patterns and complex sequence-structure relationship and thus, obtain higher-quality contact prediction regardless of how many sequence homologs are available for proteins in question. Results: Our method greatly outperforms existing methods and leads to much more accurate contact-assisted folding. Tested on 105 CASP11 targets, 76 past CAMEO hard targets, and 398 membrane proteins, the average top L long-range prediction accuracy obtained by our method, one representative EC method CCMpred and the CASP11 winner MetaPSICOV is 0.47, 0.21 and 0.30, respectively; the average top L/10 long-range accuracy of our method, CCMpred and MetaPSICOV is 0.77, 0.47 and 0.59, respectively. Ab initio folding using our predicted contacts as restraints but without any force fields can yield correct folds (i.e., TMscore>0.6) for 203 of the 579 test proteins, while that using MetaPSICOV- and CCMpred-predicted contacts can do so for only 79 and 62 of them, respectively. Our contact-assisted models also have much better quality than template-based models especially for membrane proteins. The 3D models built from our contact prediction have TMscore>0.5 for 208 of the 398 membrane proteins, while those from homology modeling have TMscore>0.5 for only 10 of them. Further, even if trained mostly by soluble proteins, our deep learning method works very well on membrane proteins. In the recent blind CAMEO benchmark, our fully-automated web server implementing this method successfully folded 6 targets with a new fold and only 0.3L-2.3L effective sequence homologs, including one β protein of 182 residues, one α+β protein of 125 residues, one α protein of 140 residues, one α protein of 217 residues, one α/β of 260 residues and one α protein of 462 residues. Our method also achieved the highest F1 score on free-modeling targets in the latest CASP (Critical Assessment of Structure Prediction), although it was not fully implemented back then. Availability: http://raptorx.uchicago.edu/ContactMap/ © 2017 Wang et al.","","Algorithms; Computational Biology; Databases, Protein; Machine Learning; Neural Networks (Computer); Protein Conformation; Proteins; Sequence Analysis, Protein; Biological membranes; Convolution; Deep neural networks; Forecasting; membrane protein; protein; Foldings; Learning methods; Learning models; Low qualities; Membrane proteins; Protein contact maps; Protein functions; Proteins structures; Structure prediction; Ultra deeps; amino acid sequence; Article; artificial neural network; evolutionary coupling; measurement accuracy; predictor variable; protein contact map; protein folding; sequence alignment; sequence homology; statistical analysis; statistical concepts; ultra deep learning method; algorithm; biology; chemistry; machine learning; metabolism; procedures; protein conformation; protein database; sequence analysis; Proteins","Public Library of Science","1553734X","","","28056090","Article","Scopus","2-s2.0-85011370897"
"Dhaliwal A.; Brenner M.; Wolujewicz P.; Zhang Z.; Mao Y.; Batish M.; Kohn J.; Moghe P.V.","Dhaliwal, Anandika (36628088100); Brenner, Matthew (57197878577); Wolujewicz, Paul (57191332868); Zhang, Zheng (55577476800); Mao, Yong (56801256600); Batish, Mona (23987330400); Kohn, Joachim (7101736238); Moghe, Prabhas V. (7006733486)","36628088100; 57197878577; 57191332868; 55577476800; 56801256600; 23987330400; 7101736238; 7006733486","Profiling stem cell states in three-dimensional biomaterial niches using high content image informatics","2016","Acta Biomaterialia","16","10.1016/j.actbio.2016.08.052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992315904&doi=10.1016%2fj.actbio.2016.08.052&partnerID=40&md5=24579cf98a00430e321a68af8f75189c","Department of Biomedical Engineering, Rutgers University, Piscataway, NJ, United States; Department of Microbiology, Biochemistry and Molecular Genetics, Rutgers University, Newark, NJ, United States; Department of Chemistry and Chemical Biology, New Jersey Center for Biomaterials, Rutgers University, Piscataway, NJ, United States; Department of Chemical and Biochemical Engineering, Rutgers University, Piscataway, NJ, United States","Dhaliwal A., Department of Biomedical Engineering, Rutgers University, Piscataway, NJ, United States; Brenner M., Department of Biomedical Engineering, Rutgers University, Piscataway, NJ, United States; Wolujewicz P., Department of Microbiology, Biochemistry and Molecular Genetics, Rutgers University, Newark, NJ, United States; Zhang Z., Department of Chemistry and Chemical Biology, New Jersey Center for Biomaterials, Rutgers University, Piscataway, NJ, United States; Mao Y., Department of Chemistry and Chemical Biology, New Jersey Center for Biomaterials, Rutgers University, Piscataway, NJ, United States; Batish M., Department of Microbiology, Biochemistry and Molecular Genetics, Rutgers University, Newark, NJ, United States; Kohn J., Department of Chemistry and Chemical Biology, New Jersey Center for Biomaterials, Rutgers University, Piscataway, NJ, United States; Moghe P.V., Department of Biomedical Engineering, Rutgers University, Piscataway, NJ, United States, Department of Chemical and Biochemical Engineering, Rutgers University, Piscataway, NJ, United States","A predictive framework for the evolution of stem cell biology in 3-D is currently lacking. In this study we propose deep image informatics of the nuclear biology of stem cells to elucidate how 3-D biomaterials steer stem cell lineage phenotypes. The approach is based on high content imaging informatics to capture minute variations in the 3-D spatial organization of splicing factor SC-35 in the nucleoplasm as a marker to classify emergent cell phenotypes of human mesenchymal stem cells (hMSCs). The cells were cultured in varied 3-D culture systems including hydrogels, electrospun mats and salt leached scaffolds. The approach encompasses high resolution 3-D imaging of SC-35 domains and high content image analysis (HCIA) to compute quantitative 3-D nuclear metrics for SC-35 organization in single cells in concert with machine learning approaches to construct a predictive cell-state classification model. Our findings indicate that hMSCs cultured in collagen hydrogels and induced to differentiate into osteogenic or adipogenic lineages could be classified into the three lineages (stem, adipogenic, osteogenic) with ⩾80% precision and sensitivity, within 72 h. Using this framework, the augmentation of osteogenesis by scaffold design exerted by porogen leached scaffolds was also profiled within 72 h with ∼80% high sensitivity. Furthermore, by employing 3-D SC-35 organizational metrics, differential osteogenesis induced by novel electrospun fibrous polymer mats incorporating decellularized matrix could also be elucidated and predictably modeled at just 3 days with high precision. We demonstrate that 3-D SC-35 organizational metrics can be applied to model the stem cell state in 3-D scaffolds. We propose that this methodology can robustly discern minute changes in stem cell states within complex 3-D architectures and map single cell biological readouts that are critical to assessing population level cell heterogeneity. Statement of Significance The sustained development and validation of bioactive materials relies on technologies that can sensitively discern cell response dynamics to biomaterials, while capturing cell-to-cell heterogeneity and preserving cellular native phenotypes. In this study, we illustrate the application of a novel high content image informatics platform to classify emergent human mesenchymal stem cell (hMSC) phenotypes in a diverse range of 3-D biomaterial scaffolds with high sensitivity and precision, and track cell responses to varied external stimuli. A major in silico innovation is the proposed image profiling technology based on unique three dimensional textural signatures of a mechanoreporter protein within the nuclei of stem cells cultured in 3-D scaffolds. This technology will accelerate the pace of high-fidelity biomaterial screening. © 2016 Acta Materialia Inc.","3-D culture systems; High content image analysis; Mesenchymal stem cells; SC-35","Animals; Biocompatible Materials; Bone Regeneration; Cattle; Cell Differentiation; Cells, Cultured; Collagen; Humans; Hydrogel; Imaging, Three-Dimensional; Mesenchymal Stromal Cells; Osteogenesis; Phenotype; Tissue Engineering; Tissue Scaffolds; Biomaterials; Hydrogels; Image analysis; Leaching; Learning systems; Scaffolds (biology); Stem cells; biomaterial; cell surface marker; collagen gel; peroxisome proliferator activated receptor gamma; polymer; RNA; sodium chloride; transcription factor RUNX2; biomaterial; collagen; hydrogel; 3-D culture system; Cell state; High content image analyse; High-content; Human mesenchymal stem cells; Image informatics; Image-analysis; Mesenchymal stem cell; SC-35; Stem-cell; adipogenesis; animal cell; Article; bovine; cartilage cell; cell differentiation; cell heterogeneity; cell lineage; controlled study; electrospinning; fibroblast; human; human cell; hydrogel; image analysis; machine learning; mesenchymal stem cell; nonhuman; osteoblast; phenotype; priority journal; quantitative analysis; stem cell culture; stem cell niche; three dimensional human mesenchymal stem cell culture; tissue scaffold; animal; bone development; bone regeneration; cell culture; chemistry; cytology; drug effects; genetics; mesenchymal stroma cell; pharmacology; procedures; three dimensional imaging; tissue engineering; Cell culture","Elsevier Ltd","17427061","","","27590870","Article","Scopus","2-s2.0-84992315904"
"Becker A.S.; Marcon M.; Ghafoor S.; Wurnig M.C.; Frauenfelder T.; Boss A.","Becker, Anton S. (55389064500); Marcon, Magda (56334882300); Ghafoor, Soleen (57076294200); Wurnig, Moritz C. (38962086100); Frauenfelder, Thomas (6507832349); Boss, Andreas (9737288900)","55389064500; 56334882300; 57076294200; 38962086100; 6507832349; 9737288900","Deep learning in mammography diagnostic accuracy of a multipurpose image analysis software in the detection of breast cancer","2017","Investigative Radiology","276","10.1097/RLI.0000000000000358","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013092765&doi=10.1097%2fRLI.0000000000000358&partnerID=40&md5=5f6a86815364b1e1943240f631fabad8","Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Raemistrasse 100, Zurich, 8091, Switzerland","Becker A.S., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Raemistrasse 100, Zurich, 8091, Switzerland; Marcon M., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Raemistrasse 100, Zurich, 8091, Switzerland; Ghafoor S., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Raemistrasse 100, Zurich, 8091, Switzerland; Wurnig M.C., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Raemistrasse 100, Zurich, 8091, Switzerland; Frauenfelder T., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Raemistrasse 100, Zurich, 8091, Switzerland; Boss A., Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Raemistrasse 100, Zurich, 8091, Switzerland","Objectives: The aim of this study was to evaluate the diagnostic accuracy of a multipurpose image analysis software based on deep learning with artificial neural networks for the detection of breast cancer in an independent, dual-center mammography data set. Materials and Methods: In this retrospective, Health Insurance Portability and Accountability Act-compliant study, all patients undergoing mammography in 2012 at our institution were reviewed (n = 3228). All of their prior and followup mammographies from a time span of 7 years (2008-2015) were considered as a reference for clinical diagnosis. After applying exclusion criteria (missing reference standard, prior procedures or therapies), patientswith the first diagnosis of a malignoma or borderline lesion were selected (n = 143). Histology or clinical long-term follow-up served as reference standard. In a first step, a breast densityand age-matched control cohort was selected (n = 143) from the remaining patients with more than 2 years follow-up (n = 1003). The neural network was trained with this data set. From the publicly available Breast Cancer Digital Repository data set, patients with cancer and a matched control cohort were selected (n = 35 X 2). The performance of the trained neural network was also tested with this external data set. Three radiologists (3, 5, and 10 years of experience) evaluated the test data set. In a second step, the neural network was trained with all cases from January to September and tested with cases from October to December 2012 (screening-like cohort). The radiologists also evaluated this second test data set. The areas under the receiver operating characteristic curve between readers and the neural network were compared. A Bonferronicorrected P value of less than 0.016 was considered statistically significant. Results: Mean age of patients with lesion was 59.6 years (range, 35-88 years) and in controls, 59.1 years (35-83 years). Breast density distribution (A/B/C/D) was 21/59/42/21 and 22/60/41/20, respectively. Histologic diagnoses were invasive ductal carcinoma in 90, ductal in situ carcinoma in 13, invasive lobular carcinoma in 13, mucinous carcinoma in 3, and borderline lesion in 12 patients. In the first step, the area under the receiver operating characteristic curve of the trained neural network was 0.81 and comparable on the test cases 0.79 (P = 0.63). One of the radiologists showed almost equal performance (0.83, P = 0.17), whereas 2 were significantly better (0.91 and 0.94, P < 0.016). In the second step, performance of the neural network (0.82) was not significantly different from the human performance (0.77-0.87, P > 0.016); however, radiologists were consistently less sensitive and more specific than the neural network. Conclusions: Current state-of-the-art artificial neural networks for general image analysis are able to detect cancer in mammographies with similar accuracy to radiologists, even in a screening-like cohort with low breast cancer prevalence. Copyright © 2017 Wolters Kluwer Health, Inc. All rights reserved.","Artificial intelligence; Artificial neural network; Breast cancer; Deep learning; Diagnostic accuracy; Machine learning; Mammography","Adult; Aged; Aged, 80 and over; Breast; Breast Neoplasms; Female; Follow-Up Studies; Humans; Image Processing, Computer-Assisted; Machine Learning; Mammography; Middle Aged; Prevalence; Reproducibility of Results; Retrospective Studies; ROC Curve; adult; aged; Article; artificial neural network; breast carcinoma; breast density; colloid carcinoma; controlled study; correlation coefficient; diagnostic accuracy; diagnostic test accuracy study; histology; human; image analysis; image processing; imaging software; intraductal carcinoma; lobular carcinoma; major clinical study; mammography; priority journal; receiver operating characteristic; retrospective study; sensitivity and specificity; breast; breast tumor; diagnostic imaging; female; follow up; machine learning; mammography; middle aged; prevalence; procedures; reproducibility; very elderly","Lippincott Williams and Wilkins","00209996","","INVRA","28212138","Article","Scopus","2-s2.0-85013092765"
"Christodoulidis S.; Anthimopoulos M.; Ebner L.; Christe A.; Mougiakakou S.","Christodoulidis, Stergios (56648066500); Anthimopoulos, Marios (25653065900); Ebner, Lukas (55520061700); Christe, Andreas (14629950700); Mougiakakou, Stavroula (6603242680)","56648066500; 25653065900; 55520061700; 14629950700; 6603242680","Multisource Transfer Learning with Convolutional Neural Networks for Lung Pattern Analysis","2017","IEEE Journal of Biomedical and Health Informatics","232","10.1109/JBHI.2016.2636929","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014941777&doi=10.1109%2fJBHI.2016.2636929&partnerID=40&md5=00b50aef85935c43bbc3d6fcc79451b3","ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, 3008, Switzerland; Department of Diagnostic, Interventional and Pediatric Radiology, Bern University Hospital inselspital, Bern, 3010, Switzerland; Department of Emergency Medicine, Bern University Hospital inselspital, Bern, 3010, Switzerland","Christodoulidis S., ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, 3008, Switzerland; Anthimopoulos M., ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, 3008, Switzerland, Department of Diagnostic, Interventional and Pediatric Radiology, Bern University Hospital inselspital, Bern, 3010, Switzerland, Department of Emergency Medicine, Bern University Hospital inselspital, Bern, 3010, Switzerland; Ebner L., Department of Emergency Medicine, Bern University Hospital inselspital, Bern, 3010, Switzerland; Christe A., Department of Emergency Medicine, Bern University Hospital inselspital, Bern, 3010, Switzerland; Mougiakakou S., ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, 3008, Switzerland, Department of Emergency Medicine, Bern University Hospital inselspital, Bern, 3010, Switzerland","Early diagnosis of interstitial lung diseases is crucial for their treatment, but even experienced physicians find it difficult, as their clinical manifestations are similar. In order to assist with the diagnosis, computer-aided diagnosis systems have been developed. These commonly rely on a fixed scale classifier that scans CT images, recognizes textural lung patterns, and generates a map of pathologies. In a previous study, we proposed a method for classifying lung tissue patterns using a deep convolutional neural network (CNN), with an architecture designed for the specific problem. In this study, we present an improved method for training the proposed network by transferring knowledge from the similar domain of general texture classification. Six publicly available texture databases are used to pretrain networks with the proposed architecture, which are then fine-tuned on the lung tissue data. The resulting CNNs are combined in an ensemble and their fused knowledge is compressed back to a network with the original architecture. The proposed approach resulted in an absolute increase of about 2% in the performance of the proposed CNN. The results demonstrate the potential of transfer learning in the field of medical image analysis, indicate the textural nature of the problem and show that the method used for training a network can be as important as designing its architecture. © 2016 IEEE.","Convolutional neural networks (CNNs); interstitial lung diseases (ILDs); knowledge distillation; model compression; model ensemble; texture classification; Transfer learning","Humans; Image Interpretation, Computer-Assisted; Lung; Lung Diseases, Interstitial; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Tomography, X-Ray Computed; Biological organs; Computer aided diagnosis; Computerized tomography; Convolution; Convolutional neural networks; Deep neural networks; Distillation; Learning systems; Medical imaging; Textures; Tissue; Tissue engineering; Transfer learning; Clinical manifestation; Computer aided diagnosis systems; Interstitial lung disease; Model compression; Model ensembles; Proposed architectures; Specific problems; Texture classification; architecture; Article; computer assisted tomography; image analysis; lung; machine learning; multisource transfer learning; multitask learning; nerve cell network; training; artificial neural network; automated pattern recognition; computer assisted diagnosis; diagnostic imaging; human; interstitial lung disease; lung; machine learning; procedures; x-ray computed tomography; Network architecture","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28114048","Article","Scopus","2-s2.0-85014941777"
"Tripathi R.; Patel S.; Kumari V.; Chakraborty P.; Varadwaj P.K.","Tripathi, Rashmi (56900559000); Patel, Sunil (57198335324); Kumari, Vandana (57193379625); Chakraborty, Pavan (7103327884); Varadwaj, Pritish Kumar (12144457700)","56900559000; 57198335324; 57193379625; 7103327884; 12144457700","DeepLNC, a long non-coding RNA prediction tool using deep neural network","2016","Network Modeling Analysis in Health Informatics and Bioinformatics","59","10.1007/s13721-016-0129-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029360191&doi=10.1007%2fs13721-016-0129-2&partnerID=40&md5=484ae7dac2720280a728362678b73315","Department of Bioinformatics, Indian Institute of Information Technology-Allahabad, Allahabad, UP, India","Tripathi R., Department of Bioinformatics, Indian Institute of Information Technology-Allahabad, Allahabad, UP, India; Patel S., Department of Bioinformatics, Indian Institute of Information Technology-Allahabad, Allahabad, UP, India; Kumari V., Department of Bioinformatics, Indian Institute of Information Technology-Allahabad, Allahabad, UP, India; Chakraborty P., Department of Bioinformatics, Indian Institute of Information Technology-Allahabad, Allahabad, UP, India; Varadwaj P.K., Department of Bioinformatics, Indian Institute of Information Technology-Allahabad, Allahabad, UP, India","The significant role of long non-coding RNAs (lncRNAs) in various cellular functions, such as gene imprinting, immune response, embryonic pluripotency, tumorogenesis, and genetic regulations, has been widely studied and reported in recent years. Several experimental and computational methods involving genome-wide search and screenings of ncRNAs are being proposed utilizing sequence features-length, occurrence, and composition of bases with various limitations. The proposed classifier, Deep Neural Network (DNN) is fast and an accurate alternative for the identification of lncRNAs as compared to other existing classifiers. The information content stored in k-mer pattern has been used as a sole feature for the DNN classifier using manually annotated training datasets from LNCipedia and RefSeq database, obtaining accuracy of 98.07 %, sensitivity of 98.98 %, and specificity of 97.19 %, respectively, on test dataset. The k-mer information content generated on the basis of Shannon entropy function has resulted in improved classifier accuracy. This classification framework was also tested on known human genome dataset, and the framework has successfully identified known lncRNAs with 99 % accuracy rate. The said algorithm has been implemented as a web prediction tool, which is available on server interface http://bioserver.iiita.ac.in/deeplnc. © 2016, Springer-Verlag Wien.","Deep neural network; K-mer features; Long non-coding RNAs (lncRNAs); Machine learning; Shannon entropy","Codes (symbols); Deep neural networks; Gene expression; Learning systems; Network coding; Nucleic acids; Statistical tests; long untranslated RNA; transcription factor; Classification framework; Genetic regulation; Information contents; Non-coding RNAs; Sequence features; Server interfaces; Shannon entropy; Training data sets; algorithm; Article; computer model; data base; diagnostic accuracy; high throughput screening; human; immunoprecipitation; machine learning; mathematical model; microarray analysis; nerve cell network; predictive value; priority journal; receiver operating characteristic; sensitivity and specificity; sequence analysis; Classification (of information)","Springer Verlag","21926662","","","","Article","Scopus","2-s2.0-85029360191"
"Baldi P.; Sadowski P.","Baldi, Pierre (7101759672); Sadowski, Peter (56074914700)","7101759672; 56074914700","A theory of local learning, the learning channel, and the optimality of backpropagation","2016","Neural Networks","43","10.1016/j.neunet.2016.07.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983514119&doi=10.1016%2fj.neunet.2016.07.006&partnerID=40&md5=2bccd491171f07df89d1626ccff85f50","Department of Computer Science, University of California, Irvine, Irvine, 92697-3435, CA, United States","Baldi P., Department of Computer Science, University of California, Irvine, Irvine, 92697-3435, CA, United States; Sadowski P., Department of Computer Science, University of California, Irvine, Irvine, 92697-3435, CA, United States","In a physical neural system, where storage and processing are intimately intertwined, the rules for adjusting the synaptic weights can only depend on variables that are available locally, such as the activity of the pre- and post-synaptic neurons, resulting in local learning rules. A systematic framework for studying the space of local learning rules is obtained by first specifying the nature of the local variables, and then the functional form that ties them together into each learning rule. Such a framework enables also the systematic discovery of new learning rules and exploration of relationships between learning rules and group symmetries. We study polynomial local learning rules stratified by their degree and analyze their behavior and capabilities in both linear and non-linear units and networks. Stacking local learning rules in deep feedforward networks leads to deep local learning. While deep local learning can learn interesting representations, it cannot learn complex input–output functions, even when targets are available for the top layer. Learning complex input–output functions requires local deep learning where target information is communicated to the deep layers through a backward learning channel. The nature of the communicated information about the targets and the structure of the learning channel partition the space of learning algorithms. For any learning algorithm, the capacity of the learning channel can be defined as the number of bits provided about the error gradient per weight, divided by the number of required operations per weight. We estimate the capacity associated with several learning algorithms and show that backpropagation outperforms them by simultaneously maximizing the information rate and minimizing the computational cost. This result is also shown to be true for recurrent networks, by unfolding them in time. The theory clarifies the concept of Hebbian learning, establishes the power and limitations of local learning rules, introduces the learning channel which enables a formal analysis of the optimality of backpropagation, and explains the sparsity of the space of learning rules discovered so far. © 2016 Elsevier Ltd","Backpropagation; Deep learning; Hebbian learning; Learning channel; Supervised learning; Unsupervised learning","Algorithms; Feedback; Machine Learning; Neural Networks (Computer); Backpropagation; Backpropagation algorithms; Complex networks; Computation theory; Formal concept analysis; Supervised learning; Unsupervised learning; Computational costs; Deep learning; Feed-forward network; Hebbian learning; Learning channel; Post-synaptic neurons; Recurrent networks; Systematic framework; algorithm; Article; artificial neural network; back propagation; Boolean function; conceptual framework; feedforward layered linear network; Hebbian learning; information processing; learning; learning algorithm; mathematical parameters; perturbation with binary feedback; perturbation with binary feedback K times; perturbation with real feedback; perturbation with real feedback K times; priority journal; simulation; artificial neural network; feedback system; machine learning; Learning algorithms","Elsevier Ltd","08936080","","NNETE","27584574","Article","Scopus","2-s2.0-84983514119"
"Tian K.; Shao M.; Wang Y.; Guan J.; Zhou S.","Tian, Kai (57188698306); Shao, Mingyu (55561850100); Wang, Yang (58747692100); Guan, Jihong (24314945300); Zhou, Shuigeng (7404166246)","57188698306; 55561850100; 58747692100; 24314945300; 7404166246","Boosting compound-protein interaction prediction by deep learning","2016","Methods","135","10.1016/j.ymeth.2016.06.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979678858&doi=10.1016%2fj.ymeth.2016.06.024&partnerID=40&md5=8aebffef860d28188e947a273e669961","Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, 200433, China; Department of Computer Science and Technology, Tongji University, Shanghai, 201804, China; School of Software, Jiangxi Normal University, Nanchang, 330022, China","Tian K., Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, 200433, China; Shao M., Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, 200433, China; Wang Y., School of Software, Jiangxi Normal University, Nanchang, 330022, China; Guan J., Department of Computer Science and Technology, Tongji University, Shanghai, 201804, China; Zhou S., Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, 200433, China","The identification of interactions between compounds and proteins plays an important role in network pharmacology and drug discovery. However, experimentally identifying compound-protein interactions (CPIs) is generally expensive and time-consuming, computational approaches are thus introduced. Among these, machine-learning based methods have achieved a considerable success. However, due to the nonlinear and imbalanced nature of biological data, many machine learning approaches have their own limitations. Recently, deep learning techniques show advantages over many state-of-the-art machine learning methods in some applications. In this study, we aim at improving the performance of CPI prediction based on deep learning, and propose a method called DL-CPI (the abbreviation of Deep Learning for Compound-Protein Interactions prediction), which employs deep neural network (DNN) to effectively learn the representations of compound-protein pairs. Extensive experiments show that DL-CPI can learn useful features of compound-protein pairs by a layerwise abstraction, and thus achieves better prediction performance than existing methods on both balanced and imbalanced datasets. © 2016 Elsevier Inc.","Compound-protein interaction; Deep learning; Deep neural network (DNN)","Algorithms; Databases, Chemical; Databases, Protein; Drug Compounding; Drug Discovery; Humans; Machine Learning; Neural Networks (Computer); Pharmaceutical Preparations; Protein Domains; Protein Interaction Mapping; Proteins; drug; protein; Article; artificial neural network; deep learning for compound protein interaction; deep neural network; intermethod comparison; machine learning; mathematical computing; prediction; priority journal; process optimization; protein database; validation process; algorithm; chemical database; chemistry; drug development; drug effects; drug formulation; human; machine learning; procedures; protein analysis; protein domain","Academic Press Inc.","10462023","","MTHDE","27378654","Article","Scopus","2-s2.0-84979678858"
"Yadav M.K.","Yadav, Maneesh K. (58445174200)","58445174200","On the synthesis of machine learning and automated reasoning for an artificial synthetic organic chemist","2017","New Journal of Chemistry","11","10.1039/c6nj02492k","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013006972&doi=10.1039%2fc6nj02492k&partnerID=40&md5=df6f2d342b78f17f49347dfff6849eb4","SRI International, 333 Ravenswood Avenue, Menlo Park, 94025-3493, CA, United States","Yadav M.K., SRI International, 333 Ravenswood Avenue, Menlo Park, 94025-3493, CA, United States","This perspective outlines current capabilities and limitations of state-of-the-art artificial intelligence methods as applied to automating the planning of synthetic routes in organic chemistry. Synthetic organic chemistry is viewed from the perspective of two prominent approaches: deep neural networks and SAT-solver based automated reasoning. After introducing these concepts to non-computer scientists, the expected performance of these approaches is estimated by surveying comparable problems in artificial intelligence. A truly artificial synthetic organic chemist that automatically constructs viable synthetic routes is clearly a challenging artificial intelligence problem and not directly amenable to existing approaches but chemistry could encourage new combinations of machine learning methods with automated reasoning to realize this goal. The importance of objective and open competitions with standardized problems and evaluations is also detailed as critical to realizing tangible computer programs that automate the planning of plausible synthetic routes. © The Royal Society of Chemistry and the Centre National de la Recherche Scientifique.","","Article; artificial intelligence; artificial neural network; automation; human; logic; machine learning; organic chemistry; planning; priority journal; scientist; software; synthesis; writing","Royal Society of Chemistry","11440546","","NJCHE","","Article","Scopus","2-s2.0-85013006972"
"Durek P.; Nordström K.; Gasparoni G.; Salhab A.; Kressler C.; de Almeida M.; Bassler K.; Ulas T.; Schmidt F.; Xiong J.; Glažar P.; Klironomos F.; Sinha A.; Kinkley S.; Yang X.; Arrigoni L.; Amirabad A.D.; Ardakani F.B.; Feuerbach L.; Gorka O.; Ebert P.; Müller F.; Li N.; Frischbutter S.; Schlickeiser S.; Cendon C.; Fröhler S.; Felder B.; Gasparoni N.; Imbusch C.D.; Hutter B.; Zipprich G.; Tauchmann Y.; Reinke S.; Wassilew G.; Hoffmann U.; Richter A.S.; Sieverling L.; Chang H.-D.; Syrbe U.; Kalus U.; Eils J.; Brors B.; Manke T.; Ruland J.; Lengauer T.; Rajewsky N.; Chen W.; Dong J.; Sawitzki B.; Chung H.-R.; Rosenstiel P.; Schulz M.H.; Schultze J.L.; Radbruch A.; Walter J.; Hamann A.; Polansky J.K.","Durek, Pawel (35285452400); Nordström, Karl (36869711900); Gasparoni, Gilles (6504106248); Salhab, Abdulrahman (57192006847); Kressler, Christopher (56521681800); de Almeida, Melanie (57217067308); Bassler, Kevin (57209042382); Ulas, Thomas (57207907279); Schmidt, Florian (57203234121); Xiong, Jieyi (55595753900); Glažar, Petar (56392946200); Klironomos, Filippos (55602173500); Sinha, Anupam (57191581726); Kinkley, Sarah (15044679800); Yang, Xinyi (57191334473); Arrigoni, Laura (55613187200); Amirabad, Azim Dehghani (57193712713); Ardakani, Fatemeh Behjati (57193359315); Feuerbach, Lars (38361241800); Gorka, Oliver (55247318600); Ebert, Peter (56292016800); Müller, Fabian (56719040300); Li, Na (57749555600); Frischbutter, Stefan (6504265999); Schlickeiser, Stephan (23502581000); Cendon, Carla (57000366400); Fröhler, Sebastian (35339108500); Felder, Bärbel (16022055000); Gasparoni, Nina (57192012177); Imbusch, Charles D. (56008806300); Hutter, Barbara (14321493700); Zipprich, Gideon (56173395500); Tauchmann, Yvonne (57160326400); Reinke, Simon (26421771000); Wassilew, Georgi (35301164200); Hoffmann, Ute (34975524500); Richter, Andreas S. (35335084600); Sieverling, Lina (55971761000); Chang, Hyun-Dong (57210108798); Syrbe, Uta (6603164800); Kalus, Ulrich (6603358354); Eils, Jürgen (6507720090); Brors, Benedikt (6701770436); Manke, Thomas (57215616179); Ruland, Jürgen (57206586103); Lengauer, Thomas (57221176359); Rajewsky, Nikolaus (57203690892); Chen, Wei (57206955107); Dong, Jun (56394889000); Sawitzki, Birgit (57196011646); Chung, Ho-Ryun (57212844135); Rosenstiel, Philip (57225390900); Schulz, Marcel H. (57189011214); Schultze, Joachim L. (7103037653); Radbruch, Andreas (7005592376); Walter, Jörn (7403076605); Hamann, Alf (57207907688); Polansky, Julia K. (15846621600)","35285452400; 36869711900; 6504106248; 57192006847; 56521681800; 57217067308; 57209042382; 57207907279; 57203234121; 55595753900; 56392946200; 55602173500; 57191581726; 15044679800; 57191334473; 55613187200; 57193712713; 57193359315; 38361241800; 55247318600; 56292016800; 56719040300; 57749555600; 6504265999; 23502581000; 57000366400; 35339108500; 16022055000; 57192012177; 56008806300; 14321493700; 56173395500; 57160326400; 26421771000; 35301164200; 34975524500; 35335084600; 55971761000; 57210108798; 6603164800; 6603358354; 6507720090; 6701770436; 57215616179; 57206586103; 57221176359; 57203690892; 57206955107; 56394889000; 57196011646; 57212844135; 57225390900; 57189011214; 7103037653; 7005592376; 7403076605; 57207907688; 15846621600","Epigenomic Profiling of Human CD4+ T Cells Supports a Linear Differentiation Model and Highlights Molecular Regulators of Memory Development","2016","Immunity","142","10.1016/j.immuni.2016.10.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999836163&doi=10.1016%2fj.immuni.2016.10.022&partnerID=40&md5=3b821891a46360999a8ef0c6b0369fbf","Experimental Rheumatology, German Rheumatism Research Centre, Berlin, 10170, Germany; Department of Genetics, University of Saarland, Saarbrücken, 66123, Germany; Life and Medical Sciences Institute, Genomics and Immunoregulation, University of Bonn, Bonn, 53115, Germany; Department of Computational Biology and Applied Algorithmics, Max Planck Institute for Informatics, Saarbrücken, 66123, Germany; Excellence Cluster on Multimodal Computing and Interaction, Saarland University, Saarbrücken, 66123, Germany; Berlin Institute for Medical Systems Biology, Max-Delbrück Center for Molecular Medicine, Berlin, 13125, Germany; Systems Biology of Gene Regulatory Elements, Max-Delbrück Center for Molecular Medicine, Berlin, 13125, Germany; Institute of Clinical Molecular Biology, Christian-Albrechts-University, Kiel, 25123, Germany; Otto Warburg Laboratories: Epigenomics at Max Plank Institute for Molecular Genetics, Berlin, 14195, Germany; Max Planck Institute of Immunobiology and Epigenetics, Freiburg, 78108, Germany; Applied Bioinformatics, Deutsches Krebsforschungszentrum, Heidelberg, 59120, Germany; Institute for Clinical Chemistry and Pathobiochemistry, Klinikum rechts der Isar, Technical University, Munich, 81675, Germany; Institute of Medical Immunology, Charité University Medicine, Berlin, 13353, Germany; Cell Biology German Rheumatism Research Centre, Berlin, 10170, Germany; Data Management and Genomics IT, Deutsches Krebsforschungszentrum, Heidelberg, 69120, Germany; Institut für Transfusionsmedizin, Charité University Medicine, Berlin, 12203, Germany; Berlin-Brandenburg Center for Regenerative Therapies, Berlin, 13353, Germany; Center for Musculoskeletal Surgery, Charité University Medicine, Berlin, 10117, Germany; Medizinische Klinik für Gastroenterologie, Infektiologie und Rheumatologie, Charité University Medicine, Berlin, 12000, Germany; German Cancer Consortium (DKTK), Heidelberg, 59120, Germany; German Center for Infection Research (DZIF), Munich, 81675, Germany","Durek P., Experimental Rheumatology, German Rheumatism Research Centre, Berlin, 10170, Germany; Nordström K., Department of Genetics, University of Saarland, Saarbrücken, 66123, Germany; Gasparoni G., Department of Genetics, University of Saarland, Saarbrücken, 66123, Germany; Salhab A., Department of Genetics, University of Saarland, Saarbrücken, 66123, Germany; Kressler C., Experimental Rheumatology, German Rheumatism Research Centre, Berlin, 10170, Germany; de Almeida M., Experimental Rheumatology, German Rheumatism Research Centre, Berlin, 10170, Germany; Bassler K., Life and Medical Sciences Institute, Genomics and Immunoregulation, University of Bonn, Bonn, 53115, Germany; Ulas T., Life and Medical Sciences Institute, Genomics and Immunoregulation, University of Bonn, Bonn, 53115, Germany; Schmidt F., Department of Computational Biology and Applied Algorithmics, Max Planck Institute for Informatics, Saarbrücken, 66123, Germany, Excellence Cluster on Multimodal Computing and Interaction, Saarland University, Saarbrücken, 66123, Germany; Xiong J., Berlin Institute for Medical Systems Biology, Max-Delbrück Center for Molecular Medicine, Berlin, 13125, Germany; Glažar P., Systems Biology of Gene Regulatory Elements, Max-Delbrück Center for Molecular Medicine, Berlin, 13125, Germany; Klironomos F., Systems Biology of Gene Regulatory Elements, Max-Delbrück Center for Molecular Medicine, Berlin, 13125, Germany; Sinha A., Institute of Clinical Molecular Biology, Christian-Albrechts-University, Kiel, 25123, Germany; Kinkley S., Otto Warburg Laboratories: Epigenomics at Max Plank Institute for Molecular Genetics, Berlin, 14195, Germany; Yang X., Otto Warburg Laboratories: Epigenomics at Max Plank Institute for Molecular Genetics, Berlin, 14195, Germany; Arrigoni L., Max Planck Institute of Immunobiology and Epigenetics, Freiburg, 78108, Germany; Amirabad A.D., Department of Computational Biology and Applied Algorithmics, Max Planck Institute for Informatics, Saarbrücken, 66123, Germany, Excellence Cluster on Multimodal Computing and Interaction, Saarland University, Saarbrücken, 66123, Germany; Ardakani F.B., Department of Computational Biology and Applied Algorithmics, Max Planck Institute for Informatics, Saarbrücken, 66123, Germany, Excellence Cluster on Multimodal Computing and Interaction, Saarland University, Saarbrücken, 66123, Germany; Feuerbach L., Applied Bioinformatics, Deutsches Krebsforschungszentrum, Heidelberg, 59120, Germany; Gorka O., Institute for Clinical Chemistry and Pathobiochemistry, Klinikum rechts der Isar, Technical University, Munich, 81675, Germany; Ebert P., Department of Computational Biology and Applied Algorithmics, Max Planck Institute for Informatics, Saarbrücken, 66123, Germany; Müller F., Department of Computational Biology and Applied Algorithmics, Max Planck Institute for Informatics, Saarbrücken, 66123, Germany; Li N., Otto Warburg Laboratories: Epigenomics at Max Plank Institute for Molecular Genetics, Berlin, 14195, Germany; Frischbutter S., Experimental Rheumatology, German Rheumatism Research Centre, Berlin, 10170, Germany; Schlickeiser S., Institute of Medical Immunology, Charité University Medicine, Berlin, 13353, Germany; Cendon C., Cell Biology German Rheumatism Research Centre, Berlin, 10170, Germany; Fröhler S., Berlin Institute for Medical Systems Biology, Max-Delbrück Center for Molecular Medicine, Berlin, 13125, Germany; Felder B., Data Management and Genomics IT, Deutsches Krebsforschungszentrum, Heidelberg, 69120, Germany; Gasparoni N., Department of Genetics, University of Saarland, Saarbrücken, 66123, Germany; Imbusch C.D., Applied Bioinformatics, Deutsches Krebsforschungszentrum, Heidelberg, 59120, Germany; Hutter B., Applied Bioinformatics, Deutsches Krebsforschungszentrum, Heidelberg, 59120, Germany; Zipprich G., Data Management and Genomics IT, Deutsches Krebsforschungszentrum, Heidelberg, 69120, Germany; Tauchmann Y., Institut für Transfusionsmedizin, Charité University Medicine, Berlin, 12203, Germany; Reinke S., Berlin-Brandenburg Center for Regenerative Therapies, Berlin, 13353, Germany; Wassilew G., Center for Musculoskeletal Surgery, Charité University Medicine, Berlin, 10117, Germany; Hoffmann U., Experimental Rheumatology, German Rheumatism Research Centre, Berlin, 10170, Germany; Richter A.S., Max Planck Institute of Immunobiology and Epigenetics, Freiburg, 78108, Germany; Sieverling L., Applied Bioinformatics, Deutsches Krebsforschungszentrum, Heidelberg, 59120, Germany; Chang H.-D., Cell Biology German Rheumatism Research Centre, Berlin, 10170, Germany; Syrbe U., Medizinische Klinik für Gastroenterologie, Infektiologie und Rheumatologie, Charité University Medicine, Berlin, 12000, Germany; Kalus U., Institut für Transfusionsmedizin, Charité University Medicine, Berlin, 12203, Germany; Eils J., Data Management and Genomics IT, Deutsches Krebsforschungszentrum, Heidelberg, 69120, Germany; Brors B., Applied Bioinformatics, Deutsches Krebsforschungszentrum, Heidelberg, 59120, Germany; Manke T., Max Planck Institute of Immunobiology and Epigenetics, Freiburg, 78108, Germany; Ruland J., Institute for Clinical Chemistry and Pathobiochemistry, Klinikum rechts der Isar, Technical University, Munich, 81675, Germany, German Cancer Consortium (DKTK), Heidelberg, 59120, Germany, German Center for Infection Research (DZIF), Munich, 81675, Germany; Lengauer T., Department of Computational Biology and Applied Algorithmics, Max Planck Institute for Informatics, Saarbrücken, 66123, Germany; Rajewsky N., Systems Biology of Gene Regulatory Elements, Max-Delbrück Center for Molecular Medicine, Berlin, 13125, Germany; Chen W., Berlin Institute for Medical Systems Biology, Max-Delbrück Center for Molecular Medicine, Berlin, 13125, Germany; Dong J., Cell Biology German Rheumatism Research Centre, Berlin, 10170, Germany; Sawitzki B., Institute of Medical Immunology, Charité University Medicine, Berlin, 13353, Germany; Chung H.-R., Otto Warburg Laboratories: Epigenomics at Max Plank Institute for Molecular Genetics, Berlin, 14195, Germany; Rosenstiel P., Institute of Clinical Molecular Biology, Christian-Albrechts-University, Kiel, 25123, Germany; Schulz M.H., Department of Computational Biology and Applied Algorithmics, Max Planck Institute for Informatics, Saarbrücken, 66123, Germany, Excellence Cluster on Multimodal Computing and Interaction, Saarland University, Saarbrücken, 66123, Germany; Schultze J.L., Life and Medical Sciences Institute, Genomics and Immunoregulation, University of Bonn, Bonn, 53115, Germany; Radbruch A., Cell Biology German Rheumatism Research Centre, Berlin, 10170, Germany; Walter J., Department of Genetics, University of Saarland, Saarbrücken, 66123, Germany; Hamann A., Experimental Rheumatology, German Rheumatism Research Centre, Berlin, 10170, Germany; Polansky J.K., Experimental Rheumatology, German Rheumatism Research Centre, Berlin, 10170, Germany","The impact of epigenetics on the differentiation of memory T (Tmem) cells is poorly defined. We generated deep epigenomes comprising genome-wide profiles of DNA methylation, histone modifications, DNA accessibility, and coding and non-coding RNA expression in naive, central-, effector-, and terminally differentiated CD45RA+ CD4+ Tmem cells from blood and CD69+ Tmem cells from bone marrow (BM-Tmem). We observed a progressive and proliferation-associated global loss of DNA methylation in heterochromatic parts of the genome during Tmem cell differentiation. Furthermore, distinct gradually changing signatures in the epigenome and the transcriptome supported a linear model of memory development in circulating T cells, while tissue-resident BM-Tmem branched off with a unique epigenetic profile. Integrative analyses identified candidate master regulators of Tmem cell differentiation, including the transcription factor FOXP1. This study highlights the importance of epigenomic changes for Tmem cell biology and demonstrates the value of epigenetic data for the identification of lineage regulators. © 2016 Elsevier Inc.","","CD4-Positive T-Lymphocytes; Cell Differentiation; Epigenesis, Genetic; Epigenomics; Female; Flow Cytometry; Gene Expression Profiling; Humans; Immunologic Memory; Machine Learning; Polymerase Chain Reaction; Transcriptome; CD45RA antigen; CD69 antigen; cyclic AMP responsive element binding protein; DNA; protein AHR; protein bcl 6; protein ETS1; protein FLI1; protein FOXJ3; protein NFEL2; protein RFX3; protein ZFP161; regulator protein; transcription factor; transcription factor E2F2; transcription factor FOXP1; transcription factor Nrf1; transcription factor RUNX3; transcriptome; unclassified drug; untranslated RNA; transcriptome; Article; bone marrow; CD4+ T lymphocyte; cell differentiation; cell maturation; controlled study; DNA methylation; epigenetics; ex vivo study; female; gene expression; histone modification; human; human cell; human tissue; memory T lymphocyte; normal human; priority journal; protein analysis; statistical model; T lymphocyte subpopulation; CD4+ T lymphocyte; cell differentiation; epigenetics; flow cytometry; gene expression profiling; genetic epigenesis; immunological memory; immunology; machine learning; polymerase chain reaction; procedures","Cell Press","10747613","","IUNIE","27851915","Article","Scopus","2-s2.0-84999836163"
"Gao J.; Yang J.; Wang G.; Li M.","Gao, Jingyu (57072040500); Yang, Jinfu (55719542500); Wang, Guanghui (56276619900); Li, Mingai (55388854300)","57072040500; 55719542500; 56276619900; 55388854300","A novel feature extraction method for scene recognition based on Centered Convolutional Restricted Boltzmann Machines","2016","Neurocomputing","33","10.1016/j.neucom.2016.06.055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992490339&doi=10.1016%2fj.neucom.2016.06.055&partnerID=40&md5=2366e05dfa14ea679336bcf27dcacc13","Department of Control & Engineering Beijing University of Technology, No.100 Chaoyang district, Beijing, 100124, China; Department of Electrical Engineering & Computer Science, University of Kansas, Lawrence, 66045-7608, KS, United States","Gao J., Department of Control & Engineering Beijing University of Technology, No.100 Chaoyang district, Beijing, 100124, China; Yang J., Department of Control & Engineering Beijing University of Technology, No.100 Chaoyang district, Beijing, 100124, China; Wang G., Department of Electrical Engineering & Computer Science, University of Kansas, Lawrence, 66045-7608, KS, United States; Li M., Department of Control & Engineering Beijing University of Technology, No.100 Chaoyang district, Beijing, 100124, China","Scene recognition is an important research topic in computer vision, while feature extraction is a key step of scene recognition. Although classical Restricted Boltzmann Machines (RBM) can efficiently represent complicated data, it is hard to handle large images due to its complexity in computation. In this paper, a novel feature extraction method, named Centered Convolutional Restricted Boltzmann Machines (CCRBM), is proposed for scene recognition. The proposed model improves the Convolutional Restricted Boltzmann Machines (CRBM) by introducing centered factors in its learning strategy to reduce the source of instabilities. First, the visible units of the network are redefined using centered factors. Then, the hidden units are learned with a modified energy function by utilizing a distribution function, and the visible units are reconstructed using the learned hidden units. In order to achieve better generative ability, the Centered Convolutional Deep Belief Networks (CCDBN) is trained in a greedy layer-wise way. Finally, a softmax regression is incorporated for scene recognition. Extensive experimental evaluations on the datasets of natural scenes, MIT-indoor scenes, MIT-Places 205, SUN 397, Caltech 101, CIFAR-10, and NORB show that the proposed approach performs better than its counterparts in terms of stability, generalization, and discrimination. The CCDBN model is more suitable for natural scene image recognition by virtue of convolutional property. © 2016 Elsevier B.V.","Centered Convolution Restricted Boltzmann Machines; Centering trick; Deep belief networks; Feature extraction; Scene recognition","Complex networks; Convolution; Data mining; Distribution functions; Extraction; Feature extraction; Image recognition; Centering trick; Deep belief networks; Experimental evaluation; Feature extraction methods; Natural scene images; Restricted boltzmann machine; Scene recognition; Source of instability; accuracy; Article; artificial neural network; Centered Convolutional Deep Belief Networks model; Centered Convolutional Restricted Boltzmann Machine; evaluation study; feature extraction; image analysis; image processing; image quality; image reconstruction; information processing; machine learning; priority journal; regression analysis; scene recognition; softmax regression model; Computer vision","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84992490339"
"Berecibar M.; Devriendt F.; Dubarry M.; Villarreal I.; Omar N.; Verbeke W.; Van Mierlo J.","Berecibar, Maitane (55816737600); Devriendt, Floris (57189003225); Dubarry, Matthieu (14122893100); Villarreal, Igor (8935014600); Omar, Noshin (35786547600); Verbeke, Wouter (16065279300); Van Mierlo, Joeri (57203921849)","55816737600; 57189003225; 14122893100; 8935014600; 35786547600; 16065279300; 57203921849","Online state of health estimation on NMC cells based on predictive analytics","2016","Journal of Power Sources","151","10.1016/j.jpowsour.2016.04.109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964620198&doi=10.1016%2fj.jpowsour.2016.04.109&partnerID=40&md5=f5eab6c8cc2c30ccc513ce37f34eb706","IK4-Ikerlan, Po. J. Ma. Arizmendiarrieta, 2, Arrasate-Mondragón, 20500, Spain; Vrije Universiteit Brussel, MOBI Research Group, Pleinlaan 2, Elsene, 1050, Belgium; Hawaii Natural Energy Institute, SOEST, University of Hawaii at Manoa, 1680 East-West Road, POST 109, Honolulu, 96822, HL, United States","Berecibar M., IK4-Ikerlan, Po. J. Ma. Arizmendiarrieta, 2, Arrasate-Mondragón, 20500, Spain, Vrije Universiteit Brussel, MOBI Research Group, Pleinlaan 2, Elsene, 1050, Belgium; Devriendt F., Vrije Universiteit Brussel, MOBI Research Group, Pleinlaan 2, Elsene, 1050, Belgium; Dubarry M., Hawaii Natural Energy Institute, SOEST, University of Hawaii at Manoa, 1680 East-West Road, POST 109, Honolulu, 96822, HL, United States; Villarreal I., IK4-Ikerlan, Po. J. Ma. Arizmendiarrieta, 2, Arrasate-Mondragón, 20500, Spain; Omar N., Vrije Universiteit Brussel, MOBI Research Group, Pleinlaan 2, Elsene, 1050, Belgium; Verbeke W., Vrije Universiteit Brussel, MOBI Research Group, Pleinlaan 2, Elsene, 1050, Belgium; Van Mierlo J., Vrije Universiteit Brussel, MOBI Research Group, Pleinlaan 2, Elsene, 1050, Belgium","Accurate on board state of health estimation is a key battery management system function to provide optimal management of the battery system under control. In this regard, this paper presents an extensive study and comparison of three of commonly used supervised learning methods for state of health estimation in Graphite/Nickel Manganese Cobalt oxide cells. The three methods were based from the study of both incremental capacity and differential voltage curves. According to the ageing evolution of both curves, features were extracted and used as inputs for the estimation techniques. Ordinary Least Squares, Multilayer Perceptron and Support Vector Machine were used as the estimation techniques and accurate results were obtained while requiring a low computational effort. Moreover, this work allows a deep comparison of the different estimation techniques in terms of accuracy, online estimation and BMS applicability. In addition, estimation can be developed by partial charging and/or partial discharging, reducing the required maintenance time. © 2016 Elsevier B.V. All rights reserved.","Ageing; Battery management; Differential voltage; Incremental capacity; Lithium ion technology; Predictive analytics; State of health estimation","Electric batteries; Health; Lithium alloys; Lithium-ion batteries; Manganese oxide; Secondary batteries; Ageing; Battery Management; Differential voltage; Incremental capacity; Lithium-ion technology; Predictive analytics; State of health; Battery management systems","Elsevier B.V.","03787753","","JPSOD","","Article","Scopus","2-s2.0-84964620198"
"Ngo T.A.; Lu Z.; Carneiro G.","Ngo, Tuan Anh (56102038400); Lu, Zhi (14037587000); Carneiro, Gustavo (23003641100)","56102038400; 14037587000; 23003641100","Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance","2017","Medical Image Analysis","268","10.1016/j.media.2016.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978204565&doi=10.1016%2fj.media.2016.05.009&partnerID=40&md5=523355fc92cc4adfe88ed0ef75b3b199","Vietnam National University of Agriculture, Viet Nam; The University of South Australia, Australia; Australian Centre for Visual Technologies, The University of Adelaide, Australia","Ngo T.A., Vietnam National University of Agriculture, Viet Nam; Lu Z., The University of South Australia, Australia; Carneiro G., Australian Centre for Visual Technologies, The University of Adelaide, Australia","We introduce a new methodology that combines deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance (MR) data. This combination is relevant for segmentation problems, where the visual object of interest presents large shape and appearance variations, but the annotated training set is small, which is the case for various medical image analysis applications, including the one considered in this paper. In particular, level set methods are based on shape and appearance terms that use small training sets, but present limitations for modelling the visual object variations. Deep learning methods can model such variations using relatively small amounts of annotated training, but they often need to be regularised to produce good generalisation. Therefore, the combination of these methods brings together the advantages of both approaches, producing a methodology that needs small training sets and produces accurate segmentation results. We test our methodology on the MICCAI 2009 left ventricle segmentation challenge database (containing 15 sequences for training, 15 for validation and 15 for testing), where our approach achieves the most accurate results in the semi-automated problem and state-of-the-art results for the fully automated challenge. © 2016","Cardiac cine magnetic resonance; Deep learning; Level set method; Segmentation of the left ventricle of the heart","Heart Ventricles; Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging, Cine; Pattern Recognition, Automated; Reproducibility of Results; Automation; Drop breakup; Evolutionary algorithms; Heart; Hydrogels; Image segmentation; Level measurement; Magnetic levitation vehicles; Magnetic resonance; Magnetism; Medical imaging; Medical problems; Numerical methods; Automated segmentation; Fully automated; Learning methods; Left ventricles; Level Set method; Segmentation results; Semi-automated; State of the art; algorithm; Article; automation; cardiac cine magnetic resonance; cardiovascular magnetic resonance; controlled study; data base; endocardium; epicardium; heart cycle; heart failure; heart left ventricle; heart left ventricle hypertrophy; heart muscle ischemia; human; intermethod comparison; learning; measurement accuracy; model; priority journal; automated pattern recognition; cine magnetic resonance imaging; diagnostic imaging; heart ventricle; image processing; machine learning; procedures; reproducibility; Deep learning","Elsevier B.V.","13618415","","MIAEC","27423113","Article","Scopus","2-s2.0-84978204565"
"Lillicrap T.P.; Cownden D.; Tweed D.B.; Akerman C.J.","Lillicrap, Timothy P. (6503977179); Cownden, Daniel (35791457200); Tweed, Douglas B. (7006141887); Akerman, Colin J. (6603238241)","6503977179; 35791457200; 7006141887; 6603238241","Random synaptic feedback weights support error backpropagation for deep learning","2016","Nature Communications","449","10.1038/ncomms13276","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994417427&doi=10.1038%2fncomms13276&partnerID=40&md5=5fab6c99e106753d6d69cec1aadf6d74","Department of Pharmacology, University of Oxford, Oxford, OX1 3QT, United Kingdom; Google DeepMind, 5 New Street Square, London, EC4A 3TW, United Kingdom; School of Biology, University of St.Andrews, Harold Mitchel Building, St.Andrews, Fife, KY16 9TH, United Kingdom; Departments of Physiology and Medicine, University of Toronto, Toronto, M5S 1A8, ON, Canada; Centre for Vision Research, York University, Toronto, M3J 1P3, ON, Canada","Lillicrap T.P., Department of Pharmacology, University of Oxford, Oxford, OX1 3QT, United Kingdom, Google DeepMind, 5 New Street Square, London, EC4A 3TW, United Kingdom; Cownden D., School of Biology, University of St.Andrews, Harold Mitchel Building, St.Andrews, Fife, KY16 9TH, United Kingdom; Tweed D.B., Departments of Physiology and Medicine, University of Toronto, Toronto, M5S 1A8, ON, Canada, Centre for Vision Research, York University, Toronto, M3J 1P3, ON, Canada; Akerman C.J., Department of Pharmacology, University of Oxford, Oxford, OX1 3QT, United Kingdom","The brain processes information through multiple layers of neurons. This deep architecture is representationally powerful, but complicates learning because it is difficult to identify the responsible neurons when a mistake is made. In machine learning, the backpropagation algorithm assigns blame by multiplying error signals with all the synaptic weights on each neuron's axon and further downstream. However, this involves a precise, symmetric backward connectivity pattern, which is thought to be impossible in the brain. Here we demonstrate that this strong architectural constraint is not required for effective error propagation. We present a surprisingly simple mechanism that assigns blame by multiplying errors by even random synaptic weights. This mechanism can transmit teaching signals across multiple layers of neurons and performs as effectively as backpropagation on a variety of tasks. Our results help reopen questions about how the brain could use error signals and dispel long-held assumptions about algorithmic constraints on learning. © The Author(s) 2016.","","Algorithms; Feedback; Machine Learning; Neural Networks (Computer); Nonlinear Dynamics; algorithm; brain; machine learning; neurology; error; learning; synapse; teaching; thinking; algorithm; artificial neural network; feedback system; machine learning; nonlinear system","Nature Publishing Group","20411723","","","27824044","Article","Scopus","2-s2.0-84994417427"
"Shi Z.; Ye Y.; Wu Y.","Shi, Zenglin (57190091937); Ye, Yangdong (7401627537); Wu, Yunpeng (55534054100)","57190091937; 7401627537; 55534054100","Rank-based pooling for deep convolutional neural networks","2016","Neural Networks","65","10.1016/j.neunet.2016.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982149359&doi=10.1016%2fj.neunet.2016.07.003&partnerID=40&md5=76d5b467171a0dd8ebbd0eaa58d9b532","School of Information Engineering, Zhengzhou University, Zhengzhou, 450052, China","Shi Z., School of Information Engineering, Zhengzhou University, Zhengzhou, 450052, China; Ye Y., School of Information Engineering, Zhengzhou University, Zhengzhou, 450052, China; Wu Y., School of Information Engineering, Zhengzhou University, Zhengzhou, 450052, China","Pooling is a key mechanism in deep convolutional neural networks (CNNs) which helps to achieve translation invariance. Numerous studies, both empirically and theoretically, show that pooling consistently boosts the performance of the CNNs. The conventional pooling methods are operated on activation values. In this work, we alternatively propose rank-based pooling. It is derived from the observations that ranking list is invariant under changes of activation values in a pooling region, and thus rank-based pooling operation may achieve more robust performance. In addition, the reasonable usage of rank can avoid the scale problems encountered by value-based methods. The novel pooling mechanism can be regarded as an instance of weighted pooling where a weighted sum of activations is used to generate the pooling output. This pooling mechanism can also be realized as rank-based average pooling (RAP), rank-based weighted pooling (RWP) and rank-based stochastic pooling (RSP) according to different weighting strategies. As another major contribution, we present a novel criterion to analyze the discriminant ability of various pooling methods, which is heavily under-researched in machine learning and computer vision community. Experimental results on several image benchmarks show that rank-based pooling outperforms the existing pooling methods in classification performance. We further demonstrate better performance on CIFAR datasets by integrating RSP into Network-in-Network. © 2016 Elsevier Ltd","Convolutional neural network; Deep learning; Image classification; Pooling","Machine Learning; Neural Networks (Computer); Artificial intelligence; Benchmarking; Chemical activation; Computer vision; Convolution; Learning systems; Neural networks; Stochastic systems; Classification performance; Convolutional neural network; Deep learning; Pooling; Robust performance; Translation invariance; Vision communities; Weighting strategies; Article; artificial neural network; controlled study; deep convolutional neural network; machine learning; network learning; priority journal; rank based average pooling; rank based pooling; rank based stochastic pooling; rank based weighted pooling; statistical analysis; statistical concepts; statistical parameters; Image classification","Elsevier Ltd","08936080","","NNETE","27543927","Article","Scopus","2-s2.0-84982149359"
"Zhang R.; Zheng Y.; Mak T.W.C.; Yu R.; Wong S.H.; Lau J.Y.W.; Poon C.C.Y.","Zhang, Ruikai (57037357800); Zheng, Yali (55516624100); Mak, Tony Wing Chung (55414664300); Yu, Ruoxi (57037652400); Wong, Sunny H. (55451145400); Lau, James Y.W. (13907867100); Poon, Carmen C.Y. (57202479652)","57037357800; 55516624100; 55414664300; 57037652400; 55451145400; 13907867100; 57202479652","Automatic Detection and Classification of Colorectal Polyps by Transferring Low-Level CNN Features from Nonmedical Domain","2017","IEEE Journal of Biomedical and Health Informatics","272","10.1109/JBHI.2016.2635662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014897203&doi=10.1109%2fJBHI.2016.2635662&partnerID=40&md5=ccad85d1871b1c0724ad1ff9cd9922ea","Department of Surgery, Chinese University of Hong Kong, Shatin, Hong Kong; Department of Medicine and Therapeutics, State Key Laboratory of Digestive Diseases, Li Ka Shing Institute of Health Sciences, Institute of Digestive Diseases, Chinese University of Hong Kong, Shatin, Hong Kong","Zhang R., Department of Surgery, Chinese University of Hong Kong, Shatin, Hong Kong; Zheng Y., Department of Surgery, Chinese University of Hong Kong, Shatin, Hong Kong; Mak T.W.C., Department of Surgery, Chinese University of Hong Kong, Shatin, Hong Kong; Yu R., Department of Surgery, Chinese University of Hong Kong, Shatin, Hong Kong; Wong S.H., Department of Medicine and Therapeutics, State Key Laboratory of Digestive Diseases, Li Ka Shing Institute of Health Sciences, Institute of Digestive Diseases, Chinese University of Hong Kong, Shatin, Hong Kong; Lau J.Y.W., Department of Surgery, Chinese University of Hong Kong, Shatin, Hong Kong; Poon C.C.Y., Department of Surgery, Chinese University of Hong Kong, Shatin, Hong Kong","Colorectal cancer (CRC) is a leading cause of cancer deaths worldwide. Although polypectomy at early stage reduces CRC incidence, 90% of the polyps are small and diminutive, where removal of them poses risks to patients that may outweigh the benefits. Correctly detecting and predicting polyp type during colonoscopy allows endoscopists to resect and discard the tissue without submitting it for histology, saving time, and costs. Nevertheless, human visual observation of early stage polyps varies. Therefore, this paper aims at developing a fully automatic algorithm to detect and classify hyperplastic and adenomatous colorectal polyps. Adenomatous polyps should be removed, whereas distal diminutive hyperplastic polyps are considered clinically insignificant and may be left in situ. A novel transfer learning application is proposed utilizing features learned from big nonmedical datasets with 1.4-2.5 million images using deep convolutional neural network. The endoscopic images we collected for experiment were taken under random lighting conditions, zooming and optical magnification, including 1104 endoscopic nonpolyp images taken under both white-light and narrowband imaging (NBI) endoscopy and 826 NBI endoscopic polyp images, of which 263 images were hyperplasia and 563 were adenoma as confirmed by histology. The proposed method identified polyp images from nonpolyp images in the beginning followed by predicting the polyp histology. When compared with visual inspection by endoscopists, the results of this study show that the proposed method has similar precision (87.3% versus 86.4%) but a higher recall rate (87.6% versus 77.0%) and a higher accuracy (85.9% versus 74.3%). In conclusion, automatic algorithms can assist endoscopists in identifying polyps that are adenomatous but have been incorrectly judged as hyperplasia and, therefore, enable timely resection of these polyps at an early stage before they develop into invasive cancer. © 2013 IEEE.","Colorectal cancer; deep learning; health informatics; polyp diagnosis","Colonic Polyps; Colonoscopy; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); ROC Curve; Computer aided instruction; Convolutional neural networks; Deep learning; Deep neural networks; Endoscopy; Histology; Medical informatics; Transfer learning; Automatic algorithms; Automatic Detection; Colorectal cancer; Colorectal cancers (CRC); Colorectal polyps; Lighting conditions; Narrow-band imaging (NBI); Visual inspection; area under the curve; Article; artificial neural network; classification algorithm; classifier; clinical feature; colorectal polyp; computer assisted diagnosis; controlled study; convolutional neural network; diagnostic accuracy; diagnostic procedure; disease classification; endoscopy; histology; hyperplasia; image analysis; image processing; measurement precision; receiver operating characteristic; artificial neural network; classification; colon polyp; colonoscopy; computer assisted diagnosis; diagnostic imaging; human; machine learning; procedures; Diseases","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","28114040","Article","Scopus","2-s2.0-85014897203"
"Roth H.R.; Lu L.; Liu J.; Yao J.; Seff A.; Cherry K.; Kim L.; Summers R.M.","Roth, Holger R. (36622444300); Lu, Le (55474685200); Liu, Jiamin (26642957600); Yao, Jianhua (57693843200); Seff, Ari (56190682500); Cherry, Kevin (35878523200); Kim, Lauren (56516142600); Summers, Ronald M. (7202364932)","36622444300; 55474685200; 26642957600; 57693843200; 56190682500; 35878523200; 56516142600; 7202364932","Improving Computer-Aided Detection Using Convolutional Neural Networks and Random View Aggregation","2016","IEEE Transactions on Medical Imaging","474","10.1109/TMI.2015.2482920","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969916782&doi=10.1109%2fTMI.2015.2482920&partnerID=40&md5=deb8163ba68a3e7de49997dc6c54bdc4","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States","Roth H.R., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Lu L., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Liu J., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Yao J., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Seff A., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Cherry K., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Kim L., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Summers R.M., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States","Automated computer-aided detection (CADe) has been an important tool in clinical practice and research. State-of-the-art methods often show high sensitivities at the cost of high false-positives (FP) per patient rates. We design a two-tiered coarse-to-fine cascade framework that first operates a candidate generation system at sensitivities ∼ 100% of but at high FP levels. By leveraging existing CADe systems, coordinates of regions or volumes of interest (ROI or VOI) are generated and function as input for a second tier, which is our focus in this study. In this second stage, we generate 2D (two-dimensional) or 2.5D views via sampling through scale transformations, random translations and rotations. These random views are used to train deep convolutional neural network (ConvNet) classifiers. In testing, the ConvNets assign class (e.g., lesion, pathology) probabilities for a new set of random views that are then averaged to compute a final per-candidate classification probability. This second tier behaves as a highly selective process to reject difficult false positives while preserving high sensitivities. The methods are evaluated on three data sets: 59 patients for sclerotic metastasis detection, 176 patients for lymph node detection, and 1,186 patients for colonic polyp detection. Experimental results show the ability of ConvNets to generalize well to different medical imaging CADe applications and scale elegantly to various data sets. Our proposed methods improve performance markedly in all cases. Sensitivities improved from 57% to 70%, 43% to 77%, and 58% to 75% at 3 FPs per patient for sclerotic metastases, lymph nodes and colonic polyps, respectively. © 2016 IEEE.","artificial neural networks; computed tomography; Computer aided diagnosis; deep learning; machine learning; medical diagnostic imaging; multi-layer neural network; object detection","Adolescent; Adult; Aged; Child; Colonic Polyps; Databases, Factual; Female; Humans; Lymph Nodes; Machine Learning; Male; Middle Aged; Neural Networks (Computer); Radiographic Image Interpretation, Computer-Assisted; Spinal Neoplasms; Tomography, X-Ray Computed; Young Adult; Artificial intelligence; Body fluids; Computer aided instruction; Computer networks; Computerized tomography; Convolution; Diagnosis; Learning systems; Medical imaging; Network layers; Neural networks; Object detection; Pathology; Colonic polyp detection; Computer aided detection; Convolutional neural network; Deep learning; Lymph node detections; Medical diagnostic imaging; Scale transformation; State-of-the-art methods; adenomatous polyp; adolescent; adult; aged; algorithm; Article; artificial neural network; bone lesion; child; colon polyp; computed tomographic colonography; computer aided design; computer aided detection; controlled study; diagnostic imaging; female; human; lymph node metastasis; major clinical study; male; probability; computer assisted diagnosis; factual database; lymph node; machine learning; middle aged; procedures; spine tumor; x-ray computed tomography; young adult; Computer aided diagnosis","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26441412","Article","Scopus","2-s2.0-84969916782"
"Zhang R.; Li J.; Lu J.; Hu R.; Yuan Y.; Zhao Z.","Zhang, Ruisheng (7404864895); Li, Juan (56018357500); Lu, Jingjing (57188881667); Hu, Rongjing (25627710700); Yuan, Yongna (55474906600); Zhao, Zhili (7404149364)","7404864895; 56018357500; 57188881667; 25627710700; 55474906600; 7404149364","Using deep learning for compound selectivity prediction","2016","Current Computer-Aided Drug Design","12","10.2174/1573409912666160219113250","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964091167&doi=10.2174%2f1573409912666160219113250&partnerID=40&md5=14b96c07bf8f6cea7f0ced2a7a4dbfab","School of Information Science and Engineering, Lanzhou University, Lanzhou, Gansu, 730000, China","Zhang R., School of Information Science and Engineering, Lanzhou University, Lanzhou, Gansu, 730000, China; Li J., School of Information Science and Engineering, Lanzhou University, Lanzhou, Gansu, 730000, China; Lu J., School of Information Science and Engineering, Lanzhou University, Lanzhou, Gansu, 730000, China; Hu R., School of Information Science and Engineering, Lanzhou University, Lanzhou, Gansu, 730000, China; Yuan Y., School of Information Science and Engineering, Lanzhou University, Lanzhou, Gansu, 730000, China; Zhao Z., School of Information Science and Engineering, Lanzhou University, Lanzhou, Gansu, 730000, China","Compound selectivity prediction plays an important role in identifying potential compounds that bind to the target of interest with high affinity. However, there is still short of efficient and accurate computational approaches to analyze and predict compound selectivity. In this paper, we propose two methods to improve the compound selectivity prediction. We employ an improved multitask learning method in Neural Networks (NNs), which not only incorporates both activity and selectivity for other targets, but also uses a probabilistic classifier with a logistic regression. We further improve the compound selectivity prediction by using the multitask learning method in Deep Belief Networks (DBNs) which can build a distributed representation model and improve the generalization of the shared tasks. In addition, we assign different weights to the auxiliary tasks that are related to the primary selectivity prediction task. In contrast to other related work, our methods greatly improve the accuracy of the compound selectivity prediction, in particular, using the multitask learning in DBNs with modified weights obtains the best performance. © 2016 Bentham Science Publishers.","Compound selectivity; Deep belief networks; Multitask learning; Neural network","Algorithms; Computer-Aided Design; Drug Design; Machine Learning; Neural Networks (Computer); Probability; Bayesian networks; Deep learning; Compound selectivity; Computational approach; Deep belief networks; High affinity; Learning methods; Logistics regressions; Multitask learning; Neural-networks; Probabilistic classifiers; Targets of interest; classifier; learning; logistic regression analysis; model; nervous system; prediction; algorithm; artificial neural network; computer aided design; drug design; machine learning; probability; Forecasting","Bentham Science Publishers","15734099","","","26892071","Article","Scopus","2-s2.0-84964091167"
"Brosch T.; Tang L.Y.W.; Yoo Y.; Li D.K.B.; Traboulsee A.; Tam R.","Brosch, Tom (55892057300); Tang, Lisa Y. W. (24336549500); Yoo, Youngjin (56047857100); Li, David K. B. (7405320868); Traboulsee, Anthony (6602953194); Tam, Roger (7006808600)","55892057300; 24336549500; 56047857100; 7405320868; 6602953194; 7006808600","Deep 3D Convolutional Encoder Networks With Shortcuts for Multiscale Feature Integration Applied to Multiple Sclerosis Lesion Segmentation","2016","IEEE Transactions on Medical Imaging","372","10.1109/TMI.2016.2528821","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968586012&doi=10.1109%2fTMI.2016.2528821&partnerID=40&md5=3772493fd9d0f9b5419c2ffb8e2c6a96","Multiple Sclerosis/Magnetic Resonance Imaging Research Group, Division of Neurology, University of British Columbia, Vancouver, V6T 2B5, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Department of Radiology, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada","Brosch T., Multiple Sclerosis/Magnetic Resonance Imaging Research Group, Division of Neurology, University of British Columbia, Vancouver, V6T 2B5, BC, Canada, Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Tang L.Y.W., Multiple Sclerosis/Magnetic Resonance Imaging Research Group, Division of Neurology, University of British Columbia, Vancouver, V6T 2B5, BC, Canada, Department of Radiology, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Yoo Y., Multiple Sclerosis/Magnetic Resonance Imaging Research Group, Division of Neurology, University of British Columbia, Vancouver, V6T 2B5, BC, Canada, Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Li D.K.B., Multiple Sclerosis/Magnetic Resonance Imaging Research Group, Division of Neurology, University of British Columbia, Vancouver, V6T 2B5, BC, Canada, Department of Radiology, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Traboulsee A., Multiple Sclerosis/Magnetic Resonance Imaging Research Group, Division of Neurology, University of British Columbia, Vancouver, V6T 2B5, BC, Canada; Tam R., Multiple Sclerosis/Magnetic Resonance Imaging Research Group, Division of Neurology, University of British Columbia, Vancouver, V6T 2B5, BC, Canada, Department of Radiology, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada","We propose a novel segmentation approach based on deep 3D convolutional encoder networks with shortcut connections and apply it to the segmentation of multiple sclerosis (MS) lesions in magnetic resonance images. Our model is a neural network that consists of two interconnected pathways, a convolutional pathway, which learns increasingly more abstract and higher-level image features, and a deconvolutional pathway, which predicts the final segmentation at the voxel level. The joint training of the feature extraction and prediction pathways allows for the automatic learning of features at different scales that are optimized for accuracy for any given combination of image types and segmentation task. In addition, shortcut connections between the two pathways allow high- and low-level features to be integrated, which enables the segmentation of lesions across a wide range of sizes. We have evaluated our method on two publicly available data sets (MICCAI 2008 and ISBI 2015 challenges) with the results showing that our method performs comparably to the top-ranked state-of-the-art methods, even when only relatively small data sets are available for training. In addition, we have compared our method with five freely available and widely used MS lesion segmentation methods (EMS, LST-LPA, LST-LGA, Lesion-TOADS, and SLS) on a large data set from an MS clinical trial. The results show that our method consistently outperforms these other methods across a wide range of lesion sizes. © 1982-2012 IEEE.","Convolutional neural networks; deep learning; machine learning; magnetic resonance imaging (MRI); multiple sclerosis lesions; segmentation","Algorithms; Brain; Humans; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Magnetic Resonance Imaging; Multiple Sclerosis; Neural Networks (Computer); Artificial intelligence; Convolution; Feature extraction; Image processing; Learning systems; Magnetic levitation vehicles; Magnetic resonance imaging; Neural networks; Convolutional encoders; Convolutional neural network; Deep learning; Interconnected pathways; Lesion segmentations; Multiple sclerosis lesions; Short-cut connection; State-of-the-art methods; Article; calculation; clinical research; convolutional neural network; deep three dimensional convolutional encoder network with shortcut; human; image analysis; imaging and display; intermethod comparison; learning algorithm; lesion size; mathematical model; measurement accuracy; multiple sclerosis; nervous system parameters; nuclear magnetic resonance imaging; receptive field; segmentation method; algorithm; artificial neural network; brain; computer assisted diagnosis; diagnostic imaging; machine learning; multiple sclerosis; nuclear magnetic resonance imaging; pathology; procedures; three dimensional imaging; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26886978","Article","Scopus","2-s2.0-84968586012"
"Chandra B.; Sharma R.K.","Chandra, B. (57043453600); Sharma, Rajesh K. (56377805700)","57043453600; 56377805700","Fast learning in Deep Neural Networks","2016","Neurocomputing","39","10.1016/j.neucom.2015.07.093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944514832&doi=10.1016%2fj.neucom.2015.07.093&partnerID=40&md5=d070e08345897dbb4505c9f2635b586e","Department of Mathematics, Indian Institute of Technology, Delhi, India","Chandra B., Department of Mathematics, Indian Institute of Technology, Delhi, India; Sharma R.K., Department of Mathematics, Indian Institute of Technology, Delhi, India","The paper aims at speeding up Deep Neural Networks (DNN) since this is one of the major bottlenecks in deep learning. This has been achieved by parameterizing the weight matrix using low rank factorization and periodic functions. By parameterization, the weight matrix is split into two matrices of smaller size of rank K with periodic functions. A shrinkage parameter has been introduced which helps in reducing the number of parameters and thus helps in increasing the speed to a great extent. Performance of the proposed parameterization is compared with standard DNN, DNN based on weight factorization alone and on periodic-bounded weights. This has been demonstrated on benchmark datasets MNIST and MNIST variants. © 2015 Elsevier B.V.","Deep learning; Deep Neural Network; Denoising autoencoder","Factorization; Auto encoders; Benchmark datasets; Bounded weights; Deep learning; Deep neural networks; Periodic function; Shrinkage parameter; Weight matrices; Article; artificial neural network; deep learning; deep neural network; machine learning; mathematical analysis; mathematical model; mathematical phenomena; parameterization; priority journal; Matrix algebra","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84944514832"
"Zhong B.; Pan S.; Zhang H.; Wang T.; Du J.; Chen D.; Cao L.","Zhong, Bineng (24473810700); Pan, Shengnan (57005946500); Zhang, Hongbo (56945874300); Wang, Tian (55866537800); Du, Jixiang (14017783700); Chen, Duansheng (56170729000); Cao, Liujuan (35749499000)","24473810700; 57005946500; 56945874300; 55866537800; 14017783700; 56170729000; 35749499000","Convolutional Deep Belief Networks for Single-Cell/Object Tracking in Computational Biology and Computer Vision","2016","BioMed Research International","4","10.1155/2016/9406259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994499990&doi=10.1155%2f2016%2f9406259&partnerID=40&md5=582df4b0fc7f58fc316736d3bcc04fae","Department of Computer Science and Engineering, Huaqiao University, Xiamen, China; School of Information Science and Technology, Xiamen University, Xiamen, China","Zhong B., Department of Computer Science and Engineering, Huaqiao University, Xiamen, China; Pan S., Department of Computer Science and Engineering, Huaqiao University, Xiamen, China; Zhang H., Department of Computer Science and Engineering, Huaqiao University, Xiamen, China; Wang T., Department of Computer Science and Engineering, Huaqiao University, Xiamen, China; Du J., Department of Computer Science and Engineering, Huaqiao University, Xiamen, China; Chen D., Department of Computer Science and Engineering, Huaqiao University, Xiamen, China; Cao L., School of Information Science and Technology, Xiamen University, Xiamen, China","In this paper, we propose deep architecture to dynamically learn the most discriminative features from data for both single-cell and object tracking in computational biology and computer vision. Firstly, the discriminative features are automatically learned via a convolutional deep belief network (CDBN). Secondly, we design a simple yet effective method to transfer features learned from CDBNs on the source tasks for generic purpose to the object tracking tasks using only limited amount of training data. Finally, to alleviate the tracker drifting problem caused by model updating, we jointly consider three different types of positive samples. Extensive experiments validate the robustness and effectiveness of the proposed method. © 2016 Bineng Zhong et al.","","Animals; Cell Tracking; Computer Simulation; Data Interpretation, Statistical; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Machine Learning; Microscopy; Models, Statistical; Neural Networks (Computer); Reproducibility of Results; Sensitivity and Specificity; biology; case report; eye tracking; model; vision; animal; artificial neural network; cell tracking; computer assisted diagnosis; computer simulation; human; image enhancement; machine learning; microscopy; procedures; reproducibility; sensitivity and specificity; statistical analysis; statistical model","Hindawi Limited","23146133","","","27847827","Article","Scopus","2-s2.0-84994499990"
"Li Y.; Yang J.; Ji W.","Li, Yun (58059965500); Yang, Jun (56999426000); Ji, Wei (57210515153)","58059965500; 56999426000; 57210515153","Local learning-based feature weighting with privacy preservation","2016","Neurocomputing","14","10.1016/j.neucom.2015.10.038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949680255&doi=10.1016%2fj.neucom.2015.10.038&partnerID=40&md5=236bf6c50b8172bdbe4b102e1480aa39","College of Compter Science, Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; Key Laboratory of Cloud Computing and oComplex System, Guilin University of Electronic Technology, Guilin, China","Li Y., College of Compter Science, Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjing University of Posts and Telecommunications, Nanjing, China; Yang J., College of Compter Science, Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjing University of Posts and Telecommunications, Nanjing, China; Ji W., College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China, Key Laboratory of Cloud Computing and oComplex System, Guilin University of Electronic Technology, Guilin, China","The privacy-preserving data analysis has been gained significant interest across several research communities. The current researches mainly focus on privacy-preserving classification and regression. On the other hand, feature selection is also one of the key problems in data mining and machine learning. However, for privacy-preserving feature selection, the relevant papers are few. In this paper, a local learning-based feature weighting framework is introduced. Moreover, in order to preserve the data privacy during local learning-based feature selection, the objective perturbation and output perturbation strategies are used to produce local learning-based feature selection algorithms with privacy preservation. Meanwhile, we give deep analysis about their privacy preserving property based on the differential privacy model. Some experiments are conducted on benchmark data sets. The experimental results show that our algorithms can preserve the data privacy to some extent and the objective perturbation always obtains higher classification performance than output perturbation when the privacy preserving degree is constant. © 2015 Elsevier B.V..","Feature weighting; Local learning; Privacy preservation","Artificial intelligence; Data mining; Feature extraction; Learning systems; Classification performance; Differential privacies; Feature selection algorithm; Feature weighting; Local learning; Output perturbations; Privacy preservation; Privacy-preserving classification; Article; classification algorithm; data analysis; data mining; information processing; local learning based feature weighting framework; machine learning; mathematical computing; measurement accuracy; priority journal; privacy preservation; regression analysis; sensitivity analysis; Data privacy","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84949680255"
"Ghesu F.C.; Krubasik E.; Georgescu B.; Singh V.; Zheng Y.; Hornegger J.; Comaniciu D.","Ghesu, Florin C. (56185916200); Krubasik, Edward (57189298335); Georgescu, Bogdan (6603044053); Singh, Vivek (57208561544); Zheng, Yefeng (8062522600); Hornegger, Joachim (6603448080); Comaniciu, Dorin (7003476440)","56185916200; 57189298335; 6603044053; 57208561544; 8062522600; 6603448080; 7003476440","Marginal Space Deep Learning: Efficient Architecture for Volumetric Image Parsing","2016","IEEE Transactions on Medical Imaging","125","10.1109/TMI.2016.2538802","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968572880&doi=10.1109%2fTMI.2016.2538802&partnerID=40&md5=86b7e16ee41422c41066f6828615f2f5","Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States; Robotics and Embedded Systems Department, Technische Universität München, München, 85748, Germany; Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany","Ghesu F.C., Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States, Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany; Krubasik E., Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States, Robotics and Embedded Systems Department, Technische Universität München, München, 85748, Germany; Georgescu B., Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States; Singh V., Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States; Zheng Y., Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States; Hornegger J., Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, 91058, Germany; Comaniciu D., Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States","Robust and fast solutions for anatomical object detection and segmentation support the entire clinical workflow from diagnosis, patient stratification, therapy planning, intervention and follow-up. Current state-of-the-art techniques for parsing volumetric medical image data are typically based on machine learning methods that exploit large annotated image databases. Two main challenges need to be addressed, these are the efficiency in scanning high-dimensional parametric spaces and the need for representative image features which require significant efforts of manual engineering. We propose a pipeline for object detection and segmentation in the context of volumetric image parsing, solving a two-step learning problem: anatomical pose estimation and boundary delineation. For this task we introduce Marginal Space Deep Learning (MSDL), a novel framework exploiting both the strengths of efficient object parametrization in hierarchical marginal spaces and the automated feature design of Deep Learning (DL) network architectures. In the 3D context, the application of deep learning systems is limited by the very high complexity of the parametrization. More specifically 9 parameters are necessary to describe a restricted affine transformation in 3D, resulting in a prohibitive amount of billions of scanning hypotheses. The mechanism of marginal space learning provides excellent run-time performance by learning classifiers in clustered, high-probability regions in spaces of gradually increasing dimensionality. To further increase computational efficiency and robustness, in our system we learn sparse adaptive data sampling patterns that automatically capture the structure of the input. Given the object localization, we propose a DL-based active shape model to estimate the non-rigid object boundary. Experimental results are presented on the aortic valve in ultrasound using an extensive dataset of 2891 volumes from 869 patients, showing significant improvements of up to 45.2% over the state-of-the-art. To our knowledge, this is the first successful demonstration of the DL potential to detection and segmentation in full 3D data with parametrized representations. © 1982-2012 IEEE.","Deep learning; image parsing; marginal space learning; sparse representations; three-dimensional (3D) object detection and segmentation","Algorithms; Aortic Valve; Databases, Factual; Echocardiography, Transesophageal; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Artificial intelligence; Complex networks; Computational efficiency; Diagnosis; Efficiency; Gesture recognition; Image processing; Image segmentation; Learning systems; Medical imaging; Network architecture; Object recognition; Patient treatment; Ultrasonic applications; Deep learning; Image parsing; Marginal space learning; Sparse representation; Three-dimensional (3-D) object detection; aorta valve; classifier; data base; diagnosis; experimental model; follow up; human; machine learning; major clinical study; pipeline; stratification; treatment planning; ultrasound; workflow; algorithm; aortic valve; artificial neural network; automated pattern recognition; diagnostic imaging; factual database; image processing; procedures; transesophageal echocardiography; Object detection","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","27046846","Article","Scopus","2-s2.0-84968572880"
"Kelley D.R.; Snoek J.; Rinn J.L.","Kelley, David R. (7202669205); Snoek, Jasper (15129127600); Rinn, John L. (6603278085)","7202669205; 15129127600; 6603278085","Basset: Learning the regulatory code of the accessible genome with deep convolutional neural networks","2016","Genome Research","562","10.1101/gr.200535.115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976908652&doi=10.1101%2fgr.200535.115&partnerID=40&md5=5f94121f373c18ae478e71b2aa6ed7a4","Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, 02138, MA, United States; School of Engineering and Applied Science, Harvard University, Cambridge, 02138, MA, United States","Kelley D.R., Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, 02138, MA, United States; Snoek J., School of Engineering and Applied Science, Harvard University, Cambridge, 02138, MA, United States; Rinn J.L., Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, 02138, MA, United States","The complex language of eukaryotic gene expression remains incompletely understood. Despite the importance suggested by many noncoding variants statistically associated with human disease, nearly all such variants have unknown mechanisms. Here, we address this challenge using an approach based on a recent machine learning advance-deep convolutional neural networks (CNNs). We introduce the open source package Basset to apply CNNs to learn the functional activity of DNA sequences from genomics data. We trained Basset on a compendium of accessible genomic sites mapped in 164 cell types by DNase-seq, and demonstrate greater predictive accuracy than previous methods. Basset predictions for the change in accessibility between variant alleles were far greater for Genome-wide association study (GWAS) SNPs that are likely to be causal relative to nearby SNPs in linkage disequilibrium with them. With Basset, a researcher can perform a single sequencing assay in their cell type of interest and simultaneously learn that cell's chromatin accessibility code and annotate every mutation in the genome with its influence on present accessibility and latent potential for accessibility. Thus, Basset offers a powerful computational approach to annotate and interpret the noncoding genome. © 2016 Kelley et al.","","Base Sequence; Binding Sites; Consensus Sequence; Humans; Linkage Disequilibrium; Models, Genetic; Molecular Sequence Annotation; Neural Networks (Computer); Polymorphism, Single Nucleotide; Sequence Analysis, DNA; Support Vector Machine; Article; Basset; cells by body anatomy; convolutional neural network; DNA sequence; gene linkage disequilibrium; genetic analysis; genome; genome-wide association study; nerve cell network; priority journal; protein binding; single nucleotide polymorphism; artificial neural network; binding site; biological model; consensus sequence; DNA sequence; human; molecular genetics; nucleotide sequence; support vector machine","Cold Spring Harbor Laboratory Press","10889051","","GEREF","27197224","Article","Scopus","2-s2.0-84976908652"
"Giloteaux L.; Goodrich J.K.; Walters W.A.; Levine S.M.; Ley R.E.; Hanson M.R.","Giloteaux, Ludovic (35956069100); Goodrich, Julia K. (35302344100); Walters, William A. (36093557900); Levine, Susan M. (7403576609); Ley, Ruth E. (57193891727); Hanson, Maureen R. (7401973705)","35956069100; 35302344100; 36093557900; 7403576609; 57193891727; 7401973705","Reduced diversity and altered composition of the gut microbiome in individuals with myalgic encephalomyelitis/chronic fatigue syndrome","2016","Microbiome","233","10.1186/s40168-016-0171-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995735596&doi=10.1186%2fs40168-016-0171-4&partnerID=40&md5=36b4d0317dbf50dbf72f1b93bd6f8c27","Department of Molecular Biology and Genetics, Cornell University, Ithaca, NY, United States; Department of Microbiology, Cornell University, Ithaca, NY, United States; Private Practice, New York, NY, United States","Giloteaux L., Department of Molecular Biology and Genetics, Cornell University, Ithaca, NY, United States; Goodrich J.K., Department of Molecular Biology and Genetics, Cornell University, Ithaca, NY, United States, Department of Microbiology, Cornell University, Ithaca, NY, United States; Walters W.A., Department of Molecular Biology and Genetics, Cornell University, Ithaca, NY, United States, Department of Microbiology, Cornell University, Ithaca, NY, United States; Levine S.M., Private Practice, New York, NY, United States; Ley R.E., Department of Molecular Biology and Genetics, Cornell University, Ithaca, NY, United States, Department of Microbiology, Cornell University, Ithaca, NY, United States; Hanson M.R., Department of Molecular Biology and Genetics, Cornell University, Ithaca, NY, United States","Background: Gastrointestinal disturbances are among symptoms commonly reported by individuals diagnosed with myalgic encephalomyelitis/chronic fatigue syndrome (ME/CFS). However, whether ME/CFS is associated with an altered microbiome has remained uncertain. Here, we profiled gut microbial diversity by sequencing 16S ribosomal ribonucleic acid (rRNA) genes from stool as well as inflammatory markers from serum for cases (n = 48) and controls (n = 39). We also examined a set of inflammatory markers in blood: C-reactive protein (CRP), intestinal fatty acid-binding protein (I-FABP), lipopolysaccharide (LPS), LPS-binding protein (LBP), and soluble CD14 (sCD14). Results: We observed elevated levels of some blood markers for microbial translocation in ME/CFS patients; levels of LPS, LBP, and sCD14 were elevated in ME/CFS subjects. Levels of LBP correlated with LPS and sCD14 and LPS levels correlated with sCD14. Through deep sequencing of bacterial rRNA markers, we identified differences between the gut microbiomes of healthy individuals and patients with ME/CFS. We observed that bacterial diversity was decreased in the ME/CFS specimens compared to controls, in particular, a reduction in the relative abundance and diversity of members belonging to the Firmicutes phylum. In the patient cohort, we find less diversity as well as increases in specific species often reported to be pro-inflammatory species and reduction in species frequently described as anti-inflammatory. Using a machine learning approach trained on the data obtained from 16S rRNA and inflammatory markers, individuals were classified correctly as ME/CFS with a cross-validation accuracy of 82.93 %. Conclusions: Our results indicate dysbiosis of the gut microbiota in this disease and further suggest an increased incidence of microbial translocation, which may play a role in inflammatory symptoms in ME/CFS. © 2016 The Author(s).","Beta-diversity; Chronic fatigue syndrome; Inflammation; Lipopolysaccharides; Microbial translocation; Microbiome; Myalgic encephalomyelitis","Acute-Phase Proteins; Adult; Aged; Antigens, CD14; Bacteria; Biodiversity; C-Reactive Protein; Carrier Proteins; Case-Control Studies; DNA, Ribosomal; Dysbiosis; Fatigue Syndrome, Chronic; Fatty Acid-Binding Proteins; Feces; Female; Firmicutes; Gastrointestinal Microbiome; High-Throughput Nucleotide Sequencing; Humans; Male; Membrane Glycoproteins; Middle Aged; Phylogeny; RNA, Ribosomal, 16S; Sequence Analysis, DNA; Young Adult; C reactive protein; CD14 antigen; fatty acid binding protein 2; lipopolysaccharide; lipopolysaccharide binding protein; RNA 16S; acute phase protein; C reactive protein; carrier protein; CD14 antigen; fatty acid binding protein; lipopolysaccharide-binding protein; membrane protein; ribosome DNA; RNA 16S; Actinobacteria; adult; antiinflammatory activity; Article; bacterial translocation; chemiluminescence immunoassay; chronic fatigue syndrome; clinical article; cohort analysis; controlled study; DNA extraction; dysbiosis; encephalomyelitis; enzyme linked immunosorbent assay; female; Firmicutes; gene sequence; human; inflammatory bowel disease; intestine flora; irritable colon; machine learning; male; microbial diversity; middle aged; nonhuman; Prevotellaceae; priority journal; Ruminococcaceae; Short Form 36; Verrucomicrobia; aged; bacterium; biodiversity; case control study; chronic fatigue syndrome; classification; DNA sequence; dysbiosis; feces; high throughput sequencing; intestine flora; isolation and purification; metabolism; microbiology; phylogeny; procedures; young adult","BioMed Central Ltd.","20492618","","","27338587","Article","Scopus","2-s2.0-84995735596"
"Kamenetzky L.; Stegmayer G.; Maldonado L.; Macchiaroli N.; Yones C.; Milone D.H.","Kamenetzky, L. (6602840669); Stegmayer, G. (6506368373); Maldonado, L. (56526515300); Macchiaroli, N. (55584531200); Yones, C. (54956134000); Milone, D.H. (6505923044)","6602840669; 6506368373; 56526515300; 55584531200; 54956134000; 6505923044","MicroRNA discovery in the human parasite Echinococcus multilocularis from genome-wide data","2016","Genomics","12","10.1016/j.ygeno.2016.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964859091&doi=10.1016%2fj.ygeno.2016.04.002&partnerID=40&md5=948569d8e7aa731dae14538627b128b3","IMPAM-UBA-CONICET, Facultad de Medicina, Buenos Aires, Argentina; sinc(i)-FICH-UNL-CONICET, Ciudad Universitaria, Santa Fe, Argentina","Kamenetzky L., IMPAM-UBA-CONICET, Facultad de Medicina, Buenos Aires, Argentina; Stegmayer G., sinc(i)-FICH-UNL-CONICET, Ciudad Universitaria, Santa Fe, Argentina; Maldonado L., IMPAM-UBA-CONICET, Facultad de Medicina, Buenos Aires, Argentina; Macchiaroli N., IMPAM-UBA-CONICET, Facultad de Medicina, Buenos Aires, Argentina; Yones C., sinc(i)-FICH-UNL-CONICET, Ciudad Universitaria, Santa Fe, Argentina; Milone D.H., sinc(i)-FICH-UNL-CONICET, Ciudad Universitaria, Santa Fe, Argentina","The cestode parasite Echinococcus multilocularis is the aetiological agent of alveolar echinococcosis, responsible for considerable human morbidity and mortality. This disease is a worldwide zoonosis of major public health concern and is considered a neglected disease by the World Health Organization. The complete genome of E. multilocularis has been recently sequenced and assembled in a collaborative effort between the Wellcome Trust Sanger Institute and our group, with the main aim of analyzing protein-coding genes. These analyses suggested that approximately 10% of E. multilocularis genome is composed of protein-coding regions. This shows there is still a vast proportion of the genome that needs to be explored, including non-coding RNAs such as small RNAs (sRNAs). Within this class of small regulatory RNAs, microRNAs (miRNAs) can be found, which have been identified in many different organisms ranging from viruses to higher eukaryotes. MiRNAs are a key regulation mechanism of gene expression at post-transcriptional level and play important roles in biological processes such as development, proliferation, cell differentiation and metabolism in animals and plants. In spite of this, identification of miRNAs directly from genome-wide data only is still a very challenging task. There are many miRNAs that remain unidentified due to the lack of either sequence information of particular phylums or appropriate algorithms to identify novel miRNAs. The motivation for this work is the discovery of new miRNAs in E. multilocularis based on non-target genomic data only, in order to obtain useful information from the currently available unexplored data. In this work, we present the discovery of new pre-miRNAs in the E. multilocularis genome through a novel approach based on machine learning. We have extracted the most commonly used structural features from the folded sequences of the parasite genome: triplets, minimum free energy and sequence length. These features have been used to train a novel deep architecture of self-organizing maps (SOMs). This model can be trained with a high class imbalance and without the artificial definition of a negative class. We discovered 886 pre-miRNA candidates within the E. multilocularis genome-wide data. After that, experimental validation by small RNA-seq analysis clearly showed 23 pre-miRNA candidates with a pattern compatible with miRNA biogenesis, indicating them as high confidence miRNAs. We discovered new pre-miRNA candidates in E. multilocularis using non-target genomic data only. Predictions were meaningful using only sequence data, with no need of RNA-seq data or target analysis for prediction. Furthermore, the methodology employed can be easily adapted and applied on any draft genomes, which are actually the most interesting ones since most non-model organisms have this kind of status and carry real biological and sanitary relevance. © 2016 Elsevier Inc.","","Animals; Echinococcosis; Echinococcus multilocularis; Genome; Humans; MicroRNAs; microRNA; untranslated RNA; microRNA; Article; controlled study; Echinococcus multilocularis; gene expression; gene function; gene identification; genome analysis; genome-wide association study; machine learning; nonhuman; parasite identification; prediction; priority journal; RNA sequence; sequence analysis; animal; echinococcosis; Echinococcus multilocularis; genetics; genome; human; isolation and purification; parasitology; pathogenicity","Academic Press Inc.","08887543","","GNMCE","27107656","Article","Scopus","2-s2.0-84964859091"
"Sirinukunwattana K.; Raza S.E.A.; Tsang Y.-W.; Snead D.R.J.; Cree I.A.; Rajpoot N.M.","Sirinukunwattana, Korsuk (43061431200); Raza, Shan E. Ahmed (54960699400); Tsang, Yee-Wah (57072889500); Snead, David R. J. (7003568153); Cree, Ian A. (7006520218); Rajpoot, Nasir M. (8042017200)","43061431200; 54960699400; 57072889500; 7003568153; 7006520218; 8042017200","Locality Sensitive Deep Learning for Detection and Classification of Nuclei in Routine Colon Cancer Histology Images","2016","IEEE Transactions on Medical Imaging","950","10.1109/TMI.2016.2525803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968542311&doi=10.1109%2fTMI.2016.2525803&partnerID=40&md5=2ddaf423c29f3424e4269beabce9bac9","Department of Computer Science, University of Warwick, Coventry, CV4 7AL, United Kingdom; Department of Pathology, University Hospitals Coventry and Warwickshire, Walsgrave, Coventry, CV2 2DX, United Kingdom; Department of Computer Science and Engineering, Qatar University, Qatar","Sirinukunwattana K., Department of Computer Science, University of Warwick, Coventry, CV4 7AL, United Kingdom; Raza S.E.A., Department of Computer Science, University of Warwick, Coventry, CV4 7AL, United Kingdom; Tsang Y.-W., Department of Pathology, University Hospitals Coventry and Warwickshire, Walsgrave, Coventry, CV2 2DX, United Kingdom; Snead D.R.J., Department of Pathology, University Hospitals Coventry and Warwickshire, Walsgrave, Coventry, CV2 2DX, United Kingdom; Cree I.A., Department of Pathology, University Hospitals Coventry and Warwickshire, Walsgrave, Coventry, CV2 2DX, United Kingdom; Rajpoot N.M., Department of Computer Science, University of Warwick, Coventry, CV4 7AL, United Kingdom, Department of Computer Science and Engineering, Qatar University, Qatar","Detection and classification of cell nuclei in histopathology images of cancerous tissue stained with the standard hematoxylin and eosin stain is a challenging task due to cellular heterogeneity. Deep learning approaches have been shown to produce encouraging results on histopathology images in various studies. In this paper, we propose a Spatially Constrained Convolutional Neural Network (SC-CNN) to perform nucleus detection. SC-CNN regresses the likelihood of a pixel being the center of a nucleus, where high probability values are spatially constrained to locate in the vicinity of the centers of nuclei. For classification of nuclei, we propose a novel Neighboring Ensemble Predictor (NEP) coupled with CNN to more accurately predict the class label of detected cell nuclei. The proposed approaches for detection and classification do not require segmentation of nuclei. We have evaluated them on a large dataset of colorectal adenocarcinoma images, consisting of more than 20,000 annotated nuclei belonging to four different classes. Our results show that the joint detection and classification of the proposed SC-CNN and NEP produces the highest average F1 score as compared to other recently published approaches. Prospectively, the proposed methods could offer benefit to pathology practice in terms of quantitative analysis of tissue constituents in whole-slide images, and potentially lead to a better understanding of cancer. © 1982-2012 IEEE.","Convolutional neural network; deep learning; histology image analysis; nucleus detection","Cell Nucleus; Cell Proliferation; Colon; Colonic Neoplasms; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Convolution; Diseases; Histology; Neural networks; Tissue; Cancerous tissues; Colorectal adenocarcinoma; Convolutional neural network; Deep learning; High probability; Histology images; Locality sensitives; Whole slide images; Article; basal cell carcinoma; breast cancer; cancer classification; cell nucleus; colorectal carcinoma; eosinophil; fibroblast; histopathology; human; image analysis; immunohistochemistry; lymphocyte; machine learning; neutrophil; prostate cancer; regression analysis; spatially constrained convolutional neural network; support vector machine; artificial neural network; cell nucleus; cell proliferation; colon; colon tumor; computer assisted diagnosis; cytochemistry; cytology; diagnostic imaging; machine learning; physiology; procedures; Image analysis","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26863654","Article","Scopus","2-s2.0-84968542311"
"Cao L.-L.; Huang W.-B.; Sun F.-C.","Cao, Le-le (56461848700); Huang, Wen-bing (55899205200); Sun, Fu-chun (55555423500)","56461848700; 55899205200; 55555423500","Building feature space of extreme learning machine with sparse denoising stacked-autoencoder","2016","Neurocomputing","53","10.1016/j.neucom.2015.02.096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940061662&doi=10.1016%2fj.neucom.2015.02.096&partnerID=40&md5=b14b81076323302c3194e06715f7d464","Tsinghua National Laboratory for Information Science and Technology (TNList), Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China","Cao L.-L., Tsinghua National Laboratory for Information Science and Technology (TNList), Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Huang W.-B., Tsinghua National Laboratory for Information Science and Technology (TNList), Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Sun F.-C., Tsinghua National Laboratory for Information Science and Technology (TNList), Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China","The random-hidden-node extreme learning machine (ELM) is a much more generalized cluster of single-hidden-layer feed-forward neural networks (SLFNs) which has three parts: random projection, non-linear transformation, and ridge regression (RR) model. Networks with deep architectures have demonstrated state-of-the-art performance in a variety of settings, especially with computer vision tasks. Deep learning algorithms such as stacked autoencoder (SAE) and deep belief network (DBN) are built on learning several levels of representation of the input. Beyond simply learning features by stacking autoencoders (AE), there is a need for increasing its robustness to noise and reinforcing the sparsity of weights to make it easier to discover interesting and prominent features. The sparse AE and denoising AE was hence developed for this purpose. This paper proposes an approach: SSDAE-RR (stacked sparse denoising autoencoder - ridge regression) that effectively integrates the advantages in SAE, sparse AE, denoising AE, and the RR implementation in ELM algorithm. We conducted experimental study on real-world classification (binary and multiclass) and regression problems with different scales among several relevant approaches: SSDAE-RR, ELM, DBN, neural network (NN), and SAE. The performance analysis shows that the SSDAE-RR tends to achieve a better generalization ability on relatively large datasets (large sample size and high dimension) that were not pre-processed for feature abstraction. For 16 out of 18 tested datasets, the performance of SSDAE-RR is more stable than other tested approaches. We also note that the sparsity regularization and denoising mechanism seem to be mandatory for constructing interpretable feature representations. The fact that a SSDAE-RR approach often has a comparable training time to ELM makes it useful in some real applications. © 2015 Elsevier B.V.","Classification; Extreme learning machine (ELM); Feature space; Regression; Ridge regression; Stacked autoencoder (SAE)","Classification (of information); Computer vision; Knowledge acquisition; Learning algorithms; Linear transformations; Mathematical transformations; Regression analysis; Auto encoders; Extreme learning machine; Feature space; Regression; Ridge regression; Article; artificial neural network; classification; deep belief network; extreme learning machine; learning algorithm; machine learning; mathematical computing; noise reduction; priority journal; regression analysis; ridge regression; stacked sparse denoising autoencoder; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84940061662"
"Chen F.; Li X.; Zhou Y.; Yang D.","Chen, Fudi (57222627135); Li, Xu (57196400412); Zhou, Yibing (53985823500); Yang, Dazuo (52464708000)","57222627135; 57196400412; 53985823500; 52464708000","Prediction of size of silver nanoparticles using support vector machine and artificial neural networks","2016","Journal of Computational and Theoretical Nanoscience","0","10.1166/jctn.2016.6028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015169543&doi=10.1166%2fjctn.2016.6028&partnerID=40&md5=da4a4c91d1602dbd797c9196295a5ade","Key Laboratory of Marine Bio-Resources Restoration and Habitat Reparation in Liaoning Province, Dalian Ocean University, Dalian, 116023, China; College of Life Science and Technology, Dalian University of Technology, Dalian, 116021, China; Dalian Productivity Promote Center, Dalian, 116025, China","Chen F., Key Laboratory of Marine Bio-Resources Restoration and Habitat Reparation in Liaoning Province, Dalian Ocean University, Dalian, 116023, China; Li X., Dalian Productivity Promote Center, Dalian, 116025, China; Zhou Y., Key Laboratory of Marine Bio-Resources Restoration and Habitat Reparation in Liaoning Province, Dalian Ocean University, Dalian, 116023, China; Yang D., Key Laboratory of Marine Bio-Resources Restoration and Habitat Reparation in Liaoning Province, Dalian Ocean University, Dalian, 116023, China, College of Life Science and Technology, Dalian University of Technology, Dalian, 116021, China","Silver nanoparticles (Ag-NPs) is of great importance in nanomaterials research for its special properties, which is mainly caused by the size of the nanoparticles. However, optimizing the synthesis conditions of Ag-NPs is of great complexity and difficulty in experimental research. Here, we propose novel machine learning techniques including support vector machine (SVM) and artificial neural networks (ANNs) to predict the size of the Ag-NPs synthesized by a novel green method. The SVM, general regression neural network (GRNN) and multilayer feed-forward neural networks (MLFNs) were developed. Synthesis conditions of Ag-NPs including NaOH volume (1 M), temperature (°C), stabilizer (%w/w) and AgNO3 concentration (M) were set as independent variables while the mean diameters of Ag-NPs (nm) was set as the dependent variable. Results show that the SVM, GRNN and MLFN with 2 nodes have the best prediction results in testing (RMS errors: 4.96, 6.14, 7.11, respectively; Prediction accuracies: All 100% under the tolerance of 30%) and the SVM and GRNN required the shortest training times (both 1 s). Taking the RMS error, training time and the model robustness into consideration, in our study, the SVM was considered as the best machine learning model for the prediction of size of Ag-NPs. © 2016 American Scientific Publishers All rights reserved.","Artificial neural networks; Silver nanoparticles; Support vector machine","Artificial intelligence; Deep neural networks; Forecasting; Intelligent systems; Learning systems; Metal nanoparticles; Multilayer neural networks; Nanoparticles; Neural networks; Support vector machines; Experimental research; General regression neural network; Independent variables; Machine learning models; Machine learning techniques; Multilayer feedforward neural networks; Silver nanoparticles; Silver nanoparticles (AgNps); Silver","American Scientific Publishers","15461955","","","","Article","Scopus","2-s2.0-85015169543"
"Chen Y.; Li Y.; Narayan R.; Subramanian A.; Xie X.","Chen, Yifei (55961779900); Li, Yi (55650717000); Narayan, Rajiv (55799026700); Subramanian, Aravind (7102892052); Xie, Xiaohui (8311948600)","55961779900; 55650717000; 55799026700; 7102892052; 8311948600","Gene expression inference with deep learning","2016","Bioinformatics","288","10.1093/bioinformatics/btw074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976420628&doi=10.1093%2fbioinformatics%2fbtw074&partnerID=40&md5=8c10643727cc78f5b8313f856bfa198b","Department of Computer Science, University of California, Irvine, 92697, CA, United States; Broad Institute of MIT and Harvard, Cambridge, 02142, MA, United States; Center for Complex Biological Systems, University of California, Irvine, 92697, CA, United States; Baidu Research-Big Data Lab, Beijing, 100085, China","Chen Y., Department of Computer Science, University of California, Irvine, 92697, CA, United States, Baidu Research-Big Data Lab, Beijing, 100085, China; Li Y., Department of Computer Science, University of California, Irvine, 92697, CA, United States; Narayan R., Broad Institute of MIT and Harvard, Cambridge, 02142, MA, United States; Subramanian A., Broad Institute of MIT and Harvard, Cambridge, 02142, MA, United States; Xie X., Department of Computer Science, University of California, Irvine, 92697, CA, United States, Center for Complex Biological Systems, University of California, Irvine, 92697, CA, United States","Motivation: Large-scale gene expression profiling has been widely used to characterize cellular states in response to various disease conditions, genetic perturbations, etc. Although the cost of whole-genome expression profiles has been dropping steadily, generating a compendium of expression profiling over thousands of samples is still very expensive. Recognizing that gene expressions are often highly correlated, researchers from the NIH LINCS program have developed a cost-effective strategy of profiling only ∼1000 carefully selected landmark genes and relying on computational methods to infer the expression of remaining target genes. However, the computational approach adopted by the LINCS program is currently based on linear regression (LR), limiting its accuracy since it does not capture complex nonlinear relationship between expressions of genes. Results: We present a deep learning method (abbreviated as D-GEX) to infer the expression of target genes from the expression of landmark genes. We used the microarray-based Gene Expression Omnibus dataset, consisting of 111K expression profiles, to train our model and compare its performance to those from other methods. In terms of mean absolute error averaged across all genes, deep learning significantly outperforms LR with 15.33% relative improvement. A gene-wise comparative analysis shows that deep learning achieves lower error than LR in 99.97% of the target genes. We also tested the performance of our learned model on an independent RNA-Seq-based GTEx dataset, which consists of 2921 expression profiles. Deep learning still outperforms LR with 6.57% relative improvement, and achieves lower error in 81.31% of the target genes. © 2016 The Author 2016.","","Gene Expression; Gene Expression Profiling; Linear Models; Machine Learning; RNA; RNA; gene expression; gene expression profiling; machine learning; statistical model","Oxford University Press","13674803","","BOINF","26873929","Article","Scopus","2-s2.0-84976420628"
"Ribeiro E.; Uhl A.; Wimmer G.; Häfner M.","Ribeiro, Eduardo (24483887700); Uhl, Andreas (7005841206); Wimmer, Georg (12790538100); Häfner, Michael (7004811714)","24483887700; 7005841206; 12790538100; 7004811714","Exploring Deep Learning and Transfer Learning for Colonic Polyp Classification","2016","Computational and Mathematical Methods in Medicine","135","10.1155/2016/6584725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994665902&doi=10.1155%2f2016%2f6584725&partnerID=40&md5=ce6ca949fd4862af530f396603203d86","Department of Computer Sciences, University of Salzburg, Salzburg, Austria; Department of Computer Sciences, Federal University of Tocantins, Palmas, TO, Brazil; St. Elisabeth Hospital, Vienna, Austria","Ribeiro E., Department of Computer Sciences, University of Salzburg, Salzburg, Austria, Department of Computer Sciences, Federal University of Tocantins, Palmas, TO, Brazil; Uhl A., Department of Computer Sciences, University of Salzburg, Salzburg, Austria; Wimmer G., Department of Computer Sciences, University of Salzburg, Salzburg, Austria; Häfner M., St. Elisabeth Hospital, Vienna, Austria","Recently, Deep Learning, especially through Convolutional Neural Networks (CNNs) has been widely used to enable the extraction of highly representative features. This is done among the network layers by filtering, selecting, and using these features in the last fully connected layers for pattern classification. However, CNN training for automated endoscopic image classification still provides a challenge due to the lack of large and publicly available annotated databases. In this work we explore Deep Learning for the automated classification of colonic polyps using different configurations for training CNNs from scratch (or full training) and distinct architectures of pretrained CNNs tested on 8-HD-endoscopic image databases acquired using different modalities. We compare our results with some commonly used features for colonic polyp classification and the good results suggest that features learned by CNNs trained from scratch and the ""off-the-shelf"" CNNs features can be highly relevant for automated classification of colonic polyps. Moreover, we also show that the combination of classical features and ""off-the-shelf"" CNNs features can be a good approach to further improve the results. © 2016 Eduardo Ribeiro et al.","","Algorithms; Colonic Polyps; Colonoscopy; Diagnosis, Computer-Assisted; Endoscopy; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); Pattern Recognition, Automated; Reproducibility of Results; Software; Video Recording; Automation; Classification (of information); Convolutional neural networks; Endoscopy; Network layers; Transfer learning; Annotated database; Automated classification; Colonic polyps; Image database; Article; classifier; colon polyp; data base; deep learning; disease classification; human; McNemar test; support vector machine; transfer learning; algorithm; artificial neural network; automated pattern recognition; classification; colon polyp; colonoscopy; computer assisted diagnosis; diagnostic imaging; endoscopy; image processing; machine learning; procedures; reproducibility; software; videorecording; Deep learning","Hindawi Limited","1748670X","","","27847543","Article","Scopus","2-s2.0-84994665902"
"Shim H.-M.; An H.; Lee S.; Lee E.H.; Min H.-K.; Lee S.","Shim, Hyeon-Min (7202595610); An, Hongsub (42761060600); Lee, Sanghyuk (35069850400); Lee, Eung Hyuk (7406968096); Min, Hong-Ki (14421387400); Lee, Sangmin (57218876411)","7202595610; 42761060600; 35069850400; 7406968096; 14421387400; 57218876411","EMG pattern classification by split and merge deep belief network","2016","Symmetry","24","10.3390/sym8120148","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003844960&doi=10.3390%2fsym8120148&partnerID=40&md5=648b0e726998c48aafc1f9a920cbc2ea","Department of Digital Electronics, Dong Seoul University, Seongnam, 13117, South Korea; Korea Electrotechnology Research Institute, Ansan, 15588, South Korea; Department of Electrical and Electronic Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, 215123, China; Biomedical Engineering Centre, Chiang Mai University, Chiang Mai, 50200, Thailand; Department of Electronic Engineering, Korea Polytechinic University, Siheung, 15073, South Korea; Department of Information and Telecommunication Engineering, Incheon National University, Incheon, 22012, South Korea; Department of Electronic Engineering, Inha University, Incheon, 22201, South Korea","Shim H.-M., Department of Digital Electronics, Dong Seoul University, Seongnam, 13117, South Korea; An H., Korea Electrotechnology Research Institute, Ansan, 15588, South Korea; Lee S., Department of Electrical and Electronic Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, 215123, China, Biomedical Engineering Centre, Chiang Mai University, Chiang Mai, 50200, Thailand; Lee E.H., Department of Electronic Engineering, Korea Polytechinic University, Siheung, 15073, South Korea; Min H.-K., Department of Information and Telecommunication Engineering, Incheon National University, Incheon, 22012, South Korea; Lee S., Department of Electronic Engineering, Inha University, Incheon, 22201, South Korea","In this paper; we introduce an enhanced electromyography (EMG) pattern recognition algorithm based on a split-and-merge deep belief network (SM-DBN). Generally, it is difficult to classify the EMG features because the EMG signal has nonlinear and time-varying characteristics. Therefore, various machine-learning methods have been applied in several previously published studies. A DBN is a fast greedy learning algorithm that can identify a fairly good set of weights rapidly-even in deep networks with a large number of parameters and many hidden layers. To reduce overfitting and to enhance performance, the adopted optimization method was based on genetic algorithms (GA). As a result, the performance of the SM-DBN was 12.06% higher than conventional DBN. Additionally, SM-DBN results in a short convergence time, thereby reducing the training epoch. It is thus efficient in reducing the risk of overfitting. It is verified that the optimization was improved using GA. © 2016 by the authors.","Deep belief network; Deep learning; EMG pattern recognition; SM-DBN; Split and merge deep belief network","","MDPI AG","20738994","","","","Article","Scopus","2-s2.0-85003844960"
"Van Grinsven M.J.J.P.; Van Ginneken B.; Hoyng C.B.; Theelen T.; Sánchez C.I.","Van Grinsven, Mark J. J. P. (55674914900); Van Ginneken, Bram (55759608800); Hoyng, Carel B. (7003671959); Theelen, Thomas (6602941893); Sánchez, Clara I. (8543425100)","55674914900; 55759608800; 7003671959; 6602941893; 8543425100","Fast Convolutional Neural Network Training Using Selective Data Sampling: Application to Hemorrhage Detection in Color Fundus Images","2016","IEEE Transactions on Medical Imaging","358","10.1109/TMI.2016.2526689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968665432&doi=10.1109%2fTMI.2016.2526689&partnerID=40&md5=850c7312e38362d14463830d6bab622d","Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525 GA, Netherlands; Department of Ophthalmology, Radboud University Medical Center, Nijmegen, 6525 EX, Netherlands; Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Department of Ophthalmology, Radboud University Medical Center, Nijmegen, 6525 GA, Netherlands","Van Grinsven M.J.J.P., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525 GA, Netherlands; Van Ginneken B., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525 GA, Netherlands; Hoyng C.B., Department of Ophthalmology, Radboud University Medical Center, Nijmegen, 6525 EX, Netherlands; Theelen T., Department of Ophthalmology, Radboud University Medical Center, Nijmegen, 6525 EX, Netherlands; Sánchez C.I., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Department of Ophthalmology, Radboud University Medical Center, Nijmegen, 6525 GA, Netherlands","Convolutional neural networks (CNNs) are deep learning network architectures that have pushed forward the state-of-the-art in a range of computer vision applications and are increasingly popular in medical image analysis. However, training of CNNs is time-consuming and challenging. In medical image analysis tasks, the majority of training examples are easy to classify and therefore contribute little to the CNN learning process. In this paper, we propose a method to improve and speed-up the CNN training for medical image analysis tasks by dynamically selecting misclassified negative samples during training. Training samples are heuristically sampled based on classification by the current status of the CNN. Weights are assigned to the training samples and informative samples are more likely to be included in the next CNN training iteration. We evaluated and compared our proposed method by training a CNN with (SeS) and without (NSeS) the selective sampling method. We focus on the detection of hemorrhages in color fundus images. A decreased training time from 170 epochs to 60 epochs with an increased performance - on par with two human experts - was achieved with areas under the receiver operating characteristics curve of 0.894 and 0.972 on two data sets. The SeS CNN statistically outperformed the NSeS CNN on an independent test set. © 1982-2012 IEEE.","Convolutional neural network; deep learning; hemorrhage; selective sampling","Databases, Factual; Fundus Oculi; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Retinal Hemorrhage; Computer vision; Convolution; Iterative methods; Learning systems; Medical imaging; Network architecture; Neural networks; Sampling; Computer vision applications; Convolutional neural network; Deep learning; hemorrhage; Hemorrhage detection; Receiver operating characteristics; Selective sampling; State of the art; Article; artificial neural network; camera; classification algorithm; controlled study; convolutional neural network; diagnostic test accuracy study; fundus camera; heuristics; human; image analysis; image processing; image quality; measurement error; ophthalmoscopy; retina hemorrhage; sensitivity and specificity; computer assisted diagnosis; diagnostic imaging; eye fundus; factual database; machine learning; procedures; retina hemorrhage; Image analysis","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26886969","Article","Scopus","2-s2.0-84968665432"
"Miao S.; Wang Z.J.; Liao R.","Miao, Shun (36629063700); Wang, Z. Jane (11241026700); Liao, Rui (55191129300)","36629063700; 11241026700; 55191129300","A CNN Regression Approach for Real-Time 2D/3D Registration","2016","IEEE Transactions on Medical Imaging","386","10.1109/TMI.2016.2521800","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968662562&doi=10.1109%2fTMI.2016.2521800&partnerID=40&md5=50ac70a3a3e5ed97f1bd1d8fb4d2ff89","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States","Miao S., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada, Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States; Wang Z.J., Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Liao R., Medical Imaging Technologies, Siemens Healthcare, Princeton, 08540, NJ, United States","In this paper, we present a Convolutional Neural Network (CNN) regression approach to address the two major limitations of existing intensity-based 2-D/3-D registration technology: 1) slow computation and 2) small capture range. Different from optimization-based methods, which iteratively optimize the transformation parameters over a scalar-valued metric function representing the quality of the registration, the proposed method exploits the information embedded in the appearances of the digitally reconstructed radiograph and X-ray images, and employs CNN regressors to directly estimate the transformation parameters. An automatic feature extraction step is introduced to calculate 3-D pose-indexed features that are sensitive to the variables to be regressed while robust to other factors. The CNN regressors are then trained for local zones and applied in a hierarchical manner to break down the complex regression task into multiple simpler sub-tasks that can be learned separately. Weight sharing is furthermore employed in the CNN regression model to reduce the memory footprint. The proposed approach has been quantitatively evaluated on 3 potential clinical applications, demonstrating its significant advantage in providing highly accurate real-time 2-D/3-D registration with a significantly enlarged capture range when compared to intensity-based methods. © 1982-2012 IEEE.","2-D/3-D registration; convolutional neural network; deep learning; image guided intervention","Arthroplasty, Replacement, Knee; Echocardiography, Transesophageal; Humans; Imaging, Three-Dimensional; Knee Joint; Machine Learning; Neural Networks (Computer); Radiography; Regression Analysis; Complex networks; Convolution; Feature extraction; Iterative methods; Neural networks; 2D/3D registration; Automatic feature extraction; Convolutional neural network; Deep learning; Digitally reconstructed radiographs; Image-guided Intervention; Optimization based methods; Transformation parameters; algorithm; Article; artificial neural network; automation; convolutional neural network; hierarchical parameter regression; image reconstruction; kinematics; local image residual; micro-computed tomography; parameter space partitioning; pose estimation via hierarchical learning; quantitative analysis; radiation attenuation; regression analysis; total knee arthroplasty; transesophageal echocardiography; X ray; diagnostic imaging; human; knee; knee replacement; machine learning; procedures; radiography; regression analysis; three dimensional imaging; Regression analysis","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26829785","Article","Scopus","2-s2.0-84968662562"
"Pereira S.; Pinto A.; Alves V.; Silva C.A.","Pereira, Sergio (56642341100); Pinto, Adriano (56642291100); Alves, Victor (7006627528); Silva, Carlos A. (56325790600)","56642341100; 56642291100; 7006627528; 56325790600","Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images","2016","IEEE Transactions on Medical Imaging","1953","10.1109/TMI.2016.2538465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968610616&doi=10.1109%2fTMI.2016.2538465&partnerID=40&md5=658e5ebdac4480c8c5b9cc5f1ff2e6fe","CMEMS-UMinho Research Unit, University of Minho, Campus Azurém, Guimarães, 4800-058, Portugal; Centro Algoritmi, Universidade Do Minho, Braga, 4710-057, Portugal","Pereira S., CMEMS-UMinho Research Unit, University of Minho, Campus Azurém, Guimarães, 4800-058, Portugal, Centro Algoritmi, Universidade Do Minho, Braga, 4710-057, Portugal; Pinto A., CMEMS-UMinho Research Unit, University of Minho, Campus Azurém, Guimarães, 4800-058, Portugal; Alves V., Centro Algoritmi, Universidade Do Minho, Braga, 4710-057, Portugal; Silva C.A., CMEMS-UMinho Research Unit, University of Minho, Campus Azurém, Guimarães, 4800-058, Portugal","Among brain tumors, gliomas are the most common and aggressive, leading to a very short life expectancy in their highest grade. Thus, treatment planning is a key stage to improve the quality of life of oncological patients. Magnetic resonance imaging (MRI) is a widely used imaging technique to assess these tumors, but the large amount of data produced by MRI prevents manual segmentation in a reasonable time, limiting the use of precise quantitative measurements in the clinical practice. So, automatic and reliable segmentation methods are required; however, the large spatial and structural variability among brain tumors make automatic segmentation a challenging problem. In this paper, we propose an automatic segmentation method based on Convolutional Neural Networks (CNN), exploring small 3 x 3 kernels. The use of small kernels allows designing a deeper architecture, besides having a positive effect against overfitting, given the fewer number of weights in the network. We also investigated the use of intensity normalization as a pre-processing step, which though not common in CNN-based segmentation methods, proved together with data augmentation to be very effective for brain tumor segmentation in MRI images. Our proposal was validated in the Brain Tumor Segmentation Challenge 2013 database (BRATS 2013), obtaining simultaneously the first position for the complete, core, and enhancing regions in Dice Similarity Coefficient metric (0.88, 0.83, 0.77) for the Challenge data set. Also, it obtained the overall first position by the online evaluation platform. We also participated in the on-site BRATS 2015 Challenge using the same model, obtaining the second place, with Dice Similarity Coefficient metric of 0.78, 0.65, and 0.75 for the complete, core, and enhancing regions, respectively. © 1982-2012 IEEE.","Brain tumor; brain tumor segmentation; convolutional neural networks; deep learning; glioma; magnetic resonance imaging","Brain Neoplasms; Glioma; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Brain; Convolution; Image segmentation; Imaging techniques; Neural networks; Patient treatment; Tumors; gadolinium; Brain tumor segmentation; Brain tumors; Convolutional neural network; Deep learning; glioma; Article; artificial neural network; astrocytoma; automation; brain tumor; case report; contrast enhancement; convolutional neural network; glioblastoma; human; image processing; kernel method; neuroimaging; nuclear magnetic resonance imaging; predictive value; sensitivity and specificity; brain tumor; computer assisted diagnosis; diagnostic imaging; glioma; machine learning; nuclear magnetic resonance imaging; pathology; procedures; Magnetic resonance imaging","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26960222","Article","Scopus","2-s2.0-84968610616"
"Zhong B.; Pan S.; Wang C.; Wang T.; Du J.; Chen D.; Cao L.","Zhong, Bineng (24473810700); Pan, Shengnan (57005946500); Wang, Cheng (55978095000); Wang, Tian (55866537800); Du, Jixiang (14017783700); Chen, Duansheng (56170729000); Cao, Liujuan (35749499000)","24473810700; 57005946500; 55978095000; 55866537800; 14017783700; 56170729000; 35749499000","Robust Individual-Cell/Object Tracking via PCANet Deep Network in Biomedicine and Computer Vision","2016","BioMed Research International","7","10.1155/2016/8182416","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985963054&doi=10.1155%2f2016%2f8182416&partnerID=40&md5=a620d98237db9c8e9beb530363fb96ed","Department of Computer Science and Engineering, Huaqiao University, Xiamen, Fujian Province, 361021, China; School of Information Science and Technology, Xiamen University, China","Zhong B., Department of Computer Science and Engineering, Huaqiao University, Xiamen, Fujian Province, 361021, China; Pan S., Department of Computer Science and Engineering, Huaqiao University, Xiamen, Fujian Province, 361021, China; Wang C., Department of Computer Science and Engineering, Huaqiao University, Xiamen, Fujian Province, 361021, China; Wang T., Department of Computer Science and Engineering, Huaqiao University, Xiamen, Fujian Province, 361021, China; Du J., Department of Computer Science and Engineering, Huaqiao University, Xiamen, Fujian Province, 361021, China; Chen D., Department of Computer Science and Engineering, Huaqiao University, Xiamen, Fujian Province, 361021, China; Cao L., School of Information Science and Technology, Xiamen University, China","Tracking individual-cell/object over time is important in understanding drug treatment effects on cancer cells and video surveillance. A fundamental problem of individual-cell/object tracking is to simultaneously address the cell/object appearance variations caused by intrinsic and extrinsic factors. In this paper, inspired by the architecture of deep learning, we propose a robust feature learning method for constructing discriminative appearance models without large-scale pretraining. Specifically, in the initial frames, an unsupervised method is firstly used to learn the abstract feature of a target by exploiting both classic principal component analysis (PCA) algorithms with recent deep learning representation architectures. We use learned PCA eigenvectors as filters and develop a novel algorithm to represent a target by composing of a PCA-based filter bank layer, a nonlinear layer, and a patch-based pooling layer, respectively. Then, based on the feature representation, a neural network with one hidden layer is trained in a supervised mode to construct a discriminative appearance model. Finally, to alleviate the tracker drifting problem, a sample update scheme is carefully designed to keep track of the most representative and diverse samples during tracking. We test the proposed tracking method on two standard individual cell/object tracking benchmarks to show our tracker's state-of-the-art performance. © 2016 Bineng Zhong et al.","","algorithm; Article; biomedicine; cancer cell; cell density; cell tracking; illumination; support vector machine","Hindawi Limited","23146133","","","","Article","Scopus","2-s2.0-84985963054"
"Putin E.; Mamoshina P.; Aliper A.; Korzinkin M.; Moskalev A.; Kolosov A.; Ostrovskiy A.; Cantor C.; Vijg J.; Zhavoronkov A.","Putin, Evgeny (57189310406); Mamoshina, Polina (56893719500); Aliper, Alexander (54889030500); Korzinkin, Mikhail (56108465700); Moskalev, Alexey (7003730453); Kolosov, Alexey (57190009412); Ostrovskiy, Alexander (57208329752); Cantor, Charles (57189989844); Vijg, Jan (7006875822); Zhavoronkov, Alex (39862415800)","57189310406; 56893719500; 54889030500; 56108465700; 7003730453; 57190009412; 57208329752; 57189989844; 7006875822; 39862415800","Deep biomarkers of human aging: Application of deep neural networks to biomarker development","2016","Aging","244","10.18632/aging.100968","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976407069&doi=10.18632%2faging.100968&partnerID=40&md5=2cfdd02c0bae9aed8359999347da666b","Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States; Computer Technologies Lab, ITMO University, St. Petersburg, 197101, Russian Federation; The Biogerontology Research Foundation, Oxford, United Kingdom; School of Systems Biology, George Mason University (GMU), Fairfax, 22030, VA, United States; Invitro Laboratory, Ltd., Moscow, 125047, Russian Federation; Department of Biomedical Engineering, Boston University, Boston, 02215, MA, United States; Department of Genetics, Albert Einstein College of Medicine, Bronx, 10461, NY, United States","Putin E., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States, Computer Technologies Lab, ITMO University, St. Petersburg, 197101, Russian Federation; Mamoshina P., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States, The Biogerontology Research Foundation, Oxford, United Kingdom; Aliper A., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States; Korzinkin M., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States; Moskalev A., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States, School of Systems Biology, George Mason University (GMU), Fairfax, 22030, VA, United States; Kolosov A., Invitro Laboratory, Ltd., Moscow, 125047, Russian Federation; Ostrovskiy A., Invitro Laboratory, Ltd., Moscow, 125047, Russian Federation; Cantor C., Department of Biomedical Engineering, Boston University, Boston, 02215, MA, United States; Vijg J., Department of Genetics, Albert Einstein College of Medicine, Bronx, 10461, NY, United States; Zhavoronkov A., Pharma.AI Department, Insilico Medicine, Inc., Baltimore, 21218, MD, United States, The Biogerontology Research Foundation, Oxford, United Kingdom","One of the major impediments in human aging research is the absence of a comprehensive and actionable set of biomarkers that may be targeted and measured to track the effectiveness of therapeutic interventions. In this study, we designed a modular ensemble of 21 deep neural networks (DNNs) of varying depth, structure and optimization to predict human chronological age using a basic blood test. To train the DNNs, we used over 60,000 samples from common blood biochemistry and cell count tests from routine health exams performed by a single laboratory and linked to chronological age and sex. The best performing DNN in the ensemble demonstrated 81.5 % epsilon-accuracy r = 0.90 with R2 = 0.80 and MAE = 6.07 years in predicting chronological age within a 10 year frame, while the entire ensemble achieved 83.5% epsilon-accuracy r = 0.91 with R2 = 0.82 and MAE = 5.55 years. The ensemble also identified the 5 most important markers for predicting human chronological age: albumin, glucose, alkaline phosphatase, urea and erythrocytes. To allow for public testing and evaluate real-life performance of the predictor, we developed an online system available at http://www.aging.ai. The ensemble approach may facilitate integration of multi-modal data linked to chronological age and sex that may lead to simple, minimally invasive, and affordable methods of tracking integrated biomarkers of aging in humans and performing cross-species feature importance analysis. © Putin et al.","Aging biomarkers; Biomarker development; Deep learning; Deep neural networks; Human aging; Machine learning","Aging; Alkaline Phosphatase; Biomarkers; Blood Glucose; Erythrocyte Count; Humans; Models, Biological; Nerve Net; Physical Examination; Serum Albumin; Urea; alkaline phosphatase; biological marker; serum albumin; urea; aging; analysis; biological model; blood; erythrocyte count; glucose blood level; human; nerve cell network; physical examination; physiology","Impact Journals LLC","19454589","","","27191382","Article","Scopus","2-s2.0-84976407069"
"O'Halloran R.; Kopell B.H.; Sprooten E.; Goodman W.K.; Frangou S.","O'Halloran, Rafael (16067549900); Kopell, Brian H. (7004055681); Sprooten, Emma (57216377958); Goodman, Wayne K. (7102365894); Frangou, Sophia (7004549374)","16067549900; 7004055681; 57216377958; 7102365894; 7004549374","Multimodal neuroimaging-informed clinical applications in neuropsychiatric disorders","2016","Frontiers in Psychiatry","21","10.3389/fpsyt.2016.00063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975292915&doi=10.3389%2ffpsyt.2016.00063&partnerID=40&md5=f35f441360b8293a9608b4c0db85551c","Brain Imaging Center, Translational and Molecular Imaging Institute, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Department of Neurosurgery, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Department of Neurology, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Department of Neuroscience, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Department of Psychiatry, Icahn School of Medicine at Mount Sinai, New York, NY, United States","O'Halloran R., Brain Imaging Center, Translational and Molecular Imaging Institute, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Kopell B.H., Department of Neurosurgery, Icahn School of Medicine at Mount Sinai, New York, NY, United States, Department of Neurology, Icahn School of Medicine at Mount Sinai, New York, NY, United States, Department of Neuroscience, Icahn School of Medicine at Mount Sinai, New York, NY, United States, Department of Psychiatry, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Sprooten E., Department of Psychiatry, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Goodman W.K., Department of Neuroscience, Icahn School of Medicine at Mount Sinai, New York, NY, United States, Department of Psychiatry, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Frangou S., Department of Psychiatry, Icahn School of Medicine at Mount Sinai, New York, NY, United States","Recent advances in neuroimaging data acquisition and analysis hold the promise to enhance the ability to make diagnostic and prognostic predictions and perform treatment planning in neuropsychiatric disorders. Prior research using a variety of types of neuroimaging techniques has confirmed that neuropsychiatric disorders are associated with dysfunction in anatomical and functional brain circuits. We first discuss current challenges associated with the identification of reliable neuroimaging markers for diagnosis and prognosis in mood disorders and for neurosurgical treatment planning for deep brain stimulation (DBS). We then present data on the use of neuroimaging for the diagnosis and prognosis of mood disorders and for DBS treatment planning. We demonstrate how multivariate analyses of functional activation and connectivity parameters can be used to differentiate patients with bipolar disorder from those with major depressive disorder and non-affective psychosis. We also present data on connectivity parameters that mediate acute treatment response in affective and non-affective psychosis. We then focus on precision mapping of functional connectivity in native space. We describe the benefits of integrating anatomical fiber reconstruction with brain functional parameters and cortical surface measures to derive anatomically informed connectivity metrics within the morphological context of each individual brain. We discuss how this approach may be particularly promising in psychiatry, given the clinical and etiological heterogeneity of the disorders, and particularly in treatment response prediction and planning. Precision mapping of connectivity is essential for DBS. In DBS, treatment electrodes are inserted into positions near key gray matter nodes within the circuits considered relevant to disease expression. However, targeting white matter tracts that underpin connectivity within these circuits may increase treatment efficacy and tolerability therefore relevant for effective treatment. We demonstrate how this approach can be validated in the treatment of Parkinson's disease by identifying connectivity patterns that can be used as biomarkers for treatment planning and thus refine the traditional approach of DBS planning that uses only gray matter landmarks. Finally, we describe how this approach could be used in planning DBS treatment of psychiatric disorders. © 2016 O'Halloran, Kopell, Sprooten, Goodman and Frangou.","Deep brain stimulation; Individual variability; Machine learning applied to neuroscience; Multimodal imaging; Precision psychiatry","Article; bipolar disorder; brain depth stimulation; brain function; brain mapping; classifier; functional magnetic resonance imaging; gray matter; human; machine learning; major depression; mental disease; mood disorder; multimodal imaging; nerve cell network; neuroimaging; neuropsychiatric disorder; neurosurgery; nonhuman; nuclear magnetic resonance scanner; Parkinson disease; pattern recognition; prognosis; psychosis; treatment planning","Frontiers Media S.A.","16640640","","","","Article","Scopus","2-s2.0-84975292915"
"Moeskops P.; Viergever M.A.; Mendrik A.M.; De Vries L.S.; Benders M.J.N.L.; Isgum I.","Moeskops, Pim (36572245300); Viergever, Max A. (57203030739); Mendrik, Adrienne M. (16203802900); De Vries, Linda S. (35551564900); Benders, Manon J.N.L. (56030466500); Isgum, Ivana (6507874503)","36572245300; 57203030739; 16203802900; 35551564900; 56030466500; 6507874503","Automatic Segmentation of MR Brain Images with a Convolutional Neural Network","2016","IEEE Transactions on Medical Imaging","703","10.1109/TMI.2016.2548501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968626579&doi=10.1109%2fTMI.2016.2548501&partnerID=40&md5=2c180b8b199c6111de09250cda3ef064","Image Sciences Institute, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands; Department of Neonatology, University Medical Center Utrecht, Utrecht, 3584 EA, Netherlands","Moeskops P., Image Sciences Institute, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands, Department of Neonatology, University Medical Center Utrecht, Utrecht, 3584 EA, Netherlands; Viergever M.A., Image Sciences Institute, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands; Mendrik A.M., Image Sciences Institute, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands; De Vries L.S., Department of Neonatology, University Medical Center Utrecht, Utrecht, 3584 EA, Netherlands; Benders M.J.N.L., Department of Neonatology, University Medical Center Utrecht, Utrecht, 3584 EA, Netherlands; Isgum I., Image Sciences Institute, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands","Automatic segmentation in MR brain images is important for quantitative analysis in large-scale studies with images acquired at all ages. This paper presents a method for the automatic segmentation of MR brain images into a number of tissue classes using a convolutional neural network. To ensure that the method obtains accurate segmentation details as well as spatial consistency, the network uses multiple patch sizes and multiple convolution kernel sizes to acquire multi-scale information about each voxel. The method is not dependent on explicit features, but learns to recognise the information that is important for the classification based on training data. The method requires a single anatomical MR image only. The segmentation method is applied to five different data sets: coronal T2-weighted images of preterm infants acquired at 30 weeks postmenstrual age (PMA) and 40 weeks PMA, axial T2-weighted images of preterm infants acquired at 40 weeks PMA, axial T1-weighted images of ageing adults acquired at an average age of 70 years, and T1-weighted images of young adults acquired at an average age of 23 years. The method obtained the following average Dice coefficients over all segmented tissue classes for each data set, respectively: 0.87, 0.82, 0.84, 0.86, and 0.91. The results demonstrate that the method obtains accurate segmentations in all five sets, and hence demonstrates its robustness to differences in age and acquisition protocol. © 1982-2012 IEEE.","Adult brain; automatic image segmentation; convolutional neural networks; deep learning; MRI; preterm neonatal brain","Adult; Aged; Brain; Humans; Image Processing, Computer-Assisted; Infant, Newborn; Infant, Premature; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Young Adult; Brain mapping; Classification (of information); Convolution; Image acquisition; Magnetic resonance imaging; Neural networks; Tissue; Tissue engineering; Acquisition protocols; Adult brain; Automatic image segmentation; Automatic segmentations; Convolutional neural network; Deep learning; Multi-scale informations; Multiple convolution; adult; aged; aging; anatomical variation; Article; artificial neural network; automation; basal ganglion; brain cortex; brain stem; cerebellum; cerebrospinal fluid; convolutional neural network; gray matter; human; image processing; infant; kernel method; major clinical study; neuroanatomy; neuroimaging; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; prematurity; thalamus; voxel based morphometry; white matter; young adult; brain; diagnostic imaging; machine learning; newborn; nuclear magnetic resonance imaging; procedures; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","27046893","Article","Scopus","2-s2.0-84968626579"
"Xu J.; Xiang L.; Liu Q.; Gilmore H.; Wu J.; Tang J.; Madabhushi A.","Xu, Jun (57191409730); Xiang, Lei (56596140700); Liu, Qingshan (36063739200); Gilmore, Hannah (16039479600); Wu, Jianzhong (36097296700); Tang, Jinghai (57145296400); Madabhushi, Anant (6603019206)","57191409730; 56596140700; 36063739200; 16039479600; 36097296700; 57145296400; 6603019206","Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images","2016","IEEE Transactions on Medical Imaging","704","10.1109/TMI.2015.2458702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959375736&doi=10.1109%2fTMI.2015.2458702&partnerID=40&md5=35dc69d9f76155378ac6f8be203a2291","Jiangsu Key Laboratory of Big Data Analysis Technique and CICAEET, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Department of Pathology-Anatomic, University Hospitals Case Medical Center, Case Western Reserve University, 44106-7207, OH, United States; Jiangsu Cancer Hospital, Nanjing, 210000, China; Department of Biomedical Engineering, Case Western Reserve University, 44106-7207, OH, United States","Xu J., Jiangsu Key Laboratory of Big Data Analysis Technique and CICAEET, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Xiang L., Jiangsu Key Laboratory of Big Data Analysis Technique and CICAEET, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Liu Q., Jiangsu Key Laboratory of Big Data Analysis Technique and CICAEET, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Gilmore H., Department of Pathology-Anatomic, University Hospitals Case Medical Center, Case Western Reserve University, 44106-7207, OH, United States; Wu J., Jiangsu Cancer Hospital, Nanjing, 210000, China; Tang J., Jiangsu Cancer Hospital, Nanjing, 210000, China; Madabhushi A., Department of Biomedical Engineering, Case Western Reserve University, 44106-7207, OH, United States","Automated nuclear detection is a critical step for a number of computer assisted pathology related image analysis algorithms such as for automated grading of breast cancer tissue specimens. The Nottingham Histologic Score system is highly correlated with the shape and appearance of breast cancer nuclei in histopathological images. However, automated nucleus detection is complicated by 1) the large number of nuclei and the size of high resolution digitized pathology images, and 2) the variability in size, shape, appearance, and texture of the individual nuclei. Recently there has been interest in the application of ""Deep Learning"" strategies for classification and analysis of big image data. Histopathology, given its size and complexity, represents an excellent use case for application of deep learning strategies. In this paper, a Stacked Sparse Autoencoder (SSAE), an instance of a deep learning strategy, is presented for efficient nuclei detection on high-resolution histopathological images of breast cancer. The SSAE learns high-level features from just pixel intensities alone in order to identify distinguishing features of nuclei. A sliding window operation is applied to each image in order to represent image patches via high-level features obtained via the auto-encoder, which are then subsequently fed to a classifier which categorizes each image patch as nuclear or non-nuclear. Across a cohort of 500 histopathological images (2200 × 2200) and approximately 3500 manually segmented individual nuclei serving as the groundtruth, SSAE was shown to have an improved F-measure 84.49% and an average area under Precision-Recall curve (AveP) 78.83%. The SSAE approach also out-performed nine other state of the art nuclear detection strategies. © 2015 IEEE.","Automated nuclei detection; Breast cancer histopathology; Deep learning; Digital pathology; Feature representation learning; Stacked sparse autoencoder","Algorithms; Breast Neoplasms; Cell Nucleus; Female; Histocytochemistry; Humans; Image Processing, Computer-Assisted; Machine Learning; Algorithms; Automation; Computer aided analysis; Diseases; Grading; Image analysis; Learning systems; Pathology; Auto encoders; Breast Cancer; Deep learning; Digital pathologies; Feature representation; Nuclei detections; Article; breast cancer; cell nucleus; classifier; controlled study; decision support system; estrogen receptor positive breast cancer; histopathology; human; image analysis; learning algorithm; machine learning; stacked sparse autoencoder; algorithm; breast tumor; cytochemistry; female; image processing; pathology; procedures; Medical imaging","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26208307","Article","Scopus","2-s2.0-84959375736"
"Tajbakhsh N.; Shin J.Y.; Gurudu S.R.; Hurst R.T.; Kendall C.B.; Gotway M.B.; Liang J.","Tajbakhsh, Nima (25655631900); Shin, Jae Y. (57189294786); Gurudu, Suryakanth R. (6506671818); Hurst, R. Todd (12776934900); Kendall, Christopher B. (16686198300); Gotway, Michael B. (7006288965); Liang, Jianming (7404541897)","25655631900; 57189294786; 6506671818; 12776934900; 16686198300; 7006288965; 7404541897","Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?","2016","IEEE Transactions on Medical Imaging","2166","10.1109/TMI.2016.2535302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968649810&doi=10.1109%2fTMI.2016.2535302&partnerID=40&md5=a598f79d5bc6831ccc3d98495acfa8f2","Department of Biomedical Informatics, Arizona State University, Scottsdale, 85259, AZ, United States; Division of Gastroenterology and Hepatology, Mayo Clinic, Scottsdale, 85259, AZ, United States; Division of Cardiovascular Diseases, Mayo Clinic, Scottsdale, 85259, AZ, United States; Department of Radiology, Mayo Clinic, Scottsdale, 85259, AZ, United States","Tajbakhsh N., Department of Biomedical Informatics, Arizona State University, Scottsdale, 85259, AZ, United States; Shin J.Y., Department of Biomedical Informatics, Arizona State University, Scottsdale, 85259, AZ, United States; Gurudu S.R., Division of Gastroenterology and Hepatology, Mayo Clinic, Scottsdale, 85259, AZ, United States; Hurst R.T., Division of Cardiovascular Diseases, Mayo Clinic, Scottsdale, 85259, AZ, United States; Kendall C.B., Division of Cardiovascular Diseases, Mayo Clinic, Scottsdale, 85259, AZ, United States; Gotway M.B., Department of Radiology, Mayo Clinic, Scottsdale, 85259, AZ, United States; Liang J., Department of Biomedical Informatics, Arizona State University, Scottsdale, 85259, AZ, United States","Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data. © 1982-2012 IEEE.","Carotid intima-media thickness; computer-aided detection; convolutional neural networks; deep learning; fine-tuning; medical image analysis; polyp detection; pulmonary embolism detection; video quality assessment","Colonic Polyps; Colonoscopy; Computed Tomography Angiography; Diagnostic Imaging; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Neural Networks (Computer); Pulmonary Embolism; ROC Curve; Computer aided analysis; Computer aided instruction; Convolution; Image analysis; Image segmentation; Knowledge management; Neural networks; Quality control; Carotid intima-media thickness; Computer aided detection; Convolutional neural network; Deep learning; Fine tuning; Polyp detection; Pulmonary embolism; Video quality assessment; arterial wall thickness; Article; artificial neural network; colon polyp; colonoscopy; computer assisted tomography; convolutional neural network; convolutional neural network trained from scratch; diagnostic imaging; echography; human; image analysis; image quality; lung angiography; lung embolism; pre trained convolutional neural network fined tuned; quality control; colon polyp; computed tomographic angiography; computer assisted diagnosis; lung embolism; machine learning; receiver operating characteristic; Medical imaging","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26978662","Article","Scopus","2-s2.0-84968649810"
"Costa L.; Gago M.F.; Yelshyna D.; Ferreira J.; Silva H.D.; Rocha L.; Sousa N.; Bicho E.","Costa, Luís (57212626613); Gago, Miguel F. (14421192400); Yelshyna, Darya (56669855300); Ferreira, Jaime (56348935500); Silva, Hélder David (56669336200); Rocha, Luís (7102199523); Sousa, Nuno (7003438440); Bicho, Estela (6602434613)","57212626613; 14421192400; 56669855300; 56348935500; 56669336200; 7102199523; 7003438440; 6602434613","Application of Machine Learning in Postural Control Kinematics for the Diagnosis of Alzheimer's Disease","2016","Computational Intelligence and Neuroscience","38","10.1155/2016/3891253","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008951537&doi=10.1155%2f2016%2f3891253&partnerID=40&md5=707a762dc49244922474537c51472525","Algoritmi Center, Department of Industrial Electronics, School of Engineering, University of Minho, Braga, Portugal; Neurology Department, Hospital da Senhora da Oliveira, Guimarães, Portugal; Life and Health Sciences Research Institute (ICVS), School of Health Sciences, University of Minho, Braga, Portugal; ICVS-3B's-PT Government Assoc. Lab., Braga, Portugal","Costa L., Algoritmi Center, Department of Industrial Electronics, School of Engineering, University of Minho, Braga, Portugal; Gago M.F., Neurology Department, Hospital da Senhora da Oliveira, Guimarães, Portugal, Life and Health Sciences Research Institute (ICVS), School of Health Sciences, University of Minho, Braga, Portugal; Yelshyna D., Algoritmi Center, Department of Industrial Electronics, School of Engineering, University of Minho, Braga, Portugal; Ferreira J., Algoritmi Center, Department of Industrial Electronics, School of Engineering, University of Minho, Braga, Portugal; Silva H.D., Algoritmi Center, Department of Industrial Electronics, School of Engineering, University of Minho, Braga, Portugal; Rocha L., Algoritmi Center, Department of Industrial Electronics, School of Engineering, University of Minho, Braga, Portugal; Sousa N., Life and Health Sciences Research Institute (ICVS), School of Health Sciences, University of Minho, Braga, Portugal, ICVS-3B's-PT Government Assoc. Lab., Braga, Portugal; Bicho E., Algoritmi Center, Department of Industrial Electronics, School of Engineering, University of Minho, Braga, Portugal","The use of wearable devices to study gait and postural control is a growing field on neurodegenerative disorders such as Alzheimer's disease (AD). In this paper, we investigate if machine-learning classifiers offer the discriminative power for the diagnosis of AD based on postural control kinematics. We compared Support Vector Machines (SVMs), Multiple Layer Perceptrons (MLPs), Radial Basis Function Neural Networks (RBNs), and Deep Belief Networks (DBNs) on 72 participants (36 AD patients and 36 healthy subjects) exposed to seven increasingly difficult postural tasks. The decisional space was composed of 18 kinematic variables (adjusted for age, education, height, and weight), with or without neuropsychological evaluation (Montreal cognitive assessment (MoCA) score), top ranked in an error incremental analysis. Classification results were based on threefold cross validation of 50 independent and randomized runs sets: training (50%), test (40%), and validation (10%). Having a decisional space relying solely on postural kinematics, accuracy of AD diagnosis ranged from 71.7 to 86.1%. Adding the MoCA variable, the accuracy ranged between 91 and 96.6%. MLP classifier achieved top performance in both decisional spaces. Having comprehended the interdynamic interaction between postural stability and cognitive performance, our results endorse machine-learning models as a useful tool for computer-aided diagnosis of AD based on postural control kinematics. © 2016 Luís Costa et al.","","Aged; Aged, 80 and over; Alzheimer Disease; Biomechanical Phenomena; Diagnosis, Computer-Assisted; Female; Humans; Machine Learning; Male; Neural Networks (Computer); Postural Balance; Posture; Psychiatric Status Rating Scales; Sensitivity and Specificity; Artificial intelligence; Computer aided diagnosis; Computer aided instruction; Diagnosis; Disease control; Kinematics; Learning systems; Radial basis function networks; Support vector machines; Classification results; Cognitive assessments; Cognitive performance; Discriminative power; Machine learning models; Neurodegenerative disorders; Radial basis function neural networks; Support vector machine (SVMs); aged; Alzheimer disease; artificial neural network; biomechanics; body equilibrium; body posture; complication; computer assisted diagnosis; female; human; machine learning; male; physiology; psychological rating scale; sensitivity and specificity; very elderly; Neurodegenerative diseases","Hindawi Publishing Corporation","16875265","","","28074090","Article","Scopus","2-s2.0-85008951537"
"Goodwin T.R.; Harabagiu S.M.","Goodwin, Travis R. (55585524800); Harabagiu, Sanda M. (6601915885)","55585524800; 6601915885","Multi-modal Patient Cohort Identification from EEG Report and Signal Data","2016","AMIA ... Annual Symposium proceedings. AMIA Symposium","15","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028288690&partnerID=40&md5=2d83ca3808c14a5779210494a0c4d244","University of Texas at Dallas, Richardson, TX, United States","Goodwin T.R., University of Texas at Dallas, Richardson, TX, United States; Harabagiu S.M., University of Texas at Dallas, Richardson, TX, United States","Clinical electroencephalography (EEG) is the most important investigation in the diagnosis and management of epilepsies. An EEG records the electrical activity along the scalp and measures spontaneous electrical activity of the brain. Because the EEG signal is complex, its interpretation is known to produce moderate inter-observer agreement among neurologists. This problem can be addressed by providing clinical experts with the ability to automatically retrieve similar EEG signals and EEG reports through a patient cohort retrieval system operating on a vast archive of EEG data. In this paper, we present a multi-modal EEG patient cohort retrieval system called MERCuRY which leverages the heterogeneous nature of EEG data by processing both the clinical narratives from EEG reports as well as the raw electrode potentials derived from the recorded EEG signal data. At the core of MERCuRY is a novel multimodal clinical indexing scheme which relies on EEG data representations obtained through deep learning. The index is used by two clinical relevance models that we have generated for identifying patient cohorts satisfying the inclusion and exclusion criteria expressed in natural language queries. Evaluations of the MERCuRY system measured the relevance of the patient cohorts, obtaining MAP scores of 69.87% and a NDCG of 83.21%.","","Abstracting and Indexing as Topic; Electrodes; Electroencephalography; Epilepsy; Humans; Information Storage and Retrieval; Information Systems; Machine Learning; Natural Language Processing; Neural Networks (Computer); artificial neural network; documentation; electrode; electroencephalography; epilepsy; human; information retrieval; information system; machine learning; natural language processing; pathophysiology","","1942597X","","","28269938","Article","Scopus","2-s2.0-85028288690"
"Kraus O.Z.; Ba J.L.; Frey B.J.","Kraus, Oren Z. (56858495300); Ba, Jimmy Lei (57189090730); Frey, Brendan J. (35459307900)","56858495300; 57189090730; 35459307900","Classifying and segmenting microscopy images with deep multiple instance learning","2016","Bioinformatics","306","10.1093/bioinformatics/btw252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976510674&doi=10.1093%2fbioinformatics%2fbtw252&partnerID=40&md5=fe1fcb51792d2e99fc0228b0e10691e3","Department of Electrical and Computer Engineering, University of Toronto, Toronto, M5S 2E4, Canada; Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, Toronto, M5S 3E1, Canada","Kraus O.Z., Department of Electrical and Computer Engineering, University of Toronto, Toronto, M5S 2E4, Canada, Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, Toronto, M5S 3E1, Canada; Ba J.L., Department of Electrical and Computer Engineering, University of Toronto, Toronto, M5S 2E4, Canada; Frey B.J., Department of Electrical and Computer Engineering, University of Toronto, Toronto, M5S 2E4, Canada, Donnelly Centre for Cellular and Biomolecular Research, University of Toronto, Toronto, M5S 3E1, Canada","Motivation: High-content screening (HCS) technologies have enabled large scale imaging experiments for studying cell biology and for drug screening. These systems produce hundreds of thousands of microscopy images per day and their utility depends on automated image analysis. Recently, deep learning approaches that learn feature representations directly from pixel intensity values have dominated object recognition challenges. These tasks typically have a single centered object per image and existing models are not directly applicable to microscopy datasets. Here we develop an approach that combines deep convolutional neural networks (CNNs) with multiple instance learning (MIL) in order to classify and segment microscopy images using only whole image level annotations. Results: We introduce a new neural network architecture that uses MIL to simultaneously classify and segment microscopy images with populations of cells. We base our approach on the similarity between the aggregation function used in MIL and pooling layers used in CNNs. To facilitate aggregating across large numbers of instances in CNN feature maps we present the Noisy-AND pooling function, a new MIL operator that is robust to outliers. Combining CNNs with MIL enables training CNNs using whole microscopy images with image level labels. We show that training end-to-end MIL CNNs outperforms several previous methods on both mammalian and yeast datasets without requiring any segmentation steps. © 2016 The Author 2016. Published by Oxford University Press.","","Algorithms; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Microscopy; Neural Networks (Computer); Yeasts; algorithm; artificial neural network; computer assisted diagnosis; cytology; human; machine learning; microscopy; yeast","Oxford University Press","13674803","","BOINF","27307644","Article","Scopus","2-s2.0-84976510674"
"Tissera M.D.; McDonnell M.D.","Tissera, Migel D. (56352088600); McDonnell, Mark D. (7102564709)","56352088600; 7102564709","Deep extreme learning machines: Supervised autoencoding architecture for classification","2016","Neurocomputing","98","10.1016/j.neucom.2015.03.110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940703890&doi=10.1016%2fj.neucom.2015.03.110&partnerID=40&md5=f203f85482a53880d20a4805cdbf04f6","Computational and Theoretical Neuroscience Laboratory, Institute for Telecommunications Research, School of Information Technology and Mathematical Sciences, University of South Australia, Mawson Lakes, 5095, SA, Australia","Tissera M.D., Computational and Theoretical Neuroscience Laboratory, Institute for Telecommunications Research, School of Information Technology and Mathematical Sciences, University of South Australia, Mawson Lakes, 5095, SA, Australia; McDonnell M.D., Computational and Theoretical Neuroscience Laboratory, Institute for Telecommunications Research, School of Information Technology and Mathematical Sciences, University of South Australia, Mawson Lakes, 5095, SA, Australia","We present a method for synthesising deep neural networks using Extreme Learning Machines (ELMs) as a stack of supervised autoencoders. We test the method using standard benchmark datasets for multi-class image classification (MNIST, CIFAR-10 and Google Streetview House Numbers (SVHN)), and show that the classification error rate can progressively improve with the inclusion of additional autoencoding ELM modules in a stack. Moreover, we found that the method can correctly classify up to 99.19% of MNIST test images, which surpasses the best error rates reported for standard 3-layer ELMs or previous deep ELM approaches when applied to MNIST. The approach simultaneously offers a significantly faster training algorithm to achieve its best performance (in the order of 5 min on a four-core CPU for MNIST) relative to a single ELM with the same total number of hidden units as the deep ELM, hence offering the best of both worlds: lower error rates and fast implementation. © 2015 Elsevier B.V.","Autoencoder; Classifier; Deep neural network; Extreme learning machine; MNIST; Supervised learning","Classification (of information); Classifiers; Errors; Knowledge acquisition; Learning systems; Supervised learning; Auto encoders; Benchmark datasets; Classification error rate; Deep neural networks; Extreme learning machine; Fast implementation; MNIST; Training algorithms; algorithm; analytical error; Article; artificial neural network; autoencoding; classification; extreme learning machine; image processing; information processing; multiclass image classification; priority journal; Image classification","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84940703890"
"Andreu-Perez J.; Leff D.R.; Shetty K.; Darzi A.; Yang G.-Z.","Andreu-Perez, Javier (55653526300); Leff, Daniel Richard (16039709600); Shetty, Kunal (55652725600); Darzi, Ara (14633357600); Yang, Guang-Zhong (55539304100)","55653526300; 16039709600; 55652725600; 14633357600; 55539304100","Disparity in Frontal Lobe Connectivity on a Complex Bimanual Motor Task Aids in Classification of Operator Skill Level","2016","Brain Connectivity","29","10.1089/brain.2015.0350","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006210791&doi=10.1089%2fbrain.2015.0350&partnerID=40&md5=7e2afb0b64c667c8550a308151c49ce8","Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom","Andreu-Perez J., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Leff D.R., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Shetty K., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Darzi A., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom; Yang G.-Z., Hamlyn Centre, Imperial College London, London, SW7 2AZ, United Kingdom","Objective metrics of technical performance (e.g., dexterity, time, and path length) are insufficient to fully characterize operator skill level, which may be encoded deep within neural function. Unlike reports that capture plasticity across days or weeks, this articles studies long-term plasticity in functional connectivity that occurs over years of professional task practice. Optical neuroimaging data are acquired from professional surgeons of varying experience on a complex bimanual coordination task with the aim of investigating learning-related disparity in frontal lobe functional connectivity that arises as a consequence of motor skill level. The results suggest that prefrontal and premotor seed connectivity is more critical during naïve versus expert performance. Given learning-related differences in connectivity, a least-squares support vector machine with a radial basis function kernel is employed to evaluate skill level using connectivity data. The results demonstrate discrimination of operator skill level with accuracy ≥0.82 and Multiclass Matthew's Correlation Coefficient ≥0.70. Furthermore, these indices are improved when local (i.e., within-region) rather than inter-regional (i.e., between-region) frontal connectivity is considered (p = 0.002). The results suggest that it is possible to classify operator skill level with good accuracy from functional connectivity data, upon which objective assessment and neurofeedback may be used to improve operator performance during technical skill training. Copyright © 2016 Mary Ann Liebert, Inc.","functional connectivity; functional near-infrared spectroscopy (fNIRS); motor learning; operator skill level; optical topography; technical skill levels assessment","Adult; Algorithms; Brain Mapping; Connectome; Frontal Lobe; Functional Neuroimaging; Humans; Learning; Male; Middle Aged; Motor Skills; Neural Pathways; Neuronal Plasticity; Spectroscopy, Near-Infrared; Support Vector Machine; hemoglobin; recombinant erythropoietin; adult; Article; bimanual motor task aid; brain function; clinical assessment; clinical evaluation; clinical practice; comparative study; connectome; controlled study; correlation coefficient; fluorescence imaging; frontal lobe; human; laparoscopic surgery; learning; matthew correlation coefficient; motor coordination; motor performance; nerve cell plasticity; neurofeedback; neuroimaging; operator skill; optical topography; personal experience; premotor cortex; priority journal; support vector machine; suturing method; task performance; topography; algorithm; brain mapping; classification; frontal lobe; functional neuroimaging; male; middle aged; motor performance; near infrared spectroscopy; nerve tract; physiology; procedures; statistics and numerical data","Mary Ann Liebert Inc.","21580014","","","26899241","Article","Scopus","2-s2.0-85006210791"
"Agostinelli F.; Ceglia N.; Shahbaba B.; Sassone-Corsi P.; Baldi P.","Agostinelli, Forest (56122754500); Ceglia, Nicholas (56047223700); Shahbaba, Babak (15045771700); Sassone-Corsi, Paolo (7102287937); Baldi, Pierre (7101759672)","56122754500; 56047223700; 15045771700; 7102287937; 7101759672","What time is it? Deep learning approaches for circadian rhythms","2016","Bioinformatics","59","10.1093/bioinformatics/btw243","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976476472&doi=10.1093%2fbioinformatics%2fbtw243&partnerID=40&md5=4a933bed0c5a20048e6b71f5b6024acc","Department of Computer Science, University of California-Irvine, Irvine, 92697, CA, United States; Department of Statistics, University of California-Irvine, Irvine, 92697, CA, United States; Department of Biological Chemistry, University of California-Irvine, Irvine, 92697, CA, United States","Agostinelli F., Department of Computer Science, University of California-Irvine, Irvine, 92697, CA, United States; Ceglia N., Department of Computer Science, University of California-Irvine, Irvine, 92697, CA, United States; Shahbaba B., Department of Statistics, University of California-Irvine, Irvine, 92697, CA, United States; Sassone-Corsi P., Department of Biological Chemistry, University of California-Irvine, Irvine, 92697, CA, United States; Baldi P., Department of Computer Science, University of California-Irvine, Irvine, 92697, CA, United States, Department of Biological Chemistry, University of California-Irvine, Irvine, 92697, CA, United States","Motivation: Circadian rhythms date back to the origins of life, are found in virtually every species and every cell, and play fundamental roles in functions ranging from metabolism to cognition. Modern high-throughput technologies allow the measurement of concentrations of transcripts, metabolites and other species along the circadian cycle creating novel computational challenges and opportunities, including the problems of inferring whether a given species oscillate in circadian fashion or not, and inferring the time at which a set of measurements was taken. Results: We first curate several large synthetic and biological time series datasets containing labels for both periodic and aperiodic signals. We then use deep learning methods to develop and train BIO-CYCLE, a system to robustly estimate which signals are periodic in high-throughput circadian experiments, producing estimates of amplitudes, periods, phases, as well as several statistical significance measures. Using the curated data, BIO-CYCLE is compared to other approaches and shown to achieve state-of-the-art performance across multiple metrics. We then use deep learning methods to develop and train BIO-CLOCK to robustly estimate the time at which a particular single-time-point transcriptomic experiment was carried. In most cases, BIO-CLOCK can reliably predict time, within approximately 1 h, using the expression levels of only a small number of core clock genes. BIO-CLOCK is shown to work reasonably well across tissue types, and often with only small degradation across conditions. BIO-CLOCK is used to annotate most mouse experiments found in the GEO database with an inferred time stamp. © 2016 The Author 2016. Published by Oxford University Press.","","Animals; Circadian Clocks; Circadian Rhythm; Computational Biology; Machine Learning; Mice; Software; Transcriptome; transcriptome; animal; biology; circadian rhythm; machine learning; mouse; procedures; software","Oxford University Press","13674803","","BOINF","27307647","Article","Scopus","2-s2.0-84976476472"
"Baumgarten C.; Zhao Y.; Sauleau P.; Malrain C.; Jannin P.; Haegelen C.","Baumgarten, Clement (57190658884); Zhao, Yulong (57190675224); Sauleau, Paul (25522717800); Malrain, Cecile (56089510300); Jannin, Pierre (57203216789); Haegelen, Claire (24168358600)","57190658884; 57190675224; 25522717800; 56089510300; 57203216789; 24168358600","Image-guided preoperative prediction of pyramidal tract side effect in deep brain stimulation: Proof of concept and application to the pyramidal tract side effect induced by pallidal stimulation","2016","Journal of Medical Imaging","11","10.1117/1.JMI.3.2.025001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991519760&doi=10.1117%2f1.JMI.3.2.025001&partnerID=40&md5=f55001a9bab8f125001a5288438616da","French Institute of Health and Medical Research, UMR 1099, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France; University of Rennes 1, Treatment of Signal and Imaging Laboratory, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France; Rennes University Hospital, Department of Neurology, 2 rue Henri Le Guilloux, Rennes Cedex 9, 35033, France; Rennes University Hospital, Department of Neurosurgery, 2 rue Henri Le Guilloux, Rennes Cedex 9, 35033, France","Baumgarten C., French Institute of Health and Medical Research, UMR 1099, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France, University of Rennes 1, Treatment of Signal and Imaging Laboratory, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France; Zhao Y., French Institute of Health and Medical Research, UMR 1099, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France, University of Rennes 1, Treatment of Signal and Imaging Laboratory, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France; Sauleau P., Rennes University Hospital, Department of Neurology, 2 rue Henri Le Guilloux, Rennes Cedex 9, 35033, France; Malrain C., Rennes University Hospital, Department of Neurology, 2 rue Henri Le Guilloux, Rennes Cedex 9, 35033, France; Jannin P., French Institute of Health and Medical Research, UMR 1099, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France, University of Rennes 1, Treatment of Signal and Imaging Laboratory, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France; Haegelen C., French Institute of Health and Medical Research, UMR 1099, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France, University of Rennes 1, Treatment of Signal and Imaging Laboratory, 2 avenue du Pr. Léon Bernard, Rennes Cedex, 35043, France, Rennes University Hospital, Department of Neurosurgery, 2 rue Henri Le Guilloux, Rennes Cedex 9, 35033, France","Deep brain stimulation of the medial globus pallidus (GPm) is a surgical procedure for treating patients suffering from Parkinson's disease. Its therapeutic effect may be limited by the presence of pyramidal tract side effect (PTSE). PTSE is a contraction time-locked to the stimulation when the current spreading reaches the motor fibers of the pyramidal tract within the internal capsule. The objective of the study was to propose a preoperative predictive model of PTSE. A machine learning-based method called PyMAN (PTSE model based on artificial neural network) accounting for the current used in stimulation, the three-dimensional electrode coordinates and the angle of the trajectory, was designed to predict the occurrence of PTSE. Ten patients implanted in the GPm have been tested by a clinician to create a labeled dataset of the stimulation parameters that trigger PTSE. The kappa index value between the data predicted by PyMAN and the labeled data was 0.78. Further evaluation studies are desirable to confirm whether PyMAN could be a reliable tool for assisting the surgeon to prevent PTSE during the preoperative planning. © 2016 Society of Photo-Optical Instrumentation Engineers (SPIE).","artificial neural network; computational modeling; computer-assisted surgery; deep brain stimulation; Parkinson's disease; patient-specific model; pyramidal tract side effect","antiparkinson agent; gadolinium; adult; aged; Article; brain depth stimulation; central nervous system disease; cerebellar stimulator; clinical article; clinical trial; computed tomography scanner; computer assisted tomography; diagnostic test accuracy study; electrode implant; female; globus pallidus; human; implantable pulse generator; machine learning; male; medial globus pallidus; middle aged; neuroimaging; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; Parkinson disease; predictive value; preoperative evaluation; programmable pulse generator; prospective study; pyramidal tract; pyramidal tract side effect; pyramidal tract side effect model based on artificial neural network; side effect; validation study","SPIE","23294302","","","","Article","Scopus","2-s2.0-84991519760"
"Ordóñez F.J.; Roggen D.","Ordóñez, Francisco Javier (25641939300); Roggen, Daniel (23478266100)","25641939300; 23478266100","Deep convolutional and LSTM recurrent neural networks for multimodal wearable activity recognition","2016","Sensors (Switzerland)","1795","10.3390/s16010115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955143444&doi=10.3390%2fs16010115&partnerID=40&md5=c79d5a30bdb8d0ff8b159712e3c3cc03","Wearable Technologies, Sensor Technology Research Centre, University of Sussex, Brighton, BN1 9RH, United Kingdom","Ordóñez F.J., Wearable Technologies, Sensor Technology Research Centre, University of Sussex, Brighton, BN1 9RH, United Kingdom; Roggen D., Wearable Technologies, Sensor Technology Research Centre, University of Sussex, Brighton, BN1 9RH, United Kingdom","Human activity recognition (HAR) tasks have traditionally been solved using engineered features obtained by heuristic processes. Current research suggests that deep convolutional neural networks are suited to automate feature extraction from raw sensor inputs. However, human activities are made of complex sequences of motor movements, and capturing this temporal dynamics is fundamental for successful HAR. Based on the recent success of recurrent neural networks for time series domains, we propose a generic deep framework for activity recognition based on convolutional and LSTM recurrent units, which: (i) is suitable for multimodal wearable sensors; (ii) can perform sensor fusion naturally; (iii) does not require expert knowledge in designing features; and (iv) explicitly models the temporal dynamics of feature activations. We evaluate our framework on two datasets, one of which has been used in a public activity recognition challenge. Our results show that our framework outperforms competing deep non-recurrent networks on the challenge dataset by 4% on average; outperforming some of the previous reported results by up to 9%. Our results show that the framework can be applied to homogeneous sensor modalities, but can also fuse multimodal sensors to improve performance. We characterise key architectural hyperparameters’ influence on performance to provide insights about their optimisation. © 2016 by the authors; licensee MDPI, Basel, Switzerland.","Deep learning; Human activity recognition; LSTM; Machine learning; Neural network; Sensor fusion; Wearable sensors","Clothing; Databases, Factual; Human Activities; Humans; Machine Learning; Monitoring, Ambulatory; Neural Networks (Computer); Signal Processing, Computer-Assisted; Artificial intelligence; Complex networks; Convolution; Feature extraction; Learning systems; Neural networks; Pattern recognition; Recurrent neural networks; Wearable technology; Activity recognition; Convolutional neural network; Deep learning; Human activity recognition; Improve performance; LSTM; Recurrent networks; Sensor fusion; ambulatory monitoring; artificial neural network; classification; clothing; factual database; human; human activities; machine learning; procedures; signal processing; Wearable sensors","MDPI AG","14248220","","","26797612","Article","Scopus","2-s2.0-84955143444"
"Manor R.; Geva A.B.","Manor, Ran (56288663400); Geva, Amir B. (56230683700)","56288663400; 56230683700","Convolutional neural network for multi-category rapid serial visual presentation BCI","2015","Frontiers in Computational Neuroscience","111","10.3389/fncom.2015.00146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955277986&doi=10.3389%2ffncom.2015.00146&partnerID=40&md5=7fdb3f4a5a90eac92213000022925b81","Department of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer-Sheva, Israel","Manor R., Department of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer-Sheva, Israel; Geva A.B., Department of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer-Sheva, Israel","Brain computer interfaces rely on machine learning (ML) algorithms to decode the brain's electrical activity into decisions. For example, in rapid serial visual presentation (RSVP) tasks, the subject is presented with a continuous stream of images containing rare target images among standard images, while the algorithm has to detect brain activity associated with target images. Here, we continue our previous work, presenting a deep neural network model for the use of single trial EEG classification in RSVP tasks. Deep neural networks have shown state of the art performance in computer vision and speech recognition and thus have great promise for other learning tasks, like classification of EEG samples. In our model, we introduce a novel spatio-temporal regularization for EEG data to reduce overfitting. We show improved classification performance compared to our earlier work on a five categories RSVP experiment. In addition, we compare performance on data from different sessions and validate the model on a public benchmark data set of a P300 speller task. Finally, we discuss the advantages of using neural network models compared to manually designing feature extraction algorithms. © 2015 Manor and Geva.","Brain computer interface (BCI); Convolutional neural networks; Deep learning; Electroencephalography (EEG); P300; Rapid serial visual presentation (RSVP)","Algorithms; Artificial intelligence; Benchmarking; Brain; Computer networks; Computer vision; Convolution; Electroencephalography; Electrophysiology; Feature extraction; Interfaces (computer); Learning systems; Neural networks; Speech recognition; Classification performance; Convolutional neural network; Deep learning; Feature extraction algorithms; P300; Rapid serial visual presentations; Spatio-temporal regularizations; State-of-the-art performance; adult; algorithm; Article; artificial neural network; automatic speech recognition; brain computer interface; controlled study; convolutional neural network; electroencephalogram; female; human; human experiment; learning; male; normal human; rapid serial visual presentation; spatiotemporal analysis; stimulus response; task performance; vision; visual stimulation; Brain computer interface","Frontiers Media S.A.","16625188","","","","Article","Scopus","2-s2.0-84955277986"
"Zabalza J.; Ren J.; Zheng J.; Zhao H.; Qing C.; Yang Z.; Du P.; Marshall S.","Zabalza, Jaime (55825361600); Ren, Jinchang (23398632100); Zheng, Jiangbin (7403975791); Zhao, Huimin (55715798100); Qing, Chunmei (24336280700); Yang, Zhijing (24336506200); Du, Peijun (7103064199); Marshall, Stephen (7401823400)","55825361600; 23398632100; 7403975791; 55715798100; 24336280700; 24336506200; 7103064199; 7401823400","Novel segmented stacked autoencoder for effective dimensionality reduction and feature extraction in hyperspectral imaging","2016","Neurocomputing","318","10.1016/j.neucom.2015.11.044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961344134&doi=10.1016%2fj.neucom.2015.11.044&partnerID=40&md5=a7520477269edef3d8b7aaa932be459f","Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, United Kingdom; School of Microelectronics and Software, Northwestern Polytechnical University, Xi'an, China; School of Electronic and Information, Guangdong Technic Normal University, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Information Engineering, Guangdong University of Technology, Guangzhou, China; Dept. of Geographical Information, Nanjing University, Nanjing, China","Zabalza J., Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, United Kingdom; Ren J., Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, United Kingdom; Zheng J., School of Microelectronics and Software, Northwestern Polytechnical University, Xi'an, China; Zhao H., School of Electronic and Information, Guangdong Technic Normal University, Guangzhou, China; Qing C., School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; Yang Z., School of Information Engineering, Guangdong University of Technology, Guangzhou, China; Du P., Dept. of Geographical Information, Nanjing University, Nanjing, China; Marshall S., Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, United Kingdom","Stacked autoencoders (SAEs), as part of the deep learning (DL) framework, have been recently proposed for feature extraction in hyperspectral remote sensing. With the help of hidden nodes in deep layers, a high-level abstraction is achieved for data reduction whilst maintaining the key information of the data. As hidden nodes in SAEs have to deal simultaneously with hundreds of features from hypercubes as inputs, this increases the complexity of the process and leads to limited abstraction and performance. As such, segmented SAE (S-SAE) is proposed by confronting the original features into smaller data segments, which are separately processed by different smaller SAEs. This has resulted in reduced complexity but improved efficacy of data abstraction and accuracy of data classification. © 2016.","Data reduction; Deep learning (DL); Hyperspectral remote sensing; Segmented stacked autoencoder (S-SAE)","Abstracting; Classification (of information); Extraction; Feature extraction; Learning systems; Remote sensing; Spectroscopy; Auto encoders; Data classification; Deep learning; Dimensionality reduction; High-level abstraction; Hyperspectral Imaging; Hyperspectral remote sensing; Reduced complexity; Article; classification algorithm; controlled study; feature extraction; hyperspectral remote sensing; image processing; intermethod comparison; machine learning; measurement accuracy; priority journal; remote sensing; segmented stacked autoencoder; Data reduction","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84961344134"
"Liao Z.; Li D.; Wang X.; Li L.; Zou Q.","Liao, Zhijun (57190954823); Li, Dapeng (57197284289); Wang, Xinrui (57189007200); Li, Lisheng (56026908100); Zou, Quan (23391564900)","57190954823; 57197284289; 57189007200; 56026908100; 23391564900","Cancer diagnosis through isomiR expression with machine learning method","2016","Current Bioinformatics","54","10.2174/1574893611666160609081155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010310543&doi=10.2174%2f1574893611666160609081155&partnerID=40&md5=7b977c4dbf086f0be8dcedcf0b97a212","Department of Biochemistry and Molecular Biology, Fujian Medical University, Fuzhou, China; Department of Internal Medicine-Oncology, The Fourth Hospital in Qinhuangdao, Qinhuangdao, China; School of Computer Science and Technology, Tianjin University, Tianjin, China","Liao Z., Department of Biochemistry and Molecular Biology, Fujian Medical University, Fuzhou, China, School of Computer Science and Technology, Tianjin University, Tianjin, China; Li D., Department of Internal Medicine-Oncology, The Fourth Hospital in Qinhuangdao, Qinhuangdao, China; Wang X., Department of Biochemistry and Molecular Biology, Fujian Medical University, Fuzhou, China; Li L., Department of Biochemistry and Molecular Biology, Fujian Medical University, Fuzhou, China; Zou Q., School of Computer Science and Technology, Tianjin University, Tianjin, China","With advancements in deep sequencing, high microRNA (miRNA) variability has been detected from the same miRNA precursor. For instance, isomiR is an isoform of miRNA, and its sequences vary from those of a reference miRNA. IsomiR exists in four main types formed through the following processes:5′ or 3′ trimming, nucleotide addition, nucleotide removal, and post-transcriptional RNA editing. However, aberrant isomiR expression profiles may contribute to tumorigenesis. As such, different isomiR expression profiles can be used to distinguish cancer and normal cell lines, especially in isomiR-mRNA regulatory networks. Cancer can also be diagnosed through machine learning method based on high-throughput data. In this study, this method was employed to extract the features of isomiR read counts from RNA-SEQ data in TCGA. With a random forest classification algorithm, these features were applied to diagnose six cancer types, namely, breast invasive carcinoma, lung adenocarcinoma, squamous-cell carcinoma of the lung, stomach adenocarcinoma, thyroid carcinoma, and uterine corpus endometrial carcinoma. Compared with the classifier libD3C, our method can be utilized to distinguish cancers from their normal counterparts. Therefore, isomiR can be successfully and effectively used to diagnose cancer. © 2016 Bentham Science Publishers.","Cancer; IsomiR; Machine learning; MicroRNA","microRNA; 3' untranslated region; 5' untranslated region; Article; breast carcinoma; cancer cell line; cancer diagnosis; classification algorithm; endometrium carcinoma; gene expression; human; hydrogen bond; lung adenocarcinoma; machine learning; priority journal; random forest; RNA sequence; sensitivity and specificity; squamous cell lung carcinoma; stomach adenocarcinoma; stomach tissue; thyroid carcinoma","Bentham Science Publishers","15748936","","","","Article","Scopus","2-s2.0-85010310543"
"Peng Z.; Li Y.; Cai Z.; Lin L.","Peng, Zhanglin (56666493200); Li, Ya (55329591800); Cai, Zhaoquan (16237958100); Lin, Liang (15061363400)","56666493200; 55329591800; 16237958100; 15061363400","Deep Boosting: Joint feature selection and analysis dictionary learning in hierarchy","2016","Neurocomputing","12","10.1016/j.neucom.2015.07.116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957435511&doi=10.1016%2fj.neucom.2015.07.116&partnerID=40&md5=da83d2384f98dd0114e6d65cd424a7e5","Sun Yat-sen University, Guangzhou, China; Huizhou University, Huizhou, China","Peng Z., Sun Yat-sen University, Guangzhou, China; Li Y., Sun Yat-sen University, Guangzhou, China; Cai Z., Huizhou University, Huizhou, China; Lin L., Sun Yat-sen University, Guangzhou, China","This work investigates how the traditional image classification pipelines can be extended into a deep architecture, inspired by recent successes of deep neural networks. We propose a deep boosting framework based on layer-by-layer joint feature boosting and dictionary learning. In each layer, we construct a dictionary of filters by combining the filters from the lower layer, and iteratively optimize the image representation with a joint discriminative-generative formulation, i.e. minimization of empirical classification error plus regularization of analysis image generation over training images. For optimization, we perform two iterating steps: (i) to minimize the classification error, select the most discriminative features using the gentle adaboost algorithm; (ii) according to the feature selection, update the filters to minimize the regularization on analysis image representation using the gradient descent method. Once the optimization is converged, we learn the higher layer representation in the same way. Our model delivers several distinct advantages. First, our layer-wise optimization provides the potential to build very deep architectures. Second, the generated image representation is compact and meaningful by jointly considering image classification and generation. In several visual recognition tasks, our framework outperforms existing state-of-the-art approaches. © 2015 Elsevier B.V..","Compositional boosting; Dictionary learning; Image Classification; Representation Learning","Adaptive boosting; Feature extraction; Image analysis; Iterative methods; Network architecture; Optimization; Compositional boosting; Dictionary learning; Discriminative features; Gentle AdaBoost algorithm; Gradient Descent method; Layer wise optimization; Representation Learning; State-of-the-art approach; algorithm; analysis dictionary learning; Article; automated pattern recognition; classifier; deep boosting; image classification; image processing; joint feature selection; machine learning; nerve cell network; priority journal; Image classification","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84957435511"
"Zhan S.; Tao Q.-Q.; Li X.-H.","Zhan, Shu (24765737400); Tao, Qin-Qin (57006190900); Li, Xiao-Hong (57006841900)","24765737400; 57006190900; 57006841900","Face detection using representation learning","2016","Neurocomputing","64","10.1016/j.neucom.2015.07.130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950149115&doi=10.1016%2fj.neucom.2015.07.130&partnerID=40&md5=270a5aa32794be01e449cf1e50de6d8d","Hefei University of Technology, Hefei, China","Zhan S., Hefei University of Technology, Hefei, China; Tao Q.-Q., Hefei University of Technology, Hefei, China; Li X.-H., Hefei University of Technology, Hefei, China","Face representation is a crucial step of face detection system. In this paper, we present a fast face detection algorithm based on representation learnt using convolutional neural network (CNN) so as to explicitly capture various latent facial features. Firstly, in order to improve the speed of detection in the system, we train an Adaboost background filter which can remove the background most quickly. Secondly, we use the CNN to extract more distinctive features for those face and non-face patterns that have not been filtered by Adaboost. CNN can automatically learn and synthesize a problem-specific feature extractor from a training set, without making any assumptions or using any hand-made design concerning the features to extract or the areas of the face pattern to analyze. Finally, support vector machines (SVM) are used to detect instead of using the classification function of CNN itself. Extensive experiments demonstrate the robustness and efficiency of our system by comparing it with several popular face detection algorithms on the widely used CMU+MIT frontal face dataset and FDDB dataset. © 2015 Elsevier B.V.","Adaboost; Convolutional neural network; Deep learning; Face detection; Support vector machine","Adaptive boosting; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Signal detection; Support vector machines; Background filters; Classification functions; Face detection algorithm; Face detection system; Face representations; Facial feature; Feature extractor; Frontal faces; Article; artificial neural network; automation; data analysis; face; face detection; face profile; image analysis; learning algorithm; priority journal; support vector machine; Face recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84950149115"
"Horii T.; Nagai Y.; Asada M.","Horii, Takato (55842337200); Nagai, Yukie (7402580650); Asada, Minoru (55843502400)","55842337200; 7402580650; 55843502400","Imitation of human expressions based on emotion estimation by mental simulation","2016","Paladyn","14","10.1515/pjbr-2016-0004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018418194&doi=10.1515%2fpjbr-2016-0004&partnerID=40&md5=7f943953ce60520ca1acbc19681a701c","Department of Adaptive Machine Systems, Graduate School of Engineering, Osaka University, Osaka, Japan","Horii T., Department of Adaptive Machine Systems, Graduate School of Engineering, Osaka University, Osaka, Japan; Nagai Y., Department of Adaptive Machine Systems, Graduate School of Engineering, Osaka University, Osaka, Japan; Asada M., Department of Adaptive Machine Systems, Graduate School of Engineering, Osaka University, Osaka, Japan","Humans can express their own emotion and estimate the emotional states of others during communication. This paper proposes a unified model that can estimate the emotional states of others and generate emotional self-expressions. The proposed model utilizes a multimodal restricted Boltzmann machine (RBM) - a type of stochastic neural network. RBMs can abstract latent information from input signals and reconstruct the signals from it. We use these two characteristics to rectify issues affecting previously proposed emotion models: constructing an emotional representation for estimation and generation for emotion instead of heuristic features, and actualizing mental simulation to infer the emotion of others from their ambiguous signals. Our experimental results showed that the proposed model can extract features representing the distribution of categories of emotion via self-organized learning. Imitation experiments demonstrated that using our model, a robot can generate expressions better than with a direct mapping mechanism when the expressions of others contain emotional inconsistencies. Moreover, our model can improve the estimated belief in the emotional states of others through the generation of imaginary sensory signals from defective multimodal signals (i.e., mental simulation). These results suggest that these abilities of the proposed model can facilitate emotional human-robot communication in more complex situations. © 2016 Takato Horii et al.","Deep learning; Emotion; Human-robot interaction; Imitation; Mental simulation","Deep learning; Neural networks; Signal reconstruction; Stochastic models; Stochastic systems; Deep learning; Emotion; Emotion estimation; Emotional state; Humans-robot interactions; Imitation; Mental simulation; Multi-modal; Restricted boltzmann machine; Unified Modeling; Human robot interaction","De Gruyter Open Ltd","20814836","","","","Article","Scopus","2-s2.0-85018418194"
"Cong Y.; Wang S.; Fan B.; Yang Y.; Yu H.","Cong, Yang (36852090700); Wang, Shuai (56399663600); Fan, Baojie (35483667900); Yang, Yunsheng (7409389203); Yu, Haibin (8404932700)","36852090700; 56399663600; 35483667900; 7409389203; 8404932700","UDSFS: Unsupervised deep sparse feature selection","2016","Neurocomputing","26","10.1016/j.neucom.2015.10.130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977997053&doi=10.1016%2fj.neucom.2015.10.130&partnerID=40&md5=3b8a6beab55dcdff8436772fbe6e7c06","State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; College of Automation, Nanjing University of Posts and Telecommunications, China; Chinese PLA General Hospital, China","Cong Y., State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, China; Wang S., State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, China, University of Chinese Academy of Sciences, China; Fan B., College of Automation, Nanjing University of Posts and Telecommunications, China; Yang Y., Chinese PLA General Hospital, China; Yu H., State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, China","In this paper, we focus on unsupervised feature selection. As we have known, the combination of several feature units into a whole feature vector is broadly adopted for effective object representation, which may inevitably includes some irrelevant/redundant feature units or feature dimensions. Most of the traditional feature selection models can only select the feature dimensions without concerning the intrinsic relationship among different feature units. By taking into consideration the group sparsity of feature dimensions and feature units based on an ℓ2,1 minimization, we propose a new unsupervised feature selection model, unsupervised deep sparse feature selection (UDSFS) in this paper. In comparison with the state-of-the-arts, our UDSFS model can not only select the most discriminative feature units but also assign proper weight to the useful feature dimensions concurrently; moreover, the efficiency and robustness of our UDSFS can be also improved without extracting the discarded irrelevant feature units. For model optimization, we introduce an efficient iterative algorithm to solve the non-smooth, convex model and obtain a global optimization with the convergence rate as O(1/K2) (K is the iteration number). For the experiments, a new medical endoscopic image dataset, Abnormal Endoscopic Image Detection dataset (AEID), is built for evaluation; we also test our model using two public UCI datasets. Various experiments and comparisons with other state-of-the-arts justified the effectiveness and efficiency of our UDSFS model. © 2016 Elsevier B.V.","Computer aided diagnosis; Deep sparse; Feature selection; Group sparsity; Machine learning","Computer aided diagnosis; Computer aided instruction; Efficiency; Endoscopy; Global optimization; Iterative methods; Learning systems; Medical imaging; Statistical tests; Deep sparse; Discriminative features; Effectiveness and efficiencies; Group sparsities; Iterative algorithm; Model optimization; Object representations; Unsupervised feature selection; algorithm; Article; data base; endoscopy; experimental study; intermethod comparison; mathematical computing; mathematical parameters; priority journal; process optimization; statistical model; statistical parameters; unsupervised deep sparse feature selection; Feature extraction","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84977997053"
"Zhao G.; Wang X.; Niu Y.; Tan L.; Zhang S.-X.","Zhao, Guangjun (57113964400); Wang, Xuchu (36237811600); Niu, Yanmin (8904523800); Tan, Liwen (7402233744); Zhang, Shao-Xiang (25824534800)","57113964400; 36237811600; 8904523800; 7402233744; 25824534800","Segmenting Brain Tissues from Chinese Visible Human Dataset by Deep-Learned Features with Stacked Autoencoder","2016","BioMed Research International","9","10.1155/2016/5284586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958073732&doi=10.1155%2f2016%2f5284586&partnerID=40&md5=3f543db29419e60db54a1a69b0f4befb","Key Laboratory of Optoelectronic Technology and Systems of Ministry of Education, College of Optoelectronic Engineering, Chongqing University, Chongqing, 400044, China; College of Computer and Information Science, Chongqing Normal University, Chongqing, 400050, China; Institute of Digital Medicine, College of Biomedical Engineering, Third Military Medical University, Chongqing, 400038, China","Zhao G., Key Laboratory of Optoelectronic Technology and Systems of Ministry of Education, College of Optoelectronic Engineering, Chongqing University, Chongqing, 400044, China; Wang X., Key Laboratory of Optoelectronic Technology and Systems of Ministry of Education, College of Optoelectronic Engineering, Chongqing University, Chongqing, 400044, China; Niu Y., College of Computer and Information Science, Chongqing Normal University, Chongqing, 400050, China; Tan L., Institute of Digital Medicine, College of Biomedical Engineering, Third Military Medical University, Chongqing, 400038, China; Zhang S.-X., Institute of Digital Medicine, College of Biomedical Engineering, Third Military Medical University, Chongqing, 400038, China","Cryosection brain images in Chinese Visible Human (CVH) dataset contain rich anatomical structure information of tissues because of its high resolution (e.g., 0.167 mm per pixel). Fast and accurate segmentation of these images into white matter, gray matter, and cerebrospinal fluid plays a critical role in analyzing and measuring the anatomical structures of human brain. However, most existing automated segmentation methods are designed for computed tomography or magnetic resonance imaging data, and they may not be applicable for cryosection images due to the imaging difference. In this paper, we propose a supervised learning-based CVH brain tissues segmentation method that uses stacked autoencoder (SAE) to automatically learn the deep feature representations. Specifically, our model includes two successive parts where two three-layer SAEs take image patches as input to learn the complex anatomical feature representation, and then these features are sent to Softmax classifier for inferring the labels. Experimental results validated the effectiveness of our method and showed that it outperformed four other classical brain tissue detection strategies. Furthermore, we reconstructed three-dimensional surfaces of these tissues, which show their potential in exploring the high-resolution anatomical structures of human brain. © 2016 Guangjun Zhao et al.","","Brain; Humans; Image Processing, Computer-Assisted; Supervised Machine Learning; Visible Human Projects; brain tissue; classifier; experimental model; human; learning; model; anatomy and histology; brain; diagnostic imaging; image processing; procedures; supervised machine learning; visible human project","Hindawi Limited","23146133","","","27057543","Article","Scopus","2-s2.0-84958073732"
"Menon D.M.; Radhika N.","Menon, Divya M. (56611469600); Radhika, N. (57205017135)","56611469600; 57205017135","A secure deep belief network architecture for intrusion detection in smart grid home area network","2016","IIOAB Journal","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020130536&partnerID=40&md5=3d597b04aa17d3b5e6072f1c4d93c96f","Department of Computer Science and Engineering, Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Amrita University, Coimbatore, India","Menon D.M., Department of Computer Science and Engineering, Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Amrita University, Coimbatore, India; Radhika N., Department of Computer Science and Engineering, Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Amrita University, Coimbatore, India","The Deployment of Smart Grid requires consideration of all the security parameters in the entire architecture of Smart Grid. Data Security and Communication Security are the major milestones in security that need to be addressed in the present scenario in Smart Grid. In this paper we model a Deep Belief Network to detect the normal and abnormal behaviors in the traffic pattern of Smart Grid data. Deep belief Network has been deployed to identify the anomalies in the Smart Grid data traffic thereby detecting intrusion. Support Vector Machine has been used for intrusion classification after creating the Deep Belief Network Model. Using SVM model with deep belief networks has helped in reduction of data complexity and also in identifying the core features to be considered for the implementation of Intrusion detection in Smart Grid Model. © 2016, Institute of Integrative Omics and Applied Biotechnology. All rights reserved.","Deep belief network intrusion detection; Home area network; Smart grid","Article; classifier; computer network; computer security; data extraction; data processing; deep belief network; intrusion detection; learning algorithm; machine learning; restricted Boltzmann machine; smart grid; support vector machine","Institute of Integrative Omics and Applied Biotechnology","09763104","","","","Article","Scopus","2-s2.0-85020130536"
"Guo Y.; Liu Y.; Oerlemans A.; Lao S.; Wu S.; Lew M.S.","Guo, Yanming (55901264100); Liu, Yu (57110188500); Oerlemans, Ard (23036132300); Lao, Songyang (7004254256); Wu, Song (55925404400); Lew, Michael S. (57208852387)","55901264100; 57110188500; 23036132300; 7004254256; 55925404400; 57208852387","Deep learning for visual understanding: A review","2016","Neurocomputing","1695","10.1016/j.neucom.2015.09.116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957837518&doi=10.1016%2fj.neucom.2015.09.116&partnerID=40&md5=c6b47408f1245c0319b820b3605e577a","LIACS Media Lab, Leiden University, Niels Bohrweg 1, Leiden, Netherlands; VDG Security BV, Zoetermeer, Netherlands; College of Information Systems and Management, National University of Defense Technology, Changsha, China","Guo Y., LIACS Media Lab, Leiden University, Niels Bohrweg 1, Leiden, Netherlands, College of Information Systems and Management, National University of Defense Technology, Changsha, China; Liu Y., LIACS Media Lab, Leiden University, Niels Bohrweg 1, Leiden, Netherlands; Oerlemans A., VDG Security BV, Zoetermeer, Netherlands; Lao S., College of Information Systems and Management, National University of Defense Technology, Changsha, China; Wu S., LIACS Media Lab, Leiden University, Niels Bohrweg 1, Leiden, Netherlands; Lew M.S., LIACS Media Lab, Leiden University, Niels Bohrweg 1, Leiden, Netherlands","Deep learning algorithms are a subset of the machine learning algorithms, which aim at discovering multiple levels of distributed representations. Recently, numerous deep learning algorithms have been proposed to solve traditional artificial intelligence problems. This work aims to review the state-of-the-art in deep learning algorithms in computer vision by highlighting the contributions and challenges from over 210 recent research papers. It first gives an overview of various deep learning approaches and their recent developments, and then briefly describes their applications in diverse vision tasks, such as image classification, object detection, image retrieval, semantic segmentation and human pose estimation. Finally, the paper summarizes the future trends and challenges in designing and training deep neural networks. © 2015 Elsevier B.V.","Applications; Challenges; Computer vision; Deep learning; Developments; Trends","Algorithms; Applications; Artificial intelligence; Computer vision; Gesture recognition; Image classification; Image segmentation; Learning systems; Motion estimation; Object detection; Semantics; Challenges; Deep learning; Deep neural networks; Developments; Distributed representation; Human pose estimations; Semantic segmentation; Trends; Article; artificial neural network; body position; convolutional neural network; deep belief network; deep Boltzmann machine; deep energy model; deep learning; denoising autoencoder; image display; image retrieval; learning algorithm; machine learning; mathematical computing; priority journal; restricted Boltzmann machine; sparse autoencoder; sparse coding; Learning algorithms","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84957837518"
"Li W.; Cao P.; Zhao D.; Wang J.","Li, Wei (58182696700); Cao, Peng (55809753000); Zhao, Dazhe (7403490069); Wang, Junbo (57192912229)","58182696700; 55809753000; 7403490069; 57192912229","Pulmonary Nodule Classification with Deep Convolutional Neural Networks on Computed Tomography Images","2016","Computational and Mathematical Methods in Medicine","153","10.1155/2016/6215085","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008883816&doi=10.1155%2f2016%2f6215085&partnerID=40&md5=0bf2c1ce1820e853529be07c64fa1dc8","Medical Image Computing Laboratory, Ministry of Education, Northeastern University, Shenyang, 110819, China; College of Computer Science and Engineering, Northeastern University, Shenyang, 110819, China; Neusoft Research Institute, Neusoft Corporation, Shenyang, 110179, China","Li W., Medical Image Computing Laboratory, Ministry of Education, Northeastern University, Shenyang, 110819, China, College of Computer Science and Engineering, Northeastern University, Shenyang, 110819, China; Cao P., Medical Image Computing Laboratory, Ministry of Education, Northeastern University, Shenyang, 110819, China, College of Computer Science and Engineering, Northeastern University, Shenyang, 110819, China; Zhao D., Medical Image Computing Laboratory, Ministry of Education, Northeastern University, Shenyang, 110819, China, College of Computer Science and Engineering, Northeastern University, Shenyang, 110819, China; Wang J., Neusoft Research Institute, Neusoft Corporation, Shenyang, 110179, China","Computer aided detection (CAD) systems can assist radiologists by offering a second opinion on early diagnosis of lung cancer. Classification and feature representation play critical roles in false-positive reduction (FPR) in lung nodule CAD. We design a deep convolutional neural networks method for nodule classification, which has an advantage of autolearning representation and strong generalization ability. A specified network structure for nodule images is proposed to solve the recognition of three types of nodules, that is, solid, semisolid, and ground glass opacity (GGO). Deep convolutional neural networks are trained by 62,492 regions-of-interest (ROIs) samples including 40,772 nodules and 21,720 nonnodules from the Lung Image Database Consortium (LIDC) database. Experimental results demonstrate the effectiveness of the proposed method in terms of sensitivity and overall accuracy and that it consistently outperforms the competing methods. © 2016 Wei Li et al.","","Algorithms; Artificial Intelligence; Computer Graphics; Databases, Factual; False Positive Reactions; Humans; Image Processing, Computer-Assisted; Lung Neoplasms; Neural Networks (Computer); Pattern Recognition, Automated; Radiographic Image Enhancement; Radiographic Image Interpretation, Computer-Assisted; Reproducibility of Results; Sensitivity and Specificity; Solitary Pulmonary Nodule; Tomography, X-Ray Computed; Biological organs; Computer aided diagnosis; Computerized tomography; Convolution; Deep neural networks; Image classification; Computed tomography images; Computer aided detection systems; False-positive reduction; Feature representation; Generalization ability; Ground-glass opacity; Overall accuracies; Regions of interest; accuracy; Article; automated pattern recognition; classification algorithm; computer assisted diagnosis; computer assisted tomography; deep convolutional neural network; false positive result; human; lung nodule; machine learning; thorax radiography; algorithm; artificial intelligence; artificial neural network; computer graphics; diagnostic imaging; factual database; image enhancement; image processing; lung nodule; lung tumor; procedures; reproducibility; sensitivity and specificity; x-ray computed tomography; Convolutional neural networks","Hindawi Limited","1748670X","","","28070212","Article","Scopus","2-s2.0-85008883816"
"Suk H.-I.; Lee S.-W.; Shen D.","Suk, Heung-Il (56332955800); Lee, Seong-Whan (7601390519); Shen, Dinggang (7401738392)","56332955800; 7601390519; 7401738392","Deep sparse multi-task learning for feature selection in Alzheimer’s disease diagnosis","2016","Brain Structure and Function","116","10.1007/s00429-015-1059-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929692240&doi=10.1007%2fs00429-015-1059-y&partnerID=40&md5=84206a7ceb8dc2626da4e576067d97fe","Department of Brain and Cognitive Engineering, Korea University, Seoul, 136-713, South Korea; Biomedical Research Imaging Center and Department of Radiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States","Suk H.-I., Department of Brain and Cognitive Engineering, Korea University, Seoul, 136-713, South Korea; Lee S.-W., Department of Brain and Cognitive Engineering, Korea University, Seoul, 136-713, South Korea; Shen D., Department of Brain and Cognitive Engineering, Korea University, Seoul, 136-713, South Korea, Biomedical Research Imaging Center and Department of Radiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States","Recently, neuroimaging-based Alzheimer’s disease (AD) or mild cognitive impairment (MCI) diagnosis has attracted researchers in the field, due to the increasing prevalence of the diseases. Unfortunately, the unfavorable high-dimensional nature of neuroimaging data, but a limited small number of samples available, makes it challenging to build a robust computer-aided diagnosis system. Machine learning techniques have been considered as a useful tool in this respect and, among various methods, sparse regression has shown its validity in the literature. However, to our best knowledge, the existing sparse regression methods mostly try to select features based on the optimal regression coefficients in one step. We argue that since the training feature vectors are composed of both informative and uninformative or less informative features, the resulting optimal regression coefficients are inevidently affected by the uninformative or less informative features. To this end, we first propose a novel deep architecture to recursively discard uninformative features by performing sparse multi-task learning in a hierarchical fashion. We further hypothesize that the optimal regression coefficients reflect the relative importance of features in representing the target response variables. In this regard, we use the optimal regression coefficients learned in one hierarchy as feature weighting factors in the following hierarchy, and formulate a weighted sparse multi-task learning method. Lastly, we also take into account the distributional characteristics of samples per class and use clustering-induced subclass label vectors as target response values in our sparse regression model. In our experiments on the ADNI cohort, we performed both binary and multi-class classification tasks in AD/MCI diagnosis and showed the superiority of the proposed method by comparing with the state-of-the-art methods. © 2015, Springer-Verlag Berlin Heidelberg.","Alzheimer’s disease (AD); Deep architecture; Feature selection; Magnetic resonance imaging (MRI); Mild cognitive impairment (MCI); Multi-task learning; Positron emission topography (PET); Sparse least squared regression","Aged; Algorithms; Alzheimer Disease; Diagnosis, Computer-Assisted; Female; Humans; Magnetic Resonance Imaging; Male; Positron-Emission Tomography; Regression Analysis; Sensitivity and Specificity; Support Vector Machine; amyloid beta protein[1-42]; biological marker; tau protein; adult; aged; Alzheimer disease; anterior commissure; Article; cerebellum; cerebrospinal fluid analysis; cluster analysis; cohort analysis; deep sparse multitask learning; diagnostic test accuracy study; female; gray matter; human; learning test; major clinical study; male; mild cognitive impairment; neuroimaging; nuclear magnetic resonance imaging; positron emission tomography; posterior commissure; predictive value; priority journal; regression analysis; response variable; sensitivity and specificity; support vector machine; white matter; algorithm; Alzheimer disease; computer assisted diagnosis; diagnostic imaging; metabolism; pathology; procedures; support vector machine","Springer Verlag","18632653","","","25993900","Article","Scopus","2-s2.0-84929692240"
"Zhao Z.; Yang Z.; Lin H.; Wang J.; Gao S.","Zhao, Zhehuan (55561416700); Yang, Zhihao (16029941200); Lin, Hongfei (24468572400); Wang, Jian (55934279300); Gao, Song (57188711652)","55561416700; 16029941200; 24468572400; 55934279300; 57188711652","A protein-protein interaction extraction approach based on deep neural network","2016","International Journal of Data Mining and Bioinformatics","47","10.1504/IJDMB.2016.076534","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969871906&doi=10.1504%2fIJDMB.2016.076534&partnerID=40&md5=6ab3c7c2ab5f6b2af4b21c79ae24f83e","College of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, China; Department of Pharmacy, First Affiliated Hospital of Dalian Medical University, Dalian, 116023, China","Zhao Z., College of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, China; Yang Z., College of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, China; Lin H., College of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, China; Wang J., College of Computer Science and Technology, Dalian University of Technology, Dalian, 116024, China; Gao S., Department of Pharmacy, First Affiliated Hospital of Dalian Medical University, Dalian, 116023, China","Protein-Protein Interactions (PPIs) information extraction from biomedical literature helps unveil the molecular mechanisms of biological processes. Machine learning methods have been the most popular ones in PPI extraction area. However, these methods are still feature engineering-based, which means that their performances are also heavily dependent on the appropriate feature selection which is still a skill-dependent task. This paper presents a deep neural network-based approach which can learn complex and abstract features automatically from unlabelled data by unsupervised representation learning methods. This approach first employs the training algorithm of auto-encoders to initialise the parameters of a deep multilayer neural network. Then the gradient descent method using back propagation is applied to train this deep multilayer neural network model. Experimental results on five public PPI corpora show that our method can achieve better performance than can a multilayer neural network: on two 'toughest handling' corpora AImed and BioInfer, the former outperforms the latter with the improvements of 3.10 and 2.89 percentage units in F-score, respectively. In addition, the performance comparison with APG also verifies the effectiveness of our method. Copyright © 2016 Inderscience Enterprises Ltd.","Biomedical text mining; Deep learning; Interaction extraction; Neural network","back propagation; comparative effectiveness; experimental model; learning; mining; nervous system; protein protein interaction","Inderscience Publishers","17485673","","","","Article","Scopus","2-s2.0-84969871906"
"Azizi S.; Imani F.; Ghavidel S.; Tahmasebi A.; Kwak J.T.; Xu S.; Turkbey B.; Choyke P.; Pinto P.; Wood B.; Mousavi P.; Abolmaesumi P.","Azizi, Shekoofeh (57014719000); Imani, Farhad (39061516500); Ghavidel, Sahar (57188875798); Tahmasebi, Amir (56606356800); Kwak, Jin Tae (57226305229); Xu, Sheng (35868251000); Turkbey, Baris (9435311800); Choyke, Peter (7102809178); Pinto, Peter (7103408914); Wood, Bradford (7401873523); Mousavi, Parvin (16176026900); Abolmaesumi, Purang (6602170125)","57014719000; 39061516500; 57188875798; 56606356800; 57226305229; 35868251000; 9435311800; 7102809178; 7103408914; 7401873523; 16176026900; 6602170125","Detection of prostate cancer using temporal sequences of ultrasound data: a large clinical feasibility study","2016","International Journal of Computer Assisted Radiology and Surgery","38","10.1007/s11548-016-1395-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964067205&doi=10.1007%2fs11548-016-1395-2&partnerID=40&md5=98e1b805cefd5d6d1442c30d6b87c3c3","University of British Columbia, Vancouver, BC, Canada; Queen’s University, Kingston, ON, Canada; Philips Research North America, Cambridge, MA, United States; National Institutes of Health, Bethesda, MD, United States","Azizi S., University of British Columbia, Vancouver, BC, Canada; Imani F., University of British Columbia, Vancouver, BC, Canada; Ghavidel S., Queen’s University, Kingston, ON, Canada; Tahmasebi A., Philips Research North America, Cambridge, MA, United States; Kwak J.T., National Institutes of Health, Bethesda, MD, United States; Xu S., National Institutes of Health, Bethesda, MD, United States; Turkbey B., National Institutes of Health, Bethesda, MD, United States; Choyke P., National Institutes of Health, Bethesda, MD, United States; Pinto P., National Institutes of Health, Bethesda, MD, United States; Wood B., National Institutes of Health, Bethesda, MD, United States; Mousavi P., Queen’s University, Kingston, ON, Canada; Abolmaesumi P., University of British Columbia, Vancouver, BC, Canada","Purpose: This paper presents the results of a large study involving fusion prostate biopsies to demonstrate that temporal ultrasound can be used to accurately classify tissue labels identified in multi-parametric magnetic resonance imaging (mp-MRI) as suspicious for cancer. Methods: We use deep learning to analyze temporal ultrasound data obtained from 255 cancer foci identified in mp-MRI. Each target is sampled in axial and sagittal planes. A deep belief network is trained to automatically learn the high-level latent features of temporal ultrasound data. A support vector machine classifier is then applied to differentiate cancerous versus benign tissue, verified by histopathology. Data from 32 targets are used for the training, while the remaining 223 targets are used for testing. Results: Our results indicate that the distance between the biopsy target and the prostate boundary, and the agreement between axial and sagittal histopathology of each target impact the classification accuracy. In 84 test cores that are 5 mm or farther to the prostate boundary, and have consistent pathology outcomes in axial and sagittal biopsy planes, we achieve an area under the curve of 0.80. In contrast, all of these targets were labeled as moderately suspicious in mp-MR. Conclusion: Using temporal ultrasound data in a fusion prostate biopsy study, we achieved a high classification accuracy specifically for moderately scored mp-MRI targets. These targets are clinically common and contribute to the high false-positive rates associated with mp-MRI for prostate cancer detection. Temporal ultrasound data combined with mp-MRI have the potential to reduce the number of unnecessary biopsies in fusion biopsy settings. © 2016, CARS.","Cancer diagnosis; Deep belief network; Deep learning; Prostate cancer; Temporal ultrasound data","Aged; Feasibility Studies; Humans; Image-Guided Biopsy; Magnetic Resonance Imaging; Male; Middle Aged; Prostate; Prostatic Neoplasms; Ultrasonography; accuracy; area under the curve; Article; feasibility study; histopathology; human; human tissue; major clinical study; male; multiparametric magnetic resonance imaging; outcome assessment; priority journal; prostate biopsy; prostate cancer; support vector machine; ultrasound; aged; diagnostic imaging; echography; image guided biopsy; middle aged; nuclear magnetic resonance imaging; procedures; prostate; Prostatic Neoplasms","Springer Verlag","18616410","","","27059021","Article","Scopus","2-s2.0-84964067205"
"Pang S.; Yang X.","Pang, Shan (54879505000); Yang, Xinyi (34972206700)","54879505000; 34972206700","Deep Convolutional Extreme Learning Machine and Its Application in Handwritten Digit Classification","2016","Computational Intelligence and Neuroscience","67","10.1155/2016/3049632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984691298&doi=10.1155%2f2016%2f3049632&partnerID=40&md5=20b28f6eadd99480ada8276cf4a28951","College of Information and Electrical Engineering, Ludong University, Yantai, 264025, China; Department of Aircraft Engineering, Naval Aeronautical and Astronautical University, Yantai, 264001, China","Pang S., College of Information and Electrical Engineering, Ludong University, Yantai, 264025, China; Yang X., Department of Aircraft Engineering, Naval Aeronautical and Astronautical University, Yantai, 264001, China","In recent years, some deep learning methods have been developed and applied to image classification applications, such as convolutional neuron network (CNN) and deep belief network (DBN). However they are suffering from some problems like local minima, slow convergence rate, and intensive human intervention. In this paper, we propose a rapid learning method, namely, deep convolutional extreme learning machine (DC-ELM), which combines the power of CNN and fast training of ELM. It uses multiple alternate convolution layers and pooling layers to effectively abstract high level features from input images. Then the abstracted features are fed to an ELM classifier, which leads to better generalization performance with faster learning speed. DC-ELM also introduces stochastic pooling in the last hidden layer to reduce dimensionality of features greatly, thus saving much training time and computation resources. We systematically evaluated the performance of DC-ELM on two handwritten digit data sets: MNIST and USPS. Experimental results show that our method achieved better testing accuracy with significantly shorter training time in comparison with deep learning methods and other ELM methods. © 2016 Shan Pang and Xinyi Yang.","","Algorithms; Handwriting; Humans; Machine Learning; Neural Networks (Computer); Character recognition; Convolution; Knowledge acquisition; Neural networks; Stochastic systems; Computation resources; Deep belief network (DBN); Extreme learning machine; Generalization performance; Handwritten digit classification; High-level features; Human intervention; Slow convergences; algorithm; artificial neural network; handwriting; human; machine learning; Deep learning","Hindawi Limited","16875265","","","27610128","Article","Scopus","2-s2.0-84984691298"
"Gokmen T.; Vlasov Y.","Gokmen, Tayfun (14619218100); Vlasov, Yurii (55403926800)","14619218100; 55403926800","Acceleration of deep neural network training with resistive cross-point devices: Design considerations","2016","Frontiers in Neuroscience","318","10.3389/fnins.2016.00333","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983247214&doi=10.3389%2ffnins.2016.00333&partnerID=40&md5=e77fe12c918872a25f20c0a86dac70de","IBM T. J. Watson Research Center, Yorktown Heights, NY, United States; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, United States","Gokmen T., IBM T. J. Watson Research Center, Yorktown Heights, NY, United States; Vlasov Y., IBM T. J. Watson Research Center, Yorktown Heights, NY, United States, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, United States","In recent years, deep neural networks (DNN) have demonstrated significant business impact in large scale analysis and classification tasks such as speech recognition, visual object detection, pattern extraction, etc. Training of large DNNs, however, is universally considered as time consuming and computationally intensive task that demands datacenter-scale computational resources recruited for many days. Here we propose a concept of resistive processing unit (RPU) devices that can potentially accelerate DNN training by orders of magnitude while using much less power. The proposed RPU device can store and update the weight values locally thus minimizing data movement during training and allowing to fully exploit the locality and the parallelism of the training algorithm. We evaluate the effect of various RPU device features/non-idealities and system parameters on performance in order to derive the device and system level specifications for implementation of an accelerator chip for DNN training in a realistic CMOS-compatible technology. For large DNNs with about 1 billion weights this massively parallel RPU architecture can achieve acceleration factors of 30, 000 × compared to state-of-the-art microprocessors while providing power efficiency of 84, 000 GigaOps/s/W. Problems that currently require days of training on a datacenter-size cluster with thousands of machines can be addressed within hours on a single RPU accelerator. A system consisting of a cluster of RPU accelerators will be able to tackle Big Data problems with trillions of parameters that is impossible to address today like, for example, natural speech recognition and translation between all world languages, real-time analytics on large streams of business and scientific data, integration, and analysis of multimodal sensory data flows from a massive number of IoT (Internet of Things) sensors. © 2016 Gokmen and Vlasov.","Artificial neural networks; Deep neural network training; Electronic devices; Machine learning; Materials engineering; Memristive devices; Nanotechnology; Synaptic device","acceleration; Article; artificial neural network; automatic speech recognition; controlled study; deep neural network; general device; intermethod comparison; microprocessor; natural language processing; resistive processing unit","Frontiers Research Foundation","16624548","","","","Article","Scopus","2-s2.0-84983247214"
"Baranov A.A.; Namazova-Baranova L.S.; Smirnov I.V.; Devyatkin D.A.; Shelmanov A.O.; Vishneva E.A.; Antonova E.V.; Smirnov V.I.","Baranov, A.A. (57201770953); Namazova-Baranova, L.S. (48761908100); Smirnov, I.V. (56712356800); Devyatkin, D.A. (56509621200); Shelmanov, A.O. (56291743600); Vishneva, E.A. (56712891600); Antonova, E.V. (7005442403); Smirnov, V.I. (7403516654)","57201770953; 48761908100; 56712356800; 56509621200; 56291743600; 56712891600; 7005442403; 7403516654","Technologies for complex intelligent clinical data analysis","2016","Vestnik Rossiiskoi Akademii Meditsinskikh Nauk","10","10.15690/vramn663","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984813603&doi=10.15690%2fvramn663&partnerID=40&md5=b3bbe5e36856ed38d4994259d32dd473","Scientific Center of Children's Health, Moscow, Russian Federation; Institute for Systems Analysis, Federal Research Center 'Computer Science and Control', Russian Academy of Sciences, Moscow, Russian Federation","Baranov A.A., Scientific Center of Children's Health, Moscow, Russian Federation; Namazova-Baranova L.S., Scientific Center of Children's Health, Moscow, Russian Federation; Smirnov I.V., Institute for Systems Analysis, Federal Research Center 'Computer Science and Control', Russian Academy of Sciences, Moscow, Russian Federation; Devyatkin D.A., Institute for Systems Analysis, Federal Research Center 'Computer Science and Control', Russian Academy of Sciences, Moscow, Russian Federation; Shelmanov A.O., Institute for Systems Analysis, Federal Research Center 'Computer Science and Control', Russian Academy of Sciences, Moscow, Russian Federation; Vishneva E.A., Scientific Center of Children's Health, Moscow, Russian Federation; Antonova E.V., Scientific Center of Children's Health, Moscow, Russian Federation; Smirnov V.I., Scientific Center of Children's Health, Moscow, Russian Federation","The paper presents the system for intelligent analysis of clinical information. Authors describe methods implemented in the system for clinical information retrieval, intelligent diagnostics of chronic diseases, patient's features importance and for detection of hidden dependencies between features. Results of the experimental evaluation of these methods are also presented. Background: Healthcare facilities generate a large flow of both structured and unstructured data which contain important information about patients. Test results are usually retained as structured data but some data is retained in the form of natural language texts (medical history, the results of physical examination, and the results of other examinations, such as ultrasound, ECG or X-ray studies). Many tasks arising in clinical practice can be automated applying methods for intelligent analysis of accumulated structured array and unstructured data that leads to improvement of the healthcare quality. Aims: the creation of the complex system for intelligent data analysis in the multi-disciplinary pediatric center. Materials and methods: Authors propose methods for information extraction from clinical texts in Russian. The methods are carried out on the basis of deep linguistic analysis. They retrieve terms of diseases, symptoms, areas of the body and drugs. The methods can recognize additional attributes such as «negation» (indicates that the disease is absent), «no patient» (indicates that the disease refers to the patient's family member, but not to the patient), «severity of illness», «disease course», «body region to which the disease refers». Authors use a set of hand-drawn templates and various techniques based on machine learning to retrieve information using a medical thesaurus. The extracted information is used to solve the problem of automatic diagnosis of chronic diseases. A machine learning method for classification of patients with similar nosology and the method for determining the most informative patients' features are also proposed. Results: Authors have processed anonymized health records from the pediatric center to estimate the proposed methods. The results show the applicability of the information extracted from the texts for solving practical problems. The records of patients with allergic, glomerular and rheumatic diseases were used for experimental assessment of the method of automatic diagnostic. Authors have also determined the most appropriate machine learning methods for classification of patients for each group of diseases, as well as the most informative disease signs. It has been found that using additional information extracted from clinical texts, together with structured data helps to improve the quality of diagnosis of chronic diseases. Authors have also obtained pattern combinations of signs of diseases. Conclusions: The proposed methods have been implemented in the intelligent data processing system for a multidisciplinary pediatric center. The experimental results show the availability of the system to improve the quality of pediatric healthcare.","Data mining in healthcare; Hospital information system; Information extraction; Natural language processing of clinical texts","Hospitals, Pediatric; Humans; Information Management; Information Storage and Retrieval; Medical Records Systems, Computerized; Russia; electronic medical record system; hospital; human; information retrieval; information system; organization and management; procedures; Russian Federation","Meditsina Publishers","08696047","","","27522718","Article","Scopus","2-s2.0-84984813603"
"Tezuka S.; Maeda G.; Baba M.; Baba N.","Tezuka, Shoki (57193697942); Maeda, Gen (57193701423); Baba, Misuzu (7402885410); Baba, Norio (55729871000)","57193697942; 57193701423; 7402885410; 55729871000","Applications of a particle extraction method with deep neural networks using improved auto-encoders to biological ultra-thin section images","2016","Microscopy","1","10.1093/jmicro/dfw068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015895975&doi=10.1093%2fjmicro%2fdfw068&partnerID=40&md5=411f80111a91e18ee13e04c9243a795c","Graduate School, Kogakuin University, Shinjuku, Japan; Research Institute for Science and Technology, Kogakuin University, Hachioji, Japan","Tezuka S., Graduate School, Kogakuin University, Shinjuku, Japan; Maeda G., Graduate School, Kogakuin University, Shinjuku, Japan; Baba M., Research Institute for Science and Technology, Kogakuin University, Hachioji, Japan; Baba N., Graduate School, Kogakuin University, Shinjuku, Japan","In the field of electron microscopic image analysis, machine learning such as neural networks [1] is remarkable method, which has abilities of automatic extraction of structural objects and automatic classification. Recently, deep leaning in the neural networks is actively applied because of high recognition rate [2]. This learning method is able to choose effective feature patterns from a set of learned local images. We are developing a deep learning software for application to biological transmission electron microscope images (including electron tomographic images), especially yeast cell (Saccharomyces cerevisiae) images, in which automatic particle extraction is a purpose. We already applied a preliminary software to ultra-thin section images of the yeast cell for picking out some kinds of structural particles (e.g. Ty1 particle in autophagy). The characteristics of the software is that it is made of auto-encoder in neural networks. The image analysis with the auto-encoder is essentially equivalent to that with the principal component analysis (PCA) [3]. The auto-encoder analyses a lot of particle images which are manually collected and a certain number of important image components are automatically extracted from the particle images like PCA. These components are visualized and the number of components is adjustable. We are improving the function of the auto-encoder so as to raise the efficiency. We are also developing a particle collection assist software which makes the manual supervised learning easy. These results will be presented. © 2016, Oxford University Press. All rights reserved.","","Application programs; Deep neural networks; Extraction; Image analysis; Image enhancement; Tomography; Transmission electron microscopy; Yeast; A-particles; Auto encoders; Neural-networks; Particle extraction; Particle images; Principal-component analysis; Section image; Thin-sections; Ultra-thin; Yeast cell; Principal component analysis","Oxford University Press","20505698","","","","Article","Scopus","2-s2.0-85015895975"
"Avdoshin S.M.; Lazarenko A.V.","Avdoshin, S.M. (8122631900); Lazarenko, A.V. (57193557043)","8122631900; 57193557043","Deep web users deanonimization system","2016","Resource: Engineering and Technology for Sustainable World","0","10.15514/ISPRAS-2016-28(3)-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103108479&doi=10.15514%2fISPRAS-2016-28%283%29-2&partnerID=40&md5=a99463fbe79b956bcd332721f6a2b507","National Research University Higher School of Economics, School of Software Engineering, 20, Myasnitskaya st., Moscow, 101000, Russian Federation","Avdoshin S.M., National Research University Higher School of Economics, School of Software Engineering, 20, Myasnitskaya st., Moscow, 101000, Russian Federation; Lazarenko A.V., National Research University Higher School of Economics, School of Software Engineering, 20, Myasnitskaya st., Moscow, 101000, Russian Federation","Privacy enhancing technologies (PETs) are ubiquitous nowadays. They are beneficial for a wide range of users: For businesses, journalists, bloggers, etc. However, PETs are not always used for legal activity. There a lot of anonymous networks and technologies which grants anonymous access to digital resources. The most popular anonymous networks nowadays is Tor. Tor is a valuable tool for hackers, drug and gun dealers. The present paper is focused on Tor users' deanonimization using out-of-the box technologies and a basic machine learning algorithm. The aim of the work is to show that it is possible to deanonimize a small fraction of users without having a lot of resources and state-of-the-art machine learning techniques. The first stage of the research was the investigation of contemporary anonymous networks. The second stage was the investigation of deanonimization techniques: Traffic analysis, timing attacks, attacks with autonomous systems. For our system, we used website fingerprinting attack, because it requires the smallest number of resources needed for successful implementation of the attack. Finally, there was an experiment held with 5 persons in one room with one corrupted entry Tor relay. We achieved a quite good accuracy (70%) for classifying the webpage, which the user visits, using the set of resources provided by global cybersecurity company. The deanonimization is a very important task from the point of view of national security. © 2016 American Society of Agricultural and Biological Engineers. All rights reserved.","Anonymous network; Deanonimization; Deep web; Tor; Traffic analysis; Website fingerprinting","Computer networks; Machine learning; National security; Network security; Personal computing; Privacy by design; Websites; Anonymous Networks; Autonomous systems; Cyber security; Digital resources; Machine learning techniques; Privacy enhancing technologies; State of the art; Traffic analysis; Learning algorithms","American Society of Agricultural and Biological Engineers","10763333","","RSOUE","","Article","Scopus","2-s2.0-85103108479"
"Albarqouni S.; Baur C.; Achilles F.; Belagiannis V.; Demirci S.; Navab N.","Albarqouni, Shadi (55129204800); Baur, Christoph (56982679100); Achilles, Felix (57118240900); Belagiannis, Vasileios (35483155200); Demirci, Stefanie (57213376774); Navab, Nassir (7003458998)","55129204800; 56982679100; 57118240900; 35483155200; 57213376774; 7003458998","AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images","2016","IEEE Transactions on Medical Imaging","460","10.1109/TMI.2016.2528120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969939903&doi=10.1109%2fTMI.2016.2528120&partnerID=40&md5=ff385d9219cfc107aeb2fa15261a230e","Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany; Deutsches Zentrum für Neurodegenerative Erkrankungen, Bonn, 53175, Germany; Visual Geometry Group, University of Oxford, Oxford, United Kingdom; Whiting School of Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States","Albarqouni S., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany, Deutsches Zentrum für Neurodegenerative Erkrankungen, Bonn, 53175, Germany; Baur C., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany; Achilles F., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany; Belagiannis V., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany, Visual Geometry Group, University of Oxford, Oxford, United Kingdom; Demirci S., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany; Navab N., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany, Whiting School of Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States","The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration. © 2016 IEEE.","Aggregation; crowdsourcing; deep learning; gamification; online learning","Breast Neoplasms; Crowdsourcing; Female; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Internet; Machine Learning; Mitosis; Neural Networks (Computer); Video Games; Agglomeration; Artificial intelligence; Crowdsourcing; Image retrieval; Learning systems; Neural networks; Biomedical image database; Conventional machines; Convolutional neural network; Deep learning; Gamification; Large-scale database; Online learning; Precise definition; algorithm; Article; breast biopsy; breast cancer; cancer diagnosis; clinical article; convolutional neural network; crowdsourcing; data base; experimental study; histopathology; human; human tissue; machine learning; mitosis; artificial neural network; breast tumor; computer assisted diagnosis; crowdsourcing; cytochemistry; diagnostic imaging; female; Internet; machine learning; physiology; procedures; video game; Medical imaging","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26891484","Article","Scopus","2-s2.0-84969939903"
"Kleesiek J.; Urban G.; Hubert A.; Schwarz D.; Maier-Hein K.; Bendszus M.; Biller A.","Kleesiek, Jens (9743752700); Urban, Gregor (57192234261); Hubert, Alexander (56205325800); Schwarz, Daniel (56430564100); Maier-Hein, Klaus (55647018100); Bendszus, Martin (7006493496); Biller, Armin (15753444000)","9743752700; 57192234261; 56205325800; 56430564100; 55647018100; 7006493496; 15753444000","Deep MRI brain extraction: A 3D convolutional neural network for skull stripping","2016","NeuroImage","379","10.1016/j.neuroimage.2016.01.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959203985&doi=10.1016%2fj.neuroimage.2016.01.024&partnerID=40&md5=74bf382675f0bb1ff4ae9c82f926e2c1","MDMI Lab, Division of Neuroradiology, Heidelberg University Hospital, Heidelberg, Germany; Junior Group Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Heidelberg University HCI/IWR, Heidelberg, Germany; Division of Radiology, German Cancer Research Center, Heidelberg, Germany","Kleesiek J., MDMI Lab, Division of Neuroradiology, Heidelberg University Hospital, Heidelberg, Germany, Junior Group Medical Image Computing, German Cancer Research Center, Heidelberg, Germany, Heidelberg University HCI/IWR, Heidelberg, Germany, Division of Radiology, German Cancer Research Center, Heidelberg, Germany; Urban G., MDMI Lab, Division of Neuroradiology, Heidelberg University Hospital, Heidelberg, Germany; Hubert A., MDMI Lab, Division of Neuroradiology, Heidelberg University Hospital, Heidelberg, Germany; Schwarz D., MDMI Lab, Division of Neuroradiology, Heidelberg University Hospital, Heidelberg, Germany; Maier-Hein K., Junior Group Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Bendszus M., MDMI Lab, Division of Neuroradiology, Heidelberg University Hospital, Heidelberg, Germany; Biller A., MDMI Lab, Division of Neuroradiology, Heidelberg University Hospital, Heidelberg, Germany, Division of Radiology, German Cancer Research Center, Heidelberg, Germany","Brain extraction from magnetic resonance imaging (MRI) is crucial for many neuroimaging workflows. Current methods demonstrate good results on non-enhanced T1-weighted images, but struggle when confronted with other modalities and pathologically altered tissue. In this paper we present a 3D convolutional deep learning architecture to address these shortcomings. In contrast to existing methods, we are not limited to non-enhanced T1w images. When trained appropriately, our approach handles an arbitrary number of modalities including contrast-enhanced scans. Its applicability to MRI data, comprising four channels: non-enhanced and contrast-enhanced T1w, T2w and FLAIR contrasts, is demonstrated on a challenging clinical data set containing brain tumors (N = 53), where our approach significantly outperforms six commonly used tools with a mean Dice score of 95.19. Further, the proposed method at least matches state-of-the-art performance as demonstrated on three publicly available data sets: IBSR, LPBA40 and OASIS, totaling N = 135 volumes. For the IBSR (96.32) and LPBA40 (96.96) data set the convolutional neuronal network (CNN) obtains the highest average Dice scores, albeit not being significantly different from the second best performing method. For the OASIS data the second best Dice (95.02) results are achieved, with no statistical difference in comparison to the best performing tool. For all data sets the highest average specificity measures are evaluated, whereas the sensitivity displays about average results. Adjusting the cut-off threshold for generating the binary masks from the CNN's probability output can be used to increase the sensitivity of the method. Of course, this comes at the cost of a decreased specificity and has to be decided application specific. Using an optimized GPU implementation predictions can be achieved in less than one minute. The proposed method may prove useful for large-scale studies and clinical trials. © 2016 Elsevier Inc.","Brain extraction; Brain mask; Convolutional networks; Deep learning; MRI; Skull stripping","Brain Neoplasms; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Neuroimaging; Skull; Article; artificial neural network; brain radiography; brain tumor; contrast enhancement; controlled study; false negative result; false positive result; human; image analysis; intermethod comparison; major clinical study; neuroimaging; nuclear magnetic resonance imaging; performance; priority journal; scoring system; sensitivity and specificity; three dimensional convolutional neuronal network; three dimensional imaging; artificial neural network; computer assisted diagnosis; diagnostic imaging; image enhancement; machine learning; neuroimaging; nuclear magnetic resonance imaging; procedures; skull; three dimensional imaging","Academic Press Inc.","10538119","","NEIME","26808333","Article","Scopus","2-s2.0-84959203985"
"Steen K.A.; Christiansen P.; Karstoft H.; Jørgensen R.N.","Steen, Kim Arild (55145753300); Christiansen, Peter (57200828942); Karstoft, Henrik (36771565700); Jørgensen, Rasmus Nyholm (35292305600)","55145753300; 57200828942; 36771565700; 35292305600","Using deep learning to challenge safety standard for highly autonomous machines in agriculture","2016","Journal of Imaging","53","10.3390/jimaging2010006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968768999&doi=10.3390%2fjimaging2010006&partnerID=40&md5=ee0cb4cd278e564808021d3742cef393","Department of Engineering, Aarhus University, Finlandsgade 22, Aarhus N, 8200, Denmark","Steen K.A., Department of Engineering, Aarhus University, Finlandsgade 22, Aarhus N, 8200, Denmark; Christiansen P., Department of Engineering, Aarhus University, Finlandsgade 22, Aarhus N, 8200, Denmark; Karstoft H., Department of Engineering, Aarhus University, Finlandsgade 22, Aarhus N, 8200, Denmark; Jørgensen R.N., Department of Engineering, Aarhus University, Finlandsgade 22, Aarhus N, 8200, Denmark","In this paper, an algorithm for obstacle detection in agricultural fields is presented. The algorithm is based on an existing deep convolutional neural net, which is fine-tuned for detection of a specific obstacle. In ISO/DIS 18497, which is an emerging standard for safety of highly automated machinery in agriculture, a barrel-shaped obstacle is defined as the obstacle which should be robustly detected to comply with the standard. We show that our fine-tuned deep convolutional net is capable of detecting this obstacle with a precision of 99.9% in row crops and 90.8% in grass mowing, while simultaneously not detecting people and other very distinct obstacles in the image frame. As such, this short note argues that the obstacle defined in the emerging standard is not capable of ensuring safe operations when imaging sensors are part of the safety system. © 2016 by the authors.","Autonomous; Deep learning; ISO; Obstacle detection","Convolution; Deep neural networks; ISO Standards; Obstacle detectors; Agricultural fields; Autonomous; Autonomous machines; Deep learning; Image frames; ISO; Obstacles detection; Row crop; Safe operation; Safety standard; Agriculture","MDPI","2313433X","","","","Article","Scopus","2-s2.0-84968768999"
"Van Tulder G.; De Bruijne M.","Van Tulder, Gijs (50263296100); De Bruijne, Marleen (6603748680)","50263296100; 6603748680","Combining Generative and Discriminative Representation Learning for Lung CT Analysis With Convolutional Restricted Boltzmann Machines","2016","IEEE Transactions on Medical Imaging","119","10.1109/TMI.2016.2526687","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968572560&doi=10.1109%2fTMI.2016.2526687&partnerID=40&md5=5be32eb502ad221eb87d045239bd610a","Biomedical Imaging Group, Erasmus MC, Rotterdam, 3000 CA, Netherlands; Department of Computer Science, University of Copenhagen, Copenhagen, 2100, Denmark","Van Tulder G., Biomedical Imaging Group, Erasmus MC, Rotterdam, 3000 CA, Netherlands; De Bruijne M., Biomedical Imaging Group, Erasmus MC, Rotterdam, 3000 CA, Netherlands, Department of Computer Science, University of Copenhagen, Copenhagen, 2100, Denmark","The choice of features greatly influences the performance of a tissue classification system. Despite this, many systems are built with standard, predefined filter banks that are not optimized for that particular application. Representation learning methods such as restricted Boltzmann machines may outperform these standard filter banks because they learn a feature description directly from the training data. Like many other representation learning methods, restricted Boltzmann machines are unsupervised and are trained with a generative learning objective; this allows them to learn representations from unlabeled data, but does not necessarily produce features that are optimal for classification. In this paper we propose the convolutional classification restricted Boltzmann machine, which combines a generative and a discriminative learning objective. This allows it to learn filters that are good both for describing the training data and for classification. We present experiments with feature learning for lung texture classification and airway detection in CT images. In both applications, a combination of learning objectives outperformed purely discriminative or generative learning, increasing, for instance, the lung tissue classification accuracy by 1 to 8 percentage points. This shows that discriminative learning can help an otherwise unsupervised feature learner to learn filters that are optimized for classification. © 1982-2012 IEEE.","Deep learning; lung; machine learning; neural network; pattern recognition and classification; representation learning; restricted Boltzmann machine; segmentation; X-ray imaging and computed tomography","Algorithms; Humans; Image Processing, Computer-Assisted; Lung; Machine Learning; Neural Networks (Computer); Tomography, X-Ray Computed; Artificial intelligence; Biological organs; Computerized tomography; Convolution; Filter banks; Image segmentation; Learning systems; Neural networks; Pattern recognition; Tissue; Deep learning; lung; Pattern recognition and classification; representation learning; Restricted boltzmann machine; Xray imaging; Article; computer assisted tomography; discrimination learning; emphysema; filter; functional magnetic resonance imaging; human; interstitial lung disease; lung fibrosis; lung parenchyma; machine learning; probability; random forest; restricted Boltzmann machine; algorithm; artificial neural network; diagnostic imaging; image processing; lung; machine learning; procedures; x-ray computed tomography; Classification (of information)","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26886968","Article","Scopus","2-s2.0-84968572560"
"Premaladha J.; Ravichandran K.S.","Premaladha, J. (56181566900); Ravichandran, K.S. (7102687553)","56181566900; 7102687553","Novel Approaches for Diagnosing Melanoma Skin Lesions Through Supervised and Deep Learning Algorithms","2016","Journal of Medical Systems","159","10.1007/s10916-016-0460-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958051709&doi=10.1007%2fs10916-016-0460-2&partnerID=40&md5=ea1d82aac747cdda83829d89168e16a5","School of Computing, SASTRA University, Tirumalaisamudram, Thanjavur, 613401, Tamilnadu, India","Premaladha J., School of Computing, SASTRA University, Tirumalaisamudram, Thanjavur, 613401, Tamilnadu, India; Ravichandran K.S., School of Computing, SASTRA University, Tirumalaisamudram, Thanjavur, 613401, Tamilnadu, India","Dermoscopy is a technique used to capture the images of skin, and these images are useful to analyze the different types of skin diseases. Malignant melanoma is a kind of skin cancer whose severity even leads to death. Earlier detection of melanoma prevents death and the clinicians can treat the patients to increase the chances of survival. Only few machine learning algorithms are developed to detect the melanoma using its features. This paper proposes a Computer Aided Diagnosis (CAD) system which equips efficient algorithms to classify and predict the melanoma. Enhancement of the images are done using Contrast Limited Adaptive Histogram Equalization technique (CLAHE) and median filter. A new segmentation algorithm called Normalized Otsu’s Segmentation (NOS) is implemented to segment the affected skin lesion from the normal skin, which overcomes the problem of variable illumination. Fifteen features are derived and extracted from the segmented images are fed into the proposed classification techniques like Deep Learning based Neural Networks and Hybrid Adaboost-Support Vector Machine (SVM) algorithms. The proposed system is tested and validated with nearly 992 images (malignant & benign lesions) and it provides a high classification accuracy of 93 %. The proposed CAD system can assist the dermatologists to confirm the decision of the diagnosis and to avoid excisional biopsies. © 2016, Springer Science+Business Media New York.","Adaboost; Artificial neural networks; Classification; Deep learning; Preprocessing; Segmentation; Support vector machine","Algorithms; Dermoscopy; Diagnosis, Computer-Assisted; Early Detection of Cancer; Humans; Image Interpretation, Computer-Assisted; Male; Melanoma; Neural Networks (Computer); Skin Neoplasms; Support Vector Machine; Adaptive Neuro Fuzzy Inference System; algorithm; Article; computer assisted diagnosis; Contrast Limited Adaptive Histogram Equalization technique; Deep Learning based Neural Network; diagnostic accuracy; epiluminescence microscopy; Hybrid Adaboost Support Vector Machine; illumination; image enhancement; image processing; learning algorithm; machine learning; median filtering technique; melanoma; Normalized Otsu Segmentation; skin defect; tumor classification; algorithm; artificial neural network; computer assisted diagnosis; early cancer diagnosis; human; male; melanoma; pathology; procedures; Skin Neoplasms; support vector machine","Springer New York LLC","01485598","","JMSYD","26872778","Article","Scopus","2-s2.0-84958051709"
"Agarwalla S.; Sarma K.K.","Agarwalla, Swapna (56730375400); Sarma, Kandarpa Kumar (35219168100)","56730375400; 35219168100","Machine learning based sample extraction for automatic speech recognition using dialectal Assamese speech","2016","Neural Networks","40","10.1016/j.neunet.2015.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954286341&doi=10.1016%2fj.neunet.2015.12.010&partnerID=40&md5=9440c58a86f9a9573d53d5d9f0a75416","Department of Electronics and Communication Engineering, Gauhati University, Guwahati, Assam, 781014, India","Agarwalla S., Department of Electronics and Communication Engineering, Gauhati University, Guwahati, Assam, 781014, India; Sarma K.K., Department of Electronics and Communication Engineering, Gauhati University, Guwahati, Assam, 781014, India","Automatic Speaker Recognition (ASR) and related issues are continuously evolving as inseparable elements of Human Computer Interaction (HCI). With assimilation of emerging concepts like big data and Internet of Things (IoT) as extended elements of HCI, ASR techniques are found to be passing through a paradigm shift. Oflate, learning based techniques have started to receive greater attention from research communities related to ASR owing to the fact that former possess natural ability to mimic biological behavior and that way aids ASR modeling and processing. The current learning based ASR techniques are found to be evolving further with incorporation of big data, IoT like concepts. Here, in this paper, we report certain approaches based on machine learning (ML) used for extraction of relevant samples from big data space and apply them for ASR using certain soft computing techniques for Assamese speech with dialectal variations. A class of ML techniques comprising of the basic Artificial Neural Network (ANN) in feedforward (FF) and Deep Neural Network (DNN) forms using raw speech, extracted features and frequency domain forms are considered. The Multi Layer Perceptron (MLP) is configured with inputs in several forms to learn class information obtained using clustering and manual labeling. DNNs are also used to extract specific sentence types. Initially, from a large storage, relevant samples are selected and assimilated. Next, a few conventional methods are used for feature extraction of a few selected types. The features comprise of both spectral and prosodic types. These are applied to Recurrent Neural Network (RNN) and Fully Focused Time Delay Neural Network (FFTDNN) structures to evaluate their performance in recognizing mood, dialect, speaker and gender variations in dialectal Assamese speech. The system is tested under several background noise conditions by considering the recognition rates (obtained using confusion matrices and manually) and computation time. It is found that the proposed ML based sentence extraction techniques and the composite feature set used with RNN as classifier outperform all other approaches. By using ANN in FF form as feature extractor, the performance of the system is evaluated and a comparison is made. Experimental results show that the application of big data samples has enhanced the learning of the ASR system. Further, the ANN based sample and feature extraction techniques are found to be efficient enough to enable application of ML techniques in big data aspects as part of ASR systems. © 2015 Elsevier Ltd.","Artificial Neural Network (ANN); Automatic Speech Recognition (ASR); Deep Neural Network (DNN); Fully Focused Time Delay Neural Network (FFTDNN); Multi Layer Perceptron (MLP); Recurrent Neural Network (RNN)","Humans; India; Language; Machine Learning; Neural Networks (Computer); Speech; Speech Perception; Speech Recognition Software; Artificial intelligence; Big data; Data mining; Digital storage; Extraction; Feature extraction; Frequency domain analysis; Human computer interaction; Internet of things; Learning systems; Neural networks; Recurrent neural networks; Soft computing; Speech; Time delay; Automatic speech recognition; Deep neural networks; Focused time-delay neural networks; Multi layer perceptron; Recurrent neural network (RNN); Article; artificial neural network; Assamese (people); automatic speech recognition; classifier; controlled study; data extraction; deep neural network; feedforward neural network; female; fully focused time delay neural network; human; human computer interaction; language; machine learning; male; mood; perceptron; priority journal; recurrent neural network; India; language; physiology; speech; speech perception; Speech recognition","Elsevier Ltd","08936080","","NNETE","26783204","Article","Scopus","2-s2.0-84954286341"
"Avendi M.R.; Kheradvar A.; Jafarkhani H.","Avendi, M.R. (55587727800); Kheradvar, Arash (12806063600); Jafarkhani, Hamid (7004144452)","55587727800; 12806063600; 7004144452","A combined deep-learning and deformable-model approach to fully automatic segmentation of the left ventricle in cardiac MRI","2016","Medical Image Analysis","470","10.1016/j.media.2016.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958955334&doi=10.1016%2fj.media.2016.01.005&partnerID=40&md5=ff337ee54c00c5436c954c4776eecafb","Center for Pervasive Communications and Computing, University of California, Irvine, United States; The Edwards Lifesciences Center for Advanced Cardiovascular Technology, University of California, Irvine, United States","Avendi M.R., Center for Pervasive Communications and Computing, University of California, Irvine, United States, The Edwards Lifesciences Center for Advanced Cardiovascular Technology, University of California, Irvine, United States; Kheradvar A., The Edwards Lifesciences Center for Advanced Cardiovascular Technology, University of California, Irvine, United States; Jafarkhani H., Center for Pervasive Communications and Computing, University of California, Irvine, United States","Segmentation of the left ventricle (LV) from cardiac magnetic resonance imaging (MRI) datasets is an essential step for calculation of clinical indices such as ventricular volume and ejection fraction. In this work, we employ deep learning algorithms combined with deformable models to develop and evaluate a fully automatic LV segmentation tool from short-axis cardiac MRI datasets. The method employs deep learning algorithms to learn the segmentation task from the ground true data. Convolutional networks are employed to automatically detect the LV chamber in MRI dataset. Stacked autoencoders are used to infer the LV shape. The inferred shape is incorporated into deformable models to improve the accuracy and robustness of the segmentation. We validated our method using 45 cardiac MR datasets from the MICCAI 2009 LV segmentation challenge and showed that it outperforms the state-of-the art methods. Excellent agreement with the ground truth was achieved. Validation metrics, percentage of good contours, Dice metric, average perpendicular distance and conformity, were computed as 96.69%, 0.94, 1.81 mm and 0.86, versus those of 79.2. -95.62%, 0.87-0.9, 1.76-2.97 mm and 0.67-0.78, obtained by other methods, respectively. © 2016 Elsevier B.V.","Caridac MRI; Deep learning; Deformable models; LV segmentation; Machine learning","Algorithms; Computer Simulation; Heart Ventricles; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging, Cine; Models, Cardiovascular; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Subtraction Technique; Ventricular Dysfunction, Left; Artificial intelligence; Deformation; Heart; Learning systems; Magnetic resonance imaging; Automatic segmentations; Cardiac magnetic resonance imaging; Convolutional networks; Deep learning; Deformable modeling; Deformable models; Ejection fraction; State-of-the-art methods; accuracy; Article; cardiovascular magnetic resonance; heart left ventricle; human; learning algorithm; priority journal; algorithm; automated pattern recognition; biological model; cine magnetic resonance imaging; computer assisted diagnosis; computer simulation; diagnostic imaging; evaluation study; heart left ventricle function; heart ventricle; image enhancement; image subtraction; machine learning; procedures; reproducibility; sensitivity and specificity; validation study; Learning algorithms","Elsevier B.V.","13618415","","MIAEC","26917105","Article","Scopus","2-s2.0-84958955334"
"Kandaswamy C.; Silva L.M.; Alexandre L.A.; Santos J.M.","Kandaswamy, Chetak (56038853000); Silva, Luís M. (57210568776); Alexandre, Luís A. (8847713100); Santos, Jorge M. (7402389359)","56038853000; 57210568776; 8847713100; 7402389359","High-Content Analysis of Breast Cancer Using Single-Cell Deep Transfer Learning","2016","Journal of Biomolecular Screening","55","10.1177/1087057115623451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959185539&doi=10.1177%2f1087057115623451&partnerID=40&md5=e2f614ce19940e9953fb850bb7a7ffde","Instituto de Engenharia Biomédica (INEB), Rua do Campo Alegre, 823, Porto, 4150-180, Portugal; Instituto de Investigação e Inovação em Saúde, Universidade Do Porto, Porto, Portugal; Departamento de Engenharia Eletrotécnica e de Computadores, Faculdade de Engenharia da Universidade Do Porto, Porto, Portugal; Departamento de Matemática, Universidade de Aveiro, Aveiro, Portugal; Universidade da Beira Interior, Instituto de Telecomunicações, Covilhã, Portugal; Departamento de Matemática, Instituto Superior de Engenharia Do Instituto Politécnico Do Porto, Porto, Portugal","Kandaswamy C., Instituto de Engenharia Biomédica (INEB), Rua do Campo Alegre, 823, Porto, 4150-180, Portugal, Instituto de Investigação e Inovação em Saúde, Universidade Do Porto, Porto, Portugal, Departamento de Engenharia Eletrotécnica e de Computadores, Faculdade de Engenharia da Universidade Do Porto, Porto, Portugal; Silva L.M., Instituto de Engenharia Biomédica (INEB), Rua do Campo Alegre, 823, Porto, 4150-180, Portugal, Instituto de Investigação e Inovação em Saúde, Universidade Do Porto, Porto, Portugal, Departamento de Matemática, Universidade de Aveiro, Aveiro, Portugal; Alexandre L.A., Universidade da Beira Interior, Instituto de Telecomunicações, Covilhã, Portugal; Santos J.M., Instituto de Engenharia Biomédica (INEB), Rua do Campo Alegre, 823, Porto, 4150-180, Portugal, Instituto de Investigação e Inovação em Saúde, Universidade Do Porto, Porto, Portugal, Departamento de Matemática, Instituto Superior de Engenharia Do Instituto Politécnico Do Porto, Porto, Portugal","High-content analysis has revolutionized cancer drug discovery by identifying substances that alter the phenotype of a cell, which prevents tumor growth and metastasis. The high-resolution biofluorescence images from assays allow precise quantitative measures enabling the distinction of small molecules of a host cell from a tumor. In this work, we are particularly interested in the application of deep neural networks (DNNs), a cutting-edge machine learning method, to the classification of compounds in chemical mechanisms of action (MOAs). Compound classification has been performed using image-based profiling methods sometimes combined with feature reduction methods such as principal component analysis or factor analysis. In this article, we map the input features of each cell to a particular MOA class without using any treatment-level profiles or feature reduction methods. To the best of our knowledge, this is the first application of DNN in this domain, leveraging single-cell information. Furthermore, we use deep transfer learning (DTL) to alleviate the intensive and computational demanding effort of searching the huge parameter's space of a DNN. Results show that using this approach, we obtain a 30% speedup and a 2% accuracy improvement. © Society for Laboratory Automation and Screening.","cancer drug discovery; deep transfer learning; high-content screening; image analysis","Antineoplastic Agents; Cell Line, Tumor; Computational Biology; Drug Discovery; Female; Genetic Engineering; High-Throughput Screening Assays; Humans; Phenotype; Reproducibility of Results; Small Molecule Libraries; antineoplastic agent; molecular library; Article; artificial neural network; breast cancer; cellular distribution; content analysis; deep transfer learning; drug development; image analysis; machine learning; phenotype; principal component analysis; priority journal; single cell analysis; support vector machine; biology; female; genetic engineering; high throughput screening; human; molecular library; procedures; reproducibility; tumor cell line","SAGE Publications Inc.","10870571","","JBISF","26746583","Article","Scopus","2-s2.0-84959185539"
"Yang L.; Xie X.","Yang, Lingxiao (55793872200); Xie, Xiaohua (57192665603)","55793872200; 57192665603","Exploiting object semantic cues for Multi-label Material Recognition","2016","Neurocomputing","3","10.1016/j.neucom.2015.09.037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955196984&doi=10.1016%2fj.neucom.2015.09.037&partnerID=40&md5=ab55318ed173f3f57a064f45c81c115f","School of Information Science and Technology, Sun Yat-Sen University, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Guangdong Key Laboratory of Information Security Technology, China","Yang L., School of Information Science and Technology, Sun Yat-Sen University, China, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Xie X., School of Information Science and Technology, Sun Yat-Sen University, China, Guangdong Key Laboratory of Information Security Technology, China","Recognizing materials on an object[U+05F3]s surface is important because it significantly benefits understanding quality and functionality of the concerned object. This paper focuses on a Multi-Label Material Recognition (M-LMR) problem that is to identify multiple material categories on an object from a single photograph. As a distinct task, material categorization is different from traditional vision recognition tasks such as recognition of shapes, objects, or scenes, and cannot be explained in terms of simple feature judgments. To address this problem, besides employing state-of-the-art image descriptors (. e.g., image features learned by deep convolutional network) for distinguishing materials, we focus on exploiting object semantic cues to facilitate the M-LMR. Specifically, we derive a binary-SVM based framework that integrates image features with the object identity as input to judge surface material categories. We argue that the use of object information is essentially for exploiting correlations of material labels, where label correlations are very useful for facilitating a multi-label recognition problem. Experimental results shows consistent improvements of the presented method over state-of-the-arts, even though the object identity is automatically inferred. © 2015 Elsevier B.V.","Material recognition; Multi-label learning; Object recognition","Convolutional neural networks; Semantics; Convolutional networks; Label correlations; Material recognition; Multi-label learning; Multiple materials; Object information; Surface materials; Vision recognition; Article; association; automation; classification; conceptual framework; decision making; experimental study; mental task; multi label material recognition; photography; priority journal; semantics; support vector machine; visual memory; Object recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84955196984"
"Rasdi Rere L.M.; Fanany M.I.; Arymurthy A.M.","Rasdi Rere, L.M. (57188509100); Fanany, Mohamad Ivan (6505757323); Arymurthy, Aniati Murni (36815724000)","57188509100; 6505757323; 36815724000","Metaheuristic Algorithms for Convolution Neural Network","2016","Computational Intelligence and Neuroscience","73","10.1155/2016/1537325","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976464001&doi=10.1155%2f2016%2f1537325&partnerID=40&md5=9275749f1bce1802a7d5eb1bc11336bc","Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok, 16424, Indonesia; Computer System Laboratory, STMIK Jakarta STIandK, Jakarta, 12140, Indonesia","Rasdi Rere L.M., Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok, 16424, Indonesia, Computer System Laboratory, STMIK Jakarta STIandK, Jakarta, 12140, Indonesia; Fanany M.I., Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok, 16424, Indonesia; Arymurthy A.M., Machine Learning and Computer Vision Laboratory, Faculty of Computer Science, Universitas Indonesia, Depok, 16424, Indonesia","A typical modern optimization technique is usually either heuristic or metaheuristic. This technique has managed to solve some optimization problems in the research area of science, engineering, and industry. However, implementation strategy of metaheuristic for accuracy improvement on convolution neural networks (CNN), a famous deep learning method, is still rarely investigated. Deep learning relates to a type of machine learning technique, where its aim is to move closer to the goal of artificial intelligence of creating a machine that could successfully perform any intellectual tasks that can be carried out by a human. In this paper, we propose the implementation strategy of three popular metaheuristic approaches, that is, simulated annealing, differential evolution, and harmony search, to optimize CNN. The performances of these metaheuristic methods in optimizing CNN on classifying MNIST and CIFAR dataset were evaluated and compared. Furthermore, the proposed methods are also compared with the original CNN. Although the proposed methods show an increase in the computation time, their accuracy has also been improved (up to 7.14 percent). © 2016 L. M. Rasdi Rere et al.","","Algorithms; Artificial Intelligence; Brain; Brain Mapping; Computer Simulation; Heuristics; Humans; Neural Networks (Computer); Algorithms; Artificial intelligence; Classification (of information); Convolution; Evolutionary algorithms; Learning systems; Simulated annealing; Convolution neural network; Differential Evolution; Implementation strategies; Machine learning techniques; Meta heuristic algorithm; Meta-heuristic approach; Meta-heuristic methods; Optimization techniques; algorithm; artificial intelligence; artificial neural network; brain; brain mapping; computer simulation; heuristics; human; physiology; Optimization","Hindawi Publishing Corporation","16875265","","","27375738","Article","Scopus","2-s2.0-84976464001"
"Gregor I.; Dröge J.; Schirmer M.; Quince C.; McHardy A.C.","Gregor, Ivan (55246928900); Dröge, Johannes (55502844200); Schirmer, Melanie (56165725000); Quince, Christopher (57207562890); McHardy, Alice C. (6602304583)","55246928900; 55502844200; 56165725000; 57207562890; 6602304583","PhyloPythiaS+: A self-training method for the rapid reconstruction of low-ranking taxonomic bins from metagenomes","2016","PeerJ","64","10.7717/peerj.1603","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963969179&doi=10.7717%2fpeerj.1603&partnerID=40&md5=74c82578dc80c26c802c341dbd45583c","Max-Planck Research Group for Computational Genomics and Epidemiology, Max-Planck Institute for Informatics, Saarbrücken, Germany; Department of Algorithmic Bioinformatics, Heinrich-Heine-University Düsseldorf, Düsseldorf, Germany; Computational Biology of Infection Research, Helmholtz Center for Infection Research, Braunschweig, Germany; The Broad Institute of MIT and Harvard, Cambridge, MA, United States; School of Engineering, University of Glasgow, Glasgow, United Kingdom","Gregor I., Max-Planck Research Group for Computational Genomics and Epidemiology, Max-Planck Institute for Informatics, Saarbrücken, Germany, Department of Algorithmic Bioinformatics, Heinrich-Heine-University Düsseldorf, Düsseldorf, Germany, Computational Biology of Infection Research, Helmholtz Center for Infection Research, Braunschweig, Germany; Dröge J., Max-Planck Research Group for Computational Genomics and Epidemiology, Max-Planck Institute for Informatics, Saarbrücken, Germany, Department of Algorithmic Bioinformatics, Heinrich-Heine-University Düsseldorf, Düsseldorf, Germany, Computational Biology of Infection Research, Helmholtz Center for Infection Research, Braunschweig, Germany; Schirmer M., The Broad Institute of MIT and Harvard, Cambridge, MA, United States; Quince C., School of Engineering, University of Glasgow, Glasgow, United Kingdom; McHardy A.C., Max-Planck Research Group for Computational Genomics and Epidemiology, Max-Planck Institute for Informatics, Saarbrücken, Germany, Department of Algorithmic Bioinformatics, Heinrich-Heine-University Düsseldorf, Düsseldorf, Germany, Computational Biology of Infection Research, Helmholtz Center for Infection Research, Braunschweig, Germany","Background. Metagenomics is an approach for characterizing environmental microbial communities in situ, it allows their functional and taxonomic characterization and to recover sequences from uncultured taxa. This is often achieved by a combination of sequence assembly and binning, where sequences are grouped into `bins' representing taxa of the underlying microbial community. Assignment to low-ranking taxonomic bins is an important challenge for binning methods as is scalability to Gb-sized datasets generated with deep sequencing techniques. One of the best available methods for species bins recovery from deep-branching phyla is the expert-trained PhyloPythiaS package, where a human expert decides on the taxa to incorporate in the model and identifies `training' sequences based on marker genes directly from the sample. Due to the manual effort involved, this approach does not scale to multiple metagenome samples and requires substantial expertise, which researchers who are new to the area do not have. Results. We have developed PhyloPythiaS+, a successor to our PhyloPythia(S) software. The new (+) component performs the work previously done by the human expert. PhyloPythiaS+ also includes a new k-mer counting algorithm, which accelerated the simultaneous counting of 4-6-mers used for taxonomic binning 100-fold and reduced the overall execution time of the software by a factor of three. Our software allows to analyze Gb-sized metagenomes with inexpensive hardware, and to recover species or genera-level bins with low error rates in a fully automated fashion. PhyloPythiaS+ was compared to MEGAN, taxator-tk, Kraken and the generic PhyloPythiaS model. The results showed that PhyloPythiaS+ performs especially well for samples originating from novel environments in comparison to the other methods. Availability. PhyloPythiaS+ in a virtual machine is available for installation under Windows, Unix systems or OS X on: https://github.com/algbioi/ppsp/wiki. © 2016 Gregor et al.","Bioinformatics; Machine learning; Metagenomics; Taxonomic classification","computer program; human; intermethod comparison; machine; marker gene; metagenome; model; scientist; species","PeerJ Inc.","21678359","","","","Article","Scopus","2-s2.0-84963969179"
"Wolf M.J.; Lee E.K.; Nicolson S.C.; Pearson G.D.; Witte M.K.; Huckaby J.; Gaies M.; Shekerdemian L.S.; Mahle W.T.","Wolf, Michael J. (57214369450); Lee, Eva K. (35107386300); Nicolson, Susan C. (7005900348); Pearson, Gail D. (7201899413); Witte, Madolin K. (7102463149); Huckaby, Jeryl (6602669642); Gaies, Michael (6508176221); Shekerdemian, Lara S. (6701527800); Mahle, William T. (7004170366)","57214369450; 35107386300; 7005900348; 7201899413; 7102463149; 6602669642; 6508176221; 6701527800; 7004170366","Rationale and methodology of a collaborative learning project in congenital cardiac care","2016","American Heart Journal","28","10.1016/j.ahj.2016.01.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959131111&doi=10.1016%2fj.ahj.2016.01.013&partnerID=40&md5=13a2ddda0ee687fe97434b67a48f097e","Emory University School of Medicine, Children's Healthcare of Atlanta, Sibley Heart Center, 2835 Brandywine Rd, Atlanta, 30341, GA, United States; School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Perelman School of Medicine at the University of Pennsylvania, Children's Hospital of Philadelphia, Philadelphia, PA, United States; National Heart, Lung, and Blood Institute, National Institutes of Health, Bethesda, MD, United States; University of Utah School of Medicine, Primary Children's Hospital, Salt Lake City, UT, United States; Children's Healthcare of Atlanta, Atlanta, GA, United States; University of Michigan Medical School, CS Mott Children's Hospital, Ann Arbor, MI, United States; Baylor College of Medicine, Texas Children's Hospital, Houston, TX, United States","Wolf M.J., Emory University School of Medicine, Children's Healthcare of Atlanta, Sibley Heart Center, 2835 Brandywine Rd, Atlanta, 30341, GA, United States; Lee E.K., School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Nicolson S.C., Perelman School of Medicine at the University of Pennsylvania, Children's Hospital of Philadelphia, Philadelphia, PA, United States; Pearson G.D., National Heart, Lung, and Blood Institute, National Institutes of Health, Bethesda, MD, United States; Witte M.K., University of Utah School of Medicine, Primary Children's Hospital, Salt Lake City, UT, United States; Huckaby J., Children's Healthcare of Atlanta, Atlanta, GA, United States; Gaies M., University of Michigan Medical School, CS Mott Children's Hospital, Ann Arbor, MI, United States; Shekerdemian L.S., Baylor College of Medicine, Texas Children's Hospital, Houston, TX, United States; Mahle W.T., Emory University School of Medicine, Children's Healthcare of Atlanta, Sibley Heart Center, 2835 Brandywine Rd, Atlanta, 30341, GA, United States","Background Collaborative learning is a technique through which individuals or teams learn together by capitalizing on one another's knowledge, skills, resources, experience, and ideas. Clinicians providing congenital cardiac care may benefit from collaborative learning given the complexity of the patient population and team approach to patient care. Rationale and development Industrial system engineers first performed broad-based time-motion and process analyses of congenital cardiac care programs at 5 Pediatric Heart Network core centers. Rotating multidisciplinary team site visits to each center were completed to facilitate deep learning and information exchange. Through monthly conference calls and an in-person meeting, we determined that duration of mechanical ventilation following infant cardiac surgery was one key variation that could impact a number of clinical outcomes. This was underscored by one participating center's practice of early extubation in the majority of its patients. A consensus clinical practice guideline using collaborative learning was developed and implemented by multidisciplinary teams from the same 5 centers. The 1-year prospective initiative was completed in May 2015, and data analysis is under way. Conclusion Collaborative learning that uses multidisciplinary team site visits and information sharing allows for rapid structured fact-finding and dissemination of expertise among institutions. System modeling and machine learning approaches objectively identify and prioritize focused areas for guideline development. The collaborative learning framework can potentially be applied to other components of congenital cardiac care and provide a complement to randomized clinical trials as a method to rapidly inform and improve the care of children with congenital heart disease. © 2016 Mosby, Inc. All rights reserved.","","Cardiology; Child; Cooperative Behavior; Health Services Research; Heart Defects, Congenital; Humans; Learning Curve; Patient Care Team; analytic method; Article; artificial ventilation; clinical practice; collaborative learning; congenital heart disease; coronary care unit; extubation; health program; heart surgery; human; information processing; learning; machine learning; medical education; medical information; outcome assessment; patient care; perioperative period; practice guideline; priority journal; treatment planning; cardiology; child; cooperation; education; health services research; Heart Defects, Congenital; learning curve; procedures","Mosby Inc.","00028703","","AHJOA","26995379","Article","Scopus","2-s2.0-84959131111"
"Sheehan S.; Song Y.S.","Sheehan, Sara (55361599200); Song, Yun S. (35231093900)","55361599200; 35231093900","Deep Learning for Population Genetic Inference","2016","PLoS Computational Biology","148","10.1371/journal.pcbi.1004845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962045150&doi=10.1371%2fjournal.pcbi.1004845&partnerID=40&md5=967a2cc306598f1f982e7584d58d77fe","Department of Computer Science, Smith College, Northampton, MA, United States; Computer Science Division, UC Berkeley, Berkeley, CA, United States; Department of Statistics, UC Berkeley, Berkeley, CA, United States; Department of Integrative Biology, UC Berkeley, Berkeley, CA, United States; Department of Mathematics, University of Pennsylvania, Philadelphia, PA, United States; Department of Biology, University of Pennsylvania, Philadelphia, PA, United States","Sheehan S., Department of Computer Science, Smith College, Northampton, MA, United States, Computer Science Division, UC Berkeley, Berkeley, CA, United States; Song Y.S., Computer Science Division, UC Berkeley, Berkeley, CA, United States, Department of Statistics, UC Berkeley, Berkeley, CA, United States, Department of Integrative Biology, UC Berkeley, Berkeley, CA, United States, Department of Mathematics, University of Pennsylvania, Philadelphia, PA, United States, Department of Biology, University of Pennsylvania, Philadelphia, PA, United States","Given genomic variation data from multiple individuals, computing the likelihood of complex population genetic models is often infeasible. To circumvent this problem, we introduce a novel likelihood-free inference framework by applying deep learning, a powerful modern technique in machine learning. Deep learning makes use of multilayer neural networks to learn a feature-based function from the input (e.g., hundreds of correlated summary statistics of data) to the output (e.g., population genetic parameters of interest). We demonstrate that deep learning can be effectively employed for population genetic inference and learning informative features of data. As a concrete application, we focus on the challenging problem of jointly inferring natural selection and demography (in the form of a population size change history). Our method is able to separate the global nature of demography from the local nature of selection, without sequential steps for these two factors. Studying demography and selection jointly is motivated by Drosophila, where pervasive selection confounds demographic analysis. We apply our method to 197 African Drosophila melanogaster genomes from Zambia to infer both their overall demography, and regions of their genome under selection. We find many regions of the genome that have experienced hard sweeps, and fewer under selection on standing variation (soft sweep) or balancing selection. Interestingly, we find that soft sweeps and balancing selection occur more frequently closer to the centromere of each chromosome. In addition, our demographic inference suggests that previously estimated bottlenecks for African Drosophila melanogaster are too extreme. © 2016 Sheehan, Song.","","Animals; Drosophila melanogaster; Genetics, Population; Genomics; Machine Learning; Models, Genetic; Deep learning; Genes; Multilayer neural networks; Population dynamics; Population statistics; Balancing selection; Drosophilla melanogaster; Feature-based; Genomics; Individual computing; Learn+; Machine-learning; Modern techniques; Population genetic models; Population genetics; Article; centromere; controlled study; deel learning algorithm; demography; directional selection; Drosophila melanogaster; gene segregation; genetic algorithm; genetic recombination; mutation rate; nonhuman; population genetics; population size; systematic error; validation process; animal; biological model; genetics; genomics; machine learning; population genetics; procedures; Demography","Public Library of Science","1553734X","","","27018908","Article","Scopus","2-s2.0-84962045150"
"Anthimopoulos M.; Christodoulidis S.; Ebner L.; Christe A.; Mougiakakou S.","Anthimopoulos, Marios (25653065900); Christodoulidis, Stergios (56648066500); Ebner, Lukas (55520061700); Christe, Andreas (14629950700); Mougiakakou, Stavroula (6603242680)","25653065900; 56648066500; 55520061700; 14629950700; 6603242680","Lung Pattern Classification for Interstitial Lung Diseases Using a Deep Convolutional Neural Network","2016","IEEE Transactions on Medical Imaging","1010","10.1109/TMI.2016.2535865","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968662241&doi=10.1109%2fTMI.2016.2535865&partnerID=40&md5=63770a7991d8a676ffab439f244b440f","ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, 3008, Switzerland; Department of Diagnostic, Interventional and Pediatric Radiology, Bern University Hospital Inselspital, Bern, 3010, Switzerland; Department of Emergency Medicine, Bern University Hospital Inselspital, Bern, 3010, Switzerland","Anthimopoulos M., ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, 3008, Switzerland, Department of Diagnostic, Interventional and Pediatric Radiology, Bern University Hospital Inselspital, Bern, 3010, Switzerland, Department of Emergency Medicine, Bern University Hospital Inselspital, Bern, 3010, Switzerland; Christodoulidis S., ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, 3008, Switzerland; Ebner L., Department of Diagnostic, Interventional and Pediatric Radiology, Bern University Hospital Inselspital, Bern, 3010, Switzerland; Christe A., Department of Diagnostic, Interventional and Pediatric Radiology, Bern University Hospital Inselspital, Bern, 3010, Switzerland; Mougiakakou S., ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, 3008, Switzerland, Department of Diagnostic, Interventional and Pediatric Radiology, Bern University Hospital Inselspital, Bern, 3010, Switzerland","Automated tissue characterization is one of the most crucial components of a computer aided diagnosis (CAD) system for interstitial lung diseases (ILDs). Although much research has been conducted in this field, the problem remains challenging. Deep learning techniques have recently achieved impressive results in a variety of computer vision problems, raising expectations that they might be applied in other domains, such as medical image analysis. In this paper, we propose and evaluate a convolutional neural network (CNN), designed for the classification of ILD patterns. The proposed network consists of 5 convolutional layers with 2 x 2 kernels and LeakyReLU activations, followed by average pooling with size equal to the size of the final feature maps and three dense layers. The last dense layer has 7 outputs, equivalent to the classes considered: healthy, ground glass opacity (GGO), micronodules, consolidation, reticulation, honeycombing and a combination of GGO/reticulation. To train and evaluate the CNN, we used a dataset of 14696 image patches, derived by 120 CT scans from different scanners and hospitals. To the best of our knowledge, this is the first deep CNN designed for the specific problem. A comparative analysis proved the effectiveness of the proposed CNN against previous methods in a challenging dataset. The classification performance (∼85.5%) demonstrated the potential of CNNs in analyzing lung patterns. Future work includes, extending the CNN to three-dimensional data provided by CT volume scans and integrating the proposed method into a CAD system that aims to provide differential diagnosis for ILDs as a supportive tool for radiologists. © 1982-2012 IEEE.","Convolutional neural networks; interstitial lung diseases; texture classification","Algorithms; Humans; Image Interpretation, Computer-Assisted; Lung; Lung Diseases, Interstitial; Neural Networks (Computer); Tomography, X-Ray Computed; Biological organs; Computer vision; Computerized tomography; Convolution; Diagnosis; Equivalence classes; Medical imaging; Medical problems; Neural networks; Pulmonary diseases; Classification performance; Computer Aided Diagnosis(CAD); Computer vision problems; Convolutional neural network; Differential diagnosis; Interstitial lung disease; Texture classification; Three-dimensional data; Article; artificial neural network; classifier; computer assisted diagnosis; computer assisted tomography; convolutional neural network; differential diagnosis; disease classification; entropy; image analysis; interstitial lung disease; k nearest neighbor; lung parenchyma; multidetector computed tomography; random forest; receptive field; support vector machine; tissue characterization; algorithm; diagnostic imaging; human; interstitial lung disease; lung; procedures; x-ray computed tomography; Computer aided diagnosis","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26955021","Article","Scopus","2-s2.0-84968662241"
"Zhen X.; Wang Z.; Islam A.; Bhaduri M.; Chan I.; Li S.","Zhen, Xiantong (55276656300); Wang, Zhijie (36062078000); Islam, Ali (7103365997); Bhaduri, Mousumi (26432538700); Chan, Ian (57219956447); Li, Shuo (57189925356)","55276656300; 36062078000; 7103365997; 26432538700; 57219956447; 57189925356","Multi-scale deep networks and regression forests for direct bi-ventricular volume estimation","2016","Medical Image Analysis","100","10.1016/j.media.2015.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958981335&doi=10.1016%2fj.media.2015.07.003&partnerID=40&md5=c743a60262122b098db6f1cb2dd3e6ce","The University of Western Ontario, London, ON, Canada; Digital Image Group (DIG), London, ON, Canada; GE Healthcare, London, ON, Canada; St. Joseph's Health Care, London, ON, Canada; London Healthcare Sciences Centre, ON, London, Canada","Zhen X., The University of Western Ontario, London, ON, Canada, Digital Image Group (DIG), London, ON, Canada; Wang Z., GE Healthcare, London, ON, Canada; Islam A., St. Joseph's Health Care, London, ON, Canada; Bhaduri M., London Healthcare Sciences Centre, ON, London, Canada; Chan I., London Healthcare Sciences Centre, ON, London, Canada; Li S., The University of Western Ontario, London, ON, Canada, Digital Image Group (DIG), London, ON, Canada, GE Healthcare, London, ON, Canada","Direct estimation of cardiac ventricular volumes has become increasingly popular and important in cardiac function analysis due to its effectiveness and efficiency by avoiding an intermediate segmentation step. However, existing methods rely on either intensive user inputs or problematic assumptions. To realize the full capacities of direct estimation, this paper presents a general, fully learning-based framework for direct bi-ventricular volume estimation, which removes user inputs and unreliable assumptions. We formulate bi-ventricular volume estimation as a general regression framework which consists of two main full learning stages: unsupervised cardiac image representation learning by multi-scale deep networks and direct bi-ventricular volume estimation by random forests.By leveraging strengths of generative and discriminant learning, the proposed method produces high correlations of around 0.92 with ground truth by human experts for both the left and right ventricles using a leave-one-subject-out cross validation, and largely outperforms existing direct methods on a larger dataset of 100 subjects including both healthy and diseased cases with twice the number of subjects used in previous methods. More importantly, the proposed method can not only be practically used in clinical cardiac function analysis but also be easily extended to other organ volume estimation tasks. © 2015 Elsevier B.V.","Direct volume estimation; Multi-scale deep networks; Random forests; Regression","Algorithms; Heart Ventricles; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Neural Networks (Computer); Organ Size; Pattern Recognition, Automated; Regression Analysis; Reproducibility of Results; Sensitivity and Specificity; Stroke Volume; Ventricular Dysfunction; Decision trees; Random forests; Cardiac function analysis; Cardiac images; Cross validation; Effectiveness and efficiencies; Regression; Regression forests; Right ventricle; Volume estimations; Article; biventricular assist device; cardiac imaging; computer network; conceptual framework; controlled study; discriminant analysis; expert system; heart left ventricle; heart right ventricle; heart volume; human; jackknife test; priority journal; random forest; regression analysis; algorithm; artificial neural network; automated pattern recognition; computer assisted diagnosis; diagnostic imaging; heart stroke volume; heart ventricle; heart ventricle function; image enhancement; machine learning; organ size; procedures; regression analysis; reproducibility; sensitivity and specificity; three dimensional imaging; Heart","Elsevier B.V.","13618415","","MIAEC","26919699","Article","Scopus","2-s2.0-84958981335"
"Janowczyk A.; Madabhushi A.","Janowczyk, Andrew (26531344300); Madabhushi, Anant (6603019206)","26531344300; 6603019206","Deep learning for digital pathology image analysis: A comprehensive tutorial with selected use cases","2016","Journal of Pathology Informatics","866","10.4103/2153-3539.186902","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009238256&doi=10.4103%2f2153-3539.186902&partnerID=40&md5=1b2fa6a54ec22277c5f5f14e9fdfe6e3","Department of Biomedical Engineering, Case Western Reserve University, Cleveland, 44106, OH, United States","Janowczyk A., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, 44106, OH, United States; Madabhushi A., Department of Biomedical Engineering, Case Western Reserve University, Cleveland, 44106, OH, United States","Background: Deep learning (DL) is a representation learning approach ideally suited for image analysis challenges in digital pathology (DP). The variety of image analysis tasks in the context of DP includes detection and counting (e.g., mitotic events), segmentation (e.g., nuclei), and tissue classification (e.g., cancerous vs. non-cancerous). Unfortunately, issues with slide preparation, variations in staining and scanning across sites, and vendor platforms, as well as biological variance, such as the presentation of different grades of disease, make these image analysis tasks particularly challenging. Traditional approaches, wherein domain-specific cues are manually identified and developed into task-specific handcrafted features, can require extensive tuning to accommodate these variances. However, DL takes a more domain agnostic approach combining both feature discovery and implementation to maximally discriminate between the classes of interest. While DL approaches have performed well in a few DP related image analysis tasks, such as detection and tissue classification, the currently available open source tools and tutorials do not provide guidance on challenges such as (a) selecting appropriate magnification, (b) managing errors in annotations in the training (or learning) dataset, and (c) identifying a suitable training set containing information rich exemplars. These foundational concepts, which are needed to successfully translate the DL paradigm to DP tasks, are non-trivial for (i) DL experts with minimal digital histology experience, and (ii) DP and image processing experts with minimal DL experience, to derive on their own, thus meriting a dedicated tutorial. Aims: This paper investigates these concepts through seven unique DP tasks as use cases to elucidate techniques needed to produce comparable, and in many cases, superior to results from the state-of-the-art hand-crafted feature-based classification approaches. Results : Specifically, in this tutorial on DL for DP image analysis, we show how an open source framework (Caffe), with a singular network architecture, can be used to address: (a) nuclei segmentation (F-score of 0.83 across 12,000 nuclei), (b) epithelium segmentation (F-score of 0.84 across 1735 regions), (c) tubule segmentation (F-score of 0.83 from 795 tubules), (d) lymphocyte detection (F-score of 0.90 across 3064 lymphocytes), (e) mitosis detection (F-score of 0.53 across 550 mitotic events), (f) invasive ductal carcinoma detection (F-score of 0.7648 on 50 k testing patches), and (g) lymphoma classification (classification accuracy of 0.97 across 374 images). Conclusion: This paper represents the largest comprehensive study of DL approaches in DP to date, with over 1200 DP images used during evaluation. The supplemental online material that accompanies this paper consists of step-by-step instructions for the usage of the supplied source code, trained models, and input data. © 2016 Journal of Pathology Informatics | Published by Wolters Kluwer -Medknow.","Classification; deep learning; detection; digital histology; machine learning; segmentation","","Medknow Publications","22295089","","","","Article","Scopus","2-s2.0-85009238256"
"Shin H.-C.; Roth H.R.; Gao M.; Lu L.; Xu Z.; Nogues I.; Yao J.; Mollura D.; Summers R.M.","Shin, Hoo-Chang (56903407200); Roth, Holger R. (36622444300); Gao, Mingchen (55424598500); Lu, Le (55474685200); Xu, Ziyue (35209309700); Nogues, Isabella (56921932100); Yao, Jianhua (57693843200); Mollura, Daniel (8886027300); Summers, Ronald M. (7202364932)","56903407200; 36622444300; 55424598500; 55474685200; 35209309700; 56921932100; 57693843200; 8886027300; 7202364932","Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning","2016","IEEE Transactions on Medical Imaging","4165","10.1109/TMI.2016.2528162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969962996&doi=10.1109%2fTMI.2016.2528162&partnerID=40&md5=32d46cbe4a8a3365d0026af444019535","Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Center for Infectious Disease Imaging, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Clinical Image Processing Service, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States","Shin H.-C., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Roth H.R., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Gao M., Center for Infectious Disease Imaging, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Lu L., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States, Clinical Image Processing Service, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Xu Z., Center for Infectious Disease Imaging, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Nogues I., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Yao J., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States, Clinical Image Processing Service, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Mollura D., Center for Infectious Disease Imaging, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States; Summers R.M., Imaging Biomarkers and Computer-Aided Diagnosis Laboratory, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States, Clinical Image Processing Service, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, 20892, MD, United States","Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks. © 2015 IEEE.","Biomedical imaging; computer aided diagnosis; image analysis; machine learning; neural networks","Databases, Factual; Diagnosis, Computer-Assisted; Humans; Image Interpretation, Computer-Assisted; Lung Diseases, Interstitial; Lymph Nodes; Neural Networks (Computer); Reproducibility of Results; Artificial intelligence; Computer aided analysis; Computer aided instruction; Computer networks; Computerized tomography; Convolution; Diagnosis; Image analysis; Image classification; Image recognition; Learning systems; Medical imaging; Network architecture; Neural networks; Pulmonary diseases; Abdominal lymph nodes; Biomedical imaging; Classification results; Computer aided detection; Convolutional neural network; Empirical evaluations; Interstitial lung disease; State-of-the-art performance; architecture; Article; classification; computer aided design; computer assisted tomography; convolutional neural network; diagnostic imaging; human; interstitial lung disease; lymph node; machine learning; major clinical study; support vector machine; task performance; artificial neural network; computer assisted diagnosis; factual database; procedures; reproducibility; Computer aided diagnosis","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26886976","Article","Scopus","2-s2.0-84969962996"
"Turkki R.; Linder N.; Kovanen P.E.; Pellinen T.; Lundin J.","Turkki, Riku (55043262100); Linder, Nina (7005892563); Kovanen, Panu E. (7101612468); Pellinen, Teijo (7004176178); Lundin, Johan (7005938363)","55043262100; 7005892563; 7101612468; 7004176178; 7005938363","Antibody-supervised deep learning for quantification of tumor-infiltrating immune cells in hematoxylin and eosin stained breast cancer samples","2016","Journal of Pathology Informatics","78","10.4103/2153-3539.189703","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009285527&doi=10.4103%2f2153-3539.189703&partnerID=40&md5=04600cdc3dcf3e5916da383f72fca215","Institute for Molecular Medicine Finland, University of Helsinki, Helsinki, Finland; Department of Pathology, HUSLAB and Haartman Institute, Helsinki University Central Hospital, University of Helsinki, Helsinki, Finland; Department of Public Health Sciences, Global Health (IHCAR), Karolinska Institutet, Stockholm, Sweden","Turkki R., Institute for Molecular Medicine Finland, University of Helsinki, Helsinki, Finland; Linder N., Institute for Molecular Medicine Finland, University of Helsinki, Helsinki, Finland; Kovanen P.E., Department of Pathology, HUSLAB and Haartman Institute, Helsinki University Central Hospital, University of Helsinki, Helsinki, Finland; Pellinen T., Institute for Molecular Medicine Finland, University of Helsinki, Helsinki, Finland; Lundin J., Institute for Molecular Medicine Finland, University of Helsinki, Helsinki, Finland, Department of Public Health Sciences, Global Health (IHCAR), Karolinska Institutet, Stockholm, Sweden","Background: Immune cell infiltration in tumor is an emerging prognostic biomarker in breast cancer. The gold standard for quantification of immune cells in tissue sections is visual assessment through a microscope, which is subjective and semi-quantitative. In this study, we propose and evaluate an approach based on antibody-guided annotation and deep learning to quantify immune cell-rich areas in hematoxylin and eosin (H&E) stained samples. Methods: Consecutive sections of formalin-fixed parafin-embedded samples obtained from the primary tumor of twenty breast cancer patients were cut and stained with H&E and the pan-leukocyte CD45 antibody. The stained slides were digitally scanned, and a training set of immune cell-rich and cell-poor tissue regions was annotated in H&E whole-slide images using the CD45-expression as a guide. In analysis, the images were divided into small homogenous regions, superpixels, from which features were extracted using a pretrained convolutional neural network (CNN) and classified with a support of vector machine. The CNN approach was compared to texture-based classification and to visual assessments performed by two pathologists. Results: In a set of 123,442 labeled superpixels, the CNN approach achieved an F-score of 0.94 (range: 0.92-0.94) in discrimination of immune cell-rich and cell-poor regions, as compared to an F-score of 0.88 (range: 0.87-0.89) obtained with the texture-based classification. When compared to visual assessment of 200 images, an agreement of 90% (k = 0.79) to quantify immune infiltration with the CNN approach was achieved while the inter-observer agreement between pathologists was 90% (k = 0.78). Conclusions: Our findings indicate that deep learning can be applied to quantify immune cell infiltration in breast cancer samples using a basic morphology staining only. A good discrimination of immune cell-rich areas was achieved, well in concordance with both leukocyte antigen expression and pathologists' visual assessment. © 2016 Journal of Pathology Informatics | Published by Wolters Kluwer -Medknow.","breast cancer; convolutional neural network; digital pathology; tumor microenvironment; tumor-infiltrating immune cells","","Medknow Publications","22295089","","","","Article","Scopus","2-s2.0-85009285527"
"Pallotto M.; Watkins P.V.; Fubara B.; Singer J.H.; Briggman K.L.","Pallotto, Marta (35243494400); Watkins, Paul V. (24385148500); Fubara, Boma (6602417178); Singer, Joshua H. (7402619982); Briggman, Kevin L. (6602301153)","35243494400; 24385148500; 6602417178; 7402619982; 6602301153","Extracellular space preservation aids the connectomic analysis of neural circuits","2015","eLife","58","10.7554/eLife.08206","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983421094&doi=10.7554%2feLife.08206&partnerID=40&md5=e19563d4c5e396bb607f7433c9597250","Circuit Dynamics and Connectivity Unit, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, United States; Department of Biology, University of Maryland, College Park, United States; Department of Biomedical Optics, Max Planck Institute for Medical Research, Heidelberg, Germany","Pallotto M., Circuit Dynamics and Connectivity Unit, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, United States; Watkins P.V., Circuit Dynamics and Connectivity Unit, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, United States; Fubara B., Circuit Dynamics and Connectivity Unit, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, United States; Singer J.H., Department of Biology, University of Maryland, College Park, United States; Briggman K.L., Circuit Dynamics and Connectivity Unit, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, United States, Department of Biomedical Optics, Max Planck Institute for Medical Research, Heidelberg, Germany","Dense connectomic mapping of neuronal circuits is limited by the time and effort required to analyze 3D electron microscopy (EM) datasets. Algorithms designed to automate image segmentation suffer from substantial error rates and require significant manual error correction. Any improvement in segmentation error rates would therefore directly reduce the time required to analyze 3D EM data. We explored preserving extracellular space (ECS) during chemical tissue fixation to improve the ability to segment neurites and to identify synaptic contacts. ECS preserved tissue is easier to segment using machine learning algorithms, leading to significantly reduced error rates. In addition, we observed that electrical synapses are readily identified in ECS preserved tissue. Finally, we determined that antibodies penetrate deep into ECS preserved tissue with only minimal permeabilization, thereby enabling correlated light microscopy (LM) and EM studies. We conclude that preservation of ECS benefits multiple aspects of the connectomic analysis of neural circuits. © 2015, eLife Sciences Publications Ltd. All rights reserved.","","Animals; Connectome; Extracellular Space; Imaging, Three-Dimensional; Mice, Inbred C57BL; Specimen Handling; Tissue Preservation; animal experiment; animal tissue; antibody labeling; Article; cell permeabilization; connectome; controlled study; electrical synapse; electron microscopy; electron tomography; extracellular space; gap junction; image segmentation; immunodiffusion; immunohistochemistry; mouse; neurite; neuropil; nonhuman; retinal tissue; tissue fixation; animal; C57BL mouse; connectome; evaluation study; procedures; specimen handling; three dimensional imaging; tissue preservation","eLife Sciences Publications Ltd","2050084X","","","26650352","Article","Scopus","2-s2.0-84983421094"
"Huynh B.Q.; Li H.; Giger M.L.","Huynh, Benjamin Q. (57210935985); Li, Hui (56986807700); Giger, Maryellen L. (7103040897)","57210935985; 56986807700; 7103040897","Digital mammographic tumor classification using transfer learning from deep convolutional neural networks","2016","Journal of Medical Imaging","414","10.1117/1.JMI.3.3.034501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000428361&doi=10.1117%2f1.JMI.3.3.034501&partnerID=40&md5=e26981f80c77d842135c5df002918c79","University of Chicago, Department of Radiology, 5841 South Maryland Avenue, Chicago, 60637, IL, United States","Huynh B.Q., University of Chicago, Department of Radiology, 5841 South Maryland Avenue, Chicago, 60637, IL, United States; Li H., University of Chicago, Department of Radiology, 5841 South Maryland Avenue, Chicago, 60637, IL, United States; Giger M.L., University of Chicago, Department of Radiology, 5841 South Maryland Avenue, Chicago, 60637, IL, United States","Convolutional neural networks (CNNs) show potential for computer-aided diagnosis (CADx) by learning features directly from the image data instead of using analytically extracted features. However, CNNs are difficult to train from scratch for medical images due to small sample sizes and variations in tumor presentations. Instead, transfer learning can be used to extract tumor information from medical images via CNNs originally pretrained for nonmedical tasks, alleviating the need for large datasets. Our database includes 219 breast lesions (607 full-field digital mammographic images). We compared support vector machine classifiers based on the CNN-extracted image features and our prior computer-extracted tumor features in the task of distinguishing between benign and malignant breast lesions. Five-fold cross validation (by lesion) was conducted with the area under the receiver operating characteristic (ROC) curve as the performance metric. Results show that classifiers based on CNN-extracted features (with transfer learning) perform comparably to those using analytically extracted features [area under the ROC curve (AUC)=0.81]. Further, the performance of ensemble classifiers based on both types was significantly better than that of either classifier type alone (AUC=0.86 versus 0.81, p=0.022). We conclude that transfer learning can improve current CADx methods while also providing standalone classifiers without large datasets, facilitating machine-learning methods in radiomics and precision medicine. © 2016 Society of Photo-Optical Instrumentation Engineers (SPIE).","computer-aided diagnosis radiomics; convolutional neural networks; deep learning; mammography; precision medicine; transfer learning","Article; artificial neural network; breast cancer; breast lesion; computer assisted diagnosis; convolutional neural network; digital mammography; image analysis; learning; receiver operating characteristic; support vector machine; tumor classification","SPIE","23294302","","","","Article","Scopus","2-s2.0-85000428361"
"Guo Y.; Gao Y.; Shen D.","Guo, Yanrong (24764663200); Gao, Yaozong (55386386400); Shen, Dinggang (7401738392)","24764663200; 55386386400; 7401738392","Deformable MR Prostate Segmentation via Deep Feature Learning and Sparse Patch Matching","2016","IEEE Transactions on Medical Imaging","208","10.1109/TMI.2015.2508280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963878431&doi=10.1109%2fTMI.2015.2508280&partnerID=40&md5=8d0c6570d1c0b48ae55893dc3866c609","Department of Radiology, BRIC, University of North Carolina, Chapel Hill, 27599, NC, United States; Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, South Korea","Guo Y., Department of Radiology, BRIC, University of North Carolina, Chapel Hill, 27599, NC, United States; Gao Y., Department of Radiology, BRIC, University of North Carolina, Chapel Hill, 27599, NC, United States; Shen D., Department of Radiology, BRIC, University of North Carolina, Chapel Hill, 27599, NC, United States, Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, South Korea","Automatic and reliable segmentation of the prostate is an important but difficult task for various clinical applications such as prostate cancer radiotherapy. The main challenges for accurate MR prostate localization lie in two aspects: (1) inhomogeneous and inconsistent appearance around prostate boundary, and (2) the large shape variation across different patients. To tackle these two problems, we propose a new deformable MR prostate segmentation method by unifying deep feature learning with the sparse patch matching. First, instead of directly using handcrafted features, we propose to learn the latent feature representation from prostate MR images by the stacked sparse auto-encoder (SSAE). Since the deep learning algorithm learns the feature hierarchy from the data, the learned features are often more concise and effective than the handcrafted features in describing the underlying data. To improve the discriminability of learned features, we further refine the feature representation in a supervised fashion. Second, based on the learned features, a sparse patch matching method is proposed to infer a prostate likelihood map by transferring the prostate labels from multiple atlases to the new prostate MR image. Finally, a deformable segmentation is used to integrate a sparse shape model with the prostate likelihood map for achieving the final segmentation. The proposed method has been extensively evaluated on the dataset that contains 66 T2-wighted prostate MR images. Experimental results show that the deep-learned features are more effective than the handcrafted features in guiding MR prostate segmentation. Moreover, our method shows superior performance than other state-of-the-art segmentation methods. © 2015 IEEE.","Deformable model; MR prostate segmentation; sparse patch matching; stacked sparse auto-encoder (SSAE)","Algorithms; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Prostate; Deformation; Diseases; Image matching; Image segmentation; Learning algorithms; Learning systems; Magnetic resonance imaging; Auto encoders; Deep feature learning; Deformable modeling; Deformable segmentation; Feature representation; Patch matching; Prostate localization; Prostate segmentation; experimental model; learning; learning algorithm; model; prostate; algorithm; diagnostic imaging; human; machine learning; male; nuclear magnetic resonance imaging; procedures; prostate; Urology","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26685226","Article","Scopus","2-s2.0-84963878431"
"Afaq Ali Shah S.; Bennamoun M.; Boussaid F.","Afaq Ali Shah, Syed (57000456400); Bennamoun, Mohammed (7004376121); Boussaid, Farid (6602749360)","57000456400; 7004376121; 6602749360","Iterative deep learning for image set based face and object recognition","2016","Neurocomputing","70","10.1016/j.neucom.2015.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949676604&doi=10.1016%2fj.neucom.2015.10.004&partnerID=40&md5=15bbbe7e0e16e70011575e110cf5078a","School of Computer Science and Software Engineering, The University of Western Australia, Perth, 6009, Australia; School of Electrical, Electronics and Computer Engineering, The University of Western Australia, Perth, 6009, Australia","Afaq Ali Shah S., School of Computer Science and Software Engineering, The University of Western Australia, Perth, 6009, Australia; Bennamoun M., School of Computer Science and Software Engineering, The University of Western Australia, Perth, 6009, Australia; Boussaid F., School of Electrical, Electronics and Computer Engineering, The University of Western Australia, Perth, 6009, Australia","We present a novel technique for image set based face/object recognition, where each gallery and query example contains a face/object image set captured from different viewpoints, background, facial expressions, resolution and illumination levels. While several image set classification approaches have been proposed in recent years, most of them represent each image set as a single linear subspace, mixture of linear subspaces or Lie group of Riemannian manifold. These techniques make prior assumptions in regards to the specific category of the geometric surface on which images of the set are believed to lie. This could result in a loss of discriminative information for classification. This paper alleviates these limitations by proposing an Iterative Deep Learning Model (IDLM) that automatically and hierarchically learns discriminative representations from raw face and object images. In the proposed approach, low level translationally invariant features are learnt by the Pooled Convolutional Layer (PCL). The latter is followed by Artificial Neural Networks (ANNs) applied iteratively in a hierarchical fashion to learn a discriminative non-linear feature representation of the input image sets. The proposed technique was extensively evaluated for the task of image set based face and object recognition on YouTube Celebrities, Honda/UCSD, CMU Mobo and ETH-80 (object) dataset, respectively. Experimental results and comparisons with state-of-the-art methods show that our technique achieves the best performance on all these datasets. © 2015 Elsevier B.V..","Face/object recognition; Image set classification","Classification (of information); Image classification; Iterative methods; Lie groups; Neural networks; Object recognition; Classification approach; Face/object recognition; Facial Expressions; Illumination levels; Image sets; Mixture of linear subspaces; Riemannian manifold; State-of-the-art methods; Article; artificial neural network; automated pattern recognition; classification algorithm; discrimination learning; facial expression; human computer interaction; image analysis; information processing; iterative deep learning model; machine learning; mathematical computing; mathematical model; priority journal; Face recognition","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84949676604"
"Che Z.; Purushotham S.; Khemani R.; Liu Y.","Che, Zhengping (56719288000); Purushotham, Sanjay (54882660300); Khemani, Robinder (24343841000); Liu, Yan (57196313067)","56719288000; 54882660300; 24343841000; 57196313067","Interpretable Deep Models for ICU Outcome Prediction","2016","AMIA ... Annual Symposium proceedings. AMIA Symposium","199","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027974126&partnerID=40&md5=675088ab63c220ccf25496e33990ea75","Children's Hospital Los Angeles, Los Angeles, CA, United States; Children's Hospital Los Angeles, Los Angeles, CA, United States","Che Z., Children's Hospital Los Angeles, Los Angeles, CA, United States; Purushotham S., Children's Hospital Los Angeles, Los Angeles, CA, United States; Khemani R., Children's Hospital Los Angeles, Los Angeles, CA, United States; Liu Y., Children's Hospital Los Angeles, Los Angeles, CA, United States","Exponential surge in health care data, such as longitudinal data from electronic health records (EHR), sensor data from intensive care unit (ICU), etc., is providing new opportunities to discover meaningful data-driven characteristics and patterns ofdiseases. Recently, deep learning models have been employedfor many computational phenotyping and healthcare prediction tasks to achieve state-of-the-art performance. However, deep models lack interpretability which is crucial for wide adoption in medical research and clinical decision-making. In this paper, we introduce a simple yet powerful knowledge-distillation approach called interpretable mimic learning, which uses gradient boosting trees to learn interpretable models and at the same time achieves strong prediction performance as deep learning models. Experiment results on Pediatric ICU dataset for acute lung injury (ALI) show that our proposed method not only outperforms state-of-the-art approaches for morality and ventilator free days prediction tasks but can also provide interpretable models to clinicians.","","Acute Lung Injury; Computer Simulation; Electronic Health Records; Humans; Intensive Care Units, Pediatric; Machine Learning; Models, Theoretical; Neural Networks (Computer); Prognosis; acute lung injury; artificial neural network; computer simulation; electronic health record; human; machine learning; pediatric intensive care unit; prognosis; theoretical model","","1942597X","","","28269832","Article","Scopus","2-s2.0-85027974126"
"Karakida R.; Okada M.; Amari S.-I.","Karakida, Ryo (55763033900); Okada, Masato (55229626500); Amari, Shun-ichi (35553922600)","55763033900; 55229626500; 35553922600","Dynamical analysis of contrastive divergence learning: Restricted Boltzmann machines with Gaussian visible units","2016","Neural Networks","37","10.1016/j.neunet.2016.03.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964528780&doi=10.1016%2fj.neunet.2016.03.013&partnerID=40&md5=0f604ae64bcedbff4983dc0b950b90b8","Department of Complexity Science and Engineering, The University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa-shi, Chiba, 277-8561, Japan; RIKEN Brain Science Institute, 2-1 Hirosawa, Wako-shi, Saitama, 351-0198, Japan","Karakida R., Department of Complexity Science and Engineering, The University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa-shi, Chiba, 277-8561, Japan; Okada M., Department of Complexity Science and Engineering, The University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa-shi, Chiba, 277-8561, Japan, RIKEN Brain Science Institute, 2-1 Hirosawa, Wako-shi, Saitama, 351-0198, Japan; Amari S.-I., RIKEN Brain Science Institute, 2-1 Hirosawa, Wako-shi, Saitama, 351-0198, Japan","The restricted Boltzmann machine (RBM) is an essential constituent of deep learning, but it is hard to train by using maximum likelihood (ML) learning, which minimizes the Kullback-Leibler (KL) divergence. Instead, contrastive divergence (CD) learning has been developed as an approximation of ML learning and widely used in practice. To clarify the performance of CD learning, in this paper, we analytically derive the fixed points where ML and CDn learning rules converge in two types of RBMs: one with Gaussian visible and Gaussian hidden units and the other with Gaussian visible and Bernoulli hidden units. In addition, we analyze the stability of the fixed points. As a result, we find that the stable points of CDn learning rule coincide with those of ML learning rule in a Gaussian-Gaussian RBM. We also reveal that larger principal components of the input data are extracted at the stable points. Moreover, in a Gaussian-Bernoulli RBM, we find that both ML and CDn learning can extract independent components at one of stable points. Our analysis demonstrates that the same feature components as those extracted by ML learning are extracted simply by performing CD1 learning. Expanding this study should elucidate the specific solutions obtained by CD learning in other types of RBMs or in deep networks. © 2016 Elsevier Ltd.","Component analysis; Contrastive divergence; Deep learning; Restricted Boltzmann machine; Stability of learning algorithms","Algorithms; Learning; Machine Learning; Neural Networks (Computer); Normal Distribution; Probability Learning; Gaussian distribution; Maximum likelihood; Component analysis; Contrastive divergence; Deep learning; Dynamical analysis; Independent components; Kullback-Leibler divergence; Principal Components; Restricted boltzmann machine; analytical parameters; Article; contrastive divergence learning; data processing; Gaussian hidden unit; Gaussian visible unit; learning algorithm; maximum likelihood method; principal component analysis; priority journal; restricted Boltzmann machine; algorithm; artificial neural network; learning; machine learning; normal distribution; Learning algorithms","Elsevier Ltd","08936080","","NNETE","27131468","Article","Scopus","2-s2.0-84964528780"
"Welchowski T.; Schmid M.","Welchowski, Thomas (56507319500); Schmid, Matthias (55684265900)","56507319500; 55684265900","A framework for parameter estimation and model selection in kernel deep stacking networks","2016","Artificial Intelligence in Medicine","9","10.1016/j.artmed.2016.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973151881&doi=10.1016%2fj.artmed.2016.04.002&partnerID=40&md5=963df5092472262c625b77101207cac9","Department of Medical Biometry, Informatics and Epidemiology, Rheinische Friedrich-Wilhelms-Universität Bonn, Sigmund-Freud-Str. 25, Bonn, 53127, Germany","Welchowski T., Department of Medical Biometry, Informatics and Epidemiology, Rheinische Friedrich-Wilhelms-Universität Bonn, Sigmund-Freud-Str. 25, Bonn, 53127, Germany; Schmid M., Department of Medical Biometry, Informatics and Epidemiology, Rheinische Friedrich-Wilhelms-Universität Bonn, Sigmund-Freud-Str. 25, Bonn, 53127, Germany","Background and objectives: Kernel deep stacking networks (KDSNs) are a novel method for supervised learning in biomedical research. Belonging to the class of deep learning techniques, KDSNs are based on artificial neural network architectures that involve multiple nonlinear transformations of the input data. Unlike traditional artificial neural networks, KDSNs do not rely on backpropagation algorithms but on an efficient fitting procedure that is based on a series of kernel ridge regression models with closed-form solutions. Although being computationally advantageous, KDSN modeling remains a challenging task, as it requires the specification of a large number of tuning parameters. Methods and material: We propose a new data-driven framework for parameter estimation, hyperparameter tuning, and model selection in KDSNs. The proposed methodology is based on a combination of model-based optimization and hill climbing approaches that do not require the pre-specification of any of the KDSN tuning parameters. We demonstrate the performance of KDSNs by analyzing three medical data sets on hospital readmission of diabetes patients, coronary artery disease, and hospital costs. Results: Our numerical studies show that the run-time of the proposed KDSN methodology is significantly shorter than the respective run-time of grid search strategies for hyperparameter tuning. They also show that KDSN modeling is competitive in terms of prediction accuracy with other state-of-the-art techniques for statistical learning. Conclusions: KDSNs are a computationally efficient approximation of backpropagation-based artificial neural network techniques. Application of the proposed methodology results in a fast tuning procedure that generates KDSN fits having a similar prediction accuracy as other techniques in the field of deep learning. © 2016 Elsevier B.V..","Artificial neural networks; Deep learning; Kernel regression; Model-based optimization","Algorithms; Coronary Artery Disease; Diabetes Mellitus; Hospital Costs; Humans; Machine Learning; Neural Networks (Computer); Backpropagation; Backpropagation algorithms; Diseases; Hospitals; Mathematical transformations; Network architecture; Neural networks; Optimization; Regression analysis; Specifications; Computationally efficient; Coronary artery disease; Deep learning; Kernel regression; Kernel ridge regressions; Model based optimization; Non-linear transformations; State-of-the-art techniques; accuracy; algorithm; Article; artificial neural network; coronary artery disease; diabetic patient; hospital cost; hospital discharge; hospital readmission; human; kernel deep stacking network; kernel method; machine learning; normal distribution; prediction; priority journal; random forest; random sample; artificial neural network; diabetes mellitus; machine learning; statistics and numerical data; Parameter estimation","Elsevier B.V.","09333657","","AIMEE","27431035","Article","Scopus","2-s2.0-84973151881"
"Teplitzky B.A.; Zitella L.M.; Xiao Y.Z.; Johnson M.D.","Teplitzky, Benjamin A. (56058082100); Zitella, Laura M. (55839751600); Xiao, Yi Zi (56673241000); Johnson, Matthew D. (55982952900)","56058082100; 55839751600; 56673241000; 55982952900","Model-based comparison of deep brain stimulation array functionality with varying number of radial electrodes and machine learning feature sets","2016","Frontiers in Computational Neuroscience","28","10.3389/fncom.2016.00058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975138653&doi=10.3389%2ffncom.2016.00058&partnerID=40&md5=6c54563e4d0450171acf0491c7f94fa7","Department of Biomedical Engineering, University of Minnesota, Minneapolis, MN, United States; Institute for Translational Neuroscience, University of Minnesota, Minneapolis, MN, United States","Teplitzky B.A., Department of Biomedical Engineering, University of Minnesota, Minneapolis, MN, United States; Zitella L.M., Department of Biomedical Engineering, University of Minnesota, Minneapolis, MN, United States; Xiao Y.Z., Department of Biomedical Engineering, University of Minnesota, Minneapolis, MN, United States; Johnson M.D., Department of Biomedical Engineering, University of Minnesota, Minneapolis, MN, United States, Institute for Translational Neuroscience, University of Minnesota, Minneapolis, MN, United States","Deep brain stimulation (DBS) leads with radially distributed electrodes have potential to improve clinical outcomes through more selective targeting of pathways and networks within the brain. However, increasing the number of electrodes on clinical DBS leads by replacing conventional cylindrical shell electrodes with radially distributed electrodes raises practical design and stimulation programming challenges. We used computational modeling to investigate: (1) how the number of radial electrodes impact the ability to steer, shift, and sculpt a region of neural activation (RoA), and (2) which RoA features are best used in combination with machine learning classifiers to predict programming settings to target a particular area near the lead. Stimulation configurations were modeled using 27 lead designs with one to nine radially distributed electrodes. The computational modeling framework consisted of a three-dimensional finite element tissue conductance model in combination with a multi-compartment biophysical axon model. For each lead design, two-dimensional threshold-dependent RoAs were calculated from the computational modeling results. The models showed more radial electrodes enabled finer resolution RoA steering; however, stimulation amplitude, and therefore spatial extent of the RoA, was limited by charge injection and charge storage capacity constraints due to the small electrode surface area for leads with more than four radially distributed electrodes. RoA shifting resolution was improved by the addition of radial electrodes when using uniform multi-cathode stimulation, but non-uniform multi-cathode stimulation produced equivalent or better resolution shifting without increasing the number of radial electrodes. Robust machine learning classification of 15 monopolar stimulation configurations was achieved using as few as three geometric features describing a RoA. The results of this study indicate that, for a clinical-scale DBS lead, more than four radial electrodes minimally improved in the ability to steer, shift, and sculpt axonal activation around a DBS lead and a simple feature set consisting of the RoA center of mass and orientation enabled robust machine learning classification. These results provide important design constraints for future development of high-density DBS arrays. © 2016 Teplitzky, Zitella, Xiao and Johnson.","Computational modeling; DBS; DBS lead; DBS programing algorithms; Deep brain stimulation; Machine learning; Neuromodulation","Artificial intelligence; Cathodes; Chemical activation; Computation theory; Finite element method; Learning systems; Charge storage capacity; Computational model; Deep brain stimulation; Design constraints; Electrode surface area; Machine learning classification; Neuromodulation; Three dimensional finite elements; Article; brain depth stimulation; classifier; computer model; deep brain stimulation lead; depth electrode; electrode implant; electrode implantation; equipment design; finite element analysis; machine learning; Neurosurgery","Frontiers Media S.A.","16625188","","","","Article","Scopus","2-s2.0-84975138653"
"Zhang N.; Ding S.; Shi Z.","Zhang, Nan (56994194400); Ding, Shifei (24314525600); Shi, Zhongzhi (55801581400)","56994194400; 24314525600; 55801581400","Denoising Laplacian multi-layer extreme learning machine","2016","Neurocomputing","42","10.1016/j.neucom.2015.07.058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944512793&doi=10.1016%2fj.neucom.2015.07.058&partnerID=40&md5=29d0aa449cc71b30addc67df4f8eb5d3","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China; Jiangsu Key Laboratory of Mine Mechanical and Electrical Equipment, China University of Mining and Technology, Xuzhou, 221116, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China","Zhang N., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China, Jiangsu Key Laboratory of Mine Mechanical and Electrical Equipment, China University of Mining and Technology, Xuzhou, 221116, China; Ding S., School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, 221116, China, Jiangsu Key Laboratory of Mine Mechanical and Electrical Equipment, China University of Mining and Technology, Xuzhou, 221116, China, Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Shi Z., Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China","Most of semi-supervised learning algorithms based on manifold regularization framework are surface learning algorithms, such as semi-supervised ELM (SS-ELM) and Laplacian smooth twin support vector machine (Lap-STSVM). Multi-layer extreme learning machine (ML-ELM) stacks extreme learning machine based auto encoder (ELM-AE) to create a multi-layer neural network. ML-ELM not only approximates the complicated function but also achieves fast training time. The outputs of ELM-AE are the same as inputs, which cannot guarantee the effectiveness of the learning feature representations. We put forward extreme learning machine based denoising auto encoder (ELM-DAE) which introduces local denoising criterion into ELM-AE and is used as the basic component for Denoising ML-ELM. Resembling ML-ELM, Denoising ML-ELM stacks ELM-DAE to create a deep network. And then we introduce manifold regularization into the model of Denoising ML-ELM and propose denoising Laplacian ML-ELM (Denoising Lap-ML-ELM). Denoising Lap-ML-ELM is more efficient than SS-ELM in classification and does not need to spend too much time. Experimental results show that Denoising ML-ELM and Denoising Lap-ML-ELM are effective learning algorithms. © 2015 Elsevier B.V.","Deep learning; Denoising; Extreme learning machine; Manifold regularization; Semi-supervised learning","Algorithms; Knowledge acquisition; Laplace transforms; Learning systems; Network layers; Supervised learning; De-noising; Deep learning; Extreme learning machine; Manifold regularizations; Semi- supervised learning; Article; artificial neural network; controlled study; Denoising Laplacian multi layer extreme learning machine; extreme learning machine based denoising auto encoder; Laplacian smooth twin support vector machine; learning algorithm; machine learning; Multi layer extreme learning machine; priority journal; semi supervised extreme learning machine; support vector machine; Learning algorithms","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84944512793"
"Fagiani M.; Squartini S.; Gabrielli L.; Spinsante S.; Piazza F.","Fagiani, M. (36835320900); Squartini, S. (6507753695); Gabrielli, L. (37096892400); Spinsante, S. (6506113067); Piazza, F. (7102584287)","36835320900; 6507753695; 37096892400; 6506113067; 7102584287","A review of datasets and load forecasting techniques for smart natural gas and water grids: Analysis and experiments","2015","Neurocomputing","37","10.1016/j.neucom.2015.04.098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940614413&doi=10.1016%2fj.neucom.2015.04.098&partnerID=40&md5=342b480876bfb4da8e41e87dc74dd338","Department of Information Engineering, Università Politecnica delle Marche, Via Brecce Bianche 1, Ancona, 60131, Italy","Fagiani M., Department of Information Engineering, Università Politecnica delle Marche, Via Brecce Bianche 1, Ancona, 60131, Italy; Squartini S., Department of Information Engineering, Università Politecnica delle Marche, Via Brecce Bianche 1, Ancona, 60131, Italy; Gabrielli L., Department of Information Engineering, Università Politecnica delle Marche, Via Brecce Bianche 1, Ancona, 60131, Italy; Spinsante S., Department of Information Engineering, Università Politecnica delle Marche, Via Brecce Bianche 1, Ancona, 60131, Italy; Piazza F., Department of Information Engineering, Università Politecnica delle Marche, Via Brecce Bianche 1, Ancona, 60131, Italy","In this paper, experiments concerning the prediction of water and natural gas consumption are presented, focusing on how to exploit data heterogeneity to get a reliable outcome. Prior to this, an up-to-date state-of-the-art review on the available datasets and forecasting techniques of water and natural gas consumption, is conducted. A collection of techniques (Artificial Neural Networks, Deep Belief Networks, Echo State Networks, Support Vector Regression, Genetic Programming and Extended Kalman Filter-Genetic Programming), partially selected from the state-of-the-art ones, are evaluated using the few publicly available datasets. The tests are performed according to two key aspects: homogeneous evaluation criteria and application of heterogeneous data. Experiments with heterogeneous data obtained combining multiple types of resources (water, gas, energy and temperature), aimed to short-term prediction, have been possible using the Almanac of Minutely Power dataset (AMPds). On the contrary, the Energy Information Administration (E.I.A.) data are used for long-term prediction combining gas and temperature information. At the end, the selected approaches have been evaluated using the sole Tehran water consumption for long-term forecasts (thanks to the full availability of the dataset). The AMPds and E.I.A. natural gas results show a correlation with temperature, that produce a performance improvement. The ANN and SVR approaches achieved good performance for both long/short-term predictions, while the EKF-GP showed good outcomes with the E.I.A. datasets. Finally, it is the authors' purpose to create a valid starting point for future works that aim to develop innovative forecasting approaches, providing a fair comparison among different computational intelligence and machine learning techniques. © 2015 Elsevier B.V.","Computational intelligence; Forecasting techniques; Heterogeneous data forecasting; Machine learning; Short/long-term load forecasting; Smart water/gas grid","Artificial intelligence; Deep learning; Electric power plant loads; Extended Kalman filters; Gases; Genetic algorithms; Genetic programming; Intelligent computing; Learning systems; Natural gas; Support vector regression; natural gas; water; Energy Information Administration; Forecasting techniques; Heterogeneous data; Load forecasting; Machine learning techniques; Smart water/gas grid; State-of-the art reviews; Temperature information; adaptation; Article; artificial neural network; controlled study; data base; Deep Belief Network; Echo State Network; energy; energy expenditure; evolutionary algorithm; feedback system; fluid intake; forecasting; Genetic reprogramming; humidity; information processing; intelligence; Iran; machine learning; medical research; nuclear reprogramming; prediction; priority journal; process optimization; regression analysis; reproducibility; sensitivity analysis; stochastic model; support vector machine; temperature; Forecasting","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84940614413"
"Li Q.; Feng B.; Xie L.; Liang P.; Zhang H.; Wang T.","Li, Qiaoliang (55552126700); Feng, Bowei (57146242700); Xie, Linpei (55815540400); Liang, Ping (23498001400); Zhang, Huisheng (57020067600); Wang, Tianfu (55602702200)","55552126700; 57146242700; 55815540400; 23498001400; 57020067600; 55602702200","A cross-modality learning approach for vessel segmentation in retinal images","2016","IEEE Transactions on Medical Imaging","490","10.1109/TMI.2015.2457891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959325071&doi=10.1109%2fTMI.2015.2457891&partnerID=40&md5=5467ee232c6bc4b0f4f9e44e801a16b2","Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China","Li Q., Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Feng B., Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Xie L., Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Liang P., Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Zhang H., Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China; Wang T., Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Department of Biomedical Engineering, Shenzhen University, Shenzhen, 518060, China","This paper presents a new supervised method for vessel segmentation in retinal images. This method remolds the task of segmentation as a problem of cross-modality data transformation from retinal image to vessel map. A wide and deep neural network with strong induction ability is proposed to model the transformation, and an efficient training strategy is presented. Instead of a single label of the center pixel, the network can output the label map of all pixels for a given image patch. Our approach outperforms reported state-of-the-art methods in terms of sensitivity, specificity and accuracy. The result of cross-training evaluation indicates its robustness to the training set. The approach needs no artificially designed feature and no preprocessing step, reducing the impact of subjective factors. The proposed method has the potential for application in image diagnosis of ophthalmologic diseases, and it may provide a new, general, high-performance computing framework for image segmentation. © 2015 IEEE.","Cross-modality learning; Deep learning; Retinal image; Vessel segmentation","Algorithms; Databases, Factual; Humans; Image Processing, Computer-Assisted; Machine Learning; Retinal Vessels; Diagnosis; Metadata; Ophthalmology; Pixels; Cross modality; Deep learning; Deep neural networks; High performance computing; Pre-processing step; Retinal image; State-of-the-art methods; Vessel segmentation; Article; artificial neural network; clinical assessment; clinical evaluation; conceptual framework; cross training; diagnostic accuracy; image analysis; image processing; learning; learning algorithm; mathematical analysis; ocular blood vessel; retina image; sensitivity and specificity; vessel segmentation; algorithm; anatomy and histology; factual database; human; image processing; machine learning; procedures; retina blood vessel; Image segmentation","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26208306","Article","Scopus","2-s2.0-84959325071"
"Wang S.; Liu Z.; Rong Y.; Zhou B.; Bai Y.; Wei W.; Wei W.; Guo Y.; Tian J.","Wang, Shuo (58671609100); Liu, Zhenyu (57204479755); Rong, Yu (57201186473); Zhou, Bin (56422899500); Bai, Yan (57077433300); Wei, Wei (57206991047); Wei, Wei (57365390900); Guo, Yingkun (57210470494); Tian, Jie (7401636162)","58671609100; 57204479755; 57201186473; 56422899500; 57077433300; 57206991047; 57365390900; 57210470494; 7401636162","Deep learning provides a new computed tomography-based prognostic biomarker for recurrence prediction in high-grade serous ovarian cancer","2016","Radiotherapy and Oncology","106","10.1016/j.radonc.2018.10.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055729642&doi=10.1016%2fj.radonc.2018.10.019&partnerID=40&md5=6772c749c297e0feddf80a73a1056bc2","CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Department of Radiology, Key Laboratory of Birth Defects and Related Diseases of Women and Children of Ministry of Education, West China Second University Hospital, Sichuan University, China; Department of Radiology, Henan Provincial People's Hospital, China; Key Laboratory of Birth Defects and Related Diseases of Women and Children of Ministry of Education, West China Second University Hospital, Sichuan University, China; Department of Radiology, Key Laboratory of Intelligent Medical Image Analysis and Precision Diagnosis in Guizhou Province, Guizhou Provincial People's Hospital, China; University of Chinese Academy of Sciences, Beijing, China; Beijing Advanced Innovation Center for Big Data-Based Precision Medicine, Beihang University, Beijing, 100191, China","Wang S., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Liu Z., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Rong Y., Department of Radiology, Key Laboratory of Intelligent Medical Image Analysis and Precision Diagnosis in Guizhou Province, Guizhou Provincial People's Hospital, China; Zhou B., Key Laboratory of Birth Defects and Related Diseases of Women and Children of Ministry of Education, West China Second University Hospital, Sichuan University, China; Bai Y., Department of Radiology, Henan Provincial People's Hospital, China; Wei W., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Wei W., Department of Radiology, Henan Provincial People's Hospital, China; Guo Y., Department of Radiology, Key Laboratory of Birth Defects and Related Diseases of Women and Children of Ministry of Education, West China Second University Hospital, Sichuan University, China, Department of Radiology, Henan Provincial People's Hospital, China; Tian J., CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing, China, University of Chinese Academy of Sciences, Beijing, China, Beijing Advanced Innovation Center for Big Data-Based Precision Medicine, Beihang University, Beijing, 100191, China","Background and purpose: Recurrence is the main risk for high-grade serous ovarian cancer (HGSOC) and few prognostic biomarkers were reported. In this study, we proposed a novel deep learning (DL) method to extract prognostic biomarkers from preoperative computed tomography (CT) images, aiming at providing a non-invasive recurrence prediction model in HGSOC. Materials and methods: We enrolled 245 patients with HGSOC from two hospitals, which included a feature-learning cohort (n = 102), a primary cohort (n = 49) and two independent validation cohorts from two hospitals (n = 49 and n = 45). We trained a novel DL network in 8917 CT images from the feature-learning cohort to extract the prognostic biomarkers (DL feature) of HGSOC. Afterward, a DL-CPH model incorporating the DL feature and Cox proportional hazard (Cox-PH) regression was developed to predict the individual recurrence risk and 3-year recurrence probability of patients. Results: In the two validation cohorts, the concordance-index of the DL-CPH model was 0.713 and 0.694. Kaplan–Meier's analysis clearly identified two patient groups with high and low recurrence risk (p = 0.0038 and 0.0164). The 3-year recurrence prediction was also effective (AUC = 0.772 and 0.825), which was validated by the good calibration and decision curve analysis. Moreover, the DL feature demonstrated stronger prognostic value than clinical characteristics. Conclusions: The DL method extracts effective CT-based prognostic biomarkers for HGSOC, and provides a non-invasive and preoperative model for individualized recurrence prediction in HGSOC. In addition, the DL-CPH model provides a new prognostic analysis method that can utilize CT data without follow-up for prognostic biomarker extraction. © 2018 The Authors","Artificial intelligence; Auto encoder; Computed tomography; Deep learning; High-grade serous ovarian cancer; Prognosis; Recurrence; Semi-supervised learning; Unsupervised learning","Biomarkers, Tumor; Cohort Studies; Cystadenocarcinoma, Serous; Deep Learning; Disease-Free Survival; Female; Humans; Kaplan-Meier Estimate; Middle Aged; Neoplasm Recurrence, Local; Ovarian Neoplasms; Precision Medicine; Predictive Value of Tests; Prognosis; Tomography, X-Ray Computed; biological marker; CA 125 antigen; tumor marker; adult; Article; cancer grading; cancer patient; cancer prognosis; cancer recurrence; cancer staging; computer assisted tomography; cytoreductive surgery; deep learning; feature extraction; female; high grade serous ovarian cancer; human; major clinical study; middle aged; ovary cancer; priority journal; recurrence risk; retrospective study; supervised machine learning; unsupervised machine learning; cohort analysis; cystadenocarcinoma; diagnostic imaging; disease free survival; Kaplan Meier method; ovary tumor; pathology; personalized medicine; predictive value; procedures; prognosis; tumor recurrence; x-ray computed tomography","Elsevier Ireland Ltd","01678140","","RAOND","30392780","Article","Scopus","2-s2.0-85055729642"
"Qin H.; Li X.; Liang J.; Peng Y.; Zhang C.","Qin, Hongwei (56442002900); Li, Xiu (7501701944); Liang, Jian (57214441373); Peng, Yigang (26041026100); Zhang, Changshui (7405490589)","56442002900; 7501701944; 57214441373; 26041026100; 7405490589","DeepFish: Accurate underwater live fish recognition with a deep architecture","2016","Neurocomputing","196","10.1016/j.neucom.2015.10.122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949678222&doi=10.1016%2fj.neucom.2015.10.122&partnerID=40&md5=8551ab65fd54edc5d1eafeee06bd520b","Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055, China; Department of Automation, Tsinghua University, Beijing, 100084, China","Qin H., Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055, China, Department of Automation, Tsinghua University, Beijing, 100084, China; Li X., Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055, China, Department of Automation, Tsinghua University, Beijing, 100084, China; Liang J., Department of Automation, Tsinghua University, Beijing, 100084, China; Peng Y., Department of Automation, Tsinghua University, Beijing, 100084, China; Zhang C., Department of Automation, Tsinghua University, Beijing, 100084, China","Underwater object recognition is in great demand, while the research is far from enough. The unrestricted natural environment makes it a challenging task. We propose a framework to recognize fish from videos captured by underwater cameras deployed in the ocean observation network. First, we extract the foreground via sparse and low-rank matrix decomposition. Then, a deep architecture is used to extract features of the foreground fish images. In this architecture, principal component analysis (PCA) is used in two convolutional layers, followed by binary hashing in the non-linear layer and block-wise histograms in the feature pooling layer. Then spatial pyramid pooling (SPP) is used to extract information invariant to large poses. Finally, a linear SVM classifier is used for the classification. This deep network model can be trained efficiently. On a real-world fish recognition dataset, we achieve the state-of-the-art accuracy of 98.64%. © 2015 Elsevier B.V.","Cascaded network; Deep learning; Object recognition; Underwater","Fish; Network architecture; Object recognition; Cascaded networks; Deep architectures; Deep learning; Extract informations; Natural environments; Ocean observations; Sparse and low ranks; Underwater; accuracy; Article; artificial neural network; conceptual framework; controlled study; deep learning; fish; histogram; image analysis; information processing; machine learning; mental performance; nonhuman; novel object recognition test; principal component analysis; priority journal; process development; spatial pyramid pooling; stimulus response; support vector machine; task performance; visual memory; Principal component analysis","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84949678222"
"Golkov V.; Dosovitskiy A.; Sperl J.I.; Menzel M.I.; Czisch M.; Sämann P.; Brox T.; Cremers D.","Golkov, Vladimir (56648189300); Dosovitskiy, Alexey (56582202400); Sperl, Jonathan I. (22981426200); Menzel, Marion I. (24605447000); Czisch, Michael (56239027800); Sämann, Philipp (16679659000); Brox, Thomas (8867345000); Cremers, Daniel (56000160900)","56648189300; 56582202400; 22981426200; 24605447000; 56239027800; 16679659000; 8867345000; 56000160900","q-Space Deep Learning: Twelve-Fold Shorter and Model-Free Diffusion MRI Scans","2016","IEEE Transactions on Medical Imaging","211","10.1109/TMI.2016.2551324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968548037&doi=10.1109%2fTMI.2016.2551324&partnerID=40&md5=5ba7b0788736755b7960986a70fa9430","Department of Computer Science, Technical University of Munich, Munich, 85748, Germany; Department of Computer Science, University of Freiburg, Freiburg, 79110, Germany; GE Global Research, Munich, 85748, Germany; Max Planck Institute of Psychiatry, Munich, 80804, Germany; Department of Computer Science, Technical University of Munich, Garching, 85748, Germany","Golkov V., Department of Computer Science, Technical University of Munich, Munich, 85748, Germany; Dosovitskiy A., Department of Computer Science, University of Freiburg, Freiburg, 79110, Germany; Sperl J.I., GE Global Research, Munich, 85748, Germany; Menzel M.I., GE Global Research, Munich, 85748, Germany; Czisch M., Max Planck Institute of Psychiatry, Munich, 80804, Germany; Sämann P., Max Planck Institute of Psychiatry, Munich, 80804, Germany; Brox T., Department of Computer Science, University of Freiburg, Freiburg, 79110, Germany; Cremers D., Department of Computer Science, Technical University of Munich, Garching, 85748, Germany","Numerous scientific fields rely on elaborate but partly suboptimal data processing pipelines. An example is diffusion magnetic resonance imaging (diffusion MRI), a non-invasive microstructure assessment method with a prominent application in neuroimaging. Advanced diffusion models providing accurate microstructural characterization so far have required long acquisition times and thus have been inapplicable for children and adults who are uncooperative, uncomfortable, or unwell. We show that the long scan time requirements are mainly due to disadvantages of classical data processing. We demonstrate how deep learning, a group of algorithms based on recent advances in the field of artificial neural networks, can be applied to reduce diffusion MRI data processing to a single optimized step. This modification allows obtaining scalar measures from advanced models at twelve-fold reduced scan time and detecting abnormalities without using diffusion models. We set a new state of the art by estimating diffusion kurtosis measures from only 12 data points and neurite orientation dispersion and density measures from only 8 data points. This allows unprecedentedly fast and robust protocols facilitating clinical routine and demonstrates how classical data processing can be streamlined by means of deep learning. © 1982-2012 IEEE.","Artificial neural networks; diffusion kurtosis imaging (DKI); diffusion magnetic resonance imaging (diffusion MRI); neurite orientation dispersion and density imaging (NODDI)","Brain; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Neural Networks (Computer); Time Factors; Data handling; Diffusion; Dispersions; Higher order statistics; Neural networks; Neuroimaging; Pipeline processing systems; Data processing pipelines; Diffusion kurtosis imaging; Diffusion magnetic resonance imaging; Diffusion mris; Micro-structural characterization; Neurites; Scientific fields; Time requirements; algorithm; Article; artificial neural network; data processing; diffusion; diffusion weighted imaging; dispersion; error; neurite; orientation; reproducibility; artificial neural network; brain; computer assisted diagnosis; diagnostic imaging; human; machine learning; nuclear magnetic resonance imaging; procedures; time factor; Magnetic resonance imaging","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","27071165","Article","Scopus","2-s2.0-84968548037"
"Li C.; Sánchez R.-V.; Zurita G.; Cerrada M.; Cabrera D.","Li, Chuan (57218766650); Sánchez, René-Vinicio (56704297100); Zurita, Grover (56704835200); Cerrada, Mariela (7102543304); Cabrera, Diego (56704715800)","57218766650; 56704297100; 56704835200; 7102543304; 56704715800","Fault diagnosis for rotating machinery using vibration measurement deep statistical feature learning","2016","Sensors (Switzerland)","208","10.3390/s16060895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975124887&doi=10.3390%2fs16060895&partnerID=40&md5=e1d8babb52648005bb4b27ee5ae65545","School of Mechanical Engineering, Dongguan University of Technology, Dongguan, 523808, China; Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, 010105, Ecuador","Li C., School of Mechanical Engineering, Dongguan University of Technology, Dongguan, 523808, China; Sánchez R.-V., Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, 010105, Ecuador; Zurita G., Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, 010105, Ecuador; Cerrada M., Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, 010105, Ecuador; Cabrera D., Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, 010105, Ecuador","Fault diagnosis is important for the maintenance of rotating machinery. The detection of faults and fault patterns is a challenging part of machinery fault diagnosis. To tackle this problem, a model for deep statistical feature learning from vibration measurements of rotating machinery is presented in this paper. Vibration sensor signals collected from rotating mechanical systems are represented in the time, frequency, and time-frequency domains, each of which is then used to produce a statistical feature set. For learning statistical features, real-value Gaussian-Bernoulli restricted Boltzmann machines (GRBMs) are stacked to develop a Gaussian-Bernoulli deep Boltzmann machine (GDBM). The suggested approach is applied as a deep statistical feature learning tool for both gearbox and bearing systems. The fault classification performances in experiments using this approach are 95.17% for the gearbox, and 91.75% for the bearing system. The proposed approach is compared to such standard methods as a support vector machine, GRBM and a combination model. In experiments, the best fault classification rate was detected using the proposed model. The results show that deep learning with statistical feature extraction has an essential improvement potential for diagnosing rotating machinery faults. © 2016 by the authors.","Deep learning; Fault diagnosis; Rotating machinery; Statistical feature; Vibration sensor","Deep learning; Electric fault currents; Failure analysis; Gears; Rotating machinery; Statistics; Ventilation exhausts; Vibration measurement; Vibrations (mechanical); Deep boltzmann machines; Diagnosis for rotating machinery; Machinery fault diagnosis; Restricted boltzmann machine; Statistical feature extractions; Statistical features; Time frequency domain; Vibration sensors; Fault detection","MDPI AG","14248220","","","","Article","Scopus","2-s2.0-84975124887"
"Xu W.; Zhang L.; Lu Y.","Xu, Wenxuan (57195393528); Zhang, Li (56066249200); Lu, Yaping (55506745400)","57195393528; 56066249200; 55506745400","SD-MSAEs: Promoter recognition in human genome based on deep feature extraction","2016","Journal of Biomedical Informatics","23","10.1016/j.jbi.2016.03.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961714889&doi=10.1016%2fj.jbi.2016.03.018&partnerID=40&md5=b25bd5eecdac3a53aad69cec53f35f38","School of Computer Science and Technology, Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, Jiangsu, 215006, China; Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing, Jiangsu, 210000, China","Xu W., School of Computer Science and Technology, Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, Jiangsu, 215006, China, Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing, Jiangsu, 210000, China; Zhang L., School of Computer Science and Technology, Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, Jiangsu, 215006, China, Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing, Jiangsu, 210000, China; Lu Y., School of Computer Science and Technology, Joint International Research Laboratory of Machine Learning and Neuromorphic Computing, Soochow University, Suzhou, Jiangsu, 215006, China, Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing, Jiangsu, 210000, China","The prediction and recognition of promoter in human genome play an important role in DNA sequence analysis. Entropy, in Shannon sense, of information theory is a multiple utility in bioinformatic details analysis. The relative entropy estimator methods based on statistical divergence (SD) are used to extract meaningful features to distinguish different regions of DNA sequences. In this paper, we choose context feature and use a set of methods of SD to select the most effective n-mers distinguishing promoter regions from other DNA regions in human genome. Extracted from the total possible combinations of n-mers, we can get four sparse distributions based on promoter and non-promoters training samples. The informative n-mers are selected by optimizing the differentiating extents of these distributions. Specially, we combine the advantage of statistical divergence and multiple sparse auto-encoders (MSAEs) in deep learning to extract deep feature for promoter recognition. And then we apply multiple SVMs and a decision model to construct a human promoter recognition method called SD-MSAEs. Framework is flexible that it can integrate new feature extraction or new classification models freely. Experimental results show that our method has high sensitivity and specificity. © 2016 Elsevier Inc.","Context features; Promoter recognition; Sparse autoencoder; Statistical divergence; Support vector machine","Computational Biology; DNA; Genome, Human; Humans; Promoter Regions, Genetic; Sequence Analysis, DNA; Biomedical signal processing; Deep learning; DNA; DNA sequences; Entropy; Extraction; Genes; Information theory; Learning systems; Support vector machines; DNA; DNA; Auto encoders; Classification models; Context features; Decision modeling; DNA sequence analysis; Promoter recognition; Sparse distribution; Statistical divergence; analytic method; Article; DNA extraction; DNA sequence; gene construct; human; human genome; intron; molecular recognition; priority journal; process optimization; promoter region; sensitivity and specificity; statistical divergence multiple sparse autoencoders; support vector machine; biology; Feature extraction","Academic Press Inc.","15320464","","JBIOB","27018214","Article","Scopus","2-s2.0-84961714889"
"Li N.; Lu G.; Li X.; Yan Y.","Li, Nan (56574555500); Lu, Gang (55825921500); Li, Xinli (26662670600); Yan, Yong (57203541957)","56574555500; 55825921500; 26662670600; 57203541957","Prediction of NOx Emissions from a Biomass Fired Combustion Process Based on Flame Radical Imaging and Deep Learning Techniques","2016","Combustion Science and Technology","43","10.1080/00102202.2015.1102905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954318014&doi=10.1080%2f00102202.2015.1102905&partnerID=40&md5=0587dc4c570609218e96cadee016ae86","School of Control and Computer Engineering, North China Electric Power University, Beijing, China; School of Engineering and Digital Arts, University of Kent, Canterbury, Kent, CT2 7NT, United Kingdom","Li N., School of Control and Computer Engineering, North China Electric Power University, Beijing, China; Lu G., School of Engineering and Digital Arts, University of Kent, Canterbury, Kent, CT2 7NT, United Kingdom; Li X., School of Control and Computer Engineering, North China Electric Power University, Beijing, China; Yan Y., School of Engineering and Digital Arts, University of Kent, Canterbury, Kent, CT2 7NT, United Kingdom","This article presents a methodology for predicting NOx emissions from a biomass combustion process through flame radical imaging and deep learning (DL). The dataset was established experimentally from flame radical images captured on a biomass-gas fired test rig. Morphological component analysis is undertaken to improve the quality of the dataset, and the region-of-interest extraction is introduced to extract the flame radical part and rescale the image size. The developed DL-based prediction model contains three successive stages for implementing the feature extraction, feature fusion, and emission prediction. The fine-tuning based on the prediction is introduced to adjust the process of the feature fusion. The effects of the feature fusion and fine-tuning are discussed in detail. A comparison between various image-and machine-learning-based prediction models show that the proposed DL prediction model outperforms other models in terms of root mean square error criteria. The predicted NOx emissions are in good agreement with the measurement results. © 2016 Taylor & Francis.","Biomass; de-noising auto-encoder; deep learning; flame radical imaging; image processing; NOx emission","Artificial intelligence; Biomass; Combustion; Extraction; Feature extraction; Forecasting; Image segmentation; Learning systems; Mean square error; Nitrogen oxides; Statistical tests; Auto encoders; Biomass combustion; Combustion pro-cess; Deep learning; Morphological component analysis; NOx emissions; Region of interest; Root mean square errors; Image processing","Taylor and Francis Inc.","00102202","","CBSTB","","Article","Scopus","2-s2.0-84954318014"
"Wang Y.; Xie Z.; Xu K.; Dou Y.; Lei Y.","Wang, Yueqing (55697602500); Xie, Zhige (56183073400); Xu, Kai (56970190100); Dou, Yong (15131095400); Lei, Yuanwu (24824943800)","55697602500; 56183073400; 56970190100; 15131095400; 24824943800","An efficient and effective convolutional auto-encoder extreme learning machine network for 3d feature learning","2016","Neurocomputing","83","10.1016/j.neucom.2015.10.035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949650401&doi=10.1016%2fj.neucom.2015.10.035&partnerID=40&md5=a47454ffcb42d8efb0a60ef78d55ae34","National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China","Wang Y., National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China, College of Computer, National University of Defense Technology, Changsha, China; Xie Z., College of Computer, National University of Defense Technology, Changsha, China; Xu K., College of Computer, National University of Defense Technology, Changsha, China; Dou Y., National Laboratory for Parallel and Distributed Processing, National University of Defense Technology, Changsha, China, College of Computer, National University of Defense Technology, Changsha, China; Lei Y., College of Computer, National University of Defense Technology, Changsha, China","3D shape features play a crucial role in graphics applications, such as 3D shape matching, recognition, and retrieval. Various 3D shape descriptors have been developed over the last two decades; however, existing descriptors are handcrafted features that are labor-intensively designed and cannot extract discriminative information for a large set of data. In this paper, we propose a rapid 3D feature learning method, namely, a convolutional auto-encoder extreme learning machine (CAE-ELM) that combines the advantages of the convolutional neuron network, auto-encoder, and extreme learning machine (ELM). This method performs better and faster than other methods. In addition, we define a novel architecture based on CAE-ELM. The architecture accepts two types of 3D shape representation, namely, voxel data and signed distance field data (SDF), as inputs to extract the global and local features of 3D shapes. Voxel data describe structural information, whereas SDF data contain details on 3D shapes. Moreover, the proposed CAE-ELM can be used in practical graphics applications, such as 3D shape completion. Experiments show that the features extracted by CAE-ELM are superior to existing hand-crafted features and other deep learning methods or ELM models. Moreover, the classification accuracy of the proposed architecture is superior to that of other methods on ModelNet10 (91.4%) and ModelNet40 (84.35%). The training process also runs faster than existing deep learning methods by approximately two orders of magnitude. © 2015 Elsevier B.V.","Auto-encoder; Convolutional; Extreme learning machine; Feature learning","Convolution; Convolutional neural networks; Data mining; Deep learning; Knowledge acquisition; Network architecture; Network coding; Three dimensional computer graphics; 3D shape representation; Auto encoders; Classification accuracy; Convolutional; Extreme learning machine; Feature learning; Signed distance fields; Structural information; Article; artificial neural network; convolutional auto encoder extreme learning machine; data analysis; image analysis; information processing; information processing device; information retrieval; machine learning; mathematical computing; measurement accuracy; pattern recognition; priority journal; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84949650401"
"Saha B.; Nguyen T.; Phung D.; Venkatesh S.","Saha, Budhaditya (51964670200); Nguyen, Thin (36180246900); Phung, Dinh (7003397144); Venkatesh, Svetha (56204854900)","51964670200; 36180246900; 7003397144; 56204854900","A Framework for Classifying Online Mental Health-Related Communities with an Interest in Depression","2016","IEEE Journal of Biomedical and Health Informatics","50","10.1109/JBHI.2016.2543741","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978288680&doi=10.1109%2fJBHI.2016.2543741&partnerID=40&md5=2a352400017161ed65b9d046d2e411bc","Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, 3216, VIC, Australia","Saha B., Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, 3216, VIC, Australia; Nguyen T., Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, 3216, VIC, Australia; Phung D., Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, 3216, VIC, Australia; Venkatesh S., Centre for Pattern Recognition and Data Analytics, Faculty of Science and Technology, Deakin University, 3216, VIC, Australia","Mental illness has a deep impact on individuals, families, and by extension, society as a whole. Social networks allow individuals with mental disorders to communicate with others sufferers via online communities, providing an invaluable resource for studies on textual signs of psychological health problems. Mental disorders often occur in combinations, e.g., a patient with an anxiety disorder may also develop depression. This co-occurring mental health condition provides the focus for our work on classifying online communities with an interest in depression. For this, we have crawled a large body of 620 000 posts made by 80 000 users in 247 online communities. We have extracted the topics and psycholinguistic features expressed in the posts, using these as inputs to our model. Following a machine learning technique, we have formulated a joint modeling framework in order to classify mental health-related co-occurring online communities from these features. Finally, we performed empirical validation of the model on the crawled dataset where our model outperforms recent state-of-the-art baselines. © 2016 IEEE.","Health Information Management; Predictive Models; statistical learning","Blogging; Depression; Health Information Management; Humans; Mental Health; Models, Statistical; Social Media; Diseases; Information management; Online systems; Predictive analytics; Social networking (online); Empirical validation; Health information management; Machine learning techniques; Mental disorders; On-line communities; Predictive models; Psychological health; Statistical learning; human; human experiment; joint; machine learning; medical information system; mental health; model; validation process; blogging; classification; depression; medical information system; mental health; procedures; social media; statistical model; Learning systems","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","27008680","Article","Scopus","2-s2.0-84978288680"
"Kallenberg M.; Petersen K.; Nielsen M.; Ng A.Y.; Diao P.; Igel C.; Vachon C.M.; Holland K.; Winkel R.R.; Karssemeijer N.; Lillholm M.","Kallenberg, Michiel (24331860100); Petersen, Kersten (36617629100); Nielsen, Mads (13605669800); Ng, Andrew Y. (35410071600); Diao, Pengfei (56258211500); Igel, Christian (6602116076); Vachon, Celine M. (35270550500); Holland, Katharina (56259164800); Winkel, Rikke Rass (55178420500); Karssemeijer, Nico (24332021400); Lillholm, Martin (6506188114)","24331860100; 36617629100; 13605669800; 35410071600; 56258211500; 6602116076; 35270550500; 56259164800; 55178420500; 24332021400; 6506188114","Unsupervised Deep Learning Applied to Breast Density Segmentation and Mammographic Risk Scoring","2016","IEEE Transactions on Medical Imaging","368","10.1109/TMI.2016.2532122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968572894&doi=10.1109%2fTMI.2016.2532122&partnerID=40&md5=aefdad2b30cc15f496bb33afa114b5d5","Department of Computer Science, University of Copenhagen, Copenhagen, DK-2100, Denmark; Biomediq A/S, Copenhagen, DK-2100, Denmark; Department of Computer Science, Stanford University, 94305, CA, United States; Mayo Clinic Hospital, 85054, AZ, United States; Radboud University Medical Centre, Nijmegen, 6525 GA, Netherlands; University Hospital of Copenhagen, Copenhagen, DK-2100, Denmark","Kallenberg M., Department of Computer Science, University of Copenhagen, Copenhagen, DK-2100, Denmark, Biomediq A/S, Copenhagen, DK-2100, Denmark; Petersen K., Department of Computer Science, University of Copenhagen, Copenhagen, DK-2100, Denmark; Nielsen M., Department of Computer Science, University of Copenhagen, Copenhagen, DK-2100, Denmark, Biomediq A/S, Copenhagen, DK-2100, Denmark; Ng A.Y., Department of Computer Science, Stanford University, 94305, CA, United States; Diao P., Department of Computer Science, University of Copenhagen, Copenhagen, DK-2100, Denmark; Igel C., Department of Computer Science, University of Copenhagen, Copenhagen, DK-2100, Denmark; Vachon C.M., Mayo Clinic Hospital, 85054, AZ, United States; Holland K., Radboud University Medical Centre, Nijmegen, 6525 GA, Netherlands; Winkel R.R., University Hospital of Copenhagen, Copenhagen, DK-2100, Denmark; Karssemeijer N., Radboud University Medical Centre, Nijmegen, 6525 GA, Netherlands; Lillholm M., Department of Computer Science, University of Copenhagen, Copenhagen, DK-2100, Denmark, Biomediq A/S, Copenhagen, DK-2100, Denmark","Mammographic risk scoring has commonly been automated by extracting a set of handcrafted features from mammograms, and relating the responses directly or indirectly to breast cancer risk. We present a method that learns a feature hierarchy from unlabeled data. When the learned features are used as the input to a simple classifier, two different tasks can be addressed: i) breast density segmentation, and ii) scoring of mammographic texture. The proposed model learns features at multiple scales. To control the models capacity a novel sparsity regularizer is introduced that incorporates both lifetime and population sparsity. We evaluated our method on three different clinical datasets. Our state-of-the-art results show that the learned breast density scores have a very strong positive relationship with manual ones, and that the learned texture scores are predictive of breast cancer. The model is easy to apply and generalizes to many other segmentation and scoring problems. © 1982-2012 IEEE.","Breast cancer; deep learning; mammograms; prognosis; risk factor; segmentation; unsupervised feature learning","Adult; Aged; Breast; Breast Density; Breast Neoplasms; Female; Humans; Image Interpretation, Computer-Assisted; Mammography; Middle Aged; Risk Factors; Unsupervised Machine Learning; Diseases; Image segmentation; X ray screens; Breast Cancer; Deep learning; mammograms; prognosis; Risk factors; Unsupervised feature learning; Article; assessment of humans; breast cancer; breast density; cancer prognosis; classifier; controlled study; learning; mammographic texture score; mammography system; risk factor; adult; aged; breast; breast density; Breast Neoplasms; computer assisted diagnosis; diagnostic imaging; female; human; mammography; middle aged; physiology; procedures; unsupervised machine learning; Mammography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26915120","Article","Scopus","2-s2.0-84968572894"
"Araki T.; Ikeda N.; Shukla D.; Londhe N.D.; Shrivastava V.K.; Banchhor S.K.; Saba L.; Nicolaides A.; Shafique S.; Laird J.R.; Suri J.S.","Araki, Tadashi (35557901200); Ikeda, Nobutaka (10141573700); Shukla, Devarshi (56992429100); Londhe, Narendra D. (49361709100); Shrivastava, Vimal K. (56592170100); Banchhor, Sumit K. (56993781800); Saba, Luca (16234937700); Nicolaides, Andrew (35419962500); Shafique, Shoaib (6506338657); Laird, John R. (7102409727); Suri, Jasjit S. (7005613223)","35557901200; 10141573700; 56992429100; 49361709100; 56592170100; 56993781800; 16234937700; 35419962500; 6506338657; 7102409727; 7005613223","A new method for IVUS-based coronary artery disease risk stratification: A link between coronary & carotid ultrasound plaque burdens","2016","Computer Methods and Programs in Biomedicine","54","10.1016/j.cmpb.2015.10.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954477592&doi=10.1016%2fj.cmpb.2015.10.022&partnerID=40&md5=6cfcdb1d0f4e518e1c7df4bedeb2381b","Division of Cardiovascular Medicine, Toho University Ohashi Medical Center, Tokyo, Japan; Cardiovascular Medicine, National Center for Global Health and Medicine, Tokyo, Japan; Department of Electrical Engineering, NIT Raipur, Chhattisgarh, India; Department of Radiology, University of Cagliari, Italy; Vascular Screening and Diagnostic Centre, London, England, United Kingdom; Vascular Diagnostic Center, University of Cyprus, Nicosia, Cyprus; CorVasc Vascular Laboratory, Indianapolis, IN, United States; UC Davis Vascular Center, University of California, Davis, CA, United States; Monitoring and Diagnostic Division, AtheroPoint, Roseville, CA, United States; Department of Electrical Engineering, University of Idaho (Affl.), ID, United States","Araki T., Division of Cardiovascular Medicine, Toho University Ohashi Medical Center, Tokyo, Japan; Ikeda N., Cardiovascular Medicine, National Center for Global Health and Medicine, Tokyo, Japan; Shukla D., Department of Electrical Engineering, NIT Raipur, Chhattisgarh, India, Department of Electrical Engineering, University of Idaho (Affl.), ID, United States; Londhe N.D., Department of Electrical Engineering, NIT Raipur, Chhattisgarh, India, Department of Electrical Engineering, University of Idaho (Affl.), ID, United States; Shrivastava V.K., Department of Electrical Engineering, NIT Raipur, Chhattisgarh, India; Banchhor S.K., Department of Electrical Engineering, NIT Raipur, Chhattisgarh, India, Department of Electrical Engineering, University of Idaho (Affl.), ID, United States; Saba L., Department of Radiology, University of Cagliari, Italy; Nicolaides A., Vascular Screening and Diagnostic Centre, London, England, United Kingdom, Vascular Diagnostic Center, University of Cyprus, Nicosia, Cyprus; Shafique S., CorVasc Vascular Laboratory, Indianapolis, IN, United States; Laird J.R., UC Davis Vascular Center, University of California, Davis, CA, United States; Suri J.S., Monitoring and Diagnostic Division, AtheroPoint, Roseville, CA, United States, Department of Electrical Engineering, University of Idaho (Affl.), ID, United States","Interventional cardiologists have a deep interest in risk stratification prior to stenting and percutaneous coronary intervention (PCI) procedures. Intravascular ultrasound (IVUS) is most commonly adapted for screening, but current tools lack the ability for risk stratification based on grayscale plaque morphology. Our hypothesis is based on the genetic makeup of the atherosclerosis disease, that there is evidence of a link between coronary atherosclerosis disease and carotid plaque built up. This novel idea is explored in this study for coronary risk assessment and its classification of patients between high risk and low risk.This paper presents a strategy for coronary risk assessment by combining the IVUS grayscale plaque morphology and carotid B-mode ultrasound carotid intima-media thickness (cIMT) - a marker of subclinical atherosclerosis. Support vector machine (SVM) learning paradigm is adapted for risk stratification, where both the learning and testing phases use tissue characteristics derived from six feature combinational spaces, which are then used by the SVM classifier with five different kernels sets. These six feature combinational spaces are designed using 56 novel feature sets. K-fold cross validation protocol with 10 trials per fold is used for optimization of best SVM-kernel and best feature combination set.IRB approved coronary IVUS and carotid B-mode ultrasound were jointly collected on 15 patients (2 days apart) via: (a) 40. MHz catheter utilizing iMap (Boston Scientific, Marlborough, MA, USA) with 2865 frames per patient (42,975 frames) and (b) linear probe B-mode carotid ultrasound (Toshiba scanner, Japan). Using the above protocol, the system shows the classification accuracy of 94.95% and AUC of 0.95 using optimized feature combination. This is the first system of its kind for risk stratification as a screening tool to prevent excessive cost burden and better patients' cardiovascular disease management, while validating our two hypotheses. © 2015 Elsevier Ireland Ltd.","B-mode ultrasound; Carotid disease; Coronary artery; IVUS; Machine learning; Risk assessment","Adult; Aged; Aged, 80 and over; Carotid Artery Diseases; Carotid Intima-Media Thickness; Coronary Artery Disease; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Male; Middle Aged; Pattern Recognition, Automated; Reproducibility of Results; Risk Assessment; Sensitivity and Specificity; Ultrasonography, Interventional; Artificial intelligence; Blood vessels; Diagnosis; Diseases; Heart; Learning systems; Support vector machines; Ultrasonics; Vector spaces; acetylsalicylic acid; clopidogrel; heparin; Cardio-vascular disease; Carotid intima-media thickness; Coronary arteries; Coronary artery disease; Intravascular ultrasound; IVUS; K fold cross validations; Percutaneous coronary intervention; accuracy; adult; aged; arterial wall thickness; Article; atherosclerosis; B scan; clinical article; coronary artery disease; coronary risk; high risk patient; human; intravascular ultrasound; intravascular ultrasound catheter; low risk patient; male; risk assessment; support vector machine; ultrasound scanner; very elderly; arterial wall thickness; automated pattern recognition; carotid artery disease; complication; computer assisted diagnosis; coronary artery disease; diagnostic imaging; evaluation study; female; interventional ultrasonography; machine learning; middle aged; procedures; reproducibility; sensitivity and specificity; Risk assessment","Elsevier Ireland Ltd","01692607","","CMPBE","26707374","Article","Scopus","2-s2.0-84954477592"
"Xu J.; Luo X.; Wang G.; Gilmore H.; Madabhushi A.","Xu, Jun (57191409730); Luo, Xiaofei (57143134900); Wang, Guanhao (56647074800); Gilmore, Hannah (16039479600); Madabhushi, Anant (6603019206)","57191409730; 57143134900; 56647074800; 16039479600; 6603019206","A Deep Convolutional Neural Network for segmenting and classifying epithelial and stromal regions in histopathological images","2016","Neurocomputing","375","10.1016/j.neucom.2016.01.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977845763&doi=10.1016%2fj.neucom.2016.01.034&partnerID=40&md5=6feadc94069463d61c8eade81d54fb4e","Jiangsu Key Laboratory of Big Data Analysis Technique, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Institute for Pathology, University Hospitals Case Medical Center, Case Western Reserve University, 44106-7207, OH, United States; Department of Biomedical Engineering, Case Western Reserve University, 44106, OH, United States","Xu J., Jiangsu Key Laboratory of Big Data Analysis Technique, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Luo X., Jiangsu Key Laboratory of Big Data Analysis Technique, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Wang G., Jiangsu Key Laboratory of Big Data Analysis Technique, Nanjing University of Information Science and Technology, Nanjing, 210044, China; Gilmore H., Institute for Pathology, University Hospitals Case Medical Center, Case Western Reserve University, 44106-7207, OH, United States; Madabhushi A., Department of Biomedical Engineering, Case Western Reserve University, 44106, OH, United States","Epithelial (EP) and stromal (ST) are two types of tissues in histological images. Automated segmentation or classification of EP and ST tissues is important when developing computerized system for analyzing the tumor microenvironment. In this paper, a Deep Convolutional Neural Networks (DCNN) based feature learning is presented to automatically segment or classify EP and ST regions from digitized tumor tissue microarrays (TMAs). Current approaches are based on handcraft feature representation, such as color, texture, and Local Binary Patterns (LBP) in classifying two regions. Compared to handcrafted feature based approaches, which involve task dependent representation, DCNN is an end-to-end feature extractor that may be directly learned from the raw pixel intensity value of EP and ST tissues in a data driven fashion. These high-level features contribute to the construction of a supervised classifier for discriminating the two types of tissues. In this work we compare DCNN based models with three handcraft feature extraction based approaches on two different datasets which consist of 157 Hematoxylin and Eosin (H&E) stained images of breast cancer and 1376 immunohistological (IHC) stained images of colorectal cancer, respectively. The DCNN based feature learning approach was shown to have a F1 classification score of 85%, 89%, and 100%, accuracy (ACC) of 84%, 88%, and 100%, and Matthews Correlation Coefficient (MCC) of 86%, 77%, and 100% on two H&E stained (NKI and VGH) and IHC stained data, respectively. Our DNN based approach was shown to outperform three handcraft feature extraction based approaches in terms of the classification of EP and ST regions. © 2016 Elsevier B.V. All rights reserved.","Breast histopathology; Colorectal cancer; Deep Convolutional Neural Networks; Feature representation; Regions; The classification of epithelial and stromal","Convolution; Deep neural networks; Diseases; Extraction; Feature extraction; Histology; Image classification; Image segmentation; Machine learning; Medical imaging; Textures; Tumors; Breast histopathology; Colorectal cancer; Feature representation; Regions; The classification of epithelial and stromal; Article; artificial neural network; breast cancer; classifier; colorectal cancer; deep convolutional neural network; digital imaging; epithelium; histopathology; human; image classification; image processing; image segmentation; immunohistochemistry; priority journal; stroma; support vector machine; tissue microarray; Convolutional neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84977845763"
"Habes M.; Erus G.; Toledo J.B.; Zhang T.; Bryan N.; Launer L.J.; Rosseel Y.; Janowitz D.; Doshi J.; Van Der Auwera S.; Von Sarnowski B.; Hegenscheid K.; Hosten N.; Homuth G.; Völzke H.; Schminke U.; Hoffmann W.; Grabe H.J.; Davatzikos C.","Habes, Mohamad (55445429000); Erus, Guray (8556756900); Toledo, Jon B. (54380869300); Zhang, Tianhao (57089336200); Bryan, Nick (56679449600); Launer, Lenore J. (7006392362); Rosseel, Yves (6603020347); Janowitz, Deborah (22950894700); Doshi, Jimit (54683520600); Van Der Auwera, Sandra (56080884100); Von Sarnowski, Bettina (35303830600); Hegenscheid, Katrin (16425192300); Hosten, Norbert (7005344438); Homuth, Georg (56357082900); Völzke, Henry (56662814100); Schminke, Ulf (57222581914); Hoffmann, Wolfgang (7202758146); Grabe, Hans J. (7004509281); Davatzikos, Christos (7005310126)","55445429000; 8556756900; 54380869300; 57089336200; 56679449600; 7006392362; 6603020347; 22950894700; 54683520600; 56080884100; 35303830600; 16425192300; 7005344438; 56357082900; 56662814100; 57222581914; 7202758146; 7004509281; 7005310126","White matter hyperintensities and imaging patterns of brain ageing in the general population","2016","Brain","275","10.1093/brain/aww008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964413922&doi=10.1093%2fbrain%2faww008&partnerID=40&md5=339f22ef585822b67f294b29edb0fbc5","Institute for Community Medicine, University of Greifswald, Germany; Centre for Biomedical Image Computing and Analytics, University of Pennsylvania, United States; Department of Psychiatry, University of Greifswald, Germany; Department of Pathology and Laboratory Medicine, Institute on Aging, Center for Neurodegenerative Disease Research, University of Pennsylvania, United States; Laboratory of Epidemiology, Demography and Biometry, National Institute on Aging, United States; Department of Data Analysis, Ghent University, Belgium; German Centre for Neurodegenerative Diseases (DZNE), Rostock/Greifswald, Germany; Department of Neurology, University of Greifswald, Germany; Department of Radiology, University of Greifswald, Germany; Institute for Genetics and Functional Genomics, University of Greifswald, Germany","Habes M., Institute for Community Medicine, University of Greifswald, Germany, Centre for Biomedical Image Computing and Analytics, University of Pennsylvania, United States, Department of Psychiatry, University of Greifswald, Germany; Erus G., Centre for Biomedical Image Computing and Analytics, University of Pennsylvania, United States; Toledo J.B., Department of Pathology and Laboratory Medicine, Institute on Aging, Center for Neurodegenerative Disease Research, University of Pennsylvania, United States; Zhang T., Centre for Biomedical Image Computing and Analytics, University of Pennsylvania, United States; Bryan N., Centre for Biomedical Image Computing and Analytics, University of Pennsylvania, United States; Launer L.J., Laboratory of Epidemiology, Demography and Biometry, National Institute on Aging, United States; Rosseel Y., Department of Data Analysis, Ghent University, Belgium; Janowitz D., Department of Psychiatry, University of Greifswald, Germany; Doshi J., Centre for Biomedical Image Computing and Analytics, University of Pennsylvania, United States; Van Der Auwera S., Department of Psychiatry, University of Greifswald, Germany, German Centre for Neurodegenerative Diseases (DZNE), Rostock/Greifswald, Germany; Von Sarnowski B., Department of Neurology, University of Greifswald, Germany; Hegenscheid K., Department of Radiology, University of Greifswald, Germany; Hosten N., Department of Radiology, University of Greifswald, Germany; Homuth G., Institute for Genetics and Functional Genomics, University of Greifswald, Germany; Völzke H., Institute for Community Medicine, University of Greifswald, Germany; Schminke U., Department of Neurology, University of Greifswald, Germany; Hoffmann W., Institute for Community Medicine, University of Greifswald, Germany, German Centre for Neurodegenerative Diseases (DZNE), Rostock/Greifswald, Germany; Grabe H.J., Department of Psychiatry, University of Greifswald, Germany, German Centre for Neurodegenerative Diseases (DZNE), Rostock/Greifswald, Germany; Davatzikos C., Centre for Biomedical Image Computing and Analytics, University of Pennsylvania, United States","White matter hyperintensities are associated with increased risk of dementia and cognitive decline. The current study investigates the relationship between white matter hyperintensities burden and patterns of brain atrophy associated with brain ageing and Alzheimer's disease in a large populatison-based sample (n = 2367) encompassing a wide age range (20-90 years), from the Study of Health in Pomerania. We quantified white matter hyperintensities using automated segmentation and summarized atrophy patterns using machine learning methods resulting in two indices: the SPARE-BA index (capturing age-related brain atrophy), and the SPARE-AD index (previously developed to capture patterns of atrophy found in patients with Alzheimer's disease). A characteristic pattern of age-related accumulation of white matter hyperintensities in both periventricular and deep white matter areas was found. Individuals with high white matter hyperintensities burden showed significantly (P < 0.0001) lower SPARE-BA and higher SPARE-AD values compared to those with low white matter hyperintensities burden, indicating that the former had more patterns of atrophy in brain regions typically affected by ageing and Alzheimer's disease dementia. To investigate a possibly causal role of white matter hyperintensities, structural equation modelling was used to quantify the effect of Framingham cardiovascular disease risk score and white matter hyperintensities burden on SPARE-BA, revealing a statistically significant (P < 0.0001) causal relationship between them. Structural equation modelling showed that the age effect on SPARE-BA was mediated by white matter hyperintensities and cardiovascular risk score each explaining 10.4% and 21.6% of the variance, respectively. The direct age effect explained 70.2% of the SPARE-BA variance. Only white matter hyperintensities significantly mediated the age effect on SPARE-AD explaining 32.8% of the variance. The direct age effect explained 66.0% of the SPARE-AD variance. Multivariable regression showed significant relationship between white matter hyperintensities volume and hypertension (P = 0.001), diabetes mellitus (P = 0.023), smoking (P = 0.002) and education level (P = 0.003). The only significant association with cognitive tests was with the immediate recall of the California verbal and learning memory test. No significant association was present with the APOE genotype. These results support the hypothesis that white matter hyperintensities contribute to patterns of brain atrophy found in beyond-normal brain ageing in the general population. White matter hyperintensities also contribute to brain atrophy patterns in regions related to Alzheimer's disease dementia, in agreement with their known additive role to the likelihood of dementia. Preventive strategies reducing the odds to develop cardiovascular disease and white matter hyperintensities could decrease the incidence or delay the onset of dementia. © 2016 The Author (2016). Published by Oxford University Press on behalf of the Guarantors of Brain. All rights reserved.","Alzheimer's disease; brain ageing; cardiovascular disease; mild cognitive impairment; white matter hyperintensities","Adult; Aged; Aged, 80 and over; Aging; Alzheimer Disease; Brain; Cognition Disorders; Cohort Studies; Dementia; Female; Germany; Humans; Magnetic Resonance Imaging; Male; Middle Aged; Poland; Population Surveillance; Risk Factors; White Matter; Young Adult; antidiabetic agent; antihypertensive agent; antilipemic agent; apolipoprotein E; cholesterol; hemoglobin A1c; high density lipoprotein; low density lipoprotein; adult; aged; aging; Alzheimer disease; apolipoprotein E gene; Article; blood pressure monitor; brain atrophy; brain region; cardiovascular risk; cholesterol blood level; controlled study; diabetes mellitus; disease association; education; female; Framingham risk score; gene; genotype; hemoglobin blood level; human; hypertension; learning and memory test; lipoprotein blood level; machine learning; major clinical study; male; middle aged; nervous system parameters; neuroimaging; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; physical activity; priority journal; recall; smoking; structural equation modeling; verbal memory test; very elderly; white matter; white matter hyperintensity; aging; Alzheimer disease; brain; Cognition Disorders; cohort analysis; dementia; Germany; health survey; pathology; Poland; procedures; risk factor; trends; white matter; young adult","Oxford University Press","00068950","","BRAIA","26912649","Article","Scopus","2-s2.0-84964413922"
"Pang X.-C.; Wang Z.; Fang J.-S.; Lian W.-W.; Zhao Y.; Kang D.; Liu A.-L.; Du G.-H.","Pang, Xiao-Cong (56443396300); Wang, Zhe (56511269500); Fang, Jian-Song (55751614400); Lian, Wen-Wen (56492439400); Zhao, Ying (56113251100); Kang, De (57190253164); Liu, Ai-Lin (14048755600); Du, Guan-Hua (13103739800)","56443396300; 56511269500; 55751614400; 56492439400; 56113251100; 57190253164; 14048755600; 13103739800","Network pharmacology study of effective constituents of traditional Chinese medicine for Alzheimer's disease treatment","2016","Yaoxue Xuebao","12","10.16438/j.0513-4870.2015-0950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978764722&doi=10.16438%2fj.0513-4870.2015-0950&partnerID=40&md5=272694b0c9499ca54410260277381862","Institute of Materia Medica, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 100050, China","Pang X.-C., Institute of Materia Medica, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 100050, China; Wang Z., Institute of Materia Medica, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 100050, China; Fang J.-S., Institute of Materia Medica, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 100050, China; Lian W.-W., Institute of Materia Medica, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 100050, China; Zhao Y., Institute of Materia Medica, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 100050, China; Kang D., Institute of Materia Medica, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 100050, China; Liu A.-L., Institute of Materia Medica, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 100050, China; Du G.-H., Institute of Materia Medica, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, 100050, China","This study aims to investigate the network pharmacology of Chinese medicinal formulae for treatment of Alzheimer's disease. Machine learning algorithms were applied to construct classifiers in predicting the active molecules against 25 key targets toward Alzheimer's disease (AD). By extensive data profiling, we compiled 13 classical traditional Chinese medicine (TCM) formulas with clinical efficacy for AD. There were 7 Chinese herbs with a frequency of 5 or higher in our study. Based on the predicted results, we built constituent-target, and further construct target-target interaction network by STRING (Search Tool for the Retrieval of Interacting Genes/Proteins) and target-disease network by DAVID (Database for Annotation, Visualization and Integrated Discovery) and gene disease database to study the synergistic mechanism of the herbal constituents in the Chinese traditional patent medicine. By prediction of blood-brain penetration and validation by TCMsp (traditional Chinese medicine systems pharmacology) and Drugbank, we found 7 typical multi-target constituents which have diverse structure. The mechanism uncovered by this study may offer a deep insight into the action mechanism of TCMs for AD. The predicted inhibitors for the AD-related targets may provide a good source of new lead constituents against AD.","Alzheimer disease; Chinese medicinal formulae; Drug-likeness; Network pharmacology; Virtual screening","Alzheimer Disease; Databases, Factual; Drugs, Chinese Herbal; Humans; Machine Learning; Medicine, Chinese Traditional; Chinese drug; herbaceous agent; algorithm; Alzheimer disease; Article; blood brain barrier; Chinese herb; Chinese medicine; drug mechanism; drug penetration; drug potentiation; genetic database; machine learning; prediction; Alzheimer disease; Chinese medicine; factual database; human","Zhonghua Yixuehui Zazhishe","05134870","","","29874009","Article","Scopus","2-s2.0-84978764722"
"Wołk K.; Marasek K.; Glinkowski W.","Wołk, Krzysztof (56287395200); Marasek, Krzysztof (23094778900); Glinkowski, Wojciech (6602141741)","56287395200; 23094778900; 6602141741","Telemedicine as a special case of machine translation","2015","Computerized Medical Imaging and Graphics","10","10.1016/j.compmedimag.2015.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983187666&doi=10.1016%2fj.compmedimag.2015.09.005&partnerID=40&md5=1735c79817207b4376840df0ccf5838c","Department of Multimedia, Polish-Japanese Institute of Information Technology, Warsaw, Poland; Department of Orthopedics and Traumatology of the Locomotor System, Center of Excellence TeleOrto for Telediagnostics, Injuries of the Locomotor System, Medical University of Warsaw, Warszawa, Poland; Polish Telemedicine Society, Warszawa, Poland","Wołk K., Department of Multimedia, Polish-Japanese Institute of Information Technology, Warsaw, Poland; Marasek K., Department of Multimedia, Polish-Japanese Institute of Information Technology, Warsaw, Poland; Glinkowski W., Department of Orthopedics and Traumatology of the Locomotor System, Center of Excellence TeleOrto for Telediagnostics, Injuries of the Locomotor System, Medical University of Warsaw, Warszawa, Poland, Polish Telemedicine Society, Warszawa, Poland","Machine translation is evolving quite rapidly in terms of quality. Nowadays, we have several machine translation systems available in the web, which provide reasonable translations. However, these systems are not perfect, and their quality may decrease in some specific domains. This paper examines the effects of different training methods when it comes to Polish-English Statistical Machine Translation system used for the medical data. Numerous elements of the EMEA parallel text corpora and not related OPUS Open Subtitles project were used as the ground for creation of phrase tables and different language models including the development, tuning and testing of these translation systems. The BLEU, NIST, METEOR, and TER metrics have been used in order to evaluate the results of various systems. Our experiments deal with the systems that include POS tagging, factored phrase models, hierarchical models, syntactic taggers, and other alignment methods. We also executed a deep analysis of Polish data as preparatory work before automatized data processing such as true casing or punctuation normalization phase. Normalized metrics was used to compare results. Scores lower than 15% mean that Machine Translation engine is unable to provide satisfying quality, scores greater than 30% mean that translations should be understandable without problems and scores over 50 reflect adequate translations. The average results of Polish to English translations scores for BLEU, NIST, METEOR, and TER were relatively high and ranged from 7058 to 8272. The lowest score was 6438. The average results ranges for English to Polish translations were little lower (6758-7897). The real-life implementations of presented high quality Machine Translation Systems are anticipated in general medical practice and telemedicine. © 2015 Published by Elsevier Ltd.","","Algorithms; Electronic Health Records; Machine Learning; Natural Language Processing; Pattern Recognition, Automated; Poland; Telemedicine; Translating; Vocabulary, Controlled; Computational linguistics; Data handling; Hierarchical systems; Telemedicine; Alignment methods; Hierarchical model; Machine translation systems; Machine translations; Normalized metrics; Real-life implementations; Statistical machine translation system; Translation systems; Article; data processing; general practice; human; information processing; language; mathematical parameters; medical information; normal human; priority journal; speech therapy; statistical machine translation; telemedicine; algorithm; automated pattern recognition; controlled vocabulary; electronic health record; machine learning; natural language processing; organization and management; Poland; procedures; telemedicine; translating (language); Computer aided language translation","Elsevier Ltd","08956111","","CMIGE","26617328","Article","Scopus","2-s2.0-84983187666"
"Suk H.-I.; Wee C.-Y.; Lee S.-W.; Shen D.","Suk, Heung-Il (56332955800); Wee, Chong-Yaw (7003756944); Lee, Seong-Whan (7601390519); Shen, Dinggang (7401738392)","56332955800; 7003756944; 7601390519; 7401738392","State-space model with deep learning for functional dynamics estimation in resting-state fMRI","2016","NeuroImage","232","10.1016/j.neuroimage.2016.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957052106&doi=10.1016%2fj.neuroimage.2016.01.005&partnerID=40&md5=d36a2ac29549b381aa2b7986d4122010","Department of Brain and Cognitive Engineering, Korea University, South Korea; Department of Biomedical Engineering, National University of Singapore, Singapore; Biomedical Research Imaging Center, Department of Radiology, University of North Carolina at Chapel Hill, United States","Suk H.-I., Department of Brain and Cognitive Engineering, Korea University, South Korea; Wee C.-Y., Department of Biomedical Engineering, National University of Singapore, Singapore; Lee S.-W., Department of Brain and Cognitive Engineering, Korea University, South Korea; Shen D., Department of Brain and Cognitive Engineering, Korea University, South Korea, Biomedical Research Imaging Center, Department of Radiology, University of North Carolina at Chapel Hill, United States","Studies on resting-state functional Magnetic Resonance Imaging (rs-fMRI) have shown that different brain regions still actively interact with each other while a subject is at rest, and such functional interaction is not stationary but changes over time. In terms of a large-scale brain network, in this paper, we focus on time-varying patterns of functional networks, i.e., functional dynamics, inherent in rs-fMRI, which is one of the emerging issues along with the network modelling. Specifically, we propose a novel methodological architecture that combines deep learning and state-space modelling, and apply it to rs-fMRI based Mild Cognitive Impairment (MCI) diagnosis. We first devise a Deep Auto-Encoder (DAE) to discover hierarchical non-linear functional relations among regions, by which we transform the regional features into an embedding space, whose bases are complex functional networks. Given the embedded functional features, we then use a Hidden Markov Model (HMM) to estimate dynamic characteristics of functional networks inherent in rs-fMRI via internal states, which are unobservable but can be inferred from observations statistically. By building a generative model with an HMM, we estimate the likelihood of the input features of rs-fMRI as belonging to the corresponding status, i.e., MCI or normal healthy control, based on which we identify the clinical label of a testing subject. In order to validate the effectiveness of the proposed method, we performed experiments on two different datasets and compared with state-of-the-art methods in the literature. We also analyzed the functional networks learned by DAE, estimated the functional connectivities by decoding hidden states in HMM, and investigated the estimated functional connectivities by means of a graph-theoretic approach. © 2016 Elsevier Inc.","Deep learning; Dynamic functional connectivity; Hidden Markov model; Mild cognitive impairment; Resting-state functional magnetic resonance imaging","Aged; Brain; Cognitive Dysfunction; Female; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Models, Neurological; Nerve Net; Rest; aged; Article; clinical article; cohort analysis; controlled study; deep learning; female; functional magnetic resonance imaging; hidden Markov model; human; image analysis; learning; male; mild cognitive impairment; nerve cell network; priority journal; resting state functional magnetic resonance imaging; signal noise ratio; signal processing; biological model; brain; cognitive defect; computer assisted diagnosis; diagnostic imaging; machine learning; nuclear magnetic resonance imaging; physiology; procedures; rest","Academic Press Inc.","10538119","","NEIME","26774612","Article","Scopus","2-s2.0-84957052106"
"Cai Y.; Landis M.; Laidley D.T.; Kornecki A.; Lum A.; Li S.","Cai, Yunliang (50460893000); Landis, Mark (56611587900); Laidley, David T. (9943780400); Kornecki, Anat (7003886154); Lum, Andrea (55807506300); Li, Shuo (57189925356)","50460893000; 56611587900; 9943780400; 7003886154; 55807506300; 57189925356","Multi-modal vertebrae recognition using Transformed Deep Convolution Network","2016","Computerized Medical Imaging and Graphics","80","10.1016/j.compmedimag.2016.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963930727&doi=10.1016%2fj.compmedimag.2016.02.002&partnerID=40&md5=313b2f12235b838d7a23ef328751323e","Dept. of Medical Biophysics, Schulich School of Medicine and Dentistry, University of Western Ontario, 1151 Richmond St, London, ON, Canada; Dept. of Medical Imaging, Schulich School of Medicine and Dentistry, University of Western Ontario, 1151 Richmond St, London, ON, Canada","Cai Y., Dept. of Medical Biophysics, Schulich School of Medicine and Dentistry, University of Western Ontario, 1151 Richmond St, London, ON, Canada; Landis M., Dept. of Medical Imaging, Schulich School of Medicine and Dentistry, University of Western Ontario, 1151 Richmond St, London, ON, Canada; Laidley D.T., Dept. of Medical Imaging, Schulich School of Medicine and Dentistry, University of Western Ontario, 1151 Richmond St, London, ON, Canada; Kornecki A., Dept. of Medical Imaging, Schulich School of Medicine and Dentistry, University of Western Ontario, 1151 Richmond St, London, ON, Canada; Lum A., Dept. of Medical Imaging, Schulich School of Medicine and Dentistry, University of Western Ontario, 1151 Richmond St, London, ON, Canada; Li S., Dept. of Medical Biophysics, Schulich School of Medicine and Dentistry, University of Western Ontario, 1151 Richmond St, London, ON, Canada, Dept. of Medical Imaging, Schulich School of Medicine and Dentistry, University of Western Ontario, 1151 Richmond St, London, ON, Canada","Automatic vertebra recognition, including the identification of vertebra locations and naming in multiple image modalities, are highly demanded in spinal clinical diagnoses where large amount of imaging data from various of modalities are frequently and interchangeably used. However, the recognition is challenging due to the variations of MR/CT appearances or shape/pose of the vertebrae. In this paper, we propose a method for multi-modal vertebra recognition using a novel deep learning architecture called Transformed Deep Convolution Network (TDCN). This new architecture can unsupervisely fuse image features from different modalities and automatically rectify the pose of vertebra. The fusion of MR and CT image features improves the discriminativity of feature representation and enhances the invariance of the vertebra pattern, which allows us to automatically process images from different contrast, resolution, protocols, even with different sizes and orientations. The feature fusion and pose rectification are naturally incorporated in a multi-layer deep learning network. Experiment results show that our method outperforms existing detection methods and provides a fully automatic location + naming + pose recognition for routine clinical practice. © 2016 Elsevier Ltd.","Convolution network; Deep learning; Vertebra detection; Vertebra recognition","Automation; Humans; Machine Learning; Spine; Computerized tomography; Convolution; Diagnosis; Image enhancement; Learning systems; Musculoskeletal system; Network architecture; Network layers; Automatic location; Clinical diagnosis; Clinical practices; Detection methods; Feature representation; Learning architectures; Vertebra detections; Vertebra recognition; Article; automation; computer assisted tomography; machine learning; nuclear magnetic resonance imaging; priority journal; sensitivity and specificity; transformed deep convulation netowrk; vertebra; diagnostic imaging; human; spine; Deep learning","Elsevier Ltd","08956111","","CMIGE","27104497","Article","Scopus","2-s2.0-84963930727"
"Kim J.; Calhoun V.D.; Shim E.; Lee J.-H.","Kim, Junghoe (48361613100); Calhoun, Vince D. (57898536200); Shim, Eunsoo (56857268800); Lee, Jong-Hwan (36065360400)","48361613100; 57898536200; 56857268800; 36065360400","Deep neural network with weight sparsity control and pre-training extracts hierarchical features and enhances classification performance: Evidence from whole-brain resting-state functional connectivity patterns of schizophrenia","2016","NeuroImage","269","10.1016/j.neuroimage.2015.05.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941964814&doi=10.1016%2fj.neuroimage.2015.05.018&partnerID=40&md5=bad466bc5c2832fd7a05ed4613aa265b","Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; Department of Electrical and Computer Engineering, University of New Mexico, NM, United States; Samsung Advanced Institute of Technology, Samsung Electronics, Suwon, South Korea; The Mind Research Network and LBERI, NM, United States","Kim J., Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; Calhoun V.D., Department of Electrical and Computer Engineering, University of New Mexico, NM, United States, The Mind Research Network and LBERI, NM, United States; Shim E., Samsung Advanced Institute of Technology, Samsung Electronics, Suwon, South Korea; Lee J.-H., Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea","Functional connectivity (FC) patterns obtained from resting-state functional magnetic resonance imaging data are commonly employed to study neuropsychiatric conditions by using pattern classifiers such as the support vector machine (SVM). Meanwhile, a deep neural network (DNN) with multiple hidden layers has shown its ability to systematically extract lower-to-higher level information of image and speech data from lower-to-higher hidden layers, markedly enhancing classification accuracy. The objective of this study was to adopt the DNN for whole-brain resting-state FC pattern classification of schizophrenia (SZ) patients vs. healthy controls (HCs) and identification of aberrant FC patterns associated with SZ. We hypothesized that the lower-to-higher level features learned via the DNN would significantly enhance the classification accuracy, and proposed an adaptive learning algorithm to explicitly control the weight sparsity in each hidden layer via L1-norm regularization. Furthermore, the weights were initialized via stacked autoencoder based pre-training to further improve the classification performance. Classification accuracy was systematically evaluated as a function of (1) the number of hidden layers/nodes, (2) the use of L1-norm regularization, (3) the use of the pre-training, (4) the use of framewise displacement (FD) removal, and (5) the use of anatomical/functional parcellation. Using FC patterns from anatomically parcellated regions without FD removal, an error rate of 14.2% was achieved by employing three hidden layers and 50 hidden nodes with both L1-norm regularization and pre-training, which was substantially lower than the error rate from the SVM (22.3%). Moreover, the trained DNN weights (i.e., the learned features) were found to represent the hierarchical organization of aberrant FC patterns in SZ compared with HC. Specifically, pairs of nodes extracted from the lower hidden layer represented sparse FC patterns implicated in SZ, which was quantified by using kurtosis/modularity measures and features from the higher hidden layer showed holistic/global FC patterns differentiating SZ from HC. Our proposed schemes and reported findings attained by using the DNN classifier and whole-brain FC data suggest that such approaches show improved ability to learn hidden patterns in brain imaging data, which may be useful for developing diagnostic tools for SZ and other neuropsychiatric disorders and identifying associated aberrant FC patterns. © 2015 Elsevier Inc.","Deep learning; Functional connectivity; Resting-state functional magnetic resonance imaging; Schizophrenia; Sparsity; Stacked autoencoder","Adult; Algorithms; Brain; Brain Mapping; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Neural Networks (Computer); Neural Pathways; Schizophrenia; adult; Article; artificial neural network; brain function; classification; classifier; clinical article; controlled study; deep neural network; error; female; functional magnetic resonance imaging; human; information processing; learning; learning algorithm; male; neuroimaging; priority journal; resting state network; schizophrenia; support vector machine; algorithm; brain; brain mapping; image processing; nerve tract; nuclear magnetic resonance imaging; pathophysiology; procedures; schizophrenia","Academic Press Inc.","10538119","","NEIME","25987366","Article","Scopus","2-s2.0-84941964814"
"Cheng S.; Guo M.; Wang C.; Liu X.; Liu Y.; Wu X.","Cheng, Shuang (57191576844); Guo, Maozu (7201564856); Wang, Chunyu (52164569700); Liu, Xiaoyan (56195855700); Liu, Yang (55912032400); Wu, Xuejian (57195394624)","57191576844; 7201564856; 52164569700; 56195855700; 55912032400; 57195394624","MiRTDL: A Deep Learning Approach for miRNA Target Prediction","2016","IEEE/ACM Transactions on Computational Biology and Bioinformatics","55","10.1109/TCBB.2015.2510002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85004151128&doi=10.1109%2fTCBB.2015.2510002&partnerID=40&md5=4cc1720e0bde6aa2b2c7e32595bc78e8","School of Computer Science and Technology, Harbin Institute of Technology, 92 West Dazhi Street, Harbin, China","Cheng S., School of Computer Science and Technology, Harbin Institute of Technology, 92 West Dazhi Street, Harbin, China; Guo M., School of Computer Science and Technology, Harbin Institute of Technology, 92 West Dazhi Street, Harbin, China; Wang C., School of Computer Science and Technology, Harbin Institute of Technology, 92 West Dazhi Street, Harbin, China; Liu X., School of Computer Science and Technology, Harbin Institute of Technology, 92 West Dazhi Street, Harbin, China; Liu Y., School of Computer Science and Technology, Harbin Institute of Technology, 92 West Dazhi Street, Harbin, China; Wu X., School of Computer Science and Technology, Harbin Institute of Technology, 92 West Dazhi Street, Harbin, China","MicroRNAs (miRNAs) regulate genes that are associated with various diseases. To better understand miRNAs, the miRNA regulatory mechanism needs to be investigated and the real targets identified. Here, we present miRTDL, a new miRNA target prediction algorithm based on convolutional neural network (CNN). The CNN automatically extracts essential information from the input data rather than completely relying on the input dataset generated artificially when the precise miRNA target mechanisms are poorly known. In this work, the constraint relaxing method is first used to construct a balanced training dataset to avoid inaccurate predictions caused by the existing unbalanced dataset. The miRTDL is then applied to 1,606 experimentally validated miRNA target pairs. Finally, the results show that our miRTDL outperforms the existing target prediction algorithms and achieves significantly higher sensitivity, specificity and accuracy of 88.43, 96.44, and 89.98 percent, respectively. We also investigate the miRNA target mechanism, and the results show that the complementation features are more important than the others. © 2004-2012 IEEE.","Constraint relaxation; convolutional neural network; miRNA; target prediction","Algorithms; Computational Biology; Humans; Machine Learning; MicroRNAs; Sequence Analysis, RNA; Convolution; Deep learning; Forecasting; Neural networks; microRNA; Constraint relaxation; Convolutional neural network; Learning approach; miRNA; Mirna target predictions; Regulatory mechanism; Target prediction; Training dataset; algorithm; biology; genetics; human; machine learning; procedures; sequence analysis; RNA","Institute of Electrical and Electronics Engineers Inc.","15455963","","","28055894","Article","Scopus","2-s2.0-85004151128"
"Setio A.A.A.; Ciompi F.; Litjens G.; Gerke P.; Jacobs C.; Van Riel S.J.; Wille M.M.W.; Naqibullah M.; Sanchez C.I.; Van Ginneken B.","Setio, Arnaud Arindra Adiyoso (53264801600); Ciompi, Francesco (32667506900); Litjens, Geert (36622356600); Gerke, Paul (57189294835); Jacobs, Colin (36145083400); Van Riel, Sarah J. (56376768500); Wille, Mathilde Marie Winkler (55571096700); Naqibullah, Matiullah (16319929800); Sanchez, Clara I. (8543425100); Van Ginneken, Bram (55759608800)","53264801600; 32667506900; 36622356600; 57189294835; 36145083400; 56376768500; 55571096700; 16319929800; 8543425100; 55759608800","Pulmonary Nodule Detection in CT Images: False Positive Reduction Using Multi-View Convolutional Networks","2016","IEEE Transactions on Medical Imaging","980","10.1109/TMI.2016.2536809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968638584&doi=10.1109%2fTMI.2016.2536809&partnerID=40&md5=a65a23723912d5e20cbf44b8582eb680","Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands; Department of Respiratory Medicine, Gentofte Hospital, University of Copenhagen, Hellerup, 2900, Denmark; Fraunhofer MEVIS, Bremen, 28359, Germany","Setio A.A.A., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands; Ciompi F., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands; Litjens G., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands; Gerke P., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands; Jacobs C., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands; Van Riel S.J., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands; Wille M.M.W., Department of Respiratory Medicine, Gentofte Hospital, University of Copenhagen, Hellerup, 2900, Denmark; Naqibullah M., Department of Respiratory Medicine, Gentofte Hospital, University of Copenhagen, Hellerup, 2900, Denmark; Sanchez C.I., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands; Van Ginneken B., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, 6525, GA, Netherlands, Fraunhofer MEVIS, Bremen, 28359, Germany","We propose a novel Computer-Aided Detection (CAD) system for pulmonary nodules using multi-view convolutional networks (ConvNets), for which discriminative features are automatically learnt from the training data. The network is fed with nodule candidates obtained by combining three candidate detectors specifically designed for solid, subsolid, and large nodules. For each candidate, a set of 2-D patches from differently oriented planes is extracted. The proposed architecture comprises multiple streams of 2-D ConvNets, for which the outputs are combined using a dedicated fusion method to get the final classification. Data augmentation and dropout are applied to avoid overfitting. On 888 scans of the publicly available LIDC-IDRI dataset, our method reaches high detection sensitivities of 85.4% and 90.1% at 1 and 4 false positives per scan, respectively. An additional evaluation on independent datasets from the ANODE09 challenge and DLCST is performed. We showed that the proposed multi-view ConvNets is highly suited to be used for false positive reduction of a CAD system. © 1982-2012 IEEE.","Computed tomography; computer-aided detection; convolutional networks; deep learning; lung cancer; pulmonary nodule","Algorithms; Humans; Lung Neoplasms; Machine Learning; Pattern Recognition, Automated; Radiographic Image Interpretation, Computer-Assisted; Solitary Pulmonary Nodule; Tomography, X-Ray Computed; Computer aided instruction; Computer networks; Convolution; Positron emission tomography; Computer aided detection; Convolutional networks; Deep learning; Lung Cancer; Pulmonary nodules; Article; computer aided detection; computer assisted tomography; evaluation study; lung nodule; machine learning; multi view convolutional network; training; algorithm; automated pattern recognition; computer assisted diagnosis; diagnostic imaging; human; lung nodule; lung tumor; machine learning; procedures; x-ray computed tomography; Computerized tomography","Institute of Electrical and Electronics Engineers Inc.","02780062","","ITMID","26955024","Article","Scopus","2-s2.0-84968638584"
"Hu X.; Zhang J.; Qi P.; Zhang B.","Hu, Xiaolin (55496159600); Zhang, Jianwei (56039580400); Qi, Peng (57190487937); Zhang, Bo (57199725787)","55496159600; 56039580400; 57190487937; 57199725787","Modeling response properties of V2 neurons using a hierarchical K-means model","2014","Neurocomputing","8","10.1016/j.neucom.2013.07.052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896548338&doi=10.1016%2fj.neucom.2013.07.052&partnerID=40&md5=511ec6277eed887a9b99c1d1d4034caf","State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Lab. for Information Science and Technology (TNList), Dept. of Computer Science and Technology, Tsinghua University, Beijing 100084, China; Department of Informatics, University of Hamburg, Hamburg D-22527, Germany","Hu X., State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Lab. for Information Science and Technology (TNList), Dept. of Computer Science and Technology, Tsinghua University, Beijing 100084, China; Zhang J., Department of Informatics, University of Hamburg, Hamburg D-22527, Germany; Qi P., State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Lab. for Information Science and Technology (TNList), Dept. of Computer Science and Technology, Tsinghua University, Beijing 100084, China; Zhang B., State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Lab. for Information Science and Technology (TNList), Dept. of Computer Science and Technology, Tsinghua University, Beijing 100084, China","Many computational models have been proposed for interpreting the properties of neurons in the primary visual cortex (V1). But relatively fewer models have been proposed for interpreting the properties of neurons beyond V1. Recently, it was found that the sparse deep belief network (DBN) could reproduce some properties of the secondary visual cortex (V2) neurons when trained on natural images. In this paper, by investigating the key factors that contribute to the success of the sparse DBN, we propose a hierarchical model based on a simple algorithm, K-means, which can be realized by competitive Hebbian learning. The resulting model exhibits some response properties of V2 neurons, and it is more biologically feasible and computationally efficient than the sparse DBN. © 2014 Elsevier B.V.","Deep learning; K-means; Neural network; V1; V2","Hierarchical systems; Neurons; Computationally efficient; Deep belief network (DBN); Deep learning; Hierarchical k-means; K-means; Primary visual cortex; V1; V2; animal tissue; article; deep belief network; k means algorithm; learning algorithm; machine learning; nerve cell network; neuroscience; nonhuman; normal distribution; priority journal; probability; receptive field; restricted Boltzmann machine; statistics; stochastic model; striate cortex; synapse; Neural networks","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84896548338"
"Wang X.","Wang, Xin (56359449300)","56359449300","Content and eigenvector centrality-based music classification algorithm","2014","Journal of Chemical and Pharmaceutical Research","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907093734&partnerID=40&md5=13d6bc40e68e69e711d89b0ea71340f8","Computer Engineering School, Weifang University, Shandong, 261061, China","Wang X., Computer Engineering School, Weifang University, Shandong, 261061, China","With the rapid development of Internet and the improvement of the storage techniques, more and more music resources are gotten, and correspondingly their classification becomes an important issue. Up to now, three main classification methods have been proposed, which are Tag-based approach, content-based approach and the methods based on machine learning. Although these approaches have been analyzed and compared based on the music features; there are still no deep researches on the intrinsic relationship between the music. This paper focuses on this issue and presents a novel music classification algorithm based on both the music content and the critical eigenvector centrality. Firstly, the new algorithm extracts the MFCC (Mel Frequency Cepstrum Coefficient) and Rhythm features of music, and then the K-Means algorithm is used to cluster these features. As a result, K-cluster centers are generated. Correspondingly, the music network using similarity relations can be constructed. At last, the music network is analyzed by using a graph-based eigenvector centrality and the music classification is completed by joint considering the K-cluster centers. Moreover, experiments are provided to evaluate the new proposed classification algorithm, and its performance is also compared with the conventional content-based classification algorithm. The results show that the new music classification algorithm is more reasonable to satisfy the needs of most of users. © 2014, Journal of Chemical and Pharmaceutical Research. All rights reserved.","Content; Eigenvectorcentrality; K-Means algorithm; Music classification","Content; Eigenvectorcentrality; k-Means algorithm; Music classification; algorithm; Article; classification; eigenvector centrality; extraction; machine learning; mathematical analysis; mathematical phenomena; mel frequency cepstrum coefficient; music; musical rhythm","Journal of Chemical and Pharmaceutical Research","09757384","","","","Article","Scopus","2-s2.0-84907093734"
"Baldi P.; Sadowski P.; Whiteson D.","Baldi, P. (7101759672); Sadowski, P. (56074914700); Whiteson, D. (57203215394)","7101759672; 56074914700; 57203215394","Searching for exotic particles in high-energy physics with deep learning","2014","Nature Communications","795","10.1038/ncomms5308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903779279&doi=10.1038%2fncomms5308&partnerID=40&md5=16e14f3cad377cbe9385e8991eb275b9","Department of Computer Science, UC Irvine, Irvine, CA 92617, United States; Department of Physics and Astronomy, UC Irvine, Irvine, CA 92617, United States","Baldi P., Department of Computer Science, UC Irvine, Irvine, CA 92617, United States; Sadowski P., Department of Computer Science, UC Irvine, Irvine, CA 92617, United States; Whiteson D., Department of Physics and Astronomy, UC Irvine, Irvine, CA 92617, United States","Collisions at high-energy particle colliders are a traditionally fruitful source of exotic particle discoveries. Finding these rare particles requires solving difficult signal-versus-background classification problems, hence machine-learning approaches are often used. Standard approaches have relied on 'shallow' machine-learning models that have a limited capacity to learn complex nonlinear functions of the inputs, and rely on a painstaking search through manually constructed nonlinear features. Progress on this problem has slowed, as a variety of techniques have shown equivalent performance. Recent advances in the field of deep learning make it possible to learn more complex functions and better discriminate between signal and background classes. Here, using benchmark data sets, we show that deep-learning methods need no manually constructed inputs and yet improve the classification metric by as much as 8% over the best current approaches. This demonstrates that deep-learning approaches can improve the power of collider searches for exotic particles. © 2014 Macmillan Publishers Limited.","","collision; energy efficiency; machinery; numerical model; particulate matter; performance assessment; article; atomic particle; boson; classification; deep learning; gluon; hadron; high energy physics; learning algorithm; lepton; machine learning; magnetic and electromagnetic equipment; muon; neutrino; physics; quality control; quark","Nature Publishing Group","20411723","","","","Article","Scopus","2-s2.0-84903779279"
"Hagenbuchner M.; Cliff D.P.; Trost S.G.; Van Tuc N.; Peoples G.E.","Hagenbuchner, Markus (6602995698); Cliff, Dylan P. (15843234300); Trost, Stewart G. (7005718888); Van Tuc, Nguyen (55916260800); Peoples, Gregory E. (26026492100)","6602995698; 15843234300; 7005718888; 55916260800; 26026492100","Prediction of activity type in preschool children using machine learning techniques","2015","Journal of Science and Medicine in Sport","48","10.1016/j.jsams.2014.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946475689&doi=10.1016%2fj.jsams.2014.06.003&partnerID=40&md5=a986fe03bdc05da8d5d447e3b08a4e3d","Faculty of Engineering and Information Science, University of Wollongong, Australia; Faculty of Social Sciences, Early Start Research Institute, University of Wollongong, Australia; Institute of Health and Biomedical Innovation, Queensland University of Technology, Australia; School of Medicine, University of Wollongong, Australia","Hagenbuchner M., Faculty of Engineering and Information Science, University of Wollongong, Australia; Cliff D.P., Faculty of Social Sciences, Early Start Research Institute, University of Wollongong, Australia; Trost S.G., Institute of Health and Biomedical Innovation, Queensland University of Technology, Australia; Van Tuc N., Faculty of Engineering and Information Science, University of Wollongong, Australia; Peoples G.E., School of Medicine, University of Wollongong, Australia","Objectives: Recent research has shown that machine learning techniques can accurately predict activity classes from accelerometer data in adolescents and adults. The purpose of this study is to develop and test machine learning models for predicting activity type in preschool-aged children. Design: Participants completed 12 standardised activity trials (TV, reading, tablet game, quiet play, art, treasure hunt, cleaning up, active game, obstacle course, bicycle riding) over two laboratory visits. Methods: Eleven children aged 3-6 years (mean age. =4.8. ± 0.87; 55% girls) completed the activity trials while wearing an ActiGraph GT3X+ accelerometer on the right hip. Activities were categorised into five activity classes: sedentary activities, light activities, moderate to vigorous activities, walking, and running. A standard feed-forward Artificial Neural Network and a Deep Learning Ensemble Network were trained on features in the accelerometer data used in previous investigations (10th, 25th, 50th, 75th and 90th percentiles and the lag-one autocorrelation). Results: Overall recognition accuracy for the standard feed forward Artificial Neural Network was 69.7%. Recognition accuracy for sedentary activities, light activities and games, moderate-to-vigorous activities, walking, and running was 82%, 79%, 64%, 36% and 46%, respectively. In comparison, overall recognition accuracy for the Deep Learning Ensemble Network was 82.6%. For sedentary activities, light activities and games, moderate-to-vigorous activities, walking, and running recognition accuracy was 84%, 91%, 79%, 73% and 73%, respectively. Conclusions: Ensemble machine learning approaches such as Deep Learning Ensemble Network can accurately predict activity type from accelerometer data in preschool children. © 2014 Sports Medicine Australia.","Accelerometry; Exercise; Neural networks; Pattern recognition; Physical activity; Validity","Accelerometry; Activities of Daily Living; Bicycling; Child; Child, Preschool; Female; Humans; Machine Learning; Male; Models, Theoretical; Motor Activity; Neural Networks (Computer); Play and Playthings; Running; Walking; accelerometer; accelerometry; art; Article; artificial neural network; child; cleaning; comparative study; controlled study; cycling; deep learning ensemble network; female; game; hip; human; human experiment; laboratory; machine learning; male; measurement accuracy; normal human; physical activity; play; prediction; predictive value; preschool child; reading; running; sitting; sport; walking; accelerometry; daily life activity; motor activity; recreation; theoretical model","Elsevier Ltd","14402440","","JSMSF","25088983","Article","Scopus","2-s2.0-84946475689"
"Lyons J.; Dehzangi A.; Heffernan R.; Sharma A.; Paliwal K.; Sattar A.; Zhou Y.; Yang Y.","Lyons, James (58584602500); Dehzangi, Abdollah (23396537700); Heffernan, Rhys (56388539300); Sharma, Alok (55482800200); Paliwal, Kuldip (7005281122); Sattar, Abdul (7006680929); Zhou, Yaoqi (7405366766); Yang, Yuedong (8439078900)","58584602500; 23396537700; 56388539300; 55482800200; 7005281122; 7006680929; 7405366766; 8439078900","Predicting backbone Cα angles and dihedrals from protein sequences by stacked sparse auto-encoder deep neural network","2014","Journal of Computational Chemistry","135","10.1002/jcc.23718","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927770389&doi=10.1002%2fjcc.23718&partnerID=40&md5=7509e67304b086325e69163e16dd5ab0","Institute for Integrated and Intelligent Systems, Griffith University, Brisbane, Australia; National ICT Australia (NICTA), Brisbane, Australia; School of Engineering and Physics, University of the South Pacific, Laucala Campus, Private Mail Bag, Suva, Fiji; Institute for Glycomics, School of Information and Communication Technique, Griffith University, Parklands Dr., Southport, 4222, QLD, Australia","Lyons J., Institute for Integrated and Intelligent Systems, Griffith University, Brisbane, Australia; Dehzangi A., Institute for Integrated and Intelligent Systems, Griffith University, Brisbane, Australia, National ICT Australia (NICTA), Brisbane, Australia; Heffernan R., Institute for Integrated and Intelligent Systems, Griffith University, Brisbane, Australia; Sharma A., Institute for Integrated and Intelligent Systems, Griffith University, Brisbane, Australia, School of Engineering and Physics, University of the South Pacific, Laucala Campus, Private Mail Bag, Suva, Fiji; Paliwal K., Institute for Integrated and Intelligent Systems, Griffith University, Brisbane, Australia; Sattar A., Institute for Integrated and Intelligent Systems, Griffith University, Brisbane, Australia, National ICT Australia (NICTA), Brisbane, Australia; Zhou Y., Institute for Glycomics, School of Information and Communication Technique, Griffith University, Parklands Dr., Southport, 4222, QLD, Australia; Yang Y., Institute for Glycomics, School of Information and Communication Technique, Griffith University, Parklands Dr., Southport, 4222, QLD, Australia","Because a nearly constant distance between two neighbouring Cα atoms, local backbone structure of proteins can be represented accurately by the angle between Cαi-1-Cαi-Cαi+1 (θ) and a dihedral angle rotated about the Cαi-Cαi+1 bond (τ). θ and τ angles, as the representative of structural properties of three to four amino-acid residues, offer a description of backbone conformations that is complementary to φ and ψ angles (single residue) and secondary structures (>3 residues). Here, we report the first machine-learning technique for sequence-based prediction of θ and τ angles. Predicted angles based on an independent test have a mean absolute error of 9° for θ and 34° for τ with a distribution on the θ-τ plane close to that of native values. The average root-mean-square distance of 10-residue fragment structures constructed from predicted θ and τ angles is only 1.9Å from their corresponding native structures. Predicted θ and τ angles are expected to be complementary to predicted φ and ψ angles and secondary structures for using in model validation and template-based as well as template-free structure prediction. The deep neural network learning technique is available as an on-line server called Structural Property prediction with Integrated DEep neuRal network (SPIDER) at http://sparks-lab.org. © 2014 Wiley Periodicals, Inc.","deep learning; fold recognition; fragment structure prediction; local structure prediction; neural network; protein structure prediction; secondary structure prediction","Neural Networks (Computer); Proteins; Amino acids; Artificial intelligence; Dihedral angle; Forecasting; Learning algorithms; Learning systems; Neural networks; Proteins; Structural properties; protein; Deep learning; Fold recognition; Local structure; Protein structure prediction; Secondary structure prediction; Structure prediction; artificial neural network; chemistry; C (programming language)","John Wiley and Sons Inc.","01928651","","JCCHD","25212657","Article","Scopus","2-s2.0-84927770389"
"Khaligh-Razavi S.-M.; Kriegeskorte N.","Khaligh-Razavi, Seyed-Mahdi (55037384600); Kriegeskorte, Nikolaus (57207515493)","55037384600; 57207515493","Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical Representation","2014","PLoS Computational Biology","665","10.1371/journal.pcbi.1003915","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912102994&doi=10.1371%2fjournal.pcbi.1003915&partnerID=40&md5=039de771fd6f72d2386256a179c920c2","Medical Research Council, Cognition and Brain Sciences Unit, Cambridge, United Kingdom","Khaligh-Razavi S.-M., Medical Research Council, Cognition and Brain Sciences Unit, Cambridge, United Kingdom; Kriegeskorte N., Medical Research Council, Cognition and Brain Sciences Unit, Cambridge, United Kingdom","Inferior temporal (IT) cortex in human and nonhuman primates serves visual object recognition. Computational object-vision models, although continually improving, do not yet reach human performance. It is unclear to what extent the internal representations of computational models can explain the IT representation. Here we investigate a wide range of computational model representations (37 in total), testing their categorization performance and their ability to account for the IT representational geometry. The models include well-known neuroscientific object-recognition models (e.g. HMAX, VisNet) along with several models from computer vision (e.g. SIFT, GIST, self-similarity features, and a deep convolutional neural network). We compared the representational dissimilarity matrices (RDMs) of the model representations with the RDMs obtained from human IT (measured with fMRI) and monkey IT (measured with cell recording) for the same set of stimuli (not used in training the models). Better performing models were more similar to IT in that they showed greater clustering of representational patterns by category. In addition, better performing models also more strongly resembled IT in terms of their within-category representational dissimilarities. Representational geometries were significantly correlated between IT and many of the models. However, the categorical clustering observed in IT was largely unexplained by the unsupervised models. The deep convolutional network, which was trained by supervision with over a million category-labeled images, reached the highest categorization performance and also best explained IT, although it did not fully explain the IT data. Combining the features of this model with appropriate weights and adding linear combinations that maximize the margin between animate and inanimate objects and between faces and other objects yielded a representation that fully explained our IT data. Overall, our results suggest that explaining IT requires computational features trained through supervised learning to emphasize the behaviorally important categorical divisions prominently reflected in IT. © 2014 Khaligh-Razavi, Kriegeskorte.","","Animals; Computational Biology; Haplorhini; Humans; Models, Neurological; Support Vector Machines; Temporal Lobe; Computation theory; Computational geometry; Computational methods; Convolution; Mammals; Neurophysiology; Object recognition; Computational modelling; Computational objects; Dissimilarity matrix; Inferior temporal cortices; Model representation; Non-human primate; Performance; Temporal Data; Vision model; Visual object recognition; Article; artificial neural network; brain function; brain region; computer model; functional magnetic resonance imaging; geometry; histogram; human; human versus animal comparison; image analysis; inferior temporal cortex; intermethod comparison; nonhuman; pattern recognition; support vector machine; validation process; animal; biological model; biology; Haplorhini; physiology; procedures; temporal lobe; Deep neural networks","Public Library of Science","1553734X","","","25375136","Article","Scopus","2-s2.0-84912102994"
"Ditzler G.; Polikar R.; Rosen G.","Ditzler, Gregory (36019949100); Polikar, Robi (7003651287); Rosen, Gail (9335288900)","36019949100; 7003651287; 9335288900","Multi-Layer and Recursive Neural Networks for Metagenomic Classification","2015","IEEE Transactions on Nanobioscience","73","10.1109/TNB.2015.2461219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940974958&doi=10.1109%2fTNB.2015.2461219&partnerID=40&md5=5b2d90296e186c62b581bfdb58344e21","Department of Electrical and Computer Engineering, Drexel University, Philadelphia, 19104, PA, United States; Department of Electrical and Computer Engineering, Rowan University, Glassboro, 08028, NJ, United States","Ditzler G., Department of Electrical and Computer Engineering, Drexel University, Philadelphia, 19104, PA, United States; Polikar R., Department of Electrical and Computer Engineering, Rowan University, Glassboro, 08028, NJ, United States; Rosen G., Department of Electrical and Computer Engineering, Drexel University, Philadelphia, 19104, PA, United States","Recent advances in machine learning, specifically in deep learning with neural networks, has made a profound impact on fields such as natural language processing, image classification, and language modeling; however, feasibility and potential benefits of the approaches to metagenomic data analysis has been largely under-explored. Deep learning exploits many layers of learning nonlinear feature representations, typically in an unsupervised fashion, and recent results have shown outstanding generalization performance on previously unseen data. Furthermore, some deep learning methods can also represent the structure in a data set. Consequently, deep learning and neural networks may prove to be an appropriate approach for metagenomic data. To determine whether such approaches are indeed appropriate for metagenomics, we experiment with two deep learning methods: i) a deep belief network, and ii) a recursive neural network, the latter of which provides a tree representing the structure of the data. We compare these approaches to the standard multi-layer perceptron, which has been well-established in the machine learning community as a powerful prediction algorithm, though its presence is largely missing in metagenomics literature. We find that traditional neural networks can be quite powerful classifiers on metagenomic data compared to baseline methods, such as random forests. On the other hand, while the deep learning approaches did not result in improvements to the classification accuracy, they do provide the ability to learn hierarchical representations of a data set that standard classification methods do not allow. Our goal in this effort is not to determine the best algorithm in terms accuracy - as that depends on the specific application - but rather to highlight the benefits and drawbacks of each of the approach we discuss and provide insight on how they can be improved for predictive metagenomic analysis. © 2002-2011 IEEE.","Comparative metagenomics; Metagenomics; Microbiome; Neural networks","Algorithms; Metagenomics; Microbiota; Neural Networks (Computer); Algorithms; Artificial intelligence; Computational linguistics; Decision trees; Image classification; Learning algorithms; Learning systems; Modeling languages; Natural language processing systems; Neural networks; Classification accuracy; Generalization performance; Hierarchical representation; Machine learning communities; Metagenomics; Microbiome; NAtural language processing; Recursive neural networks; algorithm; artificial neural network; metagenomics; microflora; procedures; Classification (of information)","Institute of Electrical and Electronics Engineers Inc.","15361241","","","26316190","Article","Scopus","2-s2.0-84940974958"
"Kim S.; Yu Z.; Kil R.M.; Lee M.","Kim, Sangwook (57169169400); Yu, Zhibin (36999020600); Kil, Rhee Man (6602829112); Lee, Minho (57191730119)","57169169400; 36999020600; 6602829112; 57191730119","Deep learning of support vector machines with class probability output networks","2015","Neural Networks","65","10.1016/j.neunet.2014.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922352357&doi=10.1016%2fj.neunet.2014.09.007&partnerID=40&md5=44d0e8c84a02057bc93c020f89cdc369","School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; College of Information and Communication Engineering, Sungkyunkwan University, 2066, Seobu-ro, Jangan-gu, Suwon, Gyeonggi-do, 440-746, South Korea","Kim S., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; Yu Z., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; Kil R.M., College of Information and Communication Engineering, Sungkyunkwan University, 2066, Seobu-ro, Jangan-gu, Suwon, Gyeonggi-do, 440-746, South Korea; Lee M., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea","Deep learning methods endeavor to learn features automatically at multiple levels and allow systems to learn complex functions mapping from the input space to the output space for the given data. The ability to learn powerful features automatically is increasingly important as the volume of data and range of applications of machine learning methods continues to grow. This paper proposes a new deep architecture that uses support vector machines (SVMs) with class probability output networks (CPONs) to provide better generalization power for pattern classification problems. As a result, deep features are extracted without additional feature engineering steps, using multiple layers of the SVM classifiers with CPONs. The proposed structure closely approaches the ideal Bayes classifier as the number of layers increases. Using a simulation of classification problems, the effectiveness of the proposed method is demonstrated. © 2014 Elsevier Ltd.","Class probability output network; Deep learning; Support vector machine; Uncertainty measure","Bayes Theorem; Pattern Recognition, Automated; Support Vector Machines; Artificial intelligence; Complex networks; Learning systems; Probability; Class probabilities; Deep learning; Feature engineerings; Machine learning methods; Output network; Pattern classification problems; Support vector machine (SVMs); Uncertainty measures; Article; artificial neural network; Bayes decision theory; class probability output network; classifier; decision theory; deep learning; learning algorithm; measurement accuracy; probability; problem solving; support vector machine; systematic error; validation process; automated pattern recognition; Bayes theorem; procedures; Support vector machines","Elsevier Ltd","08936080","","NNETE","25304363","Article","Scopus","2-s2.0-84922352357"
"Nanni L.; Brahnam S.; Ghidoni S.; Lumini A.","Nanni, Loris (8976580000); Brahnam, Sheryl (55912322400); Ghidoni, Stefano (23392337500); Lumini, Alessandra (10040521600)","8976580000; 55912322400; 23392337500; 10040521600","Toward a General-Purpose Heterogeneous Ensemble for Pattern Classification","2015","Computational Intelligence and Neuroscience","24","10.1155/2015/909123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941255122&doi=10.1155%2f2015%2f909123&partnerID=40&md5=aeb51c83faa2b3c16ad3f6997c15e56d","DEI, University of Padova, Via Gradenigo 6, Padova, 35131, Italy; Computer Information Systems, Missouri State University, 901 S. National, Springfield, 65804, MO, United States; DISI, Università di Bologna, Via Sacchi 3, Cesena, 47521, Italy","Nanni L., DEI, University of Padova, Via Gradenigo 6, Padova, 35131, Italy; Brahnam S., Computer Information Systems, Missouri State University, 901 S. National, Springfield, 65804, MO, United States; Ghidoni S., DEI, University of Padova, Via Gradenigo 6, Padova, 35131, Italy; Lumini A., DISI, Università di Bologna, Via Sacchi 3, Cesena, 47521, Italy","We perform an extensive study of the performance of different classification approaches on twenty-five datasets (fourteen image datasets and eleven UCI data mining datasets). The aim is to find General-Purpose (GP) heterogeneous ensembles (requiring little to no parameter tuning) that perform competitively across multiple datasets. The state-of-the-art classifiers examined in this study include the support vector machine, Gaussian process classifiers, random subspace of adaboost, random subspace of rotation boosting, and deep learning classifiers. We demonstrate that a heterogeneous ensemble based on the simple fusion by sum rule of different classifiers performs consistently well across all twenty-five datasets. The most important result of our investigation is demonstrating that some very recent approaches, including the heterogeneous ensemble we propose in this paper, are capable of outperforming an SVM classifier (implemented with LibSVM), even when both kernel selection and SVM parameters are carefully tuned for each dataset. © 2015 Loris Nanni et al.","","Algorithms; Artificial Intelligence; Computer Simulation; Datasets as Topic; Humans; Learning; Normal Distribution; Pattern Recognition, Automated; ROC Curve; Adaptive boosting; Data mining; Support vector machines; Vectors; Classification approach; Gaussian Processes; Heterogeneous ensembles; Kernel selection; Multiple data sets; Parameter-tuning; Random subspaces; State of the art; algorithm; artificial intelligence; automated pattern recognition; computer simulation; human; information processing; learning; normal distribution; receiver operating characteristic; Classification (of information)","Hindawi Limited","16875265","","","26413089","Article","Scopus","2-s2.0-84941255122"
"Kendra R.L.; Karki S.; Eickholt J.L.; Gandy L.","Kendra, Rachel Lynn (57193966280); Karki, Suman (56516436800); Eickholt, Jesse Lee (35069298500); Gandy, Lisa (14009977700)","57193966280; 56516436800; 35069298500; 14009977700","Characterizing the discussion of antibiotics in the Twittersphere: What is the bigger picture?","2015","Journal of Medical Internet Research","29","10.2196/jmir.4220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936754361&doi=10.2196%2fjmir.4220&partnerID=40&md5=480c6a0b20806d0dd33f2440151ce543","Department of Computer Science, Central Michigan University, 413 Pearce Hall, Mount Pleasant, 48859, MI, United States","Kendra R.L., Department of Computer Science, Central Michigan University, 413 Pearce Hall, Mount Pleasant, 48859, MI, United States; Karki S., Department of Computer Science, Central Michigan University, 413 Pearce Hall, Mount Pleasant, 48859, MI, United States; Eickholt J.L., Department of Computer Science, Central Michigan University, 413 Pearce Hall, Mount Pleasant, 48859, MI, United States; Gandy L., Department of Computer Science, Central Michigan University, 413 Pearce Hall, Mount Pleasant, 48859, MI, United States","Background: User content posted through Twitter has been used for biosurveillance, to characterize public perception of health-related topics, and as a means of distributing information to the general public. Most of the existing work surrounding Twitter and health care has shown Twitter to be an effective medium for these problems but more could be done to provide finer and more efficient access to all pertinent data. Given the diversity of user-generated content, small samples or summary presentations of the data arguably omit a large part of the virtual discussion taking place in the Twittersphere. Still, managing, processing, and querying large amounts of Twitter data is not a trivial task. This work describes tools and techniques capable of handling larger sets of Twitter data and demonstrates their use with the issue of antibiotics. Objective: This work has two principle objectives: (1) to provide an open-source means to efficiently explore all collected tweets and query health-related topics on Twitter, specifically, questions such as what users are saying and how messages are spread, and (2) to characterize the larger discourse taking place on Twitter with respect to antibiotics. Methods: Open-source software suites Hadoop, Flume, and Hive were used to collect and query a large number of Twitter posts. To classify tweets by topic, a deep network classifier was trained using a limited number of manually classified tweets. The particular machine learning approach used also allowed the use of a large number of unclassified tweets to increase performance. Results: Query-based analysis of the collected tweets revealed that a large number of users contributed to the online discussion and that a frequent topic mentioned was resistance. A number of prominent events related to antibiotics led to a number of spikes in activity but these were short in duration. The category-based classifier developed was able to correctly classify 70% of manually labeled tweets (using a 10-fold cross validation procedure and 9 classes). The classifier also performed well when evaluated on a per category basis. Conclusions: Using existing tools such as Hive, Flume, Hadoop, and machine learning techniques, it is possible to construct tools and workflows to collect and query large amounts of Twitter data to characterize the larger discussion taking place on Twitter with respect to a particular health-related topic. Furthermore, using newer machine learning techniques and a limited number of manually labeled tweets, an entire body of collected tweets can be classified to indicate what topics are driving the virtual, online discussion. The resulting classifier can also be used to efficiently explore collected tweets by category and search for messages of interest or exemplary content.","Internet; Neural network; Semi-supervised learning; Social media; Twitter messaging; Web mining","Anti-Bacterial Agents; Attitude to Health; Drug Resistance, Microbial; Humans; Information Dissemination; Internet; Machine Learning; Public Opinion; Social Media; Software; antiinfective agent; antibiotic resistance; attitude to health; human; information dissemination; Internet; machine learning; public opinion; social media; software","JMIR Publications Inc.","14388871","","","26091775","Article","Scopus","2-s2.0-84936754361"
"Plis S.M.; Hjelm D.R.; Slakhutdinov R.; Allen E.A.; Bockholt H.J.; Long J.D.; Johnson H.; Paulsen J.; Turner J.; Calhoun V.D.","Plis, Sergey M. (8970496000); Hjelm, Devon R. (56321732500); Slakhutdinov, Ruslan (56321831500); Allen, Elena A. (38661101000); Bockholt, H. Jeremy (6507900612); Long, Jeffrey D. (7403447437); Johnson, Hans (57158367900); Paulsen, Jane (7102109661); Turner, Jessica (7404250345); Calhoun, Vince D. (57898536200)","8970496000; 56321732500; 56321831500; 38661101000; 6507900612; 7403447437; 57158367900; 7102109661; 7404250345; 57898536200","Deep learning for neuroimaging: A validation study","2014","Frontiers in Neuroscience","399","10.3389/fnins.2014.00229","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905900149&doi=10.3389%2ffnins.2014.00229&partnerID=40&md5=b05c0a22bf2bb86580d72b6d09ac06bb","The Mind Research Network, Albuquerque, NM, United States; University of New Mexico, Albuquerque, NM, United States; University of Toronto, Toronto, Ontario, Canada; University of Iowa, Iowa City, IA, United States; Georgia State University, Atlanta, GA, United States; Department of Biological and Medical Psychology, University of Bergen, Norway","Plis S.M., The Mind Research Network, Albuquerque, NM, United States; Hjelm D.R., University of New Mexico, Albuquerque, NM, United States; Slakhutdinov R., University of Toronto, Toronto, Ontario, Canada; Allen E.A., The Mind Research Network, Albuquerque, NM, United States, Department of Biological and Medical Psychology, University of Bergen, Norway; Bockholt H.J., University of Iowa, Iowa City, IA, United States; Long J.D., University of Iowa, Iowa City, IA, United States; Johnson H., University of Iowa, Iowa City, IA, United States; Paulsen J., University of Iowa, Iowa City, IA, United States; Turner J., Georgia State University, Atlanta, GA, United States; Calhoun V.D., The Mind Research Network, Albuquerque, NM, United States, University of New Mexico, Albuquerque, NM, United States","Deep learning methods have recently made notable advances in the tasks of classification and representation learning. These tasks are important for brain imaging and neuroscience discovery, making the methods attractive for porting to a neuroimager's toolbox. Success of these methods is, in part, explained by the flexibility of deep learning models. However, this flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. These methods include deep belief networks and their building block the restricted Boltzmann machine. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data. © 2014 Plis, Hjelm, Salakhutdinov, Allen, Bockholt, Long, Johnson, Paulsen, Turner and Calhoun.","Classification; fMRI; Intrinsic networks; MRI; Unsupervised learning","algorithm; article; back propagation; brain region; contrast to noise ratio; controlled study; deep learning; embedding; functional magnetic resonance imaging; functional neuroimaging; human; image processing; learning; neuroimaging; receptive field; structural neuroimaging; validation study; artificial neural network; functional neuroimaging; Huntington chorea; schizophrenia","Frontiers Research Foundation","16624548","","","","Article","Scopus","2-s2.0-84905900149"
"Rajpurohit V.; Danish S.F.; Hargreaves E.L.; Wong S.","Rajpurohit, Vikram (58334981800); Danish, Shabbar F. (8316644500); Hargreaves, Eric L. (6603829437); Wong, Stephen (12781047500)","58334981800; 8316644500; 6603829437; 12781047500","Optimizing computational feature sets for subthalamic nucleus localization in DBS surgery with feature selection","2015","Clinical Neurophysiology","27","10.1016/j.clinph.2014.05.039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926170265&doi=10.1016%2fj.clinph.2014.05.039&partnerID=40&md5=833678208c94da3b33f955de34e7a9ec","Rutgers - Robert Wood Johnson Medical School, United States; Department of Surgery, Division of Neurosurgery, Rutgers - Robert Wood Johnson Medical School, United States; Department of Neurology, Rutgers - Robert Wood Johnson Medical School, United States","Rajpurohit V., Rutgers - Robert Wood Johnson Medical School, United States; Danish S.F., Department of Surgery, Division of Neurosurgery, Rutgers - Robert Wood Johnson Medical School, United States; Hargreaves E.L., Department of Surgery, Division of Neurosurgery, Rutgers - Robert Wood Johnson Medical School, United States; Wong S., Department of Neurology, Rutgers - Robert Wood Johnson Medical School, United States","Objective: Microelectrode recording (MER) is used to identify the subthalamic nucleus (STN) during deep brain stimulation (DBS) surgery. Automated STN detection typically involves extracting quantitative features from MERs for classifier training. This study evaluates the ability of feature selection to identify optimal feature combinations for automated STN localization. Methods: We extracted 13 features from 65 MERs for classifier training. For logistic regression (LR) classification, we compared classifiers identified by feature selection to those containing all possible feature combinations. We used classification error as our metric with hold-one-patient-out cross-validation. We also compared patient-specific vs. independent normalization on classifier performance. Results: Feature selection and patient-specific normalization were superior to non-optimized, patient-independent classifiers. Feature selection, patient-specific normalization, and both produced relative error reductions of 4.95%, 31.36%, and 38.92%, respectively. Three of four feature-selected LR classifiers performed better than 99% of classifiers with all possible feature combinations. Optimal feature combinations were not predictable from individual feature performance. Conclusions: Feature selection reduces classification error in automated STN localization from MERs. Additional improvement from patient-specific normalization suggests these approaches are necessary for clinically reliable automation of MER interpretation. Significance: These findings represent an incremental advance in automated functional localization of STN from MER in DBS surgery. © 2014 International Federation of Clinical Neurophysiology..","Deep brain stimulation; Feature selection; Intraoperative neurophysiology; Machine learning; Microelectrode recording; Signal processing","Algorithms; Data Interpretation, Statistical; Deep Brain Stimulation; Humans; Neuronavigation; Patient-Specific Modeling; Subthalamic Nucleus; adult; Article; brain depth stimulation; classifier; clinical article; clinical feature; female; human; male; microelectrode; microelectrode recording; priority journal; subthalamic nucleus; task performance; training; validation study; algorithm; biological model; brain depth stimulation; neuronavigation; procedures; standards; statistical analysis; subthalamic nucleus; surgery","Elsevier Ireland Ltd","13882457","","CNEUF","25270241","Article","Scopus","2-s2.0-84926170265"
"Kale D.C.; Che Z.; Bahadori M.T.; Li W.; Liu Y.; Wetzel R.","Kale, David C. (34872150800); Che, Zhengping (56719288000); Bahadori, Mohammad Taha (55376715600); Li, Wenzhe (58740451800); Liu, Yan (57196313067); Wetzel, Randall (7103376675)","34872150800; 56719288000; 55376715600; 58740451800; 57196313067; 7103376675","Causal Phenotype Discovery via Deep Networks","2015","AMIA ... Annual Symposium proceedings. AMIA Symposium","20","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032343512&partnerID=40&md5=d77b6d2ac3d674caf52546094df47f6a","Whittier Virtual PICU, Children's Hospital Los Angeles, Los Angeles, CA, United States; Whittier Virtual PICU, Children's Hospital Los Angeles, Los Angeles, CA, United States; Whittier Virtual PICU, Children's Hospital Los Angeles, Los Angeles, CA, United States","Kale D.C., Whittier Virtual PICU, Children's Hospital Los Angeles, Los Angeles, CA, United States; Che Z., Whittier Virtual PICU, Children's Hospital Los Angeles, Los Angeles, CA, United States; Bahadori M.T., Whittier Virtual PICU, Children's Hospital Los Angeles, Los Angeles, CA, United States; Li W., Whittier Virtual PICU, Children's Hospital Los Angeles, Los Angeles, CA, United States; Liu Y., Whittier Virtual PICU, Children's Hospital Los Angeles, Los Angeles, CA, United States; Wetzel R., Whittier Virtual PICU, Children's Hospital Los Angeles, Los Angeles, CA, United States","The rapid growth of digital health databases has attracted many researchers interested in using modern computational methods to discover and model patterns of health and illness in a research program known as computational phenotyping. Much of the work in this area has focused on traditional statistical learning paradigms, such as classification, prediction, clustering, pattern mining. In this paper, we propose a related but different paradigm called causal phenotype discovery, which aims to discover latent representations of illness that are causally predictive. We illustrate this idea with a two-stage framework that combines the latent representation learning power of deep neural networks with state-of-the-art tools from causal inference. We apply this framework to two large ICU time series data sets and show that it can learn features that are predictively useful, that capture complex physiologic patterns associated with critical illnesses, and that are potentially more clinically meaningful than manually designed features.","","Algorithms; Critical Illness; Databases, Factual; Disease; Humans; Intensive Care Units; Machine Learning; Neural Networks (Computer); Phenotype; Physiology; algorithm; artificial neural network; critical illness; diseases; factual database; human; intensive care unit; machine learning; phenotype; physiology","","1942597X","","","26958203","Article","Scopus","2-s2.0-85032343512"
"Hughes T.B.; Miller G.P.; Swamidass S.J.","Hughes, Tyler B. (56587334000); Miller, Grover P. (7404980306); Swamidass, S. Joshua (10045433000)","56587334000; 7404980306; 10045433000","Modeling epoxidation of drug-like molecules with a deep machine learning network","2015","ACS Central Science","131","10.1021/acscentsci.5b00131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945573112&doi=10.1021%2facscentsci.5b00131&partnerID=40&md5=201124193a63c415a6577e660cb3fb1f","Department of Pathology and Immunology, Washington University School of Medicine, 660 South Euclid Avenue, St. Louis, 63110, MO, United States; Department of Biochemistry and Molecular Biology, University of Arkansas for Medical Sciences, Little Rock, 72205, AR, United States","Hughes T.B., Department of Pathology and Immunology, Washington University School of Medicine, 660 South Euclid Avenue, St. Louis, 63110, MO, United States; Miller G.P., Department of Biochemistry and Molecular Biology, University of Arkansas for Medical Sciences, Little Rock, 72205, AR, United States; Swamidass S.J., Department of Pathology and Immunology, Washington University School of Medicine, 660 South Euclid Avenue, St. Louis, 63110, MO, United States","Drug toxicity is frequently caused by electrophilic reactive metabolites that covalently bind to proteins. Epoxides comprise a large class of three-membered cyclic ethers. These molecules are electrophilic and typically highly reactive due to ring tension and polarized carbon-oxygen bonds. Epoxides are metabolites often formed by cytochromes P450 acting on aromatic or double bonds. The specific location on a molecule that undergoes epoxidation is its site of epoxidation (SOE). Identifying a molecule's SOE can aid in interpreting adverse events related to reactive metabolites and direct modification to prevent epoxidation for safer drugs. This study utilized a database of 702 epoxidation reactions to build a model that accurately predicted sites of epoxidation. The foundation for this model was an algorithm originally designed to model sites of cytochromes P450 metabolism (called XenoSite) that was recently applied to model the intrinsic reactivity of diverse molecules with glutathione. This modeling algorithm systematically and quantitatively summarizes the knowledge from hundreds of epoxidation reactions with a deep convolution network. This network makes predictions at both an atom and molecule level. The final epoxidation model constructed with this approach identified SOEs with 94.9% area under the curve (AUC) performance and separated epoxidized and non-epoxidized molecules with 79.3% AUC. Moreover, within epoxidized molecules, the model separated aromatic or double bond SOEs from all other aromatic or double bonds with AUCs of 92.5% and 95.1%, respectively. Finally, the model separated SOEs from sites of sp2 hydroxylation with 83.2% AUC. Our model is the first of its kind and may be useful for the development of safer drugs. © 2015 American Chemical Society.","","Aromatic compounds; Aromatization; Biomolecules; Epoxidation; Metabolites; Molecules; Separation; Area Under the Curve (AUC); Carbon-oxygen bonds; Direct modification; Epoxidation reactions; Intrinsic reactivity; Model algorithms; Reactive metabolites; Specific location; Deep learning","American Chemical Society","23747943","","","","Article","Scopus","2-s2.0-84945573112"
"Montalto A.; Tessitore G.; Prevete R.","Montalto, Alessandro (56038992300); Tessitore, Giovanni (24336931200); Prevete, Roberto (9735388800)","56038992300; 24336931200; 9735388800","A linear approach for sparse coding by a two-layer neural network","2015","Neurocomputing","5","10.1016/j.neucom.2014.08.066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912100446&doi=10.1016%2fj.neucom.2014.08.066&partnerID=40&md5=22d175656de180547dbeb0efbc629202","Data Analysis Department, Gent University, Belgium; Department of Physical Sciences, University of Naples Federico II, Italy; DIETI, University of Naples Federico II, Italy","Montalto A., Data Analysis Department, Gent University, Belgium; Tessitore G., Department of Physical Sciences, University of Naples Federico II, Italy; Prevete R., DIETI, University of Naples Federico II, Italy","Many approaches to transform classification problems from non-linear to linear by feature transformation have been recently presented in the literature. These notably include sparse coding methods and deep neural networks. However, many of these approaches require the repeated application of a learning process upon the presentation of unseen data input vectors, or else involve the use of large numbers of parameters and hyper-parameters, which must be chosen through cross-validation, thus increasing running time dramatically. In this paper, we propose and experimentally investigate a new approach for the purpose of overcoming limitations of both kinds. The proposed approach makes use of a linear auto-associative network (called SCNN) with just one hidden layer. The combination of this architecture with a specific error function to be minimized enables one to learn a linear encoder computing a sparse code which turns out to be as similar as possible to the sparse coding that one obtains by re-training the neural network. Importantly, the linearity of SCNN and the choice of the error function allow one to achieve reduced running time in the learning phase. The proposed architecture is evaluated on the basis of two standard machine learning tasks. Its performances are compared with those of recently proposed non-linear auto-associative neural networks. The overall results suggest that linear encoders can be profitably used to obtain sparse data representations in the context of machine learning problems, provided that an appropriate error function is used during the learning phase. © 2014 Elsevier B.V.","Encoder-decoder; Linear approach; Neural networks; Sparse coding","Deep learning; Deep neural networks; Errors; Learning systems; Linear transformations; Mathematical transformations; Network architecture; Network coding; Network layers; Neural networks; Autoassociative networks; Autoassociative neural networks; Encoder-decoder; Feature transformations; Linear approach; Machine learning problem; Proposed architectures; Sparse coding; algorithm; Article; artificial neural network; computer system; image analysis; intermethod comparison; linear autoassociative network; linear system; machine learning; mathematical model; nonlinear system; principal component analysis; process optimization; systematic error; validation process; Multilayer neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84912100446"
"Qiao N.; Mostafa H.; Corradi F.; Osswald M.; Stefanini F.; Sumislawska D.; Indiveri G.","Qiao, Ning (56609943100); Mostafa, Hesham (56007793000); Corradi, Federico (55602185200); Osswald, Marc (54793467400); Stefanini, Fabio (36978694900); Sumislawska, Dora (56610397300); Indiveri, Giacomo (7003997439)","56609943100; 56007793000; 55602185200; 54793467400; 36978694900; 56610397300; 7003997439","A reconfigurable on-line learning spiking neuromorphic processor comprising 256 neurons and 128K synapses","2015","Frontiers in Neuroscience","482","10.3389/fnins.2015.00141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928671707&doi=10.3389%2ffnins.2015.00141&partnerID=40&md5=e7ec684d06fc1f2925592cfb9570c81e","Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland","Qiao N., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Mostafa H., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Corradi F., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Osswald M., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Stefanini F., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Sumislawska D., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Indiveri G., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland","Implementing compact, low-power artificial neural processing systems with real-time on-line learning abilities is still an open challenge. In this paper we present a full-custom mixed-signal VLSI device with neuromorphic learning circuits that emulate the biophysics of real spiking neurons and dynamic synapses for exploring the properties of computational neuroscience models and for building brain-inspired computing systems. The proposed architecture allows the on-chip configuration of a wide range of network connectivities, including recurrent and deep networks, with short-term and long-term plasticity. The device comprises 128 K analog synapse and 256 neuron circuits with biologically plausible dynamics and bi-stable spike-based plasticity mechanisms that endow it with on-line learning abilities. In addition to the analog circuits, the device comprises also asynchronous digital logic circuits for setting different synapse and neuron properties as well as different network configurations. This prototype device, fabricated using a 180 nm 1P6M CMOS process, occupies an area of 51.4 mm2, and consumes approximately 4 mW for typical experiments, for example involving attractor networks. Here we describe the details of the overall architecture and of the individual circuits and present experimental results that showcase its potential. By supporting a wide range of cortical-like computational modules comprising plasticity mechanisms, this device will enable the realization of intelligent autonomous systems with on-line learning capabilities. © 2015 Qiao, Mostafa, Corradi, Osswald, Stefanini, Sumislawska and Indiveri.","Analog VLSI; Asynchronous; Attractor network; Brain-inspired computing; Real-time; Spike-based learning; Spike-timing dependent plasticity (STDP); Winner-Take-All (WTA)","Article; connectome; controlled study; integrated circuit; learning algorithm; machine learning; negative feedback; nerve cell plasticity; pattern recognition; spike; synapse; working memory","Frontiers Research Foundation","16624548","","","","Article","Scopus","2-s2.0-84928671707"
"Ciompi F.; de Hoop B.; van Riel S.J.; Chung K.; Scholten E.T.; Oudkerk M.; de Jong P.A.; Prokop M.; van Ginneken B.","Ciompi, Francesco (32667506900); de Hoop, Bartjan (24343372000); van Riel, Sarah J. (56376768500); Chung, Kaman (56898357800); Scholten, Ernst Th (14628008900); Oudkerk, Matthijs (7004345016); de Jong, Pim A. (57203053328); Prokop, Mathias (55523334800); van Ginneken, Bram (55759608800)","32667506900; 24343372000; 56376768500; 56898357800; 14628008900; 7004345016; 57203053328; 55523334800; 55759608800","Automatic classification of pulmonary peri-fissural nodules in computed tomography using an ensemble of 2D views and a convolutional neural network out-of-the-box","2015","Medical Image Analysis","248","10.1016/j.media.2015.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943752367&doi=10.1016%2fj.media.2015.08.001&partnerID=40&md5=2aaade09b120452e3d97fabd9ebacf66","Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; University Medical Center, Utrecht, Netherlands; University Medical Center, Groningen, Netherlands; Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands; Fraunhofer Mevis, Bremen, Germany","Ciompi F., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; de Hoop B., University Medical Center, Utrecht, Netherlands; van Riel S.J., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Chung K., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Scholten E.T., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands; Oudkerk M., University Medical Center, Groningen, Netherlands; de Jong P.A., University Medical Center, Utrecht, Netherlands; Prokop M., Department of Radiology, Radboud University Medical Center, Nijmegen, Netherlands; van Ginneken B., Diagnostic Image Analysis Group, Department of Radiology and Nuclear Medicine, Radboud University Medical Center, Nijmegen, Netherlands, Fraunhofer Mevis, Bremen, Germany","In this paper, we tackle the problem of automatic classification of pulmonary peri-fissural nodules (PFNs). The classification problem is formulated as a machine learning approach, where detected nodule candidates are classified as PFNs or non-PFNs. Supervised learning is used, where a classifier is trained to label the detected nodule. The classification of the nodule in 3D is formulated as an ensemble of classifiers trained to recognize PFNs based on 2D views of the nodule. In order to describe nodule morphology in 2D views, we use the output of a pre-trained convolutional neural network known as OverFeat. We compare our approach with a recently presented descriptor of pulmonary nodule morphology, namely Bag of Frequencies, and illustrate the advantages offered by the two strategies, achieving performance of AUC = 0.868, which is close to the one of human experts. © 2015 Elsevier B.V.","Chest CT; Convolutional neural networks; Deep learning; Lung cancer screening; OverFeat; Peri-fissural nodules","Algorithms; Humans; Imaging, Three-Dimensional; Lung Neoplasms; Neural Networks (Computer); Pattern Recognition, Automated; Radiographic Image Enhancement; Radiographic Image Interpretation, Computer-Assisted; Reproducibility of Results; Sensitivity and Specificity; Software; Solitary Pulmonary Nodule; Subtraction Technique; Tomography, X-Ray Computed; Artificial intelligence; Convolution; Learning systems; Neural networks; Chest CT; Convolutional neural network; Deep learning; Lung cancer screening; OverFeat; Peri-fissural nodules; Article; automation; cancer classification; cancer screening; classifier; computer assisted tomography; human; lung cancer; priority journal; pulmonary peri fissural nodule; algorithm; artificial neural network; automated pattern recognition; computer assisted diagnosis; computer assisted tomography; image enhancement; image subtraction; lung nodule; lung tumor; procedures; radiography; reproducibility; sensitivity and specificity; software; three dimensional imaging; Computerized tomography","Elsevier","13618415","","MIAEC","26458112","Article","Scopus","2-s2.0-84943752367"
"Barros P.; Jirak D.; Weber C.; Wermter S.","Barros, Pablo (55734354000); Jirak, Doreen (37031181800); Weber, Cornelius (7402376952); Wermter, Stefan (7003826680)","55734354000; 37031181800; 7402376952; 7003826680","Multimodal emotional state recognition using sequence-dependent deep hierarchical features","2015","Neural Networks","61","10.1016/j.neunet.2015.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949058101&doi=10.1016%2fj.neunet.2015.09.009&partnerID=40&md5=294c4b0bdde7808dc8abddbc62a0733d","Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany","Barros P., Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Jirak D., Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Weber C., Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany; Wermter S., Department of Informatics, University of Hamburg, Knowledge Technology, Vogt-Koelln-Strasse 30, Hamburg, 22527, Germany","Emotional state recognition has become an important topic for human-robot interaction in the past years. By determining emotion expressions, robots can identify important variables of human behavior and use these to communicate in a more human-like fashion and thereby extend the interaction possibilities. Human emotions are multimodal and spontaneous, which makes them hard to be recognized by robots. Each modality has its own restrictions and constraints which, together with the non-structured behavior of spontaneous expressions, create several difficulties for the approaches present in the literature, which are based on several explicit feature extraction techniques and manual modality fusion. Our model uses a hierarchical feature representation to deal with spontaneous emotions, and learns how to integrate multiple modalities for non-verbal emotion recognition, making it suitable to be used in an HRI scenario. Our experiments show that a significant improvement of recognition accuracy is achieved when we use hierarchical features and multimodal information, and our model improves the accuracy of state-of-theart approaches from 82.5% reported in the literature to 91.3% for a benchmark dataset on spontaneous emotion expressions. © 2015 The Authors.","Convolutional Neural Networks; Deep learning; Emotion recognition; Hierarchical features; Human Robot Interaction","Emotions; Humans; Learning; Recognition (Psychology); Robotics; Behavioral research; Feature extraction; Man machine systems; Neural networks; Robots; Speech recognition; State estimation; Convolutional neural network; Deep learning; Emotion recognition; Feature extraction techniques; Hierarchical features; Multi-modal information; Recognition accuracy; State-of-the-art approach; Article; body movement; controlled study; emotionality; facial expression; human; mental task; priority journal; recognition; stimulus response; task performance; visual stimulation; emotion; learning; robotics; Human robot interaction","Elsevier Ltd","08936080","","NNETE","26548943","Article","Scopus","2-s2.0-84949058101"
"Jirayucharoensak S.; Pan-Ngum S.; Israsena P.","Jirayucharoensak, Suwicha (6504473840); Pan-Ngum, Setha (25926629900); Israsena, Pasin (15046655700)","6504473840; 25926629900; 15046655700","EEG-Based Emotion Recognition Using Deep Learning Network with Principal Component Based Covariate Shift Adaptation","2014","Scientific World Journal","377","10.1155/2014/627892","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930963132&doi=10.1155%2f2014%2f627892&partnerID=40&md5=70ac91a5e1b754ccfe33690c0354a608","Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, 10330, Thailand; National Electronics and Computer Technology Center, Thailand Science Park, Khlong Luang, Pathum Thani, 12120, Thailand","Jirayucharoensak S., Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, 10330, Thailand, National Electronics and Computer Technology Center, Thailand Science Park, Khlong Luang, Pathum Thani, 12120, Thailand; Pan-Ngum S., Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, 10330, Thailand; Israsena P., National Electronics and Computer Technology Center, Thailand Science Park, Khlong Luang, Pathum Thani, 12120, Thailand","Automatic emotion recognition is one of the most challenging tasks. To detect emotion from nonstationary EEG signals, a sophisticated learning algorithm that can represent high-level abstraction is required. This study proposes the utilization of a deep learning network (DLN) to discover unknown feature correlation between input signals that is crucial for the learning task. The DLN is implemented with a stacked autoencoder (SAE) using hierarchical feature learning approach. Input features of the network are power spectral densities of 32-channel EEG signals from 32 subjects. To alleviate overfitting problem, principal component analysis (PCA) is applied to extract the most important components of initial input features. Furthermore, covariate shift adaptation of the principal components is implemented to minimize the nonstationary effect of EEG signals. Experimental results show that the DLN is capable of classifying three different levels of valence and arousal with accuracy of 49.52% and 46.03%, respectively. Principal component based covariate shift adaptation enhances the respective classification accuracy by 5.55% and 6.53%. Moreover, DLN provides better performance compared to SVM and naive Bayes classifiers. © 2014 Suwicha Jirayucharoensak et al.","","Algorithms; Arousal; Electroencephalography; Emotions; Humans; Nerve Net; Neural Networks (Computer); Principal Component Analysis; Reproducibility of Results; Support Vector Machines; Task Performance and Analysis; alpha rhythm; arousal; Article; artificial neural network; beta rhythm; classification algorithm; covariate shift adaptation; deep learning network; electroencephalogram; emotion; emotion recognition; gamma rhythm; learning; left hemisphere; nerve cell network; principal component analysis; recognition; stacked autoencoder; statistical analysis; support vector machine; theta rhythm; valence; algorithm; electroencephalography; human; physiology; procedures; reproducibility; support vector machine; task performance","Hindawi Limited","23566140","","","25258728","Article","Scopus","2-s2.0-84930963132"
"Olsher D.","Olsher, Daniel (55341324600)","55341324600","Semantically-based priors and nuanced knowledge core for Big Data, Social AI, and language understanding","2014","Neural Networks","10","10.1016/j.neunet.2014.05.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906098361&doi=10.1016%2fj.neunet.2014.05.022&partnerID=40&md5=45b8090cf9f747df4c5387382e737404","Carnegie Mellon University, United States","Olsher D., Carnegie Mellon University, United States","Noise-resistant and nuanced, COGBASE makes 10 million pieces of commonsense data and a host of novel reasoning algorithms available via a family of semantically-driven prior probability distributions.Machine learning, Big Data, natural language understanding/processing, and social AI can draw on COGBASE to determine lexical semantics, infer goals and interests, simulate emotion and affect, calculate document gists and topic models, and link commonsense knowledge to domain models and social, spatial, cultural, and psychological data.COGBASE is especially ideal for social Big Data, which tends to involve highly implicit contexts, cognitive artifacts, difficult-to-parse texts, and deep domain knowledge dependencies. © 2014 Elsevier Ltd.","Big Data; Data mining; Knowledge representation; Machine learning; Natural language understanding; Nuanced commonsense reasoning; Social data","Algorithms; Artificial Intelligence; Humans; Knowledge; Language; Natural Language Processing; Semantics; Social Support; Statistics as Topic; Big data; Knowledge representation; Learning systems; Semantics; Cognitive artifacts; Commonsense knowledge; Commonsense reasoning; Language understanding; Natural language understanding; Prior probability; Reasoning algorithms; Social datum; affect; article; big data; COGBASE; emotion; INTELNET; knowledge base; learning algorithm; machine learning; natural language understanding; priority journal; probability; semantics; social AI; algorithm; artificial intelligence; human; knowledge; language; natural language processing; procedures; social support; statistics; Data mining","Elsevier Ltd","08936080","","NNETE","25022322","Article","Scopus","2-s2.0-84906098361"
"Suk H.-I.; Lee S.-W.; Shen D.","Suk, Heung-Il (56332955800); Lee, Seong-Whan (7601390519); Shen, Dinggang (7401738392)","56332955800; 7601390519; 7401738392","Hierarchical feature representation and multimodal fusion with deep learning for AD/MCI diagnosis","2014","NeuroImage","666","10.1016/j.neuroimage.2014.06.077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907019192&doi=10.1016%2fj.neuroimage.2014.06.077&partnerID=40&md5=c5dd9d8ebfca5441c9ee4ed1efcbf982","Department of Radiology and Biomedical Research Imaging Center (BRIC), University of North Carolina, Chapel Hill, NC, United States; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea","Suk H.-I., Department of Radiology and Biomedical Research Imaging Center (BRIC), University of North Carolina, Chapel Hill, NC, United States; Lee S.-W., Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; Shen D., Department of Radiology and Biomedical Research Imaging Center (BRIC), University of North Carolina, Chapel Hill, NC, United States, Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea","For the last decade, it has been shown that neuroimaging can be a potential tool for the diagnosis of Alzheimer's Disease (AD) and its prodromal stage, Mild Cognitive Impairment (MCI), and also fusion of different modalities can further provide the complementary information to enhance diagnostic accuracy. Here, we focus on the problems of both feature representation and fusion of multimodal information from Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET). To our best knowledge, the previous methods in the literature mostly used hand-crafted features such as cortical thickness, gray matter densities from MRI, or voxel intensities from PET, and then combined these multimodal features by simply concatenating into a long vector or transforming into a higher-dimensional kernel space. In this paper, we propose a novel method for a high-level latent and shared feature representation from neuroimaging modalities via deep learning. Specifically, we use Deep Boltzmann Machine (DBM). 22Although it is clear from the context that the acronym DBM denotes ""Deep Boltzmann Machine"" in this paper, we would clearly indicate that DBM here is not related to ""Deformation Based Morphometry""., a deep network with a restricted Boltzmann machine as a building block, to find a latent hierarchical feature representation from a 3D patch, and then devise a systematic method for a joint feature representation from the paired patches of MRI and PET with a multimodal DBM. To validate the effectiveness of the proposed method, we performed experiments on ADNI dataset and compared with the state-of-the-art methods. In three binary classification problems of AD vs. healthy Normal Control (NC), MCI vs. NC, and MCI converter vs. MCI non-converter, we obtained the maximal accuracies of 95.35%, 85.67%, and 74.58%, respectively, outperforming the competing methods. By visual inspection of the trained model, we observed that the proposed method could hierarchically discover the complex latent patterns inherent in both MRI and PET. © 2014 Elsevier Inc.","Alzheimer's Disease; Deep boltzmann machine; Mild cognitive impairment; Multimodal data fusion; Shared feature representation","Aged; Aged, 80 and over; Alzheimer Disease; Artificial Intelligence; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Mild Cognitive Impairment; Multimodal Imaging; Neural Networks (Computer); Positron-Emission Tomography; fluorodeoxyglucose f 18; adult; aged; Alzheimer disease; Article; classifier; computer assisted diagnosis; controlled study; diagnostic accuracy; diagnostic test accuracy study; false negative result; false positive result; female; human; image processing; intermethod comparison; machine learning; major clinical study; male; mathematical model; mild cognitive impairment; multimodal deep boltzmann machine; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; positron emission tomography; predictive value; receiver operating characteristic; sensitivity and specificity; validation study; Alzheimer disease; artificial intelligence; artificial neural network; middle aged; mild cognitive impairment; multimodal imaging; procedures; very elderly","Academic Press Inc.","10538119","","NEIME","25042445","Article","Scopus","2-s2.0-84907019192"
"Li H.; Li X.; Ramanathan M.; Zhang A.","Li, Hui (56986776300); Li, Xiaoyi (55491232500); Ramanathan, Murali (35465713900); Zhang, Aidong (7402772796)","56986776300; 55491232500; 35465713900; 7402772796","Identifying informative risk factors and predicting bone disease progression via deep belief networks","2014","Methods","40","10.1016/j.ymeth.2014.06.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927125365&doi=10.1016%2fj.ymeth.2014.06.011&partnerID=40&md5=088131fec958a6e5d88045aeeac13d46","Department of Computer Science and Engineering, State University of New York at Buffalo, United States; Department of Pharmaceutical Sciences, State University of New York at Buffalo, United States","Li H., Department of Computer Science and Engineering, State University of New York at Buffalo, United States; Li X., Department of Computer Science and Engineering, State University of New York at Buffalo, United States; Ramanathan M., Department of Pharmaceutical Sciences, State University of New York at Buffalo, United States; Zhang A., Department of Computer Science and Engineering, State University of New York at Buffalo, United States","Osteoporosis is a common disease which frequently causes death, permanent disability, and loss of quality of life in the geriatric population. Identifying risk factors for the disease progression and capturing the disease characteristics have received increasing attentions in the health informatics research. In data mining area, risk factors are features of the data and diagnostic results can be regarded as the labels to train a model for a regression or classification task. We develop a general framework based on the heterogeneous electronic health records (EHRs) for the risk factor (RF) analysis that can be used for informative RF selection and the prediction of osteoporosis. The RF selection is a task designed for ranking and explaining the semantics of informative RFs for preventing the disease and improving the understanding of the disease. Predicting the risk of osteoporosis in a prospective and population-based study is a task for monitoring the bone disease progression. We apply a variety of well-trained deep belief network (DBN) models which inherit the following good properties: (1) pinpointing the underlying causes of the disease in order to assess the risk of a patient in developing a target disease, and (2) discriminating between patients suffering from the disease and without the disease for the purpose of selecting RFs of the disease. A variety of DBN models can capture characteristics for different patient groups via a training procedure with the use of different samples. The case study shows that the proposed method can be efficiently used to select the informative RFs. Most of the selected RFs are validated by the medical literature and some new RFs will attract interests across the medical research. Moreover, the experimental analysis on a real bone disease data set shows that the proposed framework can successfully predict the progression of osteoporosis. The stable and promising performance on the evaluation metrics confirms the effectiveness of our model. © 2014 Elsevier Inc.","Bone fracture; Deep belief networks (DBNs); Informative risk factors; Osteoporosis prediction; Restricted Boltzmann machine (RBM)","Data Mining; Disease Progression; Fractures, Bone; Humans; Models, Theoretical; Osteoporosis; Prospective Studies; Quality of Life; Risk Assessment; Risk Factors; Article; bone disease; deep belief network; disease course; electronic medical record; information processing; machine learning; osteoporosis; priority journal; risk assessment; risk factor; semantics; data mining; fracture; human; osteoporosis; pathology; prospective study; quality of life; risk assessment; risk factor; theoretical model","Academic Press Inc.","10462023","","MTHDE","24979059","Article","Scopus","2-s2.0-84927125365"
"Li F.; Tran L.; Thung K.-H.; Ji S.; Shen D.; Li J.","Li, Feng (56491714200); Tran, Loc (57164382000); Thung, Kim-Han (9337867600); Ji, Shuiwang (18935244900); Shen, Dinggang (7401738392); Li, Jiang (56226550100)","56491714200; 57164382000; 9337867600; 18935244900; 7401738392; 56226550100","A Robust Deep Model for Improved Classification of AD/MCI Patients","2015","IEEE Journal of Biomedical and Health Informatics","234","10.1109/JBHI.2015.2429556","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940975497&doi=10.1109%2fJBHI.2015.2429556&partnerID=40&md5=6cea89598aaaeef00f4d502bd4032240","Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, 23529, VA, United States; Department of Radiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Department of Computer Science, Old Dominion University, Norfolk, 23529, VA, United States; Department of Brain and Cognitive Engineering, Korea University, Seoul, 136-701, South Korea","Li F., Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, 23529, VA, United States; Tran L., Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, 23529, VA, United States; Thung K.-H., Department of Radiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States; Ji S., Department of Computer Science, Old Dominion University, Norfolk, 23529, VA, United States; Shen D., Department of Radiology, University of North Carolina at Chapel Hill, Chapel Hill, 27599, NC, United States, Department of Brain and Cognitive Engineering, Korea University, Seoul, 136-701, South Korea; Li J., Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, 23529, VA, United States","Accurate classification of Alzheimer's disease (AD) and its prodromal stage, mild cognitive impairment (MCI), plays a critical role in possibly preventing progression of memory impairment and improving quality of life for AD patients. Among many research tasks, it is of a particular interest to identify noninvasive imaging biomarkers for AD diagnosis. In this paper, we present a robust deep learning system to identify different progression stages of AD patients based on MRI and PET scans. We utilized the dropout technique to improve classical deep learning by preventing its weight coadaptation, which is a typical cause of overfitting in deep learning. In addition, we incorporated stability selection, an adaptive learning factor, and a multitask learning strategy into the deep learning framework. We applied the proposed method to the ADNI dataset, and conducted experiments for AD and MCI conversion diagnosis. Experimental results showed that the dropout technique is very effective in AD diagnosis, improving the classification accuracies by 5.9% on average as compared to the classical deep learning methods. © 2013 IEEE.","Alzheimer's Disease; Deep Learning; Early Diagnosis; MRI; PET","Alzheimer Disease; Cognitive Dysfunction; Early Diagnosis; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Models, Theoretical; Positron-Emission Tomography; Principal Component Analysis; Support Vector Machine; Computer aided diagnosis; Learning systems; Magnetic resonance imaging; Neurodegenerative diseases; Polyethylene terephthalates; Adaptive learning; Alzheimer's disease; Classification accuracy; Early diagnosis; Learning frameworks; Mild cognitive impairments (MCI); Non-invasive imaging; Stability selections; Alzheimer disease; Cognitive Dysfunction; computer assisted diagnosis; early diagnosis; human; machine learning; nuclear magnetic resonance imaging; positron emission tomography; principal component analysis; procedures; support vector machine; theoretical model; Deep learning","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","25955998","Article","Scopus","2-s2.0-84940975497"
"Gu F.; Flórez-Revuelta F.; Monekosso D.; Remagnino P.","Gu, Feng (58373639900); Flórez-Revuelta, Francisco (13106226300); Monekosso, Dorothy (23091283600); Remagnino, Paolo (6602806859)","58373639900; 13106226300; 23091283600; 6602806859","Marginalised stacked denoising autoencoders for robust representation of real-time multi-view action recognition","2015","Sensors (Switzerland)","10","10.3390/s150717209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940199016&doi=10.3390%2fs150717209&partnerID=40&md5=ca719eeb96db886c4ac95a725a8240e7","School of Computing and Information Systems, Kingston University, Penrhyn Road, Kingston upon Thames, KT1 2EE, United Kingdom; Kingston University, Penrhyn Road, Kingston upon Thames, KT1 2EE, United Kingdom","Gu F., School of Computing and Information Systems, Kingston University, Penrhyn Road, Kingston upon Thames, KT1 2EE, United Kingdom; Flórez-Revuelta F., Kingston University, Penrhyn Road, Kingston upon Thames, KT1 2EE, United Kingdom; Monekosso D., School of Computing and Information Systems, Kingston University, Penrhyn Road, Kingston upon Thames, KT1 2EE, United Kingdom; Remagnino P., School of Computing and Information Systems, Kingston University, Penrhyn Road, Kingston upon Thames, KT1 2EE, United Kingdom","Multi-view action recognition has gained a great interest in video surveillance, human computer interaction, and multimedia retrieval, where multiple cameras of different types are deployed to provide a complementary field of views. Fusion of multiple camera views evidently leads to more robust decisions on both tracking multiple targets and analysing complex human activities, especially where there are occlusions. In this paper, we incorporate the marginalised stacked denoising autoencoders (mSDA) algorithm to further improve the bag of words (BoWs) representation in terms of robustness and usefulness for multi-view action recognition. The resulting representations are fed into three simple fusion strategies as well as a multiple kernel learning algorithm at the classification stage. Based on the internal evaluation, the codebook size of BoWs and the number of layers of mSDA may not significantly affect recognition performance. According to results on three multi-view benchmark datasets, the proposed framework improves recognition performance across all three datasets and outputs record recognition performance, beating the state-of-art algorithms in the literature. It is also capable of performing real-time action recognition at a frame rate ranging from 33 to 45, which could be further improved by using more powerful machines in future applications. © 2015 by the authors; licensee MDPI, Basel, Switzerland.","Bag of words; Deep learning; Marginalised stacked denoising autoencoders; Multi-view action recognition; Multiple kernel learning","Algorithms; Benchmarking; Cameras; Learning algorithms; Learning systems; Security systems; Autoencoders; Bag of words; Deep learning; Multi-view action recognition; Multiple Kernel Learning; Human computer interaction","MDPI AG","14248220","","","","Article","Scopus","2-s2.0-84940199016"
"Willemen T.; Varon C.; Caicedo Dorado A.; Haex B.; Vander Sloten J.; Van Huffel S.","Willemen, T. (55189238800); Varon, C. (42262898200); Caicedo Dorado, A. (36717350200); Haex, B. (8232257400); Vander Sloten, J. (56235308700); Van Huffel, S. (7004954228)","55189238800; 42262898200; 36717350200; 8232257400; 56235308700; 7004954228","Probabilistic cardiac and respiratory based classification of sleep and apneic events in subjects with sleep apnea","2015","Physiological Measurement","13","10.1088/0967-3334/36/10/2103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947770207&doi=10.1088%2f0967-3334%2f36%2f10%2f2103&partnerID=40&md5=a995bf1e75369adb441e1609d7f40338","Department of Mechanical Engineering, Biomechanics Section, KU Leuven, Celestijnenlaan, Leuven, Belgium; Department of Electrical Engineering (ESAT), STADIUS, KU Leuven, Kasteelpark Arenberg, Leuven, Belgium; Medical Information Technologies, IMinds, Leuven, Belgium; Maastricht University, Minderbroedersberg 4-6, Maastricht, 6211 LK, Netherlands","Willemen T., Department of Mechanical Engineering, Biomechanics Section, KU Leuven, Celestijnenlaan, Leuven, Belgium, Department of Electrical Engineering (ESAT), STADIUS, KU Leuven, Kasteelpark Arenberg, Leuven, Belgium, Medical Information Technologies, IMinds, Leuven, Belgium; Varon C., Department of Electrical Engineering (ESAT), STADIUS, KU Leuven, Kasteelpark Arenberg, Leuven, Belgium, Medical Information Technologies, IMinds, Leuven, Belgium; Caicedo Dorado A., Department of Electrical Engineering (ESAT), STADIUS, KU Leuven, Kasteelpark Arenberg, Leuven, Belgium, Medical Information Technologies, IMinds, Leuven, Belgium; Haex B., Department of Mechanical Engineering, Biomechanics Section, KU Leuven, Celestijnenlaan, Leuven, Belgium, Maastricht University, Minderbroedersberg 4-6, Maastricht, 6211 LK, Netherlands; Vander Sloten J., Department of Mechanical Engineering, Biomechanics Section, KU Leuven, Celestijnenlaan, Leuven, Belgium; Van Huffel S., Department of Electrical Engineering (ESAT), STADIUS, KU Leuven, Kasteelpark Arenberg, Leuven, Belgium, Medical Information Technologies, IMinds, Leuven, Belgium","Current clinical standards to assess sleep and its disorders lack either accuracy or user-friendliness. They are therefore difficult to use in cost-effective population-wide screening or long-term objective follow-up after diagnosis. In order to fill this gap, the use of cardiac and respiratory information was evaluated for discrimination between different sleep stages, and for detection of apneic breathing. Alternative probabilistic visual representations were also presented, referred to as the hypnocorrogram and apneacorrogram. Analysis was performed on the UCD sleep apnea database, available on Physionet. The presence of apneic events proved to have a significant impact on the performance of a cardiac and respiratory based algorithm for sleep stage classification. WAKE versus SLEEP discrimination resulted in a kappa value of κ = 0.439, while REM versus NREM resulted in κ = 0.298 and light sleep (N1N2) versus deep sleep (N3) in κ = 0.339. The high proportion of hypopneic events led to poor detection of apneic breathing, resulting in a kappa value of κ = 0.272. While the probabilistic representations allow to put classifier output in perspective, further improvements would be necessary to make the classifier reliable for use on patients with sleep apnea. © 2015 Institute of Physics and Engineering in Medicine Printed in the UK.","biomedical signal processing; medical information systems; Physionet; sleep research; supervised learning","Adult; Aged; Female; Heart; Humans; Machine Learning; Male; Middle Aged; Polysomnography; Probability; Respiration; Signal Processing, Computer-Assisted; Sleep; Sleep Apnea Syndromes; Sleep Stages; Biomedical signal processing; Classification (of information); Computer aided diagnosis; Cost effectiveness; Information use; Medical information systems; 'current; Biomedical signals processing; Cost effective; Follow up; Kappa values; PhysioNet; Probabilistics; Sleep apnea; Sleep stage; User friendliness; adult; aged; breathing; female; heart; human; machine learning; male; middle aged; pathophysiology; physiology; polysomnography; probability; signal processing; sleep; Sleep Apnea Syndromes; sleep stage; Sleep research","IOP Publishing Ltd","09673334","","PMEAE","26290159","Article","Scopus","2-s2.0-84947770207"
"Cieślik M.; Bekiranov S.","Cieślik, Marcin (26423512000); Bekiranov, Stefan (6602884385)","26423512000; 6602884385","Combinatorial epigenetic patterns as quantitative predictors of chromatin biology","2014","BMC Genomics","16","10.1186/1471-2164-15-76","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896708512&doi=10.1186%2f1471-2164-15-76&partnerID=40&md5=c75d7b37958d86e18fb254a530ec4d60","Department of Biochemistry and Molecular Genetics, University of Virginia Health System, Charlottesville, VA, United States","Cieślik M., Department of Biochemistry and Molecular Genetics, University of Virginia Health System, Charlottesville, VA, United States; Bekiranov S., Department of Biochemistry and Molecular Genetics, University of Virginia Health System, Charlottesville, VA, United States","Background: Chromatin immunoprecipitation followed by deep sequencing (ChIP-seq) is the most widely used method for characterizing the epigenetic states of chromatin on a genomic scale. With the recent availability of large genome-wide data sets, often comprising several epigenetic marks, novel approaches are required to explore functionally relevant interactions between histone modifications. Computational discovery of ""chromatin states"" defined by such combinatorial interactions enabled descriptive annotations of genomes, but more quantitative approaches are needed to progress towards predictive models.Results: We propose non-negative matrix factorization (NMF) as a new unsupervised method to discover combinatorial patterns of epigenetic marks that frequently co-occur in subsets of genomic regions. We show that this small set of combinatorial ""codes"" can be effectively displayed and interpreted. NMF codes enable dimensionality reduction and have desirable statistical properties for regression and classification tasks. We demonstrate the utility of codes in the quantitative prediction of Pol2-binding and the discrimination between Pol2-bound promoters and enhancers. Finally, we show that specific codes can be linked to molecular pathways and targets of pluripotency genes during differentiation.Conclusions: We have introduced and evaluated a new computational approach to represent combinatorial patterns of epigenetic marks as quantitative variables suitable for predictive modeling and supervised machine learning. To foster widespread adoption of this method we make it available as an open-source software-package - epicode at https://github.com/mcieslik-mctp/epicode. © 2014 Cieślik and Bekiranov; licensee BioMed Central Ltd.","","Algorithms; Area Under Curve; Chromatin; Chromatin Immunoprecipitation; Embryonic Stem Cells; Epigenomics; Histones; Humans; Internet; Principal Component Analysis; Promoter Regions, Genetic; Protein Binding; ROC Curve; User-Computer Interface; cell protein; protein Pol2; unclassified drug; analytic method; article; cell differentiation; chromatin assembly and disassembly; combinatorial library; embryo; enhancer region; epigenetic repression; gene targeting; human; human cell; Internet; machine learning; molecular biology; non negative matrix factorization; pluripotent stem cell; promoter region; protein binding; quantitative analysis; signal transduction; statistical analysis","","14712164","","BGMEE","24472558","Article","Scopus","2-s2.0-84896708512"
"Nguyen N.-P.D.; Mirarab S.; Kumar K.; Warnow T.","Nguyen, Nam-Phuong D. (56581085700); Mirarab, Siavash (22235131200); Kumar, Keerthana (57225661482); Warnow, Tandy (55109110400)","56581085700; 22235131200; 57225661482; 55109110400","Ultra-large alignments using phylogeny-aware profiles","2015","Genome Biology","89","10.1186/s13059-015-0688-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939168822&doi=10.1186%2fs13059-015-0688-z&partnerID=40&md5=7a069df0da076e6865c8f88d931c7de7","University of Illinois at Urbana-Champaign, Carl R. Woese Institute for Genomic Biology, 1206 West Gregory Drive, Urbana, 61801, IL, United States; University of Texas at Austin, Department of Computer Science, 2505 Speedway, Austin, 78712, TX, United States; University of Illinois at Urbana-Champaign, Department of Bioengineering, 1270 Digital Computer Laboratory, Urbana, 61801, IL, United States; University of Illinois at Urbana-Champaign, Department of Computer Science, 201 North Goodwin Avenue, Urbana, 61801, IL, United States","Nguyen N.-P.D., University of Illinois at Urbana-Champaign, Carl R. Woese Institute for Genomic Biology, 1206 West Gregory Drive, Urbana, 61801, IL, United States; Mirarab S., University of Texas at Austin, Department of Computer Science, 2505 Speedway, Austin, 78712, TX, United States; Kumar K., University of Texas at Austin, Department of Computer Science, 2505 Speedway, Austin, 78712, TX, United States; Warnow T., University of Illinois at Urbana-Champaign, Carl R. Woese Institute for Genomic Biology, 1206 West Gregory Drive, Urbana, 61801, IL, United States, University of Illinois at Urbana-Champaign, Department of Bioengineering, 1270 Digital Computer Laboratory, Urbana, 61801, IL, United States, University of Illinois at Urbana-Champaign, Department of Computer Science, 201 North Goodwin Avenue, Urbana, 61801, IL, United States","Many biological questions, including the estimation of deep evolutionary histories and the detection of remote homology between protein sequences, rely upon multiple sequence alignments and phylogenetic trees of large datasets. However, accurate large-scale multiple sequence alignment is very difficult, especially when the dataset contains fragmentary sequences. We present UPP, a multiple sequence alignment method that uses a new machine learning technique, the ensemble of hidden Markov models, which we propose here. UPP produces highly accurate alignments for both nucleotide and amino acid sequences, even on ultra-large datasets or datasets containing fragmentary sequences. UPP is available at https://github.com/smirarab/sepp. © 2015 Nguyen et al.","","Algorithms; Machine Learning; Markov Chains; Phylogeny; Sequence Alignment; amino acid; nucleotide; accuracy; amino acid sequence; Article; evolution; gene locus; gene sequence; hidden Markov model; human; machine learning; maximum likelihood method; phylogeny; sequence alignment; sequence homology; algorithm; Markov chain; procedures; sequence alignment","BioMed Central Ltd.","14747596","","GNBLF","26076734","Article","Scopus","2-s2.0-84939168822"
"Hadzić T.; Park D.; Abruzzi K.C.; Yang L.; Trigg J.S.; Rohs R.; Rosbash M.; Taghert P.H.","Hadzić, Tarik (6506864864); Park, Dongkook (55235777500); Abruzzi, Katharine C. (6506780653); Yang, Lin (56920896100); Trigg, Jennifer S. (8834150400); Rohs, Remo (6602420905); Rosbash, Michael (7102160821); Taghert, Paul H. (7003383955)","6506864864; 55235777500; 6506780653; 56920896100; 8834150400; 6602420905; 7102160821; 7003383955","Genome-wide features of neuroendocrine regulation in Drosophila by the basic helix-loop-helix transcription factor DIMMED","2015","Nucleic Acids Research","20","10.1093/nar/gku1377","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941114631&doi=10.1093%2fnar%2fgku1377&partnerID=40&md5=a1f22fc21dd35afa06a3170b630d185c","Department of Anatomy and Neurobiology, Washington University School of Medicine, 660 South Euclid Avenue, St. Louis, 63110, MO, United States; Howard Hughes Medical Institute, National Center for Behavioral Genomics, Department of Biology, Brandeis University, Waltham, 02454, MA, United States; Molecular and Computational Biology Program, Department of Biological Sciences, University of Southern California, Los Angeles, 90089, CA, United States; Department of Psychiatry, Washington University Medical School, 660 South Euclid Avenue, St. Louis, 63110, MO, United States","Hadzić T., Department of Anatomy and Neurobiology, Washington University School of Medicine, 660 South Euclid Avenue, St. Louis, 63110, MO, United States, Department of Psychiatry, Washington University Medical School, 660 South Euclid Avenue, St. Louis, 63110, MO, United States; Park D., Department of Anatomy and Neurobiology, Washington University School of Medicine, 660 South Euclid Avenue, St. Louis, 63110, MO, United States; Abruzzi K.C., Howard Hughes Medical Institute, National Center for Behavioral Genomics, Department of Biology, Brandeis University, Waltham, 02454, MA, United States; Yang L., Molecular and Computational Biology Program, Department of Biological Sciences, University of Southern California, Los Angeles, 90089, CA, United States; Trigg J.S., Department of Anatomy and Neurobiology, Washington University School of Medicine, 660 South Euclid Avenue, St. Louis, 63110, MO, United States; Rohs R., Molecular and Computational Biology Program, Department of Biological Sciences, University of Southern California, Los Angeles, 90089, CA, United States; Rosbash M., Howard Hughes Medical Institute, National Center for Behavioral Genomics, Department of Biology, Brandeis University, Waltham, 02454, MA, United States; Taghert P.H., Department of Anatomy and Neurobiology, Washington University School of Medicine, 660 South Euclid Avenue, St. Louis, 63110, MO, United States","Neuroendocrine (NE) cells use large dense core vesicles (LDCVs) to traffic, process, store and secrete neuropeptide hormones through the regulated secretory pathway. The dimmed (DIMM) basic helix-loop-helix transcription factor of Drosophila controls the level of regulated secretory activity in NE cells. To pursue its mechanisms, we have performed two independent genome-wide analyses of DIMM's activities: (i) in vivo chromatin immunoprecipitation (ChIP) to define genomic sites of DIMM occupancy and (ii) deep sequencing of purified DIMM neurons to characterize their transcriptional profile. By this combined approach, we showed that DIMM binds to conserved E-boxes in enhancers of 212 genes whose expression is enriched in DIMM-expressing NE cells. DIMM binds preferentially to certain E-boxes within first introns of specific gene isoforms. Statistical machine learning revealed that flanking regions of putative DIMM binding sites contribute to its DNA binding specificity. DIMM's transcriptional repertoire features at least 20 LDCV constituents. In addition, DIMM notably targets the pro-secretory transcription factor, creb-A, but significantly, DIMM does not target any neuropeptide genes. DIMM therefore prescribes the scale of secretory activity in NE neurons, by a systematic control of both proximal and distal points in the regulated secretory pathway. © 2015 The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic Acids Research.","","Animals; Base Sequence; Basic Helix-Loop-Helix Transcription Factors; Binding Sites; Chromatin Immunoprecipitation; Conserved Sequence; Drosophila; Drosophila Proteins; E-Box Elements; Genome, Insect; High-Throughput Nucleotide Sequencing; Neuroendocrine Cells; Secretory Pathway; Sequence Analysis, DNA; Trans-Activators; Transcriptome; basic helix loop helix transcription factor; dimmed protein, Drosophila; Drosophila protein; transactivator protein; transcriptome; animal; binding site; chromatin immunoprecipitation; DNA sequence; Drosophila; E box element; genetics; high throughput sequencing; insect genome; metabolism; neurosecretory cell; nucleotide sequence; secretory pathway","Oxford University Press","03051048","","NARHA","25634895","Article","Scopus","2-s2.0-84941114631"
"Mansanet J.; Albiol A.; Paredes R.; Albiol A.","Mansanet, Jordi (55839953100); Albiol, Alberto (7003872793); Paredes, Roberto (7007168408); Albiol, Antonio (7003872794)","55839953100; 7003872793; 7007168408; 7003872794","Mask selective regularization for restricted Boltzmann machines","2015","Neurocomputing","3","10.1016/j.neucom.2015.03.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929950909&doi=10.1016%2fj.neucom.2015.03.026&partnerID=40&md5=2d0cebe547ac4214dc2381470911533d","Universitat Politècnica de València, València, 46022, Spain","Mansanet J., Universitat Politècnica de València, València, 46022, Spain; Albiol A., Universitat Politècnica de València, València, 46022, Spain; Paredes R., Universitat Politècnica de València, València, 46022, Spain; Albiol A., Universitat Politècnica de València, València, 46022, Spain","In the present work, we propose to deal with two important issues regarding to the RBM's learning capabilities. First, the topology of the input space, and second, the sparseness of the RBM obtained. One problem of RBMs is that they do not take advantage of the topology of the input space. In order to alleviate this lack, we propose to use a surrogate of the mutual information of the input representation space to build a set of binary masks. This approach is general and not only applicable to images, thus it can be extended to other layers in the standard layer-by-layer unsupervised learning. On the other hand, we propose a selective application of two different regularization terms, L1 and L2, in order to ensure the sparseness of the representation and the generalization capabilities. Additionally, another interesting capability of our approach is the adaptation of the topology of the network during the learning phase by means of selecting the best set of binary masks that fit the current weights configuration. The performance of these new ideas is assessed with a set of experiments on different well-known corpus. © 2015 Elsevier B.V.","Deep belief networks; Regularization; Restricted Boltzmann machine","Topology; Deep belief networks; Generalization capability; Learning capabilities; Mutual informations; Regularization; Regularization terms; Representation space; Restricted boltzmann machine; analytic method; Article; artificial neural network; image processing; learning algorithm; mask selective regularization approach; noise; nonbiological model; priority journal; process optimization; quality control; restricted Boltzmann machine model; signal detection; validation study; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84929950909"
"Wang S.; Weng S.; Ma J.; Tang Q.","Wang, Sheng (58428221300); Weng, Shunyan (29167637700); Ma, Jianzhu (57201470592); Tang, Qingming (36601256400)","58428221300; 29167637700; 57201470592; 36601256400","DeepCNF-D: Predicting protein order/disorder regions by weighted deep convolutional neural fields","2015","International Journal of Molecular Sciences","56","10.3390/ijms160817315","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938318602&doi=10.3390%2fijms160817315&partnerID=40&md5=0607217617cf2d9201d78603be8cb180","Department of Human Genetics, University of Chicago, Chicago, 60637, IL, United States; Toyota Technological Institute at Chicago, Chicago, 60637, IL, United States; MoE Key Laboratory of Developmental Genetics and Neuropsychiatric Diseases, Bio-X Center, School of Life Sciences and Biotechnology, Shanghai Jiao Tong University, Shanghai, 200240, China","Wang S., Department of Human Genetics, University of Chicago, Chicago, 60637, IL, United States, Toyota Technological Institute at Chicago, Chicago, 60637, IL, United States; Weng S., MoE Key Laboratory of Developmental Genetics and Neuropsychiatric Diseases, Bio-X Center, School of Life Sciences and Biotechnology, Shanghai Jiao Tong University, Shanghai, 200240, China; Ma J., Toyota Technological Institute at Chicago, Chicago, 60637, IL, United States; Tang Q., Toyota Technological Institute at Chicago, Chicago, 60637, IL, United States","Intrinsically disordered proteins or protein regions are involved in key biological processes including regulation of transcription, signal transduction, and alternative splicing. Accurately predicting order/disorder regions ab initio from the protein sequence is a prerequisite step for further analysis of functions and mechanisms for these disordered regions. This work presents a learning method, weighted DeepCNF (Deep Convolutional Neural Fields), to improve the accuracy of order/disorder prediction by exploiting the long-range sequential information and the interdependency between adjacent order/disorder labels and by assigning different weights for each label during training and prediction to solve the label imbalance issue. Evaluated by the CASP9 and CASP10 targets, our method obtains 0.855 and 0.898 AUC values, which are higher than the state-of-the-art single ab initio predictors. © 2015 by the authors; licensee MDPI, Basel, Switzerland.","Conditional neural field; Deep convolutional neural network; Deep learning; Intrinsically disordered proteins; Machine learning; Prediction of disordered regions","Intrinsically Disordered Proteins; Sequence Analysis, Protein; Software; amino acid; caspase 10; caspase 9; intrinsically disordered protein; protein; intrinsically disordered protein; area under the curve; Article; artificial neural network; deep convolutional neural field; human; machine learning; measurement accuracy; prediction; protein secondary structure; receiver operating characteristic; X ray diffraction; chemistry; procedures; sequence analysis; software","MDPI AG","16616596","","","26230689","Article","Scopus","2-s2.0-84938318602"
"Agharbaoui Z.; Leclercq M.; Remita M.A.; Badawi M.A.; Lord E.; Houde M.; Danyluk J.; Diallo A.B.; Sarhan F.","Agharbaoui, Zahra (6506943731); Leclercq, Mickael (57220422899); Remita, Mohamed Amine (56650890600); Badawi, Mohamed A. (24553993400); Lord, Etienne (54891515600); Houde, Mario (7005057424); Danyluk, Jean (6701782676); Diallo, Abdoulaye Baniré (15044077500); Sarhan, Fathey (7003409235)","6506943731; 57220422899; 56650890600; 24553993400; 54891515600; 7005057424; 6701782676; 15044077500; 7003409235","An integrative approach to identify hexaploid wheat miRNAome associated with development and tolerance to abiotic stress","2015","BMC Genomics","20","10.1186/s12864-015-1490-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929578666&doi=10.1186%2fs12864-015-1490-8&partnerID=40&md5=3dc66a15aad5034c863376da1be138c2","University of Quebec in Montreal, Department of Biological Sciences, Montreal, Canada; University of Quebec in Montreal, Department of Computer Sciences, Montreal, Canada; School of Computer Science and McGill Centre for Bioinformatics, McGill University, Montreal, QC, Canada","Agharbaoui Z., University of Quebec in Montreal, Department of Biological Sciences, Montreal, Canada; Leclercq M., University of Quebec in Montreal, Department of Computer Sciences, Montreal, Canada, School of Computer Science and McGill Centre for Bioinformatics, McGill University, Montreal, QC, Canada; Remita M.A., University of Quebec in Montreal, Department of Computer Sciences, Montreal, Canada; Badawi M.A., University of Quebec in Montreal, Department of Biological Sciences, Montreal, Canada; Lord E., University of Quebec in Montreal, Department of Computer Sciences, Montreal, Canada; Houde M., University of Quebec in Montreal, Department of Biological Sciences, Montreal, Canada; Danyluk J., University of Quebec in Montreal, Department of Biological Sciences, Montreal, Canada; Diallo A.B., University of Quebec in Montreal, Department of Computer Sciences, Montreal, Canada; Sarhan F., University of Quebec in Montreal, Department of Biological Sciences, Montreal, Canada","Background: Wheat is a major staple crop with broad adaptability to a wide range of environmental conditions. This adaptability involves several stress and developmentally responsive genes, in which microRNAs (miRNAs) have emerged as important regulatory factors. However, the currently used approaches to identify miRNAs in this polyploid complex system focus on conserved and highly expressed miRNAs avoiding regularly those that are often lineage-specific, condition-specific, or appeared recently in evolution. In addition, many environmental and biological factors affecting miRNA expression were not yet considered, resulting still in an incomplete repertoire of wheat miRNAs. Results: We developed a conservation-independent technique based on an integrative approach that combines machine learning, bioinformatic tools, biological insights of known miRNA expression profiles and universal criteria of plant miRNAs to identify miRNAs with more confidence. The developed pipeline can potentially identify novel wheat miRNAs that share features common to several species or that are species specific or clade specific. It allowed the discovery of 199 miRNA candidates associated with different abiotic stresses and development stages. We also highlight from the raw data 267 miRNAs conserved with 43 miRBase families. The predicted miRNAs are highly associated with abiotic stress responses, tolerance and development. GO enrichment analysis showed that they may play biological and physiological roles associated with cold, salt and aluminum (Al) through auxin signaling pathways, regulation of gene expression, ubiquitination, transport, carbohydrates, gibberellins, lipid, glutathione and secondary metabolism, photosynthesis, as well as floral transition and flowering. Conclusion: This approach provides a broad repertoire of hexaploid wheat miRNAs associated with abiotic stress responses, tolerance and development. These valuable resources of expressed wheat miRNAs will help in elucidating the regulatory mechanisms involved in freezing and Al responses and tolerance mechanisms as well as for development and flowering. In the long term, it may help in breeding stress tolerant plants. © 2015 Agharbaoui et al.; licensee BioMed Central.","Abiotic stress; Deep sequencing; Development; Expressed sequenced tags; MiRNA prediction; Triticum aestivum. L; Vernalization","Computational Biology; Gene Expression Profiling; Gene Expression Regulation, Plant; Machine Learning; MicroRNAs; Polyploidy; RNA, Plant; Species Specificity; Stress, Physiological; Triticum; Triticum aestivum; aluminum; auxin; microRNA; sodium chloride; microRNA; plant RNA; abiotic stress; Article; cladistics; cold; controlled study; flowering; gene expression; gene expression profiling; gene ontology; nonhuman; photosynthesis; plant development; RNA analysis; secondary metabolism; signal transduction; Triticum aestivum; biology; gene expression regulation; genetics; growth, development and aging; machine learning; physiological stress; polyploidy; procedures; species difference; wheat","BioMed Central Ltd.","14712164","","BGMEE","25903161","Article","Scopus","2-s2.0-84929578666"
"Bagnasco L.; Zotti M.; Sitta N.; Oliveri P.","Bagnasco, Lucia (55628418700); Zotti, Mirca (6603935844); Sitta, Nicola (25522773600); Oliveri, Paolo (24341831500)","55628418700; 6603935844; 25522773600; 24341831500","A PCA-based hyperspectral approach to detect infections by mycophilic fungi on dried porcini mushrooms (boletus edulis and allied species)","2015","Talanta","19","10.1016/j.talanta.2015.07.071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939174555&doi=10.1016%2fj.talanta.2015.07.071&partnerID=40&md5=f174095ab067bb6d2f3be042a3046481","Department of Pharmacy, University of Genoa, Via Brigata Salerno, 13, Genoa, I-16147, Italy; Department of Earth, Environment and Life Sciences, Laboratory of Mycology, Corso Europa, 26, Genoa, I-16132, Italy; Professional Consulting Mycologist, Loc. Farné, 32, Lizzano in Belvedere, I-40042, Italy","Bagnasco L., Department of Pharmacy, University of Genoa, Via Brigata Salerno, 13, Genoa, I-16147, Italy; Zotti M., Department of Earth, Environment and Life Sciences, Laboratory of Mycology, Corso Europa, 26, Genoa, I-16132, Italy; Sitta N., Professional Consulting Mycologist, Loc. Farné, 32, Lizzano in Belvedere, I-40042, Italy; Oliveri P., Department of Pharmacy, University of Genoa, Via Brigata Salerno, 13, Genoa, I-16147, Italy","Abstract Mycophilic fungi of anamorphic genus Sepedonium (telomorphs in Hypomyces, Hypocreales, Ascomycota) infect and parasitize sporomata of boletes. The obligated hosts such as Boletus edulis and allied species (known as ""porcini mushrooms"") are among the most valued and prized edible wild mushrooms in the world. Sepedonium infections have a great morphological variability: at the initial state, contaminated mushrooms present a white coating covering tubes and pores; at the final state, Sepedonium forms a deep and thick hyphal layer that eventually leads to the total necrosis of the host. Up to date, Sepedonium infections in porcini mushrooms have been evaluated only through macroscopic and microscopic visual analysis. In this study, in order to implement the infection evaluation as a routine methodology for industrial purposes, the potential application of Hyperspectral Imaging (HSI) and Principal Component Analysis (PCA) for detection of Sepedonium presence on sliced and dried B. edulis and allied species was investigated. Hyperspectral images were obtained using a pushbroom line-scanning HSI instrument, operating in the wavelength range between 400 and 1000 nm with 5 nm resolution. PCA was applied on normal and contaminated samples. To reduce the spectral variability caused by factors unrelated to Sepedonium infection, such as scattering effects and differences in sample height, different spectral pre-treatments were applied. A supervised rule was then developed to assign spectra recorded on new test samples to each of the two classes, based on the PC scores. This allowed to visualize directly - within false-color images of test samples - which points of the samples were contaminated. The results achieved may lead to the development of a non-destructive monitoring system for a rapid on-line screening of contaminated mushrooms. © 2015 Elsevier B.V.","Edible mushrooms; Hyperspectral imaging (HSI); Mycoparasite; Principal components analysis (PCA); Sepedonium","Agaricales; Hypocreales; Image Processing, Computer-Assisted; Principal Component Analysis; Spectrum Analysis; Supervised Machine Learning; Time Factors; Contamination; Fungi; Hyperspectral imaging; Spectroscopy; Edible mushroom; Hyperspectral imaging (HSI); Mycoparasite; Principal components analysis; Sepedonium; Agaricales; Hypocreales; image processing; isolation and purification; physiology; principal component analysis; spectroscopy; supervised machine learning; time factor; Principal component analysis","Elsevier B.V.","00399140","","TLNTA","26452951","Article","Scopus","2-s2.0-84939174555"
"Hua K.-L.; Hsu C.-H.; Hidayati S.C.; Cheng W.-H.; Chen Y.-J.","Hua, Kai-Lung (55223901500); Hsu, Che-Hao (55536778100); Hidayati, Shintami Chusnul (55533725700); Cheng, Wen-Huang (24775341200); Chen, Yu-Jen (57022072800)","55223901500; 55536778100; 55533725700; 24775341200; 57022072800","Computer-aided classification of lung nodules on computed tomography images via deep learning technique","2015","OncoTargets and Therapy","451","10.2147/OTT.S80733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939781083&doi=10.2147%2fOTT.S80733&partnerID=40&md5=69c3d81ff91007a7421fbf973b69b3ee","Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, MacKay Memorial Hospital, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, MacKay Memorial Hospital, Taipei, Taiwan; Department of Radiation Oncology, MacKay Memorial Hospital, Taipei, Taiwan","Hua K.-L., Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, MacKay Memorial Hospital, Taipei, Taiwan; Hsu C.-H., Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, MacKay Memorial Hospital, Taipei, Taiwan; Hidayati S.C., Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, MacKay Memorial Hospital, Taipei, Taiwan; Cheng W.-H., Research Center for Information Technology Innovation, Academia Sinica, MacKay Memorial Hospital, Taipei, Taiwan; Chen Y.-J., Department of Radiation Oncology, MacKay Memorial Hospital, Taipei, Taiwan","Lung cancer has a poor prognosis when not diagnosed early and unresectable lesions are present. The management of small lung nodules noted on computed tomography scan is controversial due to uncertain tumor characteristics. A conventional computer-aided diagnosis (CAD) scheme requires several image processing and pattern recognition steps to accomplish a quantitative tumor differentiation result. In such an ad hoc image analysis pipeline, every step depends heavily on the performance of the previous step. Accordingly, tuning of classification performance in a conventional CAD scheme is very complicated and arduous. Deep learning techniques, on the other hand, have the intrinsic advantage of an automatic exploitation feature and tuning of performance in a seamless fashion. In this study, we attempted to simplify the image analysis pipeline of conventional CAD with deep learning techniques. Specifically, we introduced models of a deep belief network and a convolutional neural network in the context of nodule classification in computed tomography images. Two baseline methods with feature computing steps were implemented for comparison. The experimental results suggest that deep learning methods could achieve better discriminative results and hold promise in the CAD application domain. © 2015 Hua et al.","Convolutional neural network; Deep belief network; Deep learning; Nodule classification","Article; artificial neural network; computer assisted diagnosis; computer assisted tomography; convolutional neural network; deep belief network; deep learning; disease classification; human; image analysis; image processing; lung nodule; machine learning; pattern recognition; sensitivity and specificity","Dove Medical Press Ltd.","11786930","","","","Article","Scopus","2-s2.0-84939781083"
"Ertosun M.G.; Rubin D.L.","Ertosun, Mehmet Günhan (8727968800); Rubin, Daniel L. (7202307112)","8727968800; 7202307112","Automated Grading of Gliomas using Deep Learning in Digital Pathology Images: A modular approach with ensemble of convolutional neural networks","2015","AMIA ... Annual Symposium proceedings. AMIA Symposium","209","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042106575&partnerID=40&md5=1908e6a11eed8f5acd5d7c90ad2d648c","Department of Radiology, Stanford University, USA; Department of Medicine (Biomedical Informatics Research), Stanford University, Stanford, CA, United States; Department of Radiology, Stanford University, USA; Department of Medicine (Biomedical Informatics Research), Stanford University, Stanford, CA, United States","Ertosun M.G., Department of Radiology, Stanford University, USA; Department of Medicine (Biomedical Informatics Research), Stanford University, Stanford, CA, United States; Rubin D.L., Department of Radiology, Stanford University, USA; Department of Medicine (Biomedical Informatics Research), Stanford University, Stanford, CA, United States","Brain glioma is the most common primary malignant brain tumors in adults with different pathologic subtypes: Lower Grade Glioma (LGG) Grade II, Lower Grade Glioma (LGG) Grade III, and Glioblastoma Multiforme (GBM) Grade IV. The survival and treatment options are highly dependent of this glioma grade. We propose a deep learning-based, modular classification pipeline for automated grading of gliomas using digital pathology images. Whole tissue digitized images of pathology slides obtained from The Cancer Genome Atlas (TCGA) were used to train our deep learning modules. Our modular pipeline provides diagnostic quality statistics, such as precision, sensitivity and specificity, of the individual deep learning modules, and (1) facilitates training given the limited data in this domain, (2) enables exploration of different deep learning structures for each module, (3) leads to developing less complex modules that are simpler to analyze, and (4) provides flexibility, permitting use of single modules within the framework or use of other modeling or machine learning applications, such as probabilistic graphical models or support vector machines. Our modular approach helps us meet the requirements of minimum accuracy levels that are demanded by the context of different decision points within a multi-class classification scheme. Convolutional Neural Networks are trained for each module for each sub-task with more than 90% classification accuracies on validation data set, and achieved classification accuracy of 96% for the task of GBM vs LGG classification, 71% for further identifying the grade of LGG into Grade II or Grade III on independent data set coming from new patients from the multi-institutional repository.","","Automatic Data Processing; Brain Neoplasms; Glioblastoma; Glioma; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer); artificial neural network; brain tumor; diagnostic imaging; glioblastoma; glioma; human; image processing; information processing; machine learning; pathology","","1942597X","","","26958289","Article","Scopus","2-s2.0-85042106575"
"Gan J.; Li L.; Zhai Y.; Liu Y.","Gan, Junying (35902507700); Li, Lichen (56231352000); Zhai, Yikui (55430124300); Liu, Yinhua (55609384700)","35902507700; 56231352000; 55430124300; 55609384700","Deep self-taught learning for facial beauty prediction","2014","Neurocomputing","77","10.1016/j.neucom.2014.05.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906055479&doi=10.1016%2fj.neucom.2014.05.028&partnerID=40&md5=1c0f5a14861ddb9be5a97206509f7194","School of Information Engineering, Wuyi University, Jiangmen, Guangdong 529020, China","Gan J., School of Information Engineering, Wuyi University, Jiangmen, Guangdong 529020, China; Li L., School of Information Engineering, Wuyi University, Jiangmen, Guangdong 529020, China; Zhai Y., School of Information Engineering, Wuyi University, Jiangmen, Guangdong 529020, China; Liu Y., School of Information Engineering, Wuyi University, Jiangmen, Guangdong 529020, China","Most modern research of facial beauty prediction focuses on geometric features by traditional machine learning methods. Geometric features may easily lose much feature information characterizing facial beauty, rely heavily on accurate manual landmark localization of facial features and impose strict restrictions on training samples. Deep architectures have been recently demonstrated to be a promising area of research in statistical machine learning. In this paper, deep self-taught learning is utilized to obtain hierarchical representations, learn the concept of facial beauty and produce human-like predictor. Deep learning is helpful to recognize a broad range of visual concept effectively characterizing facial beauty. Through deep learning, reasonable apparent features of face images are extracted without depending completely on artificial feature selection. Self-taught learning, which has the ability of automatically improving network systems to understand the characteristics of data distribution and making recognition significantly easier and cheaper, is used to relax strict restrictions of training samples. Moreover, in order to choose a more appropriate method for mapping high-level representations into beauty ratings efficiently, we compare the performance of five regression methods and prove that support vector machine (SVM) regression is better. In addition, novel applications of deep self-taught learning on local binary pattern (LBP) and Gabor filters are presented, and the improvements on facial beauty prediction are shown by deep self-taught learning combined with LBP. Finally, human-like performance is obtained with learning features in full-sized and high-resolution images. © 2014 Elsevier B.V.","Deep self-taught learning; Facial beauty prediction; Local binary pattern; Regression methods","Forecasting; Gabor filters; Learning systems; Sampling; Support vector machines; Support vector regression; Hierarchical representation; Landmark localization; Local binary patterns; Machine learning methods; Regression method; Self-taught learning; Statistical machine learning; Support vector machine regressions; article; artificial neural network; controlled study; data extraction; deep self taught learning; esthetics; facial expression; Gabor filters; information processing; intermethod comparison; linear regression analysis; local binary pattern; logistic regression analysis; machine learning; prediction; priority journal; regression analysis; support vector machine; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84906055479"
"Stromatias E.; Neil D.; Pfeiffer M.; Galluppi F.; Furber S.B.; Liu S.-C.","Stromatias, Evangelos (56028834800); Neil, Daniel (55944451800); Pfeiffer, Michael (41662180000); Galluppi, Francesco (24775913300); Furber, Steve B. (7004528676); Liu, Shih-Chii (7409457533)","56028834800; 55944451800; 41662180000; 24775913300; 7004528676; 7409457533","Robustness of spiking Deep Belief Networks to noise and reduced bit precision of neuro-inspired hardware platforms","2015","Frontiers in Neuroscience","76","10.3389/fnins.2015.00222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84935098619&doi=10.3389%2ffnins.2015.00222&partnerID=40&md5=84ffc0ac26463a8a909ebf0924ed6ddf","Advanced Processor Technologies Group, School of Computer Science, University of Manchester, United Kingdom; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Equipe de Vision et Calcul Naturel, Vision Institute, Université Pierre et Marie Curie, UMR S968 Inserm, UPMC, CNRS UMR 7210, CHNO des Quinze-Vingts, Paris, France","Stromatias E., Advanced Processor Technologies Group, School of Computer Science, University of Manchester, United Kingdom; Neil D., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Pfeiffer M., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Galluppi F., Equipe de Vision et Calcul Naturel, Vision Institute, Université Pierre et Marie Curie, UMR S968 Inserm, UPMC, CNRS UMR 7210, CHNO des Quinze-Vingts, Paris, France; Furber S.B., Advanced Processor Technologies Group, School of Computer Science, University of Manchester, United Kingdom; Liu S.-C., Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland","Increasingly large deep learning architectures, such as Deep Belief Networks (DBNs) are the focus of current machine learning research and achieve state-of-the-art results in different domains. However, both training and execution of large-scale Deep Networks requires vast computing resources, leading to high power requirements and communication overheads. The on-going work on design and construction of spike-based hardware platforms offers an alternative for running deep neural networks with significantly lower power consumption, but has to overcome hardware limitations in terms of noise and limited weight precision, as well as noise inherent in the sensor signal. This article investigates how such hardware constraints impact the performance of spiking neural network implementations of DBNs. In particular, the influence of limited bit precision during execution and training, and the impact of silicon mismatch in the synaptic weight parameters of custom hybrid VLSI implementations is studied. Furthermore, the network performance of spiking DBNs is characterized with regard to noise in the spiking input signal. Our results demonstrate that spiking DBNs can tolerate very low levels of hardware bit precision down to almost 2 bits, and show that their performance can be improved by at least 30% through an adapted training mechanism that takes the bit precision of the target platform into account. Spiking DBNs thus present an important use-case for large-scale hybrid analog-digital or digital neuromorphic platforms such as SpiNNaker, which can execute large but precision-constrained deep networks in real time. © 2015 Stromatias, Neil, Pfeiffer, Galluppi, Furber and Liu.","Deep belief networks; Neuro-inspired hardware; Noise robustness; Spiking neural networks; SpiNNaker","accuracy; Article; artificial neural network; classification algorithm; coding; comparative study; computer program; deep belief network; energy cost; machine learning; mathematical computing; nerve cell plasticity; noise; nonlinear system; probability; receptive field; simulation; spike wave","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-84935098619"
"Mamun K.A.; Mace M.; Lutman M.E.; Stein J.; Liu X.; Aziz T.; Vaidyanathan R.; Wang S.","Mamun, K.A. (57923621700); Mace, M. (35409582600); Lutman, M.E. (16947914000); Stein, J. (56481036000); Liu, X. (55717209300); Aziz, T. (7102677271); Vaidyanathan, R. (35570517600); Wang, S. (55660820300)","57923621700; 35409582600; 16947914000; 56481036000; 55717209300; 7102677271; 35570517600; 55660820300","Movement decoding using neural synchronization and inter-hemispheric connectivity from deep brain local field potentials","2015","Journal of Neural Engineering","27","10.1088/1741-2560/12/5/056011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945207440&doi=10.1088%2f1741-2560%2f12%2f5%2f056011&partnerID=40&md5=9f8ccdb17ddc3f8475df80c6c1220349","Institute of Sound and Vibration Research, University of Southampton, Southampton, United Kingdom; Institute of Biomaterials and Biomedical Engineering, University of Toronto and Bloorview Research Institute, Holland Bloorview Kids Rehabilitation Hospital, Toronto, Canada; Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh; Department of Mechanical Engineering, Imperial College London, London, United Kingdom; Functional Neurosurgery and Experimental Neurology Group, University of Oxford, Oxford, United Kingdom; Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China","Mamun K.A., Institute of Sound and Vibration Research, University of Southampton, Southampton, United Kingdom, Institute of Biomaterials and Biomedical Engineering, University of Toronto and Bloorview Research Institute, Holland Bloorview Kids Rehabilitation Hospital, Toronto, Canada, Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh; Mace M., Department of Mechanical Engineering, Imperial College London, London, United Kingdom; Lutman M.E., Institute of Sound and Vibration Research, University of Southampton, Southampton, United Kingdom; Stein J., Functional Neurosurgery and Experimental Neurology Group, University of Oxford, Oxford, United Kingdom; Liu X., Functional Neurosurgery and Experimental Neurology Group, University of Oxford, Oxford, United Kingdom; Aziz T., Functional Neurosurgery and Experimental Neurology Group, University of Oxford, Oxford, United Kingdom; Vaidyanathan R., Department of Mechanical Engineering, Imperial College London, London, United Kingdom; Wang S., Institute of Sound and Vibration Research, University of Southampton, Southampton, United Kingdom, Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Sciences, Suzhou, China","Objective. Correlating electrical activity within the human brain to movement is essential for developing and refining interventions (e.g. deep brain stimulation (DBS)) to treat central nervous system disorders. It also serves as a basis for next generation brain-machine interfaces (BMIs). This study highlights a new decoding strategy for capturing movement and its corresponding laterality from deep brain local field potentials (LFPs). Approach. LFPs were recorded with surgically implanted electrodes from the subthalamic nucleus or globus pallidus interna in twelve patients with Parkinson's disease or dystonia during a visually cued finger-clicking task. We introduce a method to extract frequency dependent neural synchronization and inter-hemispheric connectivity features based upon wavelet packet transform (WPT) and Granger causality approaches. A novel weighted sequential feature selection algorithm has been developed to select optimal feature subsets through a feature contribution measure. This is particularly useful when faced with limited trials of high dimensionality data as it enables estimation of feature importance during the decoding process. Main results. This novel approach was able to accurately and informatively decode movement related behaviours from the recorded LFP activity. An average accuracy of 99.8% was achieved for movement identification, whilst subsequent laterality classification was 81.5%. Feature contribution analysis highlighted stronger contralateral causal driving between the basal ganglia hemispheres compared to ipsilateral driving, with causality measures considerably improving laterality discrimination. Significance. These findings demonstrate optimally selected neural synchronization alongside causality measures related to inter-hemispheric connectivity can provide an effective control signal for augmenting adaptive BMIs. In the case of DBS patients, acquiring such signals requires no additional surgery whilst providing a relatively stable and computationally inexpensive control signal. This has the potential to extend invasive BMI, based on recordings within the motor cortex, by providing additional information from subcortical regions. © 2015 IOP Publishing Ltd.","brain connectivity; brainmachine interface; deep brain stimulation; local field potentials; machine learning","Adult; Aged; Algorithms; Basal Ganglia; Brain-Computer Interfaces; Cortical Synchronization; Electroencephalography; Evoked Potentials, Motor; Female; Humans; Machine Learning; Male; Middle Aged; Movement; Movement Disorders; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Artificial intelligence; Decoding; Learning systems; Neurosurgery; Packet networks; Surgery; Synchronization; Brain connectivity; Brain machine interface; Brain machine interface (BMIs); Central nervous systems; Deep brain stimulation; Local field potentials; Sequential feature selections; Wavelet packet transform(WPT); adult; aged; algorithm; Article; brain depth stimulation; clinical article; connectome; controlled study; cortical synchronization; dystonia; female; globus pallidus; hemispheric dominance; human; male; middle aged; Parkinson disease; priority journal; subthalamic nucleus; voluntary movement; automated pattern recognition; basal ganglion; brain computer interface; cortical synchronization; electroencephalography; machine learning; motor dysfunction; motor evoked potential; movement (physiology); pathophysiology; physiology; procedures; reproducibility; sensitivity and specificity; Brain","Institute of Physics Publishing","17412560","","","26305124","Article","Scopus","2-s2.0-84945207440"
"Zhang G.; Huang Y.; Zhong L.; Ou S.; Zhang Y.; Li Z.","Zhang, Gang (57005637200); Huang, Yonghui (35190617800); Zhong, Ling (35729494300); Ou, Shanxing (36480142400); Zhang, Yi (56976476400); Li, Ziping (55636269700)","57005637200; 35190617800; 35729494300; 36480142400; 56976476400; 55636269700","An Ensemble Learning Based Framework for Traditional Chinese Medicine Data Analysis with ICD-10 Labels","2015","Scientific World Journal","3","10.1155/2015/507925","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944216202&doi=10.1155%2f2015%2f507925&partnerID=40&md5=468eef65df6ca9d7b51f29cdf5cff371","School of Automation, Guangdong University of Technology, Guangzhou, 510006, China; Department of Radiology, Guangzhou General Hospital of Guangzhou Military Command, Guangzhou, 510010, China; Department of Plastic and Reconstructive Surgery, The First Affiliated Hospital of Sun Yat-Sen University, Guangzhou, 510080, China; Second Affiliated Hospital of Guangzhou University of Chinese Medicine, Guangzhou, 510120, China","Zhang G., School of Automation, Guangdong University of Technology, Guangzhou, 510006, China; Huang Y., School of Automation, Guangdong University of Technology, Guangzhou, 510006, China; Zhong L., School of Automation, Guangdong University of Technology, Guangzhou, 510006, China; Ou S., Department of Radiology, Guangzhou General Hospital of Guangzhou Military Command, Guangzhou, 510010, China; Zhang Y., Department of Plastic and Reconstructive Surgery, The First Affiliated Hospital of Sun Yat-Sen University, Guangzhou, 510080, China; Li Z., Second Affiliated Hospital of Guangzhou University of Chinese Medicine, Guangzhou, 510120, China","Objective. This study aims to establish a model to analyze clinical experience of TCM veteran doctors. We propose an ensemble learning based framework to analyze clinical records with ICD-10 labels information for effective diagnosis and acupoints recommendation. Methods. We propose an ensemble learning framework for the analysis task. A set of base learners composed of decision tree (DT) and support vector machine (SVM) are trained by bootstrapping the training dataset. The base learners are sorted by accuracy and diversity through nondominated sort (NDS) algorithm and combined through a deep ensemble learning strategy. Results. We evaluate the proposed method with comparison to two currently successful methods on a clinical diagnosis dataset with manually labeled ICD-10 information. ICD-10 label annotation and acupoints recommendation are evaluated for three methods. The proposed method achieves an accuracy rate of 88.2% ± 2.8% measured by zero-one loss for the first evaluation session and 79.6% ± 3.6% measured by Hamming loss, which are superior to the other two methods. Conclusion. The proposed ensemble model can effectively model the implied knowledge and experience in historic clinical data records. The computational cost of training a set of base learners is relatively low. © 2015 Gang Zhang et al.","","Acupuncture Points; Algorithms; Databases as Topic; Humans; International Classification of Diseases; Medicine, Chinese Traditional; Statistics as Topic; accuracy; acupuncture; algorithm; Article; bootstrapping; Chinese medicine; comparative study; cost; data analysis; decision tree; human; ICD-10; knowledge; machine learning; medical record review; physician; procedures; support vector machine; training; work experience; algorithm; data base; International Classification of Diseases; statistics","Hindawi Publishing Corporation","23566140","","","26504897","Article","Scopus","2-s2.0-84944216202"
"Elfwing S.; Uchibe E.; Doya K.","Elfwing, S. (16199609700); Uchibe, E. (6603720332); Doya, K. (7004163287)","16199609700; 6603720332; 7004163287","Expected energy-based restricted Boltzmann machine forclassification","2015","Neural Networks","28","10.1016/j.neunet.2014.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922382574&doi=10.1016%2fj.neunet.2014.09.006&partnerID=40&md5=d9204bd062a167c8d262bdc16cbb25bb","Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa, 904-0495, Japan","Elfwing S., Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa, 904-0495, Japan; Uchibe E., Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa, 904-0495, Japan; Doya K., Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna-son, Okinawa, 904-0495, Japan","In classification tasks, restricted Boltzmann machines (RBMs) have predominantly been used in the first stage, either as feature extractors or to provide initialization of neural networks. In this study, we propose a discriminative learning approach to provide a self-contained RBM method for classification, inspired by free-energy based function approximation (FE-RBM), originally proposed for reinforcement learning. For classification, the FE-RBM method computes the output for an input vector and a class vector by the negative free energy of an RBM. Learning is achieved by stochastic gradient-descent using a mean-squared error training objective. In an earlier study, we demonstrated that the performance and the robustness of FE-RBM function approximation can be improved by scaling the free energy by a constant that is related to the size of network. In this study, we propose that the learning performance of RBM function approximation can be further improved by computing the output by the negative expected energy (EE-RBM), instead of the negative free energy. To create a deep learning architecture, we stack several RBMs on top of each other. We also connect the class nodes to all hidden layers to try to improve the performance even further. We validate the classification performance of EE-RBM using the MNIST data set and the NORB data set, achieving competitive performance compared with other classifiers such as standard neural networks, deep belief networks, classification RBMs, and support vector machines. The purpose of using the NORB data set is to demonstrate that EE-RBM with binary input nodes can achieve high performance in the continuous input domain. © 2014 The Authors.","Classification; Expected energy; Free energy; Restricted Boltzmann machine","Classification; Neural Networks (Computer); Free energy; Learning systems; Mean square error; Reinforcement learning; Stochastic systems; Classification performance; Competitive performance; Deep belief networks; Discriminative learning; Expected energy; Function approximation; Restricted boltzmann machine; Stochastic gradient descent; Article; artificial neural network; kernel method; machine learning; mathematical computing; mathematical variable; performance; restricted Boltzmann machine; support vector machine; artificial neural network; classification; procedures; Classification (of information)","Elsevier Ltd","08936080","","NNETE","25318375","Article","Scopus","2-s2.0-84922382574"
"Li S.-Z.; Yu B.; Wu W.; Su S.-Z.; Ji R.-R.","Li, Shao-Zi (8234782300); Yu, Bin (56435023500); Wu, Wei (58341509400); Su, Song-Zhi (26424887800); Ji, Rong-Rong (23134935200)","8234782300; 56435023500; 58341509400; 26424887800; 23134935200","Feature learning based on SAE-PCA network for human gesture recognition in RGBD images","2015","Neurocomputing","105","10.1016/j.neucom.2014.06.086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919650221&doi=10.1016%2fj.neucom.2014.06.086&partnerID=40&md5=f1f7a82aa415d9b8c08fdb54b8f48509","School of Information Science and Technology, Xiamen University, Xiamen, 361005, China; Fujian Key Laboratory of the Brain-like Intelligent Systems, Xiamen University, Xiamen, 361005, China; Institute of Mathematics and Computer Science, GuiZhou Normal University, Guizhou, 550001, China","Li S.-Z., School of Information Science and Technology, Xiamen University, Xiamen, 361005, China, Fujian Key Laboratory of the Brain-like Intelligent Systems, Xiamen University, Xiamen, 361005, China; Yu B., School of Information Science and Technology, Xiamen University, Xiamen, 361005, China, Fujian Key Laboratory of the Brain-like Intelligent Systems, Xiamen University, Xiamen, 361005, China, Institute of Mathematics and Computer Science, GuiZhou Normal University, Guizhou, 550001, China; Wu W., School of Information Science and Technology, Xiamen University, Xiamen, 361005, China, Fujian Key Laboratory of the Brain-like Intelligent Systems, Xiamen University, Xiamen, 361005, China; Su S.-Z., School of Information Science and Technology, Xiamen University, Xiamen, 361005, China, Fujian Key Laboratory of the Brain-like Intelligent Systems, Xiamen University, Xiamen, 361005, China; Ji R.-R., School of Information Science and Technology, Xiamen University, Xiamen, 361005, China, Fujian Key Laboratory of the Brain-like Intelligent Systems, Xiamen University, Xiamen, 361005, China","Coming with the emerging of depth sensors link Microsoft Kinect, human hand gesture recognition has received ever increasing research interests recently. A successful gesture recognition system has usually heavily relied on having a good feature representation of data, which is expected to be task-dependent as well as coping with the challenges and opportunities induced by depth sensor. In this paper, a feature learning approach based on sparse auto-encoder (SAE) and principle component analysis is proposed for recognizing human actions, i.e. finger-spelling or sign language, for RGB-D inputs. The proposed model of feature learning is consisted of two components: First, features are learned respectively from the RGB and depth channels, using sparse auto-encoder with convolutional neural networks. Second, the learned features from both channels is concatenated and fed into a multiple layer PCA to get the final feature. Experimental results on American sign language (ASL) dataset demonstrate that the proposed feature learning model is significantly effective, which improves the recognition rate from 75% to 99.05% and outperforms the state-of-the-art. © 2014 Elsevier B.V.","American sign language recognition; Auto-encoder; Convolutional neural networks; Deep learning","Channel coding; Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Learning systems; Palmprint recognition; Signal encoding; American sign language; Auto encoders; Feature representation; Gesture recognition system; Human gesture recognition; Microsoft kinect; Principle component analysis; Research interests; American; Article; artificial neural network; color; controlled study; convolutional neural network; human; human gesture recognition; information processing device; intermethod comparison; machine learning; principal component analysis; sensor; sign language; sparse auto encoder; vision; Gesture recognition","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84919650221"
"Kim S.; Choi Y.; Lee M.","Kim, Sangwook (57169169400); Choi, Yonghwa (56024386900); Lee, Minho (57191730119)","57169169400; 56024386900; 57191730119","Deep learning with support vector data description","2015","Neurocomputing","82","10.1016/j.neucom.2014.09.086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929944640&doi=10.1016%2fj.neucom.2014.09.086&partnerID=40&md5=c4bff36111404034a443555f7eb53ae1","School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea","Kim S., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; Choi Y., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea; Lee M., School of Electronics Engineering, Kyungpook National University, 1370 Sankyuk-Dong, Puk-Gu, Taegu, 702-701, South Korea","One of the most critical problems for machine learning methods is overfitting. The overfitting problem is a phenomenon in which the accuracy of the model on unseen data is poor whereas the training accuracy is nearly perfect. This problem is particularly severe in complex models that have a large set of parameters. In this paper, we propose a deep learning neural network model that adopts the support vector data description (SVDD). The SVDD is a variant of the support vector machine, which has high generalization performance by acquiring a maximal margin in one-class classification problems. The proposed model strives to obtain the representational power of deep learning. Generalization performance is maintained using the SVDD. The experimental results showed that the proposed model can learn multiclass data without severe overfitting problems. © 2015 Elsevier B.V.","Deep learning; Generalization; Pattern recognition; Support vector data description","Data description; Deep neural networks; Learning systems; Pattern recognition; Support vector machines; Vectors; Critical problems; Generalization; Generalization performance; Learning neural networks; Machine learning methods; One-class Classification; Over fitting problem; Support vector data description; algorithm; Article; artificial neural network; information processing; learning algorithm; mathematical computing; mathematical parameters; measurement accuracy; model; priority journal; simulation; support vector data description; support vector machine; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84929944640"
"Shen C.; Zhao Q.","Shen, Chengyao (53871958600); Zhao, Qi (55743334300)","53871958600; 55743334300","Learning to predict eye fixations for semantic contents using multi-layer sparse network","2014","Neurocomputing","40","10.1016/j.neucom.2013.09.053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899945571&doi=10.1016%2fj.neucom.2013.09.053&partnerID=40&md5=3277228c8f0dcfb176770b839ab4d88e","NUS Graduate School for Integrative Sciences and Engineering (NGS), National University of Singapore, 117456, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, 117576, Singapore","Shen C., NUS Graduate School for Integrative Sciences and Engineering (NGS), National University of Singapore, 117456, Singapore; Zhao Q., Department of Electrical and Computer Engineering, National University of Singapore, 117576, Singapore","In this paper, we present a novel model for saliency prediction under a unified framework of feature integration. The model distinguishes itself by directly learning from natural images and automatically incorporating higher-level semantic information in a scalable manner for gaze prediction. Unlike most existing saliency models that rely on specific features or object detectors, our model learns multiple stages of features that mimic the hierarchical organization of the ventral stream in the visual cortex and integrate them by adapting their weights based on the ground-truth fixation data. To accomplish this, we utilize a multi-layer sparse network to learn low-, mid- and high-level features from natural images and train a linear support vector machine (SVM) for weight adaption and feature integration. Experimental results show that our model could learn high-level semantic features like faces and texts and can perform competitively among existing approaches in predicting eye fixations. © 2014 Elsevier B.V.","Deep learning; Gaze prediction; Semantic saliency; Sparse coding","Image retrieval; Semantics; Support vector machines; Deep learning; Feature integration; Hierarchical organizations; High-level features; High-level semantic features; Linear Support Vector Machines; Semantic information; Sparse coding; article; eye fixation; eye tracking; learning theory; mathematical model; multilayer sparse network; prediction; priority journal; saliency model; semantics; support vector machine; system analysis; Forecasting","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84899945571"
"Zhou J.; Troyanskaya O.G.","Zhou, Jian (56095313500); Troyanskaya, Olga G (6602361421)","56095313500; 6602361421","Predicting effects of noncoding variants with deep learning-based sequence model","2015","Nature Methods","1264","10.1038/nmeth.3547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958257565&doi=10.1038%2fnmeth.3547&partnerID=40&md5=6dad61d4276320da65d1b85c71a8ca22","Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, United States; Graduate Program in Quantitative and Computational Biology, Princeton University, Princeton, NJ, United States; Department of Computer Science, Princeton University, Princeton, NJ, United States; Simons Center for Data Analysis, Simons Foundation, New York, NY, United States","Zhou J., Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, United States, Graduate Program in Quantitative and Computational Biology, Princeton University, Princeton, NJ, United States; Troyanskaya O.G., Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, United States, Department of Computer Science, Princeton University, Princeton, NJ, United States, Simons Center for Data Analysis, Simons Foundation, New York, NY, United States","Identifying functional effects of noncoding variants is a major challenge in human genetics. To predict the noncoding-variant effects de novo from sequence, we developed a deep learning-based algorithmic framework, DeepSEA (http://deepsea.princeton.edu/), that directly learns a regulatory sequence code from large-scale chromatin-profiling data, enabling prediction of chromatin effects of sequence alterations with single-nucleotide sensitivity. We further used this capability to improve prioritization of functional variants including expression quantitative trait loci (eQTLs) and disease-associated variants. © 2015 Nature America, Inc. All rights reserved.","","Algorithms; Chromatin; Epigenomics; Genome, Human; Hepatocyte Nuclear Factor 3-alpha; Humans; Models, Genetic; Mutation; Polymorphism, Single Nucleotide; Quantitative Trait Loci; Regulatory Sequences, Nucleic Acid; RNA, Untranslated; Support Vector Machine; Transcription Factors; deoxyribonuclease I; histone; transcription factor GATA 1; chromatin; FOXA1 protein, human; hepatocyte nuclear factor 3alpha; transcription factor; untranslated RNA; allelic imbalance; Article; binding site; chromatin; chromatin immunoprecipitation; classifier; comparative study; computer model; controlled study; deep learning based sequence analyzer; DNA sequence; epigenetics; genetic analyzer; genetic association; genetic conservation; genetic model; genetic variability; histone modification; human; mutagenesis; prediction; priority journal; quantitative trait locus; receiver operating characteristic; regulatory sequence; sequence analysis; single nucleotide polymorphism; algorithm; biological model; chromatin; genetics; human genome; metabolism; mutation; quantitative trait locus; regulatory sequence; support vector machine","Nature Publishing Group","15487091","","","26301843","Article","Scopus","2-s2.0-84958257565"
"Li C.; Sanchez R.-V.; Zurita G.; Cerrada M.; Cabrera D.; Vásquez R.E.","Li, Chuan (57218766650); Sanchez, René-Vinicio (56704297100); Zurita, Grover (56704835200); Cerrada, Mariela (7102543304); Cabrera, Diego (56704715800); Vásquez, Rafael E. (16040913400)","57218766650; 56704297100; 56704835200; 7102543304; 56704715800; 16040913400","Multimodal deep support vector classification with homologous features and its application to gearbox fault diagnosis","2015","Neurocomputing","272","10.1016/j.neucom.2015.06.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937818415&doi=10.1016%2fj.neucom.2015.06.008&partnerID=40&md5=3a88f04673c1292bd4f12e6553312179","Research Center of System Health Maintenance, Chongqing Technology and Business University, Chongqing, 400067, China; Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; Department of Mechanical Engineering, Universidad Pontificia Bolivariana, Medellín, Colombia","Li C., Research Center of System Health Maintenance, Chongqing Technology and Business University, Chongqing, 400067, China, Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; Sanchez R.-V., Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; Zurita G., Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; Cerrada M., Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; Cabrera D., Department of Mechanical Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; Vásquez R.E., Department of Mechanical Engineering, Universidad Pontificia Bolivariana, Medellín, Colombia","Gearboxes are crucial transmission components in mechanical systems. Fault diagnosis is an important tool to maintain gearboxes in healthy conditions. It is challenging to recognize fault existences and, if any, failure patterns in such transmission elements due to their complicated configurations. This paper addresses a multimodal deep support vector classification (MDSVC) approach, which employs separation-fusion based deep learning in order to perform fault diagnosis tasks for gearboxes. Considering that different modalities can be made to describe same object, multimodal homologous features of the gearbox vibration measurements are first separated in time, frequency and wavelet modalities, respectively. A Gaussian-Bernoulli deep Boltzmann machine (GDBM) without final output is subsequently suggested to learn pattern representations for features in each modality. A support vector classifier is finally applied to fuse GDBMs in different modalities towards the construction of the MDSVC model. With the present model, ""deep"" representations from ""wide"" modalities improve fault diagnosis capabilities. Fault diagnosis experiments were carried out to evaluate the proposed method on both spur and helical gearboxes. The proposed model achieves the best fault classification rate in experiments when compared to representative deep and shallow learning methods. Results indicate that the proposed separation-fusion based deep learning strategy is effective for the gearbox fault diagnosis. © 2015 Elsevier B.V.","Deep learning; Fault diagnosis; Gearbox; Multimodal homologous feature; Support vector classification","Classification (of information); Computer aided diagnosis; Failure analysis; Gears; Learning systems; Separation; Vectors; Deep boltzmann machines; Deep learning; Gearbox; Multi-modal; Pattern representation; Support vector classification; Support vector classifiers; Transmission components; Article; experimental model; frequency; gaussian bernoulli deep boltzmann machine; gearbox fault diagnosis; information processing; information system; machine learning; measurement; multimodal deep support vector classification; priority journal; support vector machine; time; vibration; wavelet analysis; Fault detection","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84937818415"
"Zhou Y.; Hu Q.; Liu J.; Jia Y.","Zhou, Yucan (56038822700); Hu, Qinghua (7403214664); Liu, Jie (56336428900); Jia, Yuan (35198482900)","56038822700; 7403214664; 56336428900; 35198482900","Combining heterogeneous deep neural networks with conditional random fields for Chinese dialogue act recognition","2015","Neurocomputing","27","10.1016/j.neucom.2015.05.086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937816872&doi=10.1016%2fj.neucom.2015.05.086&partnerID=40&md5=ea3a878b00b5fe63ab43dc3b87b3f1c9","School of Computer Science and Technology, Tianjin University, Tianjin, China; College of Computer and Control Engineering, Nankai University, Tianjin, China; Institute of Linguistics Chinese Academic of Social Sciences, Beijing, China","Zhou Y., School of Computer Science and Technology, Tianjin University, Tianjin, China; Hu Q., School of Computer Science and Technology, Tianjin University, Tianjin, China; Liu J., College of Computer and Control Engineering, Nankai University, Tianjin, China; Jia Y., Institute of Linguistics Chinese Academic of Social Sciences, Beijing, China","Dialogue act (DA) recognition is a fundamental step for computers to understand natural-language dialogues because it can reflect the intention of a speaker. However, it is difficult to adapt traditional machine learning models to the dialogue act recognition task due to the heterogeneous features, statistical dependence between the DA tags, and complex relationship between features and the DA tags. In this paper, we propose a new model which combines heterogeneous deep neural networks with conditional random fields (HDNN-CRF) to solve this problem. The proposed model has two main advantages. First, the heterogeneous deep neural networks (HDNN) model, which is extended from the deep neural networks (DNN), retains the powerful ability of representation learning and adds a new skill of dealing with heterogeneous features effectively. Second, the conditional random fields (CRF) can capture the statistical dependence between the DA tags which carries important information to determine the DA tag of the current utterance. To verify the effectiveness of the proposed model, we conduct several experiments on a Chinese corpus, called CASIA-CASSIL corpus. Ten kinds of features are extracted from the utterances. In the experiment, we give some quantitative analysis of these kinds of features. What's more, when comparing classification accuracies of the proposed model and some other models, the proposed model has achieved the best performance. © 2015 Elsevier B.V.","Conditional random fields; Deep learning; Dialogue act recognition; Heterogeneous features","Deep learning; Deep neural networks; Learning systems; Natural language processing systems; Random processes; Speech recognition; Classification accuracy; Complex relationships; Conditional random field; Dialogue acts; Heterogeneous features; Machine learning models; Natural language dialogue; Statistical dependence; Article; automatic speech recognition; conditional random fields; controlled study; deep neural networks; heterogenous deep neural networks; intermethod comparison; machine learning; mathematical model; measurement accuracy; priority journal; quantitative analysis; support vector machine; Neural networks","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84937816872"
"Mei K.; Peng J.; Gao L.; Zheng N.N.; Fan J.","Mei, Kuizhi (7005780313); Peng, Jinye (9246837000); Gao, Ling (55448906000); Zheng, Naiquan Nigel (26541661300); Fan, Jianping (7402795255)","7005780313; 9246837000; 55448906000; 26541661300; 7402795255","Hierarchical Classification of Large-Scale Patient Records for Automatic Treatment Stratification","2015","IEEE Journal of Biomedical and Health Informatics","7","10.1109/JBHI.2015.2414876","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938399224&doi=10.1109%2fJBHI.2015.2414876&partnerID=40&md5=e9034683cef89fc911c7ae2f5387ae1a","Institute of Artificial Intelligence and Robotics, Xi'An Jiaotong University, Xi'an, 710049, China; School of Information Science and Technology, Northwest University, Xi'an, 710069, China; Center of Biomedical Engineering, University of North Carolina at Charlotte, 28223, NC, United States; Department of Computer Science, University of North Carolina at Charlotte, 28223, NC, United States","Mei K., Institute of Artificial Intelligence and Robotics, Xi'An Jiaotong University, Xi'an, 710049, China; Peng J., School of Information Science and Technology, Northwest University, Xi'an, 710069, China; Gao L., School of Information Science and Technology, Northwest University, Xi'an, 710069, China; Zheng N.N., Center of Biomedical Engineering, University of North Carolina at Charlotte, 28223, NC, United States; Fan J., Department of Computer Science, University of North Carolina at Charlotte, 28223, NC, United States","In this paper, a hierarchical learning algorithm is developed for classifying large-scale patient records, e.g., categorizing large-scale patient records into large numbers of known patient categories (i.e., thousands of known patient categories) for automatic treatment stratification. Our hierarchical learning algorithm can leverage tree structure to train more discriminative max-margin classifiers for high-level nodes and control interlevel error propagation effectively. By ruling out unlikely groups of patient categories (i.e., irrelevant high-level nodes) at an early stage, our hierarchical approach can achieve log-linear computational complexity, which is very attractive for big data applications. Our experiments on one specific medical domain have demonstrated that our hierarchical approach can achieve very competitive results on both classification accuracy and computational efficiency as compared with other state-of-the-art techniques. © 2015 IEEE.","Automatic treatment stratification; category hierarchy; large-scale patient record classification; max-margin tree classifiers; novel category detection","Algorithms; Classification; Stratification; Decision Trees; Electronic Health Records; Humans; Medical Informatics Computing; Support Vector Machine; Classifiers; Computational efficiency; Deep learning; Forestry; Patient treatment; Trees (mathematics); Automatic treatment; category hierarchy; Classification accuracy; Hierarchical classification; Max-margin classifiers; Patient record; State-of-the-art techniques; Tree classifiers; classification; decision tree; electronic medical record; human; medical informatics; support vector machine; Learning algorithms","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","25807574","Article","Scopus","2-s2.0-84938399224"
"Pham A.-D.; Névéol A.; Lavergne T.; Yasunaga D.; Clément O.; Meyer G.; Morello R.; Burgun A.","Pham, Anne-Dominique (57189579042); Névéol, Aurélie (23474844600); Lavergne, Thomas (57215443055); Yasunaga, Daisuke (56323367700); Clément, Olivier (13906006900); Meyer, Guy (55575327700); Morello, Rémy (14066516500); Burgun, Anita (7004335489)","57189579042; 23474844600; 57215443055; 56323367700; 13906006900; 55575327700; 14066516500; 7004335489","Natural language processing of radiology reports for the detection of thromboembolic diseases and clinically relevant incidental findings","2014","BMC Bioinformatics","67","10.1186/1471-2105-15-266","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905971052&doi=10.1186%2f1471-2105-15-266&partnerID=40&md5=7bf6d5ba420a4fc58091b1735131b6d3","Department of Biostatistics and Clinical Research, CHU de Caen, Caen, F-14000, France; Biomedical Informatics and Public Health Department, University Hospital HEGP, AP-HP, Paris, France; LIMSI-CNRS, rue John von Neumann, Orsay, F-91043, France; Department of Radiology, CHU de Caen, Caen, F-14000, France; Radiology department, Assistance Publique-Hoˆpitaux de Paris, Hoˆpital Europe´en Georges-Pompidou, 20, rue Leblanc, Paris, 75015, France; Universite´ Paris-Descartes, INSERM UMR-S970 Paris Cardiovascuar Research center - PARCC, Paris, France; Pneumology department, Assistance Publique- Hoˆpitaux de Paris, Hoˆpital Europe´en Georges-Pompidou, 20, rue Leblanc, Paris, 75015, France; INSERM UMR-S 872 Team 22: Information Sciences to support Personalized Medicine, Universite´ Paris Descartes, Sorbonne Paris Cite´, Faculte´ de Me´decine, Paris, France","Pham A.-D., Department of Biostatistics and Clinical Research, CHU de Caen, Caen, F-14000, France, Biomedical Informatics and Public Health Department, University Hospital HEGP, AP-HP, Paris, France, INSERM UMR-S 872 Team 22: Information Sciences to support Personalized Medicine, Universite´ Paris Descartes, Sorbonne Paris Cite´, Faculte´ de Me´decine, Paris, France; Névéol A., LIMSI-CNRS, rue John von Neumann, Orsay, F-91043, France; Lavergne T., LIMSI-CNRS, rue John von Neumann, Orsay, F-91043, France; Yasunaga D., Department of Radiology, CHU de Caen, Caen, F-14000, France; Clément O., Radiology department, Assistance Publique-Hoˆpitaux de Paris, Hoˆpital Europe´en Georges-Pompidou, 20, rue Leblanc, Paris, 75015, France, Universite´ Paris-Descartes, INSERM UMR-S970 Paris Cardiovascuar Research center - PARCC, Paris, France; Meyer G., Pneumology department, Assistance Publique- Hoˆpitaux de Paris, Hoˆpital Europe´en Georges-Pompidou, 20, rue Leblanc, Paris, 75015, France; Morello R., Department of Biostatistics and Clinical Research, CHU de Caen, Caen, F-14000, France; Burgun A., Biomedical Informatics and Public Health Department, University Hospital HEGP, AP-HP, Paris, France, INSERM UMR-S 872 Team 22: Information Sciences to support Personalized Medicine, Universite´ Paris Descartes, Sorbonne Paris Cite´, Faculte´ de Me´decine, Paris, France","Background: Natural Language Processing (NLP) has been shown effective to analyze the content of radiology reports and identify diagnosis or patient characteristics. We evaluate the combination of NLP and machine learning to detect thromboembolic disease diagnosis and incidental clinically relevant findings from angiography and venography reports written in French. We model thromboembolic diagnosis and incidental findings as a set of concepts, modalities and relations between concepts that can be used as features by a supervised machine learning algorithm. A corpus of 573 radiology reports was de-identified and manually annotated with the support of NLP tools by a physician for relevant concepts, modalities and relations. A machine learning classifier was trained on the dataset interpreted by a physician for diagnosis of deep-vein thrombosis, pulmonary embolism and clinically relevant incidental findings. Decision models accounted for the imbalanced nature of the data and exploited the structure of the reports. Results: The best model achieved an F measure of 0.98 for pulmonary embolism identification, 1.00 for deep vein thrombosis, and 0.80 for incidental clinically relevant findings. The use of concepts, modalities and relations improved performances in all cases. Conclusions: This study demonstrates the benefits of developing an automated method to identify medical concepts, modality and relations from radiology reports in French. An end-to-end automatic system for annotation and classification which could be applied to other radiology reports databases would be valuable for epidemiological surveillance, performance monitoring, and accreditation in French hospitals. © 2014 Pham et al.; licensee BioMed Central Ltd.","Embolism and thrombosis/diagnosis; Human; Incidental findings; Medical informatics; Natural language processing; Phlebography","Algorithms; Computational Biology; Humans; Incidental Findings; Natural Language Processing; Pulmonary Embolism; Radiology; Research Report; Tomography, X-Ray Computed; Angiography; Artificial intelligence; Blood vessels; Classification (of information); Diseases; Learning algorithms; Radiation; Radiology; Supervised learning; Embolism and thrombosis/diagnosis; Human; Incidental findings; Medical informatics; Phlebography; algorithm; article; biology; computer assisted tomography; human; incidental finding; lung embolism; methodology; natural language processing; radiography; radiology; research; Natural language processing systems","BioMed Central Ltd.","14712105","","BBMIC","25099227","Article","Scopus","2-s2.0-84905971052"
"Jia T.; Zhang H.; Bai Y.K.","Jia, T. (15065442400); Zhang, H. (56927920500); Bai, Y.K. (57072194800)","15065442400; 56927920500; 57072194800","Benign and malignant lung nodule classification based on deep learning feature","2015","Journal of Medical Imaging and Health Informatics","21","10.1166/jmihi.2015.1673","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955274573&doi=10.1166%2fjmihi.2015.1673&partnerID=40&md5=91e29ff00e7758b4679e5bc697c08b08","College of Information Science and Engineering, Northeastern University, Shen Yang, 110004, China","Jia T., College of Information Science and Engineering, Northeastern University, Shen Yang, 110004, China; Zhang H., College of Information Science and Engineering, Northeastern University, Shen Yang, 110004, China; Bai Y.K., College of Information Science and Engineering, Northeastern University, Shen Yang, 110004, China","Classifying benign and malignant lung nodules is an important task in the diagnosis of lung cancer. In this study, lung nodules are classified based on deep learning features. A deep learning network structure is built according to the stacked generalization principle and a sparse autoencoder. This structure can simulate the human visual perception principle. The features of a region of interest are extracted from image data to identify the intrinsic characteristic that is most suitable for classification. Experimental findings show that the proposed method can extract features automatically and yield accurate classification results. © 2015 American Scientific Publishers All rights reserved.","CT Image; Deep Learning Feature; Lung Nodule Classification; Sparse Autoencoder","Article; artificial neural network; back propagation; disease classification; human; learning algorithm; lung nodule; support vector machine; vision; visual system","American Scientific Publishers","21567018","","","","Article","Scopus","2-s2.0-84955274573"
"Futoma J.; Morris J.; Lucas J.","Futoma, Joseph (56703705700); Morris, Jonathan (56763171600); Lucas, Joseph (23060693200)","56703705700; 56763171600; 23060693200","A comparison of models for predicting early hospital readmissions","2015","Journal of Biomedical Informatics","205","10.1016/j.jbi.2015.05.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938596257&doi=10.1016%2fj.jbi.2015.05.016&partnerID=40&md5=77a3dd5c7977ef172395db02f4f6bde6","Dept. of Statistical Science, Duke University, Box 90251, Durham, 27708, NC, United States; Quintiles, 4820 Emperor Blvd., Durham, 27703, NC, United States; Dept. of Electrical and Computer Engineering, Duke University, Box 90291, Durham, 27708, NC, United States","Futoma J., Dept. of Statistical Science, Duke University, Box 90251, Durham, 27708, NC, United States; Morris J., Quintiles, 4820 Emperor Blvd., Durham, 27703, NC, United States; Lucas J., Dept. of Statistical Science, Duke University, Box 90251, Durham, 27708, NC, United States, Dept. of Electrical and Computer Engineering, Duke University, Box 90291, Durham, 27708, NC, United States","Risk sharing arrangements between hospitals and payers together with penalties imposed by the Centers for Medicare and Medicaid (CMS) are driving an interest in decreasing early readmissions. There are a number of published risk models predicting 30. day readmissions for particular patient populations, however they often exhibit poor predictive performance and would be unsuitable for use in a clinical setting. In this work we describe and compare several predictive models, some of which have never been applied to this task and which outperform the regression methods that are typically applied in the healthcare literature. In addition, we apply methods from deep learning to the five conditions CMS is using to penalize hospitals, and offer a simple framework for determining which conditions are most cost effective to target. © 2015 The Authors.","Deep learning; Early readmission; Electronic health records; Penalized methods; Predictive models; Random forest","Adult; Algorithms; Area Under Curve; Cost-Benefit Analysis; Diagnosis-Related Groups; Electronic Health Records; Female; Health Services Research; Hospitals; Humans; Likelihood Functions; Male; Middle Aged; Models, Statistical; Neural Networks (Computer); New Zealand; Patient Readmission; Regression Analysis; Risk Assessment; ROC Curve; Software; Cost effectiveness; Decision trees; Deep learning; Health insurance; Hospitals; Learning systems; Random forests; Regression analysis; Risk assessment; Risk management; Comparison of models; Early readmission; Electronic health record; Patient population; Penalized method; Predictive models; Predictive performance; Risk-sharing arrangement; adult; African; algorithm; Article; Asian; Caucasian; cohort analysis; cost effectiveness analysis; female; Hispanic; hospital admission; hospital readmission; human; intermethod comparison; length of stay; logistic regression analysis; major clinical study; male; prediction; priority journal; random forest; statistical model; support vector machine; area under the curve; artificial neural network; comparative study; computer program; cost benefit analysis; diagnosis related group; economics; electronic health record; health services research; hospital; hospital readmission; middle aged; New Zealand; procedures; receiver operating characteristic; regression analysis; risk assessment; statistical model; statistics and numerical data; Predictive analytics","Academic Press Inc.","15320464","","JBIOB","26044081","Article","Scopus","2-s2.0-84938596257"
"Skwark M.J.; Raimondi D.; Michel M.; Elofsson A.","Skwark, Marcin J. (25824446200); Raimondi, Daniele (56429472300); Michel, Mirco (56355420200); Elofsson, Arne (7003471235)","25824446200; 56429472300; 56355420200; 7003471235","Improved Contact Predictions Using the Recognition of Protein Like Contact Patterns","2014","PLoS Computational Biology","123","10.1371/journal.pcbi.1003889","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912100015&doi=10.1371%2fjournal.pcbi.1003889&partnerID=40&md5=db7d9f04788b14520ea9600290f6359b","Department of Biochemistry and Biophysics, Stockholm University, Stockholm, Sweden; Science for Life Laboratory, Stockholm University, Solna, Sweden; Department of Information and Computer Science, Aalto University, Aalto, Finland; Interuniversity Institute of Bioinformatics in Brussels, ULB-VUB, La Plaine Campus, Triomflaan, Brussels, Belgium","Skwark M.J., Department of Biochemistry and Biophysics, Stockholm University, Stockholm, Sweden, Science for Life Laboratory, Stockholm University, Solna, Sweden, Department of Information and Computer Science, Aalto University, Aalto, Finland; Raimondi D., Department of Biochemistry and Biophysics, Stockholm University, Stockholm, Sweden, Science for Life Laboratory, Stockholm University, Solna, Sweden, Interuniversity Institute of Bioinformatics in Brussels, ULB-VUB, La Plaine Campus, Triomflaan, Brussels, Belgium; Michel M., Department of Biochemistry and Biophysics, Stockholm University, Stockholm, Sweden, Science for Life Laboratory, Stockholm University, Solna, Sweden; Elofsson A., Department of Biochemistry and Biophysics, Stockholm University, Stockholm, Sweden, Science for Life Laboratory, Stockholm University, Solna, Sweden","Given sufficient large protein families, and using a global statistical inference approach, it is possible to obtain sufficient accuracy in protein residue contact predictions to predict the structure of many proteins. However, these approaches do not consider the fact that the contacts in a protein are neither randomly, nor independently distributed, but actually follow precise rules governed by the structure of the protein and thus are interdependent. Here, we present PconsC2, a novel method that uses a deep learning approach to identify protein-like contact patterns to improve contact predictions. A substantial enhancement can be seen for all contacts independently on the number of aligned sequences, residue separation or secondary structure type, but is largest for β-sheet containing proteins. In addition to being superior to earlier methods based on statistical inferences, in comparison to state of the art methods using machine learning, PconsC2 is superior for families with more than 100 effective sequence homologs. The improved contact prediction enables improved structure prediction. © 2014 Skwark et al.","","Artificial Intelligence; Computational Biology; Databases, Protein; Pattern Recognition, Automated; Protein Conformation; Protein Structure, Secondary; Proteins; Sequence Analysis, Protein; Deep learning; Forecasting; Statistical methods; protein; Contact pattern; Learning approach; Novel methods; Protein family; Protein residues; Secondary structures; Separation structures; State-of-the-art methods; Statistical inference; Structure type; Article; beta sheet; machine learning; molecular recognition; predictive value; protein analysis; protein contact mapping; protein family; protein secondary structure; receiver operating characteristic; sequence alignment; sequence analysis; sequence homology; structure analysis; artificial intelligence; automated pattern recognition; biology; chemistry; procedures; protein conformation; protein database; Proteins","Public Library of Science","1553734X","","","25375897","Article","Scopus","2-s2.0-84912100015"
"Narang P.; Hota C.; Venkatakrishnan V.N.","Narang, Pratik (55936525200); Hota, Chittaranjan (22333968700); Venkatakrishnan, V.N. (55904193500)","55936525200; 22333968700; 55904193500","PeerShark: flow-clustering and conversation-generation for malicious peer-to-peer traffic identification","2014","Tijdschrift voor Urologie","10","10.1186/s13635-014-0015-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919333394&doi=10.1186%2fs13635-014-0015-3&partnerID=40&md5=20dafd0a0908d7b2998bfd5dee490baf","BITS-Pilani, Hyderabad Campus, Hyderabad, 500078, Telangana, India; University of Illinois at Chicago, Chicago, 60607, IL, United States","Narang P., BITS-Pilani, Hyderabad Campus, Hyderabad, 500078, Telangana, India; Hota C., BITS-Pilani, Hyderabad Campus, Hyderabad, 500078, Telangana, India; Venkatakrishnan V.N., University of Illinois at Chicago, Chicago, 60607, IL, United States","The distributed and decentralized nature of peer-to-peer (P2P) networks has offered a lucrative alternative to bot-masters to build botnets. P2P botnets are not prone to any single point of failure and have been proven to be highly resilient against takedown attempts. Moreover, smarter bots are stealthy in their communication patterns and elude the standard discovery techniques which look for anomalous network or communication behavior. In this paper, we present a methodology to detect P2P botnet traffic and differentiate it from benign P2P traffic in a network. Our approach neither assumes the availability of any ‘seed’ information of bots nor relies on deep packet inspection. It aims to detect the stealthy behavior of P2P botnets. That is, we aim to detect P2P botnets when they lie dormant (to evade detection by intrusion detection systems) or while they perform malicious activities (spamming, password stealing, etc.) in a manner which is not observable to a network administrator.; Our approach PeerShark combines the benefits of flow-based and conversation-based approaches with a two-tier architecture, and addresses the limitations of these approaches. By extracting statistical features from the network traces of P2P applications and botnets, we build supervised machine learning models which can accurately differentiate between benign P2P applications and P2P botnets. PeerShark could also detect unknown P2P botnet traffic with high accuracy. © 2014, Narang et al.; licensee Springer.","Botnets; Machine learning; Peer-to-peer; Security","","Bohn Stafleu van Loghum","22113037","","","","Article","Scopus","2-s2.0-84919333394"
"Yu W.; Zhuang F.; He Q.; Shi Z.","Yu, Wenchao (57188803893); Zhuang, Fuzhen (23391452500); He, Qing (26643590900); Shi, Zhongzhi (55801581400)","57188803893; 23391452500; 26643590900; 55801581400","Learning deep representations via extreme learning machines","2015","Neurocomputing","99","10.1016/j.neucom.2014.03.077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961291828&doi=10.1016%2fj.neucom.2014.03.077&partnerID=40&md5=594602d3111d3a53b0fb3276275c0831","The Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; University of Chinese Academy of Sciences, Beijing, 100049, China","Yu W., The Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China, University of Chinese Academy of Sciences, Beijing, 100049, China; Zhuang F., The Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China, University of Chinese Academy of Sciences, Beijing, 100049, China; He Q., The Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Shi Z., The Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China","Extreme learning machine (ELM) as an emerging technology has achieved exceptional performance in large-scale settings, and is well suited to binary and multi-class classification, as well as regression tasks. However, existing ELM and its variants predominantly employ single hidden layer feedforward networks, leaving the popular and potentially powerful stacked generalization principle unexploited for seeking predictive deep representations of input data. Deep architectures can find higher-level representations, thus can potentially capture relevant higher-level abstractions. But most of current deep learning methods require solving a difficult and non-convex optimization problem. In this paper, we propose a stacked model, DrELM, to learn deep representations via extreme learning machine according to stacked generalization philosophy. The proposed model utilizes ELM as a base building block and incorporates random shift and kernelization as stacking elements. Specifically, in each layer, DrELM integrates a random projection of the predictions obtained by ELM into the original feature, and then applies kernel functions to generate the resultant feature. To verify the classification and regression performance of DrELM, we conduct the experiments on both synthetic and real-world data sets. The experimental results show that DrELM outperforms ELM and kernel ELMs, which appear to demonstrate that DrELM could yield predictive features that are suitable for prediction tasks. The performances of the deep models (i.e. Stacked Auto-encoder) are comparable. However, due to the utilization of ELM, DrELM is easier to learn and faster in testing. © 2014 Elsevier B.V.","Deep learning; DrELM; Extreme learning machine; Representation learning; Stacked ELMs; Stacked generalization","Classification (of information); Convex optimization; Knowledge acquisition; Network layers; DrELM; Extreme learning machine; Representation learning; Stacked ELMs; Stacked generalization; algorithm; Article; classifier; controlled study; Deep Belief Networks; deep representations learning via extreme learning machine; information processing; kernel based extreme learning machine; layer by layer learning algorithm; linear extreme learning machine; linear kernel; machine learning; Optimally Pruned Extreme Learning Machine; prediction; Stacked Auto encoder; statistical analysis; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84961291828"
"Yan Y.; Yin X.-C.; Li S.; Yang M.; Hao H.-W.","Yan, Yan (56585076900); Yin, Xu-Cheng (35319162100); Li, Sujian (53984734300); Yang, Mingyuan (56585047700); Hao, Hong-Wei (9737376400)","56585076900; 35319162100; 53984734300; 56585047700; 9737376400","Learning document semantic representation with hybrid deep belief network","2015","Computational Intelligence and Neuroscience","18","10.1155/2015/650527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926622323&doi=10.1155%2f2015%2f650527&partnerID=40&md5=2e12ef893f43fbce7be6adadfd02df2f","Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China; Key Laboratory of Computational Linguistics, Peking University, Ministry of Education, Beijing, 100871, China; Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China","Yan Y., Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China; Yin X.-C., Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China; Li S., Key Laboratory of Computational Linguistics, Peking University, Ministry of Education, Beijing, 100871, China; Yang M., Department of Computer Science and Technology, School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, 100083, China; Hao H.-W., Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China","High-level abstraction, for example, semantic representation, is vital for document classification and retrieval. However, how to learn document semantic representation is still a topic open for discussion in information retrieval and natural language processing. In this paper, we propose a new Hybrid Deep Belief Network (HDBN) which uses Deep Boltzmann Machine (DBM) on the lower layers together with Deep Belief Network (DBN) on the upper layers. The advantage of DBM is that it employs undirected connection when training weight parameters which can be used to sample the states of nodes on each layer more successfully and it is also an effective way to remove noise from the different document representation type; the DBN can enhance extract abstract of the document in depth, making the model learn sufficient semantic representation. At the same time, we explore different input strategies for semantic distributed representation. Experimental results show that our model using the word embedding instead of single word has better performance. © 2015 Yan Yan et al.","","Algorithms; Information Storage and Retrieval; Models, Statistical; Natural Language Processing; Neural Networks (Computer); Semantics; Information retrieval; Information retrieval systems; Natural language processing systems; Deep belief network (DBN); Deep boltzmann machines; Distributed representation; Document Classification; Document Representation; High-level abstraction; NAtural language processing; Semantic representation; algorithm; artificial neural network; information retrieval; natural language processing; semantics; statistical model; Semantics","Hindawi Publishing Corporation","16875265","","","25878657","Article","Scopus","2-s2.0-84926622323"
"Rogers T.T.; Mcclelland J.L.","Rogers, Timothy T. (57202698345); Mcclelland, James L. (57198096249)","57202698345; 57198096249","Parallel distributed processing at 25: Further explorations in the microstructure of cognition","2014","Cognitive Science","76","10.1111/cogs.12148","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906262947&doi=10.1111%2fcogs.12148&partnerID=40&md5=01cd978a0944b8d04a06118a15e75891","Department of Psychology, University of Wisconsin-Madison, United States; Department of Psychology, Stanford University, United States","Rogers T.T., Department of Psychology, University of Wisconsin-Madison, United States; Mcclelland J.L., Department of Psychology, Stanford University, United States","This paper introduces a special issue of Cognitive Science initiated on the 25th anniversary of the publication of Parallel Distributed Processing (PDP), a two-volume work that introduced the use of neural network models as vehicles for understanding cognition. The collection surveys the core commitments of the PDP framework, the key issues the framework has addressed, and the debates the framework has spawned, and presents viewpoints on the current status of these issues. The articles focus on both historical roots and contemporary developments in learning, optimality theory, perception, memory, language, conceptual knowledge, cognitive control, and consciousness. Here we consider the approach more generally, reviewing the original motivations, the resulting framework, and the central tenets of the underlying theory. We then evaluate the impact of PDP both on the field at large and within specific subdomains of cognitive science and consider the current role of PDP models within the broader landscape of contemporary theoretical frameworks in cognitive science. Looking to the future, we consider the implications for cognitive science of the recent success of machine learning systems called ""deep networks""-systems that build on key ideas presented in the PDP volumes. © 2014 Cognitive Science Society, Inc.","Cognition; Cognitive control; Connectionist models; Language; Learning; Memory; Neural networks; Perception","Cognition; Cognitive Science; Consciousness; Humans; Language; Models, Neurological; Neural Networks (Computer); artificial neural network; biological model; cognition; consciousness; human; language; psychology","Wiley-Blackwell Publishing","03640213","","COGSD","25087578","Article","Scopus","2-s2.0-84906262947"
"Berglund M.; Raiko T.; Cho K.","Berglund, Mathias (56024686700); Raiko, Tapani (14032013000); Cho, Kyunghyun (55722769200)","56024686700; 14032013000; 55722769200","Measuring the usefulness of hidden units in Boltzmann machines with mutual information","2015","Neural Networks","15","10.1016/j.neunet.2014.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922376529&doi=10.1016%2fj.neunet.2014.09.004&partnerID=40&md5=a5dad5b1872cc42c74e94873e651127b","Department of Information and Computer Science, Aalto University School of Science, Finland","Berglund M., Department of Information and Computer Science, Aalto University School of Science, Finland; Raiko T., Department of Information and Computer Science, Aalto University School of Science, Finland; Cho K., Department of Information and Computer Science, Aalto University School of Science, Finland","Restricted Boltzmann machines (RBMs) and deep Boltzmann machines (DBMs) are important models in deep learning, but it is often difficult to measure their performance in general, or measure the importance of individual hidden units in specific. We propose to use mutual information to measure the usefulness of individual hidden units in Boltzmann machines. The measure is fast to compute, and serves as an upper bound for the information the neuron can pass on, enabling detection of a particular kind of poor training results. We confirm experimentally that the proposed measure indicates how much the performance of the model drops when some of the units of an RBM are pruned away. We demonstrate the usefulness of the measure for early detection of poor training in DBMs. © 2014 Elsevier Ltd.","Deep Boltzmann machine; Deep learning; Mutual information; Pruning; Restricted Boltzmann machine; Structural learning","Algorithms; Neural Networks (Computer); Cognitive systems; Deep boltzmann machines; Deep learning; Mutual informations; Pruning; Restricted boltzmann machine; Structural learning; Article; artificial neural network; deep Boltzmann machine; entropy; learning algorithm; machine learning; mathematical computing; restricted Boltzmann machine; variance; algorithm; artificial neural network; Artificial intelligence","Elsevier Ltd","08936080","","NNETE","25318376","Article","Scopus","2-s2.0-84922376529"
"Carrio A.; Sampedro C.; Sanchez-Lopez J.L.; Pimienta M.; Campoy P.","Carrio, Adrian (56286386100); Sampedro, Carlos (56285183900); Sanchez-Lopez, Jose Luis (55617310700); Pimienta, Miguel (57015340400); Campoy, Pascual (23007441000)","56286386100; 56285183900; 55617310700; 57015340400; 23007441000","Automated low-cost smartphone-based lateral flow saliva test reader for drugs-of-abuse detection","2015","Sensors (Switzerland)","98","10.3390/s151129569","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951166689&doi=10.3390%2fs151129569&partnerID=40&md5=535353ec7b68a1ce5e79940c3d7fed17","Computer Vision Group, Centre for Automation and Robotics (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, 28006, Spain; Aplitest Health Solutions, Paseo de la Castellana 164, Madrid, 28046, Spain","Carrio A., Computer Vision Group, Centre for Automation and Robotics (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, 28006, Spain; Sampedro C., Computer Vision Group, Centre for Automation and Robotics (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, 28006, Spain; Sanchez-Lopez J.L., Computer Vision Group, Centre for Automation and Robotics (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, 28006, Spain; Pimienta M., Aplitest Health Solutions, Paseo de la Castellana 164, Madrid, 28046, Spain; Campoy P., Computer Vision Group, Centre for Automation and Robotics (UPM-CSIC), Calle José Gutiérrez Abascal 2, Madrid, 28006, Spain","Lateral flow assay tests are nowadays becoming powerful, low-cost diagnostic tools. Obtaining a result is usually subject to visual interpretation of colored areas on the test by a human operator, introducing subjectivity and the possibility of errors in the extraction of the results. While automated test readers providing a result-consistent solution are widely available, they usually lack portability. In this paper, we present a smartphone-based automated reader for drug-of-abuse lateral flow assay tests, consisting of an inexpensive light box and a smartphone device. Test images captured with the smartphone camera are processed in the device using computer vision and machine learning techniques to perform automatic extraction of the results. A deep validation of the system has been carried out showing the high accuracy of the system. The proposed approach, applicable to any line-based or color-based lateral flow test in the market, effectively reduces the manufacturing costs of the reader and makes it portable and massively available while providing accurate, reliable results. © 2015 by the authors; licensee MDPI, Basel, Switzerland.","Computer vision; Diagnostics; Drugs-of-abuse; Machine learning; Neural networks; Smartphone","Colorimetry; Equipment Design; Humans; Image Processing, Computer-Assisted; Neural Networks (Computer); Saliva; Smartphone; Street Drugs; Substance Abuse Detection; Artificial intelligence; Automation; Computer vision; Costs; Extraction; Learning systems; Light sources; Neural networks; Plasma diagnostics; Signal encoding; street drug; Automatic extraction; Drugs of abuse; Lateral flow assay; Lateral flow test; Machine learning techniques; Manufacturing cost; Smart-phone cameras; Visual interpretation; artificial neural network; chemistry; colorimetry; equipment design; human; image processing; procedures; saliva; smartphone; substance abuse; Smartphones","MDPI AG","14248220","","","26610513","Article","Scopus","2-s2.0-84951166689"
"Spencer M.; Eickholt J.; Cheng J.","Spencer, Matt (57188698510); Eickholt, Jesse (35069298500); Cheng, Jianlin (57203108630)","57188698510; 35069298500; 57203108630","A deep learning network approach to","2015","IEEE/ACM Transactions on Computational Biology and Bioinformatics","255","10.1109/TCBB.2014.2343960","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923265167&doi=10.1109%2fTCBB.2014.2343960&partnerID=40&md5=6ce9a6c33d22a7c187c0dcc09d2f3000","Informatics Institute, University of Missouri, Columbia, 65211, MO, United States; Department of Computer Science, Central Michigan University, Mount Pleasant, 48859, MI, United States; Department of Computer Science, University of Missouri, Columbia, 65211, MO, United States","Spencer M., Informatics Institute, University of Missouri, Columbia, 65211, MO, United States; Eickholt J., Department of Computer Science, Central Michigan University, Mount Pleasant, 48859, MI, United States; Cheng J., Department of Computer Science, University of Missouri, Columbia, 65211, MO, United States","Ab initio protein secondary structure (SS) predictions are utilized to generate tertiary structure predictions, which are increasingly demanded due to the rapid discovery of proteins. Although recent developments have slightly exceeded previous methods of SS prediction, accuracy has stagnated around 80 percent and many wonder if prediction cannot be advanced beyond this ceiling. Disciplines that have traditionally employed neural networks are experimenting with novel deep learning techniques in attempts to stimulate progress. Since neural networks have historically played an important role in SS prediction, we wanted to determine whether deep learning could contribute to the advancement of this field as well. We developed an SS predictor that makes use of the position-specific scoring matrix generated by PSI-BLAST and deep learning network architectures, which we call DNSS. Graphical processing units and CUDA software optimize the deep network architecture and efficiently train the deep networks. Optimal parameters for the training process were determined, and a workflow comprising three separately trained deep networks was constructed in order to make refined predictions. This deep learning network approach was used to predict SS for a fully independent test dataset of 198 proteins, achieving a Q3 accuracy of 80.7 percent and a Sov accuracy of 74.2 percent. © 2004-2012 IEEE.","deep learning; Machine learning; neural nets; protein structure prediction","Databases, Protein; Machine Learning; Neural Networks (Computer); Protein Structure, Secondary; Proteins; Artificial intelligence; Forecasting; Learning systems; Neural networks; Proteins; Statistical tests; protein; Deep learning; Graphical processing unit (GPUs); Optimal parameter; Position specific scoring matrix; Protein secondary structure; Protein structure prediction; Tertiary structures; Training process; artificial neural network; chemistry; machine learning; protein database; protein secondary structure; Network architecture","Institute of Electrical and Electronics Engineers Inc.","15455963","","","25750595","Article","Scopus","2-s2.0-84923265167"
"Grahn P.J.; Mallory G.W.; Khurram O.U.; Berry B.M.; Hachmann J.T.; Bieber A.J.; Bennet K.E.; Min H.-K.; Chang S.-Y.; Lee K.H.; Lujan J.L.","Grahn, Peter J. (55995182200); Mallory, Grant W. (55216375800); Khurram, Obaid U. (56296686700); Berry, B. Michael (56298366100); Hachmann, Jan T. (55995332900); Bieber, Allan J. (7004948173); Bennet, Kevin E. (9041652500); Min, Hoon-Ki (24464118400); Chang, Su-Youne (35765091400); Lee, Kendall H. (8076565200); Lujan, J.L. (24830859800)","55995182200; 55216375800; 56296686700; 56298366100; 55995332900; 7004948173; 9041652500; 24464118400; 35765091400; 8076565200; 24830859800","A neurochemical closed-loop controller for deep brain stimulation: Toward individualized smart neuromodulation therapies","2014","Frontiers in Neuroscience","109","10.3389/fnins.2014.00169","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905053624&doi=10.3389%2ffnins.2014.00169&partnerID=40&md5=50b1e5c1a6a54e5eb13fa7f70a0fce63","Mayo Clinic College of Medicine, Mayo Clinic, Rochester, MN, United States; Department of Neurologic Surgery, Mayo Clinic, Rochester, MN, United States; Department of Neurology, Mayo Clinic, Rochester, MN, United States; Division of Engineering, Mayo Clinic, Rochester, MN, United States; Department of Physiology and Biomedical Engineering, Mayo Clinic, Rochester, MN, United States","Grahn P.J., Mayo Clinic College of Medicine, Mayo Clinic, Rochester, MN, United States; Mallory G.W., Department of Neurologic Surgery, Mayo Clinic, Rochester, MN, United States; Khurram O.U., Mayo Clinic College of Medicine, Mayo Clinic, Rochester, MN, United States; Berry B.M., Mayo Clinic College of Medicine, Mayo Clinic, Rochester, MN, United States; Hachmann J.T., Department of Neurologic Surgery, Mayo Clinic, Rochester, MN, United States; Bieber A.J., Department of Neurologic Surgery, Mayo Clinic, Rochester, MN, United States, Department of Neurology, Mayo Clinic, Rochester, MN, United States; Bennet K.E., Department of Neurologic Surgery, Mayo Clinic, Rochester, MN, United States, Division of Engineering, Mayo Clinic, Rochester, MN, United States; Min H.-K., Department of Neurologic Surgery, Mayo Clinic, Rochester, MN, United States, Department of Physiology and Biomedical Engineering, Mayo Clinic, Rochester, MN, United States; Chang S.-Y., Department of Neurologic Surgery, Mayo Clinic, Rochester, MN, United States; Lee K.H., Department of Neurologic Surgery, Mayo Clinic, Rochester, MN, United States, Department of Physiology and Biomedical Engineering, Mayo Clinic, Rochester, MN, United States; Lujan J.L., Department of Neurologic Surgery, Mayo Clinic, Rochester, MN, United States, Department of Physiology and Biomedical Engineering, Mayo Clinic, Rochester, MN, United States","Current strategies for optimizing deep brain stimulation (DBS) therapy involve multiple postoperative visits. During each visit, stimulation parameters are adjusted until desired therapeutic effects are achieved and adverse effects are minimized. However, the efficacy of these therapeutic parameters may decline with time due at least in part to disease progression, interactions between the host environment and the electrode, and lead migration. As such, development of closed-loop control systems that can respond to changing neurochemical environments, tailoring DBS therapy to individual patients, is paramount for improving the therapeutic efficacy of DBS. Evidence obtained using electrophysiology and imaging techniques in both animals and humans suggests that DBS works by modulating neural network activity. Recently, animal studies have shown that stimulation-evoked changes in neurotransmitter release that mirror normal physiology are associated with the therapeutic benefits of DBS. Therefore, to fully understand the neurophysiology of DBS and optimize its efficacy, it may be necessary to look beyond conventional electrophysiological analyses and characterize the neurochemical effects of therapeutic and non-therapeutic stimulation. By combining electrochemical monitoring and mathematical modeling techniques, we can potentially replace the trial-and-error process used in clinical programming with deterministic approaches that help attain optimal and stable neurochemical profiles. In this manuscript, we summarize the current understanding of electrophysiological and electrochemical processing for control of neuromodulation therapies. Additionally, we describe a proof-of-principle closed-loop controller that characterizes DBS-evoked dopamine changes to adjust stimulation parameters in a rodent model of DBS. The work described herein represents the initial steps toward achieving a ""smart"" neuroprosthetic system for treatment of neurologic and psychiatric disorders. © 2014 Grahn, Mallory, Khurram, Berry, Hachmann, Bieber, Bennet, Min, Chang, Lee and Lujan.","Deep brain stimulation (DBS); Fast scan cyclic voltammetry (FSCV); Feedback control systems; Individualized medicine; Local field potentials (LFP); Machine learning","dopamine; action potential; amperometry; article; brain depth recording; brain depth stimulation; brain electrophysiology; control system; dopamine release; electric activity; electric potential; electrochemical analysis; electrochemistry; electroencephalogram; electrophysiological procedures; electrostimulation; evoked response; feedback system; global field potential; human; local field potential; mathematical model; mental disease; microdialysis; molecular dynamics; nerve cell network; nervous system parameters; neurochemical closed loop controller; neurochemistry; neuromodulation; neuromonitoring; neurotransmitter release; nonhuman; personalized medicine; single unit activity; therapy effect; treatment response","Frontiers Research Foundation","16624548","","","","Article","Scopus","2-s2.0-84905053624"
"Berniker M.; Kording K.P.","Berniker, Max (24279474500); Kording, Konrad P. (6603812799)","24279474500; 6603812799","Deep networks for motor control functions","2015","Frontiers in Computational Neuroscience","21","10.3389/fncom.2015.00032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927606447&doi=10.3389%2ffncom.2015.00032&partnerID=40&md5=64f9efe7b58f1530e8b85dc8764e5d7f","Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, Chicago, IL, United States; Department of Physical Medicine and Rehabilitation, Northwestern University, Chicago, IL, United States","Berniker M., Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, Chicago, IL, United States, Department of Physical Medicine and Rehabilitation, Northwestern University, Chicago, IL, United States; Kording K.P., Department of Physical Medicine and Rehabilitation, Northwestern University, Chicago, IL, United States","The motor system generates time-varying commands to move our limbs and body. Conventional descriptions of motor control and learning rely on dynamical representations of our body’s state (forward and inverse models), and control policies that must be integrated forward to generate feedforward time-varying commands; thus these are representations across space, but not time. Here we examine a new approach that directly represents both time-varying commands and the resulting state trajectories with a function; a representation across space and time. Since the output of this function includes time, it necessarily requires more parameters than a typical dynamical model. To avoid the problems of local minima these extra parameters introduce, we exploit recent advances in machine learning to build our function using a stacked autoencoder, or deep network. With initial and target states as inputs, this deep network can be trained to output an accurate temporal profile of the optimal command and state trajectory for a point-to-point reach of a non-linear limb model, even when influenced by varying force fields. In a manner that mirrors motor babble, the network can also teach itself to learn through trial and error. Lastly, we demonstrate how this network can learn to optimize a cost objective. This functional approach to motor control is a sharp departure from the standard dynamical approach, and may offer new insights into the neural implementation of motor control. © 2015 Berniker and Kording.","Arm reaches; Deep learning; Motor control; Motor learning; Neural networks; Optimal control","Artificial intelligence; Neural networks; Arm reaches; Deep learning; Motor control; Motor learning; Optimal controls; Article; artificial neural network; calculation; learning algorithm; mathematical computing; mathematical model; measurement accuracy; motor control; nonlinear system; principal component analysis; process optimization; simulation; Learning systems","Frontiers Media S.A.","16625188","","","","Article","Scopus","2-s2.0-84927606447"
"Kuremoto T.; Kimura S.; Kobayashi K.; Obayashi M.","Kuremoto, Takashi (56036797900); Kimura, Shinsuke (55336598000); Kobayashi, Kunikazu (8915891600); Obayashi, Masanao (56036808200)","56036797900; 55336598000; 8915891600; 56036808200","Time series forecasting using a deep belief network with restricted Boltzmann machines","2014","Neurocomputing","471","10.1016/j.neucom.2013.03.047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899568094&doi=10.1016%2fj.neucom.2013.03.047&partnerID=40&md5=354ac68ae775a15a8eae3a29d8575388","Graduate School of Science and Engineering, Yamaguchi University, Tokiwadai 2-16-1, Ube, Yamaguchi 755-8611, Japan; School of Information Science and Technology, Aichi Prefectural University, Nagakute, Aichi 480-1198, Ibaragabasama 1522-3, Japan","Kuremoto T., Graduate School of Science and Engineering, Yamaguchi University, Tokiwadai 2-16-1, Ube, Yamaguchi 755-8611, Japan; Kimura S., Graduate School of Science and Engineering, Yamaguchi University, Tokiwadai 2-16-1, Ube, Yamaguchi 755-8611, Japan; Kobayashi K., School of Information Science and Technology, Aichi Prefectural University, Nagakute, Aichi 480-1198, Ibaragabasama 1522-3, Japan; Obayashi M., Graduate School of Science and Engineering, Yamaguchi University, Tokiwadai 2-16-1, Ube, Yamaguchi 755-8611, Japan","Multi-layer perceptron (MLP) and other artificial neural networks (ANNs) have been widely applied to time series forecasting since 1980s. However, for some problems such as initialization and local optima existing in applications, the improvement of ANNs is, and still will be the most interesting study for not only time series forecasting but also other intelligent computing fields. In this study, we propose a method for time series prediction using Hinton and Salakhutdinov's deep belief nets (DBN) which are probabilistic generative neural network composed by multiple layers of restricted Boltzmann machine (RBM). We use a 3-layer deep network of RBMs to capture the feature of input space of time series data, and after pretraining of RBMs using their energy functions, gradient descent training, i.e., back-propagation learning algorithm is used for fine-tuning connection weights between ""visible layers"" and ""hidden layers"" of RBMs. To decide the sizes of neural networks and the learning rates, Kennedy and Eberhart's particle swarm optimization (PSO) is adopted during the training processes. Furthermore, ""trend removal"", a preprocessing to the original data, is also approached in the forecasting experiment using CATS benchmark data. Additionally, approximating and short-term prediction of chaotic time series such as Lorenz chaos and logistic map were also applied by the proposed method. © 2013 Elsevier B.V.","CATS benchmark; Chaos; Deep belief nets; Multi-layer perceptron; Restricted Boltzmann machine; Time series forecasting","Chaos theory; Intelligent computing; Network layers; Neural networks; Particle swarm optimization (PSO); Time series; CATS benchmark; Deep belief nets; Multi layer perceptron; Restricted boltzmann machine; Time series forecasting; Forecasting","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84899568094"
"Li F.; Wang J.; Tang B.; Tian D.","Li, Feng (57195052887); Wang, Jiaxu (8674388800); Tang, Baoping (7402560248); Tian, Daqing (7101795885)","57195052887; 8674388800; 7402560248; 7101795885","Life grade recognition method based on supervised uncorrelated orthogonal locality preserving projection and K-nearest neighbor classifier","2014","Neurocomputing","40","10.1016/j.neucom.2014.01.037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899736273&doi=10.1016%2fj.neucom.2014.01.037&partnerID=40&md5=1c94f2e68499da54be088e63404ced53","School of Manufacturing Science and Engineering, Sichuan University, Chengdu 610065, China; School of Aeronautics and Astronautics, Sichuan University, Chengdu 610065, China; State Key Laboratory of Mechanical Transmission, Chongqing University, Chongqing 400030, China","Li F., School of Manufacturing Science and Engineering, Sichuan University, Chengdu 610065, China; Wang J., School of Aeronautics and Astronautics, Sichuan University, Chengdu 610065, China; Tang B., State Key Laboratory of Mechanical Transmission, Chongqing University, Chongqing 400030, China; Tian D., School of Manufacturing Science and Engineering, Sichuan University, Chengdu 610065, China","A novel life grade recognition method based on Supervised Uncorrelated Orthogonal Locality Preserving Projection (SUOLPP) and K-nearest neighbor classifier (KNNC) is proposed in this paper. A time-frequency domain feature set is first constructed to completely extract the feature of different life grades, then SUOLPP is proposed to automatically compress the high-dimensional time-frequency domain feature sets of training and test samples into the low-dimensional eigenvectors with better discrimination, and finally the low-dimensional eigenvectors of training and test samples are input into KNNC to conduct life grade recognition. SUOLPP algorithm considers both local information and label information in designing the similarity matrix, and requires the output basis vectors to be statistically uncorrelated and orthogonal in order to improve the life grade feature extraction power of OLPP. KNNC ranks the test samples' neighbors among the training samples and uses the class labels of similarity neighbors to classify the unknown input test samples, so that it has such advantages as less calculation amount, finer timeliness and higher pattern recognition accuracy compared with support vector machine (SVM) and Fuzzy C-Means Clustering (FCM). The life grade recognition example on deep groove ball bearings demonstrated the effectivity of the proposed life grade recognition method. © 2014 Elsevier B.V.","Feature compression; K-nearest neighbor classifier (KNNC); Life grade recognition; Rotating machine; Supervised uncorrelated orthogonal locality preserving projection (SUOLPP); Time-frequency domain feature set","Eigenvalues and eigenfunctions; Feature extraction; Frequency domain analysis; Support vector machines; Feature compression; K-nearest neighbor classifier; Life grade recognition; Locality preserving projections; Rotating machine; Time frequency domain; article; calculation; classification algorithm; cluster analysis; controlled study; Fuzzy C Means Clustering; k nearest neighbor classifier; life grade recognition method; machine learning; mathematical computing; mathematical model; measurement accuracy; priority journal; supervised uncorrelated orthogonal locality preserving projection; support vector machine; Learning algorithms","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84899736273"
"Kumar P.R.; Priya M.","Kumar, Paulraj Ranjith (53866599000); Priya, Mohan (57213052437)","53866599000; 57213052437","Classification of atherosclerotic and non-atherosclerotic individuals using multiclass state vector machine","2014","Technology and Health Care","6","10.3233/THC-140835","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907676690&doi=10.3233%2fTHC-140835&partnerID=40&md5=c34a3edc7c83817cec4cca87bb6839d3","Department of Electronics and Communication, PSR Engineering College, Sivakasi, 626140, India","Kumar P.R., Department of Electronics and Communication, PSR Engineering College, Sivakasi, 626140, India; Priya M., Department of Electronics and Communication, PSR Engineering College, Sivakasi, 626140, India","OBJECTIVE: To build an effective model which assorts the individuals, whether they belong to the normal group, risk group and pathologic group regarding atherosclerosis in real time by doing necessary preprocessing techniques and to compare the performance with other state-of-the-art machine learning techniques.; BACKGROUND: Coronary artery disease due to atherosclerosis is an epidemic in India. An estimated 1.3 million Indians died from this in 2000. The projected death from coronary artery disease by 2016 is 2.98 million.; METHODS: In this work we have employed STULONG dataset. We have made a deep case study in selecting the attributes which contributes for higher accuracy in predicting the target. The selected attributes includes missing values. Initially our work includes imputation of missing values using Iterative Principal Component Analysis (IPCA). The second step includes selecting best features using Fast Correlation Based Filter (FCBF). Finally the classifier Multiclass Support Vector Machine (SVM) with kernel Radial Basis Function (RBF) is used for classification of atherosclerotic community.; RESULTS: For the subjects belonging to the classes of normal, risk and pathologic, our methodology has outperformed with an accuracy of 99.85%, 99.80% and 99.46% respectively.; CONCLUSION: The combined optimization methods such as Iterative Principal Component Analysis (IPCA) for missing value imputation, Multiclass SVM for classifying normal, risk and pathologic community in real time has performed with overall accuracy of about 98.97%. The essential pre-processing technique, Fast Correlation Based Filter (FCBF) was employed to further intensifying the target. © 2014-IOS Press and the authors.","Atherosclerosis; feature selection; multiclass SVM classification; principal component analysis; STULONG dataset","Age Distribution; Atherosclerosis; Cause of Death; Coronary Artery Disease; Diagnostic Imaging; Disease Progression; Female; Genetic Predisposition to Disease; Humans; Incidence; India; Male; Predictive Value of Tests; Principal Component Analysis; Risk Assessment; Sex Distribution; Support Vector Machines; age distribution; atherosclerosis; cause of death; classification; complication; coronary artery disease; diagnostic imaging; disease course; female; genetic predisposition; human; incidence; India; male; mortality; predictive value; principal component analysis; procedures; risk assessment; sex ratio; support vector machine; trends","IOS Press","09287329","","THCAE","24990170","Article","Scopus","2-s2.0-84907676690"
"Cao Y.; Steffey S.; He J.; Xiao D.; Tao C.; Chen P.; Müller H.","Cao, Yu (57209518085); Steffey, Shawn (57190618385); He, Jianbiao (14032744200); Xiao, Degui (23398884000); Tao, Cui (8245410000); Chen, Ping (55490207600); Müller, Henning (8501863000)","57209518085; 57190618385; 14032744200; 23398884000; 8245410000; 55490207600; 8501863000","Medical image retrieval: A multimodal approach","2014","Cancer Informatics","48","10.4137/CIN.S14053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981714705&doi=10.4137%2fCIN.S14053&partnerID=40&md5=19096a6872d877dd92e0f7562e1c2a0b","Department of Computer Science, The University of Massachusetts Lowell, Lowell, MA, United States; School of Information Science and Engineering, Central South University, College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; School of Biomedical Informatics, The University of Texas, Health Science Center at Houston, Houston, TX, United States; Department of Computer Science, University of Massachusetts Boston, Boston, MA, United States; Department of Business Information Systems, University of Applied Sciences Western Switzerland (HES-SO), Medical Informatics, University Hospitals and University of Geneva, Geneva, Switzerland","Cao Y., Department of Computer Science, The University of Massachusetts Lowell, Lowell, MA, United States; Steffey S., Department of Computer Science, The University of Massachusetts Lowell, Lowell, MA, United States; He J., School of Information Science and Engineering, Central South University, College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Xiao D., College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Tao C., School of Biomedical Informatics, The University of Texas, Health Science Center at Houston, Houston, TX, United States; Chen P., Department of Computer Science, University of Massachusetts Boston, Boston, MA, United States; Müller H., Department of Business Information Systems, University of Applied Sciences Western Switzerland (HES-SO), Medical Informatics, University Hospitals and University of Geneva, Geneva, Switzerland","Medical imaging is becoming a vital component of war on cancer. Tremendous amounts of medical image data are captured and recorded in a digital format during cancer care and cancer research. Facing such an unprecedented volume of image data with heterogeneous image modalities, it is necessary to develop effective and efficient content-based medical image retrieval systems for cancer clinical practice and research. While substantial progress has been made in different areas of content-based image retrieval (CBIR) research, direct applications of existing CBIR techniques to the medical images produced unsatisfactory results, because of the unique characteristics of medical images. In this paper, we develop a new multimodal medical image retrieval approach based on the recent advances in the statistical graphic model and deep learning. Specifically, we first investigate a new extended probabilistic Latent Semantic Analysis model to integrate the visual and textual information from medical images to bridge the semantic gap. We then develop a new deep Boltzmann machine-based multimodal learning model to learn the joint density model from multimodal information in order to derive the missing modality. Experimental results with large volume of real-world medical images have shown that our new approach is a promising solution for the next-generation medical imaging indexing and retrieval system. © the authors, publisher and licensee Libertas Academica Limited.","Content-based image retrieval; Deep boltzmann machine; Deep learning; Extended probabilistic latent semantic analysis; Multi-modal and content-based medical image retrieval","diagnostic imaging; experimental model; image retrieval; joint; learning; machine; statistical model","Libertas Academica Ltd.","11769351","","","","Article","Scopus","2-s2.0-84981714705"
"Deng X.; Gumm J.; Karki S.; Eickholt J.; Cheng J.","Deng, Xin (7401768741); Gumm, Jordan (56720301700); Karki, Suman (56516436800); Eickholt, Jesse (35069298500); Cheng, Jianlin (57203108630)","7401768741; 56720301700; 56516436800; 35069298500; 57203108630","An overview of practical applications of protein disorder prediction and drive for faster, more accurate predictions","2015","International Journal of Molecular Sciences","17","10.3390/ijms160715384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937019610&doi=10.3390%2fijms160715384&partnerID=40&md5=ac35738441368c921534fb6359b20561","Microsoft Corporation, One Microsoft Way, Redmond, 98052, WA, United States; Department of Computer Science, Central Michigan University, Mount Pleasant, 48859, MI, United States; Department of Computer Science, University of Missouri, Columbia, 65211, MO, United States; Informatics Institute, University of Missouri, Columbia, 65211, MO, United States","Deng X., Microsoft Corporation, One Microsoft Way, Redmond, 98052, WA, United States; Gumm J., Department of Computer Science, Central Michigan University, Mount Pleasant, 48859, MI, United States; Karki S., Department of Computer Science, Central Michigan University, Mount Pleasant, 48859, MI, United States; Eickholt J., Department of Computer Science, Central Michigan University, Mount Pleasant, 48859, MI, United States; Cheng J., Department of Computer Science, University of Missouri, Columbia, 65211, MO, United States, Informatics Institute, University of Missouri, Columbia, 65211, MO, United States","Protein disordered regions are segments of a protein chain that do not adopt a stable structure. Thus far, a variety of protein disorder prediction methods have been developed and have been widely used, not only in traditional bioinformatics domains, including protein structure prediction, protein structure determination and function annotation, but also in many other biomedical fields. The relationship between intrinsically-disordered proteins and some human diseases has played a significant role in disorder prediction in disease identification and epidemiological investigations. Disordered proteins can also serve as potential targets for drug discovery with an emphasis on the disordered-to-ordered transition in the disordered binding regions, and this has led to substantial research in drug discovery or design based on protein disordered region prediction. Furthermore, protein disorder prediction has also been applied to healthcare by predicting the disease risk of mutations in patients and studying the mechanistic basis of diseases. As the applications of disorder prediction increase, so too does the need to make quick and accurate predictions. To fill this need, we also present a new approach to predict protein residue disorder using wide sequence windows that is applicable on the genomic scale. © 2015, by the authors.","Applications of disorder prediction; Deep networks; Machine learning;; Protein disorder prediction","Area Under Curve; Computational Biology; Databases, Protein; Drug Design; Drug Discovery; Intrinsically Disordered Proteins; Neural Networks (Computer); Proteins; intrinsically disordered protein; peptides and proteins; protein; amino acid sequence; Article; bioinformatics; computer model; drug design; health care; molecular biology; predictive value; protein defect; protein determination; protein disorder prediction; protein function; protein structure; structural genomics; area under the curve; artificial neural network; biology; chemistry; drug development; procedures; protein database","MDPI AG","16616596","","","26198229","Article","Scopus","2-s2.0-84937019610"
"Gu Y.; Chen Y.; Liu J.; Jiang X.","Gu, Yang (55823013400); Chen, Yiqiang (35408792800); Liu, Junfa (55983700400); Jiang, Xinlong (55932340500)","55823013400; 35408792800; 55983700400; 55932340500","Semi-supervised deep extreme learning machine for Wi-Fi based localization","2015","Neurocomputing","86","10.1016/j.neucom.2015.04.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931573903&doi=10.1016%2fj.neucom.2015.04.011&partnerID=40&md5=82876f71cc1f7f3f8f918401589cc5d2","Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Beijing, China; University of Chinese Academy of Sciences, Beijing, China","Gu Y., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, Beijing Key Laboratory of Mobile Computing and Pervasive Device, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Chen Y., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, Beijing Key Laboratory of Mobile Computing and Pervasive Device, Beijing, China; Liu J., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, Beijing Key Laboratory of Mobile Computing and Pervasive Device, Beijing, China; Jiang X., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, Beijing Key Laboratory of Mobile Computing and Pervasive Device, Beijing, China, University of Chinese Academy of Sciences, Beijing, China","Along with the proliferation of mobile devices and wireless signal coverage, indoor localization based on Wi-Fi gets great popularity. Fingerprint based method is the mainstream approach for Wi-Fi indoor localization, for it can achieve high localization performance as long as labeled data are sufficient. However, the number of labeled data is always limited due to the high cost of data acquisition. Nowadays, crowd sourcing becomes an effective approach to gather large number of data; meanwhile, most of them are unlabeled. Therefore, it is worth studying the use of unlabeled data to improve localization performance. To achieve this goal, a novel algorithm Semi-supervised Deep Extreme Learning Machine (SDELM) is proposed, which takes the advantages of semi-supervised learning, Deep Leaning (DL), and Extreme Learning Machine (ELM), so that the localization performance can be improved both in the feature extraction procedure and in the classifier. The experimental results in real indoor environments show that the proposed SDELM not only outperforms other compared methods but also reduces the calibration effort with the help of unlabeled data. © 2015 Elsevier B.V..","Deep learning; Extreme Learning Machine (ELM); Semi-supervised learning; Wi-Fi indoor localization","Data acquisition; Deep learning; Indoor positioning systems; Knowledge acquisition; Labeled data; Semi-supervised learning; Wi-Fi; Wireless local area networks (WLAN); Effective approaches; Extraction procedure; Extreme learning machine; Indoor environment; Indoor localization; Localization performance; Semi-supervised; Wireless signals; Article; calibration; classification algorithm; controlled study; data processing; deep learning; environment; extreme machine learning; indoor environment; Internet; machine learning; measurement accuracy; priority journal; semi supervised learning; unlabeled data; Wi Fi; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84931573903"
"Liu N.; Cui X.; Bryant D.M.; Glover G.H.; Reiss A.L.","Liu, Ning (56293823200); Cui, Xu (55681490000); Bryant, Daniel M. (36843663700); Glover, Gary H. (35502526500); Reiss, Allan L. (7102359271)","56293823200; 55681490000; 36843663700; 35502526500; 7102359271","Inferring deep-brain activity from cortical activity using functional near-infrared spectroscopy","2015","Biomedical Optics Express","55","10.1364/BOE.6.001074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942368100&doi=10.1364%2fBOE.6.001074&partnerID=40&md5=512b9f10553c96c6896b7adee15d9a2f","Department of Psychiatry and Behavioral Sciences, School of Medicine, Stanford University, Stanford, 94305, CA, United States; Center for Interdisciplinary Brain Sciences Research, Stanford University, Stanford, 94305, CA, United States; Stanford University, Stanford, 94305, CA, United States; Department of Radiology, Center for Advanced MR Technology, Stanford University, Stanford, 94305, CA, United States","Liu N., Department of Psychiatry and Behavioral Sciences, School of Medicine, Stanford University, Stanford, 94305, CA, United States, Center for Interdisciplinary Brain Sciences Research, Stanford University, Stanford, 94305, CA, United States; Cui X., Department of Psychiatry and Behavioral Sciences, School of Medicine, Stanford University, Stanford, 94305, CA, United States, Center for Interdisciplinary Brain Sciences Research, Stanford University, Stanford, 94305, CA, United States; Bryant D.M., Stanford University, Stanford, 94305, CA, United States; Glover G.H., Department of Radiology, Center for Advanced MR Technology, Stanford University, Stanford, 94305, CA, United States; Reiss A.L., Department of Psychiatry and Behavioral Sciences, School of Medicine, Stanford University, Stanford, 94305, CA, United States, Center for Interdisciplinary Brain Sciences Research, Stanford University, Stanford, 94305, CA, United States, Department of Radiology, Center for Advanced MR Technology, Stanford University, Stanford, 94305, CA, United States","Functional near-infrared spectroscopy (fNIRS) is an increasingly popular technology for studying brain function because it is non-invasive, non-irradiating and relatively inexpensive. Further, fNIRS potentially allows measurement of hemodynamic activity with high temporal resolution (milliseconds) and in naturalistic settings. However, in comparison with other imaging modalities, namely fMRI, fNIRS has a significant drawback: limited sensitivity to hemodynamic changes in deep-brain regions. To overcome this limitation, we developed a computational method to infer deep-brain activity using fNIRS measurements of cortical activity. Using simultaneous fNIRS and fMRI, we measured brain activity in 17 participants as they completed three cognitive tasks. A support vector regression (SVR) learning algorithm was used to predict activity in twelve deep-brain regions using information from surface fNIRS measurements. We compared these predictions against actual fMRI-measured activity using Pearson’s correlation to quantify prediction performance. To provide a benchmark for comparison, we also used fMRI measurements of cortical activity to infer deep-brain activity. When using fMRImeasured activity from the entire cortex, we were able to predict deepbrain activity in the fusiform cortex with an average correlation coefficient of 0.80 and in all deep-brain regions with an average correlation coefficient of 0.67. The top 15% of predictions using fNIRS signal achieved an accuracy of 0.7. To our knowledge, this study is the first to investigate the feasibility of using cortical activity to infer deepbrain activity. This new method has the potential to extend fNIRS applications in cognitive and clinical neuroscience research. © 2015 Optical Society of America.","","Clinical research; Forecasting; Functional neuroimaging; Infrared devices; Learning algorithms; Near infrared spectroscopy; Neurophysiology; Support vector regression; Average correlation coefficients; Clinical neuroscience; Functional near infrared spectroscopy; Functional near-infrared spectroscopy (fnirs); Hemodynamic activities; High temporal resolution; Prediction performance; Support vector regression (SVR); Article; BOLD signal; brain depth stimulation; cognition; computer prediction; controlled study; correlation coefficient; electroencephalogram; functional magnetic resonance imaging; human; information processing; mathematical parameters; near infrared spectroscopy; signal processing; support vector machine; task performance; Brain","OSA - The Optical Society","21567085","","","","Article","Scopus","2-s2.0-84942368100"
"Ithapul V.K.; Singh V.; Okonkwo O.; Johnson S.C.","Ithapul, Vamsi K. (56505414900); Singh, Vikas (57207179029); Okonkwo, Ozioma (15049910000); Johnson, Sterling C. (7406327695)","56505414900; 57207179029; 15049910000; 7406327695","Randomized denoising autoencoders for smaller and efficient imaging based AD clinical trials","2014","Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922333222&partnerID=40&md5=15f41efae0a78cc6cf400aae9a4b76f9","","","There is growing body of research devoted to designing imaging-based biomarkers that identify Alzheimer's disease (AD) in its prodromal stage using statistical machine learning methods. Recently several authors investigated how clinical trials for AD can be made more efficient (i.e., smaller sample size) using predictive measures from such classification methods. In this paper, we explain why predictive measures given by such SVM type objectives may be less than ideal for use in the setting described above. We give a solution based on a novel deep learning model, randomized denoising autoencoders (rDA), which regresses on training labels y while also accounting for the variance, a property which is very useful for clinical trial design. Our results give strong improvements in sample size estimates over strategies based on multi-kernel learning. Also, rDA predictions appear to more accurately correlate to stages of disease. Separately, our formulation empirically shows how deep architectures can be applied in the large d, small n regime--the default situation in medical imaging. This result is of independent interest.","","Algorithms; Alzheimer Disease; Artifacts; Artificial Intelligence; Brain; Clinical Trials as Topic; Humans; Image Enhancement; Information Storage and Retrieval; Magnetic Resonance Imaging; Pattern Recognition, Automated; Reproducibility of Results; Sensitivity and Specificity; Signal-To-Noise Ratio; algorithm; Alzheimer disease; artifact; artificial intelligence; automated pattern recognition; brain; clinical trial (topic); comparative study; human; image enhancement; information retrieval; nuclear magnetic resonance imaging; pathology; procedures; reproducibility; sensitivity and specificity; signal noise ratio","","","","","25485413","Article","Scopus","2-s2.0-84922333222"
"Neftci E.; Das S.; Pedroni B.; Kreutz-Delgado K.; Cauwenberghs G.","Neftci, Emre (36444841100); Das, Srinjoy (56028627600); Pedroni, Bruno (56109521800); Kreutz-Delgado, Kenneth (7004221623); Cauwenberghs, Gert (7006056098)","36444841100; 56028627600; 56109521800; 7004221623; 7006056098","Event-driven contrastive divergence for spiking neuromorphic systems","2014","Frontiers in Neuroscience","142","10.3389/fnins.2013.00272","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898035691&doi=10.3389%2ffnins.2013.00272&partnerID=40&md5=fcbd83024cf28bf5f1851bb9b29ebfbe","Institute for Neural Computation, University of California, San Diego, La Jolla, CA, United States; Electrical and Computer Engineering Department, University of California, San Diego, La Jolla, CA, United States; Department of Bioengineering, University of California, San Diego, La Jolla, CA, United States","Neftci E., Institute for Neural Computation, University of California, San Diego, La Jolla, CA, United States; Das S., Institute for Neural Computation, University of California, San Diego, La Jolla, CA, United States, Electrical and Computer Engineering Department, University of California, San Diego, La Jolla, CA, United States; Pedroni B., Department of Bioengineering, University of California, San Diego, La Jolla, CA, United States; Kreutz-Delgado K., Institute for Neural Computation, University of California, San Diego, La Jolla, CA, United States, Electrical and Computer Engineering Department, University of California, San Diego, La Jolla, CA, United States; Cauwenberghs G., Institute for Neural Computation, University of California, San Diego, La Jolla, CA, United States, Department of Bioengineering, University of California, San Diego, La Jolla, CA, United States","Restricted Boltzmann Machines (RBMs) and Deep Belief Networks have been demonstrated to perform efficiently in a variety of applications, such as dimensionality reduction, feature learning, and classification. Their implementation on neuromorphic hardware platforms emulating large-scale networks of spiking neurons can have significant advantages from the perspectives of scalability, power dissipation and real-time interfacing with the environment. However, the traditional RBM architecture and the commonly used training algorithm known as Contrastive Divergence (CD) are based on discrete updates and exact arithmetics which do not directly map onto a dynamical neural substrate. Here, we present an event-driven variation of CD to train a RBM constructed with Integrate & Fire (I&F) neurons, that is constrained by the limitations of existing and near future neuromorphic hardware platforms. Our strategy is based on neural sampling, which allows us to synthesize a spiking neural network that samples from a target Boltzmann distribution. The recurrent activity of the network replaces the discrete steps of the CD algorithm, while Spike Time Dependent Plasticity (STDP) carries out the weight updates in an online, asynchronous fashion. We demonstrate our approach by training an RBM composed of leaky I&F neurons with STDP synapses to learn a generative model of the MNIST hand-written digit dataset, and by testing it in recognition, generation and cue integration tasks. Our results contribute to a machine learning-driven approach for synthesizing networks of spiking neurons capable of carrying out practical, high-level functionality. © 2014 Neftci, Das, Pedroni, Kreutz-Delgado and Cauwenberghs.","Generative model; Markov chain monte carlo; Neuromorphic cognition; Recurrent neural network; Synaptic plasticity","algorithm; arithmetic; article; association; computer; contrastive divergence; handwriting; histogram; learning; learning algorithm; long term depression; long term potentiation; nerve cell membrane potential; nerve cell network; nerve cell plasticity; neuromorphic system; postsynaptic potential; recognition; refractory period; restricted Boltzmann machine; spike time dependent plasticity; stochastic model; synapse; task performance","Frontiers Media S.A.","16624548","","","","Article","Scopus","2-s2.0-84898035691"
"Peissig P.L.; Santos Costa V.; Caldwell M.D.; Rottscheit C.; Berg R.L.; Mendonca E.A.; Page D.","Peissig, Peggy L. (16043391700); Santos Costa, Vitor (55663393200); Caldwell, Michael D. (7101755384); Rottscheit, Carla (37029775800); Berg, Richard L. (7402880130); Mendonca, Eneida A. (7004308859); Page, David (36922487700)","16043391700; 55663393200; 7101755384; 37029775800; 7402880130; 7004308859; 36922487700","Relational machine learning for electronic health record-driven phenotyping","2014","Journal of Biomedical Informatics","40","10.1016/j.jbi.2014.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919848159&doi=10.1016%2fj.jbi.2014.07.007&partnerID=40&md5=4560b8a03a8abc21fb4e657f3b9e8d4a","Biomedical Informatics Research Center, Marshfield Clinic Research Foundation, Marshfield, WI, United States; DCC-FCUP and CRACS INESC-TEC, Department de Ciência de Computadores, Universidade do Porto, Portugal; Department of Surgery, Marshfield Clinic, Marshfield, WI, United States; Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison, United States; Department of Pediatrics, University of Wisconsin-Madison, United States; Department of Computer Sciences, University of Wisconsin-Madison, United States","Peissig P.L., Biomedical Informatics Research Center, Marshfield Clinic Research Foundation, Marshfield, WI, United States; Santos Costa V., DCC-FCUP and CRACS INESC-TEC, Department de Ciência de Computadores, Universidade do Porto, Portugal; Caldwell M.D., Department of Surgery, Marshfield Clinic, Marshfield, WI, United States; Rottscheit C., Biomedical Informatics Research Center, Marshfield Clinic Research Foundation, Marshfield, WI, United States; Berg R.L., Biomedical Informatics Research Center, Marshfield Clinic Research Foundation, Marshfield, WI, United States; Mendonca E.A., Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison, United States, Department of Pediatrics, University of Wisconsin-Madison, United States; Page D., Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison, United States, Department of Computer Sciences, University of Wisconsin-Madison, United States","Objective: Electronic health records (EHR) offer medical and pharmacogenomics research unprecedented opportunities to identify and classify patients at risk. EHRs are collections of highly inter-dependent records that include biological, anatomical, physiological, and behavioral observations. They comprise a patient's clinical phenome, where each patient has thousands of date-stamped records distributed across many relational tables. Development of EHR computer-based phenotyping algorithms require time and medical insight from clinical experts, who most often can only review a small patient subset representative of the total EHR records, to identify phenotype features. In this research we evaluate whether relational machine learning (ML) using inductive logic programming (ILP) can contribute to addressing these issues as a viable approach for EHR-based phenotyping. Methods: Two relational learning ILP approaches and three well-known WEKA (Waikato Environment for Knowledge Analysis) implementations of non-relational approaches (PART, J48, and JRIP) were used to develop models for nine phenotypes. International Classification of Diseases, Ninth Revision (ICD-9) coded EHR data were used to select training cohorts for the development of each phenotypic model. Accuracy, precision, recall, F-Measure, and Area Under the Receiver Operating Characteristic (AUROC) curve statistics were measured for each phenotypic model based on independent manually verified test cohorts. A two-sided binomial distribution test (sign test) compared the five ML approaches across phenotypes for statistical significance. Results: We developed an approach to automatically label training examples using ICD-9 diagnosis codes for the ML approaches being evaluated. Nine phenotypic models for each ML approach were evaluated, resulting in better overall model performance in AUROC using ILP when compared to PART (p= 0.039), J48 (p= 0.003) and JRIP (p= 0.003). Discussion: ILP has the potential to improve phenotyping by independently delivering clinically expert interpretable rules for phenotype definitions, or intuitive phenotypes to assist experts. Conclusion: Relational learning using ILP offers a viable approach to EHR-driven phenotyping. © 2014 Elsevier Inc.","Electronic health record; Inductive logic programming; Machine learning; Phenotyping; Relational machine learning","Algorithms; Artificial Intelligence; Data Mining; Databases, Factual; Electronic Health Records; Humans; Computer circuits; Diagnosis; E-learning; eHealth; Health risks; Learning systems; Machine learning; Medical computing; Records management; Behavioral observation; Binomial distribution; Electronic health record; International classification of disease; Interpretable rules; Phenotyping; Receiver operating characteristics; Statistical significance; acute heart infarction; algorithm; Article; binomial distribution; cataract; computer aided design; congestive heart failure; controlled study; deep vein thrombosis; dementia; diabetic retinopathy; electronic medical record; heart atrium fibrillation; ICD-9; liver injury; machine learning; measurement accuracy; non insulin dependent diabetes mellitus; phenotype; receiver operating characteristic; artificial intelligence; classification; data mining; electronic medical record; factual database; human; procedures; Inductive logic programming (ILP)","Academic Press Inc.","15320464","","JBIOB","25048351","Article","Scopus","2-s2.0-84919848159"
"Xu J.; Li H.; Zhou S.","Xu, Jungang (23092590500); Li, Hui (57848040600); Zhou, Shilong (56028497700)","23092590500; 57848040600; 56028497700","Improving mixing rate with tempered transition for learning restricted Boltzmann machines","2014","Neurocomputing","7","10.1016/j.neucom.2014.02.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901064273&doi=10.1016%2fj.neucom.2014.02.024&partnerID=40&md5=fb4313247690ebb7a5ac5c2d5cf95344","School of Computer and Control Engineering, University of Chinese Academy of Sciences, 101408 Beijing, China","Xu J., School of Computer and Control Engineering, University of Chinese Academy of Sciences, 101408 Beijing, China; Li H., School of Computer and Control Engineering, University of Chinese Academy of Sciences, 101408 Beijing, China; Zhou S., School of Computer and Control Engineering, University of Chinese Academy of Sciences, 101408 Beijing, China","Recently, as the building block of deep generative models such as Deep Belief Networks (DBNs), Restricted Boltzmann Machines (RBMs) have attracted much attention. RBM is a Markov Random Field (MRF) associated with a bipartite undirected graph which is famous for powerful expression and tractable inference. While training an RBM, we need to sample from the model. The larger the mixing rate is, the smaller the bias of the samples is. However, neither Gibbs sampling based training methods such as Contrastive Divergence (CD) nor Parallel Tempering based training methods can achieve satisfying mixing rate, which causes poor rendering of the diversity of the modes captured by these trained models. This property may hinder the existing methods to approximate the likelihood gradient. In order to alleviate this problem, we attempt to introduce Tempered Transition, an advanced tempered Markov Chain Monte Carlo method, into training RBMs to replace Gibbs sampling or Parallel Tempering for sampling from RBMs. Experimental results show that our proposed method outperforms the existing methods to achieve better mixing rate and to help approximate the likelihood gradient. © 2014 Elsevier B.V.","Deep learning; Mixing rate; Restricted Boltzmann machines; Tempered transition","Markov processes; Tempering; Contrastive divergence; Deep belief networks; Deep learning; Markov chain Monte Carlo method; Markov Random Fields; Mixing rates; Restricted boltzmann machine; Tempered transition; article; artificial neural network; contrastive divergence learning algorithm; experimental study; intermethod comparison; learning algorithm; machine learning; mathematical computing; Monte Carlo method; priority journal; probability; Restricted Boltzmann machine; sampling; statistical model; Mixing","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84901064273"
"Gao W.; Guan J.-A.; Gao J.; Zhou D.","Gao, Wei (56491952800); Guan, Jin-An (14019280000); Gao, Junfeng (55648452000); Zhou, Dao (56491931200)","56491952800; 14019280000; 55648452000; 56491931200","Multi-ganglion ANN based feature learning with application to P300-BCI signal classification","2015","Biomedical Signal Processing and Control","27","10.1016/j.bspc.2014.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921646104&doi=10.1016%2fj.bspc.2014.12.007&partnerID=40&md5=0ec4c3f686aac65174a675cda0e78ce6","College of Biomedical Engineering, South-Central University for Nationalities, Wuhan, China; Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan, China","Gao W., College of Biomedical Engineering, South-Central University for Nationalities, Wuhan, China, Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan, China; Guan J.-A., College of Biomedical Engineering, South-Central University for Nationalities, Wuhan, China, Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan, China; Gao J., College of Biomedical Engineering, South-Central University for Nationalities, Wuhan, China, Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan, China; Zhou D., College of Biomedical Engineering, South-Central University for Nationalities, Wuhan, China, Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan, China","The feature extraction of event-related potentials (ERPs) is a significant prerequisite for many types of P300-BCIs. In this paper, we proposed a multi-ganglion artificial neural network based feature learning (ANNFL) method to extract a deep feature structure of single-trial multi-channel ERP signals and improve classification accuracy. Five subjects took part in the Imitating-Reading ERP experiments. We recorded the target electroencephalography (EEG) samples (elicited by target stimuli) and non-target samples (elicited by non-target stimuli) for each subjects. Then we applied ANNFL method to extract the feature vectors and classified them by using support vector machine (SVM). The ANNFL method outperforms the principal component analysis (PCA) method and conventional three-layer auto-encoder, and then leads to higher classification accuracies of five subjects' BCI signals than using the single-channel temporal features. ANNFL is an unsupervised feature learning method, which can automatically learn feature vector from EEG data and provide more effective feature representation than PCA method and single-channel temporal feature extraction method. © 2014 Elsevier Ltd.","Imitating-Reading BCI; Multi-channel signal feature extraction; Multi-ganglion artificial neural network","Channel coding; Electroencephalography; Electrophysiology; Extraction; Feature extraction; Learning systems; Neural networks; Support vector machines; Classification accuracy; Eventrelated potential (ERPs); Feature representation; Feature structure; Imitating-Reading BCI; Multi channel; Signal classification; Unsupervised feature learning; accuracy; adult; Article; artificial neural network; artificial neural network feature learning; brain computer interface; classification algorithm; electroencephalography; event related potential; female; ganglion; human; human experiment; male; normal human; principal component analysis; priority journal; support vector machine; Biomedical signal processing","Elsevier Ltd","17468094","","","","Article","Scopus","2-s2.0-84921646104"
"Hinton G.","Hinton, Geoffrey (7006699573)","7006699573","Where do features come from?","2014","Cognitive Science","83","10.1111/cogs.12049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906221749&doi=10.1111%2fcogs.12049&partnerID=40&md5=87fa41c836c3fd7a46dcd208ad26cd63","Department of Computer Science, University of Toronto, Canada","Hinton G., Department of Computer Science, University of Toronto, Canada","It is possible to learn multiple layers of non-linear features by backpropagating error derivatives through a feedforward neural network. This is a very effective learning procedure when there is a huge amount of labeled training data, but for many learning tasks very few labeled examples are available. In an effort to overcome the need for labeled data, several different generative models were developed that learned interesting features by modeling the higher order statistical structure of a set of input vectors. One of these generative models, the restricted Boltzmann machine (RBM), has no connections between its hidden units and this makes perceptual inference and learning much simpler. More significantly, after a layer of hidden features has been learned, the activities of these features can be used as training data for another RBM. By applying this idea recursively, it is possible to learn a deep hierarchy of progressively more complicated features without requiring any labeled data. This deep hierarchy can then be treated as a feedforward neural network which can be discriminatively fine-tuned using backpropagation. Using a stack of RBMs to initialize the weights of a feedforward neural network allows backpropagation to work effectively in much deeper networks and it leads to much better generalization. A stack of RBMs can also be used to initialize a deep Boltzmann machine that has many hidden layers. Combining this initialization method with a new method for fine-tuning the weights finally leads to the first efficient way of training Boltzmann machines with many hidden layers and millions of weights. © 2013 Cognitive Science Society, Inc.","Backpropagation; Boltzmann machines; Contrastive divergence; Deep learning; Distributed representations; Learning features; Learning graphical models; Variational learning","Artificial Intelligence; Computer Simulation; Humans; Learning; Models, Neurological; Neural Networks (Computer); artificial intelligence; artificial neural network; biological model; computer simulation; human; learning","Wiley-Blackwell Publishing","03640213","","COGSD","23800216","Article","Scopus","2-s2.0-84906221749"
"Aubry S.; Kelly S.; Kümpers B.M.C.; Smith-Unna R.D.; Hibberd J.M.","Aubry, Sylvain (12769736700); Kelly, Steven (57212985928); Kümpers, Britta M. C. (55985582100); Smith-Unna, Richard D. (56118128800); Hibberd, Julian M. (7003599315)","12769736700; 57212985928; 55985582100; 56118128800; 7003599315","Deep Evolutionary Comparison of Gene Expression Identifies Parallel Recruitment of Trans-Factors in Two Independent Origins of C4 Photosynthesis","2014","PLoS Genetics","112","10.1371/journal.pgen.1004365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903442051&doi=10.1371%2fjournal.pgen.1004365&partnerID=40&md5=06bd204827b56f96c565178d0413f3db","Department of Plant Sciences, University of Cambridge, Cambridge, United Kingdom; Department of Plant Sciences, University of Oxford, Oxford, United Kingdom","Aubry S., Department of Plant Sciences, University of Cambridge, Cambridge, United Kingdom; Kelly S., Department of Plant Sciences, University of Oxford, Oxford, United Kingdom; Kümpers B.M.C., Department of Plant Sciences, University of Cambridge, Cambridge, United Kingdom; Smith-Unna R.D., Department of Plant Sciences, University of Cambridge, Cambridge, United Kingdom; Hibberd J.M., Department of Plant Sciences, University of Cambridge, Cambridge, United Kingdom","With at least 60 independent origins spanning monocotyledons and dicotyledons, the C4 photosynthetic pathway represents one of the most remarkable examples of convergent evolution. The recurrent evolution of this highly complex trait involving alterations to leaf anatomy, cell biology and biochemistry allows an increase in productivity by ~50% in tropical and subtropical areas. The extent to which separate lineages of C4 plants use the same genetic networks to maintain C4 photosynthesis is unknown. We developed a new informatics framework to enable deep evolutionary comparison of gene expression in species lacking reference genomes. We exploited this to compare gene expression in species representing two independent C4 lineages (Cleome gynandra and Zea mays) whose last common ancestor diverged ~140 million years ago. We define a cohort of 3,335 genes that represent conserved components of leaf and photosynthetic development in these species. Furthermore, we show that genes encoding proteins of the C4 cycle are recruited into networks defined by photosynthesis-related genes. Despite the wide evolutionary separation and independent origins of the C4 phenotype, we report that these species use homologous transcription factors to both induce C4 photosynthesis and to maintain the cell specific gene expression required for the pathway to operate. We define a core molecular signature associated with leaf and photosynthetic maturation that is likely shared by angiosperm species derived from the last common ancestor of the monocotyledons and dicotyledons. We show that deep evolutionary comparisons of gene expression can reveal novel insight into the molecular convergence of highly complex phenotypes and that parallel evolution of trans-factors underpins the repeated appearance of C4 photosynthesis. Thus, exploitation of extant natural variation associated with complex traits can be used to identify regulators. Moreover, the transcription factors that are shared by independent C4 lineages are key targets for engineering the C4 pathway into C3 crops such as rice. © 2014 Aubry et al.","","Amino Acid Substitution; Artificial Intelligence; Carbon Dioxide; Cleome; Gene Expression; Gene Expression Regulation, Plant; Oryza; Photosynthesis; Plant Leaves; RNA, Messenger; Transcription Factors; Transcriptional Activation; Transcriptome; Zea mays; transcription factor; transcriptome; carbon dioxide; messenger RNA; transcription factor; article; C4 plant; carbon cycle; carbon fixation; Cleome gynandra; controlled study; cytology; gene expression; leaf development; leaf morphology; machine learning; maize; maturation; measurement accuracy; nonhuman; phenotype; photosynthesis; plant cell; plant evolution; RNA analysis; RNA sequence; species difference; amino acid substitution; artificial intelligence; biosynthesis; chemistry; Cleome; comparative study; gene expression; gene expression regulation; genetics; metabolism; Oryza; photosynthesis; plant leaf; transcription initiation","Public Library of Science","15537390","","","24901697","Article","Scopus","2-s2.0-84903442051"
"Wu H.; Gu X.","Wu, Haibing (56784559400); Gu, Xiaodong (7403204205)","56784559400; 7403204205","Towards dropout training for convolutional neural networks","2015","Neural Networks","203","10.1016/j.neunet.2015.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939541134&doi=10.1016%2fj.neunet.2015.07.007&partnerID=40&md5=39f59e97ee71c184f65e77c6b2e099de","Department of Electronic Engineering, Fudan University, Shanghai, 200433, China","Wu H., Department of Electronic Engineering, Fudan University, Shanghai, 200433, China; Gu X., Department of Electronic Engineering, Fudan University, Shanghai, 200433, China","Recently, dropout has seen increasing use in deep learning. For deep convolutional neural networks, dropout is known to work well in fully-connected layers. However, its effect in convolutional and pooling layers is still not clear. This paper demonstrates that max-pooling dropout is equivalent to randomly picking activation based on a multinomial distribution at training time. In light of this insight, we advocate employing our proposed probabilistic weighted pooling, instead of commonly used max-pooling, to act as model averaging at test time. Empirical evidence validates the superiority of probabilistic weighted pooling. We also empirically show that the effect of convolutional dropout is not trivial, despite the dramatically reduced possibility of over-fitting due to the convolutional architecture. Elaborately designing dropout training simultaneously in max-pooling and fully-connected layers, we achieve state-of-the-art performance on MNIST, and very competitive results on CIFAR-10 and CIFAR-100, relative to other approaches without data augmentation. Finally, we compare max-pooling dropout and stochastic pooling, both of which introduce stochasticity based on multinomial distributions at pooling stage. © 2015 Elsevier Ltd.","Convolutional neural networks; Deep learning; Max-pooling dropout","Algorithms; Machine Learning; Models, Statistical; Neural Networks (Computer); Stochastic Processes; Neural networks; Stochastic systems; Convolutional neural network; Data augmentation; Deep learning; Max-pooling; Model averaging; Multinomial distributions; State-of-the-art performance; Stochasticity; Article; artificial neural network; convolutional neural network; information processing; intermethod comparison; machine learning; mathematical parameters; max pooling dropout; priority journal; probabilistic weighted pooling; process optimization; quality control; stochastic pooling; validation study; algorithm; machine learning; markov chain; statistical model; Convolution","Elsevier Ltd","08936080","","NNETE","26277608","Article","Scopus","2-s2.0-84939541134"
"Vázquez S.; Muñoz-García T.; Campanella I.; Poch M.; Fisas B.; Bel N.; Andreu G.","Vázquez, Silvia (55237532200); Muñoz-García, Óscar (57493751000); Campanella, Inés (56231222900); Poch, Marc (57197036086); Fisas, Beatriz (56230981800); Bel, Nuria (55369471300); Andreu, Gloria (57517066900)","55237532200; 57493751000; 56231222900; 57197036086; 56230981800; 55369471300; 57517066900","A classification of user-generated content into consumer decision journey stages","2014","Neural Networks","43","10.1016/j.neunet.2014.05.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906099804&doi=10.1016%2fj.neunet.2014.05.026&partnerID=40&md5=146a5e560dd715534941e45f14a4124f","Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain; Havas Media Group, 08017, Barcelona, Can Ràbia 3-5, Spain; Havas Media Group, 28020, Madrid, Pedro Texeira 8, 10o, Spain","Vázquez S., Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain; Muñoz-García T., Havas Media Group, 28020, Madrid, Pedro Texeira 8, 10o, Spain; Campanella I., Havas Media Group, 08017, Barcelona, Can Ràbia 3-5, Spain; Poch M., Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain; Fisas B., Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain; Bel N., Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain; Andreu G., Havas Media Group, 08017, Barcelona, Can Ràbia 3-5, Spain","In the last decades, the availability of digital user-generated documents from social media has dramatically increased. This massive growth of user-generated content has also affected traditional shopping behaviour. Customers have embraced new communication channels such as microblogs and social networks that enable them not only just to talk with friends and acquaintances about their shopping experience, but also to search for opinions expressed by complete strangers as part of their decision making processes. Uncovering how customers feel about specific products or brands and detecting purchase habits and preferences has traditionally been a costly and highly time-consuming task which involved the use of methods such as focus groups and surveys. However, the new scenario calls for a deep assessment of current market research techniques in order to better interpret and profit from this ever-growing stream of attitudinal data. With this purpose, we present a novel analysis and classification of user-generated content in terms of it belonging to one of the four stages of the Consumer Decision Journey Court etal. (2009) (i.e. the purchase process from the moment when a customer is aware of the existence of the product to the moment when he or she buys, experiences and talks about it). Using a corpus of short texts written in English and Spanish and extracted from different social media, we identify a set of linguistic patterns for each purchase stage that will be then used in a rule-based classifier. Additionally, we use machine learning algorithms to automatically identify business indicators such as the Marketing Mix elements McCarthy and Brogowicz (1981). The classification of the purchase stages achieves an average precision of 74%. The proposed classification of texts depending on the Marketing Mix elements expressed achieved an average precision of 75% for all the elements analysed. © 2014 Elsevier Ltd.","Computational intelligence; Consumer decision journey; Knowledge extraction; Marketing; Natural language processing; Social media; Text analytics","Algorithms; Artificial Intelligence; Communication; Consumer Behavior; Data Collection; Decision Making; Female; Humans; Male; Marketing; Artificial intelligence; Behavioral research; Classification (of information); Commerce; Data streams; Decision making; Intelligent computing; Learning algorithms; Machine learning; Marketing; Natural language processing systems; Purchasing; Social networking (online); Consumer decision journey; Knowledge extraction; NAtural language processing; Social media; Text analytics; article; artificial intelligence; classifier; consumer attitude; decision making; electronic commerce; Internet; linguistics; machine learning; marketing; natural language processing; priority journal; shopping; social media; algorithm; classification; decision making; female; human; information processing; interpersonal communication; male; procedures; Sales","Elsevier Ltd","08936080","","NNETE","24996448","Article","Scopus","2-s2.0-84906099804"
"Zhang S.-W.; Liu Y.-F.; Yu Y.; Zhang T.-H.; Fan X.-N.","Zhang, Shao-Wu (7409372742); Liu, Yan-Fang (56021240700); Yu, Yong (57197518741); Zhang, Ting-He (57196191482); Fan, Xiao-Nan (56018703400)","7409372742; 56021240700; 57197518741; 57196191482; 56018703400","MSLoc-DT: A new method for predicting the protein subcellular location of multispecies based on decision templates","2014","Analytical Biochemistry","22","10.1016/j.ab.2013.12.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893205292&doi=10.1016%2fj.ab.2013.12.013&partnerID=40&md5=8acb98ad488a40c3229d3b5f4d301b8c","College of Automation, Northwestern Polytechnical University, Xi'an 710072, China","Zhang S.-W., College of Automation, Northwestern Polytechnical University, Xi'an 710072, China; Liu Y.-F., College of Automation, Northwestern Polytechnical University, Xi'an 710072, China; Yu Y., College of Automation, Northwestern Polytechnical University, Xi'an 710072, China; Zhang T.-H., College of Automation, Northwestern Polytechnical University, Xi'an 710072, China; Fan X.-N., College of Automation, Northwestern Polytechnical University, Xi'an 710072, China","Revealing the subcellular location of newly discovered protein sequences can bring insight to their function and guide research at the cellular level. The rapidly increasing number of sequences entering the genome databanks has called for the development of automated analysis methods. Currently, most existing methods used to predict protein subcellular locations cover only one, or a very limited number of species. Therefore, it is necessary to develop reliable and effective computational approaches to further improve the performance of protein subcellular prediction and, at the same time, cover more species. The current study reports the development of a novel predictor called MSLoc-DT to predict the protein subcellular locations of human, animal, plant, bacteria, virus, fungi, and archaea by introducing a novel feature extraction approach termed Amino Acid Index Distribution (AAID) and then fusing gene ontology information, sequential evolutionary information, and sequence statistical information through four different modes of pseudo amino acid composition (PseAAC) with a decision template rule. Using the jackknife test, MSLoc-DT can achieve 86.5, 98.3, 90.3, 98.5, 95.9, 98.1, and 99.3% overall accuracy for human, animal, plant, bacteria, virus, fungi, and archaea, respectively, on seven stringent benchmark datasets. Compared with other predictors (e.g., Gpos-PLoc, Gneg-PLoc, Virus-PLoc, Plant-PLoc, Plant-mPLoc, ProLoc-Go, Hum-PLoc, GOASVM) on the gram-positive, gram-negative, virus, plant, eukaryotic, and human datasets, the new MSLoc-DT predictor is much more effective and robust. Although the MSLoc-DT predictor is designed to predict the single location of proteins, our method can be extended to multiple locations of proteins by introducing multilabel machine learning approaches, such as the support vector machine and deep learning, as substitutes for the K-nearest neighbor (KNN) method. As a user-friendly web server, MSLoc-DT is freely accessible at http://bioinfo.ibp.ac.cn/MSLOC-DT/index.html. © 2013 Published by Elsevier Inc. All rights reserved.","Amino acid index distribution; Decision template; Gene ontology; Multispecies; Subcellular location","Amino Acid Sequence; Animals; Artificial Intelligence; Computational Biology; Databases, Protein; Gene Ontology; Humans; Molecular Sequence Data; Proteins; Subcellular Fractions; Amino acids; Animals; Bacteria; Deep learning; Forecasting; Fungi; Genes; Nearest neighbor search; Proteins; Support vector machines; Viruses; Amino acid index distribution; Decision template; Gene ontology; Multispecies; Subcellular location; bacterial protein; fungal protein; vegetable protein; virus protein; Amino acid indices; Decision template; Gene ontology; Multi-species; Subcellular location; amino acid composition; animal; archaeon; article; bacterium; controlled study; fungus; gene ontology; human; Internet; jackknife test; machine learning; nonhuman; plant; prediction; priority journal; protein localization; support vector machine; virus; Location","Academic Press Inc.","00032697","","ANBCA","24361712","Article","Scopus","2-s2.0-84893205292"
"Zhang S.; Zhou J.; Hu H.; Gong H.; Chen L.; Cheng C.; Zeng J.","Zhang, Sai (56580715700); Zhou, Jingtian (57195321959); Hu, Hailin (57210726464); Gong, Haipeng (57205067584); Chen, Ligong (55739193800); Cheng, Chao (35304722700); Zeng, Jianyang (33468010200)","56580715700; 57195321959; 57210726464; 57205067584; 55739193800; 35304722700; 33468010200","A deep learning framework for modeling structural features of RNA-binding protein targets","2015","Nucleic Acids Research","198","10.1093/nar/gkv1025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960503750&doi=10.1093%2fnar%2fgkv1025&partnerID=40&md5=3afa736a89895a7bb6bec75d9d54a64c","Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Department of Pharmacology and Pharmaceutical Sciences, School of Medicine, Tsinghua University, Beijing, 100084, China; School of Life Sciences, Tsinghua University, Beijing, 100084, China; MOE Key Laboratory of Bioinformatics, Tsinghua University, Beijing, 100084, China; Department of Genetics, Institute for Quantitative Biomedical Sciences, Norris Cotton Cancer Center, Geisel School of Medicine at Dartmouth, Hanover, 03755, NH, United States","Zhang S., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China; Zhou J., Department of Pharmacology and Pharmaceutical Sciences, School of Medicine, Tsinghua University, Beijing, 100084, China; Hu H., Department of Pharmacology and Pharmaceutical Sciences, School of Medicine, Tsinghua University, Beijing, 100084, China; Gong H., School of Life Sciences, Tsinghua University, Beijing, 100084, China, MOE Key Laboratory of Bioinformatics, Tsinghua University, Beijing, 100084, China; Chen L., Department of Pharmacology and Pharmaceutical Sciences, School of Medicine, Tsinghua University, Beijing, 100084, China; Cheng C., Department of Genetics, Institute for Quantitative Biomedical Sciences, Norris Cotton Cancer Center, Geisel School of Medicine at Dartmouth, Hanover, 03755, NH, United States; Zeng J., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China, MOE Key Laboratory of Bioinformatics, Tsinghua University, Beijing, 100084, China","RNA-binding proteins (RBPs) play important roles in the post-transcriptional control of RNAs. Identifying RBP binding sites and characterizing RBP binding preferences are key steps toward understanding the basic mechanisms of the post-transcriptional gene regulation. Though numerous computational methods have been developed for modeling RBP binding preferences, discovering a complete structural representation of the RBP targets by integrating their available structural features in all three dimensions is still a challenging task. In this paper, we develop a general and flexible deep learning framework for modeling structural binding preferences and predicting binding sites of RBPs, which takes (predicted) RNA tertiary structural information into account for the first time. Our framework constructs a unified representation that characterizes the structural specificities of RBP targets in all three dimensions, which can be further used to predict novel candidate binding sites and discover potential binding motifs. Through testing on the real CLIP-seq datasets, we have demonstrated that our deep learning framework can automatically extract effective hidden structural features from the encoded raw sequence and structural profiles, and predict accurate RBP binding sites. In addition, we have conducted the first study to show that integrating the additional RNA tertiary structural features can improve the model performance in predicting RBP binding sites, especially for the polypyrimidine tract-binding protein (PTB), which also provides a new evidence to support the view that RBPs may own specific tertiary structural binding preferences. In particular, the tests on the internal ribosome entry site (IRES) segments yield satisfiable results with experimental support from the literature and further demonstrate the necessity of incorporating RNA tertiary structural information into the prediction model. The source code of our approach can be found in https://github.com/thucombio/deepnet-rbp. © 2016 The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic Acids Research.","","Binding Sites; Computational Biology; Gene Expression Regulation; Nucleic Acid Conformation; Polypyrimidine Tract-Binding Protein; Ribosomes; RNA Processing, Post-Transcriptional; RNA, Messenger; RNA-Binding Proteins; polypyrimidine tract binding protein; RNA binding protein; messenger RNA; RNA binding protein; Article; binding site; data processing; internal ribosome entry site; machine learning; prediction; priority journal; protein motif; protein RNA binding; RNA sequence; RNA structure; statistical analysis; statistical model; binding site; biology; chemistry; conformation; gene expression regulation; genetics; metabolism; ribosome; RNA processing","Oxford University Press","03051048","","NARHA","26467480","Article","Scopus","2-s2.0-84960503750"
"Zhou W.-G.; Cui Y.-F.; Li Y.","Zhou, Wen-Gang (55582050900); Cui, Yong-Feng (56518815100); Li, Ya (56520477000)","55582050900; 56518815100; 56520477000","A modified method combined with a support vector machine and Bayesian algorithms in biological information","2015","International Journal Bioautomation","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936752802&partnerID=40&md5=6c0e1095a2b4e4a2ecdfac937289a520","College of Computer Science and Technology, Zhoukou Normal University, Zhoukou, 466001, China","Zhou W.-G., College of Computer Science and Technology, Zhoukou Normal University, Zhoukou, 466001, China; Cui Y.-F., College of Computer Science and Technology, Zhoukou Normal University, Zhoukou, 466001, China; Li Y., College of Computer Science and Technology, Zhoukou Normal University, Zhoukou, 466001, China","With the deep research of genomics and proteomics, the number of new protein sequences has expanded rapidly. With the obvious shortcomings of high cost and low efficiency of the traditional experimental method, the calculation method for protein localization prediction has attracted a lot of attention due to its convenience and low cost. In the machine learning techniques, neural network and support vector machine (SVM) are often used as learning tools. Due to its complete theoretical framework, SVM has been widely applied. In this paper, we make an improvement on the existing machine learning algorithm of the support vector machine algorithm, and a new improved algorithm has been developed, combined with Bayesian algorithms. The proposed algorithm can improve calculation efficiency, and defects of the original algorithm are eliminated. According to the verification, the method has proved to be valid. At the same time, it can reduce calculation time and improve prediction efficiency.","Bayesian method; Biological information; Modified method; Support vector machine","Algorithms; Artificial intelligence; Bayesian networks; Efficiency; Learning algorithms; Learning systems; Molecular biology; Proteins; Support vector machines; Vectors; Bayesian methods; Biological information; Calculation efficiency; Machine learning techniques; Modified method; Protein localization; Support vector machine algorithm; Theoretical framework; Bioinformatics","Institute of Biophysics and Biomedical Engineering","13141902","","","","Article","Scopus","2-s2.0-84936752802"
"Leng B.; Zhang X.; Yao M.; Xiong Z.","Leng, Biao (23035760100); Zhang, Xiangyang (57195495506); Yao, Ming (56026287600); Xiong, Zhang (7202955989)","23035760100; 57195495506; 56026287600; 7202955989","A 3D model recognition mechanism based on deep Boltzmann machines","2015","Neurocomputing","54","10.1016/j.neucom.2014.06.084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919489106&doi=10.1016%2fj.neucom.2014.06.084&partnerID=40&md5=1b9a4c448f6f584a906a8176a01f516a","School of Computer Science and Engineering, Beihang University, Beijing, 100191, China; School of Computer Science, Carnegie Mellon University, Pittsburgh, 15213, PA, United States","Leng B., School of Computer Science and Engineering, Beihang University, Beijing, 100191, China; Zhang X., School of Computer Science and Engineering, Beihang University, Beijing, 100191, China; Yao M., School of Computer Science, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Xiong Z., School of Computer Science and Engineering, Beihang University, Beijing, 100191, China","The effectiveness of 3D model recognition generally depends on the feature representations and classification methods. Previous algorithms have not shown good capacities to detect 3D model[U+05F3]s feature, thus, they seem not to be competent to recognize 3D model. Meanwhile, recent efforts have illustrated that Deep Boltzmann Machines (DBM) have great power to approximate the distributions of input data, and can archive state-of-the-arts results. In this paper, we propose a novel 3D model recognition mechanism based on DBM, which can be divided into two parts: one is feature detecting based on DBM, and the other is classification based on semi-supervised learning method. During the first part, the high-level abstraction representation can be obtained from a well-trained DBM, and the feature is used in semi-supervised classification method in the second part. The experiments are conducted on publicly available 3D model data sets: Princeton Shape Benchmark (PSB), SHREC[U+05F3]09 and National Taiwan University (NTU). The proposed method is compared with several state-of-the-art methods in terms of several popular evaluation criteria, and the experimental results show better performance of the proposed model. © 2014 Elsevier B.V.","3D model recognition; Deep Boltzmann machines; Semi-supervised learning","3D modeling; Classification (of information); Feature extraction; Semi-supervised learning; Three dimensional computer graphics; Classification methods; Deep boltzmann machines; Feature representation; Model recognition; National Taiwan University; Semi-supervised classification method; Semi-supervised learning methods; State-of-the-art methods; 3D model recognition; algorithm; Article; classification; controlled study; deep Boltzmann machine; human; intermethod comparison; machine learning; performance; recognition; semi supervised learning; three dimensional imaging; Learning systems","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84919489106"
"Kuksa P.P.; Min M.R.; Dugar R.; Gerstein M.","Kuksa, Pavel P. (23091350400); Min, Martin Renqiang (56320769800); Dugar, Rishabh (56971331700); Gerstein, Mark (24755400900)","23091350400; 56320769800; 56971331700; 24755400900","High-order neural networks and kernel methods for peptide-MHC binding prediction","2015","Bioinformatics","28","10.1093/bioinformatics/btv371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947751854&doi=10.1093%2fbioinformatics%2fbtv371&partnerID=40&md5=c47d9d9f6d3aa87723132e0d4d9be694","Institute for Biomedical Informatics, University of Pennsylvania School of Medicine, Philadelphia, 19104, PA, United States; Department of Pathology and Laboratory Medicine, University of Pennsylvania School of Medicine, Philadelphia, 19104, PA, United States; Department of Machine Learning, NEC Laboratories America, Princeton, 08540, NJ, United States; Program of Computational Biology and Bioinformatics, Yale University, New Haven, 06511, CT, United States; Department of Molecular Biophysics and Biochemistry, Yale University, New Haven, 06511, CT, United States; Department of Computer Science, Yale University, New Haven, 06511, CT, United States","Kuksa P.P., Institute for Biomedical Informatics, University of Pennsylvania School of Medicine, Philadelphia, 19104, PA, United States, Department of Pathology and Laboratory Medicine, University of Pennsylvania School of Medicine, Philadelphia, 19104, PA, United States, Department of Machine Learning, NEC Laboratories America, Princeton, 08540, NJ, United States; Min M.R., Department of Machine Learning, NEC Laboratories America, Princeton, 08540, NJ, United States; Dugar R., Department of Machine Learning, NEC Laboratories America, Princeton, 08540, NJ, United States; Gerstein M., Program of Computational Biology and Bioinformatics, Yale University, New Haven, 06511, CT, United States, Department of Molecular Biophysics and Biochemistry, Yale University, New Haven, 06511, CT, United States, Department of Computer Science, Yale University, New Haven, 06511, CT, United States","Motivation: Effective computational methods for peptide-protein binding prediction can greatly help clinical peptide vaccine search and design. However, previous computational methods fail to capture key nonlinear high-order dependencies between different amino acid positions. As a result, they often produce low-quality rankings of strong binding peptides. To solve this problem, we propose nonlinear high-order machine learning methods including high-order neural networks (HONNs) with possible deep extensions and high-order kernel support vector machines to predict major histocompatibility complex-peptide binding. Results: The proposed high-order methods improve quality of binding predictions over other prediction methods. With the proposed methods, a significant gain of up to 25-40% is observed on the benchmark and reference peptide datasets and tasks. In addition, for the first time, our experiments show that pre-training with high-order semi-restricted Boltzmann machines significantly improves the performance of feed-forward HONNs. Moreover, our experiments show that the proposed shallow HONN outperform the popular pre-trained deep neural network on most tasks, which demonstrates the effectiveness of modelling high-order feature interactions for predicting major histocompatibility complex-peptide binding. Availability and implementation: There is no associated distributable software. © The Author 2015. Published by Oxford University Press. All rights reserved.","","Algorithms; Amino Acid Sequence; Area Under Curve; Databases, Protein; Epitopes; Humans; Major Histocompatibility Complex; Molecular Sequence Data; Neural Networks (Computer); Peptides; Protein Binding; ROC Curve; Support Vector Machine; epitope; peptide; protein binding; algorithm; amino acid sequence; area under the curve; artificial neural network; chemistry; human; major histocompatibility complex; metabolism; molecular genetics; protein database; receiver operating characteristic; support vector machine","Oxford University Press","13674803","","BOINF","26206306","Article","Scopus","2-s2.0-84947751854"
"Feng F.; Li R.; Wang X.","Feng, Fangxiang (56432140300); Li, Ruifan (13608752200); Wang, Xiaojie (35235644100)","56432140300; 13608752200; 35235644100","Deep correspondence restricted Boltzmann machine for cross-modal retrieval","2015","Neurocomputing","49","10.1016/j.neucom.2014.12.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924977297&doi=10.1016%2fj.neucom.2014.12.020&partnerID=40&md5=1968fd43a6d5975176fa3484f60fba59","School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China","Feng F., School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Li R., School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Wang X., School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China","The task of cross-modal retrieval, i.e., using a text query to search for images or vice versa, has received considerable attention with the rapid growth of multi-modal web data. Modeling the correlations between different modalities is the key to tackle this problem. In this paper, we propose a correspondence restricted Boltzmann machine (Corr-RBM) to map the original features of bimodal data, such as image and text in our setting, into a low-dimensional common space, in which the heterogeneous data are comparable. In our Corr-RBM, two RBMs built for image and text, respectively are connected at their individual hidden representation layers by a correlation loss function. A single objective function is constructed to trade off the correlation loss and likelihoods of both modalities. Through the optimization of this objective function, our Corr-RBM is able to capture the correlations between two modalities and learn the representation of each modality simultaneously. Furthermore, we construct two deep neural structures using Corr-RBM as the main building block for the task of cross-modal retrieval. A number of comparison experiments are performed on three public real-world data sets. All of our models show significantly better results than state-of-the-art models in both searching images via text query and vice versa. © 2014 Elsevier B.V.","Cross-modal; Deep Learning; Multi-modal; RBM; Retrieval","Economic and social effects; Building blockes; Cross-modal; Heterogeneous data; Multi-modal; Neural structures; Objective functions; Restricted boltzmann machine; Retrieval; Article; artificial neural network; automation; computer model; controlled study; correlational study; correspondence analysis; data analysis; information processing device; information retrieval; intermethod comparison; Internet; learning algorithm; online system; performance measurement system; priority journal; process control; process design; process optimization; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84924977297"
"Shamir R.R.; Dolber T.; Noecker A.M.; Walter B.L.; McIntyre C.C.","Shamir, Reuben R. (13406963900); Dolber, Trygve (37050612700); Noecker, Angela M. (8876191200); Walter, Benjamin L. (7102086635); McIntyre, Cameron C. (7102525112)","13406963900; 37050612700; 8876191200; 7102086635; 7102525112","Machine learning approach to optimizing combined stimulation and medication therapies for Parkinson's disease","2015","Brain Stimulation","53","10.1016/j.brs.2015.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955724849&doi=10.1016%2fj.brs.2015.06.003&partnerID=40&md5=25722e50ff66303ae70598872e3e1758","Department of Biomedical Engineering, Case Western Reserve University, 10900 Euclid Ave, Cleveland, 44106, OH, United States; Department of Neurology, Case Western Reserve University, Cleveland, OH, United States; Neurological Institute, University Hospitals Case Medical Center, Cleveland, OH, United States","Shamir R.R., Department of Biomedical Engineering, Case Western Reserve University, 10900 Euclid Ave, Cleveland, 44106, OH, United States; Dolber T., Department of Biomedical Engineering, Case Western Reserve University, 10900 Euclid Ave, Cleveland, 44106, OH, United States; Noecker A.M., Department of Biomedical Engineering, Case Western Reserve University, 10900 Euclid Ave, Cleveland, 44106, OH, United States; Walter B.L., Department of Neurology, Case Western Reserve University, Cleveland, OH, United States, Neurological Institute, University Hospitals Case Medical Center, Cleveland, OH, United States; McIntyre C.C., Department of Biomedical Engineering, Case Western Reserve University, 10900 Euclid Ave, Cleveland, 44106, OH, United States, Department of Neurology, Case Western Reserve University, Cleveland, OH, United States","Background Deep brain stimulation (DBS) of the subthalamic region is an established therapy for advanced Parkinson's disease (PD). However, patients often require time-intensive post-operative management to balance their coupled stimulation and medication treatments. Given the large and complex parameter space associated with this task, we propose that clinical decision support systems (CDSS) based on machine learning algorithms could assist in treatment optimization. Objective Develop a proof-of-concept implementation of a CDSS that incorporates patient-specific details on both stimulation and medication. Methods Clinical data from 10 patients, and 89 post-DBS surgery visits, were used to create a prototype CDSS. The system was designed to provide three key functions: 1) information retrieval; 2) visualization of treatment, and; 3) recommendation on expected effective stimulation and drug dosages, based on three machine learning methods that included support vector machines, Naïve Bayes, and random forest. Results Measures of medication dosages, time factors, and symptom-specific pre-operative response to levodopa were significantly correlated with post-operative outcomes (P < 0.05) and their effect on outcomes was of similar magnitude to that of DBS. Using those results, the combined machine learning algorithms were able to accurately predict 86% (12/14) of the motor improvement scores at one year after surgery. Conclusions Using patient-specific details, an appropriately parameterized CDSS could help select theoretically optimal DBS parameter settings and medication dosages that have potential to improve the clinical management of PD patients. © 2015 Elsevier Inc.","Clinical decision support system; Deep brain stimulation; Parkinson's disease","Adult; Aged; Antiparkinson Agents; Bayes Theorem; Combined Modality Therapy; Databases, Factual; Deep Brain Stimulation; Female; Follow-Up Studies; Humans; Levodopa; Machine Learning; Male; Middle Aged; Parkinson Disease; Retrospective Studies; Subthalamic Nucleus; Time Factors; Treatment Outcome; levodopa; antiparkinson agent; levodopa; adult; aged; algorithm; Article; Bayesian learning; brain depth stimulation; decision support system; female; human; machine learning; major clinical study; male; nuclear magnetic resonance imaging; outcome assessment; Parkinson disease; priority journal; random forest; support vector machine; Bayes theorem; brain depth stimulation; factual database; follow up; middle aged; multimodality cancer therapy; Parkinson disease; physiology; procedures; retrospective study; standards; subthalamic nucleus; time factor; treatment outcome","Elsevier Inc.","1935861X","","","26140956","Article","Scopus","2-s2.0-84955724849"
"Liang M.; Li Z.; Chen T.; Zeng J.","Liang, Muxuan (56779426100); Li, Zhizhong (55706949200); Chen, Ting (55687667200); Zeng, Jianyang (33468010200)","56779426100; 55706949200; 55687667200; 33468010200","Integrative Data Analysis of Multi-Platform Cancer Data with a Multimodal Deep Learning Approach","2015","IEEE/ACM Transactions on Computational Biology and Bioinformatics","206","10.1109/TCBB.2014.2377729","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939178155&doi=10.1109%2fTCBB.2014.2377729&partnerID=40&md5=ac7549aa5d7efd1e86fb0c9f5ea3408b","Department of Mathematical Sciences, Tsinghua University, Beijing, 100084, China; Department of Statistics, University of Wisconsin-Madison, Madison, 53706, WI, United States; Drug Discovery Oncology Group, Genomics Institute of the Novartis Research Foundation, 75 John Jay Hopkins Drive, San Diego, 92121, CA, United States; Bioinformatics Division, TNLIST and Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; Program in Computational Biology and Bioinformatics, University of Southern California, LA, 90089, CA, United States; Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China","Liang M., Department of Mathematical Sciences, Tsinghua University, Beijing, 100084, China, Department of Statistics, University of Wisconsin-Madison, Madison, 53706, WI, United States; Li Z., Drug Discovery Oncology Group, Genomics Institute of the Novartis Research Foundation, 75 John Jay Hopkins Drive, San Diego, 92121, CA, United States; Chen T., Bioinformatics Division, TNLIST and Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China, Program in Computational Biology and Bioinformatics, University of Southern California, LA, 90089, CA, United States; Zeng J., Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, 100084, China","Identification of cancer subtypes plays an important role in revealing useful insights into disease pathogenesis and advancing personalized therapy. The recent development of high-throughput sequencing technologies has enabled the rapid collection of multi-platform genomic data (e.g., gene expression, miRNA expression, and DNA methylation) for the same set of tumor samples. Although numerous integrative clustering approaches have been developed to analyze cancer data, few of them are particularly designed to exploit both deep intrinsic statistical properties of each input modality and complex cross-modality correlations among multi-platform input data. In this paper, we propose a new machine learning model, called multimodal deep belief network (DBN), to cluster cancer patients from multi-platform observation data. In our integrative clustering framework, relationships among inherent features of each single modality are first encoded into multiple layers of hidden variables, and then a joint latent model is employed to fuse common features derived from multiple input modalities. A practical learning algorithm, called contrastive divergence (CD), is applied to infer the parameters of our multimodal DBN model in an unsupervised manner. Tests on two available cancer datasets show that our integrative data analysis approach can effectively extract a unified representation of latent features to capture both intra- and cross-modality correlations, and identify meaningful disease subtypes from multi-platform cancer data. In addition, our approach can identify key genes and miRNAs that may play distinct roles in the pathogenesis of different cancer subtypes. Among those key miRNAs, we found that the expression level of miR-29a is highly correlated with survival time in ovarian cancer patients. These results indicate that our multimodal DBN based data analysis approach may have practical applications in cancer pathogenesis studies and provide useful guidelines for personalized cancer therapy. © 2015 IEEE.","clinical data; genomic data; identification of cancer subtypes; Multi-platform cancer data analysis; multimodal deep belief network; restricted Boltzmann machine","Computational Biology; Gene Expression Profiling; Humans; Kaplan-Meier Estimate; Machine Learning; MicroRNAs; Neoplasms; Alkylation; Artificial intelligence; Complex networks; Data handling; Disease control; Gene encoding; Gene expression; Genes; Information analysis; Learning algorithms; Learning systems; RNA; microRNA; Cancer subtypes; Clinical data; Deep belief networks; Genomic data; Multi-platform; Restricted boltzmann machine; biology; gene expression profiling; genetics; human; Kaplan Meier method; machine learning; metabolism; mortality; neoplasm; procedures; Diseases","Institute of Electrical and Electronics Engineers Inc.","15455963","","","26357333","Article","Scopus","2-s2.0-84939178155"
"Fonseca P.; Long X.; Radha M.; Haakma R.; Aarts R.M.; Rolink J.","Fonseca, Pedro (8314466800); Long, Xi (35774383200); Radha, Mustafa (56647987000); Haakma, Reinder (6508057219); Aarts, Ronald M. (7004383147); Rolink, Jérôme (56592927200)","8314466800; 35774383200; 56647987000; 6508057219; 7004383147; 56592927200","Sleep stage classification with ECG and respiratory effort","2015","Physiological Measurement","138","10.1088/0967-3334/36/10/2027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947762332&doi=10.1088%2f0967-3334%2f36%2f10%2f2027&partnerID=40&md5=ec3bc555fd09f81510865b8d7f0eb5e7","Philips Research, High Tech Campus 34, Eindhoven, 5656 AE, Netherlands; Department of Electrical Engineering, Eindhoven University of Technology, Postbus 513, Eindhoven, 5600MB, Netherlands; Philips Department for Medical Information Technology, RWTH Aachen University, Pauwelsstrasse 20, Aachen, D-52074, Germany","Fonseca P., Philips Research, High Tech Campus 34, Eindhoven, 5656 AE, Netherlands, Department of Electrical Engineering, Eindhoven University of Technology, Postbus 513, Eindhoven, 5600MB, Netherlands; Long X., Philips Research, High Tech Campus 34, Eindhoven, 5656 AE, Netherlands, Department of Electrical Engineering, Eindhoven University of Technology, Postbus 513, Eindhoven, 5600MB, Netherlands; Radha M., Philips Research, High Tech Campus 34, Eindhoven, 5656 AE, Netherlands; Haakma R., Philips Research, High Tech Campus 34, Eindhoven, 5656 AE, Netherlands; Aarts R.M., Philips Research, High Tech Campus 34, Eindhoven, 5656 AE, Netherlands, Department of Electrical Engineering, Eindhoven University of Technology, Postbus 513, Eindhoven, 5600MB, Netherlands; Rolink J., Philips Department for Medical Information Technology, RWTH Aachen University, Pauwelsstrasse 20, Aachen, D-52074, Germany","Automatic sleep stage classification with cardiorespiratory signals has attracted increasing attention. In contrast to the traditional manual scoring based on polysomnography, these signals can be measured using advanced unobtrusive techniques that are currently available, promising the application for personal and continuous home sleep monitoring. This paper describes a methodology for classifying wake, rapid-eye-movement (REM) sleep, and non-REM (NREM) light and deep sleep on a 30 s epoch basis. A total of 142 features were extracted from electrocardiogram and thoracic respiratory effort measured with respiratory inductance plethysmography. To improve the quality of these features, subject-specific Z-score normalization and spline smoothing were used to reduce between-subject and within-subject variability. A modified sequential forward selection feature selector procedure was applied, yielding 80 features while preventing the introduction of bias in the estimation of cross-validation performance. PSG data from 48 healthy adults were used to validate our methods. Using a linear discriminant classifier and a ten-fold cross-validation, we achieved a Cohen's kappa coefficient of 0.49 and an accuracy of 69% in the classification of wake, REM, light, and deep sleep. These values increased to kappa = 0.56 and accuracy = 80% when the classification problem was reduced to three classes, wake, REM sleep, and NREM sleep. © 2015 Institute of Physics and Engineering in Medicine.","ECG; feature selection; respiratory effort; sleep staging","Adult; Autonomic Nervous System; Electrocardiography; Female; Humans; Machine Learning; Male; Respiration; Signal Processing, Computer-Assisted; Sleep Stages; Biomedical signal processing; Electrocardiography; Eye movements; Feature extraction; Hemodynamics; Wakes; Cardiorespiratory signals; Cross validation; Features selection; Non-rapid eye movements; Polysomnography; Rapid eye movement; Respiratory efforts; Sleep monitoring; Sleep stages classifications; Sleep staging; adult; autonomic nervous system; breathing; electrocardiography; female; human; machine learning; male; physiology; signal processing; sleep stage; Sleep research","IOP Publishing Ltd","09673334","","PMEAE","26289580","Article","Scopus","2-s2.0-84947762332"
"Quang D.; Chen Y.; Xie X.","Quang, Daniel (56205914200); Chen, Yifei (55961779900); Xie, Xiaohui (8311948600)","56205914200; 55961779900; 8311948600","DANN: A deep learning approach for annotating the pathogenicity of genetic variants","2015","Bioinformatics","684","10.1093/bioinformatics/btu703","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928997067&doi=10.1093%2fbioinformatics%2fbtu703&partnerID=40&md5=14895e21a2bc295d820af63554840579","Department of Computer Science, University of California, Irvine, 92697, CA, United States; Center for Complex Biological Systems, University of California, Irvine, 92697, CA, United States","Quang D., Department of Computer Science, University of California, Irvine, 92697, CA, United States, Center for Complex Biological Systems, University of California, Irvine, 92697, CA, United States; Chen Y., Department of Computer Science, University of California, Irvine, 92697, CA, United States; Xie X., Department of Computer Science, University of California, Irvine, 92697, CA, United States, Center for Complex Biological Systems, University of California, Irvine, 92697, CA, United States","Annotating genetic variants, especially non-coding variants, for the purpose of identifying pathogenic variants remains a challenge. Combined annotation-dependent depletion (CADD) is an algorithm designed to annotate both coding and non-coding variants, and has been shown to outperform other annotation algorithms. CADD trains a linear kernel support vector machine (SVM) to differentiate evolutionarily derived, likely benign, alleles from simulated, likely deleterious, variants. However, SVMs cannot capture non-linear relationships among the features, which can limit performance. To address this issue, we have developed DANN. DANN uses the same feature set and training data as CADD to train a deep neural network (DNN). DNNs can capture non-linear relationships among features and are better suited than SVMs for problems with a large number of samples and features. We exploit Compute Unified Device Architecture-compatible graphics processing units and deep learning techniques such as dropout and momentum training to accelerate the DNN training. DANN achieves about a 19% relative reduction in the error rate and about a 14% relative increase in the area under the curve (AUC) metric over CADD's SVM methodology. © The Author 2014. Published by Oxford University Press. All rights reserved.","","Algorithms; Area Under Curve; Computer Graphics; Genetic Variation; Genome, Human; Humans; Molecular Sequence Annotation; Neural Networks (Computer); Selection, Genetic; Support Vector Machine; algorithm; area under the curve; artificial neural network; computer graphics; genetic selection; genetic variation; genetics; human; human genome; molecular genetics; support vector machine","Oxford University Press","13674803","","BOINF","25338716","Article","Scopus","2-s2.0-84928997067"
"Cadieu C.F.; Hong H.; Yamins D.L.K.; Pinto N.; Ardila D.; Solomon E.A.; Majaj N.J.; DiCarlo J.J.","Cadieu, Charles F. (22233507300); Hong, Ha (56121769900); Yamins, Daniel L. K. (8276525500); Pinto, Nicolas (35273071400); Ardila, Diego (56458163000); Solomon, Ethan A. (56200522300); Majaj, Najib J. (6602251596); DiCarlo, James J. (7006387907)","22233507300; 56121769900; 8276525500; 35273071400; 56458163000; 56200522300; 6602251596; 7006387907","Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition","2014","PLoS Computational Biology","418","10.1371/journal.pcbi.1003963","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919607718&doi=10.1371%2fjournal.pcbi.1003963&partnerID=40&md5=49556197d79e26c368fd58faa27234a7","Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, United States; Harvard–MIT Division of Health Sciences and Technology, Institute for Medical Engineering and Science, Massachusetts Institute of Technology, Cambridge, MA, United States","Cadieu C.F., Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, United States; Hong H., Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, United States, Harvard–MIT Division of Health Sciences and Technology, Institute for Medical Engineering and Science, Massachusetts Institute of Technology, Cambridge, MA, United States; Yamins D.L.K., Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, United States; Pinto N., Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, United States; Ardila D., Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, United States; Solomon E.A., Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, United States; Majaj N.J., Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, United States; DiCarlo J.J., Department of Brain and Cognitive Sciences and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, United States","The primate visual system achieves remarkable visual object recognition performance even in brief presentations, and under changes to object exemplar, geometric transformations, and background variation (a.k.a. core visual object recognition). This remarkable performance is mediated by the representation formed in inferior temporal (IT) cortex. In parallel, recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks (DNNs). It remains unclear, however, whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison, a major difficulty has been a unifying metric that accounts for experimental limitations, such as the amount of noise, the number of neural recording sites, and the number of trials, and computational limitations, such as the complexity of the decoding classifier and the number of classifier training examples. In this work, we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology, we propose an extension of “kernel analysis” that measures the generalization accuracy as a function of representational complexity. Our evaluations show that, unlike previous bio-inspired models, the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore, we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT, and on measures of predicting individual IT multi-unit responses. Whether these DNNs rely on computational mechanisms similar to the primate visual system is yet to be determined, but, unlike all previous bio-inspired models, that possibility cannot be ruled out merely on representational performance grounds. © 2014 Cadieu et al.","","Algorithms; Animals; Macaca mulatta; Male; Models, Neurological; Nerve Net; Neural Networks (Computer); Pattern Recognition, Visual; Temporal Lobe; Primates; Complex networks; Mathematical transformations; Object recognition; Background variation; Bioinspired models; Geometric transformations; Inferior temporal cortices; Machine-learning; Neural recordings; Objects recognition; Performance; Visual object recognition; Visual systems; adult; animal experiment; Article; artificial neural network; classifier; comparative study; core visual object recognition; deep neural network; inferior temporal cortex; kernel method; male; mathematical computing; mental performance; nerve cell; noise; nonhuman; prediction; visual memory; visual system; algorithm; animal; biological model; nerve cell network; pattern recognition; physiology; rhesus monkey; temporal lobe; Deep neural networks","Public Library of Science","1553734X","","","25521294","Article","Scopus","2-s2.0-84919607718"
"Kim K.B.; Song D.H.; Woo Y.W.","Kim, Kwang Baek (35198380700); Song, Doo Heon (23390773300); Woo, Young Woon (15074387000)","35198380700; 23390773300; 15074387000","Machine intelligence can guide pet dog health pre-diagnosis for casual owner: A neural network approach","2014","International Journal of Bio-Science and Bio-Technology","6","10.14257/ijbsbt.2014.6.2.08","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899669847&doi=10.14257%2fijbsbt.2014.6.2.08&partnerID=40&md5=41bae9122856bebfe406fd35b3b1c5ca","Department of Computer Engineering, Silla University, Sasang-gu, Busan 617-736, 140 Baegyang-daero(Blvd) 700beon-gil(Rd), South Korea; Department of Computer Games, Yong-In Songdam College, Mapyeong-dong, Cheoin-gu, Yongin 449-040, South Korea; Department of Multimedia Engineering, Dong-Eui University, Busanjin-gu, Busan 614-714, Gaya 3-dong, South Korea","Kim K.B., Department of Computer Engineering, Silla University, Sasang-gu, Busan 617-736, 140 Baegyang-daero(Blvd) 700beon-gil(Rd), South Korea; Song D.H., Department of Computer Games, Yong-In Songdam College, Mapyeong-dong, Cheoin-gu, Yongin 449-040, South Korea; Woo Y.W., Department of Multimedia Engineering, Dong-Eui University, Busanjin-gu, Busan 614-714, Gaya 3-dong, South Korea","In this paper, we developed a health pre-diagnosis system with ART2 neural network for Pet dog health monitoring. This system is for the pet owner who does not have deep knowledge on the pet diseases nor computer technology. The standardized database of symptoms/diseases associations is constructed from textbooks and the user simply gives the most unusual symptom that is found from the dog and then the communication between the user and the system refines and expands the input symptoms through queries. Then an unsupervised ART2 learning system checks the similarity between input and stored diseases with confidence and generates three most probable diseases as output. The system has incremental learning ability and learning by experience ability thus appropriately changes the database over time even without user's database update. In spite of the fact that the system is ad-hoc in nature, the system's performance is verified by veterinarian as adequate and it can stimulate the owner's attention on the dog's abnormality in time such that appropriate professional treatment is given in its early stage. © 2014 SERSC.","ART2; Health diagnosis; Pet dog; Symptom-disease association; Unsupervised learning","","Science and Engineering Research Support Society","22337849","","","","Article","Scopus","2-s2.0-84899669847"
"Schulz H.; Cho K.; Raiko T.; Behnke S.","Schulz, Hannes (24470137900); Cho, Kyunghyun (55722769200); Raiko, Tapani (14032013000); Behnke, Sven (13007277900)","24470137900; 55722769200; 14032013000; 13007277900","Two-layer contractive encodings for learning stable nonlinear features","2015","Neural Networks","19","10.1016/j.neunet.2014.09.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922351373&doi=10.1016%2fj.neunet.2014.09.008&partnerID=40&md5=85d95b59a3b03f3993f1bc2b7292e07b","Autonomous Intelligent Systems, Computer Science Institute VI, University of Bonn, Germany; Department of Information and Computer Science, Aalto University School of Science, Finland","Schulz H., Autonomous Intelligent Systems, Computer Science Institute VI, University of Bonn, Germany; Cho K., Department of Information and Computer Science, Aalto University School of Science, Finland; Raiko T., Department of Information and Computer Science, Aalto University School of Science, Finland; Behnke S., Autonomous Intelligent Systems, Computer Science Institute VI, University of Bonn, Germany","Unsupervised learning of feature hierarchies is often a good strategy to initialize deep architectures for supervised learning. Most existing deep learning methods build these feature hierarchies layer by layer in a greedy fashion using either auto-encoders or restricted Boltzmann machines. Both yield encoders which compute linear projections of input followed by a smooth thresholding function. In this work, we demonstrate that these encoders fail to find stable features when the required computation is in the exclusive-or class. To overcome this limitation, we propose a two-layer encoder which is less restricted in the type of features it can learn. The proposed encoder is regularized by an extension of previous work on contractive regularization. This proposed two-layer contractive encoder potentially poses a more difficult optimization problem, and we further propose to linearly transform hidden neurons of the encoder to make learning easier. We demonstrate the advantages of the two-layer encoders qualitatively on artificially constructed datasets as well as commonly used benchmark datasets. We also conduct experiments on a semi-supervised learning task and show the benefits of the proposed two-layer encoders trained with the linear transformation of perceptrons. © 2014 Elsevier Ltd.","Deep learning; Linear transformation; Multi-layer perceptron; Pretraining; Semi-supervised learning; Two-layer contractive encoding","Algorithms; Artificial Intelligence; Neural Networks (Computer); Encoding (symbols); Learning systems; Linear transformations; Optimization; Supervised learning; Deep learning; Multi layer perceptron; Pre-training; Semi- supervised learning; Two-layer; Article; artificial neural network; information processing; learning algorithm; linear system; mathematical computing; mathematical variable; nonlinear system; validation study; algorithm; artificial intelligence; artificial neural network; Mathematical transformations","Elsevier Ltd","08936080","","NNETE","25292461","Article","Scopus","2-s2.0-84922351373"
"Menchón-Lara R.-M.; Sancho-Gómez J.-L.","Menchón-Lara, Rosa-María (37861864700); Sancho-Gómez, José-Luis (8842587300)","37861864700; 8842587300","Fully automatic segmentation of ultrasound common carotid artery images based on machine learning","2015","Neurocomputing","58","10.1016/j.neucom.2014.09.066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922693250&doi=10.1016%2fj.neucom.2014.09.066&partnerID=40&md5=212875726366346687042da9e172e970","Dpto. Tecnologías de la Información y las Comunicaciones, Universidad Politécnica de Cartagena, Plaza del Hospital, 1, Murcia, 30202 Cartagena, Spain","Menchón-Lara R.-M., Dpto. Tecnologías de la Información y las Comunicaciones, Universidad Politécnica de Cartagena, Plaza del Hospital, 1, Murcia, 30202 Cartagena, Spain; Sancho-Gómez J.-L., Dpto. Tecnologías de la Información y las Comunicaciones, Universidad Politécnica de Cartagena, Plaza del Hospital, 1, Murcia, 30202 Cartagena, Spain","Atherosclerosis is responsible for a large proportion of cardiovascular diseases (CVD), which are the leading cause of death in the world. The atherosclerotic process is a complex degenerative condition mainly affecting the medium- and large-size arteries, which begins in childhood and may remain unnoticed during decades. It causes thickening and the reduction of elasticity in the blood vessels. An early diagnosis of this condition is crucial to prevent patients from suffering more serious pathologies (heart attacks and strokes). The evaluation of the Intima-Media Thickness (IMT) of the Common Carotid Artery (CCA) in B-mode ultrasound images is considered the most useful tool for the investigation of preclinical atherosclerosis. Usually, it is manually measured by the radiologists. This paper proposes a fully automatic segmentation technique based on Machine Learning and Statistical Pattern Recognition to measure IMT from ultrasound CCA images. The pixels are classified by means of artificial neural networks to identify the IMT boundaries. Moreover, the concepts of Auto-Encoders (AE) and Deep Learning have been included in the classification strategy. The suggested approach is tested on a set of 55 longitudinal ultrasound images of the CCA by comparing the automatic segmentation with four manual tracings. © 2014 Elsevier B.V.","Atherosclerosis; Auto-encoders; Deep learning; Intima-media thickness; Pattern recognition; Ultrasound imaging","Artificial intelligence; Blood vessels; Complex networks; Diagnosis; Diseases; Learning systems; Neural networks; Pathology; Pattern recognition; Ultrasonic applications; Ultrasonic imaging; Atherosclerosis; Auto encoders; Deep learning; Intima-media thickness; Ultrasound imaging; accuracy; arterial wall thickness; Article; atherosclerosis; automated pattern recognition; B scan; calculation; carotid artery; image analysis; image quality; machine learning; mathematical analysis; ultrasound; ultrasound scanner; Image segmentation","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84922693250"
"Dong Z.; Tian X.","Dong, Zhe (56595413300); Tian, Xinmei (16643535600)","56595413300; 16643535600","Multi-level photo quality assessment with multi-view features","2015","Neurocomputing","44","10.1016/j.neucom.2015.05.095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937814418&doi=10.1016%2fj.neucom.2015.05.095&partnerID=40&md5=68c191e95866edacef647bd09e2e91cb","CAS Key Laboratory of Technology, Geo-spatial Information Processing and Application System, University of Science and Technology of China, Hefei, Anhui, China","Dong Z., CAS Key Laboratory of Technology, Geo-spatial Information Processing and Application System, University of Science and Technology of China, Hefei, Anhui, China; Tian X., CAS Key Laboratory of Technology, Geo-spatial Information Processing and Application System, University of Science and Technology of China, Hefei, Anhui, China","Photo quality assessment using the principles of visual aesthetics has been a hot research topic in recent years. Due to the complexity of human aesthetic activities, this task is very challenging. Most existing works apply binary labels (""good"" or ""bad"") to represent the photo quality, and focus on constructing rule-based features under the guidance of photography knowledge. However, those features strictly imitate photography rules and suffer from low effectiveness and high computational cost. Besides, the binary quality representation is oversimplified and fails to distinguish varying quality degrees. To tackle these problems, we construct new effective and efficient features from different views and further fuse them to predict multi-level, instead of binary, photo quality. More specifically, we design a set of compact rule-based features through careful analyses on photographic rules and aesthetic attributes. We propose using Deep Convolutional Neural Network (DCNN) descriptor, which encodes the photo content thoroughly, to implicitly describe the photo quality. Experiments conducted on two large scale benchmark datasets verify the effectiveness of these two different kinds of features. Furthermore, we propose a method to combine these features for multi-level photo quality prediction. This feature fusion method has proven to be effective on a dataset that is carefully organized to support research on this new multi-level photo quality assessment problem. © 2015 Elsevier B.V.","Image aesthetics; Multi-kernel learning; Multi-view feature fusion; Photo quality assessment","Convolutional neural networks; Deep neural networks; Photography; Aesthetic attributes; Computational costs; Feature fusion; Feature fusion method; Hot research topics; Image Aesthetics; Multi-kernel learning; Photo quality; algorithm; Article; artificial neural network; computer; cost; esthetics; human; image quality; machine learning; photography; priority journal; quality control; task performance; Large dataset","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84937814418"
"Cui Y.; Shi J.; Wang Z.","Cui, Yiqian (55357075600); Shi, Junyou (12803305500); Wang, Zili (8982392900)","55357075600; 12803305500; 8982392900","Complex Rotation Quantum Dynamic Neural Networks (CRQDNN) using Complex Quantum Neuron (CQN): Applications to time series prediction","2015","Neural Networks","23","10.1016/j.neunet.2015.07.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939502419&doi=10.1016%2fj.neunet.2015.07.013&partnerID=40&md5=f35409239471ddf49b128d96852505de","School of Reliability and Systems Engineering, Beihang University, Beijing, China; Science and Technology Key Laboratory on Reliability and Environmental Engineering, Beihang University, Beijing, China","Cui Y., School of Reliability and Systems Engineering, Beihang University, Beijing, China, Science and Technology Key Laboratory on Reliability and Environmental Engineering, Beihang University, Beijing, China; Shi J., School of Reliability and Systems Engineering, Beihang University, Beijing, China, Science and Technology Key Laboratory on Reliability and Environmental Engineering, Beihang University, Beijing, China; Wang Z., School of Reliability and Systems Engineering, Beihang University, Beijing, China, Science and Technology Key Laboratory on Reliability and Environmental Engineering, Beihang University, Beijing, China","Quantum Neural Networks (QNN) models have attracted great attention since it innovates a new neural computing manner based on quantum entanglement. However, the existing QNN models are mainly based on the real quantum operations, and the potential of quantum entanglement is not fully exploited. In this paper, we proposes a novel quantum neuron model called Complex Quantum Neuron (CQN) that realizes a deep quantum entanglement. Also, a novel hybrid networks model Complex Rotation Quantum Dynamic Neural Networks (CRQDNN) is proposed based on Complex Quantum Neuron (CQN). CRQDNN is a three layer model with both CQN and classical neurons. An infinite impulse response (IIR) filter is embedded in the Networks model to enable the memory function to process time series inputs. The Levenberg-Marquardt (LM) algorithm is used for fast parameter learning. The networks model is developed to conduct time series predictions. Two application studies are done in this paper, including the chaotic time series prediction and electronic remaining useful life (RUL) prediction. © 2015 Elsevier Ltd.","Chaotic time series prediction; Complex Quantum Neuron (CQN); Infinite Impulse Response (IIR); Quantum entanglement; Remaining Useful Life (RUL) prediction","Algorithms; Computer Simulation; Computers, Hybrid; Forecasting; Machine Learning; Neural Networks (Computer); Neurons; Prognosis; Quantum Theory; Rotation; Complex networks; Forecasting; IIR filters; Impulse response; Neural networks; Neurons; Quantum theory; Rotation; Time series; Application studies; Chaotic time series prediction; Infinite impulse response; Levenberg-Marquardt algorithm; Quantum neural networks; Quantum neuron; Remaining useful life predictions; Time series prediction; Article; artificial neural network; complex quantum neuron model; complex rotation quantum dynamic neural network; controlled study; electronics; learning algorithm; mathematical model; prediction; priority journal; time series analysis; algorithm; computer simulation; forecasting; hybrid computer; machine learning; nerve cell; prognosis; quantum theory; rotation; Quantum entanglement","Elsevier Ltd","08936080","","NNETE","26277609","Article","Scopus","2-s2.0-84939502419"
"Shen F.; Chao J.; Zhao J.","Shen, Furao (24482362400); Chao, Jing (53863299300); Zhao, Jinxi (56144098100)","24482362400; 53863299300; 56144098100","Forecasting exchange rate using deep belief networks and conjugate gradient method","2015","Neurocomputing","217","10.1016/j.neucom.2015.04.071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952629849&doi=10.1016%2fj.neucom.2015.04.071&partnerID=40&md5=78a1218fac5686cd410cb7fa33ad90bf","National Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, China","Shen F., National Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, China; Chao J., National Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, China; Zhao J., National Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, China","Forecasting exchange rates is an important financial problem. In this paper, an improved deep belief network (DBN) is proposed for forecasting exchange rates. By using continuous restricted Boltzmann machines (CRBMs) to construct a DBN, we update the classical DBN to model continuous data. The structure of DBN is optimally determined through experiments for application in exchange rates forecasting. Also, conjugate gradient method is applied to accelerate the learning for DBN. In the experiments, three exchange rate series are tested and six evaluation criteria are adopted to evaluate the performance of the proposed method. Comparison with typical forecasting methods such as feed forward neural network (FFNN) shows that the proposed method is applicable to the prediction of foreign exchange rate and works better than traditional methods. © 2015 Elsevier B.V.","Conjugate gradient; Continuous restricted Boltmann machines; Deep belief networks; Exchange rate forecasting","Bayesian networks; Finance; Forecasting; Deep belief network (DBN); Deep belief networks; Evaluation criteria; Exchange rate forecasting; Financial problems; Forecasting methods; Foreign exchange rates; Restricted boltzmann machine; Article; artificial neural network; conjugate gradient method; continuous restricted Boltzmann machine; controlled study; deep belief network; feed forward neural network; forecasting; forecasting exchange rate; learning algorithm; machine learning; mathematical computing; mathematical model; priority journal; statistical analysis; time series analysis; Conjugate gradient method","Elsevier","09252312","","NRCGE","","Article","Scopus","2-s2.0-84952629849"
"Nikfarjam A.; Sarker A.; O'Connor k.; Ginn R.; Gonzalez G.","Nikfarjam, Azadeh (36069663700); Sarker, Abeed (36976315000); O'Connor, Karen (56596185000); Ginn, Rachel (56596524300); Gonzalez, Graciela (57212403040)","36069663700; 36976315000; 56596185000; 56596524300; 57212403040","Pharmacovigilance from social media: Mining adverse drug reaction mentions using sequence labeling with word embedding cluster features","2015","Journal of the American Medical Informatics Association","410","10.1093/jamia/ocu041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927943705&doi=10.1093%2fjamia%2focu041&partnerID=40&md5=dc955fbfee204d2b0dea451a25fe940e","Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ, United States","Nikfarjam A., Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ, United States; Sarker A., Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ, United States; O'Connor k., Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ, United States; Ginn R., Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ, United States; Gonzalez G., Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ, United States","Objective Social media is becoming increasingly popular as a platform for sharing personal health-related information. This information can be utilized for public health monitoring tasks, particularly for pharmacovigilance, via the use of natural language processing (NLP) techniques. However, the language in social media is highly informal, and userexpressed medical concepts are often nontechnical, descriptive, and challenging to extract. There has been limited progress in addressing these challenges, and thus far, advanced machine learning-based NLP techniques have been underutilized. Our objective is to design a machine learning-based approach to extract mentions of adverse drug reactions (ADRs) from highly informal text in social media. Methods: We introduce ADRMine, a machine learning-based concept extraction system that uses conditional random fields (CRFs). ADRMine utilizes a variety of features, including a novel feature for modeling words' semantic similarities. The similarities are modeled by clustering words based on unsupervised, pretrained word representation vectors (embeddings) generated from unlabeled user posts in social media using a deep learning technique. Results: ADRMine outperforms several strong baseline systems in the ADR extraction task by achieving an F-measure of 0.82. Feature analysis demonstrates that the proposed word cluster features significantly improve extraction performance. Conclusion: It is possible to extract complex medical concepts, with relatively high performance, from informal, usergenerated content. Our approach is particularly scalable, suitable for social media mining, as it relies on large volumes of unlabeled data, thus diminishing the need for large, annotated training data sets. © The Author 2015.","ADR; Adverse drug reaction; Deep learning word embeddings; Machine learning; Natural language processing; Pharmacovigilance; Social media mining","Artificial Intelligence; Data Mining; Humans; Natural Language Processing; Pharmacovigilance; Semantics; Social Media; acetylsalicylic acid; amphetamine plus dexamphetamine; aripiprazole; citalopram; lorazepam; paroxetine; quetiapine; venlafaxine; zolpidem tartrate; Article; data mining; drug surveillance program; hangover; headache; heartburn; human; machine learning; natural language processing; rash; semantics; social media; taste disorder; tremor; urticaria; artificial intelligence; data mining; procedures","Oxford University Press","10675027","","JAMAF","25755127","Article","Scopus","2-s2.0-84927943705"
"Ma J.; Sheridan R.P.; Liaw A.; Dahl G.E.; Svetnik V.","Ma, Junshui (7406201988); Sheridan, Robert P. (7201693208); Liaw, Andy (6507847347); Dahl, George E. (47061061200); Svetnik, Vladimir (6507549661)","7406201988; 7201693208; 6507847347; 47061061200; 6507549661","Deep neural nets as a method for quantitative structure-activity relationships","2015","Journal of Chemical Information and Modeling","805","10.1021/ci500747n","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923367417&doi=10.1021%2fci500747n&partnerID=40&md5=86957b2aa58b3fd7a9c71f3a1ab77aed","Biometrics Research Department, Merck Research Laboratories, Rahway, 07065, NJ, United States; Structural Chemistry Department, Merck Research Laboratories, Rahway, 07065, NJ, United States; Computer Science Department, University of Toronto, Toronto, ON M5S, ON, Canada","Ma J., Biometrics Research Department, Merck Research Laboratories, Rahway, 07065, NJ, United States; Sheridan R.P., Structural Chemistry Department, Merck Research Laboratories, Rahway, 07065, NJ, United States; Liaw A., Biometrics Research Department, Merck Research Laboratories, Rahway, 07065, NJ, United States; Dahl G.E., Computer Science Department, University of Toronto, Toronto, ON M5S, ON, Canada; Svetnik V., Biometrics Research Department, Merck Research Laboratories, Rahway, 07065, NJ, United States","Neural networks were widely used for quantitative structure-activity relationships (QSAR) in the 1990s. Because of various practical issues (e.g., slow on large problems, difficult to train, prone to overfitting, etc.), they were superseded by more robust methods like support vector machine (SVM) and random forest (RF), which arose in the early 2000s. The last 10 years has witnessed a revival of neural networks in the machine learning community thanks to new methods for preventing overfitting, more efficient training algorithms, and advancements in computer hardware. In particular, deep neural nets (DNNs), i.e. neural nets with more than one hidden layer, have found great successes in many applications, such as computer vision and natural language processing. Here we show that DNNs can routinely make better prospective predictions than RF on a set of large diverse QSAR data sets that are taken from Mercks drug discovery effort. The number of adjustable parameters needed for DNNs is fairly large, but our results show that it is not necessary to optimize them for individual data sets, and a single set of recommended parameters can achieve better performance than RF for most of the data sets we studied. The usefulness of the parameters is demonstrated on additional data sets not used in the calibration. Although training DNNs is still computationally intensive, using graphical processing units (GPUs) can make this issue manageable. © 2015 American Chemical Society.","","Algorithms; Drug Discovery; Machine Learning; Neural Networks (Computer); Prospective Studies; Quantitative Structure-Activity Relationship; Support Vector Machine; Workflow; Computational chemistry; Computer hardware; Decision trees; Deep neural networks; Graphics processing unit; Molecular graphics; Natural language processing systems; Program processors; Support vector machines; Adjustable parameters; Graphical processing unit (GPUs); Machine learning communities; NAtural language processing; Practical issues; Quantitative structure activity relationship; Quantitative structure-activity relationships; Training algorithms; algorithm; artificial neural network; drug development; machine learning; prospective study; quantitative structure activity relation; support vector machine; workflow; Neural networks","American Chemical Society","15499596","","JCISD","25635324","Article","Scopus","2-s2.0-84923367417"
"Dudley D.M.; Bailey A.L.; Mehta S.H.; Hughes A.L.; Kirk G.D.; Westergaard R.P.; O'Connor D.H.","Dudley, Dawn M. (26532672700); Bailey, Adam L. (35336006400); Mehta, Shruti H. (7401670716); Hughes, Austin L. (7401766103); Kirk, Gregory D. (35454021400); Westergaard, Ryan P. (8379194500); O'Connor, David H. (57202042675)","26532672700; 35336006400; 7401670716; 7401766103; 35454021400; 8379194500; 57202042675","Cross-clade simultaneous HIV drug resistance genotyping for reverse transcriptase, protease, and integrase inhibitor mutations by Illumina MiSeq","2014","Retrovirology","32","10.1186/s12977-014-0122-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924275201&doi=10.1186%2fs12977-014-0122-8&partnerID=40&md5=9f4bbf3136a2c7790d8e0e1585f43e64","Department of Pathology and Laboratory Medicine, University of Wisconsin School of Medicine and Public Health, Madison, WI, United States; Department of Epidemiology, Epidemiology and Oncology, Johns Hopkins University, Baltimore, MD, United States; Department of Biology, University of South Carolina, Columbia, SC, United States; Departments of Medicine, Epidemiology and Oncology, Johns Hopkins University, Baltimore, MD, United States; Department of Medicine, Division of Infectious Disease, University of Wisconsin School of Medicine and Public Health, Madison, WI, United States","Dudley D.M., Department of Pathology and Laboratory Medicine, University of Wisconsin School of Medicine and Public Health, Madison, WI, United States; Bailey A.L., Department of Pathology and Laboratory Medicine, University of Wisconsin School of Medicine and Public Health, Madison, WI, United States; Mehta S.H., Department of Epidemiology, Epidemiology and Oncology, Johns Hopkins University, Baltimore, MD, United States; Hughes A.L., Department of Biology, University of South Carolina, Columbia, SC, United States; Kirk G.D., Departments of Medicine, Epidemiology and Oncology, Johns Hopkins University, Baltimore, MD, United States; Westergaard R.P., Department of Medicine, Division of Infectious Disease, University of Wisconsin School of Medicine and Public Health, Madison, WI, United States; O'Connor D.H., Department of Pathology and Laboratory Medicine, University of Wisconsin School of Medicine and Public Health, Madison, WI, United States","Background: Viral resistance to antiretroviral therapy threatens our best methods to control and prevent HIV infection. Current drug resistance genotyping methods are costly, optimized for subtype B virus, and primarily detect resistance mutations to protease and reverse transcriptase inhibitors. With the increasing use of integrase inhibitors in first-line therapies, monitoring for integrase inhibitor drug resistance mutations is a priority. We designed a universal primer pair to PCR amplify all major group M HIV-1 viruses for genotyping using Illumina MiSeq to simultaneously detect drug resistance mutations associated with protease, nucleoside reverse transcriptase, non-nucleoside reverse transcriptase, and integrase inhibitors. Results: A universal primer pair targeting the HIV pol gene was used to successfully PCR amplify HIV isolates representing subtypes A, B, C, D, CRF01_AE and CRF02_AG. The universal primers were then tested on 62 samples from a US cohort of injection drug users failing treatment after release from prison. 94% of the samples were successfully genotyped for known drug resistance mutations in the protease, reverse transcriptase and integrase gene products. Control experiments demonstrate that mutations present at ≥ 2% frequency are reliably detected and above the threshold of error for this method. New drug resistance mutations not found in the baseline sample were identified in 54% of the patient samples after treatment failure. 86% of patients with major drug resistance mutations had 1 or more mutations associated with drug resistance to the treatment regimen at the time point of treatment failure. 59% of the emerging mutations were found at frequencies between 2% and 20% of the total sequences generated, below the estimated limit of detection of current FDA-approved genotyping techniques. Primary plasma samples with viral loads as low as 799 copies/ml were successfully genotyped using this method. Conclusions: Here we present an Illumina MiSeq-based HIV drug resistance genotyping assay. Our data suggests that this universal assay works across all major group M HIV-1 subtypes and identifies all drug resistance mutations in the pol gene known to confer resistance to protease, reverse transcriptase and integrase inhibitors. This high-throughput and sensitive assay could significantly improve access to drug resistance genotyping worldwide. © Dudley et al.","Antiretroviral therapy; Deep sequencing; Drug resistance genotyping; HIV drug resistance; Human immunodeficiency virus; Illumina MiSeq; Integrase inhibitor genotyping","Anti-HIV Agents; DNA Primers; Drug Resistance, Viral; Genotyping Techniques; High-Throughput Nucleotide Sequencing; HIV Infections; HIV Integrase; HIV Protease; HIV Reverse Transcriptase; HIV-1; Humans; Microbial Sensitivity Tests; Mutation, Missense; Polymerase Chain Reaction; Sensitivity and Specificity; Cercopithecine herpesvirus 1; Human immunodeficiency virus; Human immunodeficiency virus 1; integrase inhibitor; nonnucleoside reverse transcriptase inhibitor; proteinase inhibitor; RNA directed DNA polymerase inhibitor; virus DNA; virus RNA; anti human immunodeficiency virus agent; Human immunodeficiency virus proteinase; integrase; primer DNA; RNA directed DNA polymerase; adolescent; adult; analytical error; application service provider; Article; child; cladistics; controlled study; data analysis; data analysis software; drug database; genotyping technique; highly active antiretroviral therapy; human; Human immunodeficiency virus; Human immunodeficiency virus 1 (strain HXB2); Human immunodeficiency virus 1 group M; Human immunodeficiency virus infection; Human immunodeficiency virus type 1 subtype A; Human immunodeficiency virus type 1 subtype B; Human immunodeficiency virus type 1 subtype C; Human immunodeficiency virus type 1 subtype CRF01 AE; Human immunodeficiency virus type 1 subtype CRF02 AG; Human immunodeficiency virus type 1 subtype D; information processing device; machine learning; major clinical study; next generation sequencing; nonhuman; structural gene; treatment failure; virus examination; virus load; virus mutation; virus resistance; antiviral resistance; drug effects; enzymology; genetics; genotyping technique; high throughput sequencing; Human immunodeficiency virus 1; Human immunodeficiency virus infection; isolation and purification; microbial sensitivity test; missense mutation; polymerase chain reaction; procedures; sensitivity and specificity; virology","BioMed Central Ltd.","17424690","","","25533166","Article","Scopus","2-s2.0-84924275201"
"Ding X.; Cheng F.; Cao C.; Sun X.","Ding, Xiao (55459305600); Cheng, Fudong (56888292300); Cao, Changchang (55897208700); Sun, Xiao (7405626068)","55459305600; 56888292300; 55897208700; 7405626068","DectICO: An alignment-free supervised metagenomic classification method based on feature extraction and dynamic selection","2015","BMC Bioinformatics","8","10.1186/s12859-015-0753-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959165678&doi=10.1186%2fs12859-015-0753-3&partnerID=40&md5=74c9b6ef553542de330f015157563d1e","Southeast University, State Key Laboratory of Bioelectronics, School of Biological Science and Medical Engineering, Nanjing, 210096, China","Ding X., Southeast University, State Key Laboratory of Bioelectronics, School of Biological Science and Medical Engineering, Nanjing, 210096, China; Cheng F., Southeast University, State Key Laboratory of Bioelectronics, School of Biological Science and Medical Engineering, Nanjing, 210096, China; Cao C., Southeast University, State Key Laboratory of Bioelectronics, School of Biological Science and Medical Engineering, Nanjing, 210096, China; Sun X., Southeast University, State Key Laboratory of Bioelectronics, School of Biological Science and Medical Engineering, Nanjing, 210096, China","Background: Continual progress in next-generation sequencing allows for generating increasingly large metagenomes which are over time or space. Comparing and classifying the metagenomes with different microbial communities is critical. Alignment-free supervised classification is important for discriminating between the multifarious components of metagenomic samples, because it can be accomplished independently of known microbial genomes. Results: We propose an alignment-free supervised metagenomic classification method called DectICO. The intrinsic correlation of oligonucleotides provides the feature set, which is selected dynamically using a kernel partial least squares algorithm, and the feature matrices extracted with this set are sequentially employed to train classifiers by support vector machine (SVM). We evaluated the classification performance of DectICO on three actual metagenomic sequencing datasets, two containing deep sequencing metagenomes and one of low coverage. Validation results show that DectICO is powerful, performs well based on long oligonucleotides (i.e., 6-mer to 8-mer), and is more stable and generalized than a sequence-composition-based method. The classifiers trained by our method are more accurate than non-dynamic feature selection methods and a recently published recursive-SVM-based classification approach. Conclusions: The alignment-free supervised classification method DectICO can accurately classify metagenomic samples without dependence on known microbial genomes. Selecting the ICO dynamically offers better stability and generality compared with sequence-composition-based classification algorithms. Our proposed method provides new insights in metagenomic sample classification. © 2015 Ding et al.","Alignment-free; Classification; Feature selection; Metagenome; Sequence feature","Algorithms; Bacteria; Least-Squares Analysis; Metagenome; Metagenomics; Support Vector Machine; Feature extraction; Genes; Least squares approximations; Oligonucleotides; Supervised learning; Support vector machines; Alignment-free; Classification performance; Dynamic feature selections; Kernel partial least squares; Metagenomes; Next-generation sequencing; Sequence features; Supervised classification; algorithm; bacterium; classification; genetics; least square analysis; metagenome; metagenomics; procedures; support vector machine; Classification (of information)","BioMed Central Ltd.","14712105","","BBMIC","26446672","Article","Scopus","2-s2.0-84959165678"
"Kleftogiannis D.; Kalnis P.; Bajic V.B.","Kleftogiannis, Dimitrios (36975690000); Kalnis, Panos (6603477534); Bajic, Vladimir B. (35377862500)","36975690000; 6603477534; 35377862500","DEEP: A general computational framework for predicting enhancers","2015","Nucleic Acids Research","94","10.1093/nar/gku1058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943143082&doi=10.1093%2fnar%2fgku1058&partnerID=40&md5=fc450105f9b4e2a4b0d15f0c9d04f307","CEMSE, KAUST, Thuwal, 23955-6900, Saudi Arabia; CBRC, CEMSE, KAUST, Thuwal, 23955-6900, Saudi Arabia","Kleftogiannis D., CEMSE, KAUST, Thuwal, 23955-6900, Saudi Arabia; Kalnis P., CEMSE, KAUST, Thuwal, 23955-6900, Saudi Arabia; Bajic V.B., CBRC, CEMSE, KAUST, Thuwal, 23955-6900, Saudi Arabia","Transcription regulation in multicellular eukaryotes is orchestrated by a number of DNA functional elements located at gene regulatory regions. Some regulatory regions (e.g. enhancers) are located far away from the gene they affect. Identification of distal regulatory elements is a challenge for the bioinformatics research. Although existing methodologies increased the number of computationally predicted enhancers, performance inconsistency of computational models across different cell-lines, class imbalance within the learning sets and ad hoc rules for selecting enhancer candidates for supervised learning, are some key questions that require further examination. In this study we developed DEEP, a novel ensemble prediction framework. DEEP integrates three components with diverse characteristics that streamline the analysis of enhancer's properties in a great variety of cellular conditions. In our method we train many individual classification models that we combine to classify DNA regions as enhancers or non-enhancers. DEEP uses features derived from histone modification marks or attributes coming from sequence characteristics. Experimental results indicate that DEEP performs better than four state-of-the-art methods on the ENCODE data. We report the first computational enhancer prediction results on FANTOM5 data where DEEP achieves 90.2% accuracy and 90% geometric mean (GM) of specificity and sensitivity across 36 different tissues. We further present results derived using in vivo-derived enhancer data from VISTA database. DEEP-VISTA, when tested on an independent test set, achieved GM of 80.1% and accuracy of 89.64%. DEEP framework is publicly available at http://cbrc.kaust.edu.sa/deep/. © 2014 The Author(s).","","Chromatin Immunoprecipitation; Enhancer Elements, Genetic; Genomics; HeLa Cells; Histones; Humans; K562 Cells; Sequence Analysis, DNA; Support Vector Machine; Transcription Factors; histone; transcription factor; chromatin immunoprecipitation; DNA sequence; enhancer region; genomics; HeLa cell line; human; K562 cell line; metabolism; procedures; support vector machine; validation study","Oxford University Press","03051048","","NARHA","25378307","Article","Scopus","2-s2.0-84943143082"
"Khuwaja G.A.; Haghighi S.J.; Hatzinakos D.","Khuwaja, Gulzar A (6701896423); Haghighi, Sahar Javaher (36164113000); Hatzinakos, Dimitrios (7004380329)","6701896423; 36164113000; 7004380329","40-Hz ASSR fusion classification system for observing sleep patterns","2015","Eurasip Journal on Bioinformatics and Systems Biology","3","10.1186/s13637-014-0021-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922586919&doi=10.1186%2fs13637-014-0021-2&partnerID=40&md5=c7f6df688473a18f1c3cb9e872a8df9a","Department of Electrical and Computer Engineering, University of Toronto, 40 St. George Street, Toronto, M5S 2E4, ON, Canada","Khuwaja G.A., Department of Electrical and Computer Engineering, University of Toronto, 40 St. George Street, Toronto, M5S 2E4, ON, Canada; Haghighi S.J., Department of Electrical and Computer Engineering, University of Toronto, 40 St. George Street, Toronto, M5S 2E4, ON, Canada; Hatzinakos D., Department of Electrical and Computer Engineering, University of Toronto, 40 St. George Street, Toronto, M5S 2E4, ON, Canada","This paper presents a fusion-based neural network (NN) classification algorithm for 40-Hz auditory steady state response (ASSR) ensemble averaged signals which were recorded from eight human subjects for observing sleep patterns (wakefulness W0 and deep sleep N3 or slow wave sleep SWS). In SWS, sensitivity to pain is the lowest relative to other sleep stages and arousal needs stronger stimuli. 40-Hz ASSR signals were extracted by averaging over 900 sweeps on a 30-s window. Signals generated during N3 deep sleep state show similarities to those produced when general anesthesia is given to patients during clinical surgery. Our experimental results show that the automatic classification system used identifies sleep states with an accuracy rate of 100% when the training and test signals come from the same subjects while its accuracy is reduced to 97.6%, on average, when signals are used from different training and test subjects. Our results may lead to future classification of consciousness and wakefulness of patients with 40-Hz ASSR for observing the depth and effects of general anesthesia (DGA). © 2015, Khuwaja et al.; licensee Springer.","Adaptive classification; ASSR extraction; Depth of general anesthesia (DGA); Features-level fusion; Observing sleep patterns","Algorithms; Anesthesiology; Slow wave structures; 40-Hz auditory steady-state response; Adaptive classification; Automatic classification systems; Classification algorithm; Fusion classification; General anesthesias; Level fusion; Sleep pattern; accuracy; arousal; Article; artificial neural network; classification algorithm; electrode; electroencephalogram; human; human experiment; learning algorithm; machine learning; nociception; normal human; REM sleep; sleep pattern; sleep stage; slow wave sleep; steady state; Sleep research","Springer Verlag","16874145","","","","Article","Scopus","2-s2.0-84922586919"
"Zhang W.; Li R.; Deng H.; Wang L.; Lin W.; Ji S.; Shen D.","Zhang, Wenlu (55975167900); Li, Rongjian (55975033200); Deng, Houtao (40761188300); Wang, Li (57875734800); Lin, Weili (7406521110); Ji, Shuiwang (18935244900); Shen, Dinggang (7401738392)","55975167900; 55975033200; 40761188300; 57875734800; 7406521110; 18935244900; 7401738392","Deep convolutional neural networks for multi-modality isointense infant brain image segmentation","2015","NeuroImage","667","10.1016/j.neuroimage.2014.12.061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921492033&doi=10.1016%2fj.neuroimage.2014.12.061&partnerID=40&md5=12e352cf5773521ed695f5ad41c505ba","Department of Computer Science, Old Dominion University, Norfolk, 23529, VA, United States; Instacart, San Francisco, 94107, CA, United States; IDEA Lab, Department of Radiology and BRIC, University of North Carolina, Chapel Hill, 27599, NC, United States; MRI Lab, Department of Radiology and BRIC, University of North Carolina, Chapel Hill, 27599, NC, United States; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea","Zhang W., Department of Computer Science, Old Dominion University, Norfolk, 23529, VA, United States; Li R., Department of Computer Science, Old Dominion University, Norfolk, 23529, VA, United States; Deng H., Instacart, San Francisco, 94107, CA, United States; Wang L., IDEA Lab, Department of Radiology and BRIC, University of North Carolina, Chapel Hill, 27599, NC, United States; Lin W., MRI Lab, Department of Radiology and BRIC, University of North Carolina, Chapel Hill, 27599, NC, United States; Ji S., Department of Computer Science, Old Dominion University, Norfolk, 23529, VA, United States; Shen D., IDEA Lab, Department of Radiology and BRIC, University of North Carolina, Chapel Hill, 27599, NC, United States, Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea","The segmentation of infant brain tissue images into white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) plays an important role in studying early brain development in health and disease. In the isointense stage (approximately 6-8 months of age), WM and GM exhibit similar levels of intensity in both T1 and T2 MR images, making the tissue segmentation very challenging. Only a small number of existing methods have been designed for tissue segmentation in this isointense stage; however, they only used a single T1 or T2 images, or the combination of T1 and T2 images. In this paper, we propose to use deep convolutional neural networks (CNNs) for segmenting isointense stage brain tissues using multi-modality MR images. CNNs are a type of deep models in which trainable filters and local neighborhood pooling operations are applied alternatingly on the raw input images, resulting in a hierarchy of increasingly complex features. Specifically, we used multi-modality information from T1, T2, and fractional anisotropy (FA) images as inputs and then generated the segmentation maps as outputs. The multiple intermediate layers applied convolution, pooling, normalization, and other operations to capture the highly nonlinear mappings between inputs and outputs. We compared the performance of our approach with that of the commonly used segmentation methods on a set of manually segmented isointense stage brain images. Results showed that our proposed model significantly outperformed prior methods on infant brain tissue segmentation. In addition, our results indicated that integration of multi-modality images led to significant performance improvement. © 2014 Elsevier Inc.","Convolutional neural networks; Deep learning; Image segmentation; Infant brain image; Multi-modality data","Anisotropy; Brain; Brain Mapping; Gray Matter; Humans; Image Processing, Computer-Assisted; Infant; Magnetic Resonance Imaging; Neural Networks (Computer); White Matter; analytic method; Article; cerebrospinal fluid; comparative effectiveness; convolutional neural network; coupled level set; diffusion weighted imaging; fractional anisotropy; human; image analysis; infant; intermethod comparison; majority voting method; measurement accuracy; nerve cell network; neuroimaging; normal human; performance measurement system; random forest; support vector machine; anatomy and histology; anisotropy; artificial neural network; brain; brain mapping; gray matter; image processing; infant; nuclear magnetic resonance imaging; procedures; white matter","Academic Press Inc.","10538119","","NEIME","25562829","Article","Scopus","2-s2.0-84921492033"
"Liu H.; Ma B.; Qin L.; Pang J.; Zhang C.; Huang Q.","Liu, Hao (56275670700); Ma, Bingpeng (13606466200); Qin, Lei (49561776300); Pang, Junbiao (25823996400); Zhang, Chunjie (55860215300); Huang, Qingming (8435766200)","56275670700; 13606466200; 49561776300; 25823996400; 55860215300; 8435766200","Set-label modeling and deep metric learning on person re-identification","2015","Neurocomputing","30","10.1016/j.neucom.2014.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84918523025&doi=10.1016%2fj.neucom.2014.11.002&partnerID=40&md5=7dbbd9d476408c1747ab8c8d0e5ad459","School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100190, China; Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, 100190, China; Beijing Key Laboratory of Multimedia and Intelligent Software Technology, College of Metropolitan Transportation, Beijing University of Technology, 100124, China","Liu H., School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100190, China; Ma B., School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100190, China; Qin L., Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, 100190, China; Pang J., Beijing Key Laboratory of Multimedia and Intelligent Software Technology, College of Metropolitan Transportation, Beijing University of Technology, 100124, China; Zhang C., School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100190, China; Huang Q., School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, 100190, China, Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, 100190, China","Person re-identification aims at matching individuals across multiple non-overlapping adjacent cameras. By condensing multiple gallery images of a person as a whole, we propose a novel method named Set-Label Model (SLM) to improve the performance of person re-identification under the multi-shot setting. Moreover, we utilize mutual-information to measure the relevance between query image and gallery sets. To decrease the computational complexity, we apply a Naive-Bayes Nearest-Neighbor algorithm to approximate the mutual-information value. To overcome the limitations of traditional linear metric learning, we further develop a deep non-linear metric learning (DeepML) approach based on Neighborhood Component Analysis and Deep Belief Network. To evaluate the effectiveness of our proposed approaches, SLM and DeepML, we have carried out extensive experiments on two challenging datasets i-LIDS and ETHZ. The experimental results demonstrate that the proposed methods can obtain better performances compared with the state-of-the-art methods. © 2014 Elsevier B.V.","Deep learning; Metric learning; Mutual-information; Neighborhood component analysis; Person re-identification","Image enhancement; Deep belief networks; Metric learning; Mutual informations; Nearest neighbor algorithm; Neighborhood component analysis; Person re identifications; Query images; State-of-the-art methods; Article; automated pattern recognition; calculation; camera; comparative effectiveness; controlled study; deep non linear metric learning; experimental design; experimental study; human; image analysis; image display; image processing; image quality; machine learning; naive Bayes nearest neighbor algorithm; person reidentification; set label modeling; validation study; Deep learning","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-84918523025"
"Baldi P.; Lu Z.","Baldi, Pierre (7101759672); Lu, Zhiqin (7404769018)","7101759672; 7404769018","Complex-valued autoencoders","2012","Neural Networks","43","10.1016/j.neunet.2012.04.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863883286&doi=10.1016%2fj.neunet.2012.04.011&partnerID=40&md5=32d32126653849621c1f8b65a2931043","Department of Computer Science, UCI, Irvine, CA 92697-3435, United States; Department of Mathematics, UCI, Irvine, CA 92697-3875, United States","Baldi P., Department of Computer Science, UCI, Irvine, CA 92697-3435, United States; Lu Z., Department of Mathematics, UCI, Irvine, CA 92697-3875, United States","Autoencoders are unsupervised machine learning circuits, with typically one hidden layer, whose learning goal is to minimize an average distortion measure between inputs and outputs. Linear autoencoders correspond to the special case where only linear transformations between visible and hidden variables are used. While linear autoencoders can be defined over any field, only real-valued linear autoencoders have been studied so far. Here we study complex-valued linear autoencoders where the components of the training vectors and adjustable matrices are defined over the complex field with the L2 norm. We provide simpler and more general proofs that unify the real-valued and complex-valued cases, showing that in both cases the landscape of the error function is invariant under certain groups of transformations. The landscape has no local minima, a family of global minima associated with Principal Component Analysis, and many families of saddle points associated with orthogonal projections onto sub-space spanned by sub-optimal subsets of eigenvectors of the covariance matrix. The theory yields several iterative, convergent, learning algorithms, a clear understanding of the generalization properties of the trained autoencoders, and can equally be applied to the hetero-associative case when external targets are provided. Partial results on deep architecture as well as the differential geometry of autoencoders are also presented. The general framework described here is useful to classify autoencoders and identify general properties that ought to be investigated for each class, illuminating some of the connections between autoencoders, unsupervised learning, clustering, Hebbian learning, and information theory. © 2012 Elsevier Ltd.","Autoencoders; Complex neural networks; Complex numbers; Critical points; Deep architectures; Differential geometry; EM algorithm; Linear networks; Principal component analysis; Unsupervised learning","Artificial Intelligence; Neural Networks (Computer); Principal Component Analysis; Covariance matrix; Information theory; Linear networks; Neural networks; Principal component analysis; Unsupervised learning; Autoencoders; Complex neural networks; Complex number; Critical points; Differential geometry; EM algorithms; analytical error; article; autoencoder; automation; classification; cluster analysis; covariance; geometry; information; learning algorithm; linear system; machine learning; mathematical computing; mathematical parameters; principal component analysis; priority journal; sampling; theory; Learning algorithms","","18792782","","NNETE","22622264","Article","Scopus","2-s2.0-84863883286"
"Inza I.; Calvo B.; Armañanzas R.; Bengoetxea E.; Larrañaga P.; Lozano J.A.","Inza, Iñaki (6701794860); Calvo, Borja (15842912900); Armañanzas, Rubén (8890077400); Bengoetxea, Endika (56113398900); Larrañaga, Pedro (7004720416); Lozano, José A (35473051700)","6701794860; 15842912900; 8890077400; 56113398900; 7004720416; 35473051700","Machine learning: an indispensable tool in bioinformatics.","2010","Methods in molecular biology (Clifton, N.J.)","71","10.1007/978-1-60327-194-3_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-75649108240&doi=10.1007%2f978-1-60327-194-3_2&partnerID=40&md5=35f70711ba40b3308e5f10e814388f19","Intelligent Systems Group, Donostia - San Sebastián, Basque Country, Spain","Inza I., Intelligent Systems Group, Donostia - San Sebastián, Basque Country, Spain; Calvo B., Intelligent Systems Group, Donostia - San Sebastián, Basque Country, Spain; Armañanzas R., Intelligent Systems Group, Donostia - San Sebastián, Basque Country, Spain; Bengoetxea E., Intelligent Systems Group, Donostia - San Sebastián, Basque Country, Spain; Larrañaga P., Intelligent Systems Group, Donostia - San Sebastián, Basque Country, Spain; Lozano J.A., Intelligent Systems Group, Donostia - San Sebastián, Basque Country, Spain","The increase in the number and complexity of biological databases has raised the need for modern and powerful data analysis tools and techniques. In order to fulfill these requirements, the machine learning discipline has become an everyday tool in bio-laboratories. The use of machine learning techniques has been extended to a wide spectrum of bioinformatics applications. It is broadly used to investigate the underlying mechanisms and interactions between biological molecules in many diseases, and it is an essential tool in any biomarker discovery process. In this chapter, we provide a basic taxonomy of machine learning algorithms, and the characteristics of main data preprocessing, supervised classification, and clustering techniques are shown. Feature selection, classifier evaluation, and two supervised classification topics that have a deep impact on current bioinformatics are presented. We make the interested reader aware of a set of popular web resources, open source software tools, and benchmarking data repositories that are frequently used by the machine learning community.","","Artificial Intelligence; Automatic Data Processing; Cluster Analysis; Computational Biology; Databases, Factual; Software; MLCS; MLOWN; article; artificial intelligence; biology; cluster analysis; computer program; factual database; information processing; instrumentation; methodology","","19406029","","","19957143","Article","Scopus","2-s2.0-75649108240"
"Neumann W.P.; Eklund J.; Hansson B.; Lindbeck L.","Neumann, W.P. (57209493710); Eklund, J. (7006257650); Hansson, B. (15837404800); Lindbeck, L. (6602859506)","57209493710; 7006257650; 15837404800; 6602859506","Effect assessment in work environment interventions: A methodological reflection","2010","Ergonomics","29","10.1080/00140130903349914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-73949084941&doi=10.1080%2f00140130903349914&partnerID=40&md5=98cc16c36beecf635287d2adff312e25","Department of Mechanical and Industrial Engineering, Ryerson University, Canada; Department of Management and Engineering, Linköping University, Sweden; School of Business, Mälardalen University, Västerås, Sweden; Royal Institute of Technology, Huddinge, Sweden","Neumann W.P., Department of Mechanical and Industrial Engineering, Ryerson University, Canada; Eklund J., Department of Management and Engineering, Linköping University, Sweden, Royal Institute of Technology, Huddinge, Sweden; Hansson B., School of Business, Mälardalen University, Västerås, Sweden; Lindbeck L., Royal Institute of Technology, Huddinge, Sweden","This paper addresses a number of issues for work environment intervention (WEI) researchers in light of the mixed results reported in the literature. If researchers emphasise study quality over intervention quality, reviews that exclude case studies with high quality and multifactorial interventions may be vulnerable to 'quality criteria selection bias'. Learning from 'failed' interventions is inhibited by both publication bias and reporting lengths that limit information on relevant contextual and implementation factors. The authors argue for the need to develop evaluation approaches consistent with the complexity of multifactorial WEIs that: a) are owned by and aimed at the whole organisation; and b) include intervention in early design stages where potential impact is highest. Context variety, complexity and instability in and around organisations suggest that attention might usefully shift from generalisable 'proof of effectiveness' to a more nuanced identification of intervention elements and the situations in which they are more likely to work as intended. Statement of Relevance: This paper considers ergonomics interventions from perspectives of what constitutes quality and 'proof'. It points to limitations of traditional experimental intervention designs and argues that the complexity of organisational change, and the need for multifactorial interventions that reach deep into work processes for greater impact, should be recognised. © 2010 Taylor & Francis.","Ergonomics intervention; Macroergonomics; Musculoskeletal disorders; Research methodology","Bias (Epidemiology); Humans; Man-Machine Systems; Musculoskeletal Diseases; Occupational Diseases; Occupational Health; Workplace; Employment; Research; Early design stages; Ergonomics intervention; Evaluation approach; High quality; Macroergonomics; Musculoskeletal disorders; Organisational change; Potential impacts; Quality criteria; Research methodologies; Selection bias; Work environments; Work process; article; ergonomics; medical literature; medical research; methodology; occupational health; publishing; quality control; work environment; workplace; Ergonomics","","13665847","","ERGOA","20069488","Article","Scopus","2-s2.0-73949084941"
"Reichert D.P.; Seriès P.; Storkey A.J.","Reichert, David P. (40762235400); Seriès, Peggy (6507757583); Storkey, Amos J. (6602511464)","40762235400; 6507757583; 6602511464","Charles Bonnet Syndrome: Evidence for a Generative Model in the Cortex?","2013","PLoS Computational Biology","43","10.1371/journal.pcbi.1003134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880806806&doi=10.1371%2fjournal.pcbi.1003134&partnerID=40&md5=362487fa6b89036ed4b11af5de3c4b47","Institute for Adaptive and Neural Computation, University of Edinburgh, Edinburgh, United Kingdom; Department of Cognitive, Linguistic and Psychological Sciences, Brown University, Providence, RI, United States","Reichert D.P., Institute for Adaptive and Neural Computation, University of Edinburgh, Edinburgh, United Kingdom, Department of Cognitive, Linguistic and Psychological Sciences, Brown University, Providence, RI, United States; Seriès P., Institute for Adaptive and Neural Computation, University of Edinburgh, Edinburgh, United Kingdom; Storkey A.J., Institute for Adaptive and Neural Computation, University of Edinburgh, Edinburgh, United Kingdom","Several theories propose that the cortex implements an internal model to explain, predict, and learn about sensory data, but the nature of this model is unclear. One condition that could be highly informative here is Charles Bonnet syndrome (CBS), where loss of vision leads to complex, vivid visual hallucinations of objects, people, and whole scenes. CBS could be taken as indication that there is a generative model in the brain, specifically one that can synthesise rich, consistent visual representations even in the absence of actual visual input. The processes that lead to CBS are poorly understood. Here, we argue that a model recently introduced in machine learning, the deep Boltzmann machine (DBM), could capture the relevant aspects of (hypothetical) generative processing in the cortex. The DBM carries both the semantics of a probabilistic generative model and of a neural network. The latter allows us to model a concrete neural mechanism that could underlie CBS, namely, homeostatic regulation of neuronal activity. We show that homeostatic plasticity could serve to make the learnt internal model robust against e.g. degradation of sensory input, but overcompensate in the case of CBS, leading to hallucinations. We demonstrate how a wide range of features of CBS can be explained in the model and suggest a potential role for the neuromodulator acetylcholine. This work constitutes the first concrete computational model of CBS and the first application of the DBM as a model in computational neuroscience. Our results lend further credence to the hypothesis of a generative model in the brain. © 2013 Reichert et al.","","Concretes; Electric circuit breakers; Learning systems; Neural networks; Semantics; acetylcholine; Charles Bonnet; Condition; Cortexes; Deep boltzmann machines; Generative model; Internal models; Learn+; Machine-learning; Sensory data; Visual representations; article; brain cortex; brain function; brain nerve cell; cell function; Charles Bonnet syndrome; clinical feature; deep Boltzmann machine; disease model; feedback system; hallucination; homeostasis; human; machine learning; mathematical computing; mathematical model; nerve cell network; nerve cell plasticity; nerve cell stimulation; nerve conduction; neuromodulation; positive feedback; semantics; sensory stimulation; vision; visual hallucination; Computation theory","Public Library of Science","1553734X","","","23874177","Article","Scopus","2-s2.0-84880806806"
"Mora-Jiménez I.; Figueiras-Vidal A.R.","Mora-Jiménez, I. (56039860600); Figueiras-Vidal, A.R. (7006625369)","56039860600; 7006625369","Improving performance of neural classifiers via selective reduction of target levels","2009","Neurocomputing","2","10.1016/j.neucom.2009.04.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952744737&doi=10.1016%2fj.neucom.2009.04.002&partnerID=40&md5=b37656e57c47f31ded28265ea64a4f1f","Department of Signal Theory and Communications, Universidad Rey Juan Carlos, 28943 Fuenlabrada, Madrid, Spain; Department of Signal Theory and Communications, Universidad Carlos III de Madrid, 28911 Leganés, Madrid, Spain","Mora-Jiménez I., Department of Signal Theory and Communications, Universidad Rey Juan Carlos, 28943 Fuenlabrada, Madrid, Spain; Figueiras-Vidal A.R., Department of Signal Theory and Communications, Universidad Carlos III de Madrid, 28911 Leganés, Madrid, Spain","Reducing the level of the targets corresponding to training samples for a machine classifier using the outputs of an auxiliary classifier is interesting because it allows to save expressive power unnecessarily dedicated to increase the output level of well-classified samples. In this paper we propose an iterative form of this selective reduction of target levels with a simple linear reduction schedule. Extensive simulations show that the proposed method has not only a performance better than or equal to conventional training or using static versions of the reduction, but also with respect to support vector machines (SVM). This potential advantage is accompanied by a smaller size and a design effort not much higher than the corresponding SVM, thus making the proposed method very attractive for practical applications. © 2009 Elsevier B.V.","Artificial neural networks; Classification; Learning algorithm; Reduced target level; Sample selection","Classification (of information); Deep neural networks; Iterative methods; Learning algorithms; Neural networks; Expressive power; Extensive simulations; Improving performance; Linear reduction; Neural classifiers; Sample selection; Selective reduction; Target levels; accuracy; article; artificial neural network; classification; classifier; learning algorithm; mathematical model; neural classifier; priority journal; simulation; support vector machine; Support vector machines","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-79952744737"
"Mozetič I.","Mozetič, Igor (6506490886)","6506490886","Diagnostic efficiency of deep and surface knowledge in KARDIO","1990","Artificial Intelligence In Medicine","9","10.1016/0933-3657(90)90030-U","https://www.scopus.com/inward/record.uri?eid=2-s2.0-5244346849&doi=10.1016%2f0933-3657%2890%2990030-U&partnerID=40&md5=37c49855c9f3c3ca7266c8e00a6f713e","Austrian Research Institute for Artificial Intelligence, 1010 Vienna, Schottengasse 3, Austria","Mozetič I., Austrian Research Institute for Artificial Intelligence, 1010 Vienna, Schottengasse 3, Austria","The KARDIO system deals with the problem of diagnosing cardiac arrhythmias from symbolic descriptions of electrocardiograms. The system incorporates a qualitative model which simulates the electrical activity of the heart. In the paper we outline two methods for an efficient application of a simulation model to diagnosis. First, through abstractions and refinements, the model is represented at several levels of detail. Second, the model is 'compiled' into surface diagnostic rules. Through simulation, a relational table is generated and subsequently compressed into efficient diagnostic rules by inductive learning. A novel contribution to KARDIO, presented here, includes a comparison of diagnostic efficiency and space complexity of four types of knowledge: a simulation model of the heart, a hierarchical four-level model, a relational table, and compressed diagnostic rules. © 1990.","Abstractions; Diagnosis; Machine learning; Qualitative modeling","","","09333657","","AIMEE","","Article","Scopus","2-s2.0-5244346849"
"Herrero Á.; Corchado E.; Pellicer M.A.; Abraham A.","Herrero, Álvaro (8892618100); Corchado, Emilio (6602872701); Pellicer, María A. (22433728300); Abraham, Ajith (7202760099)","8892618100; 6602872701; 22433728300; 7202760099","MOVIH-IDS: A mobile-visualization hybrid intrusion detection system","2009","Neurocomputing","44","10.1016/j.neucom.2008.12.033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650135042&doi=10.1016%2fj.neucom.2008.12.033&partnerID=40&md5=e9de3893b016341473fb067a8ba1b61a","Department of Civil Engineering, University of Burgos, 09006 Burgos, C/Francisco de Vitoria s/n, Spain; Centre for Quantifiable Quality of Service in Communication Systems, Norwegian University of Science and Technology, Trondheim, Norway","Herrero Á., Department of Civil Engineering, University of Burgos, 09006 Burgos, C/Francisco de Vitoria s/n, Spain; Corchado E., Department of Civil Engineering, University of Burgos, 09006 Burgos, C/Francisco de Vitoria s/n, Spain; Pellicer M.A., Department of Civil Engineering, University of Burgos, 09006 Burgos, C/Francisco de Vitoria s/n, Spain; Abraham A., Centre for Quantifiable Quality of Service in Communication Systems, Norwegian University of Science and Technology, Trondheim, Norway","A novel hybrid artificial intelligent system for intrusion detection, called MObile-VIsualization Hybrid IDS (MOVIH-IDS), is presented in this study. A hybrid model built by means of a multiagent system that incorporates an unsupervised connectionist intrusion detection system (IDS) has been defined to guaranty an efficient computer network security architecture. This hybrid IDS facilitates the intrusion detection in dynamic networks, in a more flexible and adaptable manner. The proposed improvement of the system in this paper includes deliberative agents characterized by the use of an unsupervised connectionist model to identify intrusions in computer networks. This hybrid IDS has been probed through several real anomalous situations related to the simple network management protocol as it is potentially dangerous. Experimental results probed the successful detection of such attacks through MOVIH-IDS. © 2009 Elsevier B.V.","Artificial neural networks; Hybrid artificial intelligent systems; Intrusion detection systems; Multiagent systems; Unsupervised projection methods","Artificial intelligence; Computer crime; Computer networks; Deep neural networks; Electric ship equipment; Intelligent systems; Mercury (metal); Multi agent systems; Network security; Neural networks; Visualization; Connectionist models; Deliberative agents; Hybrid Artificial Intelligent Systems; Hybrid intrusion detection; Intrusion Detection Systems; Mobile visualization; Projection method; Simple network management protocols; article; artificial intelligence; computer analysis; computer model; computer network; computer system; machine learning; mathematical analysis; mathematical computing; mobile visualization hybrid intrusion detection system; priority journal; Intrusion detection","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-78650135042"
"O'Connor P.; Neil D.; Liu S.-C.; Delbruck T.; Pfeiffer M.","O'Connor, Peter (57196840028); Neil, Daniel (55944451800); Liu, Shih-Chii (7409457533); Delbruck, Tobi (35576634800); Pfeiffer, Michael (41662180000)","57196840028; 55944451800; 7409457533; 35576634800; 41662180000","Real-time classification and sensor fusion with a spiking deep belief network","2013","Frontiers in Neuroscience","331","10.3389/fnins.2013.00178","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888811418&doi=10.3389%2ffnins.2013.00178&partnerID=40&md5=40467ce55385e2a3e94df21a05c43f4c","Institute of Neuroinformatics, University of Zurich, ETH Zurich, Zurich, Switzerland","O'Connor P., Institute of Neuroinformatics, University of Zurich, ETH Zurich, Zurich, Switzerland; Neil D., Institute of Neuroinformatics, University of Zurich, ETH Zurich, Zurich, Switzerland; Liu S.-C., Institute of Neuroinformatics, University of Zurich, ETH Zurich, Zurich, Switzerland; Delbruck T., Institute of Neuroinformatics, University of Zurich, ETH Zurich, Zurich, Switzerland; Pfeiffer M., Institute of Neuroinformatics, University of Zurich, ETH Zurich, Zurich, Switzerland","Deep Belief Networks (DBNs) have recently shown impressive performance on a broad range of classification problems. Their generative properties allow better understanding of the performance, and provide a simpler solution for sensor fusion tasks. However, because of their inherent need for feedback and parallel update of large numbers of units, DBNs are expensive to implement on serial computers. This paper proposes a method based on the Siegert approximation for Integrate-and-Fire neurons to map an offline-trained DBN onto an efficient event-driven spiking neural network suitable for hardware implementation. The method is demonstrated in simulation and by a real-time implementation of a 3-layer network with 2694 neurons used for visual classification of MNIST handwritten digits with input from a 128 × 128 Dynamic Vision Sensor (DVS) silicon retina, and sensory-fusion using additional input from a 64-channel AER-EAR silicon cochlea. The system is implemented through the open-source software in the jAER project and runs in real-time on a laptop computer. It is demonstrated that the system can recognize digits in the presence of distractions, noise, scaling, translation and rotation, and that the degradation of recognition performance by using an event-based approach is less than 1%. Recognition is achieved in an average of 5.8 ms after the onset of the presentation of a digit. By cue integration from both silicon retina and cochlea outputs we show that the system can be biased to select the correct digit from otherwise ambiguous input. © 2013 O'Connor, Neil, Liu, Delbruck and Pfeiffer.","Deep belief networks; Deep learning; Generative model; Sensory fusion; Silicon cochlea; Silicon retina; Spiking neural network","silicon; article; association; cochlea; computer program; computer simulation; deep belief network; digital computer; machine learning; nerve cell; noise; recognition; refractory period; retina; rotation; sensory stimulation; spiking neural network; task performance","","1662453X","","","","Article","Scopus","2-s2.0-84888811418"
"Sample P.A.; Chan K.; Boden C.; Lee T.-W.; Blumenthal E.Z.; Weinreb R.N.; Bernd A.; Pascual J.; Hao J.; Sejnowski T.; Goldbaum M.H.","Sample, Pamela A. (7006319711); Chan, Kwokleung (56232762900); Boden, Catherine (7003640464); Lee, Te-Won (57201788403); Blumenthal, Eytan Z. (7006548687); Weinreb, Robert N. (35380128600); Bernd, Antje (7006101865); Pascual, John (7202676345); Hao, Jiucang (8368245100); Sejnowski, Terrence (35595178300); Goldbaum, Michael H. (7005893154)","7006319711; 56232762900; 7003640464; 57201788403; 7006548687; 35380128600; 7006101865; 7202676345; 8368245100; 35595178300; 7005893154","Using unsupervised learning with variational bayesian mixture of factor analysis to identify patterns of glaucomatous visual field defects","2004","Investigative Ophthalmology and Visual Science","38","10.1167/iovs.03-0343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-3242892323&doi=10.1167%2fiovs.03-0343&partnerID=40&md5=59c29a22b1162e322f7b0d41a835ab72","Hamilton Glaucoma Center, Univ. of California at San Diego, San Diego, CA, United States; Ophthalmic Informatics Laboratory, Department of Ophthalmology, Univ. of California at San Diego, San Diego, CA, United States; Institute for Neural Computation, Univ. of California at San Diego, San Diego, CA, United States; Department of Ophthalmology, Hadassah University Hospital, Jerusalem, Israel; Compl. Neurobiology Laboratory, Salk Institute, San Diego, CA, United States; Department of Ophthalmology, University of California, San Diego, CA 92093-0946, 9500 Gilman Drive, United States","Sample P.A., Hamilton Glaucoma Center, Univ. of California at San Diego, San Diego, CA, United States, Department of Ophthalmology, University of California, San Diego, CA 92093-0946, 9500 Gilman Drive, United States; Chan K., Ophthalmic Informatics Laboratory, Department of Ophthalmology, Univ. of California at San Diego, San Diego, CA, United States; Boden C., Hamilton Glaucoma Center, Univ. of California at San Diego, San Diego, CA, United States; Lee T.-W., Ophthalmic Informatics Laboratory, Department of Ophthalmology, Univ. of California at San Diego, San Diego, CA, United States; Blumenthal E.Z., Institute for Neural Computation, Univ. of California at San Diego, San Diego, CA, United States; Weinreb R.N., Hamilton Glaucoma Center, Univ. of California at San Diego, San Diego, CA, United States; Bernd A., Hamilton Glaucoma Center, Univ. of California at San Diego, San Diego, CA, United States; Pascual J., Hamilton Glaucoma Center, Univ. of California at San Diego, San Diego, CA, United States; Hao J., Ophthalmic Informatics Laboratory, Department of Ophthalmology, Univ. of California at San Diego, San Diego, CA, United States; Sejnowski T., Department of Ophthalmology, Hadassah University Hospital, Jerusalem, Israel; Goldbaum M.H., Hamilton Glaucoma Center, Univ. of California at San Diego, San Diego, CA, United States, Compl. Neurobiology Laboratory, Salk Institute, San Diego, CA, United States","PURPOSE. To determine whether an unsupervised machine learning classifier can identify patterns of visual field loss in standard visual fields consistent with typical patterns learned by decades of human experience. METHODS. Standard perimetry thresholds for 52 locations plus age from one eye of each of 156 patients with glaucomatous optic neuropathy (GON) and 189 eyes of healthy subjects were clustered with an unsupervised machine classifier, variational Bayesian mixture of factor analysis (vbMFA). RESULTS. The vbMFA formed five distinct clusters. Cluster 5 held 186 of 189 fields from normal eyes plus 46 from eyes with GON. These fields were then judged within normal limits by several traditional methods. Each of the other four clusters could be described by the pattern of loss found within it. Cluster 1 (71 GON + 3 normal optic discs) included early, localized defects. A purely diffuse component was rare. Cluster 2 (26 GON) exhibited primarily deep superior hemifield defects, and cluster 3 (10 GON) held deep inferior hemifield defects only or in combination with lesser superior field defects. Cluster 4 (6 GON) showed deep defects in both hemifields. In other words, visual fields within a given cluster had similar patterns of loss that differed from the predominant pattern found in other clusters. The classifier separated the data based solely on the patterns of loss within the fields, without being guided by the diagnosis, placing 98.4% of the healthy eyes within the same cluster and spreading 70.5% of the eyes with GON across the other four clusters, in good agreement with a glaucoma expert and pattern standard deviation. CONCLUSIONS. Without training-based diagnosis (unsupervised learning), the vbMFA identified four important patterns of field loss in eyes with GON in a manner consistent with years of clinical experience.","","Algorithms; Bayes Theorem; Glaucoma; Humans; Image Interpretation, Computer-Assisted; Learning; Middle Aged; Optic Nerve Diseases; Perimetry; Vision Disorders; Visual Fields; age; article; Bayes theorem; controlled study; factorial analysis; glaucoma; glaucomatous optic neuropathy; human; learning; major clinical study; optic disk; optic nerve disease; perimetry; priority journal; visual field; visual field defect","","01460404","","IOVSD","15277482","Article","Scopus","2-s2.0-3242892323"
"Willemen T.; Van Deun D.; Verhaert V.; Vandekerckhove M.; Exadaktylos V.; Verbraecken J.; Van Huffel S.; Haex B.; Vander Sloten J.","Willemen, T. (55189238800); Van Deun, D. (55189827000); Verhaert, V. (36926226700); Vandekerckhove, M. (8765165000); Exadaktylos, V. (24075881500); Verbraecken, J. (6701917364); Van Huffel, S. (7004954228); Haex, B. (8232257400); Vander Sloten, J. (56235308700)","55189238800; 55189827000; 36926226700; 8765165000; 24075881500; 6701917364; 7004954228; 8232257400; 56235308700","An evaluation of cardiorespiratory and movement features with respect to sleep-stage classification","2014","IEEE Journal of Biomedical and Health Informatics","96","10.1109/JBHI.2013.2276083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896476875&doi=10.1109%2fJBHI.2013.2276083&partnerID=40&md5=b38e8e081f820905caec732678cfc536","Biomechanics Section, Mechanical Engineering Department, KU Leuven, Heverlee 3001, Belgium; Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Leuven 3001, Belgium; IMinds Future Health Department, KU Leuven, Heverlee 3001, Belgium; Vrije Universiteit Brussel, Research Group of Biological Psychology, Brussels 1050, Belgium; KU Leuven, Division of Measure, Model and Manage Bioresponses, Leuven 3001, Belgium; Antwerp University Hospital, University of Antwerp, Multidisciplinary Sleep Disorders Centre, Edegem 2650, Belgium; Imec, Leuven 3001, Belgium","Willemen T., Biomechanics Section, Mechanical Engineering Department, KU Leuven, Heverlee 3001, Belgium, Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Leuven 3001, Belgium, IMinds Future Health Department, KU Leuven, Heverlee 3001, Belgium; Van Deun D., Biomechanics Section, Mechanical Engineering Department, KU Leuven, Heverlee 3001, Belgium; Verhaert V., Biomechanics Section, Mechanical Engineering Department, KU Leuven, Heverlee 3001, Belgium; Vandekerckhove M., Vrije Universiteit Brussel, Research Group of Biological Psychology, Brussels 1050, Belgium; Exadaktylos V., KU Leuven, Division of Measure, Model and Manage Bioresponses, Leuven 3001, Belgium; Verbraecken J., Antwerp University Hospital, University of Antwerp, Multidisciplinary Sleep Disorders Centre, Edegem 2650, Belgium; Van Huffel S., Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Leuven 3001, Belgium, IMinds Future Health Department, KU Leuven, Heverlee 3001, Belgium; Haex B., Biomechanics Section, Mechanical Engineering Department, KU Leuven, Heverlee 3001, Belgium, Imec, Leuven 3001, Belgium; Vander Sloten J., Biomechanics Section, Mechanical Engineering Department, KU Leuven, Heverlee 3001, Belgium","Polysomnography (PSG) is considered the gold standard to assess sleep accurately, but it can be expensive, time-consuming, and uncomfortable, specifically in long-term sleep studies. Actigraphy, on the other hand, is both cheap and user-friendly, but depending on the application lacks detail and accuracy. Our aim was to evaluate cardiorespiratory and movement signals in discriminating between wake, rapid-eye-movement (REM), light (N1N2), and deep (N3) sleep. The dataset comprised 85 nights of PSG from a healthy population. Starting from a total of 750 characteristic variables (features), problem-specific subsets of 40 features were forwardly selected using the combination of a wrapper method (Cohen's kappa statistic on radial basis function (RBF)-kernel support vector machine (SVM) classifier) and filter method (minimum redundancy maximum relevance criterion on mutual information). Final classification was performed using an RBF-kernel SVM. Non-subject-specific wake versus sleep classification resulted in a Cohen's kappa value of 0.695, while REM versus NREM resulted in 0.558 and N3 versus N1N2 in 0.553. The broad pool of initial features gave insight in which features discriminated best between the different classes. The classification results demonstrate the possibility of making long-term sleep monitoring more widely available. © 2013 IEEE.","Biomedical signal processing; data analysis; medical information systems; sleep research; supervised learning","Adult; Heart Rate; Humans; Medical Informatics Applications; Movement; Polysomnography; Respiration; Signal Processing, Computer-Assisted; Support Vector Machines; Young Adult; Biomedical signal processing; Data handling; Data reduction; Eye movements; Medical information systems; Patient monitoring; Signal processing; Sleep research; Supervised learning; Support vector machines; Wakes; Classification results; Healthy population; Minimum redundancy-maximum relevances; Mutual informations; Radial Basis Function(RBF); Rapid eye movement; Sleep monitoring; Subject-specific; adult; article; breathing; heart rate; human; medical informatics; methodology; movement (physiology); physiology; polysomnography; signal processing; support vector machine; young adult; Classification (of information)","Institute of Electrical and Electronics Engineers Inc.","21682194","","ITIBF","24058031","Article","Scopus","2-s2.0-84896476875"
"Sandholm T.W.; Crites R.H.","Sandholm, Tuomas W. (57203083791); Crites, Robert H. (7004085313)","57203083791; 7004085313","Multiagent reinforcement learning in the Iterated Prisoner's Dilemma","1996","BioSystems","232","10.1016/0303-2647(95)01551-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030050933&doi=10.1016%2f0303-2647%2895%2901551-5&partnerID=40&md5=cf1e42a162832062d0f8d52feef9e32f","Univ. of Massachusetts at Amherst, Computer Science Department, Amherst, MA 01003, United States","Sandholm T.W., Univ. of Massachusetts at Amherst, Computer Science Department, Amherst, MA 01003, United States; Crites R.H., Univ. of Massachusetts at Amherst, Computer Science Department, Amherst, MA 01003, United States","Reinforcement learning (RL) is based on the idea that the tendency to produce an action should be strengthened (reinforced) if it produces favourable results, and weakened if it produces unfavourable results. Q-learning is a recent RL algorithm that does not need a model of its environment and can be used on-line. Therefore, it is well suited for use in repeated games against an unknown opponent. Most RL research has been confined to single-agent settings or to multiagent settings where the agents have totally positively correlated payoffs (team problems) or totally negatively correlated payoffs (zero-sum games). This paper is an empirical study of reinforcement learning in the Iterated Prisoner's Dilemma (IPD), where the agents' payoffs are neither totally positively nor totally negatively correlated. RL is considerably more difficult in such a domain. This paper investigates the ability of a variety of Q-learning agents to play the IPD game against an unknown opponent. In some experiments, the opponent is the fixed strategy Tit-For-Tat, while in others it is another Q-learner. All the Q-learners learned to play optimally against Tit-For-Tat. Playing against another learner was more difficult because the adaptation of the other learner created a non-stationary environment, and because the other learner was not endowed with any a priori knowledge about the IPD game such as a policy designed to encourage cooperation. The learners that were studied varied along three dimensions: the length of history they received as context, the type of memory they employed (look up tables based on restricted history windows or recurrent neural networks that can theoretically store features from arbitrarily deep in the past), and the exploration schedule they followed. Although all the learners faced difficulties when playing against other learners, agents with longer history windows, lookup table memories, and longer exploration schedules fared best in the IPD games.","Exploration; Machine learning; Multiagent learning; Prisoner's Dilemma; Recurrent neural network; Reinforcement learning","algorithm; article; computer program; game; human; prison; prisoner; reinforcement","Elsevier Ireland Ltd","03032647","","BSYMB","8924633","Article","Scopus","2-s2.0-0030050933"
"Xie W.F.; Zhu Y.Q.; Zhao Z.Y.; Wong Y.K.","Xie, W.F. (25932438400); Zhu, Y.Q. (56172370800); Zhao, Z.Y. (13806019500); Wong, Y.K. (55911418900)","25932438400; 56172370800; 13806019500; 55911418900","Nonlinear system identification using optimized dynamic neural network","2009","Neurocomputing","38","10.1016/j.neucom.2009.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952763605&doi=10.1016%2fj.neucom.2009.02.004&partnerID=40&md5=a4abe7e07fd73aedb3be6a7c8ff663cd","Department of Mechanical and Industrial Engineering, Concordia University, Montreal, QC, H3G 1M8, 1455 de Maisonneuve Blvd. W., Canada; Department of Electrical Engineering, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong, Hong Kong","Xie W.F., Department of Mechanical and Industrial Engineering, Concordia University, Montreal, QC, H3G 1M8, 1455 de Maisonneuve Blvd. W., Canada; Zhu Y.Q., Department of Mechanical and Industrial Engineering, Concordia University, Montreal, QC, H3G 1M8, 1455 de Maisonneuve Blvd. W., Canada; Zhao Z.Y., Department of Mechanical and Industrial Engineering, Concordia University, Montreal, QC, H3G 1M8, 1455 de Maisonneuve Blvd. W., Canada; Wong Y.K., Department of Electrical Engineering, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong, Hong Kong","In this paper, both off-line architecture optimization and on-line adaptation have been developed for a dynamic neural network (DNN) in nonlinear system identification. In the off-line architecture optimization, a new effective encoding scheme-Direct Matrix Mapping Encoding (DMME) method is proposed to represent the structure of neural network by establishing connection matrices. A series of GA operations are applied to the connection matrices to find the optimal number of neurons on each hidden layer and interconnection between two neighboring layers of DNN. The hybrid training is adopted to evolve the architecture, and to tune the weights and input delays of DNN by combining GA with the modified adaptation laws. The modified adaptation laws are subsequently used to tune the input time delays, weights and linear parameters in the optimized DNN-based model in on-line nonlinear system identification. The effectiveness of the architecture optimization and adaptation is extensively tested by means of two nonlinear system identification examples. © 2009 Elsevier B.V.","Artificial neural network; Genetic algorithm; Nonlinear system identification; On-line adaptation","Deep neural networks; Encoding (symbols); Genetic algorithms; Matrix algebra; Memory architecture; Network architecture; Neural networks; Nonlinear systems; Religious buildings; Time delay; Architecture optimization; Connection matrices; Dynamic neural networks; Encoding schemes; Hybrid training; Input time delays; Linear parameters; On-line adaptation; adaptation; article; controlled study; dynamic neural network; linear system; machine learning; mathematical parameters; nerve cell; nonlinear system; online system; priority journal; time; weight; Computer architecture","Elsevier B.V.","09252312","","NRCGE","","Article","Scopus","2-s2.0-79952763605"
"Fu L.D.; Aliferis C.","Fu, Lawrence D (23472863700); Aliferis, Constantin (6602844802)","23472863700; 6602844802","Models for predicting and explaining citation count of biomedical articles.","2008","AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium","39","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-73949096493&partnerID=40&md5=b79bfd5f871f3720692f965257567e2a","Vanderbilt University, Nashville, TN, United States","Fu L.D., Vanderbilt University, Nashville, TN, United States; Aliferis C., Vanderbilt University, Nashville, TN, United States","The single most important bibliometric criterion for judging the impact of biomedical papers and their authors work is the number of citations received which is commonly referred to as citation count. This metric however is unavailable until several years after publication time. In the present work, we build computer models that accurately predict citation counts of biomedical publications within a deep horizon of ten years using only predictive information available at publication time. Our experiments show that it is indeed feasible to accurately predict future citation counts with a mixture of content-based and bibliometric features using machine learning methods. The models pave the way for practical prediction of the long-term impact of publication, and their statistical analysis provides greater insight into citation behavior.","","Algorithms; Bibliometrics; Computer Simulation; Journal Impact Factor; MEDLINE; Models, Statistical; Periodicals as Topic; United States; algorithm; article; bibliometrics; computer simulation; journal impact factor; MEDLINE; publication; statistical model; statistics; United States","","1942597X","","","18999029","Article","Scopus","2-s2.0-73949096493"
"Borrebaeck C.A.K.","Borrebaeck, Carl A.K. (7005014324)","7005014324","Viewpoints in clinical proteomics: When will proteomics deliver clinically useful information?","2012","Proteomics - Clinical Applications","9","10.1002/prca.201200020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865587204&doi=10.1002%2fprca.201200020&partnerID=40&md5=2ad9eef6cde9757346e561d4acd3df0d","Department of Immunotechnology, CREATE Health Translational Cancer Center, Lund University, Lund, BMC D13, Sweden","Borrebaeck C.A.K., Department of Immunotechnology, CREATE Health Translational Cancer Center, Lund University, Lund, BMC D13, Sweden","Despite massive efforts, proteomics has not delivered biomarkers of clinical value. However, the technologies that are emerging today have the power to reach deep into proteomes and identify the patterns associated with different diseases. Study design is then crucial and sample quality, bioinformatics approaches, prevalidation, using independent patient cohort need to attract increased attention before proteomics will contribute to the needs of personalized medicine. © 2012 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.","Biobanks; Bioinformatics; Over-fitting; Pre-validation; Signatures","Algorithms; Biological Markers; Databases, Protein; Humans; Proteomics; Reproducibility of Results; Translational Medical Research; biological marker; accuracy; amino acid composition; antibody affinity; antibody specificity; area under the curve; article; artificial neural network; Bayesian learning; bioinformatics; blood sampling; cancer localization; cancer staging; cancer tissue; early diagnosis; human; mass spectrometry; metastasis; patient satisfaction; priority journal; protein expression; proteomics; risk assessment; risk factor; screening test; support vector machine; validation process","","18628354","","","22696166","Article","Scopus","2-s2.0-84865587204"
"Taira R.K.; Soderland S.G.; Jakobovits R.M.","Taira, Ricky K. (35509805600); Soderland, Stephen G. (58934363900); Jakobovits, Rex M. (17934940400)","35509805600; 58934363900; 17934940400","Automatic structuring of radiology free-text reports","2001","Radiographics","91","10.1148/radiographics.21.1.g01ja18237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035220275&doi=10.1148%2fradiographics.21.1.g01ja18237&partnerID=40&md5=f39d5469d7dfc39b08e1a4d815c5229e","Department of Radiology, Children's Hosp. and Regl. Med. Ctr., Mailstop CH-69, Seattle, WA 98105, 4800 Sandpoint Way NE, United States; Department of Radiological Sciences, University of California, Los Angeles, CA, United States","Taira R.K., Department of Radiology, Children's Hosp. and Regl. Med. Ctr., Mailstop CH-69, Seattle, WA 98105, 4800 Sandpoint Way NE, United States; Soderland S.G., Department of Radiological Sciences, University of California, Los Angeles, CA, United States; Jakobovits R.M., Department of Radiological Sciences, University of California, Los Angeles, CA, United States","A natural language processor was developed that automatically structures the important medical information (eg, the existence, properties, location, and diagnostic interpretation of findings) contained in a radiology free-text document as a formal information model that can be interpreted by a computer program. The input to the system is a free-text report from a radiologic study. The system requires no reporting style changes on the part of the radiologist. Statistical and machine learning methods are used extensively throughout the system. A graphical user interface has been developed that allows the creation of hand-tagged training examples. Various aspects of the difficult problem of implementing an automated structured reporting system have been addressed, and the relevant technology is progressing well. Extensible Markup Language is emerging as the preferred syntactic standard for representing and distributing these structured reports within a clinical environment. Early successes hold out hope that similar statistically based models of language will allow deep understanding of textual reports. The success of these statistical methods will depend on the availability of large numbers of high-quality training examples for each radiologic subdomain. The acceptability of automated structured reporting systems will ultimately depend on the results of comprehensive evaluations.","Computers; Computers, diagnostic aid; Radiology and radiologists, design of radiological facilities; Radiology reporting systems","Humans; Radiology Information Systems; User-Computer Interface; article; computer interface; hospital information system; human","Radiological Society of North America Inc.","02715333","","","11158658","Article","Scopus","2-s2.0-0035220275"
"Cireşan D.; Meier U.; Masci J.; Schmidhuber J.","Cireşan, Dan (15041556100); Meier, Ueli (36656205700); Masci, Jonathan (40761927100); Schmidhuber, Jürgen (7003514621)","15041556100; 36656205700; 40761927100; 7003514621","Multi-column deep neural network for traffic sign classification","2012","Neural Networks","786","10.1016/j.neunet.2012.02.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861776914&doi=10.1016%2fj.neunet.2012.02.023&partnerID=40&md5=2536e8266ce9ce63f3e36b1442385ba6","IDSIA - USI - SUPSI, Manno - Lugano 6928, Galleria 2, Switzerland","Cireşan D., IDSIA - USI - SUPSI, Manno - Lugano 6928, Galleria 2, Switzerland; Meier U., IDSIA - USI - SUPSI, Manno - Lugano 6928, Galleria 2, Switzerland; Masci J., IDSIA - USI - SUPSI, Manno - Lugano 6928, Galleria 2, Switzerland; Schmidhuber J., IDSIA - USI - SUPSI, Manno - Lugano 6928, Galleria 2, Switzerland","We describe the approach that won the final phase of the German traffic sign recognition benchmark. Our method is the only one that achieved a better-than-human recognition rate of 99.46%. We use a fast, fully parameterizable GPU implementation of a Deep Neural Network (DNN) that does not require careful design of pre-wired feature extractors, which are rather learned in a supervised way. Combining various DNNs trained on differently preprocessed data into a Multi-Column DNN (MCDNN) further boosts recognition performance, making the system insensitive also to variations in contrast and illumination. © 2012 Elsevier Ltd.","Deep neural networks; Image classification; Image preprocessing; Traffic signs","Algorithms; Automatic Data Processing; Automobile Driving; Computer Graphics; Motor Vehicles; Neural Networks (Computer); Pattern Recognition, Automated; Vision, Ocular; Image classification; Neural networks; Feature extractor; GPU implementation; Image preprocessing; Pre-processed data; Recognition performance; Recognition rates; Traffic sign recognition; article; artificial neural network; classification algorithm; computer interface; image processing; image quality; learning algorithm; machine learning; mathematical computing; priority journal; process optimization; quality control; signal noise ratio; task performance; traffic sign recognition; Traffic signs","","18792782","","NNETE","22386783","Article","Scopus","2-s2.0-84861776914"
"Mathelier A.; Carbone A.","Mathelier, Anthony (36173135600); Carbone, Alessandra (57196175695)","36173135600; 57196175695","MIReNA: Finding microRNAs with high accuracy and no learning at genome scale and from deep sequencing data","2010","Bioinformatics","124","10.1093/bioinformatics/btq329","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956508095&doi=10.1093%2fbioinformatics%2fbtq329&partnerID=40&md5=c2f6d6fcd52766da99eba067b90fd752","UPMC Univ. Paris 06, FRE3214, Génomique Analytique, F-75006 Paris, 15 rue de l'Ecole de Médecine, France; CNRS, FRE3214, Laboratoire de Génomique des Microorganismes, F-75006 Paris, France","Mathelier A., UPMC Univ. Paris 06, FRE3214, Génomique Analytique, F-75006 Paris, 15 rue de l'Ecole de Médecine, France, CNRS, FRE3214, Laboratoire de Génomique des Microorganismes, F-75006 Paris, France; Carbone A., UPMC Univ. Paris 06, FRE3214, Génomique Analytique, F-75006 Paris, 15 rue de l'Ecole de Médecine, France, CNRS, FRE3214, Laboratoire de Génomique des Microorganismes, F-75006 Paris, France","Motivation: MicroRNAs (miRNAs) are a class of endogenes derived from a precursor (pre-miRNA) and involved in post-transcriptional regulation. Experimental identification of novel miRNAs is difficult because they are often transcribed under specific conditions and cell types. Several computational methods were developed to detect new miRNAs starting from known ones or from deep sequencing data, and to validate their pre-miRNAs. Results: We present a genome-wide search algorithm, called MIReNA, that looks for miRNA sequences by exploring a multidimensional space defined by only five (physical and combinatorial) parameters characterizing acceptable pre-miRNAs. MIReNA validates pre-miRNAs with high sensitivity and specificity, and detects new miRNAs by homology from known miRNAs or from deep sequencing data. A performance comparison between MIReNA and four available predictive systems has been done. MIReNA approach is strikingly simple but it turns out to be powerful at least as much as more sophisticated algorithmic methods. MIReNA obtains better results than three known algorithms that validate pre-miRNAs. It demonstrates that machine-learning is not a necessary algorithmic approach for pre-miRNAs computational validation. In particular, machine learning algorithms can only confirm pre-miRNAs that look alike known ones, this being a limitation while exploring species with no known pre-miRNAs. The possibility to adapt the search to specific species, possibly characterized by specific properties of their miRNAs and pre-miRNAs, is a major feature of MIReNA. A parameter adjustment calibrates specificity and sensitivity in MIReNA, a key feature for predictive systems, which is not present in machine learning approaches. Comparison of MIReNA with miRDeep using deep sequencing data to predict miRNAs highlights a highly specific predictive power of MIReNA. © The Author 2010. Published by Oxford University Press. All rights reserved.","","Algorithms; Animals; Artificial Intelligence; Base Sequence; Genome; Humans; MicroRNAs; microRNA; algorithm; animal; article; artificial intelligence; comparative study; evaluation; genome; human; nucleotide sequence; validation study","","14602059","","BOINF","20591903","Article","Scopus","2-s2.0-77956508095"
"Mihara M.; Hattori N.; Miyai I.","Mihara, Masahito (12243263100); Hattori, Noriaki (7201655764); Miyai, Ichiro (57197991576)","12243263100; 7201655764; 57197991576","Applications of Near-Infrared Spectroscopy in Movement Disorders","2013","Current Clinical Neurology","0","10.1007/978-1-62703-471-5_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897375961&doi=10.1007%2f978-1-62703-471-5_6&partnerID=40&md5=c13ba9428a5cab7b6a2dea5887d846ed","Department of Neurology, Graduate School of Medicine, Osaka University, Suita, Osaka 565-0871, 2-2, D-4 Yamadaoka, Japan; Neurorehabilitation Research Institute, Morinomiya Hospital, Joto-ku, Osaka 536-0025, 2-1-88, Morinomiya, Japan; Morinomiya Hospital, 536-0025 Joto-ku, Osaka, 2-1-88, Morinomiya, Japan","Mihara M., Department of Neurology, Graduate School of Medicine, Osaka University, Suita, Osaka 565-0871, 2-2, D-4 Yamadaoka, Japan; Hattori N., Neurorehabilitation Research Institute, Morinomiya Hospital, Joto-ku, Osaka 536-0025, 2-1-88, Morinomiya, Japan; Miyai I., Morinomiya Hospital, 536-0025 Joto-ku, Osaka, 2-1-88, Morinomiya, Japan","Near-infrared spectroscopy (NIRS) is a unique neuroimaging tool that allows for monitoring of cortical activation during daily activities such as standing, walking, and reaching. NIRS uses near-infrared light that penetrates skin and skull bone to measure task-related cortical vascular responses. Although NIRS cannot monitor deep brain structures such as the basal ganglia and cerebellum, its less onerous constraints are a characteristic advantage of this methodology. NIRS has been applied successfully in studies investigating the neural mechanisms for gait and postural control that are challenging to perform using other modalities. NIRS has also been utilized as a therapeutic tool in neurofeedback and brain-machine interface applications. Despite some shortcomings, NIRS could be a useful tool in the motor control study in a clinical setting, and might be effective as a therapeutic intervention.","","article; body equilibrium; body posture; brain computer interface; cognition; functional magnetic resonance imaging; functional near infrared spectroscopy; gait; gait disorder; human; learning; locomotion; motor control; motor dysfunction; motor performance; near infrared spectroscopy; neurofeedback; neurologic disease; priority journal; sensorimotor cortex; standing","Humana Press Inc.","15590585","","","","Article","Scopus","2-s2.0-84897375961"
"Blazadonakis M.; Moustakis V.; Charissis G.","Blazadonakis, Michalis (23388271000); Moustakis, Vassilis (7003503719); Charissis, Giorgos (6701758456)","23388271000; 7003503719; 6701758456","Deep assessment of machine learning techniques using patient treatment in acute abdominal pain in children","1996","Artificial Intelligence in Medicine","21","10.1016/S0933-3657(96)00354-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030294553&doi=10.1016%2fS0933-3657%2896%2900354-5&partnerID=40&md5=49e0940991fd2a8e27586a9783f80b1a","Institute of Computer Science, Found. for Res./Technol. - Hellas, Science and Technology Park of Crete, 71110 Heraklion, P.O. Box 1385, Greece; Dept. of Prod./Mgmt. Engineering, Technical University of Crete, 73132 Chania, Greece; Paediatric Surgery Clinic, University Hospital of Crete, Heraklion, Greece","Blazadonakis M., Institute of Computer Science, Found. for Res./Technol. - Hellas, Science and Technology Park of Crete, 71110 Heraklion, P.O. Box 1385, Greece; Moustakis V., Institute of Computer Science, Found. for Res./Technol. - Hellas, Science and Technology Park of Crete, 71110 Heraklion, P.O. Box 1385, Greece, Dept. of Prod./Mgmt. Engineering, Technical University of Crete, 73132 Chania, Greece; Charissis G., Paediatric Surgery Clinic, University Hospital of Crete, Heraklion, Greece","Learning from patient records may aid knowledge acquisition and decision making. Existing inductive machine learning (ML) systems such us NewId, CN2, C4.5 and AQ15 learn from past case histories using symbolic and/or numeric values. These systems learn symbolic rules (IF... THEN like) which link an antecedent set of clinical factors to a consequent class or decision. This paper compares the learning performance of alternative ML systems with each other and with respect to a novel approach using logic minimization, called LML, to learn from data. Patient cases were taken from the archives of the Paediatric Surgery Clinic of the University Hospital of Crete, Heraklion, Greece. Comparison of ML system performance is based both on classification accuracy and on informal expert assessment of learned knowledge.; Learning from patient records may aid knowledge acquisition and decision making. Existing inductive machine learning (ML) systems such us NewId, CN2, C4.5 and AQ15 learn from past case histories using symbolic and/or numeric values. These systems learn symbolic rules (IF... THEN like) which link an antecedent set of clinical factors to a consequent class or decision. This paper compares the learning performance of alternative ML systems with each other and with respect to a novel approach using logic minimization, called LML, to learn from data. Patient cases were taken from the archives of the Paediatric Surgery Clinic of the University Hospital of Crete, Heraklion, Greece. Comparison of ML system performance is based both on classification accuracy and on informal expert assessment of learned knowledge.","acute abdominal pain in children; logic minimization; machine learning","Classification (of information); Decision making; Expert systems; Gastroenterology; Knowledge acquisition; Medical computing; Patient treatment; Acute abdominal pain; Logic minimizations; acute abdomen; article; child; classification; expert system; human; medical decision making; priority journal; Learning systems","Elsevier B.V.","09333657","","AIMEE","8985539","Article","Scopus","2-s2.0-0030294553"
"Szcześniak M.W.; Makałowska I.","Szcześniak, Michał W. (37078330500); Makałowska, Izabela (6701670159)","37078330500; 6701670159","MiRNEST 2.0: A database of plant and animal microRNAs","2014","Nucleic Acids Research","58","10.1093/nar/gkt1156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891815183&doi=10.1093%2fnar%2fgkt1156&partnerID=40&md5=0c6f41c8363fbb71456eff25dad66071","Laboratory of Bioinformatics, Adam Mickiewicz University in Poznań, Poznań, Poland","Szcześniak M.W., Laboratory of Bioinformatics, Adam Mickiewicz University in Poznań, Poznań, Poland; Makałowska I., Laboratory of Bioinformatics, Adam Mickiewicz University in Poznań, Poznań, Poland","Ever growing interest in microRNAs has immensely populated the number of resources and research papers devoted to the field and, as a result, it becomes more and more demanding to find miRNA data of interest. To mitigate this problem, we created miRNEST database (http://mirnest.amu.edu.pl), an integrative microRNAs resource. In its updated version, named miRNEST 2.0, the database is complemented with our extensive miRNA predictions from deep sequencing libraries, data from plant degradome analyses, results of pre-miRNA classification with HuntMi and miRNA splice sites information. We also added download and upload options and improved the user interface to make it easier to browse through miRNA records. © 2013 The Author(s). Published by Oxford University Press.","","Animals; Databases, Nucleic Acid; High-Throughput Nucleotide Sequencing; Internet; MicroRNAs; RNA Precursors; RNA Splice Sites; RNA, Plant; Sequence Analysis, RNA; Animalia; microRNA; microRNA; plant RNA; RNA precursor; RNA splicing; Arabidopsis thaliana; article; barley; barrel medic; classification algorithm; computer interface; expressed sequence tag; gene mapping; integration; machine learning; Malus domestica; miRNEST 2.0 database; nonhuman; nucleic acid database; peach; Physcomitrella patens; priority journal; RNA sequence; RNA structure; soybean; structure analysis; tomato; animal; chemistry; high throughput sequencing; Internet; RNA splicing; sequence analysis; Article; data base; degradome analysis; grape; HuntMi; miRNEST 2.0; RNA analysis; Triticum aestivum","","13624962","","NARHA","24243848","Article","Scopus","2-s2.0-84891815183"
"Denil M.; Bazzani L.; Larochelle H.; de Freitas N.","Denil, Misha (36132695800); Bazzani, Loris (35589476700); Larochelle, Hugo (14827997400); de Freitas, Nando (6602751682)","36132695800; 35589476700; 14827997400; 6602751682","Learning where to attend with deep architectures for image tracking","2012","Neural Computation","156","10.1162/NECO_a_00312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867478719&doi=10.1162%2fNECO_a_00312&partnerID=40&md5=48e97ff2a8fc7baa0379146071b9f828","University of British Columbia, Vancouver, BC V6G 1Z4, Canada; University of Verona, Verona, 37134, Italy; Université de Sherbrooke, Sherbrooke J1K 2R1, Canada","Denil M., University of British Columbia, Vancouver, BC V6G 1Z4, Canada; Bazzani L., University of Verona, Verona, 37134, Italy; Larochelle H., Université de Sherbrooke, Sherbrooke J1K 2R1, Canada; de Freitas N., University of British Columbia, Vancouver, BC V6G 1Z4, Canada","We discuss an attentional model for simultaneous object tracking and recognition that is driven by gaze data. Motivated by theories of perception, the model consists of two interacting pathways, identity and control, intended tomirror the what andwhere pathways in neuroscience models. The identity pathway models object appearance and performs classification using deep (factored)-restricted Boltzmann machines. At each point in time, the observations consist of foveated images, with decaying resolution toward the periphery of the gaze. The control pathway models the location, orientation, scale, and speed of the attended object. The posterior distribution of these states is estimated with particle filtering. Deeper in the control pathway, we encounter an attentional mechanism that learns to select gazes so as to minimize tracking uncertainty. Unlike in our previous work, we introduce gaze selection strategies that operate in the presence of partial information and on a continuous action space. We show that a straightforward extension of the existing approach to the partial information setting results in poor performance, and we propose an alternative method based on modeling the reward surface as a gaussian process. This approach gives good performance in the presence of partial information and allows us to expand the action space from a small, discrete set of fixation points to a continuous domain. © 2012 Massachusetts Institute of Technology.","","Algorithms; Attention; Distance Perception; Humans; Learning; Orientation; Pattern Recognition, Visual; Space Perception; algorithm; article; attention; depth perception; distance perception; human; learning; orientation; pattern recognition; physiology","","1530888X","","","22509964","Article","Scopus","2-s2.0-84867478719"
"Gromiha M.M.; Harini K.; Sowdhamini R.; Fukui K.","Gromiha, M Michael (7006556058); Harini, K (55179569100); Sowdhamini, R (57210222753); Fukui, Kazuhiko (7402645917)","7006556058; 55179569100; 57210222753; 7402645917","Relationship between amino acid properties and functional parameters in olfactory receptors and discrimination of mutants with enhanced specificity","2012","BMC Bioinformatics","10","10.1186/1471-2105-13-S7-S1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872788665&doi=10.1186%2f1471-2105-13-S7-S1&partnerID=40&md5=ca72247753eb8fa90eb94871c16f6db5","Department of Biotechnology, Indian Institute of Technology Madras, Chennai 600 036, Tamilnadu, India; National Center for Biological Sciences, Bangalore, India; Computational Biology Research Center, National Institute of Advanced Industrial Science and Technology, Koto-ku, Tokyo 135-0064, 2-4-7 Aomi, Japan","Gromiha M.M., Department of Biotechnology, Indian Institute of Technology Madras, Chennai 600 036, Tamilnadu, India; Harini K., National Center for Biological Sciences, Bangalore, India; Sowdhamini R., National Center for Biological Sciences, Bangalore, India; Fukui K., Computational Biology Research Center, National Institute of Advanced Industrial Science and Technology, Koto-ku, Tokyo 135-0064, 2-4-7 Aomi, Japan","Background: Olfactory receptors are key components in signal transduction. Mutations in olfactory receptors alter the odor response, which is a fundamental response of organisms to their immediate environment. Understanding the relationship between odorant response and mutations in olfactory receptors is an important problem in bioinformatics and computational biology. In this work, we have systematically analyzed the relationship between various physical, chemical, energetic and conformational properties of amino acid residues, and the change of odor response/compound's potency/half maximal effective concentration (EC50) due to amino acid substitutions.Results: We observed that both the characteristics of odorant molecule (ligand) and amino acid properties are important for odor response and EC50. Additional information on neighboring and surrounding residues of the mutants enhanced the correlation between amino acid properties and EC50. Further, amino acid properties have been combined systematically using multiple regression techniques and we obtained a correlation of 0.90-0.98 with odor response/EC50 of goldfish, mouse and human olfactory receptors. In addition, we have utilized machine learning methods to discriminate the mutants, which enhance or reduce EC50 values upon mutation and we obtained an accuracy of 93% and 79% for self-consistency and jack-knife tests, respectively.Conclusions: Our analysis provides deep insights for understanding the odor response of olfactory receptor mutants and the present method could be used for identifying the mutants with enhanced specificity. © 2012 Gromiha et al.; licensee BioMed Central Ltd.","","Amino Acid Substitution; Animals; Goldfish; Humans; Ligands; Mice; Molecular Conformation; Mutation; Odors; Receptors, Odorant; Regression Analysis; Signal Transduction; Bioinformatics; Chemical analysis; Learning systems; Signal transduction; ligand; Computational biology; Conformational properties; Effective concentration; Functional parameters; Human olfactory receptors; Immediate environment; Machine learning methods; Multiple regression techniques; amino acid substitution; animal; article; chemistry; conformation; genetics; goldfish; human; metabolism; mouse; mutation; odor; olfactory receptor; regression analysis; signal transduction; Amino acids","","14712105","","BBMIC","22594995","Article","Scopus","2-s2.0-84872788665"
"Binder T.; Garbe C.S.; Wagenbach D.; Freitag J.; Kipfstuhl S.","Binder, T. (55570301600); Garbe, C.S. (7101929484); Wagenbach, D. (7003279605); Freitag, J. (7006093704); Kipfstuhl, S. (6507770295)","55570301600; 7101929484; 7003279605; 7006093704; 6507770295","Extraction and parametrization of grain boundary networks in glacier ice, using a dedicated method of automatic image analysis","2013","Journal of Microscopy","10","10.1111/jmi.12029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876094792&doi=10.1111%2fjmi.12029&partnerID=40&md5=57bc7aea33534c9df560e6a569317ad7","Interdisciplinary Center for Scientific Computing, Universität Heidelberg, Heidelberg, Germany; Institut für Umweltphysik, Universität Heidelberg, Heidelberg, Germany; Alfred Wegener Institute for Polar and Marine Research, Bremerhaven, Germany","Binder T., Interdisciplinary Center for Scientific Computing, Universität Heidelberg, Heidelberg, Germany; Garbe C.S., Interdisciplinary Center for Scientific Computing, Universität Heidelberg, Heidelberg, Germany; Wagenbach D., Institut für Umweltphysik, Universität Heidelberg, Heidelberg, Germany; Freitag J., Alfred Wegener Institute for Polar and Marine Research, Bremerhaven, Germany; Kipfstuhl S., Alfred Wegener Institute for Polar and Marine Research, Bremerhaven, Germany","Microstructure analysis of polar ice cores is vital to understand the processes controlling the flow of polar ice on the microscale. This paper presents an automatic image processing framework for extraction and parametrization of grain boundary networks from images of the NEEM deep ice core. As cross-section images are acquired using controlled surface sublimation, grain boundaries and air inclusions appear dark, whereas the inside of grains appears grey. The initial segmentation step of the software is to separate possible boundaries of grains and air inclusions from background. A Machine learning approach is utilized to gain automatic, reliable classification, which is required for processing large data sets along deep ice cores. The second step is to compose the perimeter of section profiles of grains by planar sections of the grain surface between triple points. Ultimately, grain areas, grain boundaries and triple junctions of the later are diversely parametrized. High resolution is achieved, so that small grain sizes and local curvatures of grain boundaries can systematically be investigated. © 2013 Royal Microscopical Society.","Grain boundary network; Ice microstructure; Image segmentation; Machine learning; Surface sublimation etching","Classification (of information); Data handling; Extraction; Ice; Learning systems; Microstructure; Sublimation; Automatic image analysis; Glacier ice; Grain boundary network; Grain-boundaries; Ice core; Ice microstructure; Images segmentations; Machine-learning; Parametrizations; Surface sublimation etching; agricultural parameters; article; defense mechanism; extraction; glacier; grain; image analysis; image processing; machine learning; priority journal; random forest; watershed; Image segmentation","","00222720","","JMICA","","Article","Scopus","2-s2.0-84876094792"
"Segal N.H.; Pavlidis P.; Noble W.S.; Antonescu C.R.; Viale A.; Wesley U.V.; Busam K.; Gallardo H.; DeSantis D.; Brennan M.F.; Cordon-Cardo C.; Wolchok J.D.; Houghton A.N.","Segal, Neil H. (7102997595); Pavlidis, Paul (7004159655); Noble, William S. (7102482003); Antonescu, Cristina R. (7006213102); Viale, Agnes (7006429487); Wesley, Umadevi V. (35609728700); Busam, Klaus (7005393264); Gallardo, Humilidad (7003352937); DeSantis, Dianne (8567382300); Brennan, Murray F. (7402656294); Cordon-Cardo, Carlos (57205281879); Wolchok, Jedd D. (7003481268); Houghton, Alan N. (7102646773)","7102997595; 7004159655; 7102482003; 7006213102; 7006429487; 35609728700; 7005393264; 7003352937; 8567382300; 7402656294; 57205281879; 7003481268; 7102646773","Classification of clear-cell sarcoma as a subtype of melanoma by genomic profiling","2003","Journal of Clinical Oncology","169","10.1200/JCO.2003.10.108","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037797247&doi=10.1200%2fJCO.2003.10.108&partnerID=40&md5=2dc5bef177ad263501ac2bc6fa104c0c","Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States","Segal N.H., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Pavlidis P., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Noble W.S., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Antonescu C.R., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Viale A., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Wesley U.V., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Busam K., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Gallardo H., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; DeSantis D., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Brennan M.F., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Cordon-Cardo C., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Wolchok J.D., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States; Houghton A.N., Memorial Sloan-Kettering Cancer Center and Columbia Genome Center, Columbia University, New York, NY 10021, 1275 York Ave, United States","Purpose: To develop a genome-based classification scheme for clear-cell sarcoma (CCS), also known as melanoma of soft parts (MSP), which would have implications for diagnosis and treatment. This tumor displays characteristic features of soft tissue sarcoma (STS), including deep soft tissue primary location and a characteristic translocation, t(12; 22)(q13;q12), involving EWS and ATF1 genes. CCS/MSP also has typical melanoma features, including immunoreactrvity for S100 and HMB45, pigmentation, MITF-M expression, and a propensity for regional lymph node metastases. Materials and Methods: RNA samples from 21 cell lines and 60 pathologically confirmed cases of STS, melanoma, and CCS/MSP were examined using the U95A GeneChip (Affymetrix, Santa Clara, CA). Hierarchical cluster analysis, principal component analysis, and support vector machine (SVM) analysis exploited genomic correlations within the data to classify CCS/MSP. Results: Unsupervised analyses demonstrated a clear distinction between STS and melanoma and, furthermore, showed that CCS/MSP cluster with the melanomas as a distinct group. A supervised SVM learning approach further validated this finding and provided a user-independent approach to diagnosis. Genes of interest that discriminate CCS/MSP included those encoding melanocyte differentiation antigens, MITF, SOX10, ERBB3, and FGFR1. Conclusion: Gene expression profiles support the classification of CCS/MSP as a distinct genomic subtype of melanoma. Analysis of these gene profiles using the SVM may be an important diagnostic tool. Genomic analysis identified potential targets for the development of therapeutic strategies in the treatment of this disease. © 2003 by American Society of Clinical Oncology.","","Algorithms; Antigens, Neoplasm; Artificial Intelligence; Diagnosis, Differential; Gene Expression Profiling; Humans; Immunohistochemistry; Melanoma; Oligonucleotide Array Sequence Analysis; Sarcoma, Clear Cell; Soft Tissue Neoplasms; Tumor Cells, Cultured; activating transcription factor 1; epidermal growth factor receptor 3; fibroblast growth factor receptor 1; microphthalmia associated transcription factor; protein S 100; RNA binding protein EWS; transcription factor Sox10; tumor antigen; article; cancer cell; cancer classification; cell differentiation; chromosome 12q; chromosome 13q; chromosome translocation 12; chromosome translocation 22; clear cell sarcoma; clinical feature; cluster analysis; controlled study; correlation analysis; DNA microarray; genomics; human; human cell; immunoreactivity; lymph node metastasis; melanocyte; melanoma; pigmentation; principal component analysis; priority journal; protein expression; soft tissue sarcoma; support vector machine; tumor localization; validation study; algorithm; artificial intelligence; cell culture; classification; differential diagnosis; DNA microarray; gene expression profiling; genetics; immunohistochemistry; pathology; soft tissue tumor","","0732183X","","JCOND","12721254","Article","Scopus","2-s2.0-0037797247"
"Breuer G.; Schweizer K.; Schüttler J.; Weiß M.; Vladut A.","Breuer, G. (35847501600); Schweizer, K. (55489340000); Schüttler, J. (7005142974); Weiß, M. (58590804400); Vladut, A. (55980819900)","35847501600; 55489340000; 7005142974; 58590804400; 55980819900","""Jump in at the deep end"". Simulator-based learning in acute care; [""Sprung ins kalte wasser"". Simulatorbasiertes lernen in akutmedizinischen bereichen]","2014","Anaesthesist","7","10.1007/s00101-013-2270-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896044940&doi=10.1007%2fs00101-013-2270-y&partnerID=40&md5=516326a62910c5c888ff7c03ae621540","Klinik für Anästhesiologie, Universitätsklinikum Erlangen, 91054 Erlangen, Krankenhausstr. 12, Germany; Pädagogische Psychologie, Pädagogische Hochschule Weingarten, Germany; Pädagogische Psychologie, Universität Erlangen-Nürnberg, Erlangen, Germany","Breuer G., Klinik für Anästhesiologie, Universitätsklinikum Erlangen, 91054 Erlangen, Krankenhausstr. 12, Germany; Schweizer K., Pädagogische Psychologie, Pädagogische Hochschule Weingarten, Germany; Schüttler J., Klinik für Anästhesiologie, Universitätsklinikum Erlangen, 91054 Erlangen, Krankenhausstr. 12, Germany; Weiß M., Klinik für Anästhesiologie, Universitätsklinikum Erlangen, 91054 Erlangen, Krankenhausstr. 12, Germany; Vladut A., Pädagogische Psychologie, Universität Erlangen-Nürnberg, Erlangen, Germany","Background. With high-fidelity simulators in a modern blended learning setting, students are able to acquire knowledge and practical skills in acute medicine in realistic scenarios. However, it has not yet been clarified if the sequence of linking between knowledge and simulator-based training of practical skills plays an important role for increasing knowledge, for the self-concept and learning emotions of trainees. Aim. In a pilot study the influence of the type of knowledge acquisition under two independent conditions was investigated in which the order of presenting the learning material (firstly theory and then simulation vs. simulation elements before the theory) was reversed. In addition the influence of individual attributes of personality on the construction of situated knowledge was correlated with these conditions in two groups. Material and methods. To investigate the outcome of simulator-based learning 20 students were randomly allocated to one of the two conditions and undertook two scenarios (anaphylactic shock and myocardial infarction), whereby the theoretical lessons were given either before or after the scenarios. Using standardized questionnaires and problem-centered semi-standardized interviews, the following variables of the participants were assessed: personality traits, current positive and negative feelings, professional self-concept, general self-efficacy and coping strategies for stress. Theoretical knowledge and practical skills were assessed using a knowledge test and standardized assessment questionnaires which also focused on performance and patient safety. Results. All together the results showed a slight advantage for the condition of theory before simulation which was not determined by the acquisition of knowledge but by a better performance of trainees as assessed by the trainers. Regarding knowledge acquisition, no statistically significant differences could be shown. Significant differences (p<0.05) were found for negative feelings (very intense negative emotional state) and for the professional self-concept (perception of own professional skills) in favor of the theory then simulation condition. More extrovert participants showed poorer results which could not be attributed to one of the conditions. However, the participants always assessed the allocated learning condition as the best premise for effective learning outcome. Reaction to stress has been described as ""jumping in at the deep end"" as well as the lasting effect on learning from errors. Conclusion. In the context of simulation-based teaching, the learning outcome not only depends on knowledge, practical skills and motivational variables but also on the presence of negative feelings, ability self-concepts and various personality traits. There was a trend which showed that simulation in the field of anesthesiology and emergency medicine should be set up with the theoretical basis first in order to avoid negative feelings. © Springer-Verlag 2014.","Clinical competence; Curriculum; Emotions; Learning; Self-concept","Adult; Anesthesiology; Clinical Competence; Emergency Medicine; Emotions; Female; Humans; Learning; Male; Patient Simulation; Pilot Projects; Self Concept; Young Adult; anaphylactic shock; article; coping behavior; emergency care; heart infarction; human; human experiment; knowledge; learning; machine learning; medical education; medical student; personality; pilot study; professional competence; questionnaire; self concept; simulation; simulator; skill; stress; theory; adult; anesthesiology; clinical competence; controlled study; education; emergency medicine; emotion; female; learning; male; randomized controlled trial; teaching; young adult","Springer Verlag","00032417","","ANATA","24390682","Article","Scopus","2-s2.0-84896044940"
"Lederer C.; Heider D.; van den Boom J.; Hoffmann D.; Mueller J.W.; Bayer P.","Lederer, Christoph (53881534000); Heider, Dominik (16743488600); van den Boom, Johannes (35849234000); Hoffmann, Daniel (7202976733); Mueller, Jonathan W. (7402829417); Bayer, Peter (7004945843)","53881534000; 16743488600; 35849234000; 7202976733; 7402829417; 7004945843","Single-domain parvulins constitute a specific marker for recently proposed deep-branching archaeal subgroups","2011","Evolutionary Bioinformatics","4","10.4137/EBO.S7683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053582114&doi=10.4137%2fEBO.S7683&partnerID=40&md5=e105c5e85cc666436eab045ab1f551bf","Departments for Structural and Medicinal Biochemistry, Faculty of Biology, University of Duisburg-Essen, 45117 Essen, Germany; Bioinformatics, Centre for Medical Biotechnology (ZMB), Faculty of Biology, University of Duisburg-Essen, 45117 Essen, Germany","Lederer C., Departments for Structural and Medicinal Biochemistry, Faculty of Biology, University of Duisburg-Essen, 45117 Essen, Germany; Heider D., Bioinformatics, Centre for Medical Biotechnology (ZMB), Faculty of Biology, University of Duisburg-Essen, 45117 Essen, Germany; van den Boom J., Departments for Structural and Medicinal Biochemistry, Faculty of Biology, University of Duisburg-Essen, 45117 Essen, Germany; Hoffmann D., Bioinformatics, Centre for Medical Biotechnology (ZMB), Faculty of Biology, University of Duisburg-Essen, 45117 Essen, Germany; Mueller J.W., Departments for Structural and Medicinal Biochemistry, Faculty of Biology, University of Duisburg-Essen, 45117 Essen, Germany; Bayer P., Departments for Structural and Medicinal Biochemistry, Faculty of Biology, University of Duisburg-Essen, 45117 Essen, Germany","Peptidyl-prolyl cis/trans isomerases (PPIases) are enzymes assisting protein folding and protein quality control in organisms of all kingdoms of life. In contrast to the other sub-classes of PPIases, the cyclophilins and the FK-506 binding proteins, little was formerly known about the parvulin type of PPIase in Archaea. Recently, the first solution structure of an archaeal parvulin, the PinA protein from Cenarchaeum symbiosum, was reported. Investigation of occurrence and frequency of PPIase sequences in numerous archaeal genomes now revealed a strong tendency for thermophilic microorganisms to reduce the number of PPIases. Single-domain parvulins were mostly found in the genomes of recently proposed deep-branching archaeal subgroups, the Thaumarchaeota and the ARMANs (archaeal Richmond Mine acidophilic nanoorganisms). Hence, we used the parvulin sequence to reclassify available archaeal metagenomic contigs, thereby, adding new members to these subgroups. A combination of genomic background analysis and phylogenetic approaches of parvulin sequences suggested that the assigned sequences belong to at least two distinct groups of Thaumarchaeota. Finally, machine learning approaches were applied to identify amino acid residues that separate archaeal and bacterial parvulin proteins from each other. When mapped onto the recent PinA solution structure, most of these positions form a cluster at one site of the protein possibly indicating a different functionality of the two groups of parvulin proteins. © the author(s), publisher and licensee Libertas Academica Ltd.","Archaeal protein; Pin1; PPIase; Single-domain parvulin; Thaumarchaeota","Archaea; Bacteria (microorganisms); Cenarchaeum symbiosum; archaeal protein; bacterial protein; biological marker; isomerase; parvulin; prolyl isomerase; protein PinA; unclassified drug; amino acid sequence; archaebacterium; article; bacterial genome; Cenarchaeum symbiosum; controlled study; DNA sequence; enzyme localization; genome analysis; machine learning; mesophilic bacterium; metagenomics; nitrosopumilus maritimus; nucleotide sequence; phylogenetic tree; protein determination; protein domain; residue analysis; sequence analysis; structure analysis; Thaumarchaeota; thermophilic archaeon","Libertas Academica Ltd.","11769343","","","","Article","Scopus","2-s2.0-80053582114"
"In Y.; Lee S.K.; Kim P.J.; No K.T.","In, Youngyong (7005993885); Lee, Sung Kwang (7601418476); Kim, Pil Je (58451308700); No, Kyoung Tai (7102197764)","7005993885; 7601418476; 58451308700; 7102197764","Prediction of acute toxicity to fathead minnow by local model based QSAR and global QSAR approaches","2012","Bulletin of the Korean Chemical Society","14","10.5012/bkcs.2012.33.2.613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863147203&doi=10.5012%2fbkcs.2012.33.2.613&partnerID=40&md5=506a0288d90b55fc46e8729cc45d48af","Bioinformatics and Molecular Design Research Center, Seoul 120-749, South Korea; Department of Chemistry, Hannam University, Daejeon 305-811, South Korea; National Institute of Environmental Research, Incheon 404-170, South Korea; Department of Biotechnology, Yonsei University, Seoul 120-749, South Korea","In Y., Bioinformatics and Molecular Design Research Center, Seoul 120-749, South Korea; Lee S.K., Department of Chemistry, Hannam University, Daejeon 305-811, South Korea; Kim P.J., National Institute of Environmental Research, Incheon 404-170, South Korea; No K.T., Bioinformatics and Molecular Design Research Center, Seoul 120-749, South Korea, Department of Biotechnology, Yonsei University, Seoul 120-749, South Korea","We applied several machine learning methods for developing QSAR models for prediction of acute toxicity to fathead minnow. The multiple linear regression (MLR) and artificial neural network (ANN) method were applied to predict 96 h LC50 (median lethal concentration) of 555 chemical compounds. Molecular descriptors based on 2D chemical structure were calculated by PreADMET program. The recursive partitioning (RP) model was used for grouping of mode of actions as reactive or narcosis, followed by MLR method of chemicals within the same mode of action. The MLR, ANN, and two RP-MLR models possessed correlation coefficients (R2) as 0.553, 0.618, 0.632, and 0.605 on test set, respectively. The consensus model of ANN and two RP-MLR models was used as the best model on training set and showed good predictivity (R2=0.663) on the test set.","Acute toxicity; ANN; Consensus model; Fathead minnow; QSAR","Chemical compounds; Deep neural networks; Forecasting; Learning systems; Linear regression; Molecular graphics; Neural networks; Regression analysis; Toxicity; Acute toxicity; Consensus models; Correlation coefficient; Fathead minnow; Machine learning methods; Median Lethal concentration; Multiple linear regressions; QSAR; Computational chemistry","Korean Chemical Society","02532964","","BKCSD","","Article","Scopus","2-s2.0-84863147203"
"Saulnier D.M.; Riehle K.; Mistretta T.-A.; Diaz M.-A.; Mandal D.; Raza S.; Weidler E.M.; Qin X.; Coarfa C.; Milosavljevic A.; Petrosino J.F.; Highlander S.; Gibbs R.; Lynch S.V.; Shulman R.J.; Versalovic J.","Saulnier, Delphine M. (14029177300); Riehle, Kevin (54389701100); Mistretta, Toni-Ann (6506940136); Diaz, Maria-Alejandra (7402044219); Mandal, Debasmita (57212398056); Raza, Sabeen (7102353045); Weidler, Erica M. (26424158700); Qin, Xiang (57037659400); Coarfa, Cristian (8869754900); Milosavljevic, Aleksandar (7004058696); Petrosino, Joseph F. (6603064501); Highlander, Sarah (7004172855); Gibbs, Richard (7202068919); Lynch, Susan V. (8578897800); Shulman, Robert J. (56961627200); Versalovic, James (7003744341)","14029177300; 54389701100; 6506940136; 7402044219; 57212398056; 7102353045; 26424158700; 57037659400; 8869754900; 7004058696; 6603064501; 7004172855; 7202068919; 8578897800; 56961627200; 7003744341","Gastrointestinal microbiome signatures of pediatric patients with irritable bowel syndrome","2011","Gastroenterology","531","10.1053/j.gastro.2011.06.072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054851581&doi=10.1053%2fj.gastro.2011.06.072&partnerID=40&md5=0100543203fd6fc02c3c9f21cc46b50c","Departments of Pathology and Immunology, Baylor College of Medicine, Houston, TX, United States; Department of Pathology, Texas Children's Hospital, Houston, TX, United States; NIZO, Ede, Netherlands; Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, United States; Bioinformatics Research Laboratory, Baylor College of Medicine, Houston, TX, United States; Department of Medicine, University of California San Francisco, San Francisco, CA, United States; Department of Pediatrics, Baylor College of Medicine, Houston, TX, United States; Children's Nutrition Research Center, Houston, TX, United States; Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States; Department of Molecular Virology and Microbiology, Baylor College of Medicine, Houston, TX, United States; Center for Metagenomics and Microbiome Research, Baylor College of Medicine, Houston, TX, United States","Saulnier D.M., Departments of Pathology and Immunology, Baylor College of Medicine, Houston, TX, United States, Department of Pathology, Texas Children's Hospital, Houston, TX, United States, NIZO, Ede, Netherlands; Riehle K., Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, United States, Bioinformatics Research Laboratory, Baylor College of Medicine, Houston, TX, United States; Mistretta T.-A., Departments of Pathology and Immunology, Baylor College of Medicine, Houston, TX, United States, Department of Pathology, Texas Children's Hospital, Houston, TX, United States; Diaz M.-A., Departments of Pathology and Immunology, Baylor College of Medicine, Houston, TX, United States, Department of Pathology, Texas Children's Hospital, Houston, TX, United States; Mandal D., Department of Medicine, University of California San Francisco, San Francisco, CA, United States; Raza S., Departments of Pathology and Immunology, Baylor College of Medicine, Houston, TX, United States, Department of Pathology, Texas Children's Hospital, Houston, TX, United States; Weidler E.M., Department of Pediatrics, Baylor College of Medicine, Houston, TX, United States, Children's Nutrition Research Center, Houston, TX, United States; Qin X., Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States; Coarfa C., Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, United States, Bioinformatics Research Laboratory, Baylor College of Medicine, Houston, TX, United States; Milosavljevic A., Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, United States, Bioinformatics Research Laboratory, Baylor College of Medicine, Houston, TX, United States; Petrosino J.F., Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States, Department of Molecular Virology and Microbiology, Baylor College of Medicine, Houston, TX, United States, Center for Metagenomics and Microbiome Research, Baylor College of Medicine, Houston, TX, United States; Highlander S., Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States, Department of Molecular Virology and Microbiology, Baylor College of Medicine, Houston, TX, United States; Gibbs R., Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States; Lynch S.V., Department of Medicine, University of California San Francisco, San Francisco, CA, United States; Shulman R.J., Department of Pediatrics, Baylor College of Medicine, Houston, TX, United States, Children's Nutrition Research Center, Houston, TX, United States; Versalovic J., Departments of Pathology and Immunology, Baylor College of Medicine, Houston, TX, United States, Department of Pathology, Texas Children's Hospital, Houston, TX, United States, Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, United States, Department of Pediatrics, Baylor College of Medicine, Houston, TX, United States, Department of Molecular Virology and Microbiology, Baylor College of Medicine, Houston, TX, United States","Background & Aims: The intestinal microbiomes of healthy children and pediatric patients with irritable bowel syndrome (IBS) are not well defined. Studies in adults have indicated that the gastrointestinal microbiota could be involved in IBS. Methods: We analyzed 71 samples from 22 children with IBS (pediatric Rome III criteria) and 22 healthy children, ages 7-12 years, by 16S ribosomal RNA gene sequencing, with an average of 54,287 reads/stool sample (average 454 read length = 503 bases). Data were analyzed using phylogenetic-based clustering (Unifrac), or an operational taxonomic unit (OTU) approach using a supervised machine learning tool (randomForest). Most samples were also hybridized to a microarray that can detect 8741 bacterial taxa (16S rRNA PhyloChip). Results: Microbiomes associated with pediatric IBS were characterized by a significantly greater percentage of the class γ-proteobacteria (0.07% vs 0.89% of total bacteria, respectively; P < .05); 1 prominent component of this group was Haemophilus parainfluenzae. Differences highlighted by 454 sequencing were confirmed by high-resolution PhyloChip analysis. Using supervised learning techniques, we were able to classify different subtypes of IBS with a success rate of 98.5%, using limited sets of discriminant bacterial species. A novel Ruminococcus-like microbe was associated with IBS, indicating the potential utility of microbe discovery for gastrointestinal disorders. A greater frequency of pain correlated with an increased abundance of several bacterial taxa from the genus Alistipes. Conclusions: Using16S metagenomics by PhyloChip DNA hybridization and deep 454 pyrosequencing, we associated specific microbiome signatures with pediatric IBS. These findings indicate the important association between gastrointestinal microbes and IBS in children; these approaches might be used in diagnosis of functional bowel disorders in pediatric patients. © 2011 AGA Institute.","16S rRNA; 454 Sequencing; Functional Abdominal Pain; Phylo-Chip","Alcaligenaceae; article; Bacteroidaceae; child; clinical article; Clostridiaceae; controlled study; Coriobacteriaceae; DNA hybridization; Enterobacteriaceae; Enterococcaceae; Erysipelotrichaceae; Eubacteriaceae; feces analysis; female; Gammaproteobacteria; gastrointestinal pain; gene sequence; Haemophilus parainfluenzae; human; intestine flora; irritable colon; Lachnospiraceae; male; microarray analysis; nonhuman; phylogeny; Porphyromonadaceae; Prevotellaceae; priority journal; Ruminococcus; school child; Streptococcaceae; Veillonella","W.B. Saunders","00165085","","GASTA","","Article","Scopus","2-s2.0-80054851581"
"Längkvist M.; Coradeschi S.; Loutfi A.; Balaguru Rayappan J.B.","Längkvist, Martin (55986627900); Coradeschi, Silvia (6601980858); Loutfi, Amy (7004383993); Balaguru Rayappan, John Bosco (57212653754)","55986627900; 6601980858; 7004383993; 57212653754","Fast classification of meat spoilage markers using nanostructured ZnO thin films and unsupervised feature learning","2013","Sensors (Switzerland)","37","10.3390/s130201578","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873853951&doi=10.3390%2fs130201578&partnerID=40&md5=833905832957f7a15a188acbfa6144ea","Center for Applied Autonomous Sensor Systems, Örebro University, SE-701-82, Örebro, Sweden; Centre for Nanotechnology and Advanced Biomaterials (CeNTAB), School of Electrical and Electronics Engineering, SASTRA University, Thanjavur 613 401, Tamil Nadu, India","Längkvist M., Center for Applied Autonomous Sensor Systems, Örebro University, SE-701-82, Örebro, Sweden; Coradeschi S., Center for Applied Autonomous Sensor Systems, Örebro University, SE-701-82, Örebro, Sweden; Loutfi A., Center for Applied Autonomous Sensor Systems, Örebro University, SE-701-82, Örebro, Sweden; Balaguru Rayappan J.B., Centre for Nanotechnology and Advanced Biomaterials (CeNTAB), School of Electrical and Electronics Engineering, SASTRA University, Thanjavur 613 401, Tamil Nadu, India","This paper investigates a rapid and accurate detection system for spoilage in meat. We use unsupervised feature learning techniques (stacked restricted Boltzmann machines and auto-encoders) that consider only the transient response from undoped zinc oxide, manganese-doped zinc oxide, and fluorine-doped zinc oxide in order to classify three categories: the type of thin film that is used, the type of gas, and the approximate ppm-level of the gas. These models mainly offer the advantage that features are learned from data instead of being hand-designed. We compare our results to a feature-based approach using samples with various ppm level of ethanol and trimethylamine (TMA) that are good markers for meat spoilage. The result is that deep networks give a better and faster classification than the feature-based approach, and we thus conclude that the fine-tuning of our deep models are more efficient for this kind of multi-label classification task. © 2013 by the authors; licensee MDPI, Basel, Switzerland.","Electronic nose; Fast multi-label classification; Representational learning; Sensor material","Algorithms; Food Analysis; Meat; Nanostructures; Principal Component Analysis; Reproducibility of Results; Support Vector Machines; Zinc Oxide; Learning systems; Meats; Zinc oxide; nanomaterial; zinc oxide; Electronic NOSE; Fast classification; Manganese-doped zinc oxides; Multi-label classifications; Representational learning; Restricted boltzmann machine; Sensor materials; Unsupervised feature learning; algorithm; article; chemistry; food analysis; meat; methodology; principal component analysis; reproducibility; support vector machine; Spoilage","","14248220","","","23353140","Article","Scopus","2-s2.0-84873853951"
"Hollingsworth S.A.; Lewis M.C.; Berkholz D.S.; Wong W.-K.; Karplus P.A.","Hollingsworth, Scott A. (26640333200); Lewis, Matthew C. (56714464500); Berkholz, Donald S. (22953072100); Wong, Weng-Keen (7403972568); Karplus, P. Andrew (7007146506)","26640333200; 56714464500; 22953072100; 7403972568; 7007146506","(φ,ψ)2 motifs: A purely conformation-based fine-grained enumeration of protein parts at the two-residue level","2012","Journal of Molecular Biology","19","10.1016/j.jmb.2011.12.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856441445&doi=10.1016%2fj.jmb.2011.12.022&partnerID=40&md5=2a34d54d090f539ccc39576ce831520b","Department of Biochemistry and Biophysics, Oregon State University, Corvallis, OR 97331, United States; Department of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR 97331, United States","Hollingsworth S.A., Department of Biochemistry and Biophysics, Oregon State University, Corvallis, OR 97331, United States; Lewis M.C., Department of Biochemistry and Biophysics, Oregon State University, Corvallis, OR 97331, United States; Berkholz D.S., Department of Biochemistry and Biophysics, Oregon State University, Corvallis, OR 97331, United States; Wong W.-K., Department of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR 97331, United States; Karplus P.A., Department of Biochemistry and Biophysics, Oregon State University, Corvallis, OR 97331, United States","A deep understanding of protein structure benefits from the use of a variety of classification strategies that enhance our ability to effectively describe local patterns of conformation. Here, we use a clustering algorithm to analyze 76,533 all-trans segments from protein structures solved at 1.2 Å resolution or better to create a purely φ,ψ-based comprehensive empirical categorization of common conformations adopted by two adjacent φ,ψ pairs (i.e., (φ,ψ)2 motifs). The clustering algorithm works in an origin-shifted four-dimensional space based on the two φ,ψ pairs to yield a parameter-dependent list of (φ,ψ) 2 motifs, in order of their prominence. The results are remarkably distinct from and complementary to the standard hydrogen-bond-centered view of secondary structure. New insights include an unprecedented level of precision in describing the φ,ψ angles of both previously known and novel motifs, ordering of these motifs by their population density, a data-driven recommendation that the standard C αi...C α i + 3 < 7 Å criteria for defining turns be changed to 6.5 Å, identification of β-strand and turn capping motifs, and identification of conformational capping by residues in polypeptide II conformation. We further document that the conformational preferences of a residue are substantially influenced by the conformation of its neighbors, and we suggest that accounting for these dependencies will improve protein modeling accuracy. Although the CUEVAS-4D(r10ε14) 'parts list' presented here is only an initial exploration of the complex (φ,ψ) 2 landscape of proteins, it shows that there is value to be had from this approach, and it opens the door to more in-depth characterizations at the (φ,ψ)2 level and at higher dimensions. © 2011 Elsevier Ltd.","capping motifs; machine learning; protein conformation; Ramachandran plot; secondary structure","polypeptide; accuracy; article; controlled study; diagnostic value; hydrogen bond; population density; priority journal; protein analysis; protein conformation; protein domain; protein structure","Academic Press","00222836","","JMOBA","22198294","Article","Scopus","2-s2.0-84856441445"
"Widmer G.; Horn W.; Nagele B.","Widmer, Gerhard (7004342843); Horn, Werner (7101838151); Nagele, Bernhard (24307520800)","7004342843; 7101838151; 24307520800","Automatic knowledge base refinement: Learning from examples and deep knowledge in rheumatology","1993","Artificial Intelligence In Medicine","11","10.1016/0933-3657(93)90026-Y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027607456&doi=10.1016%2f0933-3657%2893%2990026-Y&partnerID=40&md5=16504a1c458a3a337468ce6fc2e990ec","Department of Medical Cybernetics and Artificial Intelligence, University of Vienna, 1010 Vienna, Freyung 6, Austria; Austrian Research Institute for Artificial Intelligence, Vienna, Austria","Widmer G., Department of Medical Cybernetics and Artificial Intelligence, University of Vienna, 1010 Vienna, Freyung 6, Austria, Austrian Research Institute for Artificial Intelligence, Vienna, Austria; Horn W., Department of Medical Cybernetics and Artificial Intelligence, University of Vienna, 1010 Vienna, Freyung 6, Austria, Austrian Research Institute for Artificial Intelligence, Vienna, Austria; Nagele B., Department of Medical Cybernetics and Artificial Intelligence, University of Vienna, 1010 Vienna, Freyung 6, Austria","MESICAR is a second generation expert system which contains very general descriptions of rheumatological disorders in the primary medical care field. With the help of a detailed hierarchical description of the human anatomy the system is able to support diagnostic decisions. The paper describes how machine learning techniques are used to automatically construct more specific disease descriptions for common, frequently occurring cases. The system MESICAR-LEARN implements a learning method which integrates analytical and empirical learning techniques. Cases diagnosed by MESICAR form the training examples, and MESICAR's knowledge base is used as domain theory. The leamed concepts are integrated into a hierarchy of disease descriptions. They support efficient and fast reasoning on common cases in addition to the general diagnostic support afforded by MESICAR's deep knowledge. © 1993.","deep and shallow knowledge; knowledge base refinement; knowledge compilation; machine learning; Medical expert system; rheumatology","Algorithms; Artificial Intelligence; Diagnosis, Computer-Assisted; Human; Rheumatology; Software; Support, Non-U.S. Gov't; Computer aided diagnosis; Decision support systems; Expert systems; Knowledge based systems; article; expert system; human; medical education; rheumatology; Knowledge compilation; Medical expert systems; Rheumatology; Medical computing","","09333657","","AIMEE","8358497","Article","Scopus","2-s2.0-0027607456"
"Groza T.","Groza, Tudor (19638535200)","19638535200","Using typed dependencies to study and recognise conceptualisation zones in biomedical literature","2013","PLoS ONE","7","10.1371/journal.pone.0079570","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894129628&doi=10.1371%2fjournal.pone.0079570&partnerID=40&md5=1c5c64e0f03a25690ad2c536968e7174","School of Information, Telecommunications, and Electronics Engineering, University of Queensland, QLD, Australia","Groza T., School of Information, Telecommunications, and Electronics Engineering, University of Queensland, QLD, Australia","In the biomedical domain, authors publish their experiments and findings using a quasi-standard coarse-grained discourse structure, which starts with an introduction that sets up the motivation, continues with a description of the materials and methods, and concludes with results and discussions. Over the course of the years, there has been a fair amount of research done in the area of scientific discourse analysis, with a focus on performing automatic recognition of scientific artefacts/ conceptualisation zones from the raw content of scientific publications. Most of the existing approaches use Machine Learning techniques to perform classification based on features that rely on the shallow structure of the sentence tokens, or sentences as a whole, in addition to corpus-driven statistics. In this article, we investigate the role carried by the deep (dependency) structure of the sentences in describing their rhetorical nature. Using association rule mining techniques, we study the presence of dependency structure patterns in the context of a given rhetorical type, the use of these patterns in exploring differences in structure between the rhetorical types, and their ability to discriminate between the different rhetorical types. Our final goal is to provide a series of insights that can be used to complement existing classification approaches. Experimental results show that, in particular in the context of a fine-grained multi-class classification context, the association rules emerged from the dependency structure are not able to produce uniform classification results. However, they can be used to derive discriminative pair-wise classification mechanisms, in particular for some of the most ambiguous types. © 2013 Tudor Groza.","","Artificial Intelligence; Biomedical Research; Data Mining; Literature","","19326203","","POLNC","24260252","Article","Scopus","2-s2.0-84894129628"
"Lusci A.; Pollastri G.; Baldi P.","Lusci, Alessandro (55800784200); Pollastri, Gianluca (55902203700); Baldi, Pierre (7101759672)","55800784200; 55902203700; 7101759672","Deep architectures and deep learning in chemoinformatics: The prediction of aqueous solubility for drug-like molecules","2013","Journal of Chemical Information and Modeling","409","10.1021/ci400187y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880542260&doi=10.1021%2fci400187y&partnerID=40&md5=4b75f4f7417b9ab5417269443257cc50","School of Computer Science and Informatics, University College Dublin, Belfield, Dublin 4, Ireland; Department of Computer Science, University of California, Irvine, Irvine, CA 92697, United States","Lusci A., School of Computer Science and Informatics, University College Dublin, Belfield, Dublin 4, Ireland; Pollastri G., School of Computer Science and Informatics, University College Dublin, Belfield, Dublin 4, Ireland; Baldi P., Department of Computer Science, University of California, Irvine, Irvine, CA 92697, United States","Shallow machine learning methods have been applied to chemoinformatics problems with some success. As more data becomes available and more complex problems are tackled, deep machine learning methods may also become useful. Here, we present a brief overview of deep learning methods and show in particular how recursive neural network approaches can be applied to the problem of predicting molecular properties. However, molecules are typically described by undirected cyclic graphs, while recursive approaches typically use directed acyclic graphs. Thus, we develop methods to address this discrepancy, essentially by considering an ensemble of recursive neural networks associated with all possible vertex-centered acyclic orientations of the molecular graph. One advantage of this approach is that it relies only minimally on the identification of suitable molecular descriptors because suitable representations are learned automatically from the data. Several variants of this approach are applied to the problem of predicting aqueous solubility and tested on four benchmark data sets. Experimental results show that the performance of the deep learning methods matches or exceeds the performance of other state-of-the-art methods according to several evaluation metrics and expose the fundamental limitations arising from training sets that are too small or too noisy. A Web-based predictor, AquaSol, is available online through the ChemDB portal (cdb.ics.uci.edu) together with additional material. © 2013 American Chemical Society.","","Acetic Acid; Artificial Intelligence; Computer Graphics; Databases, Pharmaceutical; Informatics; Internet; Neural Networks (Computer); Pharmaceutical Preparations; Solubility; Water; Directed graphs; Drug delivery; Forecasting; Learning systems; Molecular graphics; Molecules; Neural networks; Solubility; acetic acid; drug; water; drug; water; Acyclic orientation; Directed acyclic graph (DAG); Fundamental limitations; Machine learning methods; Molecular descriptors; Molecular properties; Recursive neural networks; State-of-the-art methods; article; artificial intelligence; artificial neural network; chemistry; computer graphics; drug database; information science; Internet; methodology; solubility; information science; procedures; Deep learning","American Chemical Society","15499596","","JCISD","23795551","Article","Scopus","2-s2.0-84880542260"
"Hackenberg M.; Sturm M.; Langenberger D.; Falcón-Pérez J.M.; Aransay A.M.","Hackenberg, Michael (6602124331); Sturm, Martin (35070436100); Langenberger, David (25635871300); Falcón-Pérez, Juan Manuel (6508252458); Aransay, Ana M. (6603346811)","6602124331; 35070436100; 25635871300; 6508252458; 6603346811","miRanalyzer: A microRNA detection and analysis tool for next-generation sequencing experiments","2009","Nucleic Acids Research","250","10.1093/nar/gkp347","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67849114241&doi=10.1093%2fnar%2fgkp347&partnerID=40&md5=241b5f22a2d00d9f9585a0ea8d2d35ce","Functional Genomics Unit, CIC bioGUNE, CIBERehd, 48160 Derio, Bizkaia, Technology Park of Bizkaia, Spain; Institute for Bioinformatics and Systems Biology, German Research Center for Environmental Health, D-85764 Neuherberg, Ingolästdter Landstrasse 1, Germany; Department of Genome-Oriented Bioinformatics, Wissenschaftszentrum Weihenstephan, Technische Universitat München, 85350 Freising, Germany; Bioinformatics Group, Department of Computer Science, University of Leipzig, D-04107 Leipzig, Haertelstr. 16-18, Germany; Metabolomics Unit, CIC bioGUNE, CIBERehd, 48160 Derio, Bizkaia, Technology Park of Bizkaia, Spain","Hackenberg M., Functional Genomics Unit, CIC bioGUNE, CIBERehd, 48160 Derio, Bizkaia, Technology Park of Bizkaia, Spain; Sturm M., Institute for Bioinformatics and Systems Biology, German Research Center for Environmental Health, D-85764 Neuherberg, Ingolästdter Landstrasse 1, Germany; Langenberger D., Department of Genome-Oriented Bioinformatics, Wissenschaftszentrum Weihenstephan, Technische Universitat München, 85350 Freising, Germany, Bioinformatics Group, Department of Computer Science, University of Leipzig, D-04107 Leipzig, Haertelstr. 16-18, Germany; Falcón-Pérez J.M., Metabolomics Unit, CIC bioGUNE, CIBERehd, 48160 Derio, Bizkaia, Technology Park of Bizkaia, Spain; Aransay A.M., Functional Genomics Unit, CIC bioGUNE, CIBERehd, 48160 Derio, Bizkaia, Technology Park of Bizkaia, Spain","Next-generation sequencing allows now the sequencing of small RNA molecules and the estimation of their expression levels. Consequently, there will be a high demand of bioinformatics tools to cope with the several gigabytes of sequence data generated in each single deep-sequencing experiment. Given this scene, we developed miRanalyzer, a web server tool for the analysis of deep-sequencing experiments for small RNAs. The web server tool requires a simple input file containing a list of unique reads and its copy numbers (expression levels). Using these data, miRanalyzer (i) detects all known microRNA sequences annotated in miRBase, (ii) finds all perfect matches against other libraries of transcribed sequences and (iii) predicts new microRNAs. The prediction of new microRNAs is an especially important point as there are many species with very few known microRNAs. Therefore, we implemented a highly accurate machine learning algorithm for the prediction of new microRNAs that reaches AUC values of 97.9% and recall values of up to 75% on unseen data. The web tool summarizes all the described steps in a single output page, which provides a comprehensive overview of the analysis, adding links to more detailed output pages for each analysis module. miRanalyzer is available at http://web.bioinformatics.cicbiogune.es/microRNA/.","","Animals; Dogs; Humans; Mice; MicroRNAs; Rats; Sequence Analysis, RNA; Software; Transcription, Genetic; User-Computer Interface; microRNA; article; bioinformatics; client server application; computer memory; computer system; data analysis; data analysis software; data synthesis; gene expression; gene library; gene number; machine learning; nucleic acid database; priority journal; RNA analysis; RNA sequence; web browser","","13624962","","NARHA","19433510","Article","Scopus","2-s2.0-67849114241"
"Salakhutdinov R.; Hinton G.","Salakhutdinov, Ruslan (57203057355); Hinton, Geoffrey (7006699573)","57203057355; 7006699573","An efficient learning procedure for deep Boltzmann machines","2012","Neural Computation","370","10.1162/NECO_a_00311","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874125782&doi=10.1162%2fNECO_a_00311&partnerID=40&md5=562643584b1be40b971351c6ee9adfe4","Department of Statistics, University of Toronto, Toronto, ON M5S 3G3, Canada; Department of Computer Science, University of Toronto, Toronto, ON M5S 3G3, Canada","Salakhutdinov R., Department of Statistics, University of Toronto, Toronto, ON M5S 3G3, Canada; Hinton G., Department of Computer Science, University of Toronto, Toronto, ON M5S 3G3, Canada","We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent statistics are estimated using a variational approximation that tends to focus on a single mode, and data-independent statistics are estimated using persistent Markov chains. The use of two quite different techniques for estimating the two types of statistic that enter into the gradient of the log likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer pretraining phase that initializes the weights sensibly. The pretraining also allows the variational inference to be initialized sensibly with a single bottom-up pass.We present results on the MNIST and NORB data sets showing that deep Boltzmann machines learn very good generative models of handwritten digits and 3D objects. We also show that the features discovered by deep Boltzmann machines are a very effective way to initialize the hidden layers of feedforward neural nets, which are then discriminatively fine-tuned. © 2012 Massachusetts Institute of Technology.","","","","1530888X","","","","Article","Scopus","2-s2.0-84874125782"
"Saariluoma P.; Sajaniemi J.","Saariluoma, Pertti (6701538700); Sajaniemi, Jorma (6602275349)","6701538700; 6602275349","Extracting implicit tree structures in spreadsheet calculation","1991","Ergonomics","19","10.1080/00140139108964845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026207169&doi=10.1080%2f00140139108964845&partnerID=40&md5=771ba433c6ce64cb37751182444e49de","Department of Psychology, University of Helsinki, Helsinki, SF-00100, Fabianinkatu 28, Finland; University of Joensuu, Joensuu, SF-80101, PO Box 111, Finland","Saariluoma P., Department of Psychology, University of Helsinki, Helsinki, SF-00100, Fabianinkatu 28, Finland; Sajaniemi J., University of Joensuu, Joensuu, SF-80101, PO Box 111, Finland","While information search in user interfaces has mainly been studied with menu systems, this paper extends the problem to spreadsheets, where it is important to extract, i.e. search and store in memory, implicit computational structures. The central concern is the extent to which subjects' cursor paths follow visible surface structures (i.e., the systems of occupied and unoccupied cells) and the extent to which their information intake is controlled by the deep structure (i.e., the references of equations to be computed) when they extract the computational structure of a spreadsheet. To understand this, cursor movements collected in three experiments in which subjects tried to learn ten different types of spreadsheets are analysed. The analysis shows that subjects base their information search almost totally on the surface structure of spreadsheets. As a consequence, they have great difficulties with spreadsheets where the surface structure is very inconsistent with the deep structure. They are unable to use the surface structure with these spreadsheets to support memory for underlying structures, and as a result learning times increase greatly. The experiments suggest very strongly that spreadsheet systems should provide facilities to make the deep structure visible. © 1991 Taylor & Francis Group, LLC.","Cognitive ergonomics; Information scanning and storing; Spreadsheet calculation; User interfaces","Computer Interfaces--Ergonomics; Systems Science And Cybernetics--Cognitive Systems; Systems Science And Cybernetics--Man Machine Systems; Vision--Eye Movements; article; calculation; clinical article; computer; ergonomics; human; normal human; psychology; skill; Extracting Implicit Tree Structures; Information Scanning; Information Storing; Menu Search Problem; User Interfaces; Computer Programming","","00140139","","","","Article","Scopus","2-s2.0-0026207169"
"Jain P.; Garibaldi J.M.; Hirst J.D.","Jain, Pooja (8954065500); Garibaldi, Jonathan M. (56765542600); Hirst, Jonathan D. (7102628530)","8954065500; 56765542600; 7102628530","Supervised machine learning algorithms for protein structure classification","2009","Computational Biology and Chemistry","82","10.1016/j.compbiolchem.2009.04.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349229243&doi=10.1016%2fj.compbiolchem.2009.04.004&partnerID=40&md5=12740ce4c3ac8286eba851f64aad8114","School of Chemistry, The University of Nottingham, Nottingham, NG7 2RD, University Park, United Kingdom; School of Computer Science and IT, The University of Nottingham, Nottingham, NG8 1BB, Jubilee Campus, United Kingdom","Jain P., School of Chemistry, The University of Nottingham, Nottingham, NG7 2RD, University Park, United Kingdom; Garibaldi J.M., School of Computer Science and IT, The University of Nottingham, Nottingham, NG8 1BB, Jubilee Campus, United Kingdom; Hirst J.D., School of Chemistry, The University of Nottingham, Nottingham, NG7 2RD, University Park, United Kingdom","We explore automation of protein structural classification using supervised machine learning methods on a set of 11,360 pairs of protein domains (up to 35% sequence identity) consisting of three secondary structure elements. Fifteen algorithms from five categories of supervised algorithms are evaluated for their ability to learn for a pair of protein domains, the deepest common structural level within the SCOP hierarchy, given a one-dimensional representation of the domain structures. This representation encapsulates evolutionary information in terms of sequence identity and structural information characterising the secondary structure elements and lengths of the respective domains. The evaluation is performed in two steps, first selecting the best performing base learners and subsequently evaluating boosted and bagged meta learners. The boosted random forest, a collection of decision trees, is found to be the most accurate, with a cross-validated accuracy of 97.0% and F-measures of 0.97, 0.85, 0.93 and 0.98 for classification of proteins to the Class, Fold, Super-Family and Family levels in the SCOP hierarchy. The meta learning regime, especially boosting, improved performance by more accurately classifying the instances from less populated classes. © 2009 Elsevier Ltd. All rights reserved.","Random forest; Structure classification; Supervised learning","Algorithms; Artificial Intelligence; Protein Conformation; Protein Structure, Tertiary; Proteins; Decision trees; Education; Robot learning; Supervised learning; protein; Base learners; Domain structure; Evolutionary information; Meta-learner; Metalearning; Protein domains; Protein structures; Random forest; Random forests; Secondary structure elements; Sequence identity; Structural classification; Structural information; Structure classification; Supervised algorithm; Supervised machine learning; algorithm; article; artificial intelligence; chemistry; protein conformation; protein tertiary structure; Learning algorithms","","14769271","","","19473879","Article","Scopus","2-s2.0-67349229243"
"Li M.; Patrick J.","Li, Min (57199162121); Patrick, Jon (56704380400)","57199162121; 56704380400","Extracting temporal information from electronic patient records.","2012","AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium","11","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880821180&partnerID=40&md5=b399779511c648aa14c5b32b8869a427","School of IT, the University of Sydney, Sydney, NSW, Australia","Li M., School of IT, the University of Sydney, Sydney, NSW, Australia; Patrick J.","A method for automatic extraction of clinical temporal information would be of significant practical importance for deep medical language understanding, and a key to creating many successful applications, such as medical decision making, medical question and answering, etc. This paper proposes a rich statistical model for extracting temporal information from an extremely noisy clinical corpus. Besides the common linguistic, contextual and semantic features, the highly restricted training sample expansion and the structure distance between the temporal expression & related event expressions are also integrated into a supervised machine-learning approach. The learning method produces almost 80% F- score in the extraction of five temporal classes, and nearly 75% F-score in identifying temporally related events. This process has been integrated into the document-processing component of an implemented clinical question answering system that focuses on answering patient-specific questions (See demonstration at http://hitrl.cs.usyd.edu.au/ICNS/).","","Bayes Theorem; Electronic Health Records; Humans; Information Storage and Retrieval; Natural Language Processing; Time; article; Bayes theorem; electronic medical record; human; information retrieval; natural language processing; time","","1942597X","","","23304326","Article","Scopus","2-s2.0-84880821180"
"Williams P.H.; Eyles R.; Weiller G.","Williams, Philip H. (55504585000); Eyles, Rod (55504984100); Weiller, Georg (6603796678)","55504585000; 55504984100; 6603796678","Plant microRNA prediction by supervised machine learning using C5.0 decision trees","2012","Journal of Nucleic Acids","20","10.1155/2012/652979","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870221987&doi=10.1155%2f2012%2f652979&partnerID=40&md5=055ee34d188c5fd2f2880d279b85a282","Division of Plant Sciences, College of Medicine, Biology and Environment, Australian National University, Canberra, ACT 0200, Australia","Williams P.H., Division of Plant Sciences, College of Medicine, Biology and Environment, Australian National University, Canberra, ACT 0200, Australia; Eyles R., Division of Plant Sciences, College of Medicine, Biology and Environment, Australian National University, Canberra, ACT 0200, Australia; Weiller G., Division of Plant Sciences, College of Medicine, Biology and Environment, Australian National University, Canberra, ACT 0200, Australia","MicroRNAs (miRNAs) are nonprotein coding RNAs between 20 and 22 nucleotides long that attenuate protein production. Different types of sequence data are being investigated for novel miRNAs, including genomic and transcriptomic sequences. A variety of machine learning methods have successfully predicted miRNA precursors, mature miRNAs, and other nonprotein coding sequences. MirTools, mirDeep2, and miRanalyzer require read count to be included with the input sequences, which restricts their use to deep-sequencing data. Our aim was to train a predictor using a cross-section of different species to accurately predict miRNAs outside the training set. We wanted a system that did not require read-count for prediction and could therefore be applied to short sequences extracted from genomic, EST, or RNA-seq sources. A miRNA-predictive decision-tree model has been developed by supervised machine learning. It only requires that the corresponding genome or transcriptome is available within a sequence window that includes the precursor candidate so that the required sequence features can be collected. Some of the most critical features for training the predictor are the miRNA:miRNA* duplex energy and the number of mismatches in the duplex. We present a cross-species plant miRNA predictor with 84.08 sensitivity and 98.53 specificity based on rigorous testing by leave-one-out validation. © 2012 Philip H. Williams et al.","","microRNA; plant RNA; transcriptome; accuracy; angiosperm; article; base pairing; clubmoss; controlled study; decision tree; dicotyledon; DNA base composition; Embryophyta; expressed sequence tag; machine learning; monocot; nonhuman; nucleotide sequence; plant genome; prediction; priority journal; RNA sequence; sensitivity and specificity; validity","Hindawi Limited","20900201","","","","Article","Scopus","2-s2.0-84870221987"
"El Hindi K.; Al-Akhras M.","El Hindi, Khalil (8361746000); Al-Akhras, Mousa (25653537100)","8361746000; 25653537100","Smoothing decision boundaries to avoid overfitting in neural network training","2011","Neural Network World","16","10.14311/NNW.2011.21.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053632198&doi=10.14311%2fNNW.2011.21.019&partnerID=40&md5=36c9fae674d718c7e4dcf826b8cedf75","Computer Information Systems Department, King Abdullah II School for Information Technology, University of Jordan, Amman 11942, P.O.Box 13835, Jordan","El Hindi K., Computer Information Systems Department, King Abdullah II School for Information Technology, University of Jordan, Amman 11942, P.O.Box 13835, Jordan; Al-Akhras M., Computer Information Systems Department, King Abdullah II School for Information Technology, University of Jordan, Amman 11942, P.O.Box 13835, Jordan","This work addresses the problem of overfitting the training data. We suggest smoothing the decision boundaries by eliminating border instances from the training set before training Artificial Neural Networks (ANNs). This is achieved by using a variety of instance reduction techniques. A large number of experiments were performed using 21 benchmark data sets from UCI machine learning repository, the experiments were performed with and without the introduction of noise in the data set. Our empirical results show that using a noise filtering algorithm to filter out border instances before training an ANN does not only improve the classification accuracy but also speeds up the training process by reducing the number of training epochs. The effectiveness of the approach is more obvious when the training data contains noisy instances. © ICS AS CR 2011.","Artificial neural network; Instance reduction; Instance selection; Instance-based learning; Machine learning; Noise filtering; Over learning; Overfitting; Prototype selection","Artificial intelligence; Learning systems; Neural networks; Spurious signal noise; Instance based learning; Instance selection; Noise filtering; Over learning; Overfitting; Prototype selection; Deep neural networks","Institute of Computer Science","12100552","","NNWOF","","Article","Scopus","2-s2.0-80053632198"
"Newman A.M.; Cooper J.B.","Newman, Aaron M. (23985967100); Cooper, James B. (7406079294)","23985967100; 7406079294","AutoSOME: A clustering method for identifying gene expression modules without prior knowledge of cluster number","2010","BMC Bioinformatics","91","10.1186/1471-2105-11-117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952311570&doi=10.1186%2f1471-2105-11-117&partnerID=40&md5=052455a39dcf891ed35462d03a969f72","Biomolecular Science and Engineering Program, University of California, Santa Barbara CA 93106, United States; Molecular Cellular and Developmental Biology, University of California, Santa Barbara CA 93106, United States","Newman A.M., Biomolecular Science and Engineering Program, University of California, Santa Barbara CA 93106, United States; Cooper J.B., Biomolecular Science and Engineering Program, University of California, Santa Barbara CA 93106, United States, Molecular Cellular and Developmental Biology, University of California, Santa Barbara CA 93106, United States","Background: Clustering the information content of large high-dimensional gene expression datasets has widespread application in ""omics"" biology. Unfortunately, the underlying structure of these natural datasets is often fuzzy, and the computational identification of data clusters generally requires knowledge about cluster number and geometry.Results: We integrated strategies from machine learning, cartography, and graph theory into a new informatics method for automatically clustering self-organizing map ensembles of high-dimensional data. Our new method, called AutoSOME, readily identifies discrete and fuzzy data clusters without prior knowledge of cluster number or structure in diverse datasets including whole genome microarray data. Visualization of AutoSOME output using network diagrams and differential heat maps reveals unexpected variation among well-characterized cancer cell lines. Co-expression analysis of data from human embryonic and induced pluripotent stem cells using AutoSOME identifies >3400 up-regulated genes associated with pluripotency, and indicates that a recently identified protein-protein interaction network characterizing pluripotency was underestimated by a factor of four.Conclusions: By effectively extracting important information from high-dimensional microarray data without prior knowledge or the need for data filtration, AutoSOME can yield systems-level insights from whole genome microarray expression studies. Due to its generality, this new method should also have practical utility for a variety of data-intensive applications, including the results of deep sequencing experiments. AutoSOME is available for download at http://jimcooperlab.mcdb.ucsb.edu/autosome. © 2010 Newman and Cooper; licensee BioMed Central Ltd.","","Cluster Analysis; Databases, Genetic; Gene Expression Profiling; Gene Regulatory Networks; Oligonucleotide Array Sequence Analysis; Software; Cell culture; Conformal mapping; Graph theory; Maps; Proteins; Stem cells; Computational identification; Data-intensive application; Gene expression datasets; High dimensional data; Induced pluripotent stem cells; Information contents; Integrated strategy; Protein-protein interaction networks; article; cluster analysis; computer program; DNA microarray; gene expression profiling; gene regulatory network; genetic database; methodology; Gene expression","","14712105","","BBMIC","20202218","Article","Scopus","2-s2.0-77952311570"
"Kilicoglu H.; Demner-Fushman D.; Rindflesch T.C.; Wilczynski N.L.; Haynes R.B.","Kilicoglu, Halil (8272303300); Demner-Fushman, Dina (7801377760); Rindflesch, Thomas C (6601978448); Wilczynski, Nancy L (6602705757); Haynes, R Brian (7202566529)","8272303300; 7801377760; 6601978448; 6602705757; 7202566529","Toward automatic recognition of high quality clinical evidence.","2008","AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-73949095140&partnerID=40&md5=7fa8aff6b2f84a12329dcda73c6447ec","Concordia University, Department of Computer Science and Software Engineering, Montreal, Canada","Kilicoglu H., Concordia University, Department of Computer Science and Software Engineering, Montreal, Canada; Demner-Fushman D., Concordia University, Department of Computer Science and Software Engineering, Montreal, Canada; Rindflesch T.C., Concordia University, Department of Computer Science and Software Engineering, Montreal, Canada; Wilczynski N.L., Concordia University, Department of Computer Science and Software Engineering, Montreal, Canada; Haynes R.B., Concordia University, Department of Computer Science and Software Engineering, Montreal, Canada","Automatic methods for recognizing topically relevant documents supported by high quality research can assist clinicians in practicing evidence-based medicine. We approach the challenge of identifying articles with high quality clinical evidence as a binary classification problem. Combining predictions from supervised machine learning methods and using deep semantic features, we achieve 73.5% precision and 67% recall.","","Algorithms; Artificial Intelligence; Canada; Evidence-Based Medicine; MEDLINE; Natural Language Processing; Pattern Recognition, Automated; Periodicals as Topic; Quality Control; Semantics; Vocabulary, Controlled; algorithm; article; artificial intelligence; automated pattern recognition; Canada; evidence based medicine; linguistics; MEDLINE; methodology; natural language processing; publication; quality control; semantics","","1942597X","","","18998881","Article","Scopus","2-s2.0-73949095140"
"Panuccio G.; Guez A.; Vincent R.; Avoli M.; Pineau J.","Panuccio, Gabriella (8584856900); Guez, Arthur (25925850300); Vincent, Robert (14631379200); Avoli, Massimo (18333527300); Pineau, Joelle (13404973100)","8584856900; 25925850300; 14631379200; 18333527300; 13404973100","Adaptive control of epileptiform excitability in an in vitro model of limbic seizures","2013","Experimental Neurology","22","10.1016/j.expneurol.2013.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872856940&doi=10.1016%2fj.expneurol.2013.01.002&partnerID=40&md5=9d3293f96a067e3872de9fa7f95083c6","Montreal Neurological Institute, Department of Neurology and Neurosurgery, McGill University, Montreal, QC, H3A 2B4, Canada; Gatsby Computational Neuroscience Unit, UCL, London WC1N 3AR, 17 Queen Square, United Kingdom; School of Computer Science, McGill University, Montreal, QC, H3A 2A7, 3480 University Street, Canada","Panuccio G., Montreal Neurological Institute, Department of Neurology and Neurosurgery, McGill University, Montreal, QC, H3A 2B4, Canada; Guez A., Gatsby Computational Neuroscience Unit, UCL, London WC1N 3AR, 17 Queen Square, United Kingdom; Vincent R., School of Computer Science, McGill University, Montreal, QC, H3A 2A7, 3480 University Street, Canada; Avoli M., Montreal Neurological Institute, Department of Neurology and Neurosurgery, McGill University, Montreal, QC, H3A 2B4, Canada; Pineau J., School of Computer Science, McGill University, Montreal, QC, H3A 2A7, 3480 University Street, Canada","Deep brain stimulation (DBS) is a promising tool for treating drug-resistant epileptic patients. Currently, the most common approach is fixed-frequency stimulation (periodic pacing) by means of stimulating devices that operate under open-loop control. However, a drawback of this DBS strategy is the impossibility of tailoring a personalized treatment, which also limits the optimization of the stimulating apparatus. Here, we propose a novel DBS methodology based on a closed-loop control strategy, developed by exploiting statistical machine learning techniques, in which stimulation parameters are adapted to the current neural activity thus allowing for seizure suppression that is fine-tuned on the individual scale (adaptive stimulation). By means of field potential recording from adult rat hippocampus-entorhinal cortex (EC) slices treated with the convulsant drug 4-aminopyridine we determined the effectiveness of this approach compared to low-frequency periodic pacing, and found that the closed-loop stimulation strategy: (i) has similar efficacy as low-frequency periodic pacing in suppressing ictal-like events but (ii) is more efficient than periodic pacing in that it requires less electrical pulses. We also provide evidence that the closed-loop stimulation strategy can alternatively be employed to tune the frequency of a periodic pacing strategy. Our findings indicate that the adaptive stimulation strategy may represent a novel, promising approach to DBS for individually-tailored epilepsy treatment. © 2013 Elsevier Inc.","Closed-loop strategy; Deep brain stimulation; Epilepsy","Adaptation, Physiological; Animals; Biophysics; Electric Stimulation; Evoked Potentials; Limbic System; Neural Pathways; Rats; Rats, Sprague-Dawley; adult animal; animal tissue; article; brain depth stimulation; brain slice; complex partial seizure; controlled study; disease control; entorhinal cortex; epileptic discharge; hippocampal CA1 region; hippocampal CA3 region; in vitro study; male; nonhuman; priority journal; rat; subiculum","","10902430","","EXNEA","23313899","Article","Scopus","2-s2.0-84872856940"
"Ciesielczyk B.; Cwaliński J.; Janusz P.","Ciesielczyk, Błazej (6603311023); Cwaliński, Jarosław (24279223000); Janusz, Piotr (57050871300)","6603311023; 24279223000; 57050871300","Robotic surgery and NOTES - Natural Orifice Translumenal Endoscopic Surgery in treatment of cholellthiasis - revolution or failed conception; [Robotyka medyczna i operacje NOTES - Natural Orifice Translumenal Endoscopic Surgery w leczeniu kamicy żółciowej - rewolucja czy ślepa droga]","2008","Polski Merkuriusz Lekarski","2","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-56249115932&partnerID=40&md5=3776a9e93673e8f16b99265f89eadc37","Szpital Im. F. Raszel w Poznaniu, Oddzial Chirurgii Ogólnej; Raszeja Hospital, Surgery Department, Poznan, Poland; 61-312 Poznań, ul. Glebowa 17, Poland","Ciesielczyk B., Szpital Im. F. Raszel w Poznaniu, Oddzial Chirurgii Ogólnej, Raszeja Hospital, Surgery Department, Poznan, Poland, 61-312 Poznań, ul. Glebowa 17, Poland; Cwaliński J., Szpital Im. F. Raszel w Poznaniu, Oddzial Chirurgii Ogólnej, Raszeja Hospital, Surgery Department, Poznan, Poland; Janusz P., Szpital Im. F. Raszel w Poznaniu, Oddzial Chirurgii Ogólnej, Raszeja Hospital, Surgery Department, Poznan, Poland","At the beginning of 90th years of the last century a laparoscopy technique initiated a new chapter in surgical treatment becoming the realistic alternative of classical laparotomies. Nowadays, after 20. years from first laparoscopic cholecystectomy new treatment methods such as Natural Orifice Translumenal Endoscopic Surgery (NOTES) and robotic surgery are gaining more and more great interest. The first robots created In the middle of 90 years were used only for keeping a camera and they were steered with voice, however with the development of technology was possible constructing precise machines, which were able to carry complicated procedures out (fundoplication, gastrectomy or colectomy), also from a long distance. At present two types of robots are being applied in the medical practice: da Vinci and Zeus. NOTES is a method that make possible to perform operations trough natural orifice of the body with an endoscope and appropriate instrumentation. Actually three fundamental ways of reaching the peritoneum are being used: through the stomach, through the rectum and through the vagina. Some authors tried also to use transbladder approach. The main advantage of the NOTES technique is a possibility of performing the procedure without necessity of cutting the abdominal wall, what decreases postoperative pain, eliminates the problem of an infecting wound, minimizes risk of postoperative hernias and reduces amount of postoperative adhesions. Problems related to the NOTES technique are mostly need of inventing new and better equipment, assurance tightness of the surgical access, development of an efficient antiseptic prophylaxis and also standardize learning methods. Dynamic development of the NOTES method allows overcoming some of these limitations by using innovative technical solutions and new systems e.g. TULA, NOTUS, ShapeLock, ViaCath, MAGS and many others. The aim of this study is a deep analysis of the recent technical solutions, rules of the therapy and schedules of management valid in the NOTES method and the robotic surgery suggested by the leading clinics. The article is also an attempt to answer the question if this new surgical procedures become as great revolution as laparoscopy.","Cholecystectomy; MAGS; NOTES; Robotic surgery; TULA","Cholecystectomy, Laparoscopic; Cholelithiasis; Humans; Pain, Postoperative; Robotics; Surgical Procedures, Minimally Invasive; article; cholecystectomy; cholelithiasis; human; instrumentation; methodology; minimally invasive surgery; postoperative pain; robotics","","14269686","","PMLOB","19145941","Article","Scopus","2-s2.0-56249115932"
"Mason M.R.; Nagaraja H.N.; Camerlengo T.; Joshi V.; Kumar P.S.","Mason, Matthew R. (55091674300); Nagaraja, Haikady N. (7003457638); Camerlengo, Terry (13807418100); Joshi, Vinayak (16047774800); Kumar, Purnima S. (9745930400)","55091674300; 7003457638; 13807418100; 16047774800; 9745930400","Deep Sequencing Identifies Ethnicity-Specific Bacterial Signatures in the Oral Microbiome","2013","PLoS ONE","156","10.1371/journal.pone.0077287","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886019355&doi=10.1371%2fjournal.pone.0077287&partnerID=40&md5=90024d4f6040afb295147b02ba51062b","Division of Oral Biology, College of Dentistry, The Ohio State University, Columbus, OH, United States; Division of Biostatistics, College of Public Health, The Ohio State University, Columbus, OH, United States; Comprehensive Cancer Center, The Ohio State University, Columbus, OH, United States; Department of Periodontics, Maratha Mandal's NGH Institute of Dental Sciences and Research Centre, Belgaum, India; Division of Periodontology, College of Dentistry, The Ohio State University, Columbus, OH, United States","Mason M.R., Division of Oral Biology, College of Dentistry, The Ohio State University, Columbus, OH, United States; Nagaraja H.N., Division of Biostatistics, College of Public Health, The Ohio State University, Columbus, OH, United States; Camerlengo T., Comprehensive Cancer Center, The Ohio State University, Columbus, OH, United States; Joshi V., Department of Periodontics, Maratha Mandal's NGH Institute of Dental Sciences and Research Centre, Belgaum, India; Kumar P.S., Division of Periodontology, College of Dentistry, The Ohio State University, Columbus, OH, United States","Oral infections have a strong ethnic predilection; suggesting that ethnicity is a critical determinant of oral microbial colonization. Dental plaque and saliva samples from 192 subjects belonging to four major ethnicities in the United States were analyzed using terminal restriction fragment length polymorphism (t-RFLP) and 16S pyrosequencing. Ethnicity-specific clustering of microbial communities was apparent in saliva and subgingival biofilms, and a machine-learning classifier was capable of identifying an individual's ethnicity from subgingival microbial signatures. The classifier identified African Americans with a 100% sensitivity and 74% specificity and Caucasians with a 50% sensitivity and 91% specificity. The data demonstrates a significant association between ethnic affiliation and the composition of the oral microbiome; to the extent that these microbial signatures appear to be capable of discriminating between ethnicities. © 2013 Mason et al.","","African Americans; Analysis of Variance; Asian Americans; Bacterial Infections; Biofilms; Dental Plaque; DNA Primers; European Continental Ancestry Group; High-Throughput Nucleotide Sequencing; Hispanic Americans; Humans; Likelihood Functions; Microbiota; Polymorphism, Restriction Fragment Length; RNA, Ribosomal, 16S; Saliva; Species Specificity; United States; Bacteria (microorganisms); primer DNA; RNA 16S; African American; article; biofilm; Caucasian; Chinese; ethnic difference; Hispanic; human; microbial community; mouth flora; nonhuman; pyrosequencing; random forest; restriction fragment length polymorphism; saliva; sensitivity and specificity; tooth plaque; United States; African American; analysis of variance; Asian American; bacterial infection; Caucasian; comparative study; epidemiology; ethnology; genetics; high throughput sequencing; Hispanic; microbiology; microflora; procedures; species difference; statistical model","Public Library of Science","19326203","","POLNC","24194878","Article","Scopus","2-s2.0-84886019355"
"Morin R.D.; Aksay G.; Dolgosheina E.; Ebhardt H.A.; Magrini V.; Mardis E.R.; Sahinalp S.C.; Unrau P.J.","Morin, Ryan D. (8385202000); Aksay, Gozde (23992342300); Dolgosheina, Elena (23992387600); Ebhardt, H. Alexander (9233194600); Magrini, Vincent (6602548928); Mardis, Elaine R. (7003499321); Sahinalp, S. Cenk (6603800467); Unrau, Peter J. (7003473993)","8385202000; 23992342300; 23992387600; 9233194600; 6602548928; 7003499321; 6603800467; 7003473993","Comparative analysis of the small RNA transcriptomes of Pinus contorta and Oryza sativa","2008","Genome Research","284","10.1101/gr.6897308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-41649102715&doi=10.1101%2fgr.6897308&partnerID=40&md5=a7a79389b7de4920079177274a6e006f","Genome Sciences Centre, BC Cancer Agency, Vancouver V5Z 1L3, Canada; University of Washington, Department of Genome Sciences, Seattle, WA 98195-5065, United States; Department of Molecular Biology and Biochemistry, Simon Fraser University, Burnaby V5A 1S6, Canada; Department of Biochemistry, University of Alberta, Edmonton, AB T6G 2H7, Canada; Washington University School of Medicine, Genome Sequencing Center, St. Louis, MO 63108, United States; Department of Computing Science, Simon Fraser University, Burnaby V5A 1S6, Canada","Morin R.D., Genome Sciences Centre, BC Cancer Agency, Vancouver V5Z 1L3, Canada; Aksay G., University of Washington, Department of Genome Sciences, Seattle, WA 98195-5065, United States; Dolgosheina E., Department of Molecular Biology and Biochemistry, Simon Fraser University, Burnaby V5A 1S6, Canada; Ebhardt H.A., Department of Biochemistry, University of Alberta, Edmonton, AB T6G 2H7, Canada; Magrini V., Washington University School of Medicine, Genome Sequencing Center, St. Louis, MO 63108, United States; Mardis E.R., Washington University School of Medicine, Genome Sequencing Center, St. Louis, MO 63108, United States; Sahinalp S.C., Department of Computing Science, Simon Fraser University, Burnaby V5A 1S6, Canada; Unrau P.J., Department of Molecular Biology and Biochemistry, Simon Fraser University, Burnaby V5A 1S6, Canada","The diversity of microRNAs and small-interfering RNAs has been extensively explored within angiosperms by focusing on a few key organisms such as Oryza sativa and Arabidopsis thaliana. A deeper division of the plants is defined by the radiation of the angiosperms and gymnosperms, with the latter comprising the commercially important conifers. The conifers are expected to provide important information regarding the evolution of highly conserved small regulatory RNAs. Deep sequencing provides the means to characterize and quantitatively profile small RNAs in understudied organisms such as these. Pyrosequencing of small RNAs from O. sativa revealed, as expected, ∼21- and ∼24-nt RNAs. The former contained known microRNAs, and the latter largely comprised intergenic-derived sequences likely representing heterochromatin siRNAs. In contrast, sequences from Pinus contorta were dominated by 21-nt small RNAs. Using a novel sequence-based clustering algorithm, we identified sequences belonging to 18 highly conserved microRNA families in P. contorta as well as numerous clusters of conserved small RNAs of unknown function. Using multiple methods, including expressed sequence folding and machine learning algorithms, we found a further 53 candidate novel microRNA families, 51 appearing specific to the P. contorta library. In addition, alignment of small RNA sequences to the O. sativa genome revealed six perfectly conserved classes of small RNA that included chloroplast transcripts and specific types of genomic repeats. The conservation of microRNAs and other small RNAs between the conifers and the angiosperms indicates that important RNA silencing processes were highly developed in the earliest spermatophytes. Genomic mapping of all sequences to the O. sativa genome can be viewed at http://microrna.bcgsc.ca/cgi-bin/gbrowse/rice_build_3/. ©2008 by Cold Spring Harbor Laboratory Press.","","Chromosome Mapping; Conserved Sequence; Gene Expression Profiling; MicroRNAs; Oryza sativa; Pinus; RNA, Plant; RNA, Small Interfering; RNA, Untranslated; Sequence Alignment; Sequence Analysis, RNA; Arabidopsis thaliana; Coniferophyta; Gymnospermae; Magnoliophyta; Oryza sativa; Pinus contorta; Spermatophyta; microRNA; small interfering RNA; transcriptome; algorithm; angiosperm; article; chloroplast; comparative study; conifer; conservation genetics; controlled study; gene cluster; gene mapping; gene silencing; genome; gymnosperm; heterochromatin; machine learning; molecular evolution; nonhuman; nucleotide sequence; Pinus contorta; plant; priority journal; quantitative genetics; radiation; rice; RNA sequence; RNA transcription; sequence alignment","","15495469","","GEREF","18323537","Article","Scopus","2-s2.0-41649102715"
"Ingolia N.T.; Lareau L.F.; Weissman J.S.","Ingolia, Nicholas T. (6507210373); Lareau, Liana F. (8754254500); Weissman, Jonathan S. (34974882800)","6507210373; 8754254500; 34974882800","Ribosome profiling of mouse embryonic stem cells reveals the complexity and dynamics of mammalian proteomes","2011","Cell","1557","10.1016/j.cell.2011.10.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81055155799&doi=10.1016%2fj.cell.2011.10.002&partnerID=40&md5=0196e17024159e5faf61194efc95148c","Howard Hughes Medical Institute, Department of Cellular and Molecular Pharmacology, University of California, San Francisco, San Francisco, CA 94158, United States; Department of Biochemistry, Stanford University, Stanford, CA 94305, United States","Ingolia N.T., Howard Hughes Medical Institute, Department of Cellular and Molecular Pharmacology, University of California, San Francisco, San Francisco, CA 94158, United States; Lareau L.F., Department of Biochemistry, Stanford University, Stanford, CA 94305, United States; Weissman J.S., Howard Hughes Medical Institute, Department of Cellular and Molecular Pharmacology, University of California, San Francisco, San Francisco, CA 94158, United States","The ability to sequence genomes has far outstripped approaches for deciphering the information they encode. Here we present a suite of techniques, based on ribosome profiling (the deep sequencing of ribosome-protected mRNA fragments), to provide genome-wide maps of protein synthesis as well as a pulse-chase strategy for determining rates of translation elongation. We exploit the propensity of harringtonine to cause ribosomes to accumulate at sites of translation initiation together with a machine learning algorithm to define protein products systematically. Analysis of translation in mouse embryonic stem cells reveals thousands of strong pause sites and unannotated translation products. These include amino-terminal extensions and truncations and upstream open reading frames with regulatory potential, initiated at both AUG and non-AUG codons, whose translation changes after differentiation. We also define a class of short, polycistronic ribosome-associated coding RNAs (sprcRNAs) that encode small proteins. Our studies reveal an unanticipated complexity to mammalian proteomes. © 2011 Elsevier Inc.","","Mammalia; harringtonine; proteome; RNA; short polycistronic ribosome associated RNA; unclassified drug; article; DNA footprinting; embryo; genetic association; genetic code; machine learning; mammal; mouse; mouse embryonic stem cell; nonhuman; nucleotide sequence; open reading frame; priority journal; protein analysis; protein synthesis; ribosome; sequence analysis; stem cell; translation initiation","Elsevier B.V.","00928674","","CELLB","22056041","Article","Scopus","2-s2.0-81055155799"
"Hinton G.; Salakhutdinov R.","Hinton, Geoffrey (7006699573); Salakhutdinov, Ruslan (57203057355)","7006699573; 57203057355","Discovering binary codes for documents by learning deep generative models","2011","Topics in Cognitive Science","73","10.1111/j.1756-8765.2010.01109.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79961219393&doi=10.1111%2fj.1756-8765.2010.01109.x&partnerID=40&md5=85954a1b00ab9f89b25808e862ca6f65","Department of Computer Science, University of Toronto, Toronto, ON, Canada; Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, United States","Hinton G., Department of Computer Science, University of Toronto, Toronto, ON, Canada; Salakhutdinov R., Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, United States","We describe a deep generative model in which the lowest layer represents the word-count vector of a document and the top layer represents a learned binary code for that document. The top two layers of the generative model form an undirected associative memory and the remaining layers form a belief net with directed, top-down connections. We present efficient learning and inference procedures for this type of generative model and show that it allows more accurate and much faster retrieval than latent semantic analysis. By using our method as a filter for a much slower method called TF-IDF we achieve higher accuracy than TF-IDF alone and save several orders of magnitude in retrieval time. By using short binary codes as addresses, we can perform retrieval on very large document sets in a time that is independent of the size of the document set using only one word of memory to describe each document. © 2010 Cognitive Science Society, Inc.","Auto-encoders; Binary codes; Deep learning; Document retrieval; Restricted Boltzmann machines; Semantic hashing","Artificial Intelligence; Documentation; Information Storage and Retrieval; Models, Theoretical; Semantics; artificial intelligence; documentation; information retrieval; procedures; semantics; theoretical model","","17568765","","","25164175","Article","Scopus","2-s2.0-79961219393"
"Tango F.; Minin L.; Tesauri F.; Montanari R.","Tango, Fabio (55914652500); Minin, Luca (23094823900); Tesauri, Francesco (23095859100); Montanari, Roberto (55319577400)","55914652500; 23094823900; 23095859100; 55319577400","Field tests and machine learning approaches for refining algorithms and correlations of driver's model parameters","2010","Applied Ergonomics","24","10.1016/j.apergo.2009.01.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449520382&doi=10.1016%2fj.apergo.2009.01.010&partnerID=40&md5=28e1a500193e3172fb364c38d1c6719c","Centro Ricerche Fiat, 10043 Orbassano (TO), Strada Torino, 50, Italy; Human Machine Interaction Group, Dipartimento di Scienze e Metodi dell'Ingegneria, University of Modena e Reggio Emilia, 42100 Reggio Emilia, Via Amendola, 2 (Pad. Tamburini), Italy","Tango F., Centro Ricerche Fiat, 10043 Orbassano (TO), Strada Torino, 50, Italy; Minin L., Human Machine Interaction Group, Dipartimento di Scienze e Metodi dell'Ingegneria, University of Modena e Reggio Emilia, 42100 Reggio Emilia, Via Amendola, 2 (Pad. Tamburini), Italy; Tesauri F., Human Machine Interaction Group, Dipartimento di Scienze e Metodi dell'Ingegneria, University of Modena e Reggio Emilia, 42100 Reggio Emilia, Via Amendola, 2 (Pad. Tamburini), Italy; Montanari R., Human Machine Interaction Group, Dipartimento di Scienze e Metodi dell'Ingegneria, University of Modena e Reggio Emilia, 42100 Reggio Emilia, Via Amendola, 2 (Pad. Tamburini), Italy","This paper describes the field tests on a driving simulator carried out to validate the algorithms and the correlations of dynamic parameters, specifically driving task demand and drivers' distraction, able to predict drivers' intentions. These parameters belong to the driver's model developed by AIDE (Adaptive Integrated Driver-vehicle InterfacE) European Integrated Project. Drivers' behavioural data have been collected from the simulator tests to model and validate these parameters using machine learning techniques, specifically the adaptive neuro fuzzy inference systems (ANFIS) and the artificial neural network (ANN). Two models of task demand and distraction have been developed, one for each adopted technique. The paper provides an overview of the driver's model, the description of the task demand and distraction modelling and the tests conducted for the validation of these parameters. A test comparing predicted and expected outcomes of the modelled parameters for each machine learning technique has been carried out: for distraction, in particular, promising results (low prediction errors) have been obtained by adopting an artificial neural network. © 2009 Elsevier Ltd. All rights reserved.","Behavioural model; Cognitive architecture; Distraction; Driver-vehicle-environment frame work; Fuzzy logic; Machine learning; Neural networks; Simulation","Artificial intelligence; Deep neural networks; Fuzzy inference; Fuzzy logic; Fuzzy neural networks; Fuzzy systems; Learning algorithms; Neural networks; Parameter estimation; Testing; Behavioural model; Cognitive architectures; Distraction; Frame-work; Simulation; adaptive behavior; algorithm; article; artificial neural network; computer simulation; driving ability; experimental design; field study; fuzzy system; human; human factors research; machine learning; man machine interaction; task performance; theoretical model; validation process; Learning systems","Elsevier Ltd","00036870","","AERGB","19286165","Article","Scopus","2-s2.0-70449520382"
"Gorkin D.U.; Lee D.; Reed X.; Fletez-Brant C.; Bessling S.L.; Loftus S.K.; Beer M.A.; Pavan W.J.; McCallion A.S.","Gorkin, David U. (35722107800); Lee, Dongwon (55698921700); Reed, Xylena (40561536800); Fletez-Brant, Christopher (55446447700); Bessling, Seneca L. (12809242000); Loftus, Stacie K. (7004762782); Beer, Michael A. (7101885059); Pavan, William J. (7006536998); McCallion, Andrew S. (6603112386)","35722107800; 55698921700; 40561536800; 55446447700; 12809242000; 7004762782; 7101885059; 7006536998; 6603112386","Integration of ChIP-seq and machine learning reveals enhancers and a predictive regulatory sequence vocabulary in melanocytes","2012","Genome Research","54","10.1101/gr.139360.112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868318661&doi=10.1101%2fgr.139360.112&partnerID=40&md5=585b1e768ccc275ed5d4d93d4c118d19","McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States; Predoctoral Training Program in Human Genetics, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States; Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD 21201, United States; Genetic Disease Research Branch, National Human Genome Research Institute, National Institutes of Health, Bethesda, MD 20892, United States","Gorkin D.U., McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States, Predoctoral Training Program in Human Genetics, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States; Lee D., Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD 21201, United States; Reed X., McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States, Predoctoral Training Program in Human Genetics, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States; Fletez-Brant C., McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States; Bessling S.L., McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States; Loftus S.K., Genetic Disease Research Branch, National Human Genome Research Institute, National Institutes of Health, Bethesda, MD 20892, United States; Beer M.A., McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States, Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD 21201, United States; Pavan W.J., Genetic Disease Research Branch, National Human Genome Research Institute, National Institutes of Health, Bethesda, MD 20892, United States; McCallion A.S., McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins University School of Medicine, Baltimore, MD 21205, United States","We take a comprehensive approach to the study of regulatory control of gene expression in melanocytes that proceeds from large-scale enhancer discovery facilitated by ChIP-seq; to rigorous validation in silico, in vitro, and in vivo; and finally to the use of machine learning to elucidate a regulatory vocabulary with genome-wide predictive power. We identify 2489 putative melanocyte enhancer loci in the mouse genome by ChIP-seq for EP300 and H3K4me1. We demonstrate that these putative enhancers are evolutionarily constrained, enriched for sequence motifs predicted to bind key melanocyte transcription factors, located near genes relevant to melanocyte biology, and capable of driving reporter gene expression in melanocytes in culture (86%; 43/50) and in transgenic zebrafish (70%; 7/10). Next, using the sequences of these putative enhancers as a training set for a supervised machine learning algorithm, we develop a vocabulary of 6-mers predictive of melanocyte enhancer function. Lastly, we demonstrate that this vocabulary has genome-wide predictive power in both the mouse and human genomes. This study provides deep insight into the regulation of gene expression in melanocytes and demonstrates a powerful approach to the investigation of regulatory sequences that can be applied to other cell types. © 2012, Published by Cold Spring Harbor Laboratory Press.","","Algorithms; Animals; Artificial Intelligence; Chromatin Immunoprecipitation; E1A-Associated p300 Protein; Enhancer Elements, Genetic; Evolution, Molecular; Gene Expression Regulation; Genes, Reporter; Genome, Human; Histones; Humans; Melanocytes; Mice; Sequence Analysis, DNA; Transcription Factors; Zebrafish; Danio rerio; microphthalmia associated transcription factor; animal cell; article; chromatin immunoprecipitation; controlled study; cytology; DNA flanking region; enhancer region; gene expression; gene locus; human; in vivo study; machine learning; melanocyte; mouse; nonhuman; priority journal; protein binding; regulatory sequence; zebra fish","","15495469","","GEREF","23019145","Article","Scopus","2-s2.0-84868318661"
"Gunawardana Y.; Niranjan M.","Gunawardana, Yawwani (55960676000); Niranjan, Mahesan (57205698392)","55960676000; 57205698392","Bridging the gap between transcriptome and proteome measurements identifies post-translationally regulated genes","2013","Bioinformatics","23","10.1093/bioinformatics/btt537","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890084536&doi=10.1093%2fbioinformatics%2fbtt537&partnerID=40&md5=0a8937afbfc1d48adb712a67ef3c33f7","School of Electronics and Computer Science, University of Southampton, Southampton, SO17 1BJ, United Kingdom","Gunawardana Y., School of Electronics and Computer Science, University of Southampton, Southampton, SO17 1BJ, United Kingdom; Niranjan M., School of Electronics and Computer Science, University of Southampton, Southampton, SO17 1BJ, United Kingdom","Motivation: Despite much dynamical cellular behaviour being achieved by accurate regulation of protein concentrations, messenger RNA abundances, measured by microarray technology, and more recently by deep sequencing techniques, are widely used as proxies for proteinmeasurements. Although for some species and under some conditions, there is good correlation between transcriptome and proteome level measurements, such correlation is by no means universal due to post-transcriptional and post-translational regulation, both of which are highly prevalent in cells. Here, we seek to develop a datadriven machine learning approach to bridging the gap between these two levels of high-throughput omic measurements on Saccharomyces cerevisiae and deploy the model in a novel way to uncover mRNAprotein pairs that are candidates for post-translational regulation. Results: The application of feature selection by sparsity inducing regression (l1 norm regularization) leads to a stable set of features: i.e. mRNA, ribosomal occupancy, ribosome density, tRNA adaptation index and codon bias while achieving a feature reduction from 37 to 5. A linear predictor used with these features is capable of predicting protein concentrations fairly accurately (R2 = 0:86). Proteins whose concentration cannot be predicted accurately, taken as outliers with respect to the predictor, are shown to have annotation evidence of post-translational modification, significantly more than random subsets of similar size P<0:02. In a data mining sense, this work also shows a wider point that outliers with respect to a learning method can carry meaningful information about a problem domain. © The Author 2013. Published by Oxford University Press. All rights reserved.","","Artificial Intelligence; Codon; Computational Biology; Gene Expression Regulation, Fungal; Protein Processing, Post-Translational; Proteome; Ribosomes; RNA, Messenger; RNA, Transfer; Saccharomyces cerevisiae; Saccharomyces cerevisiae Proteins; Transcriptome; codon; messenger RNA; proteome; Saccharomyces cerevisiae protein; transcriptome; transfer RNA; proteome; Saccharomyces cerevisiae protein; artificial intelligence; biology; codon; gene expression regulation; genetics; metabolism; procedures; protein processing; ribosome; Saccharomyces cerevisiae; article; biology; methodology; Saccharomyces cerevisiae","","14602059","","BOINF","24045772","Article","Scopus","2-s2.0-84890084536"
"Depristo M.A.; Banks E.; Poplin R.; Garimella K.V.; Maguire J.R.; Hartl C.; Philippakis A.A.; Del Angel G.; Rivas M.A.; Hanna M.; McKenna A.; Fennell T.J.; Kernytsky A.M.; Sivachenko A.Y.; Cibulskis K.; Gabriel S.B.; Altshuler D.; Daly M.J.","Depristo, Mark A. (6602278308); Banks, Eric (36514157400); Poplin, Ryan (37026985800); Garimella, Kiran V. (57816898900); Maguire, Jared R. (26027944100); Hartl, Christopher (37026123100); Philippakis, Anthony A. (8271665900); Del Angel, Guillermo (42961136500); Rivas, Manuel A. (57208733620); Hanna, Matt (37025915100); McKenna, Aaron (37026546400); Fennell, Tim J. (35336309800); Kernytsky, Andrew M. (58474828700); Sivachenko, Andrey Y. (55218699700); Cibulskis, Kristian (24467331700); Gabriel, Stacey B. (7202104113); Altshuler, David (7005798316); Daly, Mark J. (7201456226)","6602278308; 36514157400; 37026985800; 57816898900; 26027944100; 37026123100; 8271665900; 42961136500; 57208733620; 37025915100; 37026546400; 35336309800; 58474828700; 55218699700; 24467331700; 7202104113; 7005798316; 7201456226","A framework for variation discovery and genotyping using next-generation DNA sequencing data","2011","Nature Genetics","7857","10.1038/ng.806","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955483667&doi=10.1038%2fng.806&partnerID=40&md5=c48f4d0696934d402812c9783d89efed","Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Brigham and Women's Hospital, Boston, MA, United States; Harvard Medical School, Boston, MA, United States","Depristo M.A., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Banks E., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Poplin R., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Garimella K.V., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Maguire J.R., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Hartl C., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Philippakis A.A., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States, Brigham and Women's Hospital, Boston, MA, United States, Harvard Medical School, Boston, MA, United States; Del Angel G., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Rivas M.A., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Hanna M., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; McKenna A., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Fennell T.J., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Kernytsky A.M., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Sivachenko A.Y., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Cibulskis K., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Gabriel S.B., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States; Altshuler D., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States, Harvard Medical School, Boston, MA, United States; Daly M.J., Program in Medical and Population Genetics, Broad Institute of Harvard and MIT, Cambridge, MA, United States, Harvard Medical School, Boston, MA, United States","Recent advances in sequencing technology make it possible to comprehensively catalog genetic variation in population samples, creating a foundation for understanding human disease, ancestry and evolution. The amounts of raw data produced are prodigious, and many computational steps are required to translate this output into high-quality variant calls. We present a unified analytic framework to discover and genotype variation among multiple samples simultaneously that achieves sensitive and specific results across five sequencing technologies and three distinct, canonical experimental designs. Our process includes (i) initial read mapping; (ii) local realignment around indels; (iii) base quality score recalibration; (iv) SNP discovery and genotyping to find all potential variants; and (v) machine learning to separate true segregating variation from machine artifacts common to next-generation sequencing technologies. We here discuss the application of these tools, instantiated in the Genome Analysis Toolkit, to deep whole-genome, whole-exome capture and multi-sample low-pass (∼1/44×) 1000 Genomes Project datasets. © 2011 Nature America, Inc. All rights reserved.","","Data Interpretation, Statistical; Databases, Nucleic Acid; Exons; Genetic Variation; Genetics, Population; Genome, Human; Genotype; Humans; Polymorphism, Single Nucleotide; Sequence Alignment; Sequence Analysis, DNA; Software; article; DNA sequence; gene mapping; genetic variability; genome analysis; genotype; nonhuman; priority journal; single nucleotide polymorphism","","15461718","","NGENE","21478889","Article","Scopus","2-s2.0-79955483667"
"Friedman Y.; Balaga O.; Linial M.","Friedman, Yitzhak (36189915500); Balaga, Ohad (55164769700); Linial, Michal (7103138031)","36189915500; 55164769700; 7103138031","Working together: Combinatorial regulation by microRNAs","2013","Advances in Experimental Medicine and Biology","22","10.1007/978-94-7-5590-1_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934439280&doi=10.1007%2f978-94-7-5590-1_16&partnerID=40&md5=937499ce21b44741f1a28df0319b04fa","Department of Biological Chemistry, Institute of Life Sciences, Hebrew University of Jerusalem, Jerusalem 91904, Israel; School of Computer Science and Engineering, Hebrew University of Jerusalem, Jerusalem 91904, Israel","Friedman Y., Department of Biological Chemistry, Institute of Life Sciences, Hebrew University of Jerusalem, Jerusalem 91904, Israel; Balaga O., School of Computer Science and Engineering, Hebrew University of Jerusalem, Jerusalem 91904, Israel; Linial M., Department of Biological Chemistry, Institute of Life Sciences, Hebrew University of Jerusalem, Jerusalem 91904, Israel","MicroRNAs (miRNAs) negatively regulate gene expression level of mRNA post-transcriptionally. Deep sequencing and large-scale screening methods have yielded about 1,500 miRNA sequences in human. Each miRNA contains a seed sequence that is required, but not sufficient, for the correct matching with its targets. Recent technological advances make it possible to capture the miRNAs with their cognate mRNAs at the RISC complex. These experiments have revealed thousands of validated mRNA-miRNA pairing events. In the context of human stem cells, 90% of the identified transcripts appear to be paired with at least two different miRNAs. In this chapter, we present a comprehensive outline for a combinatorial regulation mode by miRNAs. Initially, we summarize the computational and experimental evidence that support a combined effect of multiple miRNAs. Then, we describe miRror2.0, a platform specifically convened to consider the likelihood of miRNAs cooperativity in view of the targets, tissues and cell lines. We show that results from miRror2.0 can be further refined by an iterative procedure, calls Psi-miRror that gauges the robustness of the regulation. We illustrate the combinatorial regulation projected onto graphs of human pathways and show that these pathways are amenable to disruption by a small set of miRNAs. Finally, we propose that miRNA combinatorial regulation is an attractive regulatory strategy not only at the level of single target, but also at the level of pathways and cellular homeostasis. The joint operation of miRNAs is a powerful means to overcome the low specificity inherent in each individual miRNA. © Springer Science+Business Media Dordrecht 2013.","3′ -UTR; Bioinformatics; Database; Deep sequencing; Genomics; MicroRNA; Prediction tools; Regulatory pathway","Animals; Gene Expression Regulation; Humans; MicroRNAs; RNA, Messenger; Signal Transduction; microRNA; messenger RNA; microRNA; MLCS; MLOWN; 3' untranslated region; article; binding site; biochemistry; biogenesis; cell differentiation; gene expression profiling; gene expression regulation; gene mapping; gene targeting; genetic transcription; human; intron; machine learning; mass spectrometry; mathematical analysis; mathematical computing; metabolic stress; nomenclature; nonhuman; organogenesis; prediction; priority journal; RNA sequence; sequence analysis; transcription regulation; transcriptomics; animal; genetics; metabolism; review; signal transduction","Springer New York LLC","00652598","978-940075589-5","AEMBA","23377980","Article","Scopus","2-s2.0-84934439280"
"Sturm M.; Hackenberg M.; Langenberger D.; Frishman D.","Sturm, Martin (35070436100); Hackenberg, Michael (6602124331); Langenberger, David (25635871300); Frishman, Dmitrij (7004860440)","35070436100; 6602124331; 25635871300; 7004860440","TargetSpy: A supervised machine learning approach for microRNA target prediction","2010","BMC Bioinformatics","138","10.1186/1471-2105-11-292","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952671774&doi=10.1186%2f1471-2105-11-292&partnerID=40&md5=8f883ff05b2cfd83cc5ef969c268b37d","Institute of Bioinformatics and Systems Biology, Helmholtz Zentrum München, 85764 Neuherberg, Ingolstädter Landstr. 1, Germany; Dpto. de Genetica, Facultad de Ciencias, Universidad de Granada, E-18071, Granada, Spain; Bioinformatics Group, Department of Computer Science and Interdisciplinary Center for Bioinformatics, University of Leipzig, D-04107 Leipzig, Haertelstrasse 16-18, Germany; Department of Genome Oriented Bioinformatics, Technische Universität München, Life and Food Science Center Weihenstephan, D-85354 Freising-Weihenstephan, Am Forum 1, Germany","Sturm M., Institute of Bioinformatics and Systems Biology, Helmholtz Zentrum München, 85764 Neuherberg, Ingolstädter Landstr. 1, Germany; Hackenberg M., Dpto. de Genetica, Facultad de Ciencias, Universidad de Granada, E-18071, Granada, Spain; Langenberger D., Bioinformatics Group, Department of Computer Science and Interdisciplinary Center for Bioinformatics, University of Leipzig, D-04107 Leipzig, Haertelstrasse 16-18, Germany, Department of Genome Oriented Bioinformatics, Technische Universität München, Life and Food Science Center Weihenstephan, D-85354 Freising-Weihenstephan, Am Forum 1, Germany; Frishman D., Institute of Bioinformatics and Systems Biology, Helmholtz Zentrum München, 85764 Neuherberg, Ingolstädter Landstr. 1, Germany, Department of Genome Oriented Bioinformatics, Technische Universität München, Life and Food Science Center Weihenstephan, D-85354 Freising-Weihenstephan, Am Forum 1, Germany","Background: Virtually all currently available microRNA target site prediction algorithms require the presence of a (conserved) seed match to the 5' end of the microRNA. Recently however, it has been shown that this requirement might be too stringent, leading to a substantial number of missed target sites.Results: We developed TargetSpy, a novel computational approach for predicting target sites regardless of the presence of a seed match. It is based on machine learning and automatic feature selection using a wide spectrum of compositional, structural, and base pairing features covering current biological knowledge. Our model does not rely on evolutionary conservation, which allows the detection of species-specific interactions and makes TargetSpy suitable for analyzing unconserved genomic sequences.In order to allow for an unbiased comparison of TargetSpy to other methods, we classified all algorithms into three groups: I) no seed match requirement, II) seed match requirement, and III) conserved seed match requirement. TargetSpy predictions for classes II and III are generated by appropriate postfiltering. On a human dataset revealing fold-change in protein production for five selected microRNAs our method shows superior performance in all classes. In Drosophila melanogaster not only our class II and III predictions are on par with other algorithms, but notably the class I (no-seed) predictions are just marginally less accurate. We estimate that TargetSpy predicts between 26 and 112 functional target sites without a seed match per microRNA that are missed by all other currently available algorithms.Conclusion: Only a few algorithms can predict target sites without demanding a seed match and TargetSpy demonstrates a substantial improvement in prediction accuracy in that class. Furthermore, when conservation and the presence of a seed match are required, the performance is comparable with state-of-the-art algorithms. TargetSpy was trained on mouse and performs well in human and drosophila, suggesting that it may be applicable to a broad range of species. Moreover, we have demonstrated that the application of machine learning techniques in combination with upcoming deep sequencing data results in a powerful microRNA target site prediction tool http://www.targetspy.org. © 2010 Sturm et al; licensee BioMed Central Ltd.","","Animals; Artificial Intelligence; Drosophila; MicroRNAs; Proteins; RNA, Messenger; Software; Drosophila melanogaster; Algorithms; Conservation; Forecasting; Learning systems; messenger RNA; microRNA; protein; Automatic feature selection; Computational approach; Drosophila melanogaster; Evolutionary conservations; Machine learning techniques; Microrna target predictions; State-of-the-art algorithms; Supervised machine learning; animal; article; artificial intelligence; chemistry; computer program; Drosophila; genetics; RNA","","14712105","","BBMIC","20509939","Article","Scopus","2-s2.0-77952671774"
"Halder S.; Varkuti B.; Bogdan M.; Kübler A.; Rosenstiel W.; Sitaram R.; Birbaumer N.","Halder, S. (25226601600); Varkuti, B. (23981378000); Bogdan, M. (12140637700); Kübler, A. (7005589429); Rosenstiel, W. (7006528940); Sitaram, R. (15835525200); Birbaumer, N. (7101787804)","25226601600; 23981378000; 12140637700; 7005589429; 7006528940; 15835525200; 7101787804","Prediction of brain-computer interface aptitude from individual brain structure","2013","Frontiers in Human Neuroscience","84","10.3389/fnhum.2013.00105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933680003&doi=10.3389%2ffnhum.2013.00105&partnerID=40&md5=f39b917c60c38e72238fcab304395a3f","Department of Psychology I, University of Würzburg, Würzburg, Germany; Institute of Medical Psychology and Behavioral Neurobiology, University of Tübingen, Tübingen, Germany; Wilhelm-Schickard Institute for Computer Science, University of Tübingen, Tübingen, Germany; Department of Computer Engineering, University of Leipzig, Leipzig, Germany; Department of Biomedical Engineering, University of Florida, Gainesville, FL, United States; Ospedale San Camillo, Laboratorio di Neuroscience Comportamentale, Istituto di Ricovero e Cura a Carattere Scientifico, Venezia, Italy","Halder S., Department of Psychology I, University of Würzburg, Würzburg, Germany, Institute of Medical Psychology and Behavioral Neurobiology, University of Tübingen, Tübingen, Germany, Wilhelm-Schickard Institute for Computer Science, University of Tübingen, Tübingen, Germany; Varkuti B., Department of Psychology I, University of Würzburg, Würzburg, Germany; Bogdan M., Wilhelm-Schickard Institute for Computer Science, University of Tübingen, Tübingen, Germany, Department of Computer Engineering, University of Leipzig, Leipzig, Germany; Kübler A., Department of Psychology I, University of Würzburg, Würzburg, Germany; Rosenstiel W., Wilhelm-Schickard Institute for Computer Science, University of Tübingen, Tübingen, Germany; Sitaram R., Department of Biomedical Engineering, University of Florida, Gainesville, FL, United States; Birbaumer N., Institute of Medical Psychology and Behavioral Neurobiology, University of Tübingen, Tübingen, Germany, Ospedale San Camillo, Laboratorio di Neuroscience Comportamentale, Istituto di Ricovero e Cura a Carattere Scientifico, Venezia, Italy","Objective: Brain-computer interface (BCI) provide a non-muscular communication channel for patients with impairments of the motor system. A significant number of BCI users is unable to obtain voluntary control of a BCI-system in proper time. This makes methods that can be used to determine the aptitude of a user necessary. Methods: We hypothesized that integrity and connectivity of involved white matter connections may serve as a predictor of individual BCI-performance. Therefore, we analyzed structural data from anatomical scans and DTI of motor imagery BCI-users differentiated into high and low BCI-aptitude groups based on their overall performance. Results: Using a machine learning classification method we identified discriminating structural brain trait features and correlated the best features with a continuous measure of individual BCI-performance. Prediction of the aptitude group of each participant was possible with near perfect accuracy (one error). Conclusions: Tissue volumetric analysis yielded only poor classification results. In contrast, the structural integrity and myelination quality of deep white matter structures such as the Corpus Callosum, Cingulum, and Superior Fronto-Occipital Fascicle were positively correlated with individual BCI-performance. Significance: This confirms that structural brain traits contribute to individual performance in BCI use. © 2013 Halder, Varkuti, Bogdan, Kübler, Rosenstiel, Sitaram and Birbaumer.","Aptitude; BCI; DTI; Fractional anisotropy; Motor imagery","adult; aptitude; article; brain computer interface; cingulum; controlled study; corpus callosum; diffusion tensor imaging; electroencephalograph; female; fractional anisotropy; human; human experiment; machine learning; male; nerve cell network; neuroanatomy; neuroimaging; normal human; prediction; superior fronto occipital fascicle; volumetry; white matter","Frontiers Media S. A.","16625161","","","","Article","Scopus","2-s2.0-84933680003"
"Vincent P.","Vincent, Pascal (57203214842)","57203214842","A connection between scorematching and denoising autoencoders","2011","Neural Computation","473","10.1162/NECO_a_00142","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959575293&doi=10.1162%2fNECO_a_00142&partnerID=40&md5=06d7d54dc22d5046c78370fad3fcf6e0","Département d'Informatique, Université de Montréal, Montréal, QC H3C 3J7, Canada","Vincent P., Département d'Informatique, Université de Montréal, Montréal, QC H3C 3J7, Canada","Denoising autoencoders have been previously shown to be competitive alternatives to restricted Boltzmann machines for unsupervised pretraining of each layer of a deep architecture. We show that a simple denoising autoencoder training criterion is equivalent to matching the score (with respect to the data) of a specific energy-based model to that of a nonparametric Parzen density estimator of the data. This yields several useful insights. It defines a proper probabilistic model for the denoising autoencoder technique, which makes it in principle possible to sample from them or rank examples by their energy. It suggests a different way to apply score matching that is related to learning to denoise and does not require computing second derivatives. It justifies the use of tied weights between the encoder and decoder and suggests ways to extend the success of denoising autoencoders to a larger family of energy-based models. © 2011 Massachusetts Institute of Technology.","","Computer Simulation; Models, Statistical; article; computer simulation; statistical model","","1530888X","","","21492012","Article","Scopus","2-s2.0-79959575293"
"Messina F.C.; Cooper D.; Huffman G.; Bartkus E.; Wilbur L.","Messina, Frank C. (55781353200); Cooper, Dylan (45660929700); Huffman, Gretchen (55443307900); Bartkus, Edward (6602373366); Wilbur, Lee (6602580496)","55781353200; 45660929700; 55443307900; 6602373366; 6602580496","A human cadaver fascial compartment pressure measurement model","2013","Journal of Emergency Medicine","2","10.1016/j.jemermed.2013.05.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884674750&doi=10.1016%2fj.jemermed.2013.05.008&partnerID=40&md5=8550181393ceb734b87983c695946e15","Department of Emergency Medicine, Indiana University School of Medicine, Indianapolis, IN 46202, 1050 Wishard Blvd., R2200, United States","Messina F.C., Department of Emergency Medicine, Indiana University School of Medicine, Indianapolis, IN 46202, 1050 Wishard Blvd., R2200, United States; Cooper D., Department of Emergency Medicine, Indiana University School of Medicine, Indianapolis, IN 46202, 1050 Wishard Blvd., R2200, United States; Huffman G., Department of Emergency Medicine, Indiana University School of Medicine, Indianapolis, IN 46202, 1050 Wishard Blvd., R2200, United States; Bartkus E., Department of Emergency Medicine, Indiana University School of Medicine, Indianapolis, IN 46202, 1050 Wishard Blvd., R2200, United States; Wilbur L., Department of Emergency Medicine, Indiana University School of Medicine, Indianapolis, IN 46202, 1050 Wishard Blvd., R2200, United States","Background Fresh human cadavers provide an effective model for procedural training. Currently, there are no realistic models to teach fascial compartment pressure measurement. Objectives We created a human cadaver fascial compartment pressure measurement model and studied its feasibility with a pre-post design. Methods Three faculty members, following instructions from a common procedure textbook, used a standard handheld intra-compartment pressure monitor (Stryker®, Kalamazoo, MI) to measure baseline pressures ("" unembalmed"") in the anterior, lateral, deep posterior, and superficial posterior compartments of the lower legs of a fresh human cadaver. The right femoral artery was then identified by superficial dissection, cannulated distally towards the lower leg, and connected to a standard embalming machine. After a 5-min infusion, the same three faculty members re-measured pressures (""embalmed"") of the same compartments on the cannulated right leg. Unembalmed and embalmed readings for each compartment, and baseline readings for each leg, were compared using a two-sided paired t-test. Results The mean baseline compartment pressures did not differ between the right and left legs. Using the embalming machine, compartment pressure readings increased significantly over baseline for three of four fascial compartments; all in mm Hg (±SD): anterior from 40 (±9) to 143 (±44) (p = 0.08); lateral from 22 (±2.5) to 160 (±4.3) (p < 0.01); deep posterior from 34 (±7.9) to 161 (±15) (p < 0.01); superficial posterior from 33 (±0) to 140 (±13) (p < 0.01). Conclusion We created a novel and measurable fascial compartment pressure measurement model in a fresh human cadaver using a standard embalming machine. Set-up is minimal and the model can be incorporated into teaching curricula. © 2013 Elsevier Inc.","compartment syndrome; education; fascial compartment pressure measurement; human cadaver; procedural training","Anterior Compartment Syndrome; Cadaver; Education, Medical; Embalming; Fascia; Humans; Manometry; Pressure; compartment syndrome; education; fascial compartment pressure measurement; human cadaver; procedural training; article; biological model; cadaver; compartment syndrome; education program; emergency medicine; fascia; fascial compartment pressure measurement; femoral artery; human; human tissue; learning; lower leg; machine; manometer; observational study; posthumous care; pressure measurement; priority journal; procedures; residency education; simulation; training","","07364679","","JEMMD","23845521","Article","Scopus","2-s2.0-84884674750"
"Zhou S.; Chen Q.; Wang X.","Zhou, Shusen (36189232700); Chen, Qingcai (34869206800); Wang, Xiaolong (9276464700)","36189232700; 34869206800; 9276464700","Convolutional deep networks for visual data classification","2013","Neural Processing Letters","25","10.1007/s11063-012-9260-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880512710&doi=10.1007%2fs11063-012-9260-y&partnerID=40&md5=ef0cdf115f9d395e099fe061987575c4","Key Laboratory of Network Oriented Intelligent Computation, Shenzhen Graduate School, Harbin Institute of Technology, Harbin, China","Zhou S., Key Laboratory of Network Oriented Intelligent Computation, Shenzhen Graduate School, Harbin Institute of Technology, Harbin, China; Chen Q., Key Laboratory of Network Oriented Intelligent Computation, Shenzhen Graduate School, Harbin Institute of Technology, Harbin, China; Wang X., Key Laboratory of Network Oriented Intelligent Computation, Shenzhen Graduate School, Harbin Institute of Technology, Harbin, China","This paper develops a semi-supervised learning algorithm called convolutional deep networks (CDN), to address the image classification problem with deep learning. First, we construct the previous several hidden layers using convolutional restricted Boltzmann machines, which can reduce the dimension and abstract the information of the images effectively. Second, we construct the following hidden layers using restricted Boltzmann machines, which can abstract the information of images quickly. Third, the constructed deep architecture is fine-tuned by gradient-descent based supervised learning with an exponential loss function. CDN can reduce the dimension and abstract the information of the images at the same time efficiently. More importantly, the abstraction and classification procedure of CDN use the same deep architecture to optimize the same parameter in different steps continuously, which can improve the learning ability effectively. We did several experiments on two standard image datasets, and show that CDN are competitive with both representative semi-supervised classifiers and existing deep learning techniques. © 2012 Springer Science+Business Media New York.","Convolutional neural networks; Deep learning; Semi-supervised learning; Visual data classification","Convolution; Image classification; Network architecture; Neural networks; Supervised learning; Classification procedure; Convolutional neural network; Deep architectures; Deep learning; Exponential loss function; Restricted boltzmann machine; Semi-supervised learning; Visual data; Classification (of information)","","1573773X","","NPLEF","","Article","Scopus","2-s2.0-84880512710"
"Schoening T.; Bergmann M.; Ontrup J.; Taylor J.; Dannheim J.; Gutt J.; Purser A.; Nattkemper T.W.","Schoening, Timm (35148374400); Bergmann, Melanie (7202017093); Ontrup, Jörg (7801485255); Taylor, James (56512773900); Dannheim, Jennifer (20733530000); Gutt, Julian (56186618700); Purser, Autun (35303629300); Nattkemper, Tim W. (6603561865)","35148374400; 7202017093; 7801485255; 56512773900; 20733530000; 56186618700; 35303629300; 6603561865","Semi-automated image analysis for the assessment of megafaunal densities at the Artic deep-sea observatory HAUSGARTEN","2012","PLoS ONE","89","10.1371/journal.pone.0038179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861879396&doi=10.1371%2fjournal.pone.0038179&partnerID=40&md5=9fa971d2ee170f916bca21088dadeaaf","Biodata Mining Group, Faculty of Technology, Bielefeld University, Bielefeld, Germany; HGF-MPG Group for Deep-Sea Ecology and Technology, Alfred Wegener Institute for Polar and Marine Research, Bremerhaven, Germany; University of Glasgow, Glasgow, United Kingdom; School of Engineering and Science, Jacobs University, Bremen, Germany","Schoening T., Biodata Mining Group, Faculty of Technology, Bielefeld University, Bielefeld, Germany; Bergmann M., HGF-MPG Group for Deep-Sea Ecology and Technology, Alfred Wegener Institute for Polar and Marine Research, Bremerhaven, Germany; Ontrup J., Biodata Mining Group, Faculty of Technology, Bielefeld University, Bielefeld, Germany; Taylor J., University of Glasgow, Glasgow, United Kingdom; Dannheim J., HGF-MPG Group for Deep-Sea Ecology and Technology, Alfred Wegener Institute for Polar and Marine Research, Bremerhaven, Germany; Gutt J., HGF-MPG Group for Deep-Sea Ecology and Technology, Alfred Wegener Institute for Polar and Marine Research, Bremerhaven, Germany; Purser A., School of Engineering and Science, Jacobs University, Bremen, Germany; Nattkemper T.W., Biodata Mining Group, Faculty of Technology, Bielefeld University, Bielefeld, Germany","Megafauna play an important role in benthic ecosystem function and are sensitive indicators of environmental change. Non-invasive monitoring of benthic communities can be accomplished by seafloor imaging. However, manual quantification of megafauna in images is labor-intensive and therefore, this organism size class is often neglected in ecosystem studies. Automated image analysis has been proposed as a possible approach to such analysis, but the heterogeneity of megafaunal communities poses a non-trivial challenge for such automated techniques. Here, the potential of a generalized object detection architecture, referred to as iSIS (intelligent Screening of underwater Image Sequences), for the quantification of a heterogenous group of megafauna taxa is investigated. The iSIS system is tuned for a particular image sequence (i.e. a transect) using a small subset of the images, in which megafauna taxa positions were previously marked by an expert. To investigate the potential of iSIS and compare its results with those obtained from human experts, a group of eight different taxa from one camera transect of seafloor images taken at the Arctic deep-sea observatory HAUSGARTEN is used. The results show that inter- and intra-observer agreements of human experts exhibit considerable variation between the species, with a similar degree of variation apparent in the automatically derived results obtained by iSIS. Whilst some taxa (e. g. Bathycrinus stalks, Kolga hyalina, small white sea anemone) were well detected by iSIS (i. e. overall Sensitivity: 87%, overall Positive Predictive Value: 67%), some taxa such as the small sea cucumber Elpidia heckeri remain challenging, for both human observers and iSIS. © 2012 Schoening et al.","","Arctic Regions; Automation; Biodiversity; Oceans and Seas; Remote Sensing Technology; Actiniaria; Bathycrinus; Elpidia; Holothuroidea; Kolga hyalina; Pieris rapae; article; automation; Bathycrinus; deep sea; density; ecosystem; environmental change; fauna; image analysis; intelligent Screening of underwater Image Sequences; Kolga hyalina; machine learning; megafaunal density; nonhuman; predictive value; sea anemone; sensitivity analysis; species difference; sponge (Porifera)","","19326203","","","22719868","Article","Scopus","2-s2.0-84861879396"
"Wong S.; Baltuch G.H.; Jaggi J.L.; Danish S.F.","Wong, S. (12781047500); Baltuch, G.H. (6701814068); Jaggi, J.L. (7003942576); Danish, S.F. (8316644500)","12781047500; 6701814068; 7003942576; 8316644500","Functional localization and visualization of the subthalamic nucleus from microelectrode recordings acquired during DBS surgery with unsupervised machine learning.","2009","Journal of neural engineering","76","10.1088/1741-2560/6/2/026006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-65649088286&doi=10.1088%2f1741-2560%2f6%2f2%2f026006&partnerID=40&md5=3b0265a2ed04ce4dedb8062a79bd20e4","Department of Neurology, Hospital of the University of Pennsylvania, 3 West Gates Bldg, 3400 Spruce Street, Philadelphia, 19104, PA, United States","Wong S., Department of Neurology, Hospital of the University of Pennsylvania, 3 West Gates Bldg, 3400 Spruce Street, Philadelphia, 19104, PA, United States; Baltuch G.H., Department of Neurology, Hospital of the University of Pennsylvania, 3 West Gates Bldg, 3400 Spruce Street, Philadelphia, 19104, PA, United States; Jaggi J.L., Department of Neurology, Hospital of the University of Pennsylvania, 3 West Gates Bldg, 3400 Spruce Street, Philadelphia, 19104, PA, United States; Danish S.F., Department of Neurology, Hospital of the University of Pennsylvania, 3 West Gates Bldg, 3400 Spruce Street, Philadelphia, 19104, PA, United States","Microelectrode recordings are a useful adjunctive method for subthalamic nucleus localization during deep brain stimulation surgery for Parkinson's disease. Attempts to quantitate and standardize this process, using single computational measures of neural activity, have been limited by variability in patient neurophysiology and recording conditions. Investigators have suggested that a multi-feature approach may be necessary for automated approaches to perform within acceptable clinical standards. We present a novel data visualization algorithm and several unique features that address these shortcomings. The algorithm extracts multiple computational features from the microelectrode neurophysiology and integrates them with tools from unsupervised machine learning. The resulting colour-coded map of neural activity reveals activity transitions that correspond to the anatomic boundaries of subcortical structures. Using these maps, a non-neurophysiologist is able to achieve sensitivities of 90% and 95% for STN entry and exit, respectively, to within 0.5 mm accuracy of the current gold standard. The accuracy of this technique is attributed to the multi-feature approach. This activity map can simplify and standardize the process of localizing the subthalamic nucleus (STN) for neurostimulation. Because this method does not require a stationary electrode for careful recording of unit activity for spike sorting, the length of the operation may be shortened.","","Action Potentials; Algorithms; Artificial Intelligence; Cluster Analysis; Deep Brain Stimulation; Fuzzy Logic; Humans; Microelectrodes; Parkinson Disease; Pattern Recognition, Automated; Subthalamic Nucleus; action potential; algorithm; article; artificial intelligence; automated pattern recognition; brain depth stimulation; cluster analysis; fuzzy logic; histology; human; methodology; microelectrode; Parkinson disease; physiology; subthalamic nucleus","","17412552","","","19287077","Article","Scopus","2-s2.0-65649088286"
"Le Roux N.; Bengio Y.","Le Roux, Nicolas (55883429300); Bengio, Yoshua (7003958245)","55883429300; 7003958245","Representational power of restricted boltzmann machines and deep belief networks","2008","Neural Computation","612","10.1162/neco.2008.04-07-510","https://www.scopus.com/inward/record.uri?eid=2-s2.0-45749110924&doi=10.1162%2fneco.2008.04-07-510&partnerID=40&md5=001301c4787134a80d5f25f28b163aa6","Département Informatique et Recherche Opérationnelle, Université de Montréal, Montréal, QC H3C 3J7, Canada","Le Roux N., Département Informatique et Recherche Opérationnelle, Université de Montréal, Montréal, QC H3C 3J7, Canada; Bengio Y., Département Informatique et Recherche Opérationnelle, Université de Montréal, Montréal, QC H3C 3J7, Canada","Deep belief networks (DBN) are generative neural network models with many layers of hidden explanatory factors, recently introduced by Hinton,Osindero, and Teh (2006) alongwith a greedy layer-wise unsupervised learning algorithm. The building block of a DBN is a probabilistic model called a restricted Boltzmann machine (RBM), used to represent one layer of the model. Restricted Boltzmann machines are interesting because inference is easy in them and because they have been successfully used as building blocks for training deeper models. We first prove that adding hidden units yields strictly improvedmodeling power,while a second theorem shows that RBMs are universal approximators of discrete distributions. We then study the question of whether DBNs with more layers are strictly more powerful in terms of representational power. This suggests a new and less greedy criterion for training RBMs within DBNs. © 2008 Massachusetts Institute of Technology.","","Algorithms; Animals; Computer Simulation; Humans; Learning; Models, Statistical; Neural Networks (Computer); Signal Processing, Computer-Assisted; algorithm; animal; article; artificial neural network; computer simulation; human; learning; physiology; signal processing; statistical model","","1530888X","","","18254699","Article","Scopus","2-s2.0-45749110924"
"Wang X.; Tian X.; Cheng Y.","Wang, Xuesong (56090094900); Tian, Xilan (15832742700); Cheng, Yuhu (9733966500)","56090094900; 15832742700; 9733966500","Value approximation with least squares support vector machine in reinforcement learning system","2007","Journal of Computational and Theoretical Nanoscience","19","10.1166/jctn.2007.2413","https://www.scopus.com/inward/record.uri?eid=2-s2.0-47149095559&doi=10.1166%2fjctn.2007.2413&partnerID=40&md5=9d4f228efce47b0fc010322d7c2c8803","School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, Jiangsu 221008, China","Wang X., School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, Jiangsu 221008, China; Tian X., School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, Jiangsu 221008, China; Cheng Y., School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, Jiangsu 221008, China","In this paper, we propose a new Q learning system based on the least squares support vector machine (LS-SVM) for continuous state space. A least squares support vector machine is used to realize a mapping from state-action pair to Q value function. A sliding time window mechanism and a criterion of adding the new observed data to the training sample set of LS-SVM are introduced into the method. Based on the on-line estimated Q values of all the state-action pairs from LS-SVM, a stochastic action selector is used to generate stochastically an actual action according to Boltzmann-Gibbs distribution of Q values. In order to improve the learning speed, a simulated annealing method is used to adjust the temperature value of Boltzmann-Gibbs distribution dynamically. The simulation results of Mountain Car Control show that the proposed Q learning method has characteristics of a simple control structure and high learning efficiency. Copyright © 2007 American Scientific Publishers. All rights reserved.","Boltzmann-Gibbs distribution; Least squares support vector machine; Reinforcement learning; Value approximation","Deep neural networks; Learning systems; Least squares approximations; Simulated annealing; Stochastic systems; Support vector machines; Vector spaces; Vectors; Boltzmann-Gibbs distribution; Continuous State Space; Learning efficiency; Least squares support vector machines; Simulated annealing method; Sliding time windows; Temperature values; Value approximation; Reinforcement learning","American Scientific Publishers","15461955","","","","Article","Scopus","2-s2.0-47149095559"
"Prokop L.; Mišák S.; Snášel V.; Platoš J.; Krömer P.","Prokop, Lukáš (23393638900); Mišák, Stanislav (34977261800); Snášel, Václav (57195632134); Platoš, Jan (23397962200); Krömer, Pavel (8907452600)","23393638900; 34977261800; 57195632134; 23397962200; 8907452600","Supervised learning of photovoltaic power plant output prediction models","2013","Neural Network World","18","10.14311/NNW.2013.23.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885672403&doi=10.14311%2fNNW.2013.23.020&partnerID=40&md5=accbeab4c3475b4d2a7897458ef27590","Department of Electric Power Engineering, Faculty of Electrical Engineering and Computer Science, VŠB - Technical University of Ostrava, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic; Department of Computer Science, Faculty of Electrical Engineering and Computer Science, VŠB - Technical University of Ostrava, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic; IT4Innovations, European Center for Excelence, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic","Prokop L., Department of Electric Power Engineering, Faculty of Electrical Engineering and Computer Science, VŠB - Technical University of Ostrava, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic; Mišák S., Department of Electric Power Engineering, Faculty of Electrical Engineering and Computer Science, VŠB - Technical University of Ostrava, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic; Snášel V., Department of Computer Science, Faculty of Electrical Engineering and Computer Science, VŠB - Technical University of Ostrava, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic, IT4Innovations, European Center for Excelence, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic; Platoš J., Department of Computer Science, Faculty of Electrical Engineering and Computer Science, VŠB - Technical University of Ostrava, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic, IT4Innovations, European Center for Excelence, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic; Krömer P., Department of Computer Science, Faculty of Electrical Engineering and Computer Science, VŠB - Technical University of Ostrava, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic, IT4Innovations, European Center for Excelence, 708 33 Ostrava - Poruba, 17. listopadu 15, Czech Republic","This article presents an application of evolutionary fuzzy rules to the modeling and prediction of power output of a real-world Photovoltaic Power Plant (PVPP). The method is compared to artificial neural networks and support vector regression that were also used to build predictors in order to analyse a time-series like data describing the production of the PVPP. The models of the PVPP are created using different supervised machine learning methods in order to forecast the short-term output of the power plant and compare the accuracy of the prediction. © CTU FTS 2013.","Artificial neural networks; Fuzzy rules; Regression; Supervised learning; Support vector machines","Deep neural networks; Forecasting; Fuzzy neural networks; Fuzzy rules; Learning systems; Neural networks; Photovoltaic cells; Supervised learning; Support vector machines; Modeling and predictions; Photovoltaic power plant; Power out put; Prediction model; Regression; Short term; Supervised machine learning; Support vector regression (SVR); Fuzzy inference","Institute of Computer Science","12100552","","NNWOF","","Article","Scopus","2-s2.0-84885672403"
"Le Roux N.; Heess N.; Shotton J.; Winn J.","Le Roux, Nicolas (55883429300); Heess, Nicolas (36450421000); Shotton, Jamie (23019722900); Winn, John (15621648700)","55883429300; 36450421000; 23019722900; 15621648700","Learning a generative model of images by factoring appearance and shape","2011","Neural Computation","67","10.1162/NECO_a_00086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951571992&doi=10.1162%2fNECO_a_00086&partnerID=40&md5=471ce8a011cd6364eb41efcf3d1db70b","Microsoft Research Cambridge, Machine Learning and Perception, Cambridge CB3 0FB, United Kingdom; Neuroinformatics and Computational Neuroscience Doctoral Training Centre, Institute for Adaptive and Neural Computation, School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, United Kingdom","Le Roux N., Microsoft Research Cambridge, Machine Learning and Perception, Cambridge CB3 0FB, United Kingdom; Heess N., Neuroinformatics and Computational Neuroscience Doctoral Training Centre, Institute for Adaptive and Neural Computation, School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, United Kingdom; Shotton J., Microsoft Research Cambridge, Machine Learning and Perception, Cambridge CB3 0FB, United Kingdom; Winn J., Microsoft Research Cambridge, Machine Learning and Perception, Cambridge CB3 0FB, United Kingdom","Computer vision has grown tremendously in the past two decades. Despite all efforts, existing attempts at matching parts of the human visual system's extraordinary ability to understand visual scenes lack either scope or power. By combining the advantages of general low-level generative models and powerful layer-based and hierarchical models, this work aims at being a first step toward richer, more flexible models of images. After comparing various types of restricted Boltzmann machines (RBMs) able to model continuous-valued data, we introduce our basic model, the masked RBM, which explicitly models occlusion boundaries in image patches by factoring the appearance of any patch region from its shape.We then propose a generativemodel of larger images using a field of such RBMs. Finally, we discuss how masked RBMs could be stacked to form a deep model able to generate more complicated structures and suitable for various tasks such as segmentation or object recognition. © 2011 Massachusetts Institute of Technology.","","","","1530888X","","","","Article","Scopus","2-s2.0-79951571992"
"Salvatori G.; Ronco F.; Bonello M.; Bottero M.","Salvatori, Gabriella (7004178843); Ronco, F. (6701363273); Bonello, M. (6603847930); Bottero, M. (7003670287)","7004178843; 6701363273; 6603847930; 7003670287","Management of fluid overload in congestive heart failure: Learning from a case report","2006","International Journal of Artificial Organs","5","10.1177/039139880602900205","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645832344&doi=10.1177%2f039139880602900205&partnerID=40&md5=6369a891e13c1d1611203bae8108115a","Department of Intensive Care, Neprhology and Cardiology, St. Bortolo Hospital, 36100 Vicenza, Viale Rodolfi 37, Italy","Salvatori G., Department of Intensive Care, Neprhology and Cardiology, St. Bortolo Hospital, 36100 Vicenza, Viale Rodolfi 37, Italy; Ronco F., Department of Intensive Care, Neprhology and Cardiology, St. Bortolo Hospital, 36100 Vicenza, Viale Rodolfi 37, Italy; Bonello M., Department of Intensive Care, Neprhology and Cardiology, St. Bortolo Hospital, 36100 Vicenza, Viale Rodolfi 37, Italy; Bottero M., Department of Intensive Care, Neprhology and Cardiology, St. Bortolo Hospital, 36100 Vicenza, Viale Rodolfi 37, Italy","A case of refractory fluid overload due to congestive heart failure and consequent renal insufficiency is reported. The case was approached multidisciplinarily, at the beginning with conservative and pharmacological therapy, subsequently with extracorporeal fluid removal in which a specific attention was payed to the maintenance of circulating blood volume and achievement of dry weight, and finally with chronic peritoneal dialysis as a maintenance therapy. The case seems to summarize the pathway of many patients seen initially in intensive care and cardiology departments and subsequently in nephrological wards. © Wichtig Editore, 2006.","Congestive heart failure; Extracorporeal therapy; Ultrafiltration","acetylsalicylic acid; amiodarone; carvedilol; cefotaxime; dobutamine; dopamine; furosemide; heparin; morphine; omeprazole; oxygen; vitamin D; Blood volumes; Case reports; Congestive heart failures; Dry weight; Extracorporeal therapy; Intensive care; Peritoneal dialysis; aged; anxiety disorder; article; blood volume; cardiology; case report; comorbidity; congestive heart failure; conservative treatment; continuous ambulatory peritoneal dialysis; continuous hemofiltration; deep vein thrombosis; drug use; dry weight; hemodialysis; human; intensive care; kidney failure; maintenance therapy; male; nephrology; percutaneous transluminal angioplasty; slow continuous ultrafiltration; ward; Cardiology","Wichtig Editore s.r.l.","03913988","","IJAOD","16552666","Article","Scopus","2-s2.0-33645832344"
"Zhou S.; Chen Q.; Wang X.","Zhou, Shusen (36189232700); Chen, Qingcai (34869206800); Wang, Xiaolong (9276464700)","36189232700; 34869206800; 9276464700","Active deep learning method for semi-supervised sentiment classification","2013","Neurocomputing","128","10.1016/j.neucom.2013.04.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882929257&doi=10.1016%2fj.neucom.2013.04.017&partnerID=40&md5=e532c8c2a3ab3cf0286acf48471c4b8c","School of Information and Electrical Engineering, Ludong University, Yantai, China; Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China","Zhou S., School of Information and Electrical Engineering, Ludong University, Yantai, China; Chen Q., Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China; Wang X., Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China","In natural language processing community, sentiment classification based on insufficient labeled data is a well-known challenging problem. In this paper, a novel semi-supervised learning algorithm called active deep network (ADN) is proposed to address this problem. First, we propose the semi-supervised learning framework of ADN. ADN is constructed by restricted Boltzmann machines (RBM) with unsupervised learning based on labeled reviews and abundant of unlabeled reviews. Then the constructed structure is fine-tuned by gradient-descent based supervised learning with an exponential loss function. Second, in the semi-supervised learning framework, we apply active learning to identify reviews that should be labeled as training data, then using the selected labeled reviews and all unlabeled reviews to train ADN architecture. Moreover, we combine the information density with ADN, and propose information ADN (IADN) method, which can apply the information density of all unlabeled reviews in choosing the manual labeled reviews. Experiments on five sentiment classification datasets show that ADN and IADN outperform classical semi-supervised learning algorithms, and deep learning techniques applied for sentiment classification. © 2013 Elsevier B.V.","Active learning; Deep learning; Neural networks; Sentiment classification","Learning algorithms; Natural language processing systems; Neural networks; Active Learning; Deep learning; Exponential loss function; Information density; NAtural language processing; Restricted boltzmann machine; Semi-supervised learning; Sentiment classification; article; artificial neural network; classification algorithm; computer network; conceptual framework; learning algorithm; machine learning; mathematical computing; network learning; priority journal; restricted Boltzmann machine; structural equation modeling; Supervised learning","","18728286","","NRCGE","","Article","Scopus","2-s2.0-84882929257"
"Di lena P.; Nagata K.; Baldi P.","Di lena, Pietro (57205150239); Nagata, Ken (54781686700); Baldi, Pierre (7101759672)","57205150239; 54781686700; 7101759672","Deep architectures for protein contact map prediction","2012","Bioinformatics","225","10.1093/bioinformatics/bts475","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867316765&doi=10.1093%2fbioinformatics%2fbts475&partnerID=40&md5=95584715b75968bb2d2990369ca58491","Department of Computer Science, University of California, Irvine, CA 92697, United States; Institute for Genomics and Bioinformatics, University of California, Irvine, CA 92697, United States","Di lena P., Department of Computer Science, University of California, Irvine, CA 92697, United States, Institute for Genomics and Bioinformatics, University of California, Irvine, CA 92697, United States; Nagata K., Department of Computer Science, University of California, Irvine, CA 92697, United States, Institute for Genomics and Bioinformatics, University of California, Irvine, CA 92697, United States; Baldi P., Department of Computer Science, University of California, Irvine, CA 92697, United States, Institute for Genomics and Bioinformatics, University of California, Irvine, CA 92697, United States","Motivation: Residue-residue contact prediction is important for protein structure prediction and other applications. However, the accuracy of current contact predictors often barely exceeds 20% on long-range contacts, falling short of the level required for ab initio structure prediction.Results: Here, we develop a novel machine learning approach for contact map prediction using three steps of increasing resolution. First, we use 2D recursive neural networks to predict coarse contacts and orientations between secondary structure elements. Second, we use an energy-based method to align secondary structure elements and predict contact probabilities between residues in contacting alpha-helices or strands. Third, we use a deep neural network architecture to organize and progressively refine the prediction of contacts, integrating information over both space and time. We train the architecture on a large set of non-redundant proteins and test it on a large set of non-homologous domains, as well as on the set of protein domains used for contact prediction in the two most recent CASP8 and CASP9 experiments. For long-range contacts, the accuracy of the new CMAPpro predictor is close to 30%, a significant increase over existing approaches. © The Author 2012. Published by Oxford University Press. All rights reserved.","","Algorithms; Artificial Intelligence; Computational Biology; Neural Networks (Computer); Protein Structure, Secondary; Protein Structure, Tertiary; Proteins; protein; algorithm; article; artificial intelligence; artificial neural network; biology; chemistry; methodology; protein secondary structure; protein tertiary structure","","14602059","","BOINF","22847931","Article","Scopus","2-s2.0-84867316765"
